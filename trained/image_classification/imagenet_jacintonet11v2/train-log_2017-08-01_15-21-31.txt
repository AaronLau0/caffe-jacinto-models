Logging output to training/imagenet_jacintonet11v2_2017-08-01_15-21-31/train-log_2017-08-01_15-21-31.txt
training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse
training/imagenet_jacintonet11v2_2017-08-01_15-21-31/test
I0801 15:21:33.933498 12170 caffe.cpp:608] This is NVCaffe 0.16.3 started at Tue Aug  1 15:21:33 2017
I0801 15:21:33.933624 12170 caffe.cpp:611] CuDNN version: 6021
I0801 15:21:33.933629 12170 caffe.cpp:612] CuBLAS version: 8000
I0801 15:21:33.933629 12170 caffe.cpp:613] CUDA version: 8000
I0801 15:21:33.933631 12170 caffe.cpp:614] CUDA driver version: 8000
I0801 15:21:34.220325 12170 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0801 15:21:34.220892 12170 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0801 15:21:34.221411 12170 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0801 15:21:34.221925 12170 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0801 15:21:34.221933 12170 caffe.cpp:208] Using GPUs 0, 1, 2
I0801 15:21:34.222254 12170 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0801 15:21:34.222576 12170 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0801 15:21:34.222898 12170 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0801 15:21:34.222934 12170 solver.cpp:42] Solver data type: FLOAT
I0801 15:21:34.222964 12170 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/test.prototxt"
test_iter: 1000
test_interval: 2000
base_lr: 0.1
display: 100
max_iter: 320000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 2
type: "SGD"
I0801 15:21:34.229663 12170 solver.cpp:77] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/train.prototxt
I0801 15:21:34.230083 12170 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0801 15:21:34.230090 12170 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0801 15:21:34.230113 12170 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0801 15:21:34.230296 12170 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 43
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0801 15:21:34.230398 12170 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:34.230403 12170 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:34.230406 12170 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 15:21:34.230410 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.230454 12170 net.cpp:184] Created Layer data (0)
I0801 15:21:34.230459 12170 net.cpp:530] data -> data
I0801 15:21:34.230468 12170 net.cpp:530] data -> label
I0801 15:21:34.230489 12170 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0801 15:21:34.230511 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 15:21:34.231343 12205 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0801 15:21:34.232980 12170 data_layer.cpp:184] [0] ReshapePrefetch 43, 3, 224, 224
I0801 15:21:34.233052 12170 data_layer.cpp:208] [0] Output data size: 43, 3, 224, 224
I0801 15:21:34.233057 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 15:21:34.233077 12170 net.cpp:245] Setting up data
I0801 15:21:34.233084 12170 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 3 224 224 (6472704)
I0801 15:21:34.233088 12170 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 (43)
I0801 15:21:34.233094 12170 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 15:21:34.233098 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.233111 12170 net.cpp:184] Created Layer data/bias (1)
I0801 15:21:34.233115 12170 net.cpp:561] data/bias <- data
I0801 15:21:34.233121 12170 net.cpp:530] data/bias -> data/bias
I0801 15:21:34.235093 12170 net.cpp:245] Setting up data/bias
I0801 15:21:34.235102 12170 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 43 3 224 224 (6472704)
I0801 15:21:34.235110 12170 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 15:21:34.235112 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.235124 12170 net.cpp:184] Created Layer conv1a (2)
I0801 15:21:34.235126 12170 net.cpp:561] conv1a <- data/bias
I0801 15:21:34.235129 12170 net.cpp:530] conv1a -> conv1a
I0801 15:21:34.551529 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 7.97G, req 0G)
I0801 15:21:34.551550 12170 net.cpp:245] Setting up conv1a
I0801 15:21:34.551555 12170 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 43 32 112 112 (17260544)
I0801 15:21:34.551564 12170 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 15:21:34.551568 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.551579 12170 net.cpp:184] Created Layer conv1a/bn (3)
I0801 15:21:34.551582 12170 net.cpp:561] conv1a/bn <- conv1a
I0801 15:21:34.551586 12170 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 15:21:34.552235 12170 net.cpp:245] Setting up conv1a/bn
I0801 15:21:34.552242 12170 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 43 32 112 112 (17260544)
I0801 15:21:34.552250 12170 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 15:21:34.552253 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.552258 12170 net.cpp:184] Created Layer conv1a/relu (4)
I0801 15:21:34.552259 12170 net.cpp:561] conv1a/relu <- conv1a
I0801 15:21:34.552261 12170 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 15:21:34.552273 12170 net.cpp:245] Setting up conv1a/relu
I0801 15:21:34.552276 12170 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 43 32 112 112 (17260544)
I0801 15:21:34.552280 12170 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 15:21:34.552283 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.552290 12170 net.cpp:184] Created Layer conv1b (5)
I0801 15:21:34.552292 12170 net.cpp:561] conv1b <- conv1a
I0801 15:21:34.552295 12170 net.cpp:530] conv1b -> conv1b
I0801 15:21:34.580332 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0G)
I0801 15:21:34.580353 12170 net.cpp:245] Setting up conv1b
I0801 15:21:34.580360 12170 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 43 32 112 112 (17260544)
I0801 15:21:34.580368 12170 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 15:21:34.580373 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.580382 12170 net.cpp:184] Created Layer conv1b/bn (6)
I0801 15:21:34.580401 12170 net.cpp:561] conv1b/bn <- conv1b
I0801 15:21:34.580406 12170 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 15:21:34.581182 12170 net.cpp:245] Setting up conv1b/bn
I0801 15:21:34.581192 12170 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 43 32 112 112 (17260544)
I0801 15:21:34.581198 12170 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 15:21:34.581202 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.581209 12170 net.cpp:184] Created Layer conv1b/relu (7)
I0801 15:21:34.581212 12170 net.cpp:561] conv1b/relu <- conv1b
I0801 15:21:34.581214 12170 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 15:21:34.581218 12170 net.cpp:245] Setting up conv1b/relu
I0801 15:21:34.581221 12170 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 43 32 112 112 (17260544)
I0801 15:21:34.581223 12170 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 15:21:34.581226 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.581233 12170 net.cpp:184] Created Layer pool1 (8)
I0801 15:21:34.581236 12170 net.cpp:561] pool1 <- conv1b
I0801 15:21:34.581239 12170 net.cpp:530] pool1 -> pool1
I0801 15:21:34.581321 12170 net.cpp:245] Setting up pool1
I0801 15:21:34.581326 12170 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 43 32 56 56 (4315136)
I0801 15:21:34.581329 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 15:21:34.581332 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.581346 12170 net.cpp:184] Created Layer res2a_branch2a (9)
I0801 15:21:34.581348 12170 net.cpp:561] res2a_branch2a <- pool1
I0801 15:21:34.581351 12170 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 15:21:34.607944 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.71G, req 0G)
I0801 15:21:34.607960 12170 net.cpp:245] Setting up res2a_branch2a
I0801 15:21:34.607966 12170 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 43 64 56 56 (8630272)
I0801 15:21:34.607973 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.607977 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.607985 12170 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0801 15:21:34.607987 12170 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 15:21:34.607990 12170 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 15:21:34.608773 12170 net.cpp:245] Setting up res2a_branch2a/bn
I0801 15:21:34.608783 12170 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 43 64 56 56 (8630272)
I0801 15:21:34.608790 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.608793 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.608798 12170 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0801 15:21:34.608800 12170 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 15:21:34.608803 12170 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 15:21:34.608808 12170 net.cpp:245] Setting up res2a_branch2a/relu
I0801 15:21:34.608810 12170 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 43 64 56 56 (8630272)
I0801 15:21:34.608814 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 15:21:34.608824 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.608832 12170 net.cpp:184] Created Layer res2a_branch2b (12)
I0801 15:21:34.608836 12170 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 15:21:34.608839 12170 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 15:21:34.622252 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.64G, req 0G)
I0801 15:21:34.622292 12170 net.cpp:245] Setting up res2a_branch2b
I0801 15:21:34.622300 12170 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 43 64 56 56 (8630272)
I0801 15:21:34.622308 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.622314 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.622324 12170 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0801 15:21:34.622328 12170 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 15:21:34.622334 12170 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 15:21:34.623857 12170 net.cpp:245] Setting up res2a_branch2b/bn
I0801 15:21:34.623869 12170 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 43 64 56 56 (8630272)
I0801 15:21:34.623878 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.623881 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.623885 12170 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0801 15:21:34.623888 12170 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 15:21:34.623893 12170 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 15:21:34.623898 12170 net.cpp:245] Setting up res2a_branch2b/relu
I0801 15:21:34.623900 12170 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 43 64 56 56 (8630272)
I0801 15:21:34.623903 12170 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 15:21:34.623908 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.623914 12170 net.cpp:184] Created Layer pool2 (15)
I0801 15:21:34.623919 12170 net.cpp:561] pool2 <- res2a_branch2b
I0801 15:21:34.623921 12170 net.cpp:530] pool2 -> pool2
I0801 15:21:34.624004 12170 net.cpp:245] Setting up pool2
I0801 15:21:34.624011 12170 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 43 64 28 28 (2157568)
I0801 15:21:34.624016 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 15:21:34.624018 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.624033 12170 net.cpp:184] Created Layer res3a_branch2a (16)
I0801 15:21:34.624037 12170 net.cpp:561] res3a_branch2a <- pool2
I0801 15:21:34.624039 12170 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 15:21:34.648658 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.58G, req 0G)
I0801 15:21:34.648684 12170 net.cpp:245] Setting up res3a_branch2a
I0801 15:21:34.648690 12170 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 43 128 28 28 (4315136)
I0801 15:21:34.648699 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.648705 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.648715 12170 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0801 15:21:34.648720 12170 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 15:21:34.648723 12170 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 15:21:34.649662 12170 net.cpp:245] Setting up res3a_branch2a/bn
I0801 15:21:34.649673 12170 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 43 128 28 28 (4315136)
I0801 15:21:34.649683 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.649688 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.649693 12170 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0801 15:21:34.649695 12170 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 15:21:34.649699 12170 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 15:21:34.649704 12170 net.cpp:245] Setting up res3a_branch2a/relu
I0801 15:21:34.649708 12170 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 43 128 28 28 (4315136)
I0801 15:21:34.649724 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 15:21:34.649729 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.649740 12170 net.cpp:184] Created Layer res3a_branch2b (19)
I0801 15:21:34.649745 12170 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 15:21:34.649750 12170 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 15:21:34.660689 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.54G, req 0G)
I0801 15:21:34.660708 12170 net.cpp:245] Setting up res3a_branch2b
I0801 15:21:34.660718 12170 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 43 128 28 28 (4315136)
I0801 15:21:34.660728 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.660735 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.660744 12170 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0801 15:21:34.660749 12170 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 15:21:34.660758 12170 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 15:21:34.661738 12170 net.cpp:245] Setting up res3a_branch2b/bn
I0801 15:21:34.661751 12170 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 43 128 28 28 (4315136)
I0801 15:21:34.661763 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.661769 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.661777 12170 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0801 15:21:34.661782 12170 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 15:21:34.661787 12170 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 15:21:34.661797 12170 net.cpp:245] Setting up res3a_branch2b/relu
I0801 15:21:34.661803 12170 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 43 128 28 28 (4315136)
I0801 15:21:34.661809 12170 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 15:21:34.661815 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.661823 12170 net.cpp:184] Created Layer pool3 (22)
I0801 15:21:34.661828 12170 net.cpp:561] pool3 <- res3a_branch2b
I0801 15:21:34.661834 12170 net.cpp:530] pool3 -> pool3
I0801 15:21:34.661931 12170 net.cpp:245] Setting up pool3
I0801 15:21:34.661939 12170 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 43 128 14 14 (1078784)
I0801 15:21:34.661945 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 15:21:34.661952 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.661963 12170 net.cpp:184] Created Layer res4a_branch2a (23)
I0801 15:21:34.661968 12170 net.cpp:561] res4a_branch2a <- pool3
I0801 15:21:34.661974 12170 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 15:21:34.691335 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.51G, req 0G)
I0801 15:21:34.691360 12170 net.cpp:245] Setting up res4a_branch2a
I0801 15:21:34.691371 12170 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 43 256 14 14 (2157568)
I0801 15:21:34.691385 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.691392 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.691412 12170 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0801 15:21:34.691418 12170 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 15:21:34.691426 12170 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 15:21:34.692349 12170 net.cpp:245] Setting up res4a_branch2a/bn
I0801 15:21:34.692361 12170 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 43 256 14 14 (2157568)
I0801 15:21:34.692373 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.692390 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.692400 12170 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0801 15:21:34.692405 12170 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 15:21:34.692411 12170 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 15:21:34.692420 12170 net.cpp:245] Setting up res4a_branch2a/relu
I0801 15:21:34.692427 12170 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 43 256 14 14 (2157568)
I0801 15:21:34.692433 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 15:21:34.692440 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.692452 12170 net.cpp:184] Created Layer res4a_branch2b (26)
I0801 15:21:34.692457 12170 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 15:21:34.692463 12170 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 15:21:34.703858 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0G)
I0801 15:21:34.703884 12170 net.cpp:245] Setting up res4a_branch2b
I0801 15:21:34.703893 12170 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 43 256 14 14 (2157568)
I0801 15:21:34.703907 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.703914 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.703927 12170 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0801 15:21:34.703933 12170 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 15:21:34.703941 12170 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 15:21:34.704900 12170 net.cpp:245] Setting up res4a_branch2b/bn
I0801 15:21:34.704913 12170 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 43 256 14 14 (2157568)
I0801 15:21:34.704926 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.704931 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.704941 12170 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0801 15:21:34.704946 12170 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 15:21:34.704952 12170 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 15:21:34.704962 12170 net.cpp:245] Setting up res4a_branch2b/relu
I0801 15:21:34.704967 12170 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 43 256 14 14 (2157568)
I0801 15:21:34.704972 12170 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 15:21:34.704978 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.704988 12170 net.cpp:184] Created Layer pool4 (29)
I0801 15:21:34.704993 12170 net.cpp:561] pool4 <- res4a_branch2b
I0801 15:21:34.704998 12170 net.cpp:530] pool4 -> pool4
I0801 15:21:34.705085 12170 net.cpp:245] Setting up pool4
I0801 15:21:34.705093 12170 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 43 256 7 7 (539392)
I0801 15:21:34.705101 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 15:21:34.705106 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.705128 12170 net.cpp:184] Created Layer res5a_branch2a (30)
I0801 15:21:34.705133 12170 net.cpp:561] res5a_branch2a <- pool4
I0801 15:21:34.705138 12170 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 15:21:34.761278 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.45G, req 0G)
I0801 15:21:34.761298 12170 net.cpp:245] Setting up res5a_branch2a
I0801 15:21:34.761306 12170 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 43 512 7 7 (1078784)
I0801 15:21:34.761314 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.761328 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.761340 12170 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0801 15:21:34.761344 12170 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 15:21:34.761349 12170 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 15:21:34.762037 12170 net.cpp:245] Setting up res5a_branch2a/bn
I0801 15:21:34.762045 12170 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 43 512 7 7 (1078784)
I0801 15:21:34.762054 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.762058 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.762064 12170 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0801 15:21:34.762068 12170 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 15:21:34.762071 12170 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 15:21:34.762079 12170 net.cpp:245] Setting up res5a_branch2a/relu
I0801 15:21:34.762082 12170 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 43 512 7 7 (1078784)
I0801 15:21:34.762086 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 15:21:34.762091 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.762100 12170 net.cpp:184] Created Layer res5a_branch2b (33)
I0801 15:21:34.762104 12170 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 15:21:34.762109 12170 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 15:21:34.783602 12170 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 7.44G, req 0G)
I0801 15:21:34.783617 12170 net.cpp:245] Setting up res5a_branch2b
I0801 15:21:34.783623 12170 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 43 512 7 7 (1078784)
I0801 15:21:34.783639 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.783644 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.783656 12170 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0801 15:21:34.783660 12170 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 15:21:34.783664 12170 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 15:21:34.784330 12170 net.cpp:245] Setting up res5a_branch2b/bn
I0801 15:21:34.784339 12170 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 43 512 7 7 (1078784)
I0801 15:21:34.784348 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.784353 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.784358 12170 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0801 15:21:34.784361 12170 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 15:21:34.784365 12170 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 15:21:34.784371 12170 net.cpp:245] Setting up res5a_branch2b/relu
I0801 15:21:34.784376 12170 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 43 512 7 7 (1078784)
I0801 15:21:34.784380 12170 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 15:21:34.784385 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.784391 12170 net.cpp:184] Created Layer pool5 (36)
I0801 15:21:34.784395 12170 net.cpp:561] pool5 <- res5a_branch2b
I0801 15:21:34.784400 12170 net.cpp:530] pool5 -> pool5
I0801 15:21:34.784430 12170 net.cpp:245] Setting up pool5
I0801 15:21:34.784435 12170 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 43 512 1 1 (22016)
I0801 15:21:34.784440 12170 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0801 15:21:34.784445 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.784453 12170 net.cpp:184] Created Layer fc1000 (37)
I0801 15:21:34.784464 12170 net.cpp:561] fc1000 <- pool5
I0801 15:21:34.784469 12170 net.cpp:530] fc1000 -> fc1000
I0801 15:21:34.795709 12170 net.cpp:245] Setting up fc1000
I0801 15:21:34.795737 12170 net.cpp:252] TRAIN Top shape for layer 37 'fc1000' 43 1000 (43000)
I0801 15:21:34.795745 12170 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 15:21:34.795752 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.795769 12170 net.cpp:184] Created Layer loss (38)
I0801 15:21:34.795774 12170 net.cpp:561] loss <- fc1000
I0801 15:21:34.795780 12170 net.cpp:561] loss <- label
I0801 15:21:34.795788 12170 net.cpp:530] loss -> loss
I0801 15:21:34.795997 12170 net.cpp:245] Setting up loss
I0801 15:21:34.796005 12170 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0801 15:21:34.796008 12170 net.cpp:256]     with loss weight 1
I0801 15:21:34.796020 12170 net.cpp:323] loss needs backward computation.
I0801 15:21:34.796026 12170 net.cpp:323] fc1000 needs backward computation.
I0801 15:21:34.796030 12170 net.cpp:323] pool5 needs backward computation.
I0801 15:21:34.796034 12170 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 15:21:34.796038 12170 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 15:21:34.796042 12170 net.cpp:323] res5a_branch2b needs backward computation.
I0801 15:21:34.796047 12170 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 15:21:34.796051 12170 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 15:21:34.796054 12170 net.cpp:323] res5a_branch2a needs backward computation.
I0801 15:21:34.796059 12170 net.cpp:323] pool4 needs backward computation.
I0801 15:21:34.796063 12170 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 15:21:34.796067 12170 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 15:21:34.796072 12170 net.cpp:323] res4a_branch2b needs backward computation.
I0801 15:21:34.796077 12170 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 15:21:34.796079 12170 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 15:21:34.796084 12170 net.cpp:323] res4a_branch2a needs backward computation.
I0801 15:21:34.796088 12170 net.cpp:323] pool3 needs backward computation.
I0801 15:21:34.796092 12170 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 15:21:34.796097 12170 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 15:21:34.796100 12170 net.cpp:323] res3a_branch2b needs backward computation.
I0801 15:21:34.796104 12170 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 15:21:34.796108 12170 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 15:21:34.796111 12170 net.cpp:323] res3a_branch2a needs backward computation.
I0801 15:21:34.796115 12170 net.cpp:323] pool2 needs backward computation.
I0801 15:21:34.796120 12170 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 15:21:34.796124 12170 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 15:21:34.796128 12170 net.cpp:323] res2a_branch2b needs backward computation.
I0801 15:21:34.796131 12170 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 15:21:34.796134 12170 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 15:21:34.796139 12170 net.cpp:323] res2a_branch2a needs backward computation.
I0801 15:21:34.796141 12170 net.cpp:323] pool1 needs backward computation.
I0801 15:21:34.796145 12170 net.cpp:323] conv1b/relu needs backward computation.
I0801 15:21:34.796149 12170 net.cpp:323] conv1b/bn needs backward computation.
I0801 15:21:34.796154 12170 net.cpp:323] conv1b needs backward computation.
I0801 15:21:34.796157 12170 net.cpp:323] conv1a/relu needs backward computation.
I0801 15:21:34.796160 12170 net.cpp:323] conv1a/bn needs backward computation.
I0801 15:21:34.796164 12170 net.cpp:323] conv1a needs backward computation.
I0801 15:21:34.796169 12170 net.cpp:325] data/bias does not need backward computation.
I0801 15:21:34.796174 12170 net.cpp:325] data does not need backward computation.
I0801 15:21:34.796187 12170 net.cpp:367] This network produces output loss
I0801 15:21:34.796231 12170 net.cpp:389] Top memory (TRAIN) required for data: 802615296 diff: 802615304
I0801 15:21:34.796236 12170 net.cpp:392] Bottom memory (TRAIN) required for data: 802615296 diff: 802615296
I0801 15:21:34.796239 12170 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 535076864 diff: 535076864
I0801 15:21:34.796242 12170 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0801 15:21:34.796247 12170 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0801 15:21:34.796249 12170 net.cpp:407] Network initialization done.
I0801 15:21:34.796646 12170 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/test.prototxt
W0801 15:21:34.796703 12170 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 15:21:34.796849 12170 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0801 15:21:34.796952 12170 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:34.796957 12170 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:34.796960 12170 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0801 15:21:34.796964 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.796977 12170 net.cpp:184] Created Layer data (0)
I0801 15:21:34.796980 12170 net.cpp:530] data -> data
I0801 15:21:34.796985 12170 net.cpp:530] data -> label
I0801 15:21:34.796994 12170 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 15:21:34.797008 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 15:21:34.797899 12207 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0801 15:21:34.798496 12170 data_layer.cpp:184] (0) ReshapePrefetch 17, 3, 224, 224
I0801 15:21:34.798578 12170 data_layer.cpp:208] (0) Output data size: 17, 3, 224, 224
I0801 15:21:34.798583 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 15:21:34.798598 12170 net.cpp:245] Setting up data
I0801 15:21:34.798604 12170 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 224 224 (2558976)
I0801 15:21:34.798609 12170 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0801 15:21:34.798614 12170 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0801 15:21:34.798617 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.798625 12170 net.cpp:184] Created Layer label_data_1_split (1)
I0801 15:21:34.798635 12170 net.cpp:561] label_data_1_split <- label
I0801 15:21:34.798640 12170 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0801 15:21:34.798645 12170 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0801 15:21:34.798650 12170 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0801 15:21:34.798718 12170 net.cpp:245] Setting up label_data_1_split
I0801 15:21:34.798724 12170 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 15:21:34.798729 12170 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 15:21:34.798734 12170 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0801 15:21:34.798738 12170 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0801 15:21:34.798743 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.798750 12170 net.cpp:184] Created Layer data/bias (2)
I0801 15:21:34.798753 12170 net.cpp:561] data/bias <- data
I0801 15:21:34.798758 12170 net.cpp:530] data/bias -> data/bias
I0801 15:21:34.798925 12170 net.cpp:245] Setting up data/bias
I0801 15:21:34.798933 12170 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 224 224 (2558976)
I0801 15:21:34.798939 12170 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0801 15:21:34.798943 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.798954 12170 net.cpp:184] Created Layer conv1a (3)
I0801 15:21:34.798957 12170 net.cpp:561] conv1a <- data/bias
I0801 15:21:34.798961 12170 net.cpp:530] conv1a -> conv1a
I0801 15:21:34.799257 12208 data_layer.cpp:97] (0) Parser threads: 1
I0801 15:21:34.799263 12208 data_layer.cpp:99] (0) Transformer threads: 1
I0801 15:21:34.805136 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.4G, req 0G)
I0801 15:21:34.805166 12170 net.cpp:245] Setting up conv1a
I0801 15:21:34.805172 12170 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 112 112 (6823936)
I0801 15:21:34.805186 12170 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0801 15:21:34.805191 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.805204 12170 net.cpp:184] Created Layer conv1a/bn (4)
I0801 15:21:34.805209 12170 net.cpp:561] conv1a/bn <- conv1a
I0801 15:21:34.805214 12170 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0801 15:21:34.806069 12170 net.cpp:245] Setting up conv1a/bn
I0801 15:21:34.806085 12170 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 112 112 (6823936)
I0801 15:21:34.806097 12170 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0801 15:21:34.806102 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.806109 12170 net.cpp:184] Created Layer conv1a/relu (5)
I0801 15:21:34.806113 12170 net.cpp:561] conv1a/relu <- conv1a
I0801 15:21:34.806118 12170 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0801 15:21:34.806125 12170 net.cpp:245] Setting up conv1a/relu
I0801 15:21:34.806130 12170 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 112 112 (6823936)
I0801 15:21:34.806143 12170 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0801 15:21:34.806149 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.806164 12170 net.cpp:184] Created Layer conv1b (6)
I0801 15:21:34.806169 12170 net.cpp:561] conv1b <- conv1a
I0801 15:21:34.806174 12170 net.cpp:530] conv1b -> conv1b
I0801 15:21:34.811969 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.37G, req 0G)
I0801 15:21:34.811993 12170 net.cpp:245] Setting up conv1b
I0801 15:21:34.812002 12170 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 112 112 (6823936)
I0801 15:21:34.812016 12170 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0801 15:21:34.812022 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.812047 12170 net.cpp:184] Created Layer conv1b/bn (7)
I0801 15:21:34.812052 12170 net.cpp:561] conv1b/bn <- conv1b
I0801 15:21:34.812057 12170 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0801 15:21:34.812878 12170 net.cpp:245] Setting up conv1b/bn
I0801 15:21:34.812889 12170 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 112 112 (6823936)
I0801 15:21:34.812898 12170 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0801 15:21:34.812904 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.812912 12170 net.cpp:184] Created Layer conv1b/relu (8)
I0801 15:21:34.812917 12170 net.cpp:561] conv1b/relu <- conv1b
I0801 15:21:34.812922 12170 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0801 15:21:34.812928 12170 net.cpp:245] Setting up conv1b/relu
I0801 15:21:34.812933 12170 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 112 112 (6823936)
I0801 15:21:34.812937 12170 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0801 15:21:34.812942 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.812949 12170 net.cpp:184] Created Layer pool1 (9)
I0801 15:21:34.812953 12170 net.cpp:561] pool1 <- conv1b
I0801 15:21:34.812959 12170 net.cpp:530] pool1 -> pool1
I0801 15:21:34.813038 12170 net.cpp:245] Setting up pool1
I0801 15:21:34.813045 12170 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 56 56 (1705984)
I0801 15:21:34.813050 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0801 15:21:34.813055 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.813066 12170 net.cpp:184] Created Layer res2a_branch2a (10)
I0801 15:21:34.813071 12170 net.cpp:561] res2a_branch2a <- pool1
I0801 15:21:34.813076 12170 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0801 15:21:34.818821 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.34G, req 0G)
I0801 15:21:34.818840 12170 net.cpp:245] Setting up res2a_branch2a
I0801 15:21:34.818846 12170 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 56 56 (3411968)
I0801 15:21:34.818858 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.818863 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.818874 12170 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0801 15:21:34.818878 12170 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0801 15:21:34.818884 12170 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0801 15:21:34.820964 12170 net.cpp:245] Setting up res2a_branch2a/bn
I0801 15:21:34.820978 12170 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 56 56 (3411968)
I0801 15:21:34.820991 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.820996 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.821003 12170 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0801 15:21:34.821007 12170 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0801 15:21:34.821012 12170 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0801 15:21:34.821024 12170 net.cpp:245] Setting up res2a_branch2a/relu
I0801 15:21:34.821028 12170 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 56 56 (3411968)
I0801 15:21:34.821033 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0801 15:21:34.821038 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.821055 12170 net.cpp:184] Created Layer res2a_branch2b (13)
I0801 15:21:34.821059 12170 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0801 15:21:34.821064 12170 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0801 15:21:34.824961 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.32G, req 0G)
I0801 15:21:34.824992 12170 net.cpp:245] Setting up res2a_branch2b
I0801 15:21:34.825000 12170 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 56 56 (3411968)
I0801 15:21:34.825008 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.825013 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.825024 12170 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0801 15:21:34.825028 12170 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0801 15:21:34.825033 12170 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0801 15:21:34.825799 12170 net.cpp:245] Setting up res2a_branch2b/bn
I0801 15:21:34.825809 12170 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 56 56 (3411968)
I0801 15:21:34.825817 12170 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.825821 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.825826 12170 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0801 15:21:34.825830 12170 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0801 15:21:34.825834 12170 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0801 15:21:34.825840 12170 net.cpp:245] Setting up res2a_branch2b/relu
I0801 15:21:34.825845 12170 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 56 56 (3411968)
I0801 15:21:34.825847 12170 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0801 15:21:34.825852 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.825860 12170 net.cpp:184] Created Layer pool2 (16)
I0801 15:21:34.825862 12170 net.cpp:561] pool2 <- res2a_branch2b
I0801 15:21:34.825866 12170 net.cpp:530] pool2 -> pool2
I0801 15:21:34.825937 12170 net.cpp:245] Setting up pool2
I0801 15:21:34.825942 12170 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 28 28 (852992)
I0801 15:21:34.825947 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0801 15:21:34.825951 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.825960 12170 net.cpp:184] Created Layer res3a_branch2a (17)
I0801 15:21:34.825964 12170 net.cpp:561] res3a_branch2a <- pool2
I0801 15:21:34.825968 12170 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0801 15:21:34.833297 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.31G, req 0G)
I0801 15:21:34.833307 12170 net.cpp:245] Setting up res3a_branch2a
I0801 15:21:34.833313 12170 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 28 28 (1705984)
I0801 15:21:34.833320 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.833325 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.833333 12170 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0801 15:21:34.833336 12170 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0801 15:21:34.833340 12170 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0801 15:21:34.834058 12170 net.cpp:245] Setting up res3a_branch2a/bn
I0801 15:21:34.834066 12170 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 28 28 (1705984)
I0801 15:21:34.834076 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.834080 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.834085 12170 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0801 15:21:34.834089 12170 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0801 15:21:34.834094 12170 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0801 15:21:34.834100 12170 net.cpp:245] Setting up res3a_branch2a/relu
I0801 15:21:34.834103 12170 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 28 28 (1705984)
I0801 15:21:34.834115 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0801 15:21:34.834120 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.834130 12170 net.cpp:184] Created Layer res3a_branch2b (20)
I0801 15:21:34.834132 12170 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0801 15:21:34.834137 12170 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0801 15:21:34.837395 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.3G, req 0G)
I0801 15:21:34.837406 12170 net.cpp:245] Setting up res3a_branch2b
I0801 15:21:34.837410 12170 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 28 28 (1705984)
I0801 15:21:34.837419 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.837422 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.837435 12170 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0801 15:21:34.837440 12170 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0801 15:21:34.837442 12170 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0801 15:21:34.838141 12170 net.cpp:245] Setting up res3a_branch2b/bn
I0801 15:21:34.838150 12170 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 28 28 (1705984)
I0801 15:21:34.838155 12170 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.838158 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.838161 12170 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0801 15:21:34.838165 12170 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0801 15:21:34.838166 12170 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0801 15:21:34.838171 12170 net.cpp:245] Setting up res3a_branch2b/relu
I0801 15:21:34.838174 12170 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 28 28 (1705984)
I0801 15:21:34.838176 12170 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0801 15:21:34.838179 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.838182 12170 net.cpp:184] Created Layer pool3 (23)
I0801 15:21:34.838186 12170 net.cpp:561] pool3 <- res3a_branch2b
I0801 15:21:34.838187 12170 net.cpp:530] pool3 -> pool3
I0801 15:21:34.838256 12170 net.cpp:245] Setting up pool3
I0801 15:21:34.838261 12170 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 14 14 (426496)
I0801 15:21:34.838263 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0801 15:21:34.838266 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.838276 12170 net.cpp:184] Created Layer res4a_branch2a (24)
I0801 15:21:34.838280 12170 net.cpp:561] res4a_branch2a <- pool3
I0801 15:21:34.838282 12170 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0801 15:21:34.850340 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.29G, req 0G)
I0801 15:21:34.850350 12170 net.cpp:245] Setting up res4a_branch2a
I0801 15:21:34.850354 12170 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 14 14 (852992)
I0801 15:21:34.850358 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.850361 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.850365 12170 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0801 15:21:34.850368 12170 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0801 15:21:34.850370 12170 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0801 15:21:34.851075 12170 net.cpp:245] Setting up res4a_branch2a/bn
I0801 15:21:34.851083 12170 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 14 14 (852992)
I0801 15:21:34.851089 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.851100 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.851104 12170 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0801 15:21:34.851106 12170 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0801 15:21:34.851109 12170 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0801 15:21:34.851112 12170 net.cpp:245] Setting up res4a_branch2a/relu
I0801 15:21:34.851115 12170 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 14 14 (852992)
I0801 15:21:34.851117 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0801 15:21:34.851119 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.851126 12170 net.cpp:184] Created Layer res4a_branch2b (27)
I0801 15:21:34.851130 12170 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0801 15:21:34.851131 12170 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0801 15:21:34.857316 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.28G, req 0G)
I0801 15:21:34.857331 12170 net.cpp:245] Setting up res4a_branch2b
I0801 15:21:34.857337 12170 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 14 14 (852992)
I0801 15:21:34.857342 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.857348 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.857358 12170 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0801 15:21:34.857363 12170 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0801 15:21:34.857368 12170 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0801 15:21:34.858171 12170 net.cpp:245] Setting up res4a_branch2b/bn
I0801 15:21:34.858180 12170 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 14 14 (852992)
I0801 15:21:34.858186 12170 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.858191 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.858193 12170 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0801 15:21:34.858196 12170 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0801 15:21:34.858199 12170 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0801 15:21:34.858204 12170 net.cpp:245] Setting up res4a_branch2b/relu
I0801 15:21:34.858207 12170 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 14 14 (852992)
I0801 15:21:34.858209 12170 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0801 15:21:34.858212 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.858218 12170 net.cpp:184] Created Layer pool4 (30)
I0801 15:21:34.858222 12170 net.cpp:561] pool4 <- res4a_branch2b
I0801 15:21:34.858227 12170 net.cpp:530] pool4 -> pool4
I0801 15:21:34.858325 12170 net.cpp:245] Setting up pool4
I0801 15:21:34.858332 12170 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 7 7 (213248)
I0801 15:21:34.858336 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0801 15:21:34.858341 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.858351 12170 net.cpp:184] Created Layer res5a_branch2a (31)
I0801 15:21:34.858355 12170 net.cpp:561] res5a_branch2a <- pool4
I0801 15:21:34.858361 12170 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0801 15:21:34.889387 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.28G, req 0G)
I0801 15:21:34.889406 12170 net.cpp:245] Setting up res5a_branch2a
I0801 15:21:34.889411 12170 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 7 7 (426496)
I0801 15:21:34.889418 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0801 15:21:34.889421 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.889446 12170 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0801 15:21:34.889451 12170 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0801 15:21:34.889454 12170 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0801 15:21:34.890296 12170 net.cpp:245] Setting up res5a_branch2a/bn
I0801 15:21:34.890305 12170 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 7 7 (426496)
I0801 15:21:34.890312 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0801 15:21:34.890314 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.890324 12170 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0801 15:21:34.890327 12170 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0801 15:21:34.890329 12170 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0801 15:21:34.890333 12170 net.cpp:245] Setting up res5a_branch2a/relu
I0801 15:21:34.890336 12170 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 7 7 (426496)
I0801 15:21:34.890338 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0801 15:21:34.890341 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.890355 12170 net.cpp:184] Created Layer res5a_branch2b (34)
I0801 15:21:34.890357 12170 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0801 15:21:34.890360 12170 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0801 15:21:34.907799 12170 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.27G, req 0G)
I0801 15:21:34.907810 12170 net.cpp:245] Setting up res5a_branch2b
I0801 15:21:34.907814 12170 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 7 7 (426496)
I0801 15:21:34.907822 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0801 15:21:34.907824 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.907830 12170 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0801 15:21:34.907832 12170 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0801 15:21:34.907835 12170 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0801 15:21:34.908623 12170 net.cpp:245] Setting up res5a_branch2b/bn
I0801 15:21:34.908632 12170 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 7 7 (426496)
I0801 15:21:34.908638 12170 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0801 15:21:34.908641 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.908644 12170 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0801 15:21:34.908646 12170 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0801 15:21:34.908649 12170 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0801 15:21:34.908653 12170 net.cpp:245] Setting up res5a_branch2b/relu
I0801 15:21:34.908655 12170 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 7 7 (426496)
I0801 15:21:34.908658 12170 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0801 15:21:34.908659 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.908663 12170 net.cpp:184] Created Layer pool5 (37)
I0801 15:21:34.908668 12170 net.cpp:561] pool5 <- res5a_branch2b
I0801 15:21:34.908670 12170 net.cpp:530] pool5 -> pool5
I0801 15:21:34.908704 12170 net.cpp:245] Setting up pool5
I0801 15:21:34.908707 12170 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0801 15:21:34.908710 12170 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0801 15:21:34.908712 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.908716 12170 net.cpp:184] Created Layer fc1000 (38)
I0801 15:21:34.908718 12170 net.cpp:561] fc1000 <- pool5
I0801 15:21:34.908735 12170 net.cpp:530] fc1000 -> fc1000
I0801 15:21:34.920197 12170 net.cpp:245] Setting up fc1000
I0801 15:21:34.920230 12170 net.cpp:252] TEST Top shape for layer 38 'fc1000' 17 1000 (17000)
I0801 15:21:34.920238 12170 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0801 15:21:34.920243 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.920250 12170 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0801 15:21:34.920253 12170 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0801 15:21:34.920258 12170 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0801 15:21:34.920262 12170 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0801 15:21:34.920265 12170 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0801 15:21:34.920372 12170 net.cpp:245] Setting up fc1000_fc1000_0_split
I0801 15:21:34.920380 12170 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0801 15:21:34.920385 12170 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0801 15:21:34.920388 12170 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0801 15:21:34.920392 12170 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0801 15:21:34.920397 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.920408 12170 net.cpp:184] Created Layer loss (40)
I0801 15:21:34.920411 12170 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0801 15:21:34.920416 12170 net.cpp:561] loss <- label_data_1_split_0
I0801 15:21:34.920420 12170 net.cpp:530] loss -> loss
I0801 15:21:34.920683 12170 net.cpp:245] Setting up loss
I0801 15:21:34.920693 12170 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0801 15:21:34.920697 12170 net.cpp:256]     with loss weight 1
I0801 15:21:34.920707 12170 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0801 15:21:34.920712 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.920723 12170 net.cpp:184] Created Layer accuracy/top1 (41)
I0801 15:21:34.920728 12170 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0801 15:21:34.920733 12170 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0801 15:21:34.920738 12170 net.cpp:530] accuracy/top1 -> accuracy/top1
I0801 15:21:34.920745 12170 net.cpp:245] Setting up accuracy/top1
I0801 15:21:34.920750 12170 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0801 15:21:34.920755 12170 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0801 15:21:34.920759 12170 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0801 15:21:34.920765 12170 net.cpp:184] Created Layer accuracy/top5 (42)
I0801 15:21:34.920769 12170 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0801 15:21:34.920773 12170 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0801 15:21:34.920778 12170 net.cpp:530] accuracy/top5 -> accuracy/top5
I0801 15:21:34.920785 12170 net.cpp:245] Setting up accuracy/top5
I0801 15:21:34.920790 12170 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0801 15:21:34.920795 12170 net.cpp:325] accuracy/top5 does not need backward computation.
I0801 15:21:34.920800 12170 net.cpp:325] accuracy/top1 does not need backward computation.
I0801 15:21:34.920804 12170 net.cpp:323] loss needs backward computation.
I0801 15:21:34.920809 12170 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0801 15:21:34.920812 12170 net.cpp:323] fc1000 needs backward computation.
I0801 15:21:34.920835 12170 net.cpp:323] pool5 needs backward computation.
I0801 15:21:34.920841 12170 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0801 15:21:34.920845 12170 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0801 15:21:34.920850 12170 net.cpp:323] res5a_branch2b needs backward computation.
I0801 15:21:34.920853 12170 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0801 15:21:34.920869 12170 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0801 15:21:34.920874 12170 net.cpp:323] res5a_branch2a needs backward computation.
I0801 15:21:34.920878 12170 net.cpp:323] pool4 needs backward computation.
I0801 15:21:34.920883 12170 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0801 15:21:34.920887 12170 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0801 15:21:34.920892 12170 net.cpp:323] res4a_branch2b needs backward computation.
I0801 15:21:34.920894 12170 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0801 15:21:34.920899 12170 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0801 15:21:34.920903 12170 net.cpp:323] res4a_branch2a needs backward computation.
I0801 15:21:34.920907 12170 net.cpp:323] pool3 needs backward computation.
I0801 15:21:34.920912 12170 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0801 15:21:34.920917 12170 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0801 15:21:34.920922 12170 net.cpp:323] res3a_branch2b needs backward computation.
I0801 15:21:34.920925 12170 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0801 15:21:34.920929 12170 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0801 15:21:34.920933 12170 net.cpp:323] res3a_branch2a needs backward computation.
I0801 15:21:34.920938 12170 net.cpp:323] pool2 needs backward computation.
I0801 15:21:34.920943 12170 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0801 15:21:34.920946 12170 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0801 15:21:34.920950 12170 net.cpp:323] res2a_branch2b needs backward computation.
I0801 15:21:34.920953 12170 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0801 15:21:34.920958 12170 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0801 15:21:34.920961 12170 net.cpp:323] res2a_branch2a needs backward computation.
I0801 15:21:34.920966 12170 net.cpp:323] pool1 needs backward computation.
I0801 15:21:34.920971 12170 net.cpp:323] conv1b/relu needs backward computation.
I0801 15:21:34.920975 12170 net.cpp:323] conv1b/bn needs backward computation.
I0801 15:21:34.920979 12170 net.cpp:323] conv1b needs backward computation.
I0801 15:21:34.920984 12170 net.cpp:323] conv1a/relu needs backward computation.
I0801 15:21:34.920987 12170 net.cpp:323] conv1a/bn needs backward computation.
I0801 15:21:34.920991 12170 net.cpp:323] conv1a needs backward computation.
I0801 15:21:34.920995 12170 net.cpp:325] data/bias does not need backward computation.
I0801 15:21:34.921000 12170 net.cpp:325] label_data_1_split does not need backward computation.
I0801 15:21:34.921005 12170 net.cpp:325] data does not need backward computation.
I0801 15:21:34.921008 12170 net.cpp:367] This network produces output accuracy/top1
I0801 15:21:34.921013 12170 net.cpp:367] This network produces output accuracy/top5
I0801 15:21:34.921017 12170 net.cpp:367] This network produces output loss
I0801 15:21:34.921061 12170 net.cpp:389] Top memory (TEST) required for data: 317313024 diff: 8
I0801 15:21:34.921066 12170 net.cpp:392] Bottom memory (TEST) required for data: 317313024 diff: 317313024
I0801 15:21:34.921069 12170 net.cpp:395] Shared (in-place) memory (TEST) by data: 211542016 diff: 211542016
I0801 15:21:34.921073 12170 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0801 15:21:34.921077 12170 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0801 15:21:34.921080 12170 net.cpp:407] Network initialization done.
I0801 15:21:34.921154 12170 solver.cpp:56] Solver scaffolding done.
I0801 15:21:34.925663 12170 parallel.cpp:108] [0 - 0] P2pSync adding callback
I0801 15:21:34.925676 12170 parallel.cpp:108] [1 - 1] P2pSync adding callback
I0801 15:21:34.925679 12170 parallel.cpp:108] [2 - 2] P2pSync adding callback
I0801 15:21:34.925681 12170 parallel.cpp:61] Starting Optimization
I0801 15:21:34.925683 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0801 15:21:34.925712 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 15:21:34.925725 12170 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 15:21:34.926407 12219 device_alternate.hpp:116] NVML initialized on thread 140395431864064
I0801 15:21:34.938994 12219 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 15:21:34.939047 12220 device_alternate.hpp:116] NVML initialized on thread 140395423471360
I0801 15:21:34.940407 12220 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 15:21:34.940461 12221 device_alternate.hpp:116] NVML initialized on thread 140395415078656
I0801 15:21:34.941105 12221 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 15:21:34.946458 12220 solver.cpp:42] Solver data type: FLOAT
W0801 15:21:34.946877 12220 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0801 15:21:34.946964 12220 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:34.946969 12220 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:34.946995 12220 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0801 15:21:34.947005 12220 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 15:21:34.951704 12221 solver.cpp:42] Solver data type: FLOAT
W0801 15:21:34.952168 12221 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0801 15:21:34.952265 12221 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:34.952271 12221 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:34.952313 12221 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0801 15:21:34.952333 12221 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 15:21:34.952550 12222 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0801 15:21:34.953233 12223 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0801 15:21:34.954825 12220 data_layer.cpp:184] [1] ReshapePrefetch 43, 3, 224, 224
I0801 15:21:34.955106 12221 data_layer.cpp:184] [2] ReshapePrefetch 43, 3, 224, 224
I0801 15:21:34.955260 12221 data_layer.cpp:208] [2] Output data size: 43, 3, 224, 224
I0801 15:21:34.955269 12221 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 15:21:34.955312 12220 data_layer.cpp:208] [1] Output data size: 43, 3, 224, 224
I0801 15:21:34.955322 12220 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 15:21:35.435988 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0801 15:21:35.462851 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0801 15:21:35.467252 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0801 15:21:35.490887 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0801 15:21:35.494118 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0801 15:21:35.508618 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0801 15:21:35.518249 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0801 15:21:35.532536 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0801 15:21:35.533255 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0801 15:21:35.544891 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 1 3  (limit 7.64G, req 0G)
I0801 15:21:35.557401 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0801 15:21:35.567412 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.64G, req 0G)
I0801 15:21:35.572768 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.6G, req 0G)
I0801 15:21:35.585393 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0801 15:21:35.596200 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.6G, req 0G)
I0801 15:21:35.606511 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0801 15:21:35.639793 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 3  (limit 7.55G, req 0G)
I0801 15:21:35.660898 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.55G, req 0G)
I0801 15:21:35.662067 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 7.53G, req 0G)
I0801 15:21:35.675637 12220 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/test.prototxt
W0801 15:21:35.675693 12220 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 15:21:35.675783 12220 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:35.675788 12220 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:35.675806 12220 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 15:21:35.675812 12220 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 15:21:35.677424 12243 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0801 15:21:35.680097 12220 data_layer.cpp:184] (1) ReshapePrefetch 17, 3, 224, 224
I0801 15:21:35.680255 12220 data_layer.cpp:208] (1) Output data size: 17, 3, 224, 224
I0801 15:21:35.680263 12220 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0801 15:21:35.681154 12244 data_layer.cpp:97] (1) Parser threads: 1
I0801 15:21:35.681161 12244 data_layer.cpp:99] (1) Transformer threads: 1
I0801 15:21:35.682516 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 7.53G, req 0G)
I0801 15:21:35.687829 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0801 15:21:35.694108 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0801 15:21:35.698815 12221 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/test.prototxt
W0801 15:21:35.698873 12221 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0801 15:21:35.698971 12221 net.cpp:104] Using FLOAT as default forward math type
I0801 15:21:35.698976 12221 net.cpp:110] Using FLOAT as default backward math type
I0801 15:21:35.698994 12221 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0801 15:21:35.699002 12221 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 15:21:35.699750 12245 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0801 15:21:35.700335 12221 data_layer.cpp:184] (2) ReshapePrefetch 17, 3, 224, 224
I0801 15:21:35.700423 12221 data_layer.cpp:208] (2) Output data size: 17, 3, 224, 224
I0801 15:21:35.700428 12221 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0801 15:21:35.702359 12246 data_layer.cpp:97] (2) Parser threads: 1
I0801 15:21:35.702368 12246 data_layer.cpp:99] (2) Transformer threads: 1
I0801 15:21:35.702679 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.43G, req 0G)
I0801 15:21:35.709415 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0801 15:21:35.712139 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0801 15:21:35.716989 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0801 15:21:35.721431 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0801 15:21:35.726047 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.43G, req 0G)
I0801 15:21:35.726721 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0801 15:21:35.730911 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0801 15:21:35.740298 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0801 15:21:35.740479 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0801 15:21:35.745214 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0801 15:21:35.748060 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0801 15:21:35.758265 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0801 15:21:35.764997 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0801 15:21:35.779976 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0801 15:21:35.798167 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0801 15:21:35.798698 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0801 15:21:35.813375 12220 solver.cpp:56] Solver scaffolding done.
I0801 15:21:35.817075 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0801 15:21:35.831188 12221 solver.cpp:56] Solver scaffolding done.
I0801 15:21:35.877579 12219 parallel.cpp:164] [0 - 0] P2pSync adding callback
I0801 15:21:35.877604 12220 parallel.cpp:164] [1 - 1] P2pSync adding callback
I0801 15:21:35.877604 12221 parallel.cpp:164] [2 - 2] P2pSync adding callback
I0801 15:21:36.194177 12221 solver.cpp:479] Solving jacintonet11v2_train
I0801 15:21:36.194195 12221 solver.cpp:480] Learning Rate Policy: poly
I0801 15:21:36.194205 12219 solver.cpp:479] Solving jacintonet11v2_train
I0801 15:21:36.194212 12219 solver.cpp:480] Learning Rate Policy: poly
I0801 15:21:36.194236 12220 solver.cpp:479] Solving jacintonet11v2_train
I0801 15:21:36.194247 12220 solver.cpp:480] Learning Rate Policy: poly
I0801 15:21:36.203713 12220 solver.cpp:268] Starting Optimization on GPU 1
I0801 15:21:36.203716 12221 solver.cpp:268] Starting Optimization on GPU 2
I0801 15:21:36.203716 12219 solver.cpp:268] Starting Optimization on GPU 0
I0801 15:21:36.205845 12219 solver.cpp:550] Iteration 0, Testing net (#0)
I0801 15:21:36.205888 12264 device_alternate.hpp:116] NVML initialized on thread 140253596825344
I0801 15:21:36.205909 12264 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0801 15:21:36.206603 12266 device_alternate.hpp:116] NVML initialized on thread 140253580039936
I0801 15:21:36.206614 12266 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0801 15:21:36.206701 12265 device_alternate.hpp:116] NVML initialized on thread 140253588432640
I0801 15:21:36.206717 12265 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0801 15:21:36.219533 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.31G, req 0G)
I0801 15:21:36.220245 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.31G, req 0G)
I0801 15:21:36.222728 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.24G, req 0G)
I0801 15:21:36.230335 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.26G, req 0G)
I0801 15:21:36.231134 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.26G, req 0G)
I0801 15:21:36.236235 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.17G, req 0G)
I0801 15:21:36.245759 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.19G, req 0G)
I0801 15:21:36.246531 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.19G, req 0G)
I0801 15:21:36.250464 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.1G, req 0G)
I0801 15:21:36.252238 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.16G, req 0G)
I0801 15:21:36.253168 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.16G, req 0G)
I0801 15:21:36.256708 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0801 15:21:36.259743 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.13G, req 0G)
I0801 15:21:36.261277 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.13G, req 0G)
I0801 15:21:36.264457 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.04G, req 0G)
I0801 15:21:36.264750 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.11G, req 0G)
I0801 15:21:36.266999 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.11G, req 0G)
I0801 15:21:36.269918 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.02G, req 0G)
I0801 15:21:36.273102 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.09G, req 0G)
I0801 15:21:36.274631 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.09G, req 0G)
I0801 15:21:36.277380 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0801 15:21:36.277560 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.01G, req 0G)
I0801 15:21:36.279160 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0801 15:21:36.282893 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7G, req 0G)
I0801 15:21:36.285470 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.08G, req 0G)
I0801 15:21:36.287116 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.08G, req 0G)
I0801 15:21:36.289890 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 6.99G, req 0G)
I0801 15:21:36.290699 12220 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0801 15:21:36.292989 12221 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0801 15:21:36.296105 12219 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 6.99G, req 0G)
I0801 15:21:36.299984 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0
I0801 15:21:36.299994 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0
I0801 15:21:36.299999 12219 solver.cpp:635]     Test net output #2: loss = 87.3365 (* 1 = 87.3365 loss)
I0801 15:21:36.300011 12219 solver.cpp:295] [MultiGPU] Initial Test completed
I0801 15:21:36.300024 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 15:21:36.396235 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.01G, req 0G)
I0801 15:21:36.397382 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.01G, req 0G)
I0801 15:21:36.400207 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 6.93G, req 0G)
I0801 15:21:36.427582 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.87G, req 0G)
I0801 15:21:36.428171 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.87G, req 0G)
I0801 15:21:36.433043 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.79G, req 0G)
I0801 15:21:36.465570 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.71G, req 0G)
I0801 15:21:36.471778 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.63G, req 0G)
I0801 15:21:36.472687 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.71G, req 0G)
I0801 15:21:36.489084 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.64G, req 0G)
I0801 15:21:36.494947 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.56G, req 0G)
I0801 15:21:36.495692 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.64G, req 0G)
I0801 15:21:36.512348 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.56G, req 0G)
I0801 15:21:36.522642 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.48G, req 0G)
I0801 15:21:36.522822 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.56G, req 0G)
I0801 15:21:36.523013 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.52G, req 0G)
I0801 15:21:36.533018 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.44G, req 0G)
I0801 15:21:36.534668 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.52G, req 0G)
I0801 15:21:36.543660 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.48G, req 0G)
I0801 15:21:36.550591 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.46G, req 0G)
I0801 15:21:36.555475 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 6.39G, req 0G)
I0801 15:21:36.555634 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.48G, req 0G)
I0801 15:21:36.564662 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.46G, req 0G)
I0801 15:21:36.564826 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.37G, req 0G)
I0801 15:21:36.574409 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.43G, req 0G)
I0801 15:21:36.581218 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 6.42G, req 0G)
I0801 15:21:36.589530 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.43G, req 0G)
I0801 15:21:36.595350 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 3  (limit 6.34G, req 0G)
I0801 15:21:36.600852 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 6.42G, req 0G)
I0801 15:21:36.602943 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 6.33G, req 0G)
I0801 15:21:36.639067 12225 data_layer.cpp:97] [1] Parser threads: 1
I0801 15:21:36.639082 12225 data_layer.cpp:99] [1] Transformer threads: 1
I0801 15:21:36.656456 12206 data_layer.cpp:97] [0] Parser threads: 1
I0801 15:21:36.656471 12206 data_layer.cpp:99] [0] Transformer threads: 1
I0801 15:21:36.656688 12224 data_layer.cpp:97] [2] Parser threads: 1
I0801 15:21:36.656697 12224 data_layer.cpp:99] [2] Transformer threads: 1
I0801 15:21:36.783890 12219 solver.cpp:358] Iteration 0 (0.483839 s), loss = 7.15223
I0801 15:21:36.783911 12219 solver.cpp:375]     Train net output #0: loss = 7.15778 (* 1 = 7.15778 loss)
I0801 15:21:36.783915 12219 sgd_solver.cpp:136] Iteration 0, lr = 0.1, m = 0.9
I0801 15:21:36.815520 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.32G, req 0G)
I0801 15:21:36.818631 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.41G, req 0G)
I0801 15:21:36.819499 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 1  (limit 5.41G, req 0G)
I0801 15:21:36.860659 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.61G, req 0G)
I0801 15:21:36.863569 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0G)
I0801 15:21:36.869817 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0G)
I0801 15:21:36.907424 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 1  (limit 4.61G, req 0G)
I0801 15:21:36.913754 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 3  (limit 4.7G, req 0G)
I0801 15:21:36.923838 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 1  (limit 4.7G, req 0G)
I0801 15:21:36.934703 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 5  (limit 4.61G, req 0.08G)
I0801 15:21:36.941184 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.7G, req 0G)
I0801 15:21:36.949777 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 5  (limit 4.7G, req 0.08G)
I0801 15:21:36.971127 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.61G, req 0.08G)
I0801 15:21:36.977039 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.7G, req 0.06G)
I0801 15:21:36.989258 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.7G, req 0.08G)
I0801 15:21:36.990265 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 6 4 3  (limit 4.61G, req 0.08G)
I0801 15:21:36.995409 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0.06G)
I0801 15:21:37.005169 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0.08G)
I0801 15:21:37.021381 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.61G, req 0.08G)
I0801 15:21:37.024849 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.7G, req 0.06G)
I0801 15:21:37.030735 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.61G, req 0.08G)
I0801 15:21:37.033800 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0.06G)
I0801 15:21:37.035555 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.7G, req 0.08G)
I0801 15:21:37.045388 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.7G, req 0.08G)
I0801 15:21:37.081727 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.61G, req 0.08G)
I0801 15:21:37.085408 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.7G, req 0.06G)
I0801 15:21:37.095088 12219 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 6 1 5  (limit 4.61G, req 0.08G)
I0801 15:21:37.096189 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.7G, req 0.08G)
I0801 15:21:37.096441 12220 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 6 1 5  (limit 4.7G, req 0.06G)
I0801 15:21:37.107183 12221 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 7 1 5  (limit 4.7G, req 0.08G)
I0801 15:21:37.135457 12219 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.43G -> 0.16G
I0801 15:21:37.138273 12220 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0801 15:21:37.151130 12221 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.43G -> 0.16G
I0801 15:21:37.224048 12219 solver.cpp:358] Iteration 1 (0.440139 s), loss = 7.11891
I0801 15:21:37.224074 12219 solver.cpp:375]     Train net output #0: loss = 7.1578 (* 1 = 7.1578 loss)
I0801 15:21:37.373788 12219 solver.cpp:358] Iteration 2 (0.149732 s), loss = 7.09206
I0801 15:21:37.373812 12219 solver.cpp:375]     Train net output #0: loss = 7.06251 (* 1 = 7.06251 loss)
I0801 15:21:50.968847 12219 solver.cpp:353] Iteration 100 (7.20872 iter/s, 13.5946s/98 iter), loss = 6.59969
I0801 15:21:50.968900 12219 solver.cpp:375]     Train net output #0: loss = 6.74906 (* 1 = 6.74906 loss)
I0801 15:21:50.968911 12219 sgd_solver.cpp:136] Iteration 100, lr = 0.0999688, m = 0.9
I0801 15:22:04.807695 12219 solver.cpp:353] Iteration 200 (7.22625 iter/s, 13.8384s/100 iter), loss = 6.21457
I0801 15:22:04.807804 12219 solver.cpp:375]     Train net output #0: loss = 6.26292 (* 1 = 6.26292 loss)
I0801 15:22:04.807811 12219 sgd_solver.cpp:136] Iteration 200, lr = 0.0999375, m = 0.9
I0801 15:22:18.639020 12219 solver.cpp:353] Iteration 300 (7.23018 iter/s, 13.8309s/100 iter), loss = 6.17689
I0801 15:22:18.639045 12219 solver.cpp:375]     Train net output #0: loss = 6.00743 (* 1 = 6.00743 loss)
I0801 15:22:18.639050 12219 sgd_solver.cpp:136] Iteration 300, lr = 0.0999063, m = 0.9
I0801 15:22:32.456100 12219 solver.cpp:353] Iteration 400 (7.23763 iter/s, 13.8167s/100 iter), loss = 5.76661
I0801 15:22:32.456125 12219 solver.cpp:375]     Train net output #0: loss = 5.95095 (* 1 = 5.95095 loss)
I0801 15:22:32.456130 12219 sgd_solver.cpp:136] Iteration 400, lr = 0.099875, m = 0.9
I0801 15:22:46.204229 12219 solver.cpp:353] Iteration 500 (7.27393 iter/s, 13.7477s/100 iter), loss = 5.63144
I0801 15:22:46.204340 12219 solver.cpp:375]     Train net output #0: loss = 5.84067 (* 1 = 5.84067 loss)
I0801 15:22:46.204349 12219 sgd_solver.cpp:136] Iteration 500, lr = 0.0998438, m = 0.9
I0801 15:23:00.131443 12219 solver.cpp:353] Iteration 600 (7.1804 iter/s, 13.9268s/100 iter), loss = 5.50818
I0801 15:23:00.131515 12219 solver.cpp:375]     Train net output #0: loss = 5.35297 (* 1 = 5.35297 loss)
I0801 15:23:00.131542 12219 sgd_solver.cpp:136] Iteration 600, lr = 0.0998125, m = 0.9
I0801 15:23:14.046835 12219 solver.cpp:353] Iteration 700 (7.1865 iter/s, 13.915s/100 iter), loss = 5.41284
I0801 15:23:14.046861 12219 solver.cpp:375]     Train net output #0: loss = 5.60268 (* 1 = 5.60268 loss)
I0801 15:23:14.046869 12219 sgd_solver.cpp:136] Iteration 700, lr = 0.0997813, m = 0.9
I0801 15:23:27.877873 12219 solver.cpp:353] Iteration 800 (7.23033 iter/s, 13.8306s/100 iter), loss = 5.44521
I0801 15:23:27.877952 12219 solver.cpp:375]     Train net output #0: loss = 5.43042 (* 1 = 5.43042 loss)
I0801 15:23:27.877959 12219 sgd_solver.cpp:136] Iteration 800, lr = 0.09975, m = 0.9
I0801 15:23:41.682871 12219 solver.cpp:353] Iteration 900 (7.24397 iter/s, 13.8046s/100 iter), loss = 5.17929
I0801 15:23:41.682940 12219 solver.cpp:375]     Train net output #0: loss = 5.37247 (* 1 = 5.37247 loss)
I0801 15:23:41.682956 12219 sgd_solver.cpp:136] Iteration 900, lr = 0.0997187, m = 0.9
I0801 15:23:55.489403 12219 solver.cpp:353] Iteration 1000 (7.24316 iter/s, 13.8061s/100 iter), loss = 4.83954
I0801 15:23:55.489428 12219 solver.cpp:375]     Train net output #0: loss = 4.90296 (* 1 = 4.90296 loss)
I0801 15:23:55.489433 12219 sgd_solver.cpp:136] Iteration 1000, lr = 0.0996875, m = 0.9
I0801 15:24:09.412132 12219 solver.cpp:353] Iteration 1100 (7.18271 iter/s, 13.9223s/100 iter), loss = 4.87109
I0801 15:24:09.412216 12219 solver.cpp:375]     Train net output #0: loss = 4.85506 (* 1 = 4.85506 loss)
I0801 15:24:09.412225 12219 sgd_solver.cpp:136] Iteration 1100, lr = 0.0996562, m = 0.9
I0801 15:24:23.232681 12219 solver.cpp:353] Iteration 1200 (7.23581 iter/s, 13.8201s/100 iter), loss = 5.05308
I0801 15:24:23.232704 12219 solver.cpp:375]     Train net output #0: loss = 4.77728 (* 1 = 4.77728 loss)
I0801 15:24:23.232708 12219 sgd_solver.cpp:136] Iteration 1200, lr = 0.099625, m = 0.9
I0801 15:24:37.085294 12219 solver.cpp:353] Iteration 1300 (7.21907 iter/s, 13.8522s/100 iter), loss = 4.6194
I0801 15:24:37.085327 12219 solver.cpp:375]     Train net output #0: loss = 4.63432 (* 1 = 4.63432 loss)
I0801 15:24:37.085335 12219 sgd_solver.cpp:136] Iteration 1300, lr = 0.0995938, m = 0.9
I0801 15:24:50.866076 12219 solver.cpp:353] Iteration 1400 (7.2567 iter/s, 13.7804s/100 iter), loss = 4.56451
I0801 15:24:50.866137 12219 solver.cpp:375]     Train net output #0: loss = 4.58401 (* 1 = 4.58401 loss)
I0801 15:24:50.866143 12219 sgd_solver.cpp:136] Iteration 1400, lr = 0.0995625, m = 0.9
I0801 15:25:04.733232 12219 solver.cpp:353] Iteration 1500 (7.21149 iter/s, 13.8668s/100 iter), loss = 4.52373
I0801 15:25:04.733256 12219 solver.cpp:375]     Train net output #0: loss = 4.84617 (* 1 = 4.84617 loss)
I0801 15:25:04.733260 12219 sgd_solver.cpp:136] Iteration 1500, lr = 0.0995313, m = 0.9
I0801 15:25:18.559918 12219 solver.cpp:353] Iteration 1600 (7.2326 iter/s, 13.8263s/100 iter), loss = 4.69671
I0801 15:25:18.559948 12219 solver.cpp:375]     Train net output #0: loss = 4.61482 (* 1 = 4.61482 loss)
I0801 15:25:18.559955 12219 sgd_solver.cpp:136] Iteration 1600, lr = 0.0995, m = 0.9
I0801 15:25:32.391086 12219 solver.cpp:353] Iteration 1700 (7.23026 iter/s, 13.8308s/100 iter), loss = 4.33676
I0801 15:25:32.391175 12219 solver.cpp:375]     Train net output #0: loss = 4.10954 (* 1 = 4.10954 loss)
I0801 15:25:32.391188 12219 sgd_solver.cpp:136] Iteration 1700, lr = 0.0994688, m = 0.9
I0801 15:25:46.296332 12219 solver.cpp:353] Iteration 1800 (7.19175 iter/s, 13.9048s/100 iter), loss = 4.62461
I0801 15:25:46.296362 12219 solver.cpp:375]     Train net output #0: loss = 4.76257 (* 1 = 4.76257 loss)
I0801 15:25:46.296370 12219 sgd_solver.cpp:136] Iteration 1800, lr = 0.0994375, m = 0.9
I0801 15:26:00.165457 12219 solver.cpp:353] Iteration 1900 (7.21047 iter/s, 13.8687s/100 iter), loss = 4.12775
I0801 15:26:00.165483 12219 solver.cpp:375]     Train net output #0: loss = 4.29976 (* 1 = 4.29976 loss)
I0801 15:26:00.165488 12219 sgd_solver.cpp:136] Iteration 1900, lr = 0.0994062, m = 0.9
I0801 15:26:13.839412 12219 solver.cpp:550] Iteration 2000, Testing net (#0)
I0801 15:26:31.675339 12207 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 15:26:32.927229 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.0984699
I0801 15:26:32.927253 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.250704
I0801 15:26:32.927259 12219 solver.cpp:635]     Test net output #2: loss = 4.96468 (* 1 = 4.96468 loss)
I0801 15:26:32.927311 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.0873s
I0801 15:26:33.089123 12219 solver.cpp:353] Iteration 2000 (3.03742 iter/s, 32.9227s/100 iter), loss = 4.38121
I0801 15:26:33.089148 12219 solver.cpp:375]     Train net output #0: loss = 4.64972 (* 1 = 4.64972 loss)
I0801 15:26:33.089151 12219 sgd_solver.cpp:136] Iteration 2000, lr = 0.099375, m = 0.9
I0801 15:26:46.962051 12219 solver.cpp:353] Iteration 2100 (7.20849 iter/s, 13.8725s/100 iter), loss = 3.94914
I0801 15:26:46.962147 12219 solver.cpp:375]     Train net output #0: loss = 4.22179 (* 1 = 4.22179 loss)
I0801 15:26:46.962154 12219 sgd_solver.cpp:136] Iteration 2100, lr = 0.0993438, m = 0.9
I0801 15:27:00.814046 12219 solver.cpp:353] Iteration 2200 (7.21939 iter/s, 13.8516s/100 iter), loss = 4.15886
I0801 15:27:00.814074 12219 solver.cpp:375]     Train net output #0: loss = 4.24333 (* 1 = 4.24333 loss)
I0801 15:27:00.814079 12219 sgd_solver.cpp:136] Iteration 2200, lr = 0.0993125, m = 0.9
I0801 15:27:14.658213 12219 solver.cpp:353] Iteration 2300 (7.22347 iter/s, 13.8438s/100 iter), loss = 3.99863
I0801 15:27:14.658238 12219 solver.cpp:375]     Train net output #0: loss = 3.99613 (* 1 = 3.99613 loss)
I0801 15:27:14.658244 12219 sgd_solver.cpp:136] Iteration 2300, lr = 0.0992813, m = 0.9
I0801 15:27:28.444530 12219 solver.cpp:353] Iteration 2400 (7.25378 iter/s, 13.7859s/100 iter), loss = 4.59547
I0801 15:27:28.444578 12219 solver.cpp:375]     Train net output #0: loss = 4.49335 (* 1 = 4.49335 loss)
I0801 15:27:28.444584 12219 sgd_solver.cpp:136] Iteration 2400, lr = 0.09925, m = 0.9
I0801 15:27:42.267392 12219 solver.cpp:353] Iteration 2500 (7.2346 iter/s, 13.8225s/100 iter), loss = 3.88409
I0801 15:27:42.267422 12219 solver.cpp:375]     Train net output #0: loss = 3.94335 (* 1 = 3.94335 loss)
I0801 15:27:42.267428 12219 sgd_solver.cpp:136] Iteration 2500, lr = 0.0992187, m = 0.9
I0801 15:27:56.122510 12219 solver.cpp:353] Iteration 2600 (7.21776 iter/s, 13.8547s/100 iter), loss = 4.27203
I0801 15:27:56.122534 12219 solver.cpp:375]     Train net output #0: loss = 4.11778 (* 1 = 4.11778 loss)
I0801 15:27:56.122539 12219 sgd_solver.cpp:136] Iteration 2600, lr = 0.0991875, m = 0.9
I0801 15:28:09.984827 12219 solver.cpp:353] Iteration 2700 (7.21402 iter/s, 13.8619s/100 iter), loss = 3.77707
I0801 15:28:09.985075 12219 solver.cpp:375]     Train net output #0: loss = 3.87329 (* 1 = 3.87329 loss)
I0801 15:28:09.985186 12219 sgd_solver.cpp:136] Iteration 2700, lr = 0.0991563, m = 0.9
I0801 15:28:23.819178 12219 solver.cpp:353] Iteration 2800 (7.22859 iter/s, 13.834s/100 iter), loss = 3.50708
I0801 15:28:23.819205 12219 solver.cpp:375]     Train net output #0: loss = 3.75496 (* 1 = 3.75496 loss)
I0801 15:28:23.819211 12219 sgd_solver.cpp:136] Iteration 2800, lr = 0.099125, m = 0.9
I0801 15:28:37.715240 12219 solver.cpp:353] Iteration 2900 (7.1965 iter/s, 13.8956s/100 iter), loss = 3.78811
I0801 15:28:37.715270 12219 solver.cpp:375]     Train net output #0: loss = 3.90149 (* 1 = 3.90149 loss)
I0801 15:28:37.715276 12219 sgd_solver.cpp:136] Iteration 2900, lr = 0.0990938, m = 0.9
I0801 15:28:51.559034 12219 solver.cpp:353] Iteration 3000 (7.22366 iter/s, 13.8434s/100 iter), loss = 3.94139
I0801 15:28:51.559092 12219 solver.cpp:375]     Train net output #0: loss = 4.07882 (* 1 = 4.07882 loss)
I0801 15:28:51.559098 12219 sgd_solver.cpp:136] Iteration 3000, lr = 0.0990625, m = 0.9
I0801 15:29:05.488451 12219 solver.cpp:353] Iteration 3100 (7.17926 iter/s, 13.929s/100 iter), loss = 3.907
I0801 15:29:05.488478 12219 solver.cpp:375]     Train net output #0: loss = 3.37867 (* 1 = 3.37867 loss)
I0801 15:29:05.488484 12219 sgd_solver.cpp:136] Iteration 3100, lr = 0.0990313, m = 0.9
I0801 15:29:19.366065 12219 solver.cpp:353] Iteration 3200 (7.20606 iter/s, 13.8772s/100 iter), loss = 3.94836
I0801 15:29:19.366123 12219 solver.cpp:375]     Train net output #0: loss = 3.82414 (* 1 = 3.82414 loss)
I0801 15:29:19.366134 12219 sgd_solver.cpp:136] Iteration 3200, lr = 0.099, m = 0.9
I0801 15:29:33.217586 12219 solver.cpp:353] Iteration 3300 (7.21963 iter/s, 13.8511s/100 iter), loss = 3.65315
I0801 15:29:33.217663 12219 solver.cpp:375]     Train net output #0: loss = 3.73481 (* 1 = 3.73481 loss)
I0801 15:29:33.217669 12219 sgd_solver.cpp:136] Iteration 3300, lr = 0.0989688, m = 0.9
I0801 15:29:47.134675 12219 solver.cpp:353] Iteration 3400 (7.18562 iter/s, 13.9167s/100 iter), loss = 3.67879
I0801 15:29:47.134702 12219 solver.cpp:375]     Train net output #0: loss = 3.56325 (* 1 = 3.56325 loss)
I0801 15:29:47.134707 12219 sgd_solver.cpp:136] Iteration 3400, lr = 0.0989375, m = 0.9
I0801 15:30:01.083988 12219 solver.cpp:353] Iteration 3500 (7.16902 iter/s, 13.9489s/100 iter), loss = 4.22512
I0801 15:30:01.084014 12219 solver.cpp:375]     Train net output #0: loss = 3.97739 (* 1 = 3.97739 loss)
I0801 15:30:01.084020 12219 sgd_solver.cpp:136] Iteration 3500, lr = 0.0989062, m = 0.9
I0801 15:30:15.007339 12219 solver.cpp:353] Iteration 3600 (7.18239 iter/s, 13.9229s/100 iter), loss = 3.66619
I0801 15:30:15.007400 12219 solver.cpp:375]     Train net output #0: loss = 3.85865 (* 1 = 3.85865 loss)
I0801 15:30:15.007405 12219 sgd_solver.cpp:136] Iteration 3600, lr = 0.098875, m = 0.9
I0801 15:30:28.933197 12219 solver.cpp:353] Iteration 3700 (7.18109 iter/s, 13.9255s/100 iter), loss = 3.54337
I0801 15:30:28.933226 12219 solver.cpp:375]     Train net output #0: loss = 4.17896 (* 1 = 4.17896 loss)
I0801 15:30:28.933233 12219 sgd_solver.cpp:136] Iteration 3700, lr = 0.0988437, m = 0.9
I0801 15:30:42.766364 12219 solver.cpp:353] Iteration 3800 (7.22921 iter/s, 13.8328s/100 iter), loss = 3.80554
I0801 15:30:42.766393 12219 solver.cpp:375]     Train net output #0: loss = 3.95294 (* 1 = 3.95294 loss)
I0801 15:30:42.766399 12219 sgd_solver.cpp:136] Iteration 3800, lr = 0.0988125, m = 0.9
I0801 15:30:56.613142 12219 solver.cpp:353] Iteration 3900 (7.22211 iter/s, 13.8464s/100 iter), loss = 3.50653
I0801 15:30:56.613451 12219 solver.cpp:375]     Train net output #0: loss = 3.71999 (* 1 = 3.71999 loss)
I0801 15:30:56.613458 12219 sgd_solver.cpp:136] Iteration 3900, lr = 0.0987813, m = 0.9
I0801 15:31:10.382855 12219 solver.cpp:550] Iteration 4000, Testing net (#0)
I0801 15:31:29.522572 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.174057
I0801 15:31:29.522629 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.387764
I0801 15:31:29.522634 12219 solver.cpp:635]     Test net output #2: loss = 4.25211 (* 1 = 4.25211 loss)
I0801 15:31:29.522657 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.1393s
I0801 15:31:29.667088 12219 solver.cpp:353] Iteration 4000 (3.02544 iter/s, 33.053s/100 iter), loss = 3.36895
I0801 15:31:29.667140 12219 solver.cpp:375]     Train net output #0: loss = 3.70243 (* 1 = 3.70243 loss)
I0801 15:31:29.667152 12219 sgd_solver.cpp:136] Iteration 4000, lr = 0.09875, m = 0.9
I0801 15:31:43.485991 12219 solver.cpp:353] Iteration 4100 (7.23667 iter/s, 13.8185s/100 iter), loss = 3.36719
I0801 15:31:43.486016 12219 solver.cpp:375]     Train net output #0: loss = 3.30308 (* 1 = 3.30308 loss)
I0801 15:31:43.486021 12219 sgd_solver.cpp:136] Iteration 4100, lr = 0.0987188, m = 0.9
I0801 15:31:57.362515 12219 solver.cpp:353] Iteration 4200 (7.20662 iter/s, 13.8761s/100 iter), loss = 3.43897
I0801 15:31:57.362545 12219 solver.cpp:375]     Train net output #0: loss = 3.65857 (* 1 = 3.65857 loss)
I0801 15:31:57.362550 12219 sgd_solver.cpp:136] Iteration 4200, lr = 0.0986875, m = 0.9
I0801 15:32:11.272825 12219 solver.cpp:353] Iteration 4300 (7.18912 iter/s, 13.9099s/100 iter), loss = 3.5733
I0801 15:32:11.272953 12219 solver.cpp:375]     Train net output #0: loss = 3.64137 (* 1 = 3.64137 loss)
I0801 15:32:11.272958 12219 sgd_solver.cpp:136] Iteration 4300, lr = 0.0986563, m = 0.9
I0801 15:32:25.151614 12219 solver.cpp:353] Iteration 4400 (7.20545 iter/s, 13.8784s/100 iter), loss = 3.59838
I0801 15:32:25.151639 12219 solver.cpp:375]     Train net output #0: loss = 3.54114 (* 1 = 3.54114 loss)
I0801 15:32:25.151643 12219 sgd_solver.cpp:136] Iteration 4400, lr = 0.098625, m = 0.9
I0801 15:32:39.041812 12219 solver.cpp:353] Iteration 4500 (7.19954 iter/s, 13.8898s/100 iter), loss = 3.66163
I0801 15:32:39.041841 12219 solver.cpp:375]     Train net output #0: loss = 3.74436 (* 1 = 3.74436 loss)
I0801 15:32:39.041846 12219 sgd_solver.cpp:136] Iteration 4500, lr = 0.0985937, m = 0.9
I0801 15:32:52.923051 12219 solver.cpp:353] Iteration 4600 (7.20418 iter/s, 13.8808s/100 iter), loss = 3.21689
I0801 15:32:52.923137 12219 solver.cpp:375]     Train net output #0: loss = 3.48634 (* 1 = 3.48634 loss)
I0801 15:32:52.923144 12219 sgd_solver.cpp:136] Iteration 4600, lr = 0.0985625, m = 0.9
I0801 15:33:06.810184 12219 solver.cpp:353] Iteration 4700 (7.20112 iter/s, 13.8867s/100 iter), loss = 3.93483
I0801 15:33:06.810215 12219 solver.cpp:375]     Train net output #0: loss = 3.84452 (* 1 = 3.84452 loss)
I0801 15:33:06.810221 12219 sgd_solver.cpp:136] Iteration 4700, lr = 0.0985313, m = 0.9
I0801 15:33:20.698134 12219 solver.cpp:353] Iteration 4800 (7.2007 iter/s, 13.8875s/100 iter), loss = 3.46667
I0801 15:33:20.698173 12219 solver.cpp:375]     Train net output #0: loss = 3.95318 (* 1 = 3.95318 loss)
I0801 15:33:20.698179 12219 sgd_solver.cpp:136] Iteration 4800, lr = 0.0985, m = 0.9
I0801 15:33:34.635466 12219 solver.cpp:353] Iteration 4900 (7.17518 iter/s, 13.9369s/100 iter), loss = 3.56412
I0801 15:33:34.635731 12219 solver.cpp:375]     Train net output #0: loss = 3.50302 (* 1 = 3.50302 loss)
I0801 15:33:34.635843 12219 sgd_solver.cpp:136] Iteration 4900, lr = 0.0984688, m = 0.9
I0801 15:33:48.529340 12219 solver.cpp:353] Iteration 5000 (7.19762 iter/s, 13.8935s/100 iter), loss = 3.40669
I0801 15:33:48.529366 12219 solver.cpp:375]     Train net output #0: loss = 4.03875 (* 1 = 4.03875 loss)
I0801 15:33:48.529372 12219 sgd_solver.cpp:136] Iteration 5000, lr = 0.0984375, m = 0.9
I0801 15:34:02.387521 12219 solver.cpp:353] Iteration 5100 (7.21616 iter/s, 13.8578s/100 iter), loss = 3.37479
I0801 15:34:02.387547 12219 solver.cpp:375]     Train net output #0: loss = 3.34088 (* 1 = 3.34088 loss)
I0801 15:34:02.387553 12219 sgd_solver.cpp:136] Iteration 5100, lr = 0.0984062, m = 0.9
I0801 15:34:16.272616 12219 solver.cpp:353] Iteration 5200 (7.20217 iter/s, 13.8847s/100 iter), loss = 3.45046
I0801 15:34:16.272682 12219 solver.cpp:375]     Train net output #0: loss = 3.38868 (* 1 = 3.38868 loss)
I0801 15:34:16.272691 12219 sgd_solver.cpp:136] Iteration 5200, lr = 0.098375, m = 0.9
I0801 15:34:30.124855 12219 solver.cpp:353] Iteration 5300 (7.21926 iter/s, 13.8518s/100 iter), loss = 3.49831
I0801 15:34:30.124881 12219 solver.cpp:375]     Train net output #0: loss = 3.43035 (* 1 = 3.43035 loss)
I0801 15:34:30.124884 12219 sgd_solver.cpp:136] Iteration 5300, lr = 0.0983438, m = 0.9
I0801 15:34:44.054919 12219 solver.cpp:353] Iteration 5400 (7.17892 iter/s, 13.9297s/100 iter), loss = 3.42589
I0801 15:34:44.054944 12219 solver.cpp:375]     Train net output #0: loss = 3.64696 (* 1 = 3.64696 loss)
I0801 15:34:44.054949 12219 sgd_solver.cpp:136] Iteration 5400, lr = 0.0983125, m = 0.9
I0801 15:34:57.896349 12219 solver.cpp:353] Iteration 5500 (7.2249 iter/s, 13.841s/100 iter), loss = 3.04533
I0801 15:34:57.896411 12219 solver.cpp:375]     Train net output #0: loss = 3.25076 (* 1 = 3.25076 loss)
I0801 15:34:57.896419 12219 sgd_solver.cpp:136] Iteration 5500, lr = 0.0982813, m = 0.9
I0801 15:35:11.741103 12219 solver.cpp:353] Iteration 5600 (7.22316 iter/s, 13.8444s/100 iter), loss = 3.18598
I0801 15:35:11.741132 12219 solver.cpp:375]     Train net output #0: loss = 3.11853 (* 1 = 3.11853 loss)
I0801 15:35:11.741137 12219 sgd_solver.cpp:136] Iteration 5600, lr = 0.09825, m = 0.9
I0801 15:35:25.676837 12219 solver.cpp:353] Iteration 5700 (7.176 iter/s, 13.9353s/100 iter), loss = 3.51559
I0801 15:35:25.676889 12219 solver.cpp:375]     Train net output #0: loss = 3.49649 (* 1 = 3.49649 loss)
I0801 15:35:25.676901 12219 sgd_solver.cpp:136] Iteration 5700, lr = 0.0982188, m = 0.9
I0801 15:35:39.528828 12219 solver.cpp:353] Iteration 5800 (7.21939 iter/s, 13.8516s/100 iter), loss = 2.8782
I0801 15:35:39.528920 12219 solver.cpp:375]     Train net output #0: loss = 2.87123 (* 1 = 2.87123 loss)
I0801 15:35:39.528934 12219 sgd_solver.cpp:136] Iteration 5800, lr = 0.0981875, m = 0.9
I0801 15:35:53.474037 12219 solver.cpp:353] Iteration 5900 (7.17113 iter/s, 13.9448s/100 iter), loss = 2.97679
I0801 15:35:53.474066 12219 solver.cpp:375]     Train net output #0: loss = 2.75246 (* 1 = 2.75246 loss)
I0801 15:35:53.474072 12219 sgd_solver.cpp:136] Iteration 5900, lr = 0.0981563, m = 0.9
I0801 15:36:07.217229 12219 solver.cpp:550] Iteration 6000, Testing net (#0)
I0801 15:36:26.678715 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.230175
I0801 15:36:26.678810 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.465059
I0801 15:36:26.678820 12219 solver.cpp:635]     Test net output #2: loss = 3.88373 (* 1 = 3.88373 loss)
I0801 15:36:26.678839 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.4611s
I0801 15:36:26.816447 12219 solver.cpp:353] Iteration 6000 (2.99927 iter/s, 33.3415s/100 iter), loss = 3.41707
I0801 15:36:26.816478 12219 solver.cpp:375]     Train net output #0: loss = 3.362 (* 1 = 3.362 loss)
I0801 15:36:26.816483 12219 sgd_solver.cpp:136] Iteration 6000, lr = 0.098125, m = 0.9
I0801 15:36:40.685086 12219 solver.cpp:353] Iteration 6100 (7.21072 iter/s, 13.8682s/100 iter), loss = 3.46111
I0801 15:36:40.685114 12219 solver.cpp:375]     Train net output #0: loss = 3.37651 (* 1 = 3.37651 loss)
I0801 15:36:40.685119 12219 sgd_solver.cpp:136] Iteration 6100, lr = 0.0980937, m = 0.9
I0801 15:36:54.589193 12219 solver.cpp:353] Iteration 6200 (7.19233 iter/s, 13.9037s/100 iter), loss = 3.6221
I0801 15:36:54.589221 12219 solver.cpp:375]     Train net output #0: loss = 3.31705 (* 1 = 3.31705 loss)
I0801 15:36:54.589226 12219 sgd_solver.cpp:136] Iteration 6200, lr = 0.0980625, m = 0.9
I0801 15:37:08.460989 12219 solver.cpp:353] Iteration 6300 (7.20908 iter/s, 13.8714s/100 iter), loss = 2.77034
I0801 15:37:08.461050 12219 solver.cpp:375]     Train net output #0: loss = 2.41612 (* 1 = 2.41612 loss)
I0801 15:37:08.461056 12219 sgd_solver.cpp:136] Iteration 6300, lr = 0.0980313, m = 0.9
I0801 15:37:22.340965 12219 solver.cpp:353] Iteration 6400 (7.20483 iter/s, 13.8796s/100 iter), loss = 2.70039
I0801 15:37:22.340992 12219 solver.cpp:375]     Train net output #0: loss = 2.96498 (* 1 = 2.96498 loss)
I0801 15:37:22.340996 12219 sgd_solver.cpp:136] Iteration 6400, lr = 0.098, m = 0.9
I0801 15:37:36.295733 12219 solver.cpp:353] Iteration 6500 (7.16621 iter/s, 13.9544s/100 iter), loss = 3.2103
I0801 15:37:36.295758 12219 solver.cpp:375]     Train net output #0: loss = 3.32919 (* 1 = 3.32919 loss)
I0801 15:37:36.295763 12219 sgd_solver.cpp:136] Iteration 6500, lr = 0.0979687, m = 0.9
I0801 15:37:50.180706 12219 solver.cpp:353] Iteration 6600 (7.20225 iter/s, 13.8846s/100 iter), loss = 2.71534
I0801 15:37:50.180794 12219 solver.cpp:375]     Train net output #0: loss = 2.79786 (* 1 = 2.79786 loss)
I0801 15:37:50.180807 12219 sgd_solver.cpp:136] Iteration 6600, lr = 0.0979375, m = 0.9
I0801 15:38:04.032428 12219 solver.cpp:353] Iteration 6700 (7.21952 iter/s, 13.8513s/100 iter), loss = 3.37336
I0801 15:38:04.032452 12219 solver.cpp:375]     Train net output #0: loss = 3.39755 (* 1 = 3.39755 loss)
I0801 15:38:04.032455 12219 sgd_solver.cpp:136] Iteration 6700, lr = 0.0979063, m = 0.9
I0801 15:38:17.886582 12219 solver.cpp:353] Iteration 6800 (7.21826 iter/s, 13.8538s/100 iter), loss = 2.7683
I0801 15:38:17.886610 12219 solver.cpp:375]     Train net output #0: loss = 3.02287 (* 1 = 3.02287 loss)
I0801 15:38:17.886615 12219 sgd_solver.cpp:136] Iteration 6800, lr = 0.097875, m = 0.9
I0801 15:38:31.736191 12219 solver.cpp:353] Iteration 6900 (7.22063 iter/s, 13.8492s/100 iter), loss = 3.00714
I0801 15:38:31.736250 12219 solver.cpp:375]     Train net output #0: loss = 3.00793 (* 1 = 3.00793 loss)
I0801 15:38:31.736255 12219 sgd_solver.cpp:136] Iteration 6900, lr = 0.0978438, m = 0.9
I0801 15:38:45.656433 12219 solver.cpp:353] Iteration 7000 (7.18399 iter/s, 13.9198s/100 iter), loss = 2.71986
I0801 15:38:45.656462 12219 solver.cpp:375]     Train net output #0: loss = 2.52087 (* 1 = 2.52087 loss)
I0801 15:38:45.656468 12219 sgd_solver.cpp:136] Iteration 7000, lr = 0.0978125, m = 0.9
I0801 15:38:59.543272 12219 solver.cpp:353] Iteration 7100 (7.20127 iter/s, 13.8864s/100 iter), loss = 3.17229
I0801 15:38:59.543325 12219 solver.cpp:375]     Train net output #0: loss = 3.18492 (* 1 = 3.18492 loss)
I0801 15:38:59.543339 12219 sgd_solver.cpp:136] Iteration 7100, lr = 0.0977813, m = 0.9
I0801 15:39:13.457460 12219 solver.cpp:353] Iteration 7200 (7.18711 iter/s, 13.9138s/100 iter), loss = 3.56775
I0801 15:39:13.457535 12219 solver.cpp:375]     Train net output #0: loss = 3.47695 (* 1 = 3.47695 loss)
I0801 15:39:13.457540 12219 sgd_solver.cpp:136] Iteration 7200, lr = 0.09775, m = 0.9
I0801 15:39:27.317394 12219 solver.cpp:353] Iteration 7300 (7.21525 iter/s, 13.8595s/100 iter), loss = 3.06765
I0801 15:39:27.317421 12219 solver.cpp:375]     Train net output #0: loss = 3.19942 (* 1 = 3.19942 loss)
I0801 15:39:27.317425 12219 sgd_solver.cpp:136] Iteration 7300, lr = 0.0977188, m = 0.9
I0801 15:39:41.247572 12219 solver.cpp:353] Iteration 7400 (7.17886 iter/s, 13.9298s/100 iter), loss = 3.19044
I0801 15:39:41.247638 12219 solver.cpp:375]     Train net output #0: loss = 3.06991 (* 1 = 3.06991 loss)
I0801 15:39:41.247658 12219 sgd_solver.cpp:136] Iteration 7400, lr = 0.0976875, m = 0.9
I0801 15:39:55.211294 12219 solver.cpp:353] Iteration 7500 (7.16162 iter/s, 13.9633s/100 iter), loss = 3.5452
I0801 15:39:55.211355 12219 solver.cpp:375]     Train net output #0: loss = 3.92561 (* 1 = 3.92561 loss)
I0801 15:39:55.211362 12219 sgd_solver.cpp:136] Iteration 7500, lr = 0.0976562, m = 0.9
I0801 15:40:09.098875 12219 solver.cpp:353] Iteration 7600 (7.20089 iter/s, 13.8872s/100 iter), loss = 2.50431
I0801 15:40:09.098906 12219 solver.cpp:375]     Train net output #0: loss = 2.24237 (* 1 = 2.24237 loss)
I0801 15:40:09.098912 12219 sgd_solver.cpp:136] Iteration 7600, lr = 0.097625, m = 0.9
I0801 15:40:22.973091 12219 solver.cpp:353] Iteration 7700 (7.20782 iter/s, 13.8738s/100 iter), loss = 3.05699
I0801 15:40:22.973117 12219 solver.cpp:375]     Train net output #0: loss = 2.98239 (* 1 = 2.98239 loss)
I0801 15:40:22.973122 12219 sgd_solver.cpp:136] Iteration 7700, lr = 0.0975937, m = 0.9
I0801 15:40:36.917016 12219 solver.cpp:353] Iteration 7800 (7.17179 iter/s, 13.9435s/100 iter), loss = 3.07691
I0801 15:40:36.917075 12219 solver.cpp:375]     Train net output #0: loss = 3.3035 (* 1 = 3.3035 loss)
I0801 15:40:36.917081 12219 sgd_solver.cpp:136] Iteration 7800, lr = 0.0975625, m = 0.9
I0801 15:40:50.840299 12219 solver.cpp:353] Iteration 7900 (7.18242 iter/s, 13.9229s/100 iter), loss = 2.6728
I0801 15:40:50.840325 12219 solver.cpp:375]     Train net output #0: loss = 3.12612 (* 1 = 3.12612 loss)
I0801 15:40:50.840330 12219 sgd_solver.cpp:136] Iteration 7900, lr = 0.0975313, m = 0.9
I0801 15:41:04.694197 12219 solver.cpp:550] Iteration 8000, Testing net (#0)
I0801 15:41:09.330940 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 15:41:24.395002 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.265704
I0801 15:41:24.395023 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.515117
I0801 15:41:24.395030 12219 solver.cpp:635]     Test net output #2: loss = 3.56357 (* 1 = 3.56357 loss)
I0801 15:41:24.395094 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7003s
I0801 15:41:24.532676 12219 solver.cpp:353] Iteration 8000 (2.96811 iter/s, 33.6914s/100 iter), loss = 2.85784
I0801 15:41:24.532706 12219 solver.cpp:375]     Train net output #0: loss = 2.56354 (* 1 = 2.56354 loss)
I0801 15:41:24.532709 12219 sgd_solver.cpp:136] Iteration 8000, lr = 0.0975, m = 0.9
I0801 15:41:38.398627 12219 solver.cpp:353] Iteration 8100 (7.21212 iter/s, 13.8656s/100 iter), loss = 3.13451
I0801 15:41:38.398651 12219 solver.cpp:375]     Train net output #0: loss = 2.8675 (* 1 = 2.8675 loss)
I0801 15:41:38.398658 12219 sgd_solver.cpp:136] Iteration 8100, lr = 0.0974688, m = 0.9
I0801 15:41:52.265296 12219 solver.cpp:353] Iteration 8200 (7.21174 iter/s, 13.8663s/100 iter), loss = 2.91529
I0801 15:41:52.265416 12219 solver.cpp:375]     Train net output #0: loss = 3.0283 (* 1 = 3.0283 loss)
I0801 15:41:52.265439 12219 sgd_solver.cpp:136] Iteration 8200, lr = 0.0974375, m = 0.9
I0801 15:42:06.157757 12219 solver.cpp:353] Iteration 8300 (7.19835 iter/s, 13.8921s/100 iter), loss = 2.60749
I0801 15:42:06.157783 12219 solver.cpp:375]     Train net output #0: loss = 2.82373 (* 1 = 2.82373 loss)
I0801 15:42:06.157788 12219 sgd_solver.cpp:136] Iteration 8300, lr = 0.0974063, m = 0.9
I0801 15:42:20.045310 12219 solver.cpp:353] Iteration 8400 (7.2009 iter/s, 13.8872s/100 iter), loss = 2.82838
I0801 15:42:20.045336 12219 solver.cpp:375]     Train net output #0: loss = 2.99747 (* 1 = 2.99747 loss)
I0801 15:42:20.045339 12219 sgd_solver.cpp:136] Iteration 8400, lr = 0.097375, m = 0.9
I0801 15:42:33.940999 12219 solver.cpp:353] Iteration 8500 (7.19668 iter/s, 13.8953s/100 iter), loss = 2.96353
I0801 15:42:33.941076 12219 solver.cpp:375]     Train net output #0: loss = 3.1021 (* 1 = 3.1021 loss)
I0801 15:42:33.941082 12219 sgd_solver.cpp:136] Iteration 8500, lr = 0.0973438, m = 0.9
I0801 15:42:47.794682 12219 solver.cpp:353] Iteration 8600 (7.2185 iter/s, 13.8533s/100 iter), loss = 3.16736
I0801 15:42:47.794713 12219 solver.cpp:375]     Train net output #0: loss = 3.19342 (* 1 = 3.19342 loss)
I0801 15:42:47.794720 12219 sgd_solver.cpp:136] Iteration 8600, lr = 0.0973125, m = 0.9
I0801 15:43:01.653046 12219 solver.cpp:353] Iteration 8700 (7.21607 iter/s, 13.858s/100 iter), loss = 2.61775
I0801 15:43:01.653144 12219 solver.cpp:375]     Train net output #0: loss = 2.56013 (* 1 = 2.56013 loss)
I0801 15:43:01.653169 12219 sgd_solver.cpp:136] Iteration 8700, lr = 0.0972812, m = 0.9
I0801 15:43:15.636335 12219 solver.cpp:353] Iteration 8800 (7.1516 iter/s, 13.9829s/100 iter), loss = 2.78697
I0801 15:43:15.636396 12219 solver.cpp:375]     Train net output #0: loss = 3.13369 (* 1 = 3.13369 loss)
I0801 15:43:15.636402 12219 sgd_solver.cpp:136] Iteration 8800, lr = 0.09725, m = 0.9
I0801 15:43:29.513319 12219 solver.cpp:353] Iteration 8900 (7.20638 iter/s, 13.8766s/100 iter), loss = 3.06401
I0801 15:43:29.513382 12219 solver.cpp:375]     Train net output #0: loss = 3.01444 (* 1 = 3.01444 loss)
I0801 15:43:29.513401 12219 sgd_solver.cpp:136] Iteration 8900, lr = 0.0972188, m = 0.9
I0801 15:43:43.421150 12219 solver.cpp:353] Iteration 9000 (7.1904 iter/s, 13.9074s/100 iter), loss = 3.07568
I0801 15:43:43.421177 12219 solver.cpp:375]     Train net output #0: loss = 3.14021 (* 1 = 3.14021 loss)
I0801 15:43:43.421183 12219 sgd_solver.cpp:136] Iteration 9000, lr = 0.0971875, m = 0.9
I0801 15:43:57.263983 12219 solver.cpp:353] Iteration 9100 (7.22416 iter/s, 13.8424s/100 iter), loss = 2.67332
I0801 15:43:57.264050 12219 solver.cpp:375]     Train net output #0: loss = 2.31749 (* 1 = 2.31749 loss)
I0801 15:43:57.264056 12219 sgd_solver.cpp:136] Iteration 9100, lr = 0.0971562, m = 0.9
I0801 15:44:11.158676 12219 solver.cpp:353] Iteration 9200 (7.1972 iter/s, 13.8943s/100 iter), loss = 2.82679
I0801 15:44:11.158702 12219 solver.cpp:375]     Train net output #0: loss = 3.24265 (* 1 = 3.24265 loss)
I0801 15:44:11.158707 12219 sgd_solver.cpp:136] Iteration 9200, lr = 0.097125, m = 0.9
I0801 15:44:24.991343 12219 solver.cpp:353] Iteration 9300 (7.22947 iter/s, 13.8323s/100 iter), loss = 3.51474
I0801 15:44:24.991370 12219 solver.cpp:375]     Train net output #0: loss = 3.72493 (* 1 = 3.72493 loss)
I0801 15:44:24.991376 12219 sgd_solver.cpp:136] Iteration 9300, lr = 0.0970938, m = 0.9
I0801 15:44:38.873028 12219 solver.cpp:353] Iteration 9400 (7.20394 iter/s, 13.8813s/100 iter), loss = 2.62488
I0801 15:44:38.873095 12219 solver.cpp:375]     Train net output #0: loss = 2.20629 (* 1 = 2.20629 loss)
I0801 15:44:38.873101 12219 sgd_solver.cpp:136] Iteration 9400, lr = 0.0970625, m = 0.9
I0801 15:44:52.694208 12219 solver.cpp:353] Iteration 9500 (7.23548 iter/s, 13.8208s/100 iter), loss = 2.79805
I0801 15:44:52.694238 12219 solver.cpp:375]     Train net output #0: loss = 2.6787 (* 1 = 2.6787 loss)
I0801 15:44:52.694244 12219 sgd_solver.cpp:136] Iteration 9500, lr = 0.0970313, m = 0.9
I0801 15:45:06.599283 12219 solver.cpp:353] Iteration 9600 (7.19182 iter/s, 13.9047s/100 iter), loss = 3.27971
I0801 15:45:06.599309 12219 solver.cpp:375]     Train net output #0: loss = 3.20752 (* 1 = 3.20752 loss)
I0801 15:45:06.599314 12219 sgd_solver.cpp:136] Iteration 9600, lr = 0.097, m = 0.9
I0801 15:45:20.441470 12219 solver.cpp:353] Iteration 9700 (7.2245 iter/s, 13.8418s/100 iter), loss = 3.02464
I0801 15:45:20.441545 12219 solver.cpp:375]     Train net output #0: loss = 3.42082 (* 1 = 3.42082 loss)
I0801 15:45:20.441551 12219 sgd_solver.cpp:136] Iteration 9700, lr = 0.0969688, m = 0.9
I0801 15:45:34.253582 12219 solver.cpp:353] Iteration 9800 (7.24023 iter/s, 13.8117s/100 iter), loss = 2.87252
I0801 15:45:34.253612 12219 solver.cpp:375]     Train net output #0: loss = 2.91113 (* 1 = 2.91113 loss)
I0801 15:45:34.253618 12219 sgd_solver.cpp:136] Iteration 9800, lr = 0.0969375, m = 0.9
I0801 15:45:48.163033 12219 solver.cpp:353] Iteration 9900 (7.18956 iter/s, 13.9091s/100 iter), loss = 2.61201
I0801 15:45:48.163059 12219 solver.cpp:375]     Train net output #0: loss = 2.41667 (* 1 = 2.41667 loss)
I0801 15:45:48.163066 12219 sgd_solver.cpp:136] Iteration 9900, lr = 0.0969063, m = 0.9
I0801 15:46:01.908620 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_10000.caffemodel
I0801 15:46:01.935354 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_10000.solverstate
I0801 15:46:01.941603 12219 solver.cpp:550] Iteration 10000, Testing net (#0)
I0801 15:46:21.663136 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.304058
I0801 15:46:21.663161 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.554882
I0801 15:46:21.663167 12219 solver.cpp:635]     Test net output #2: loss = 3.35382 (* 1 = 3.35382 loss)
I0801 15:46:21.663187 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.721s
I0801 15:46:21.801623 12219 solver.cpp:353] Iteration 10000 (2.97286 iter/s, 33.6376s/100 iter), loss = 3.06423
I0801 15:46:21.801651 12219 solver.cpp:375]     Train net output #0: loss = 2.81622 (* 1 = 2.81622 loss)
I0801 15:46:21.801656 12219 sgd_solver.cpp:136] Iteration 10000, lr = 0.096875, m = 0.9
I0801 15:46:35.752660 12219 solver.cpp:353] Iteration 10100 (7.16813 iter/s, 13.9506s/100 iter), loss = 2.40304
I0801 15:46:35.752740 12219 solver.cpp:375]     Train net output #0: loss = 2.67523 (* 1 = 2.67523 loss)
I0801 15:46:35.752748 12219 sgd_solver.cpp:136] Iteration 10100, lr = 0.0968437, m = 0.9
I0801 15:46:49.659248 12219 solver.cpp:353] Iteration 10200 (7.19104 iter/s, 13.9062s/100 iter), loss = 2.69159
I0801 15:46:49.659276 12219 solver.cpp:375]     Train net output #0: loss = 2.56743 (* 1 = 2.56743 loss)
I0801 15:46:49.659282 12219 sgd_solver.cpp:136] Iteration 10200, lr = 0.0968125, m = 0.9
I0801 15:47:03.647475 12219 solver.cpp:353] Iteration 10300 (7.14907 iter/s, 13.9878s/100 iter), loss = 2.74165
I0801 15:47:03.647500 12219 solver.cpp:375]     Train net output #0: loss = 3.22065 (* 1 = 3.22065 loss)
I0801 15:47:03.647505 12219 sgd_solver.cpp:136] Iteration 10300, lr = 0.0967812, m = 0.9
I0801 15:47:17.590303 12219 solver.cpp:353] Iteration 10400 (7.17235 iter/s, 13.9424s/100 iter), loss = 2.44505
I0801 15:47:17.590569 12219 solver.cpp:375]     Train net output #0: loss = 1.91771 (* 1 = 1.91771 loss)
I0801 15:47:17.590680 12219 sgd_solver.cpp:136] Iteration 10400, lr = 0.09675, m = 0.9
I0801 15:47:31.426859 12219 solver.cpp:353] Iteration 10500 (7.22744 iter/s, 13.8362s/100 iter), loss = 2.33942
I0801 15:47:31.426888 12219 solver.cpp:375]     Train net output #0: loss = 2.11844 (* 1 = 2.11844 loss)
I0801 15:47:31.426894 12219 sgd_solver.cpp:136] Iteration 10500, lr = 0.0967188, m = 0.9
I0801 15:47:45.358513 12219 solver.cpp:353] Iteration 10600 (7.1781 iter/s, 13.9313s/100 iter), loss = 3.25343
I0801 15:47:45.358541 12219 solver.cpp:375]     Train net output #0: loss = 3.5679 (* 1 = 3.5679 loss)
I0801 15:47:45.358546 12219 sgd_solver.cpp:136] Iteration 10600, lr = 0.0966875, m = 0.9
I0801 15:47:59.280688 12219 solver.cpp:353] Iteration 10700 (7.18299 iter/s, 13.9218s/100 iter), loss = 2.89895
I0801 15:47:59.284929 12219 solver.cpp:375]     Train net output #0: loss = 2.45387 (* 1 = 2.45387 loss)
I0801 15:47:59.284948 12219 sgd_solver.cpp:136] Iteration 10700, lr = 0.0966563, m = 0.9
I0801 15:48:13.230396 12219 solver.cpp:353] Iteration 10800 (7.16881 iter/s, 13.9493s/100 iter), loss = 2.49333
I0801 15:48:13.230424 12219 solver.cpp:375]     Train net output #0: loss = 2.28773 (* 1 = 2.28773 loss)
I0801 15:48:13.230432 12219 sgd_solver.cpp:136] Iteration 10800, lr = 0.096625, m = 0.9
I0801 15:48:27.160490 12219 solver.cpp:353] Iteration 10900 (7.17891 iter/s, 13.9297s/100 iter), loss = 2.67486
I0801 15:48:27.160516 12219 solver.cpp:375]     Train net output #0: loss = 2.94353 (* 1 = 2.94353 loss)
I0801 15:48:27.160521 12219 sgd_solver.cpp:136] Iteration 10900, lr = 0.0965938, m = 0.9
I0801 15:48:41.053455 12219 solver.cpp:353] Iteration 11000 (7.19809 iter/s, 13.8926s/100 iter), loss = 2.5125
I0801 15:48:41.053517 12219 solver.cpp:375]     Train net output #0: loss = 2.3706 (* 1 = 2.3706 loss)
I0801 15:48:41.053524 12219 sgd_solver.cpp:136] Iteration 11000, lr = 0.0965625, m = 0.9
I0801 15:48:54.941309 12219 solver.cpp:353] Iteration 11100 (7.20074 iter/s, 13.8875s/100 iter), loss = 2.85606
I0801 15:48:54.941334 12219 solver.cpp:375]     Train net output #0: loss = 2.84738 (* 1 = 2.84738 loss)
I0801 15:48:54.941337 12219 sgd_solver.cpp:136] Iteration 11100, lr = 0.0965312, m = 0.9
I0801 15:49:08.832026 12219 solver.cpp:353] Iteration 11200 (7.19926 iter/s, 13.8903s/100 iter), loss = 2.54294
I0801 15:49:08.832053 12219 solver.cpp:375]     Train net output #0: loss = 2.26988 (* 1 = 2.26988 loss)
I0801 15:49:08.832060 12219 sgd_solver.cpp:136] Iteration 11200, lr = 0.0965, m = 0.9
I0801 15:49:22.656864 12219 solver.cpp:353] Iteration 11300 (7.23356 iter/s, 13.8244s/100 iter), loss = 2.79965
I0801 15:49:22.656929 12219 solver.cpp:375]     Train net output #0: loss = 2.72523 (* 1 = 2.72523 loss)
I0801 15:49:22.656936 12219 sgd_solver.cpp:136] Iteration 11300, lr = 0.0964688, m = 0.9
I0801 15:49:36.547652 12219 solver.cpp:353] Iteration 11400 (7.19922 iter/s, 13.8904s/100 iter), loss = 2.98134
I0801 15:49:36.547677 12219 solver.cpp:375]     Train net output #0: loss = 2.82381 (* 1 = 2.82381 loss)
I0801 15:49:36.547682 12219 sgd_solver.cpp:136] Iteration 11400, lr = 0.0964375, m = 0.9
I0801 15:49:50.409237 12219 solver.cpp:353] Iteration 11500 (7.21439 iter/s, 13.8612s/100 iter), loss = 3.21848
I0801 15:49:50.409265 12219 solver.cpp:375]     Train net output #0: loss = 3.01784 (* 1 = 3.01784 loss)
I0801 15:49:50.409271 12219 sgd_solver.cpp:136] Iteration 11500, lr = 0.0964063, m = 0.9
I0801 15:50:04.223801 12219 solver.cpp:353] Iteration 11600 (7.23894 iter/s, 13.8142s/100 iter), loss = 2.45969
I0801 15:50:04.223887 12219 solver.cpp:375]     Train net output #0: loss = 2.53947 (* 1 = 2.53947 loss)
I0801 15:50:04.223894 12219 sgd_solver.cpp:136] Iteration 11600, lr = 0.096375, m = 0.9
I0801 15:50:18.112993 12219 solver.cpp:353] Iteration 11700 (7.20005 iter/s, 13.8888s/100 iter), loss = 2.64295
I0801 15:50:18.113021 12219 solver.cpp:375]     Train net output #0: loss = 2.70761 (* 1 = 2.70761 loss)
I0801 15:50:18.113028 12219 sgd_solver.cpp:136] Iteration 11700, lr = 0.0963437, m = 0.9
I0801 15:50:31.972057 12219 solver.cpp:353] Iteration 11800 (7.2157 iter/s, 13.8587s/100 iter), loss = 2.55157
I0801 15:50:31.972082 12219 solver.cpp:375]     Train net output #0: loss = 2.2057 (* 1 = 2.2057 loss)
I0801 15:50:31.972088 12219 sgd_solver.cpp:136] Iteration 11800, lr = 0.0963125, m = 0.9
I0801 15:50:45.876574 12219 solver.cpp:353] Iteration 11900 (7.19211 iter/s, 13.9041s/100 iter), loss = 3.19661
I0801 15:50:45.876794 12219 solver.cpp:375]     Train net output #0: loss = 3.55676 (* 1 = 3.55676 loss)
I0801 15:50:45.876802 12219 sgd_solver.cpp:136] Iteration 11900, lr = 0.0962813, m = 0.9
I0801 15:50:59.568886 12219 solver.cpp:550] Iteration 12000, Testing net (#0)
I0801 15:51:18.881093 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.318058
I0801 15:51:18.881146 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.568882
I0801 15:51:18.881153 12219 solver.cpp:635]     Test net output #2: loss = 3.25738 (* 1 = 3.25738 loss)
I0801 15:51:18.881178 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.3117s
I0801 15:51:19.031014 12219 solver.cpp:353] Iteration 12000 (3.01627 iter/s, 33.1535s/100 iter), loss = 2.48314
I0801 15:51:19.031039 12219 solver.cpp:375]     Train net output #0: loss = 2.55421 (* 1 = 2.55421 loss)
I0801 15:51:19.031044 12219 sgd_solver.cpp:136] Iteration 12000, lr = 0.09625, m = 0.9
I0801 15:51:32.887291 12219 solver.cpp:353] Iteration 12100 (7.21715 iter/s, 13.8559s/100 iter), loss = 2.94413
I0801 15:51:32.887320 12219 solver.cpp:375]     Train net output #0: loss = 2.72598 (* 1 = 2.72598 loss)
I0801 15:51:32.887323 12219 sgd_solver.cpp:136] Iteration 12100, lr = 0.0962188, m = 0.9
I0801 15:51:46.774932 12219 solver.cpp:353] Iteration 12200 (7.20085 iter/s, 13.8872s/100 iter), loss = 2.67097
I0801 15:51:46.775008 12219 solver.cpp:375]     Train net output #0: loss = 2.26096 (* 1 = 2.26096 loss)
I0801 15:51:46.775028 12219 sgd_solver.cpp:136] Iteration 12200, lr = 0.0961875, m = 0.9
I0801 15:52:00.676487 12219 solver.cpp:353] Iteration 12300 (7.19364 iter/s, 13.9012s/100 iter), loss = 2.57171
I0801 15:52:00.676568 12219 solver.cpp:375]     Train net output #0: loss = 2.64192 (* 1 = 2.64192 loss)
I0801 15:52:00.676575 12219 sgd_solver.cpp:136] Iteration 12300, lr = 0.0961563, m = 0.9
I0801 15:52:14.585368 12219 solver.cpp:353] Iteration 12400 (7.18985 iter/s, 13.9085s/100 iter), loss = 2.41879
I0801 15:52:14.585398 12219 solver.cpp:375]     Train net output #0: loss = 2.53178 (* 1 = 2.53178 loss)
I0801 15:52:14.585404 12219 sgd_solver.cpp:136] Iteration 12400, lr = 0.096125, m = 0.9
I0801 15:52:28.527025 12219 solver.cpp:353] Iteration 12500 (7.17295 iter/s, 13.9413s/100 iter), loss = 2.73757
I0801 15:52:28.527053 12219 solver.cpp:375]     Train net output #0: loss = 2.75034 (* 1 = 2.75034 loss)
I0801 15:52:28.527060 12219 sgd_solver.cpp:136] Iteration 12500, lr = 0.0960938, m = 0.9
I0801 15:52:42.428328 12219 solver.cpp:353] Iteration 12600 (7.19378 iter/s, 13.9009s/100 iter), loss = 3.32047
I0801 15:52:42.428390 12219 solver.cpp:375]     Train net output #0: loss = 3.10984 (* 1 = 3.10984 loss)
I0801 15:52:42.428397 12219 sgd_solver.cpp:136] Iteration 12600, lr = 0.0960625, m = 0.9
I0801 15:52:56.354787 12219 solver.cpp:353] Iteration 12700 (7.18078 iter/s, 13.9261s/100 iter), loss = 2.62763
I0801 15:52:56.354817 12219 solver.cpp:375]     Train net output #0: loss = 2.43795 (* 1 = 2.43795 loss)
I0801 15:52:56.354823 12219 sgd_solver.cpp:136] Iteration 12700, lr = 0.0960312, m = 0.9
I0801 15:53:10.261734 12219 solver.cpp:353] Iteration 12800 (7.19085 iter/s, 13.9066s/100 iter), loss = 2.85079
I0801 15:53:10.261759 12219 solver.cpp:375]     Train net output #0: loss = 3.08677 (* 1 = 3.08677 loss)
I0801 15:53:10.261765 12219 sgd_solver.cpp:136] Iteration 12800, lr = 0.096, m = 0.9
I0801 15:53:24.144239 12219 solver.cpp:353] Iteration 12900 (7.20351 iter/s, 13.8821s/100 iter), loss = 2.23503
I0801 15:53:24.144289 12219 solver.cpp:375]     Train net output #0: loss = 2.46773 (* 1 = 2.46773 loss)
I0801 15:53:24.144294 12219 sgd_solver.cpp:136] Iteration 12900, lr = 0.0959687, m = 0.9
I0801 15:53:38.049209 12219 solver.cpp:353] Iteration 13000 (7.19188 iter/s, 13.9046s/100 iter), loss = 2.72548
I0801 15:53:38.049260 12219 solver.cpp:375]     Train net output #0: loss = 2.78529 (* 1 = 2.78529 loss)
I0801 15:53:38.049271 12219 sgd_solver.cpp:136] Iteration 13000, lr = 0.0959375, m = 0.9
I0801 15:53:51.958632 12219 solver.cpp:353] Iteration 13100 (7.18957 iter/s, 13.909s/100 iter), loss = 3.0431
I0801 15:53:51.958658 12219 solver.cpp:375]     Train net output #0: loss = 2.70584 (* 1 = 2.70584 loss)
I0801 15:53:51.958663 12219 sgd_solver.cpp:136] Iteration 13100, lr = 0.0959063, m = 0.9
I0801 15:54:05.878280 12219 solver.cpp:353] Iteration 13200 (7.18429 iter/s, 13.9193s/100 iter), loss = 3.16337
I0801 15:54:05.878352 12219 solver.cpp:375]     Train net output #0: loss = 3.00815 (* 1 = 3.00815 loss)
I0801 15:54:05.878358 12219 sgd_solver.cpp:136] Iteration 13200, lr = 0.095875, m = 0.9
I0801 15:54:19.783705 12219 solver.cpp:353] Iteration 13300 (7.19165 iter/s, 13.905s/100 iter), loss = 2.58297
I0801 15:54:19.783733 12219 solver.cpp:375]     Train net output #0: loss = 2.37277 (* 1 = 2.37277 loss)
I0801 15:54:19.783740 12219 sgd_solver.cpp:136] Iteration 13300, lr = 0.0958438, m = 0.9
I0801 15:54:33.757251 12219 solver.cpp:353] Iteration 13400 (7.15658 iter/s, 13.9732s/100 iter), loss = 2.4758
I0801 15:54:33.757277 12219 solver.cpp:375]     Train net output #0: loss = 2.47613 (* 1 = 2.47613 loss)
I0801 15:54:33.757280 12219 sgd_solver.cpp:136] Iteration 13400, lr = 0.0958125, m = 0.9
I0801 15:54:47.657541 12219 solver.cpp:353] Iteration 13500 (7.1943 iter/s, 13.8999s/100 iter), loss = 2.51744
I0801 15:54:47.657603 12219 solver.cpp:375]     Train net output #0: loss = 2.56535 (* 1 = 2.56535 loss)
I0801 15:54:47.657610 12219 sgd_solver.cpp:136] Iteration 13500, lr = 0.0957813, m = 0.9
I0801 15:55:01.579737 12219 solver.cpp:353] Iteration 13600 (7.18298 iter/s, 13.9218s/100 iter), loss = 2.72801
I0801 15:55:01.579800 12219 solver.cpp:375]     Train net output #0: loss = 2.78646 (* 1 = 2.78646 loss)
I0801 15:55:01.579818 12219 sgd_solver.cpp:136] Iteration 13600, lr = 0.09575, m = 0.9
I0801 15:55:15.504137 12219 solver.cpp:353] Iteration 13700 (7.18184 iter/s, 13.924s/100 iter), loss = 2.28139
I0801 15:55:15.504160 12219 solver.cpp:375]     Train net output #0: loss = 2.06425 (* 1 = 2.06425 loss)
I0801 15:55:15.504165 12219 sgd_solver.cpp:136] Iteration 13700, lr = 0.0957187, m = 0.9
I0801 15:55:29.341714 12219 solver.cpp:353] Iteration 13800 (7.2269 iter/s, 13.8372s/100 iter), loss = 2.24269
I0801 15:55:29.341775 12219 solver.cpp:375]     Train net output #0: loss = 1.98245 (* 1 = 1.98245 loss)
I0801 15:55:29.341781 12219 sgd_solver.cpp:136] Iteration 13800, lr = 0.0956875, m = 0.9
I0801 15:55:43.260854 12219 solver.cpp:353] Iteration 13900 (7.18456 iter/s, 13.9187s/100 iter), loss = 2.43035
I0801 15:55:43.260900 12219 solver.cpp:375]     Train net output #0: loss = 2.53447 (* 1 = 2.53447 loss)
I0801 15:55:43.260910 12219 sgd_solver.cpp:136] Iteration 13900, lr = 0.0956563, m = 0.9
I0801 15:55:57.038120 12219 solver.cpp:550] Iteration 14000, Testing net (#0)
I0801 15:56:06.000615 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 15:56:16.282573 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.306587
I0801 15:56:16.282596 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.561
I0801 15:56:16.282603 12219 solver.cpp:635]     Test net output #2: loss = 3.37489 (* 1 = 3.37489 loss)
I0801 15:56:16.282624 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.244s
I0801 15:56:16.434856 12219 solver.cpp:353] Iteration 14000 (3.01449 iter/s, 33.1731s/100 iter), loss = 2.53742
I0801 15:56:16.434885 12219 solver.cpp:375]     Train net output #0: loss = 2.57082 (* 1 = 2.57082 loss)
I0801 15:56:16.434891 12219 sgd_solver.cpp:136] Iteration 14000, lr = 0.095625, m = 0.9
I0801 15:56:30.339282 12219 solver.cpp:353] Iteration 14100 (7.19216 iter/s, 13.904s/100 iter), loss = 2.98369
I0801 15:56:30.339329 12219 solver.cpp:375]     Train net output #0: loss = 3.30775 (* 1 = 3.30775 loss)
I0801 15:56:30.339344 12219 sgd_solver.cpp:136] Iteration 14100, lr = 0.0955938, m = 0.9
I0801 15:56:44.262536 12219 solver.cpp:353] Iteration 14200 (7.18243 iter/s, 13.9229s/100 iter), loss = 2.90087
I0801 15:56:44.262617 12219 solver.cpp:375]     Train net output #0: loss = 3.09469 (* 1 = 3.09469 loss)
I0801 15:56:44.262624 12219 sgd_solver.cpp:136] Iteration 14200, lr = 0.0955625, m = 0.9
I0801 15:56:58.111910 12219 solver.cpp:353] Iteration 14300 (7.22075 iter/s, 13.849s/100 iter), loss = 2.58031
I0801 15:56:58.111989 12219 solver.cpp:375]     Train net output #0: loss = 2.33113 (* 1 = 2.33113 loss)
I0801 15:56:58.112007 12219 sgd_solver.cpp:136] Iteration 14300, lr = 0.0955312, m = 0.9
I0801 15:57:11.996315 12219 solver.cpp:353] Iteration 14400 (7.20253 iter/s, 13.884s/100 iter), loss = 2.50509
I0801 15:57:11.996341 12219 solver.cpp:375]     Train net output #0: loss = 2.56432 (* 1 = 2.56432 loss)
I0801 15:57:11.996347 12219 sgd_solver.cpp:136] Iteration 14400, lr = 0.0955, m = 0.9
I0801 15:57:25.946985 12219 solver.cpp:353] Iteration 14500 (7.16832 iter/s, 13.9503s/100 iter), loss = 2.56807
I0801 15:57:25.947062 12219 solver.cpp:375]     Train net output #0: loss = 2.67507 (* 1 = 2.67507 loss)
I0801 15:57:25.947069 12219 sgd_solver.cpp:136] Iteration 14500, lr = 0.0954688, m = 0.9
I0801 15:57:39.820940 12219 solver.cpp:353] Iteration 14600 (7.20795 iter/s, 13.8736s/100 iter), loss = 2.53434
I0801 15:57:39.820991 12219 solver.cpp:375]     Train net output #0: loss = 2.3347 (* 1 = 2.3347 loss)
I0801 15:57:39.821004 12219 sgd_solver.cpp:136] Iteration 14600, lr = 0.0954375, m = 0.9
I0801 15:57:53.647156 12219 solver.cpp:353] Iteration 14700 (7.23284 iter/s, 13.8258s/100 iter), loss = 2.78263
I0801 15:57:53.647186 12219 solver.cpp:375]     Train net output #0: loss = 2.63943 (* 1 = 2.63943 loss)
I0801 15:57:53.647192 12219 sgd_solver.cpp:136] Iteration 14700, lr = 0.0954063, m = 0.9
I0801 15:58:07.527271 12219 solver.cpp:353] Iteration 14800 (7.20476 iter/s, 13.8797s/100 iter), loss = 2.38744
I0801 15:58:07.527456 12219 solver.cpp:375]     Train net output #0: loss = 2.51501 (* 1 = 2.51501 loss)
I0801 15:58:07.527472 12219 sgd_solver.cpp:136] Iteration 14800, lr = 0.095375, m = 0.9
I0801 15:58:21.516651 12219 solver.cpp:353] Iteration 14900 (7.14848 iter/s, 13.989s/100 iter), loss = 2.359
I0801 15:58:21.516675 12219 solver.cpp:375]     Train net output #0: loss = 2.61209 (* 1 = 2.61209 loss)
I0801 15:58:21.516681 12219 sgd_solver.cpp:136] Iteration 14900, lr = 0.0953438, m = 0.9
I0801 15:58:35.607427 12219 solver.cpp:353] Iteration 15000 (7.09704 iter/s, 14.0904s/100 iter), loss = 2.60591
I0801 15:58:35.607455 12219 solver.cpp:375]     Train net output #0: loss = 2.61312 (* 1 = 2.61312 loss)
I0801 15:58:35.607460 12219 sgd_solver.cpp:136] Iteration 15000, lr = 0.0953125, m = 0.9
I0801 15:58:49.690191 12219 solver.cpp:353] Iteration 15100 (7.10108 iter/s, 14.0824s/100 iter), loss = 2.4415
I0801 15:58:49.690809 12219 solver.cpp:375]     Train net output #0: loss = 2.36951 (* 1 = 2.36951 loss)
I0801 15:58:49.690817 12219 sgd_solver.cpp:136] Iteration 15100, lr = 0.0952813, m = 0.9
I0801 15:59:03.591910 12219 solver.cpp:353] Iteration 15200 (7.19356 iter/s, 13.9013s/100 iter), loss = 3.03039
I0801 15:59:03.591939 12219 solver.cpp:375]     Train net output #0: loss = 3.0423 (* 1 = 3.0423 loss)
I0801 15:59:03.591945 12219 sgd_solver.cpp:136] Iteration 15200, lr = 0.09525, m = 0.9
I0801 15:59:17.471835 12219 solver.cpp:353] Iteration 15300 (7.20485 iter/s, 13.8795s/100 iter), loss = 2.77298
I0801 15:59:17.471899 12219 solver.cpp:375]     Train net output #0: loss = 2.81291 (* 1 = 2.81291 loss)
I0801 15:59:17.471920 12219 sgd_solver.cpp:136] Iteration 15300, lr = 0.0952187, m = 0.9
I0801 15:59:31.437216 12219 solver.cpp:353] Iteration 15400 (7.16076 iter/s, 13.965s/100 iter), loss = 2.42512
I0801 15:59:31.437288 12219 solver.cpp:375]     Train net output #0: loss = 2.5875 (* 1 = 2.5875 loss)
I0801 15:59:31.437294 12219 sgd_solver.cpp:136] Iteration 15400, lr = 0.0951875, m = 0.9
I0801 15:59:45.435550 12219 solver.cpp:353] Iteration 15500 (7.14392 iter/s, 13.9979s/100 iter), loss = 3.10948
I0801 15:59:45.435580 12219 solver.cpp:375]     Train net output #0: loss = 3.09363 (* 1 = 3.09363 loss)
I0801 15:59:45.435586 12219 sgd_solver.cpp:136] Iteration 15500, lr = 0.0951563, m = 0.9
I0801 15:59:59.363890 12219 solver.cpp:353] Iteration 15600 (7.17981 iter/s, 13.928s/100 iter), loss = 2.94393
I0801 15:59:59.363917 12219 solver.cpp:375]     Train net output #0: loss = 2.98759 (* 1 = 2.98759 loss)
I0801 15:59:59.363922 12219 sgd_solver.cpp:136] Iteration 15600, lr = 0.095125, m = 0.9
I0801 16:00:13.248440 12219 solver.cpp:353] Iteration 15700 (7.20245 iter/s, 13.8842s/100 iter), loss = 2.78432
I0801 16:00:13.248525 12219 solver.cpp:375]     Train net output #0: loss = 2.49764 (* 1 = 2.49764 loss)
I0801 16:00:13.248564 12219 sgd_solver.cpp:136] Iteration 15700, lr = 0.0950937, m = 0.9
I0801 16:00:27.147621 12219 solver.cpp:353] Iteration 15800 (7.19487 iter/s, 13.8988s/100 iter), loss = 2.51026
I0801 16:00:27.147650 12219 solver.cpp:375]     Train net output #0: loss = 2.43661 (* 1 = 2.43661 loss)
I0801 16:00:27.147655 12219 sgd_solver.cpp:136] Iteration 15800, lr = 0.0950625, m = 0.9
I0801 16:00:41.087344 12219 solver.cpp:353] Iteration 15900 (7.17395 iter/s, 13.9393s/100 iter), loss = 2.79775
I0801 16:00:41.087369 12219 solver.cpp:375]     Train net output #0: loss = 2.53251 (* 1 = 2.53251 loss)
I0801 16:00:41.087373 12219 sgd_solver.cpp:136] Iteration 15900, lr = 0.0950313, m = 0.9
I0801 16:00:54.911602 12219 solver.cpp:550] Iteration 16000, Testing net (#0)
I0801 16:01:10.330863 12207 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 16:01:14.056859 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.340293
I0801 16:01:14.056880 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.592706
I0801 16:01:14.056885 12219 solver.cpp:635]     Test net output #2: loss = 3.18744 (* 1 = 3.18744 loss)
I0801 16:01:14.056906 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.1448s
I0801 16:01:14.230907 12219 solver.cpp:353] Iteration 16000 (3.01726 iter/s, 33.1426s/100 iter), loss = 2.3747
I0801 16:01:14.230973 12219 solver.cpp:375]     Train net output #0: loss = 2.17534 (* 1 = 2.17534 loss)
I0801 16:01:14.230990 12219 sgd_solver.cpp:136] Iteration 16000, lr = 0.095, m = 0.9
I0801 16:01:28.043823 12219 solver.cpp:353] Iteration 16100 (7.23981 iter/s, 13.8125s/100 iter), loss = 2.53666
I0801 16:01:28.043879 12219 solver.cpp:375]     Train net output #0: loss = 2.25549 (* 1 = 2.25549 loss)
I0801 16:01:28.043884 12219 sgd_solver.cpp:136] Iteration 16100, lr = 0.0949688, m = 0.9
I0801 16:01:41.931670 12219 solver.cpp:353] Iteration 16200 (7.20074 iter/s, 13.8875s/100 iter), loss = 2.43311
I0801 16:01:41.931699 12219 solver.cpp:375]     Train net output #0: loss = 2.64045 (* 1 = 2.64045 loss)
I0801 16:01:41.931705 12219 sgd_solver.cpp:136] Iteration 16200, lr = 0.0949375, m = 0.9
I0801 16:01:55.788106 12219 solver.cpp:353] Iteration 16300 (7.21707 iter/s, 13.856s/100 iter), loss = 2.35716
I0801 16:01:55.788130 12219 solver.cpp:375]     Train net output #0: loss = 2.16837 (* 1 = 2.16837 loss)
I0801 16:01:55.788136 12219 sgd_solver.cpp:136] Iteration 16300, lr = 0.0949063, m = 0.9
I0801 16:02:09.684921 12219 solver.cpp:353] Iteration 16400 (7.1961 iter/s, 13.8964s/100 iter), loss = 2.63564
I0801 16:02:09.685186 12219 solver.cpp:375]     Train net output #0: loss = 2.46374 (* 1 = 2.46374 loss)
I0801 16:02:09.685312 12219 sgd_solver.cpp:136] Iteration 16400, lr = 0.094875, m = 0.9
I0801 16:02:23.608553 12219 solver.cpp:353] Iteration 16500 (7.18223 iter/s, 13.9232s/100 iter), loss = 2.78575
I0801 16:02:23.608619 12219 solver.cpp:375]     Train net output #0: loss = 3.07755 (* 1 = 3.07755 loss)
I0801 16:02:23.608639 12219 sgd_solver.cpp:136] Iteration 16500, lr = 0.0948438, m = 0.9
I0801 16:02:37.532974 12219 solver.cpp:353] Iteration 16600 (7.18183 iter/s, 13.924s/100 iter), loss = 2.92103
I0801 16:02:37.533002 12219 solver.cpp:375]     Train net output #0: loss = 2.99624 (* 1 = 2.99624 loss)
I0801 16:02:37.533010 12219 sgd_solver.cpp:136] Iteration 16600, lr = 0.0948125, m = 0.9
I0801 16:02:51.497253 12219 solver.cpp:353] Iteration 16700 (7.16133 iter/s, 13.9639s/100 iter), loss = 2.67539
I0801 16:02:51.497334 12219 solver.cpp:375]     Train net output #0: loss = 2.73366 (* 1 = 2.73366 loss)
I0801 16:02:51.497344 12219 sgd_solver.cpp:136] Iteration 16700, lr = 0.0947812, m = 0.9
I0801 16:03:05.395887 12219 solver.cpp:353] Iteration 16800 (7.19515 iter/s, 13.8982s/100 iter), loss = 2.07584
I0801 16:03:05.395915 12219 solver.cpp:375]     Train net output #0: loss = 2.00556 (* 1 = 2.00556 loss)
I0801 16:03:05.395920 12219 sgd_solver.cpp:136] Iteration 16800, lr = 0.09475, m = 0.9
I0801 16:03:19.236508 12219 solver.cpp:353] Iteration 16900 (7.22531 iter/s, 13.8402s/100 iter), loss = 2.18824
I0801 16:03:19.236537 12219 solver.cpp:375]     Train net output #0: loss = 2.04739 (* 1 = 2.04739 loss)
I0801 16:03:19.236543 12219 sgd_solver.cpp:136] Iteration 16900, lr = 0.0947187, m = 0.9
I0801 16:03:33.020408 12219 solver.cpp:353] Iteration 17000 (7.25505 iter/s, 13.7835s/100 iter), loss = 2.49231
I0801 16:03:33.020506 12219 solver.cpp:375]     Train net output #0: loss = 2.41674 (* 1 = 2.41674 loss)
I0801 16:03:33.020514 12219 sgd_solver.cpp:136] Iteration 17000, lr = 0.0946875, m = 0.9
I0801 16:03:46.916326 12219 solver.cpp:353] Iteration 17100 (7.19656 iter/s, 13.8955s/100 iter), loss = 2.61361
I0801 16:03:46.916354 12219 solver.cpp:375]     Train net output #0: loss = 2.86539 (* 1 = 2.86539 loss)
I0801 16:03:46.916359 12219 sgd_solver.cpp:136] Iteration 17100, lr = 0.0946563, m = 0.9
I0801 16:04:00.806918 12219 solver.cpp:353] Iteration 17200 (7.19932 iter/s, 13.8902s/100 iter), loss = 2.9334
I0801 16:04:00.806943 12219 solver.cpp:375]     Train net output #0: loss = 2.85017 (* 1 = 2.85017 loss)
I0801 16:04:00.806948 12219 sgd_solver.cpp:136] Iteration 17200, lr = 0.094625, m = 0.9
I0801 16:04:14.705016 12219 solver.cpp:353] Iteration 17300 (7.19543 iter/s, 13.8977s/100 iter), loss = 2.20647
I0801 16:04:14.705113 12219 solver.cpp:375]     Train net output #0: loss = 1.90739 (* 1 = 1.90739 loss)
I0801 16:04:14.705121 12219 sgd_solver.cpp:136] Iteration 17300, lr = 0.0945938, m = 0.9
I0801 16:04:28.539297 12219 solver.cpp:353] Iteration 17400 (7.22862 iter/s, 13.8339s/100 iter), loss = 2.40768
I0801 16:04:28.539321 12219 solver.cpp:375]     Train net output #0: loss = 2.67957 (* 1 = 2.67957 loss)
I0801 16:04:28.539327 12219 sgd_solver.cpp:136] Iteration 17400, lr = 0.0945625, m = 0.9
I0801 16:04:42.444753 12219 solver.cpp:353] Iteration 17500 (7.19163 iter/s, 13.9051s/100 iter), loss = 2.40601
I0801 16:04:42.444782 12219 solver.cpp:375]     Train net output #0: loss = 2.27987 (* 1 = 2.27987 loss)
I0801 16:04:42.444787 12219 sgd_solver.cpp:136] Iteration 17500, lr = 0.0945313, m = 0.9
I0801 16:04:56.305815 12219 solver.cpp:353] Iteration 17600 (7.21466 iter/s, 13.8607s/100 iter), loss = 2.38624
I0801 16:04:56.305897 12219 solver.cpp:375]     Train net output #0: loss = 2.59619 (* 1 = 2.59619 loss)
I0801 16:04:56.305904 12219 sgd_solver.cpp:136] Iteration 17600, lr = 0.0945, m = 0.9
I0801 16:05:10.167585 12219 solver.cpp:353] Iteration 17700 (7.2143 iter/s, 13.8614s/100 iter), loss = 2.70009
I0801 16:05:10.167613 12219 solver.cpp:375]     Train net output #0: loss = 3.11534 (* 1 = 3.11534 loss)
I0801 16:05:10.167620 12219 sgd_solver.cpp:136] Iteration 17700, lr = 0.0944688, m = 0.9
I0801 16:05:24.175727 12219 solver.cpp:353] Iteration 17800 (7.1389 iter/s, 14.0078s/100 iter), loss = 2.73026
I0801 16:05:24.175751 12219 solver.cpp:375]     Train net output #0: loss = 2.70252 (* 1 = 2.70252 loss)
I0801 16:05:24.175755 12219 sgd_solver.cpp:136] Iteration 17800, lr = 0.0944375, m = 0.9
I0801 16:05:38.062221 12219 solver.cpp:353] Iteration 17900 (7.20144 iter/s, 13.8861s/100 iter), loss = 2.32919
I0801 16:05:38.062305 12219 solver.cpp:375]     Train net output #0: loss = 1.95637 (* 1 = 1.95637 loss)
I0801 16:05:38.062319 12219 sgd_solver.cpp:136] Iteration 17900, lr = 0.0944062, m = 0.9
I0801 16:05:51.826539 12219 solver.cpp:550] Iteration 18000, Testing net (#0)
I0801 16:06:10.809463 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.292646
I0801 16:06:10.809542 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.549529
I0801 16:06:10.809551 12219 solver.cpp:635]     Test net output #2: loss = 3.49106 (* 1 = 3.49106 loss)
I0801 16:06:10.809571 12219 solver.cpp:305] [MultiGPU] Tests completed in 18.9825s
I0801 16:06:10.953609 12219 solver.cpp:353] Iteration 18000 (3.04039 iter/s, 32.8905s/100 iter), loss = 2.69219
I0801 16:06:10.953634 12219 solver.cpp:375]     Train net output #0: loss = 2.47592 (* 1 = 2.47592 loss)
I0801 16:06:10.953641 12219 sgd_solver.cpp:136] Iteration 18000, lr = 0.094375, m = 0.9
I0801 16:06:24.814795 12219 solver.cpp:353] Iteration 18100 (7.21459 iter/s, 13.8608s/100 iter), loss = 2.67546
I0801 16:06:24.814822 12219 solver.cpp:375]     Train net output #0: loss = 2.61748 (* 1 = 2.61748 loss)
I0801 16:06:24.814829 12219 sgd_solver.cpp:136] Iteration 18100, lr = 0.0943438, m = 0.9
I0801 16:06:38.744161 12219 solver.cpp:353] Iteration 18200 (7.17928 iter/s, 13.929s/100 iter), loss = 2.61124
I0801 16:06:38.744187 12219 solver.cpp:375]     Train net output #0: loss = 2.376 (* 1 = 2.376 loss)
I0801 16:06:38.744191 12219 sgd_solver.cpp:136] Iteration 18200, lr = 0.0943125, m = 0.9
I0801 16:06:52.683182 12219 solver.cpp:353] Iteration 18300 (7.17431 iter/s, 13.9386s/100 iter), loss = 2.90649
I0801 16:06:52.686285 12219 solver.cpp:375]     Train net output #0: loss = 2.82273 (* 1 = 2.82273 loss)
I0801 16:06:52.686293 12219 sgd_solver.cpp:136] Iteration 18300, lr = 0.0942812, m = 0.9
I0801 16:07:06.559942 12219 solver.cpp:353] Iteration 18400 (7.20649 iter/s, 13.8764s/100 iter), loss = 2.226
I0801 16:07:06.559972 12219 solver.cpp:375]     Train net output #0: loss = 2.31689 (* 1 = 2.31689 loss)
I0801 16:07:06.559978 12219 sgd_solver.cpp:136] Iteration 18400, lr = 0.09425, m = 0.9
I0801 16:07:20.453771 12219 solver.cpp:353] Iteration 18500 (7.19764 iter/s, 13.8934s/100 iter), loss = 2.16142
I0801 16:07:20.453831 12219 solver.cpp:375]     Train net output #0: loss = 2.42379 (* 1 = 2.42379 loss)
I0801 16:07:20.453845 12219 sgd_solver.cpp:136] Iteration 18500, lr = 0.0942188, m = 0.9
I0801 16:07:34.307823 12219 solver.cpp:353] Iteration 18600 (7.21831 iter/s, 13.8537s/100 iter), loss = 2.4389
I0801 16:07:34.307924 12219 solver.cpp:375]     Train net output #0: loss = 2.49719 (* 1 = 2.49719 loss)
I0801 16:07:34.307931 12219 sgd_solver.cpp:136] Iteration 18600, lr = 0.0941875, m = 0.9
I0801 16:07:48.200075 12219 solver.cpp:353] Iteration 18700 (7.19846 iter/s, 13.8919s/100 iter), loss = 2.60353
I0801 16:07:48.200101 12219 solver.cpp:375]     Train net output #0: loss = 2.71167 (* 1 = 2.71167 loss)
I0801 16:07:48.200107 12219 sgd_solver.cpp:136] Iteration 18700, lr = 0.0941563, m = 0.9
I0801 16:08:02.167182 12219 solver.cpp:353] Iteration 18800 (7.15988 iter/s, 13.9667s/100 iter), loss = 2.4379
I0801 16:08:02.167248 12219 solver.cpp:375]     Train net output #0: loss = 2.44804 (* 1 = 2.44804 loss)
I0801 16:08:02.167266 12219 sgd_solver.cpp:136] Iteration 18800, lr = 0.094125, m = 0.9
I0801 16:08:16.159766 12219 solver.cpp:353] Iteration 18900 (7.14685 iter/s, 13.9922s/100 iter), loss = 2.78379
I0801 16:08:16.159847 12219 solver.cpp:375]     Train net output #0: loss = 2.97685 (* 1 = 2.97685 loss)
I0801 16:08:16.159854 12219 sgd_solver.cpp:136] Iteration 18900, lr = 0.0940938, m = 0.9
I0801 16:08:30.010033 12219 solver.cpp:353] Iteration 19000 (7.22028 iter/s, 13.8499s/100 iter), loss = 2.65456
I0801 16:08:30.010056 12219 solver.cpp:375]     Train net output #0: loss = 2.49912 (* 1 = 2.49912 loss)
I0801 16:08:30.010061 12219 sgd_solver.cpp:136] Iteration 19000, lr = 0.0940625, m = 0.9
I0801 16:08:43.858871 12219 solver.cpp:353] Iteration 19100 (7.22103 iter/s, 13.8484s/100 iter), loss = 2.35201
I0801 16:08:43.858947 12219 solver.cpp:375]     Train net output #0: loss = 2.19517 (* 1 = 2.19517 loss)
I0801 16:08:43.858965 12219 sgd_solver.cpp:136] Iteration 19100, lr = 0.0940313, m = 0.9
I0801 16:08:57.846266 12219 solver.cpp:353] Iteration 19200 (7.1495 iter/s, 13.987s/100 iter), loss = 2.34998
I0801 16:08:57.846328 12219 solver.cpp:375]     Train net output #0: loss = 2.81317 (* 1 = 2.81317 loss)
I0801 16:08:57.846334 12219 sgd_solver.cpp:136] Iteration 19200, lr = 0.094, m = 0.9
I0801 16:09:11.707687 12219 solver.cpp:353] Iteration 19300 (7.21447 iter/s, 13.861s/100 iter), loss = 2.83173
I0801 16:09:11.707715 12219 solver.cpp:375]     Train net output #0: loss = 2.79826 (* 1 = 2.79826 loss)
I0801 16:09:11.707718 12219 sgd_solver.cpp:136] Iteration 19300, lr = 0.0939687, m = 0.9
I0801 16:09:25.593998 12219 solver.cpp:353] Iteration 19400 (7.20154 iter/s, 13.8859s/100 iter), loss = 2.37418
I0801 16:09:25.594027 12219 solver.cpp:375]     Train net output #0: loss = 2.23963 (* 1 = 2.23963 loss)
I0801 16:09:25.594032 12219 sgd_solver.cpp:136] Iteration 19400, lr = 0.0939375, m = 0.9
I0801 16:09:39.542997 12219 solver.cpp:353] Iteration 19500 (7.16918 iter/s, 13.9486s/100 iter), loss = 2.51474
I0801 16:09:39.543071 12219 solver.cpp:375]     Train net output #0: loss = 2.56323 (* 1 = 2.56323 loss)
I0801 16:09:39.543078 12219 sgd_solver.cpp:136] Iteration 19500, lr = 0.0939062, m = 0.9
I0801 16:09:53.406260 12219 solver.cpp:353] Iteration 19600 (7.21351 iter/s, 13.8629s/100 iter), loss = 2.23571
I0801 16:09:53.406288 12219 solver.cpp:375]     Train net output #0: loss = 2.24398 (* 1 = 2.24398 loss)
I0801 16:09:53.406293 12219 sgd_solver.cpp:136] Iteration 19600, lr = 0.093875, m = 0.9
I0801 16:10:07.335465 12219 solver.cpp:353] Iteration 19700 (7.17936 iter/s, 13.9288s/100 iter), loss = 2.46354
I0801 16:10:07.335491 12219 solver.cpp:375]     Train net output #0: loss = 2.28887 (* 1 = 2.28887 loss)
I0801 16:10:07.335497 12219 sgd_solver.cpp:136] Iteration 19700, lr = 0.0938438, m = 0.9
I0801 16:10:21.188390 12219 solver.cpp:353] Iteration 19800 (7.2189 iter/s, 13.8525s/100 iter), loss = 3.13918
I0801 16:10:21.188658 12219 solver.cpp:375]     Train net output #0: loss = 2.73592 (* 1 = 2.73592 loss)
I0801 16:10:21.188762 12219 sgd_solver.cpp:136] Iteration 19800, lr = 0.0938125, m = 0.9
I0801 16:10:35.053436 12219 solver.cpp:353] Iteration 19900 (7.21258 iter/s, 13.8647s/100 iter), loss = 2.59096
I0801 16:10:35.053460 12219 solver.cpp:375]     Train net output #0: loss = 2.14997 (* 1 = 2.14997 loss)
I0801 16:10:35.053465 12219 sgd_solver.cpp:136] Iteration 19900, lr = 0.0937813, m = 0.9
I0801 16:10:48.736220 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_20000.caffemodel
I0801 16:10:48.757027 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_20000.solverstate
I0801 16:10:48.762246 12219 solver.cpp:550] Iteration 20000, Testing net (#0)
I0801 16:11:02.431327 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 16:11:08.076416 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.350117
I0801 16:11:08.076436 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.605705
I0801 16:11:08.076442 12219 solver.cpp:635]     Test net output #2: loss = 3.08412 (* 1 = 3.08412 loss)
I0801 16:11:08.076463 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.3137s
I0801 16:11:08.224191 12219 solver.cpp:353] Iteration 20000 (3.01479 iter/s, 33.1698s/100 iter), loss = 2.62477
I0801 16:11:08.224220 12219 solver.cpp:375]     Train net output #0: loss = 2.31532 (* 1 = 2.31532 loss)
I0801 16:11:08.224225 12219 sgd_solver.cpp:136] Iteration 20000, lr = 0.09375, m = 0.9
I0801 16:11:22.105036 12219 solver.cpp:353] Iteration 20100 (7.20437 iter/s, 13.8805s/100 iter), loss = 2.4027
I0801 16:11:22.105062 12219 solver.cpp:375]     Train net output #0: loss = 2.69031 (* 1 = 2.69031 loss)
I0801 16:11:22.105067 12219 sgd_solver.cpp:136] Iteration 20100, lr = 0.0937188, m = 0.9
I0801 16:11:35.969203 12219 solver.cpp:353] Iteration 20200 (7.21304 iter/s, 13.8638s/100 iter), loss = 2.60617
I0801 16:11:35.969259 12219 solver.cpp:375]     Train net output #0: loss = 2.37745 (* 1 = 2.37745 loss)
I0801 16:11:35.969264 12219 sgd_solver.cpp:136] Iteration 20200, lr = 0.0936875, m = 0.9
I0801 16:11:49.912256 12219 solver.cpp:353] Iteration 20300 (7.17223 iter/s, 13.9427s/100 iter), loss = 2.57614
I0801 16:11:49.912279 12219 solver.cpp:375]     Train net output #0: loss = 2.85896 (* 1 = 2.85896 loss)
I0801 16:11:49.912283 12219 sgd_solver.cpp:136] Iteration 20300, lr = 0.0936562, m = 0.9
I0801 16:12:03.799103 12219 solver.cpp:353] Iteration 20400 (7.20126 iter/s, 13.8865s/100 iter), loss = 2.24369
I0801 16:12:03.799129 12219 solver.cpp:375]     Train net output #0: loss = 2.13546 (* 1 = 2.13546 loss)
I0801 16:12:03.799134 12219 sgd_solver.cpp:136] Iteration 20400, lr = 0.093625, m = 0.9
I0801 16:12:17.664746 12219 solver.cpp:353] Iteration 20500 (7.21228 iter/s, 13.8653s/100 iter), loss = 2.57992
I0801 16:12:17.664824 12219 solver.cpp:375]     Train net output #0: loss = 2.2167 (* 1 = 2.2167 loss)
I0801 16:12:17.664832 12219 sgd_solver.cpp:136] Iteration 20500, lr = 0.0935938, m = 0.9
I0801 16:12:31.532146 12219 solver.cpp:353] Iteration 20600 (7.21136 iter/s, 13.867s/100 iter), loss = 2.56748
I0801 16:12:31.532173 12219 solver.cpp:375]     Train net output #0: loss = 2.06923 (* 1 = 2.06923 loss)
I0801 16:12:31.532179 12219 sgd_solver.cpp:136] Iteration 20600, lr = 0.0935625, m = 0.9
I0801 16:12:45.516103 12219 solver.cpp:353] Iteration 20700 (7.15125 iter/s, 13.9836s/100 iter), loss = 2.67419
I0801 16:12:45.516129 12219 solver.cpp:375]     Train net output #0: loss = 2.30265 (* 1 = 2.30265 loss)
I0801 16:12:45.516134 12219 sgd_solver.cpp:136] Iteration 20700, lr = 0.0935313, m = 0.9
I0801 16:12:59.459950 12219 solver.cpp:353] Iteration 20800 (7.17183 iter/s, 13.9435s/100 iter), loss = 2.21938
I0801 16:12:59.460011 12219 solver.cpp:375]     Train net output #0: loss = 2.63099 (* 1 = 2.63099 loss)
I0801 16:12:59.460017 12219 sgd_solver.cpp:136] Iteration 20800, lr = 0.0935, m = 0.9
I0801 16:13:13.349416 12219 solver.cpp:353] Iteration 20900 (7.1999 iter/s, 13.8891s/100 iter), loss = 2.5452
I0801 16:13:13.349445 12219 solver.cpp:375]     Train net output #0: loss = 2.76441 (* 1 = 2.76441 loss)
I0801 16:13:13.349450 12219 sgd_solver.cpp:136] Iteration 20900, lr = 0.0934687, m = 0.9
I0801 16:13:27.172646 12219 solver.cpp:353] Iteration 21000 (7.2344 iter/s, 13.8228s/100 iter), loss = 2.63041
I0801 16:13:27.172672 12219 solver.cpp:375]     Train net output #0: loss = 2.26887 (* 1 = 2.26887 loss)
I0801 16:13:27.172675 12219 sgd_solver.cpp:136] Iteration 21000, lr = 0.0934375, m = 0.9
I0801 16:13:41.028452 12219 solver.cpp:353] Iteration 21100 (7.2174 iter/s, 13.8554s/100 iter), loss = 2.61611
I0801 16:13:41.028520 12219 solver.cpp:375]     Train net output #0: loss = 2.15841 (* 1 = 2.15841 loss)
I0801 16:13:41.028527 12219 sgd_solver.cpp:136] Iteration 21100, lr = 0.0934063, m = 0.9
I0801 16:13:54.960150 12219 solver.cpp:353] Iteration 21200 (7.17808 iter/s, 13.9313s/100 iter), loss = 2.84178
I0801 16:13:54.960180 12219 solver.cpp:375]     Train net output #0: loss = 3.2269 (* 1 = 3.2269 loss)
I0801 16:13:54.960187 12219 sgd_solver.cpp:136] Iteration 21200, lr = 0.093375, m = 0.9
I0801 16:14:08.856640 12219 solver.cpp:353] Iteration 21300 (7.19626 iter/s, 13.8961s/100 iter), loss = 2.50075
I0801 16:14:08.856706 12219 solver.cpp:375]     Train net output #0: loss = 3.12853 (* 1 = 3.12853 loss)
I0801 16:14:08.856724 12219 sgd_solver.cpp:136] Iteration 21300, lr = 0.0933437, m = 0.9
I0801 16:14:22.765837 12219 solver.cpp:353] Iteration 21400 (7.18969 iter/s, 13.9088s/100 iter), loss = 2.37498
I0801 16:14:22.765918 12219 solver.cpp:375]     Train net output #0: loss = 2.16882 (* 1 = 2.16882 loss)
I0801 16:14:22.765931 12219 sgd_solver.cpp:136] Iteration 21400, lr = 0.0933125, m = 0.9
I0801 16:14:36.620760 12219 solver.cpp:353] Iteration 21500 (7.21785 iter/s, 13.8545s/100 iter), loss = 2.34912
I0801 16:14:36.620790 12219 solver.cpp:375]     Train net output #0: loss = 2.56333 (* 1 = 2.56333 loss)
I0801 16:14:36.620795 12219 sgd_solver.cpp:136] Iteration 21500, lr = 0.0932813, m = 0.9
I0801 16:14:50.536412 12219 solver.cpp:353] Iteration 21600 (7.18636 iter/s, 13.9153s/100 iter), loss = 2.98405
I0801 16:14:50.536480 12219 solver.cpp:375]     Train net output #0: loss = 2.68417 (* 1 = 2.68417 loss)
I0801 16:14:50.536501 12219 sgd_solver.cpp:136] Iteration 21600, lr = 0.09325, m = 0.9
I0801 16:15:04.446462 12219 solver.cpp:353] Iteration 21700 (7.18925 iter/s, 13.9097s/100 iter), loss = 2.53341
I0801 16:15:04.446578 12219 solver.cpp:375]     Train net output #0: loss = 2.58099 (* 1 = 2.58099 loss)
I0801 16:15:04.446596 12219 sgd_solver.cpp:136] Iteration 21700, lr = 0.0932188, m = 0.9
I0801 16:15:18.385663 12219 solver.cpp:353] Iteration 21800 (7.17421 iter/s, 13.9388s/100 iter), loss = 2.02774
I0801 16:15:18.385689 12219 solver.cpp:375]     Train net output #0: loss = 1.80579 (* 1 = 1.80579 loss)
I0801 16:15:18.385694 12219 sgd_solver.cpp:136] Iteration 21800, lr = 0.0931875, m = 0.9
I0801 16:15:32.202886 12219 solver.cpp:353] Iteration 21900 (7.23755 iter/s, 13.8168s/100 iter), loss = 2.41578
I0801 16:15:32.202915 12219 solver.cpp:375]     Train net output #0: loss = 2.85421 (* 1 = 2.85421 loss)
I0801 16:15:32.202921 12219 sgd_solver.cpp:136] Iteration 21900, lr = 0.0931562, m = 0.9
I0801 16:15:46.040292 12219 solver.cpp:550] Iteration 22000, Testing net (#0)
I0801 16:16:05.687984 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.35247
I0801 16:16:05.688004 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.604117
I0801 16:16:05.688009 12219 solver.cpp:635]     Test net output #2: loss = 3.06479 (* 1 = 3.06479 loss)
I0801 16:16:05.688076 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6473s
I0801 16:16:05.828228 12219 solver.cpp:353] Iteration 22000 (2.97403 iter/s, 33.6244s/100 iter), loss = 2.68132
I0801 16:16:05.828255 12219 solver.cpp:375]     Train net output #0: loss = 2.42845 (* 1 = 2.42845 loss)
I0801 16:16:05.828261 12219 sgd_solver.cpp:136] Iteration 22000, lr = 0.093125, m = 0.9
I0801 16:16:19.686594 12219 solver.cpp:353] Iteration 22100 (7.21607 iter/s, 13.858s/100 iter), loss = 2.52969
I0801 16:16:19.686648 12219 solver.cpp:375]     Train net output #0: loss = 2.63663 (* 1 = 2.63663 loss)
I0801 16:16:19.686653 12219 sgd_solver.cpp:136] Iteration 22100, lr = 0.0930938, m = 0.9
I0801 16:16:33.653250 12219 solver.cpp:353] Iteration 22200 (7.16011 iter/s, 13.9663s/100 iter), loss = 2.26739
I0801 16:16:33.653280 12219 solver.cpp:375]     Train net output #0: loss = 1.94725 (* 1 = 1.94725 loss)
I0801 16:16:33.653285 12219 sgd_solver.cpp:136] Iteration 22200, lr = 0.0930625, m = 0.9
I0801 16:16:47.557339 12219 solver.cpp:353] Iteration 22300 (7.19233 iter/s, 13.9037s/100 iter), loss = 2.22662
I0801 16:16:47.557365 12219 solver.cpp:375]     Train net output #0: loss = 2.27844 (* 1 = 2.27844 loss)
I0801 16:16:47.557371 12219 sgd_solver.cpp:136] Iteration 22300, lr = 0.0930312, m = 0.9
I0801 16:17:01.489542 12219 solver.cpp:353] Iteration 22400 (7.17782 iter/s, 13.9318s/100 iter), loss = 2.51236
I0801 16:17:01.489871 12219 solver.cpp:375]     Train net output #0: loss = 2.25796 (* 1 = 2.25796 loss)
I0801 16:17:01.489876 12219 sgd_solver.cpp:136] Iteration 22400, lr = 0.093, m = 0.9
I0801 16:17:15.365685 12219 solver.cpp:353] Iteration 22500 (7.20682 iter/s, 13.8758s/100 iter), loss = 2.43196
I0801 16:17:15.365711 12219 solver.cpp:375]     Train net output #0: loss = 2.53806 (* 1 = 2.53806 loss)
I0801 16:17:15.365717 12219 sgd_solver.cpp:136] Iteration 22500, lr = 0.0929688, m = 0.9
I0801 16:17:29.166604 12219 solver.cpp:353] Iteration 22600 (7.2461 iter/s, 13.8005s/100 iter), loss = 2.33247
I0801 16:17:29.166630 12219 solver.cpp:375]     Train net output #0: loss = 1.71182 (* 1 = 1.71182 loss)
I0801 16:17:29.166633 12219 sgd_solver.cpp:136] Iteration 22600, lr = 0.0929375, m = 0.9
I0801 16:17:43.026592 12219 solver.cpp:353] Iteration 22700 (7.21522 iter/s, 13.8596s/100 iter), loss = 2.30453
I0801 16:17:43.026651 12219 solver.cpp:375]     Train net output #0: loss = 2.61809 (* 1 = 2.61809 loss)
I0801 16:17:43.026659 12219 sgd_solver.cpp:136] Iteration 22700, lr = 0.0929063, m = 0.9
I0801 16:17:56.822564 12219 solver.cpp:353] Iteration 22800 (7.24869 iter/s, 13.7956s/100 iter), loss = 2.40688
I0801 16:17:56.822588 12219 solver.cpp:375]     Train net output #0: loss = 2.66349 (* 1 = 2.66349 loss)
I0801 16:17:56.822593 12219 sgd_solver.cpp:136] Iteration 22800, lr = 0.092875, m = 0.9
I0801 16:18:10.681484 12219 solver.cpp:353] Iteration 22900 (7.21577 iter/s, 13.8585s/100 iter), loss = 2.53173
I0801 16:18:10.681511 12219 solver.cpp:375]     Train net output #0: loss = 2.63784 (* 1 = 2.63784 loss)
I0801 16:18:10.681517 12219 sgd_solver.cpp:136] Iteration 22900, lr = 0.0928437, m = 0.9
I0801 16:18:24.557813 12219 solver.cpp:353] Iteration 23000 (7.20672 iter/s, 13.8759s/100 iter), loss = 2.52275
I0801 16:18:24.557896 12219 solver.cpp:375]     Train net output #0: loss = 2.5289 (* 1 = 2.5289 loss)
I0801 16:18:24.557905 12219 sgd_solver.cpp:136] Iteration 23000, lr = 0.0928125, m = 0.9
I0801 16:18:38.417780 12219 solver.cpp:353] Iteration 23100 (7.21523 iter/s, 13.8596s/100 iter), loss = 2.47275
I0801 16:18:38.417809 12219 solver.cpp:375]     Train net output #0: loss = 2.38383 (* 1 = 2.38383 loss)
I0801 16:18:38.417814 12219 sgd_solver.cpp:136] Iteration 23100, lr = 0.0927813, m = 0.9
I0801 16:18:52.345048 12219 solver.cpp:353] Iteration 23200 (7.18036 iter/s, 13.9269s/100 iter), loss = 2.27889
I0801 16:18:52.345100 12219 solver.cpp:375]     Train net output #0: loss = 2.04199 (* 1 = 2.04199 loss)
I0801 16:18:52.345113 12219 sgd_solver.cpp:136] Iteration 23200, lr = 0.09275, m = 0.9
I0801 16:19:06.228189 12219 solver.cpp:353] Iteration 23300 (7.20318 iter/s, 13.8828s/100 iter), loss = 2.30511
I0801 16:19:06.228276 12219 solver.cpp:375]     Train net output #0: loss = 2.39915 (* 1 = 2.39915 loss)
I0801 16:19:06.228288 12219 sgd_solver.cpp:136] Iteration 23300, lr = 0.0927188, m = 0.9
I0801 16:19:20.174738 12219 solver.cpp:353] Iteration 23400 (7.17043 iter/s, 13.9462s/100 iter), loss = 2.62254
I0801 16:19:20.174767 12219 solver.cpp:375]     Train net output #0: loss = 2.82078 (* 1 = 2.82078 loss)
I0801 16:19:20.174772 12219 sgd_solver.cpp:136] Iteration 23400, lr = 0.0926875, m = 0.9
I0801 16:19:34.064136 12219 solver.cpp:353] Iteration 23500 (7.19994 iter/s, 13.889s/100 iter), loss = 2.57433
I0801 16:19:34.064159 12219 solver.cpp:375]     Train net output #0: loss = 2.77278 (* 1 = 2.77278 loss)
I0801 16:19:34.064165 12219 sgd_solver.cpp:136] Iteration 23500, lr = 0.0926562, m = 0.9
I0801 16:19:47.984397 12219 solver.cpp:353] Iteration 23600 (7.18397 iter/s, 13.9199s/100 iter), loss = 2.55714
I0801 16:19:47.984458 12219 solver.cpp:375]     Train net output #0: loss = 2.78172 (* 1 = 2.78172 loss)
I0801 16:19:47.984464 12219 sgd_solver.cpp:136] Iteration 23600, lr = 0.092625, m = 0.9
I0801 16:20:01.870715 12219 solver.cpp:353] Iteration 23700 (7.20153 iter/s, 13.8859s/100 iter), loss = 2.61775
I0801 16:20:01.870779 12219 solver.cpp:375]     Train net output #0: loss = 2.47434 (* 1 = 2.47434 loss)
I0801 16:20:01.870795 12219 sgd_solver.cpp:136] Iteration 23700, lr = 0.0925938, m = 0.9
I0801 16:20:15.725698 12219 solver.cpp:353] Iteration 23800 (7.21782 iter/s, 13.8546s/100 iter), loss = 2.49398
I0801 16:20:15.725728 12219 solver.cpp:375]     Train net output #0: loss = 2.77015 (* 1 = 2.77015 loss)
I0801 16:20:15.725733 12219 sgd_solver.cpp:136] Iteration 23800, lr = 0.0925625, m = 0.9
I0801 16:20:29.576934 12219 solver.cpp:353] Iteration 23900 (7.21977 iter/s, 13.8509s/100 iter), loss = 2.3785
I0801 16:20:29.576994 12219 solver.cpp:375]     Train net output #0: loss = 2.29005 (* 1 = 2.29005 loss)
I0801 16:20:29.577002 12219 sgd_solver.cpp:136] Iteration 23900, lr = 0.0925313, m = 0.9
I0801 16:20:43.295464 12219 solver.cpp:550] Iteration 24000, Testing net (#0)
I0801 16:21:02.756731 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.352823
I0801 16:21:02.756852 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.616117
I0801 16:21:02.756861 12219 solver.cpp:635]     Test net output #2: loss = 3.05855 (* 1 = 3.05855 loss)
I0801 16:21:02.756880 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.4609s
I0801 16:21:02.896733 12219 solver.cpp:353] Iteration 24000 (3.0013 iter/s, 33.3189s/100 iter), loss = 2.43988
I0801 16:21:02.896759 12219 solver.cpp:375]     Train net output #0: loss = 2.08194 (* 1 = 2.08194 loss)
I0801 16:21:02.896764 12219 sgd_solver.cpp:136] Iteration 24000, lr = 0.0925, m = 0.9
I0801 16:21:16.745281 12219 solver.cpp:353] Iteration 24100 (7.22118 iter/s, 13.8482s/100 iter), loss = 2.41088
I0801 16:21:16.745306 12219 solver.cpp:375]     Train net output #0: loss = 2.40068 (* 1 = 2.40068 loss)
I0801 16:21:16.745311 12219 sgd_solver.cpp:136] Iteration 24100, lr = 0.0924688, m = 0.9
I0801 16:21:30.683868 12219 solver.cpp:353] Iteration 24200 (7.17453 iter/s, 13.9382s/100 iter), loss = 2.28698
I0801 16:21:30.683895 12219 solver.cpp:375]     Train net output #0: loss = 1.82546 (* 1 = 1.82546 loss)
I0801 16:21:30.683902 12219 sgd_solver.cpp:136] Iteration 24200, lr = 0.0924375, m = 0.9
I0801 16:21:44.607080 12219 solver.cpp:353] Iteration 24300 (7.18245 iter/s, 13.9228s/100 iter), loss = 2.03899
I0801 16:21:44.607151 12219 solver.cpp:375]     Train net output #0: loss = 2.05357 (* 1 = 2.05357 loss)
I0801 16:21:44.607158 12219 sgd_solver.cpp:136] Iteration 24300, lr = 0.0924063, m = 0.9
I0801 16:21:58.456732 12219 solver.cpp:353] Iteration 24400 (7.2206 iter/s, 13.8493s/100 iter), loss = 2.49427
I0801 16:21:58.456761 12219 solver.cpp:375]     Train net output #0: loss = 2.45773 (* 1 = 2.45773 loss)
I0801 16:21:58.456768 12219 sgd_solver.cpp:136] Iteration 24400, lr = 0.092375, m = 0.9
I0801 16:22:12.305687 12219 solver.cpp:353] Iteration 24500 (7.22096 iter/s, 13.8486s/100 iter), loss = 2.64019
I0801 16:22:12.305711 12219 solver.cpp:375]     Train net output #0: loss = 3.13661 (* 1 = 3.13661 loss)
I0801 16:22:12.305716 12219 sgd_solver.cpp:136] Iteration 24500, lr = 0.0923437, m = 0.9
I0801 16:22:26.213469 12219 solver.cpp:353] Iteration 24600 (7.19042 iter/s, 13.9074s/100 iter), loss = 2.48876
I0801 16:22:26.213529 12219 solver.cpp:375]     Train net output #0: loss = 2.28111 (* 1 = 2.28111 loss)
I0801 16:22:26.213536 12219 sgd_solver.cpp:136] Iteration 24600, lr = 0.0923125, m = 0.9
I0801 16:22:40.076324 12219 solver.cpp:353] Iteration 24700 (7.21372 iter/s, 13.8625s/100 iter), loss = 2.37154
I0801 16:22:40.076347 12219 solver.cpp:375]     Train net output #0: loss = 2.558 (* 1 = 2.558 loss)
I0801 16:22:40.076351 12219 sgd_solver.cpp:136] Iteration 24700, lr = 0.0922813, m = 0.9
I0801 16:22:53.901396 12219 solver.cpp:353] Iteration 24800 (7.23344 iter/s, 13.8247s/100 iter), loss = 2.09747
I0801 16:22:53.901422 12219 solver.cpp:375]     Train net output #0: loss = 2.17691 (* 1 = 2.17691 loss)
I0801 16:22:53.901428 12219 sgd_solver.cpp:136] Iteration 24800, lr = 0.09225, m = 0.9
I0801 16:23:07.829424 12219 solver.cpp:353] Iteration 24900 (7.17998 iter/s, 13.9276s/100 iter), loss = 2.26565
I0801 16:23:07.829506 12219 solver.cpp:375]     Train net output #0: loss = 2.2212 (* 1 = 2.2212 loss)
I0801 16:23:07.829514 12219 sgd_solver.cpp:136] Iteration 24900, lr = 0.0922187, m = 0.9
I0801 16:23:21.694268 12219 solver.cpp:353] Iteration 25000 (7.21269 iter/s, 13.8645s/100 iter), loss = 2.49567
I0801 16:23:21.694298 12219 solver.cpp:375]     Train net output #0: loss = 2.3845 (* 1 = 2.3845 loss)
I0801 16:23:21.694303 12219 sgd_solver.cpp:136] Iteration 25000, lr = 0.0921875, m = 0.9
I0801 16:23:35.593446 12219 solver.cpp:353] Iteration 25100 (7.19487 iter/s, 13.8988s/100 iter), loss = 2.79663
I0801 16:23:35.593477 12219 solver.cpp:375]     Train net output #0: loss = 3.0423 (* 1 = 3.0423 loss)
I0801 16:23:35.593483 12219 sgd_solver.cpp:136] Iteration 25100, lr = 0.0921563, m = 0.9
I0801 16:23:49.439640 12219 solver.cpp:353] Iteration 25200 (7.2224 iter/s, 13.8458s/100 iter), loss = 2.2365
I0801 16:23:49.439728 12219 solver.cpp:375]     Train net output #0: loss = 2.19484 (* 1 = 2.19484 loss)
I0801 16:23:49.439741 12219 sgd_solver.cpp:136] Iteration 25200, lr = 0.092125, m = 0.9
I0801 16:24:03.295002 12219 solver.cpp:353] Iteration 25300 (7.21762 iter/s, 13.855s/100 iter), loss = 2.76876
I0801 16:24:03.295029 12219 solver.cpp:375]     Train net output #0: loss = 2.81979 (* 1 = 2.81979 loss)
I0801 16:24:03.295034 12219 sgd_solver.cpp:136] Iteration 25300, lr = 0.0920938, m = 0.9
I0801 16:24:17.214901 12219 solver.cpp:353] Iteration 25400 (7.18416 iter/s, 13.9195s/100 iter), loss = 2.57224
I0801 16:24:17.214953 12219 solver.cpp:375]     Train net output #0: loss = 2.55955 (* 1 = 2.55955 loss)
I0801 16:24:17.214967 12219 sgd_solver.cpp:136] Iteration 25400, lr = 0.0920625, m = 0.9
I0801 16:24:31.050293 12219 solver.cpp:353] Iteration 25500 (7.22804 iter/s, 13.835s/100 iter), loss = 2.82089
I0801 16:24:31.050366 12219 solver.cpp:375]     Train net output #0: loss = 2.74301 (* 1 = 2.74301 loss)
I0801 16:24:31.050374 12219 sgd_solver.cpp:136] Iteration 25500, lr = 0.0920313, m = 0.9
I0801 16:24:44.898664 12219 solver.cpp:353] Iteration 25600 (7.22128 iter/s, 13.848s/100 iter), loss = 2.48879
I0801 16:24:44.898718 12219 solver.cpp:375]     Train net output #0: loss = 2.3173 (* 1 = 2.3173 loss)
I0801 16:24:44.898731 12219 sgd_solver.cpp:136] Iteration 25600, lr = 0.092, m = 0.9
I0801 16:24:58.774641 12219 solver.cpp:353] Iteration 25700 (7.2069 iter/s, 13.8756s/100 iter), loss = 2.42871
I0801 16:24:58.774669 12219 solver.cpp:375]     Train net output #0: loss = 2.14952 (* 1 = 2.14952 loss)
I0801 16:24:58.774677 12219 sgd_solver.cpp:136] Iteration 25700, lr = 0.0919688, m = 0.9
I0801 16:25:12.623634 12219 solver.cpp:353] Iteration 25800 (7.22094 iter/s, 13.8486s/100 iter), loss = 2.40381
I0801 16:25:12.623697 12219 solver.cpp:375]     Train net output #0: loss = 2.22848 (* 1 = 2.22848 loss)
I0801 16:25:12.623702 12219 sgd_solver.cpp:136] Iteration 25800, lr = 0.0919375, m = 0.9
I0801 16:25:26.539096 12219 solver.cpp:353] Iteration 25900 (7.18645 iter/s, 13.9151s/100 iter), loss = 2.481
I0801 16:25:26.539125 12219 solver.cpp:375]     Train net output #0: loss = 3.01634 (* 1 = 3.01634 loss)
I0801 16:25:26.539131 12219 sgd_solver.cpp:136] Iteration 25900, lr = 0.0919062, m = 0.9
I0801 16:25:40.423565 12219 solver.cpp:550] Iteration 26000, Testing net (#0)
I0801 16:25:58.850623 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 16:25:59.772081 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.31394
I0801 16:25:59.772106 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.565117
I0801 16:25:59.772112 12219 solver.cpp:635]     Test net output #2: loss = 3.32948 (* 1 = 3.32948 loss)
I0801 16:25:59.772140 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.348s
I0801 16:25:59.921808 12219 solver.cpp:353] Iteration 26000 (2.99565 iter/s, 33.3818s/100 iter), loss = 2.03365
I0801 16:25:59.921872 12219 solver.cpp:375]     Train net output #0: loss = 1.95418 (* 1 = 1.95418 loss)
I0801 16:25:59.921891 12219 sgd_solver.cpp:136] Iteration 26000, lr = 0.091875, m = 0.9
I0801 16:26:13.843305 12219 solver.cpp:353] Iteration 26100 (7.18334 iter/s, 13.9211s/100 iter), loss = 2.614
I0801 16:26:13.843335 12219 solver.cpp:375]     Train net output #0: loss = 2.62925 (* 1 = 2.62925 loss)
I0801 16:26:13.843341 12219 sgd_solver.cpp:136] Iteration 26100, lr = 0.0918437, m = 0.9
I0801 16:26:27.791103 12219 solver.cpp:353] Iteration 26200 (7.1698 iter/s, 13.9474s/100 iter), loss = 2.34164
I0801 16:26:27.791132 12219 solver.cpp:375]     Train net output #0: loss = 2.41779 (* 1 = 2.41779 loss)
I0801 16:26:27.791138 12219 sgd_solver.cpp:136] Iteration 26200, lr = 0.0918125, m = 0.9
I0801 16:26:41.911835 12219 solver.cpp:353] Iteration 26300 (7.08198 iter/s, 14.1203s/100 iter), loss = 2.69317
I0801 16:26:41.911895 12219 solver.cpp:375]     Train net output #0: loss = 3.07784 (* 1 = 3.07784 loss)
I0801 16:26:41.911902 12219 sgd_solver.cpp:136] Iteration 26300, lr = 0.0917813, m = 0.9
I0801 16:26:55.919287 12219 solver.cpp:353] Iteration 26400 (7.13926 iter/s, 14.0071s/100 iter), loss = 2.24085
I0801 16:26:55.919312 12219 solver.cpp:375]     Train net output #0: loss = 2.03309 (* 1 = 2.03309 loss)
I0801 16:26:55.919317 12219 sgd_solver.cpp:136] Iteration 26400, lr = 0.09175, m = 0.9
I0801 16:27:09.908324 12219 solver.cpp:353] Iteration 26500 (7.14866 iter/s, 13.9886s/100 iter), loss = 2.88503
I0801 16:27:09.908402 12219 solver.cpp:375]     Train net output #0: loss = 2.94664 (* 1 = 2.94664 loss)
I0801 16:27:09.908421 12219 sgd_solver.cpp:136] Iteration 26500, lr = 0.0917188, m = 0.9
I0801 16:27:23.970468 12219 solver.cpp:353] Iteration 26600 (7.11149 iter/s, 14.0618s/100 iter), loss = 2.21379
I0801 16:27:23.970538 12219 solver.cpp:375]     Train net output #0: loss = 2.1912 (* 1 = 2.1912 loss)
I0801 16:27:23.970544 12219 sgd_solver.cpp:136] Iteration 26600, lr = 0.0916875, m = 0.9
I0801 16:27:37.972966 12219 solver.cpp:353] Iteration 26700 (7.14178 iter/s, 14.0021s/100 iter), loss = 2.55491
I0801 16:27:37.972990 12219 solver.cpp:375]     Train net output #0: loss = 2.65326 (* 1 = 2.65326 loss)
I0801 16:27:37.972995 12219 sgd_solver.cpp:136] Iteration 26700, lr = 0.0916563, m = 0.9
I0801 16:27:52.150365 12219 solver.cpp:353] Iteration 26800 (7.05368 iter/s, 14.177s/100 iter), loss = 2.36959
I0801 16:27:52.150390 12219 solver.cpp:375]     Train net output #0: loss = 2.0577 (* 1 = 2.0577 loss)
I0801 16:27:52.150395 12219 sgd_solver.cpp:136] Iteration 26800, lr = 0.091625, m = 0.9
I0801 16:28:06.133173 12219 solver.cpp:353] Iteration 26900 (7.15184 iter/s, 13.9824s/100 iter), loss = 2.41204
I0801 16:28:06.133235 12219 solver.cpp:375]     Train net output #0: loss = 2.54081 (* 1 = 2.54081 loss)
I0801 16:28:06.133242 12219 sgd_solver.cpp:136] Iteration 26900, lr = 0.0915937, m = 0.9
I0801 16:28:20.220438 12219 solver.cpp:353] Iteration 27000 (7.09881 iter/s, 14.0869s/100 iter), loss = 2.29829
I0801 16:28:20.220466 12219 solver.cpp:375]     Train net output #0: loss = 2.47364 (* 1 = 2.47364 loss)
I0801 16:28:20.220470 12219 sgd_solver.cpp:136] Iteration 27000, lr = 0.0915625, m = 0.9
I0801 16:28:34.324509 12219 solver.cpp:353] Iteration 27100 (7.09035 iter/s, 14.1037s/100 iter), loss = 2.4103
I0801 16:28:34.324537 12219 solver.cpp:375]     Train net output #0: loss = 2.75409 (* 1 = 2.75409 loss)
I0801 16:28:34.324542 12219 sgd_solver.cpp:136] Iteration 27100, lr = 0.0915313, m = 0.9
I0801 16:28:48.257972 12219 solver.cpp:353] Iteration 27200 (7.17717 iter/s, 13.9331s/100 iter), loss = 2.68337
I0801 16:28:48.258046 12219 solver.cpp:375]     Train net output #0: loss = 2.61466 (* 1 = 2.61466 loss)
I0801 16:28:48.258060 12219 sgd_solver.cpp:136] Iteration 27200, lr = 0.0915, m = 0.9
I0801 16:29:02.293814 12219 solver.cpp:353] Iteration 27300 (7.12481 iter/s, 14.0355s/100 iter), loss = 2.70164
I0801 16:29:02.293869 12219 solver.cpp:375]     Train net output #0: loss = 2.88403 (* 1 = 2.88403 loss)
I0801 16:29:02.293880 12219 sgd_solver.cpp:136] Iteration 27300, lr = 0.0914688, m = 0.9
I0801 16:29:16.343727 12219 solver.cpp:353] Iteration 27400 (7.11768 iter/s, 14.0495s/100 iter), loss = 2.04782
I0801 16:29:16.343752 12219 solver.cpp:375]     Train net output #0: loss = 1.63255 (* 1 = 1.63255 loss)
I0801 16:29:16.343756 12219 sgd_solver.cpp:136] Iteration 27400, lr = 0.0914375, m = 0.9
I0801 16:29:30.473800 12219 solver.cpp:353] Iteration 27500 (7.0773 iter/s, 14.1297s/100 iter), loss = 2.22487
I0801 16:29:30.473857 12219 solver.cpp:375]     Train net output #0: loss = 2.36249 (* 1 = 2.36249 loss)
I0801 16:29:30.473865 12219 sgd_solver.cpp:136] Iteration 27500, lr = 0.0914062, m = 0.9
I0801 16:29:44.541357 12219 solver.cpp:353] Iteration 27600 (7.10875 iter/s, 14.0672s/100 iter), loss = 2.48652
I0801 16:29:44.541383 12219 solver.cpp:375]     Train net output #0: loss = 2.46481 (* 1 = 2.46481 loss)
I0801 16:29:44.541388 12219 sgd_solver.cpp:136] Iteration 27600, lr = 0.091375, m = 0.9
I0801 16:29:58.482779 12219 solver.cpp:353] Iteration 27700 (7.17308 iter/s, 13.941s/100 iter), loss = 2.29159
I0801 16:29:58.482805 12219 solver.cpp:375]     Train net output #0: loss = 2.23963 (* 1 = 2.23963 loss)
I0801 16:29:58.482810 12219 sgd_solver.cpp:136] Iteration 27700, lr = 0.0913438, m = 0.9
I0801 16:30:12.399819 12219 solver.cpp:353] Iteration 27800 (7.18564 iter/s, 13.9167s/100 iter), loss = 2.13368
I0801 16:30:12.399884 12219 solver.cpp:375]     Train net output #0: loss = 2.31773 (* 1 = 2.31773 loss)
I0801 16:30:12.399891 12219 sgd_solver.cpp:136] Iteration 27800, lr = 0.0913125, m = 0.9
I0801 16:30:26.426829 12219 solver.cpp:353] Iteration 27900 (7.1293 iter/s, 14.0266s/100 iter), loss = 2.2476
I0801 16:30:26.426857 12219 solver.cpp:375]     Train net output #0: loss = 2.03326 (* 1 = 2.03326 loss)
I0801 16:30:26.426863 12219 sgd_solver.cpp:136] Iteration 27900, lr = 0.0912813, m = 0.9
I0801 16:30:40.119657 12219 solver.cpp:550] Iteration 28000, Testing net (#0)
I0801 16:30:59.542263 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.347293
I0801 16:30:59.542340 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.609823
I0801 16:30:59.542346 12219 solver.cpp:635]     Test net output #2: loss = 3.06697 (* 1 = 3.06697 loss)
I0801 16:30:59.542364 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.4222s
I0801 16:30:59.688594 12219 solver.cpp:353] Iteration 28000 (3.00654 iter/s, 33.2608s/100 iter), loss = 2.32568
I0801 16:30:59.688617 12219 solver.cpp:375]     Train net output #0: loss = 2.1365 (* 1 = 2.1365 loss)
I0801 16:30:59.688621 12219 sgd_solver.cpp:136] Iteration 28000, lr = 0.09125, m = 0.9
I0801 16:31:13.542693 12219 solver.cpp:353] Iteration 28100 (7.21828 iter/s, 13.8537s/100 iter), loss = 2.65494
I0801 16:31:13.542722 12219 solver.cpp:375]     Train net output #0: loss = 2.19706 (* 1 = 2.19706 loss)
I0801 16:31:13.542728 12219 sgd_solver.cpp:136] Iteration 28100, lr = 0.0912188, m = 0.9
I0801 16:31:27.400365 12219 solver.cpp:353] Iteration 28200 (7.21642 iter/s, 13.8573s/100 iter), loss = 2.32933
I0801 16:31:27.400393 12219 solver.cpp:375]     Train net output #0: loss = 2.96747 (* 1 = 2.96747 loss)
I0801 16:31:27.400398 12219 sgd_solver.cpp:136] Iteration 28200, lr = 0.0911875, m = 0.9
I0801 16:31:41.287717 12219 solver.cpp:353] Iteration 28300 (7.201 iter/s, 13.887s/100 iter), loss = 2.03858
I0801 16:31:41.287778 12219 solver.cpp:375]     Train net output #0: loss = 1.85344 (* 1 = 1.85344 loss)
I0801 16:31:41.287784 12219 sgd_solver.cpp:136] Iteration 28300, lr = 0.0911563, m = 0.9
I0801 16:31:55.168591 12219 solver.cpp:353] Iteration 28400 (7.20436 iter/s, 13.8805s/100 iter), loss = 2.46487
I0801 16:31:55.168615 12219 solver.cpp:375]     Train net output #0: loss = 2.07648 (* 1 = 2.07648 loss)
I0801 16:31:55.168622 12219 sgd_solver.cpp:136] Iteration 28400, lr = 0.091125, m = 0.9
I0801 16:32:09.050285 12219 solver.cpp:353] Iteration 28500 (7.20393 iter/s, 13.8813s/100 iter), loss = 2.4237
I0801 16:32:09.050318 12219 solver.cpp:375]     Train net output #0: loss = 2.30108 (* 1 = 2.30108 loss)
I0801 16:32:09.050323 12219 sgd_solver.cpp:136] Iteration 28500, lr = 0.0910937, m = 0.9
I0801 16:32:22.899572 12219 solver.cpp:353] Iteration 28600 (7.2208 iter/s, 13.8489s/100 iter), loss = 2.4927
I0801 16:32:22.899660 12219 solver.cpp:375]     Train net output #0: loss = 2.29907 (* 1 = 2.29907 loss)
I0801 16:32:22.899668 12219 sgd_solver.cpp:136] Iteration 28600, lr = 0.0910625, m = 0.9
I0801 16:32:36.710587 12219 solver.cpp:353] Iteration 28700 (7.2408 iter/s, 13.8106s/100 iter), loss = 2.46505
I0801 16:32:36.710613 12219 solver.cpp:375]     Train net output #0: loss = 2.67649 (* 1 = 2.67649 loss)
I0801 16:32:36.710616 12219 sgd_solver.cpp:136] Iteration 28700, lr = 0.0910313, m = 0.9
I0801 16:32:50.571815 12219 solver.cpp:353] Iteration 28800 (7.21457 iter/s, 13.8608s/100 iter), loss = 2.72492
I0801 16:32:50.571842 12219 solver.cpp:375]     Train net output #0: loss = 2.82222 (* 1 = 2.82222 loss)
I0801 16:32:50.571846 12219 sgd_solver.cpp:136] Iteration 28800, lr = 0.091, m = 0.9
I0801 16:33:04.478468 12219 solver.cpp:353] Iteration 28900 (7.191 iter/s, 13.9063s/100 iter), loss = 1.90209
I0801 16:33:04.478552 12219 solver.cpp:375]     Train net output #0: loss = 1.8266 (* 1 = 1.8266 loss)
I0801 16:33:04.478559 12219 sgd_solver.cpp:136] Iteration 28900, lr = 0.0909688, m = 0.9
I0801 16:33:18.311872 12219 solver.cpp:353] Iteration 29000 (7.22908 iter/s, 13.833s/100 iter), loss = 2.06956
I0801 16:33:18.311899 12219 solver.cpp:375]     Train net output #0: loss = 2.26744 (* 1 = 2.26744 loss)
I0801 16:33:18.311903 12219 sgd_solver.cpp:136] Iteration 29000, lr = 0.0909375, m = 0.9
I0801 16:33:32.268774 12219 solver.cpp:353] Iteration 29100 (7.16512 iter/s, 13.9565s/100 iter), loss = 2.14137
I0801 16:33:32.268803 12219 solver.cpp:375]     Train net output #0: loss = 1.93213 (* 1 = 1.93213 loss)
I0801 16:33:32.268810 12219 sgd_solver.cpp:136] Iteration 29100, lr = 0.0909063, m = 0.9
I0801 16:33:46.268036 12219 solver.cpp:353] Iteration 29200 (7.14344 iter/s, 13.9989s/100 iter), loss = 2.54655
I0801 16:33:46.268138 12219 solver.cpp:375]     Train net output #0: loss = 2.19757 (* 1 = 2.19757 loss)
I0801 16:33:46.268146 12219 sgd_solver.cpp:136] Iteration 29200, lr = 0.090875, m = 0.9
I0801 16:34:00.285140 12219 solver.cpp:353] Iteration 29300 (7.13434 iter/s, 14.0167s/100 iter), loss = 2.6064
I0801 16:34:00.285164 12219 solver.cpp:375]     Train net output #0: loss = 2.26509 (* 1 = 2.26509 loss)
I0801 16:34:00.285171 12219 sgd_solver.cpp:136] Iteration 29300, lr = 0.0908438, m = 0.9
I0801 16:34:14.245847 12219 solver.cpp:353] Iteration 29400 (7.16316 iter/s, 13.9603s/100 iter), loss = 2.2258
I0801 16:34:14.245874 12219 solver.cpp:375]     Train net output #0: loss = 1.93364 (* 1 = 1.93364 loss)
I0801 16:34:14.245878 12219 sgd_solver.cpp:136] Iteration 29400, lr = 0.0908125, m = 0.9
I0801 16:34:28.219812 12219 solver.cpp:353] Iteration 29500 (7.15636 iter/s, 13.9736s/100 iter), loss = 2.05785
I0801 16:34:28.219900 12219 solver.cpp:375]     Train net output #0: loss = 1.91891 (* 1 = 1.91891 loss)
I0801 16:34:28.219907 12219 sgd_solver.cpp:136] Iteration 29500, lr = 0.0907812, m = 0.9
I0801 16:34:42.147195 12219 solver.cpp:353] Iteration 29600 (7.1803 iter/s, 13.927s/100 iter), loss = 2.00586
I0801 16:34:42.147224 12219 solver.cpp:375]     Train net output #0: loss = 2.46041 (* 1 = 2.46041 loss)
I0801 16:34:42.147228 12219 sgd_solver.cpp:136] Iteration 29600, lr = 0.09075, m = 0.9
I0801 16:34:56.132967 12219 solver.cpp:353] Iteration 29700 (7.15032 iter/s, 13.9854s/100 iter), loss = 2.41335
I0801 16:34:56.132999 12219 solver.cpp:375]     Train net output #0: loss = 1.88937 (* 1 = 1.88937 loss)
I0801 16:34:56.133005 12219 sgd_solver.cpp:136] Iteration 29700, lr = 0.0907188, m = 0.9
I0801 16:35:10.142202 12219 solver.cpp:353] Iteration 29800 (7.13835 iter/s, 14.0088s/100 iter), loss = 2.2672
I0801 16:35:10.142259 12219 solver.cpp:375]     Train net output #0: loss = 2.3058 (* 1 = 2.3058 loss)
I0801 16:35:10.142264 12219 sgd_solver.cpp:136] Iteration 29800, lr = 0.0906875, m = 0.9
I0801 16:35:24.163105 12219 solver.cpp:353] Iteration 29900 (7.13241 iter/s, 14.0205s/100 iter), loss = 2.1492
I0801 16:35:24.163130 12219 solver.cpp:375]     Train net output #0: loss = 2.2223 (* 1 = 2.2223 loss)
I0801 16:35:24.163134 12219 sgd_solver.cpp:136] Iteration 29900, lr = 0.0906563, m = 0.9
I0801 16:35:37.865615 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_30000.caffemodel
I0801 16:35:37.879526 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_30000.solverstate
I0801 16:35:37.885367 12219 solver.cpp:550] Iteration 30000, Testing net (#0)
I0801 16:35:51.107717 12207 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 16:35:57.709441 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.327881
I0801 16:35:57.709465 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.58
I0801 16:35:57.709472 12219 solver.cpp:635]     Test net output #2: loss = 3.2661 (* 1 = 3.2661 loss)
I0801 16:35:57.709523 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8236s
I0801 16:35:57.859145 12219 solver.cpp:353] Iteration 30000 (2.96779 iter/s, 33.6951s/100 iter), loss = 2.40507
I0801 16:35:57.859169 12219 solver.cpp:375]     Train net output #0: loss = 2.60164 (* 1 = 2.60164 loss)
I0801 16:35:57.859174 12219 sgd_solver.cpp:136] Iteration 30000, lr = 0.090625, m = 0.9
I0801 16:36:11.799532 12219 solver.cpp:353] Iteration 30100 (7.1736 iter/s, 13.94s/100 iter), loss = 2.41843
I0801 16:36:11.799561 12219 solver.cpp:375]     Train net output #0: loss = 3.0096 (* 1 = 3.0096 loss)
I0801 16:36:11.799564 12219 sgd_solver.cpp:136] Iteration 30100, lr = 0.0905937, m = 0.9
I0801 16:36:25.736538 12219 solver.cpp:353] Iteration 30200 (7.17534 iter/s, 13.9366s/100 iter), loss = 2.45186
I0801 16:36:25.736613 12219 solver.cpp:375]     Train net output #0: loss = 2.10197 (* 1 = 2.10197 loss)
I0801 16:36:25.736620 12219 sgd_solver.cpp:136] Iteration 30200, lr = 0.0905625, m = 0.9
I0801 16:36:39.631223 12219 solver.cpp:353] Iteration 30300 (7.1972 iter/s, 13.8943s/100 iter), loss = 2.16632
I0801 16:36:39.631249 12219 solver.cpp:375]     Train net output #0: loss = 2.22832 (* 1 = 2.22832 loss)
I0801 16:36:39.631255 12219 sgd_solver.cpp:136] Iteration 30300, lr = 0.0905313, m = 0.9
I0801 16:36:53.567514 12219 solver.cpp:353] Iteration 30400 (7.17571 iter/s, 13.9359s/100 iter), loss = 2.47534
I0801 16:36:53.567540 12219 solver.cpp:375]     Train net output #0: loss = 2.52112 (* 1 = 2.52112 loss)
I0801 16:36:53.567544 12219 sgd_solver.cpp:136] Iteration 30400, lr = 0.0905, m = 0.9
I0801 16:37:07.510620 12219 solver.cpp:353] Iteration 30500 (7.1722 iter/s, 13.9427s/100 iter), loss = 2.21732
I0801 16:37:07.510680 12219 solver.cpp:375]     Train net output #0: loss = 2.22952 (* 1 = 2.22952 loss)
I0801 16:37:07.510687 12219 sgd_solver.cpp:136] Iteration 30500, lr = 0.0904688, m = 0.9
I0801 16:37:21.343963 12219 solver.cpp:353] Iteration 30600 (7.22911 iter/s, 13.833s/100 iter), loss = 2.61427
I0801 16:37:21.343991 12219 solver.cpp:375]     Train net output #0: loss = 2.61155 (* 1 = 2.61155 loss)
I0801 16:37:21.343997 12219 sgd_solver.cpp:136] Iteration 30600, lr = 0.0904375, m = 0.9
I0801 16:37:35.227669 12219 solver.cpp:353] Iteration 30700 (7.20289 iter/s, 13.8833s/100 iter), loss = 2.61212
I0801 16:37:35.227694 12219 solver.cpp:375]     Train net output #0: loss = 2.66732 (* 1 = 2.66732 loss)
I0801 16:37:35.227700 12219 sgd_solver.cpp:136] Iteration 30700, lr = 0.0904063, m = 0.9
I0801 16:37:49.145313 12219 solver.cpp:353] Iteration 30800 (7.18533 iter/s, 13.9173s/100 iter), loss = 2.82477
I0801 16:37:49.145390 12219 solver.cpp:375]     Train net output #0: loss = 3.03836 (* 1 = 3.03836 loss)
I0801 16:37:49.145397 12219 sgd_solver.cpp:136] Iteration 30800, lr = 0.090375, m = 0.9
I0801 16:38:02.979871 12219 solver.cpp:353] Iteration 30900 (7.22848 iter/s, 13.8342s/100 iter), loss = 2.58356
I0801 16:38:02.979897 12219 solver.cpp:375]     Train net output #0: loss = 2.60176 (* 1 = 2.60176 loss)
I0801 16:38:02.979902 12219 sgd_solver.cpp:136] Iteration 30900, lr = 0.0903438, m = 0.9
I0801 16:38:16.855139 12219 solver.cpp:353] Iteration 31000 (7.20727 iter/s, 13.8749s/100 iter), loss = 2.37835
I0801 16:38:16.855167 12219 solver.cpp:375]     Train net output #0: loss = 2.26973 (* 1 = 2.26973 loss)
I0801 16:38:16.855173 12219 sgd_solver.cpp:136] Iteration 31000, lr = 0.0903125, m = 0.9
I0801 16:38:30.698041 12219 solver.cpp:353] Iteration 31100 (7.22412 iter/s, 13.8425s/100 iter), loss = 2.1889
I0801 16:38:30.698138 12219 solver.cpp:375]     Train net output #0: loss = 1.9253 (* 1 = 1.9253 loss)
I0801 16:38:30.698156 12219 sgd_solver.cpp:136] Iteration 31100, lr = 0.0902812, m = 0.9
I0801 16:38:44.558907 12219 solver.cpp:353] Iteration 31200 (7.21476 iter/s, 13.8605s/100 iter), loss = 2.32993
I0801 16:38:44.558934 12219 solver.cpp:375]     Train net output #0: loss = 2.07011 (* 1 = 2.07011 loss)
I0801 16:38:44.558939 12219 sgd_solver.cpp:136] Iteration 31200, lr = 0.09025, m = 0.9
I0801 16:38:58.472681 12219 solver.cpp:353] Iteration 31300 (7.18732 iter/s, 13.9134s/100 iter), loss = 2.51688
I0801 16:38:58.472733 12219 solver.cpp:375]     Train net output #0: loss = 2.42519 (* 1 = 2.42519 loss)
I0801 16:38:58.472746 12219 sgd_solver.cpp:136] Iteration 31300, lr = 0.0902187, m = 0.9
I0801 16:39:12.389986 12219 solver.cpp:353] Iteration 31400 (7.1855 iter/s, 13.9169s/100 iter), loss = 2.23922
I0801 16:39:12.390051 12219 solver.cpp:375]     Train net output #0: loss = 2.17481 (* 1 = 2.17481 loss)
I0801 16:39:12.390058 12219 sgd_solver.cpp:136] Iteration 31400, lr = 0.0901875, m = 0.9
I0801 16:39:26.399731 12219 solver.cpp:353] Iteration 31500 (7.13809 iter/s, 14.0094s/100 iter), loss = 2.6798
I0801 16:39:26.399765 12219 solver.cpp:375]     Train net output #0: loss = 2.82862 (* 1 = 2.82862 loss)
I0801 16:39:26.399770 12219 sgd_solver.cpp:136] Iteration 31500, lr = 0.0901562, m = 0.9
I0801 16:39:40.481581 12219 solver.cpp:353] Iteration 31600 (7.10154 iter/s, 14.0815s/100 iter), loss = 2.04051
I0801 16:39:40.481812 12219 solver.cpp:375]     Train net output #0: loss = 2.14524 (* 1 = 2.14524 loss)
I0801 16:39:40.481921 12219 sgd_solver.cpp:136] Iteration 31600, lr = 0.090125, m = 0.9
I0801 16:39:54.602063 12219 solver.cpp:353] Iteration 31700 (7.08211 iter/s, 14.1201s/100 iter), loss = 2.81963
I0801 16:39:54.602154 12219 solver.cpp:375]     Train net output #0: loss = 2.57216 (* 1 = 2.57216 loss)
I0801 16:39:54.602160 12219 sgd_solver.cpp:136] Iteration 31700, lr = 0.0900938, m = 0.9
I0801 16:40:08.593019 12219 solver.cpp:353] Iteration 31800 (7.14767 iter/s, 13.9906s/100 iter), loss = 2.30853
I0801 16:40:08.593045 12219 solver.cpp:375]     Train net output #0: loss = 2.37315 (* 1 = 2.37315 loss)
I0801 16:40:08.593050 12219 sgd_solver.cpp:136] Iteration 31800, lr = 0.0900625, m = 0.9
I0801 16:40:22.541265 12219 solver.cpp:353] Iteration 31900 (7.16956 iter/s, 13.9479s/100 iter), loss = 2.56076
I0801 16:40:22.541293 12219 solver.cpp:375]     Train net output #0: loss = 2.53539 (* 1 = 2.53539 loss)
I0801 16:40:22.541301 12219 sgd_solver.cpp:136] Iteration 31900, lr = 0.0900313, m = 0.9
I0801 16:40:36.332628 12219 solver.cpp:550] Iteration 32000, Testing net (#0)
I0801 16:40:56.537555 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.324234
I0801 16:40:56.537583 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.577412
I0801 16:40:56.537590 12219 solver.cpp:635]     Test net output #2: loss = 3.27192 (* 1 = 3.27192 loss)
I0801 16:40:56.537675 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2045s
I0801 16:40:56.689155 12219 solver.cpp:353] Iteration 32000 (2.92852 iter/s, 34.1469s/100 iter), loss = 2.54994
I0801 16:40:56.689205 12219 solver.cpp:375]     Train net output #0: loss = 2.15925 (* 1 = 2.15925 loss)
I0801 16:40:56.689218 12219 sgd_solver.cpp:136] Iteration 32000, lr = 0.09, m = 0.9
I0801 16:41:10.587649 12219 solver.cpp:353] Iteration 32100 (7.19523 iter/s, 13.8981s/100 iter), loss = 2.18739
I0801 16:41:10.587709 12219 solver.cpp:375]     Train net output #0: loss = 2.20503 (* 1 = 2.20503 loss)
I0801 16:41:10.587715 12219 sgd_solver.cpp:136] Iteration 32100, lr = 0.0899688, m = 0.9
I0801 16:41:24.477289 12219 solver.cpp:353] Iteration 32200 (7.19981 iter/s, 13.8893s/100 iter), loss = 2.55381
I0801 16:41:24.477315 12219 solver.cpp:375]     Train net output #0: loss = 2.8977 (* 1 = 2.8977 loss)
I0801 16:41:24.477319 12219 sgd_solver.cpp:136] Iteration 32200, lr = 0.0899375, m = 0.9
I0801 16:41:38.463882 12219 solver.cpp:353] Iteration 32300 (7.1499 iter/s, 13.9862s/100 iter), loss = 2.23949
I0801 16:41:38.463951 12219 solver.cpp:375]     Train net output #0: loss = 2.01296 (* 1 = 2.01296 loss)
I0801 16:41:38.463971 12219 sgd_solver.cpp:136] Iteration 32300, lr = 0.0899063, m = 0.9
I0801 16:41:52.316108 12219 solver.cpp:353] Iteration 32400 (7.21926 iter/s, 13.8518s/100 iter), loss = 2.17821
I0801 16:41:52.316171 12219 solver.cpp:375]     Train net output #0: loss = 2.26343 (* 1 = 2.26343 loss)
I0801 16:41:52.316177 12219 sgd_solver.cpp:136] Iteration 32400, lr = 0.089875, m = 0.9
I0801 16:42:06.155006 12219 solver.cpp:353] Iteration 32500 (7.22621 iter/s, 13.8385s/100 iter), loss = 2.25321
I0801 16:42:06.155030 12219 solver.cpp:375]     Train net output #0: loss = 2.39258 (* 1 = 2.39258 loss)
I0801 16:42:06.155035 12219 sgd_solver.cpp:136] Iteration 32500, lr = 0.0898438, m = 0.9
I0801 16:42:19.997072 12219 solver.cpp:353] Iteration 32600 (7.22456 iter/s, 13.8417s/100 iter), loss = 2.48161
I0801 16:42:19.997098 12219 solver.cpp:375]     Train net output #0: loss = 3.03255 (* 1 = 3.03255 loss)
I0801 16:42:19.997103 12219 sgd_solver.cpp:136] Iteration 32600, lr = 0.0898125, m = 0.9
I0801 16:42:33.885484 12219 solver.cpp:353] Iteration 32700 (7.20045 iter/s, 13.888s/100 iter), loss = 2.21251
I0801 16:42:33.885561 12219 solver.cpp:375]     Train net output #0: loss = 2.37227 (* 1 = 2.37227 loss)
I0801 16:42:33.885568 12219 sgd_solver.cpp:136] Iteration 32700, lr = 0.0897812, m = 0.9
I0801 16:42:47.788427 12219 solver.cpp:353] Iteration 32800 (7.19292 iter/s, 13.9026s/100 iter), loss = 1.95107
I0801 16:42:47.788455 12219 solver.cpp:375]     Train net output #0: loss = 2.09088 (* 1 = 2.09088 loss)
I0801 16:42:47.788461 12219 sgd_solver.cpp:136] Iteration 32800, lr = 0.08975, m = 0.9
I0801 16:43:01.732295 12219 solver.cpp:353] Iteration 32900 (7.17181 iter/s, 13.9435s/100 iter), loss = 3.07214
I0801 16:43:01.732318 12219 solver.cpp:375]     Train net output #0: loss = 3.36763 (* 1 = 3.36763 loss)
I0801 16:43:01.732322 12219 sgd_solver.cpp:136] Iteration 32900, lr = 0.0897188, m = 0.9
I0801 16:43:15.603853 12219 solver.cpp:353] Iteration 33000 (7.2092 iter/s, 13.8712s/100 iter), loss = 2.53523
I0801 16:43:15.603911 12219 solver.cpp:375]     Train net output #0: loss = 2.18408 (* 1 = 2.18408 loss)
I0801 16:43:15.603919 12219 sgd_solver.cpp:136] Iteration 33000, lr = 0.0896875, m = 0.9
I0801 16:43:29.471956 12219 solver.cpp:353] Iteration 33100 (7.21099 iter/s, 13.8677s/100 iter), loss = 2.38544
I0801 16:43:29.471984 12219 solver.cpp:375]     Train net output #0: loss = 2.61948 (* 1 = 2.61948 loss)
I0801 16:43:29.471989 12219 sgd_solver.cpp:136] Iteration 33100, lr = 0.0896563, m = 0.9
I0801 16:43:43.345378 12219 solver.cpp:353] Iteration 33200 (7.20823 iter/s, 13.873s/100 iter), loss = 2.27174
I0801 16:43:43.345407 12219 solver.cpp:375]     Train net output #0: loss = 2.25495 (* 1 = 2.25495 loss)
I0801 16:43:43.345414 12219 sgd_solver.cpp:136] Iteration 33200, lr = 0.089625, m = 0.9
I0801 16:43:57.204249 12219 solver.cpp:353] Iteration 33300 (7.2158 iter/s, 13.8585s/100 iter), loss = 2.61115
I0801 16:43:57.204326 12219 solver.cpp:375]     Train net output #0: loss = 2.4692 (* 1 = 2.4692 loss)
I0801 16:43:57.204334 12219 sgd_solver.cpp:136] Iteration 33300, lr = 0.0895938, m = 0.9
I0801 16:44:11.138571 12219 solver.cpp:353] Iteration 33400 (7.17672 iter/s, 13.9339s/100 iter), loss = 2.60112
I0801 16:44:11.138595 12219 solver.cpp:375]     Train net output #0: loss = 2.39118 (* 1 = 2.39118 loss)
I0801 16:44:11.138602 12219 sgd_solver.cpp:136] Iteration 33400, lr = 0.0895625, m = 0.9
I0801 16:44:24.994838 12219 solver.cpp:353] Iteration 33500 (7.21715 iter/s, 13.8559s/100 iter), loss = 2.47492
I0801 16:44:24.994864 12219 solver.cpp:375]     Train net output #0: loss = 2.22064 (* 1 = 2.22064 loss)
I0801 16:44:24.994870 12219 sgd_solver.cpp:136] Iteration 33500, lr = 0.0895313, m = 0.9
I0801 16:44:38.849053 12219 solver.cpp:353] Iteration 33600 (7.21822 iter/s, 13.8538s/100 iter), loss = 2.55688
I0801 16:44:38.849117 12219 solver.cpp:375]     Train net output #0: loss = 2.6634 (* 1 = 2.6634 loss)
I0801 16:44:38.849123 12219 sgd_solver.cpp:136] Iteration 33600, lr = 0.0895, m = 0.9
I0801 16:44:52.718669 12219 solver.cpp:353] Iteration 33700 (7.21021 iter/s, 13.8692s/100 iter), loss = 2.23076
I0801 16:44:52.718698 12219 solver.cpp:375]     Train net output #0: loss = 2.5932 (* 1 = 2.5932 loss)
I0801 16:44:52.718701 12219 sgd_solver.cpp:136] Iteration 33700, lr = 0.0894688, m = 0.9
I0801 16:45:06.629762 12219 solver.cpp:353] Iteration 33800 (7.18871 iter/s, 13.9107s/100 iter), loss = 2.71357
I0801 16:45:06.629818 12219 solver.cpp:375]     Train net output #0: loss = 3.13159 (* 1 = 3.13159 loss)
I0801 16:45:06.629832 12219 sgd_solver.cpp:136] Iteration 33800, lr = 0.0894375, m = 0.9
I0801 16:45:20.501667 12219 solver.cpp:353] Iteration 33900 (7.20902 iter/s, 13.8715s/100 iter), loss = 2.12982
I0801 16:45:20.501734 12219 solver.cpp:375]     Train net output #0: loss = 2.11338 (* 1 = 2.11338 loss)
I0801 16:45:20.501742 12219 sgd_solver.cpp:136] Iteration 33900, lr = 0.0894063, m = 0.9
I0801 16:45:34.249634 12219 solver.cpp:550] Iteration 34000, Testing net (#0)
I0801 16:45:37.376746 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 16:45:53.612787 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.34994
I0801 16:45:53.612915 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.60453
I0801 16:45:53.612923 12219 solver.cpp:635]     Test net output #2: loss = 3.16138 (* 1 = 3.16138 loss)
I0801 16:45:53.612972 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.3628s
I0801 16:45:53.777279 12219 solver.cpp:353] Iteration 34000 (3.00529 iter/s, 33.2747s/100 iter), loss = 2.95859
I0801 16:45:53.777329 12219 solver.cpp:375]     Train net output #0: loss = 2.72414 (* 1 = 2.72414 loss)
I0801 16:45:53.777341 12219 sgd_solver.cpp:136] Iteration 34000, lr = 0.089375, m = 0.9
I0801 16:46:07.717115 12219 solver.cpp:353] Iteration 34100 (7.17389 iter/s, 13.9394s/100 iter), loss = 2.31734
I0801 16:46:07.717140 12219 solver.cpp:375]     Train net output #0: loss = 2.7851 (* 1 = 2.7851 loss)
I0801 16:46:07.717145 12219 sgd_solver.cpp:136] Iteration 34100, lr = 0.0893437, m = 0.9
I0801 16:46:21.650125 12219 solver.cpp:353] Iteration 34200 (7.1774 iter/s, 13.9326s/100 iter), loss = 2.44383
I0801 16:46:21.650177 12219 solver.cpp:375]     Train net output #0: loss = 1.90577 (* 1 = 1.90577 loss)
I0801 16:46:21.650190 12219 sgd_solver.cpp:136] Iteration 34200, lr = 0.0893125, m = 0.9
I0801 16:46:35.588570 12219 solver.cpp:353] Iteration 34300 (7.1746 iter/s, 13.9381s/100 iter), loss = 2.27865
I0801 16:46:35.588654 12219 solver.cpp:375]     Train net output #0: loss = 1.99895 (* 1 = 1.99895 loss)
I0801 16:46:35.588660 12219 sgd_solver.cpp:136] Iteration 34300, lr = 0.0892813, m = 0.9
I0801 16:46:49.504297 12219 solver.cpp:353] Iteration 34400 (7.18631 iter/s, 13.9153s/100 iter), loss = 2.39369
I0801 16:46:49.504320 12219 solver.cpp:375]     Train net output #0: loss = 2.25682 (* 1 = 2.25682 loss)
I0801 16:46:49.504324 12219 sgd_solver.cpp:136] Iteration 34400, lr = 0.08925, m = 0.9
I0801 16:47:03.381135 12219 solver.cpp:353] Iteration 34500 (7.20645 iter/s, 13.8764s/100 iter), loss = 2.19867
I0801 16:47:03.381186 12219 solver.cpp:375]     Train net output #0: loss = 2.40335 (* 1 = 2.40335 loss)
I0801 16:47:03.381199 12219 sgd_solver.cpp:136] Iteration 34500, lr = 0.0892188, m = 0.9
I0801 16:47:17.255388 12219 solver.cpp:353] Iteration 34600 (7.2078 iter/s, 13.8739s/100 iter), loss = 2.17471
I0801 16:47:17.255460 12219 solver.cpp:375]     Train net output #0: loss = 1.96541 (* 1 = 1.96541 loss)
I0801 16:47:17.255466 12219 sgd_solver.cpp:136] Iteration 34600, lr = 0.0891875, m = 0.9
I0801 16:47:31.201449 12219 solver.cpp:353] Iteration 34700 (7.17068 iter/s, 13.9457s/100 iter), loss = 1.93122
I0801 16:47:31.201484 12219 solver.cpp:375]     Train net output #0: loss = 1.9869 (* 1 = 1.9869 loss)
I0801 16:47:31.201489 12219 sgd_solver.cpp:136] Iteration 34700, lr = 0.0891563, m = 0.9
I0801 16:47:45.119339 12219 solver.cpp:353] Iteration 34800 (7.1852 iter/s, 13.9175s/100 iter), loss = 2.18929
I0801 16:47:45.119367 12219 solver.cpp:375]     Train net output #0: loss = 2.63706 (* 1 = 2.63706 loss)
I0801 16:47:45.119371 12219 sgd_solver.cpp:136] Iteration 34800, lr = 0.089125, m = 0.9
I0801 16:47:59.134340 12219 solver.cpp:353] Iteration 34900 (7.13541 iter/s, 14.0146s/100 iter), loss = 2.062
I0801 16:47:59.134444 12219 solver.cpp:375]     Train net output #0: loss = 2.02842 (* 1 = 2.02842 loss)
I0801 16:47:59.134454 12219 sgd_solver.cpp:136] Iteration 34900, lr = 0.0890938, m = 0.9
I0801 16:48:13.139955 12219 solver.cpp:353] Iteration 35000 (7.14019 iter/s, 14.0052s/100 iter), loss = 2.31792
I0801 16:48:13.139977 12219 solver.cpp:375]     Train net output #0: loss = 2.00707 (* 1 = 2.00707 loss)
I0801 16:48:13.139982 12219 sgd_solver.cpp:136] Iteration 35000, lr = 0.0890625, m = 0.9
I0801 16:48:27.121022 12219 solver.cpp:353] Iteration 35100 (7.15273 iter/s, 13.9807s/100 iter), loss = 2.14085
I0801 16:48:27.121060 12219 solver.cpp:375]     Train net output #0: loss = 2.88583 (* 1 = 2.88583 loss)
I0801 16:48:27.121067 12219 sgd_solver.cpp:136] Iteration 35100, lr = 0.0890312, m = 0.9
I0801 16:48:41.033233 12219 solver.cpp:353] Iteration 35200 (7.18813 iter/s, 13.9118s/100 iter), loss = 2.26684
I0801 16:48:41.033298 12219 solver.cpp:375]     Train net output #0: loss = 2.3441 (* 1 = 2.3441 loss)
I0801 16:48:41.033304 12219 sgd_solver.cpp:136] Iteration 35200, lr = 0.089, m = 0.9
I0801 16:48:55.048449 12219 solver.cpp:353] Iteration 35300 (7.1353 iter/s, 14.0148s/100 iter), loss = 2.5524
I0801 16:48:55.048491 12219 solver.cpp:375]     Train net output #0: loss = 1.8234 (* 1 = 1.8234 loss)
I0801 16:48:55.048499 12219 sgd_solver.cpp:136] Iteration 35300, lr = 0.0889687, m = 0.9
I0801 16:49:09.077697 12219 solver.cpp:353] Iteration 35400 (7.12816 iter/s, 14.0289s/100 iter), loss = 2.10337
I0801 16:49:09.077728 12219 solver.cpp:375]     Train net output #0: loss = 1.95638 (* 1 = 1.95638 loss)
I0801 16:49:09.077733 12219 sgd_solver.cpp:136] Iteration 35400, lr = 0.0889375, m = 0.9
I0801 16:49:23.008085 12219 solver.cpp:353] Iteration 35500 (7.17875 iter/s, 13.93s/100 iter), loss = 2.43322
I0801 16:49:23.008201 12219 solver.cpp:375]     Train net output #0: loss = 2.34239 (* 1 = 2.34239 loss)
I0801 16:49:23.008213 12219 sgd_solver.cpp:136] Iteration 35500, lr = 0.0889063, m = 0.9
I0801 16:49:36.969139 12219 solver.cpp:353] Iteration 35600 (7.16298 iter/s, 13.9607s/100 iter), loss = 2.66055
I0801 16:49:36.969168 12219 solver.cpp:375]     Train net output #0: loss = 2.8248 (* 1 = 2.8248 loss)
I0801 16:49:36.969175 12219 sgd_solver.cpp:136] Iteration 35600, lr = 0.088875, m = 0.9
I0801 16:49:50.912720 12219 solver.cpp:353] Iteration 35700 (7.17196 iter/s, 13.9432s/100 iter), loss = 2.31362
I0801 16:49:50.912746 12219 solver.cpp:375]     Train net output #0: loss = 1.81227 (* 1 = 1.81227 loss)
I0801 16:49:50.912752 12219 sgd_solver.cpp:136] Iteration 35700, lr = 0.0888438, m = 0.9
I0801 16:50:04.866788 12219 solver.cpp:353] Iteration 35800 (7.16657 iter/s, 13.9537s/100 iter), loss = 2.18226
I0801 16:50:04.866878 12219 solver.cpp:375]     Train net output #0: loss = 2.43038 (* 1 = 2.43038 loss)
I0801 16:50:04.866896 12219 sgd_solver.cpp:136] Iteration 35800, lr = 0.0888125, m = 0.9
I0801 16:50:18.836859 12219 solver.cpp:353] Iteration 35900 (7.15836 iter/s, 13.9697s/100 iter), loss = 2.26048
I0801 16:50:18.836913 12219 solver.cpp:375]     Train net output #0: loss = 2.22439 (* 1 = 2.22439 loss)
I0801 16:50:18.836926 12219 sgd_solver.cpp:136] Iteration 35900, lr = 0.0887813, m = 0.9
I0801 16:50:32.663486 12219 solver.cpp:550] Iteration 36000, Testing net (#0)
I0801 16:50:52.532779 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.345411
I0801 16:50:52.532882 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.598705
I0801 16:50:52.532891 12219 solver.cpp:635]     Test net output #2: loss = 3.18027 (* 1 = 3.18027 loss)
I0801 16:50:52.532910 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8689s
I0801 16:50:52.675043 12219 solver.cpp:353] Iteration 36000 (2.95532 iter/s, 33.8372s/100 iter), loss = 2.62431
I0801 16:50:52.675068 12219 solver.cpp:375]     Train net output #0: loss = 2.54052 (* 1 = 2.54052 loss)
I0801 16:50:52.675072 12219 sgd_solver.cpp:136] Iteration 36000, lr = 0.08875, m = 0.9
I0801 16:51:06.629039 12219 solver.cpp:353] Iteration 36100 (7.16661 iter/s, 13.9536s/100 iter), loss = 2.22706
I0801 16:51:06.629066 12219 solver.cpp:375]     Train net output #0: loss = 2.27571 (* 1 = 2.27571 loss)
I0801 16:51:06.629072 12219 sgd_solver.cpp:136] Iteration 36100, lr = 0.0887187, m = 0.9
I0801 16:51:20.520568 12219 solver.cpp:353] Iteration 36200 (7.19883 iter/s, 13.8911s/100 iter), loss = 2.90618
I0801 16:51:20.520597 12219 solver.cpp:375]     Train net output #0: loss = 2.75256 (* 1 = 2.75256 loss)
I0801 16:51:20.520603 12219 sgd_solver.cpp:136] Iteration 36200, lr = 0.0886875, m = 0.9
I0801 16:51:34.468904 12219 solver.cpp:353] Iteration 36300 (7.16952 iter/s, 13.9479s/100 iter), loss = 2.19115
I0801 16:51:34.468977 12219 solver.cpp:375]     Train net output #0: loss = 2.23071 (* 1 = 2.23071 loss)
I0801 16:51:34.468983 12219 sgd_solver.cpp:136] Iteration 36300, lr = 0.0886562, m = 0.9
I0801 16:51:48.582036 12219 solver.cpp:353] Iteration 36400 (7.0858 iter/s, 14.1127s/100 iter), loss = 2.29673
I0801 16:51:48.582063 12219 solver.cpp:375]     Train net output #0: loss = 2.62256 (* 1 = 2.62256 loss)
I0801 16:51:48.582070 12219 sgd_solver.cpp:136] Iteration 36400, lr = 0.088625, m = 0.9
I0801 16:52:02.578796 12219 solver.cpp:353] Iteration 36500 (7.14471 iter/s, 13.9964s/100 iter), loss = 2.32672
I0801 16:52:02.578826 12219 solver.cpp:375]     Train net output #0: loss = 2.34597 (* 1 = 2.34597 loss)
I0801 16:52:02.578831 12219 sgd_solver.cpp:136] Iteration 36500, lr = 0.0885938, m = 0.9
I0801 16:52:16.590934 12219 solver.cpp:353] Iteration 36600 (7.13687 iter/s, 14.0117s/100 iter), loss = 2.1797
I0801 16:52:16.591001 12219 solver.cpp:375]     Train net output #0: loss = 1.95642 (* 1 = 1.95642 loss)
I0801 16:52:16.591007 12219 sgd_solver.cpp:136] Iteration 36600, lr = 0.0885625, m = 0.9
I0801 16:52:30.605146 12219 solver.cpp:353] Iteration 36700 (7.13581 iter/s, 14.0138s/100 iter), loss = 2.33545
I0801 16:52:30.605175 12219 solver.cpp:375]     Train net output #0: loss = 1.87377 (* 1 = 1.87377 loss)
I0801 16:52:30.605180 12219 sgd_solver.cpp:136] Iteration 36700, lr = 0.0885312, m = 0.9
I0801 16:52:44.654006 12219 solver.cpp:353] Iteration 36800 (7.11821 iter/s, 14.0485s/100 iter), loss = 1.90332
I0801 16:52:44.654031 12219 solver.cpp:375]     Train net output #0: loss = 2.22938 (* 1 = 2.22938 loss)
I0801 16:52:44.654036 12219 sgd_solver.cpp:136] Iteration 36800, lr = 0.0885, m = 0.9
I0801 16:52:58.638150 12219 solver.cpp:353] Iteration 36900 (7.15115 iter/s, 13.9838s/100 iter), loss = 2.41436
I0801 16:52:58.638273 12219 solver.cpp:375]     Train net output #0: loss = 2.58195 (* 1 = 2.58195 loss)
I0801 16:52:58.638279 12219 sgd_solver.cpp:136] Iteration 36900, lr = 0.0884688, m = 0.9
I0801 16:53:12.714557 12219 solver.cpp:353] Iteration 37000 (7.10429 iter/s, 14.076s/100 iter), loss = 2.21016
I0801 16:53:12.714609 12219 solver.cpp:375]     Train net output #0: loss = 1.61504 (* 1 = 1.61504 loss)
I0801 16:53:12.714622 12219 sgd_solver.cpp:136] Iteration 37000, lr = 0.0884375, m = 0.9
I0801 16:53:26.722098 12219 solver.cpp:353] Iteration 37100 (7.13921 iter/s, 14.0071s/100 iter), loss = 1.94125
I0801 16:53:26.722151 12219 solver.cpp:375]     Train net output #0: loss = 1.59539 (* 1 = 1.59539 loss)
I0801 16:53:26.722164 12219 sgd_solver.cpp:136] Iteration 37100, lr = 0.0884063, m = 0.9
I0801 16:53:40.741432 12219 solver.cpp:353] Iteration 37200 (7.1332 iter/s, 14.0189s/100 iter), loss = 2.56018
I0801 16:53:40.741500 12219 solver.cpp:375]     Train net output #0: loss = 2.5797 (* 1 = 2.5797 loss)
I0801 16:53:40.741506 12219 sgd_solver.cpp:136] Iteration 37200, lr = 0.088375, m = 0.9
I0801 16:53:54.743391 12219 solver.cpp:353] Iteration 37300 (7.14206 iter/s, 14.0016s/100 iter), loss = 2.4123
I0801 16:53:54.743417 12219 solver.cpp:375]     Train net output #0: loss = 2.45578 (* 1 = 2.45578 loss)
I0801 16:53:54.743422 12219 sgd_solver.cpp:136] Iteration 37300, lr = 0.0883438, m = 0.9
I0801 16:54:08.826925 12219 solver.cpp:353] Iteration 37400 (7.10069 iter/s, 14.0831s/100 iter), loss = 2.66211
I0801 16:54:08.826985 12219 solver.cpp:375]     Train net output #0: loss = 2.70283 (* 1 = 2.70283 loss)
I0801 16:54:08.827003 12219 sgd_solver.cpp:136] Iteration 37400, lr = 0.0883125, m = 0.9
I0801 16:54:22.845752 12219 solver.cpp:353] Iteration 37500 (7.13346 iter/s, 14.0184s/100 iter), loss = 2.55529
I0801 16:54:22.845875 12219 solver.cpp:375]     Train net output #0: loss = 2.99041 (* 1 = 2.99041 loss)
I0801 16:54:22.845882 12219 sgd_solver.cpp:136] Iteration 37500, lr = 0.0882813, m = 0.9
I0801 16:54:36.860517 12219 solver.cpp:353] Iteration 37600 (7.13553 iter/s, 14.0144s/100 iter), loss = 2.38303
I0801 16:54:36.860545 12219 solver.cpp:375]     Train net output #0: loss = 2.61183 (* 1 = 2.61183 loss)
I0801 16:54:36.860551 12219 sgd_solver.cpp:136] Iteration 37600, lr = 0.08825, m = 0.9
I0801 16:54:51.017055 12219 solver.cpp:353] Iteration 37700 (7.06407 iter/s, 14.1561s/100 iter), loss = 2.62779
I0801 16:54:51.017084 12219 solver.cpp:375]     Train net output #0: loss = 2.47655 (* 1 = 2.47655 loss)
I0801 16:54:51.017122 12219 sgd_solver.cpp:136] Iteration 37700, lr = 0.0882187, m = 0.9
I0801 16:55:05.014206 12219 solver.cpp:353] Iteration 37800 (7.14451 iter/s, 13.9968s/100 iter), loss = 2.45353
I0801 16:55:05.014278 12219 solver.cpp:375]     Train net output #0: loss = 2.03031 (* 1 = 2.03031 loss)
I0801 16:55:05.014286 12219 sgd_solver.cpp:136] Iteration 37800, lr = 0.0881875, m = 0.9
I0801 16:55:19.130825 12219 solver.cpp:353] Iteration 37900 (7.08405 iter/s, 14.1162s/100 iter), loss = 2.44228
I0801 16:55:19.130848 12219 solver.cpp:375]     Train net output #0: loss = 2.9422 (* 1 = 2.9422 loss)
I0801 16:55:19.130853 12219 sgd_solver.cpp:136] Iteration 37900, lr = 0.0881562, m = 0.9
I0801 16:55:33.023859 12219 solver.cpp:550] Iteration 38000, Testing net (#0)
I0801 16:55:53.443500 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.377058
I0801 16:55:53.443563 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.630117
I0801 16:55:53.443572 12219 solver.cpp:635]     Test net output #2: loss = 2.90708 (* 1 = 2.90708 loss)
I0801 16:55:53.443594 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4192s
I0801 16:55:53.620684 12219 solver.cpp:353] Iteration 38000 (2.89948 iter/s, 34.4889s/100 iter), loss = 2.18468
I0801 16:55:53.620712 12219 solver.cpp:375]     Train net output #0: loss = 2.35984 (* 1 = 2.35984 loss)
I0801 16:55:53.620718 12219 sgd_solver.cpp:136] Iteration 38000, lr = 0.088125, m = 0.9
I0801 16:56:07.704345 12219 solver.cpp:353] Iteration 38100 (7.10063 iter/s, 14.0833s/100 iter), loss = 2.44004
I0801 16:56:07.704371 12219 solver.cpp:375]     Train net output #0: loss = 2.71094 (* 1 = 2.71094 loss)
I0801 16:56:07.704376 12219 sgd_solver.cpp:136] Iteration 38100, lr = 0.0880938, m = 0.9
I0801 16:56:21.894099 12219 solver.cpp:353] Iteration 38200 (7.04754 iter/s, 14.1893s/100 iter), loss = 2.17457
I0801 16:56:21.894127 12219 solver.cpp:375]     Train net output #0: loss = 2.55898 (* 1 = 2.55898 loss)
I0801 16:56:21.894131 12219 sgd_solver.cpp:136] Iteration 38200, lr = 0.0880625, m = 0.9
I0801 16:56:35.878018 12219 solver.cpp:353] Iteration 38300 (7.15127 iter/s, 13.9835s/100 iter), loss = 2.41527
I0801 16:56:35.878110 12219 solver.cpp:375]     Train net output #0: loss = 2.4272 (* 1 = 2.4272 loss)
I0801 16:56:35.878123 12219 sgd_solver.cpp:136] Iteration 38300, lr = 0.0880313, m = 0.9
I0801 16:56:49.847661 12219 solver.cpp:353] Iteration 38400 (7.15858 iter/s, 13.9693s/100 iter), loss = 2.11664
I0801 16:56:49.847687 12219 solver.cpp:375]     Train net output #0: loss = 2.226 (* 1 = 2.226 loss)
I0801 16:56:49.847693 12219 sgd_solver.cpp:136] Iteration 38400, lr = 0.088, m = 0.9
I0801 16:57:03.937324 12219 solver.cpp:353] Iteration 38500 (7.0976 iter/s, 14.0893s/100 iter), loss = 2.25835
I0801 16:57:03.937352 12219 solver.cpp:375]     Train net output #0: loss = 2.20744 (* 1 = 2.20744 loss)
I0801 16:57:03.937358 12219 sgd_solver.cpp:136] Iteration 38500, lr = 0.0879688, m = 0.9
I0801 16:57:18.084944 12219 solver.cpp:353] Iteration 38600 (7.06853 iter/s, 14.1472s/100 iter), loss = 2.14848
I0801 16:57:18.085054 12219 solver.cpp:375]     Train net output #0: loss = 1.96719 (* 1 = 1.96719 loss)
I0801 16:57:18.085063 12219 sgd_solver.cpp:136] Iteration 38600, lr = 0.0879375, m = 0.9
I0801 16:57:32.209846 12219 solver.cpp:353] Iteration 38700 (7.07989 iter/s, 14.1245s/100 iter), loss = 1.83156
I0801 16:57:32.209872 12219 solver.cpp:375]     Train net output #0: loss = 1.83943 (* 1 = 1.83943 loss)
I0801 16:57:32.209877 12219 sgd_solver.cpp:136] Iteration 38700, lr = 0.0879063, m = 0.9
I0801 16:57:46.389111 12219 solver.cpp:353] Iteration 38800 (7.05275 iter/s, 14.1789s/100 iter), loss = 2.1626
I0801 16:57:46.389135 12219 solver.cpp:375]     Train net output #0: loss = 2.28092 (* 1 = 2.28092 loss)
I0801 16:57:46.389139 12219 sgd_solver.cpp:136] Iteration 38800, lr = 0.087875, m = 0.9
I0801 16:58:00.333333 12219 solver.cpp:353] Iteration 38900 (7.17163 iter/s, 13.9438s/100 iter), loss = 2.6692
I0801 16:58:00.333401 12219 solver.cpp:375]     Train net output #0: loss = 2.56926 (* 1 = 2.56926 loss)
I0801 16:58:00.333408 12219 sgd_solver.cpp:136] Iteration 38900, lr = 0.0878438, m = 0.9
I0801 16:58:14.287118 12219 solver.cpp:353] Iteration 39000 (7.16672 iter/s, 13.9534s/100 iter), loss = 2.22602
I0801 16:58:14.287151 12219 solver.cpp:375]     Train net output #0: loss = 2.18304 (* 1 = 2.18304 loss)
I0801 16:58:14.287158 12219 sgd_solver.cpp:136] Iteration 39000, lr = 0.0878125, m = 0.9
I0801 16:58:28.318403 12219 solver.cpp:353] Iteration 39100 (7.12713 iter/s, 14.0309s/100 iter), loss = 2.54285
I0801 16:58:28.318433 12219 solver.cpp:375]     Train net output #0: loss = 2.59652 (* 1 = 2.59652 loss)
I0801 16:58:28.318439 12219 sgd_solver.cpp:136] Iteration 39100, lr = 0.0877813, m = 0.9
I0801 16:58:42.274883 12219 solver.cpp:353] Iteration 39200 (7.16534 iter/s, 13.9561s/100 iter), loss = 2.12296
I0801 16:58:42.274960 12219 solver.cpp:375]     Train net output #0: loss = 1.92896 (* 1 = 1.92896 loss)
I0801 16:58:42.274967 12219 sgd_solver.cpp:136] Iteration 39200, lr = 0.08775, m = 0.9
I0801 16:58:56.306915 12219 solver.cpp:353] Iteration 39300 (7.12675 iter/s, 14.0316s/100 iter), loss = 2.65249
I0801 16:58:56.306943 12219 solver.cpp:375]     Train net output #0: loss = 2.64147 (* 1 = 2.64147 loss)
I0801 16:58:56.306949 12219 sgd_solver.cpp:136] Iteration 39300, lr = 0.0877187, m = 0.9
I0801 16:59:10.226570 12219 solver.cpp:353] Iteration 39400 (7.18429 iter/s, 13.9193s/100 iter), loss = 2.19729
I0801 16:59:10.226598 12219 solver.cpp:375]     Train net output #0: loss = 2.23591 (* 1 = 2.23591 loss)
I0801 16:59:10.226603 12219 sgd_solver.cpp:136] Iteration 39400, lr = 0.0876875, m = 0.9
I0801 16:59:24.333405 12219 solver.cpp:353] Iteration 39500 (7.08896 iter/s, 14.1064s/100 iter), loss = 2.0859
I0801 16:59:24.333484 12219 solver.cpp:375]     Train net output #0: loss = 2.04193 (* 1 = 2.04193 loss)
I0801 16:59:24.333490 12219 sgd_solver.cpp:136] Iteration 39500, lr = 0.0876563, m = 0.9
I0801 16:59:38.248387 12219 solver.cpp:353] Iteration 39600 (7.1867 iter/s, 13.9146s/100 iter), loss = 2.10941
I0801 16:59:38.248410 12219 solver.cpp:375]     Train net output #0: loss = 2.1604 (* 1 = 2.1604 loss)
I0801 16:59:38.248415 12219 sgd_solver.cpp:136] Iteration 39600, lr = 0.087625, m = 0.9
I0801 16:59:52.168735 12219 solver.cpp:353] Iteration 39700 (7.18394 iter/s, 13.9199s/100 iter), loss = 2.29663
I0801 16:59:52.168762 12219 solver.cpp:375]     Train net output #0: loss = 2.18372 (* 1 = 2.18372 loss)
I0801 16:59:52.168766 12219 sgd_solver.cpp:136] Iteration 39700, lr = 0.0875938, m = 0.9
I0801 17:00:06.048842 12219 solver.cpp:353] Iteration 39800 (7.20476 iter/s, 13.8797s/100 iter), loss = 2.3368
I0801 17:00:06.048894 12219 solver.cpp:375]     Train net output #0: loss = 2.16033 (* 1 = 2.16033 loss)
I0801 17:00:06.048899 12219 sgd_solver.cpp:136] Iteration 39800, lr = 0.0875625, m = 0.9
I0801 17:00:20.016199 12219 solver.cpp:353] Iteration 39900 (7.15975 iter/s, 13.967s/100 iter), loss = 2.31348
I0801 17:00:20.016276 12219 solver.cpp:375]     Train net output #0: loss = 2.38995 (* 1 = 2.38995 loss)
I0801 17:00:20.016297 12219 sgd_solver.cpp:136] Iteration 39900, lr = 0.0875313, m = 0.9
I0801 17:00:33.911804 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_40000.caffemodel
I0801 17:00:33.991869 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_40000.solverstate
I0801 17:00:33.997937 12219 solver.cpp:550] Iteration 40000, Testing net (#0)
I0801 17:00:39.667877 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 17:00:53.296248 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.359352
I0801 17:00:53.296272 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.611588
I0801 17:00:53.296278 12219 solver.cpp:635]     Test net output #2: loss = 3.02863 (* 1 = 3.02863 loss)
I0801 17:00:53.296301 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.2978s
I0801 17:00:53.440989 12219 solver.cpp:353] Iteration 40000 (2.99188 iter/s, 33.4239s/100 iter), loss = 2.62937
I0801 17:00:53.441040 12219 solver.cpp:375]     Train net output #0: loss = 2.45634 (* 1 = 2.45634 loss)
I0801 17:00:53.441061 12219 sgd_solver.cpp:136] Iteration 40000, lr = 0.0875, m = 0.9
I0801 17:01:07.352382 12219 solver.cpp:353] Iteration 40100 (7.18855 iter/s, 13.911s/100 iter), loss = 2.61754
I0801 17:01:07.352407 12219 solver.cpp:375]     Train net output #0: loss = 2.26528 (* 1 = 2.26528 loss)
I0801 17:01:07.352413 12219 sgd_solver.cpp:136] Iteration 40100, lr = 0.0874688, m = 0.9
I0801 17:01:21.240690 12219 solver.cpp:353] Iteration 40200 (7.2005 iter/s, 13.8879s/100 iter), loss = 2.08353
I0801 17:01:21.240792 12219 solver.cpp:375]     Train net output #0: loss = 1.81391 (* 1 = 1.81391 loss)
I0801 17:01:21.240804 12219 sgd_solver.cpp:136] Iteration 40200, lr = 0.0874375, m = 0.9
I0801 17:01:35.153111 12219 solver.cpp:353] Iteration 40300 (7.18802 iter/s, 13.912s/100 iter), loss = 2.31892
I0801 17:01:35.153141 12219 solver.cpp:375]     Train net output #0: loss = 2.51736 (* 1 = 2.51736 loss)
I0801 17:01:35.153146 12219 sgd_solver.cpp:136] Iteration 40300, lr = 0.0874062, m = 0.9
I0801 17:01:49.066418 12219 solver.cpp:353] Iteration 40400 (7.18756 iter/s, 13.9129s/100 iter), loss = 1.96873
I0801 17:01:49.066442 12219 solver.cpp:375]     Train net output #0: loss = 1.87016 (* 1 = 1.87016 loss)
I0801 17:01:49.066447 12219 sgd_solver.cpp:136] Iteration 40400, lr = 0.087375, m = 0.9
I0801 17:02:02.934705 12219 solver.cpp:353] Iteration 40500 (7.2109 iter/s, 13.8679s/100 iter), loss = 2.4766
I0801 17:02:02.934765 12219 solver.cpp:375]     Train net output #0: loss = 2.56721 (* 1 = 2.56721 loss)
I0801 17:02:02.934772 12219 sgd_solver.cpp:136] Iteration 40500, lr = 0.0873438, m = 0.9
I0801 17:02:16.849651 12219 solver.cpp:353] Iteration 40600 (7.18672 iter/s, 13.9146s/100 iter), loss = 2.36177
I0801 17:02:16.849675 12219 solver.cpp:375]     Train net output #0: loss = 2.39137 (* 1 = 2.39137 loss)
I0801 17:02:16.849679 12219 sgd_solver.cpp:136] Iteration 40600, lr = 0.0873125, m = 0.9
I0801 17:02:30.772658 12219 solver.cpp:353] Iteration 40700 (7.18256 iter/s, 13.9226s/100 iter), loss = 1.74077
I0801 17:02:30.772696 12219 solver.cpp:375]     Train net output #0: loss = 1.54277 (* 1 = 1.54277 loss)
I0801 17:02:30.772704 12219 sgd_solver.cpp:136] Iteration 40700, lr = 0.0872812, m = 0.9
I0801 17:02:44.731401 12219 solver.cpp:353] Iteration 40800 (7.16417 iter/s, 13.9584s/100 iter), loss = 2.38585
I0801 17:02:44.731478 12219 solver.cpp:375]     Train net output #0: loss = 2.34842 (* 1 = 2.34842 loss)
I0801 17:02:44.731485 12219 sgd_solver.cpp:136] Iteration 40800, lr = 0.08725, m = 0.9
I0801 17:02:58.581307 12219 solver.cpp:353] Iteration 40900 (7.22047 iter/s, 13.8495s/100 iter), loss = 2.2131
I0801 17:02:58.581336 12219 solver.cpp:375]     Train net output #0: loss = 2.03144 (* 1 = 2.03144 loss)
I0801 17:02:58.581341 12219 sgd_solver.cpp:136] Iteration 40900, lr = 0.0872188, m = 0.9
I0801 17:03:12.532609 12219 solver.cpp:353] Iteration 41000 (7.16799 iter/s, 13.9509s/100 iter), loss = 1.92245
I0801 17:03:12.532637 12219 solver.cpp:375]     Train net output #0: loss = 2.11555 (* 1 = 2.11555 loss)
I0801 17:03:12.532644 12219 sgd_solver.cpp:136] Iteration 41000, lr = 0.0871875, m = 0.9
I0801 17:03:26.367848 12219 solver.cpp:353] Iteration 41100 (7.22812 iter/s, 13.8349s/100 iter), loss = 2.59401
I0801 17:03:26.367933 12219 solver.cpp:375]     Train net output #0: loss = 2.49164 (* 1 = 2.49164 loss)
I0801 17:03:26.367945 12219 sgd_solver.cpp:136] Iteration 41100, lr = 0.0871563, m = 0.9
I0801 17:03:40.270212 12219 solver.cpp:353] Iteration 41200 (7.19322 iter/s, 13.902s/100 iter), loss = 2.59143
I0801 17:03:40.270237 12219 solver.cpp:375]     Train net output #0: loss = 2.53496 (* 1 = 2.53496 loss)
I0801 17:03:40.270241 12219 sgd_solver.cpp:136] Iteration 41200, lr = 0.087125, m = 0.9
I0801 17:03:54.181442 12219 solver.cpp:353] Iteration 41300 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.8899
I0801 17:03:54.181493 12219 solver.cpp:375]     Train net output #0: loss = 1.93682 (* 1 = 1.93682 loss)
I0801 17:03:54.181505 12219 sgd_solver.cpp:136] Iteration 41300, lr = 0.0870937, m = 0.9
I0801 17:04:08.122187 12219 solver.cpp:353] Iteration 41400 (7.17342 iter/s, 13.9404s/100 iter), loss = 2.42646
I0801 17:04:08.122261 12219 solver.cpp:375]     Train net output #0: loss = 2.18126 (* 1 = 2.18126 loss)
I0801 17:04:08.122267 12219 sgd_solver.cpp:136] Iteration 41400, lr = 0.0870625, m = 0.9
I0801 17:04:21.994707 12219 solver.cpp:353] Iteration 41500 (7.20869 iter/s, 13.8721s/100 iter), loss = 2.36973
I0801 17:04:21.994735 12219 solver.cpp:375]     Train net output #0: loss = 2.27916 (* 1 = 2.27916 loss)
I0801 17:04:21.994740 12219 sgd_solver.cpp:136] Iteration 41500, lr = 0.0870313, m = 0.9
I0801 17:04:35.889359 12219 solver.cpp:353] Iteration 41600 (7.19722 iter/s, 13.8943s/100 iter), loss = 2.21926
I0801 17:04:35.889462 12219 solver.cpp:375]     Train net output #0: loss = 1.77963 (* 1 = 1.77963 loss)
I0801 17:04:35.889480 12219 sgd_solver.cpp:136] Iteration 41600, lr = 0.087, m = 0.9
I0801 17:04:49.859483 12219 solver.cpp:353] Iteration 41700 (7.15833 iter/s, 13.9697s/100 iter), loss = 2.12889
I0801 17:04:49.859536 12219 solver.cpp:375]     Train net output #0: loss = 2.11871 (* 1 = 2.11871 loss)
I0801 17:04:49.859541 12219 sgd_solver.cpp:136] Iteration 41700, lr = 0.0869687, m = 0.9
I0801 17:05:03.792294 12219 solver.cpp:353] Iteration 41800 (7.1775 iter/s, 13.9324s/100 iter), loss = 2.22233
I0801 17:05:03.792390 12219 solver.cpp:375]     Train net output #0: loss = 1.8581 (* 1 = 1.8581 loss)
I0801 17:05:03.792412 12219 sgd_solver.cpp:136] Iteration 41800, lr = 0.0869375, m = 0.9
I0801 17:05:17.731320 12219 solver.cpp:353] Iteration 41900 (7.1743 iter/s, 13.9386s/100 iter), loss = 3.12348
I0801 17:05:17.731349 12219 solver.cpp:375]     Train net output #0: loss = 3.45988 (* 1 = 3.45988 loss)
I0801 17:05:17.731355 12219 sgd_solver.cpp:136] Iteration 41900, lr = 0.0869062, m = 0.9
I0801 17:05:31.441246 12219 solver.cpp:550] Iteration 42000, Testing net (#0)
I0801 17:05:50.726840 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.360117
I0801 17:05:50.726858 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.611411
I0801 17:05:50.726863 12219 solver.cpp:635]     Test net output #2: loss = 3.08359 (* 1 = 3.08359 loss)
I0801 17:05:50.726881 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.2851s
I0801 17:05:50.864248 12219 solver.cpp:353] Iteration 42000 (3.01823 iter/s, 33.132s/100 iter), loss = 2.18666
I0801 17:05:50.864274 12219 solver.cpp:375]     Train net output #0: loss = 2.03514 (* 1 = 2.03514 loss)
I0801 17:05:50.864279 12219 sgd_solver.cpp:136] Iteration 42000, lr = 0.086875, m = 0.9
I0801 17:06:04.744866 12219 solver.cpp:353] Iteration 42100 (7.20449 iter/s, 13.8802s/100 iter), loss = 1.88014
I0801 17:06:04.744928 12219 solver.cpp:375]     Train net output #0: loss = 2.18377 (* 1 = 2.18377 loss)
I0801 17:06:04.744935 12219 sgd_solver.cpp:136] Iteration 42100, lr = 0.0868438, m = 0.9
I0801 17:06:18.760092 12219 solver.cpp:353] Iteration 42200 (7.1353 iter/s, 14.0148s/100 iter), loss = 2.58009
I0801 17:06:18.760120 12219 solver.cpp:375]     Train net output #0: loss = 2.52639 (* 1 = 2.52639 loss)
I0801 17:06:18.760124 12219 sgd_solver.cpp:136] Iteration 42200, lr = 0.0868125, m = 0.9
I0801 17:06:32.822705 12219 solver.cpp:353] Iteration 42300 (7.11125 iter/s, 14.0622s/100 iter), loss = 1.80911
I0801 17:06:32.822732 12219 solver.cpp:375]     Train net output #0: loss = 1.71989 (* 1 = 1.71989 loss)
I0801 17:06:32.822736 12219 sgd_solver.cpp:136] Iteration 42300, lr = 0.0867813, m = 0.9
I0801 17:06:46.878303 12219 solver.cpp:353] Iteration 42400 (7.1148 iter/s, 14.0552s/100 iter), loss = 2.63398
I0801 17:06:46.878360 12219 solver.cpp:375]     Train net output #0: loss = 2.51847 (* 1 = 2.51847 loss)
I0801 17:06:46.878367 12219 sgd_solver.cpp:136] Iteration 42400, lr = 0.08675, m = 0.9
I0801 17:07:00.932580 12219 solver.cpp:353] Iteration 42500 (7.11547 iter/s, 14.0539s/100 iter), loss = 2.00076
I0801 17:07:00.932611 12219 solver.cpp:375]     Train net output #0: loss = 1.76904 (* 1 = 1.76904 loss)
I0801 17:07:00.932617 12219 sgd_solver.cpp:136] Iteration 42500, lr = 0.0867188, m = 0.9
I0801 17:07:14.967142 12219 solver.cpp:353] Iteration 42600 (7.12546 iter/s, 14.0342s/100 iter), loss = 2.27971
I0801 17:07:14.967170 12219 solver.cpp:375]     Train net output #0: loss = 2.18563 (* 1 = 2.18563 loss)
I0801 17:07:14.967175 12219 sgd_solver.cpp:136] Iteration 42600, lr = 0.0866875, m = 0.9
I0801 17:07:28.905275 12219 solver.cpp:353] Iteration 42700 (7.17476 iter/s, 13.9377s/100 iter), loss = 2.44005
I0801 17:07:28.905344 12219 solver.cpp:375]     Train net output #0: loss = 2.70841 (* 1 = 2.70841 loss)
I0801 17:07:28.905350 12219 sgd_solver.cpp:136] Iteration 42700, lr = 0.0866563, m = 0.9
I0801 17:07:42.937011 12219 solver.cpp:353] Iteration 42800 (7.1269 iter/s, 14.0313s/100 iter), loss = 1.89307
I0801 17:07:42.937041 12219 solver.cpp:375]     Train net output #0: loss = 1.6832 (* 1 = 1.6832 loss)
I0801 17:07:42.937047 12219 sgd_solver.cpp:136] Iteration 42800, lr = 0.086625, m = 0.9
I0801 17:07:57.017074 12219 solver.cpp:353] Iteration 42900 (7.10244 iter/s, 14.0797s/100 iter), loss = 2.21391
I0801 17:07:57.017101 12219 solver.cpp:375]     Train net output #0: loss = 2.69903 (* 1 = 2.69903 loss)
I0801 17:07:57.017107 12219 sgd_solver.cpp:136] Iteration 42900, lr = 0.0865937, m = 0.9
I0801 17:08:11.018103 12219 solver.cpp:353] Iteration 43000 (7.14253 iter/s, 14.0006s/100 iter), loss = 2.17673
I0801 17:08:11.019088 12219 solver.cpp:375]     Train net output #0: loss = 2.01258 (* 1 = 2.01258 loss)
I0801 17:08:11.019174 12219 sgd_solver.cpp:136] Iteration 43000, lr = 0.0865625, m = 0.9
I0801 17:08:25.002404 12219 solver.cpp:353] Iteration 43100 (7.15108 iter/s, 13.9839s/100 iter), loss = 2.0976
I0801 17:08:25.002434 12219 solver.cpp:375]     Train net output #0: loss = 2.53329 (* 1 = 2.53329 loss)
I0801 17:08:25.002441 12219 sgd_solver.cpp:136] Iteration 43100, lr = 0.0865313, m = 0.9
I0801 17:08:38.942227 12219 solver.cpp:353] Iteration 43200 (7.17389 iter/s, 13.9394s/100 iter), loss = 2.45527
I0801 17:08:38.942253 12219 solver.cpp:375]     Train net output #0: loss = 2.72925 (* 1 = 2.72925 loss)
I0801 17:08:38.942257 12219 sgd_solver.cpp:136] Iteration 43200, lr = 0.0865, m = 0.9
I0801 17:08:53.034493 12219 solver.cpp:353] Iteration 43300 (7.09629 iter/s, 14.0919s/100 iter), loss = 2.08959
I0801 17:08:53.034564 12219 solver.cpp:375]     Train net output #0: loss = 2.32574 (* 1 = 2.32574 loss)
I0801 17:08:53.034570 12219 sgd_solver.cpp:136] Iteration 43300, lr = 0.0864687, m = 0.9
I0801 17:09:07.043649 12219 solver.cpp:353] Iteration 43400 (7.13839 iter/s, 14.0088s/100 iter), loss = 2.32128
I0801 17:09:07.043676 12219 solver.cpp:375]     Train net output #0: loss = 2.64717 (* 1 = 2.64717 loss)
I0801 17:09:07.043684 12219 sgd_solver.cpp:136] Iteration 43400, lr = 0.0864375, m = 0.9
I0801 17:09:21.045445 12219 solver.cpp:353] Iteration 43500 (7.14214 iter/s, 14.0014s/100 iter), loss = 2.24361
I0801 17:09:21.045475 12219 solver.cpp:375]     Train net output #0: loss = 2.26857 (* 1 = 2.26857 loss)
I0801 17:09:21.045480 12219 sgd_solver.cpp:136] Iteration 43500, lr = 0.0864063, m = 0.9
I0801 17:09:34.995337 12219 solver.cpp:353] Iteration 43600 (7.16871 iter/s, 13.9495s/100 iter), loss = 2.3277
I0801 17:09:34.995414 12219 solver.cpp:375]     Train net output #0: loss = 1.97323 (* 1 = 1.97323 loss)
I0801 17:09:34.995420 12219 sgd_solver.cpp:136] Iteration 43600, lr = 0.086375, m = 0.9
I0801 17:09:48.974377 12219 solver.cpp:353] Iteration 43700 (7.15377 iter/s, 13.9787s/100 iter), loss = 2.8476
I0801 17:09:48.974630 12219 solver.cpp:375]     Train net output #0: loss = 2.37893 (* 1 = 2.37893 loss)
I0801 17:09:48.974743 12219 sgd_solver.cpp:136] Iteration 43700, lr = 0.0863438, m = 0.9
I0801 17:10:02.993904 12219 solver.cpp:353] Iteration 43800 (7.13311 iter/s, 14.0191s/100 iter), loss = 2.12617
I0801 17:10:02.993932 12219 solver.cpp:375]     Train net output #0: loss = 2.72845 (* 1 = 2.72845 loss)
I0801 17:10:02.993939 12219 sgd_solver.cpp:136] Iteration 43800, lr = 0.0863125, m = 0.9
I0801 17:10:17.062634 12219 solver.cpp:353] Iteration 43900 (7.10816 iter/s, 14.0683s/100 iter), loss = 2.46839
I0801 17:10:17.062783 12219 solver.cpp:375]     Train net output #0: loss = 2.97526 (* 1 = 2.97526 loss)
I0801 17:10:17.062808 12219 sgd_solver.cpp:136] Iteration 43900, lr = 0.0862813, m = 0.9
I0801 17:10:31.010195 12219 solver.cpp:550] Iteration 44000, Testing net (#0)
I0801 17:10:50.771822 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.384941
I0801 17:10:50.771925 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.645706
I0801 17:10:50.771934 12219 solver.cpp:635]     Test net output #2: loss = 2.84969 (* 1 = 2.84969 loss)
I0801 17:10:50.771984 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7612s
I0801 17:10:50.913519 12219 solver.cpp:353] Iteration 44000 (2.95421 iter/s, 33.85s/100 iter), loss = 2.48775
I0801 17:10:50.913548 12219 solver.cpp:375]     Train net output #0: loss = 2.77131 (* 1 = 2.77131 loss)
I0801 17:10:50.913554 12219 sgd_solver.cpp:136] Iteration 44000, lr = 0.08625, m = 0.9
I0801 17:11:04.775605 12219 solver.cpp:353] Iteration 44100 (7.21412 iter/s, 13.8617s/100 iter), loss = 2.1394
I0801 17:11:04.775629 12219 solver.cpp:375]     Train net output #0: loss = 2.38537 (* 1 = 2.38537 loss)
I0801 17:11:04.775635 12219 sgd_solver.cpp:136] Iteration 44100, lr = 0.0862188, m = 0.9
I0801 17:11:18.689532 12219 solver.cpp:353] Iteration 44200 (7.18724 iter/s, 13.9135s/100 iter), loss = 2.10431
I0801 17:11:18.689559 12219 solver.cpp:375]     Train net output #0: loss = 2.18411 (* 1 = 2.18411 loss)
I0801 17:11:18.689563 12219 sgd_solver.cpp:136] Iteration 44200, lr = 0.0861875, m = 0.9
I0801 17:11:32.578009 12219 solver.cpp:353] Iteration 44300 (7.20041 iter/s, 13.8881s/100 iter), loss = 2.37331
I0801 17:11:32.578068 12219 solver.cpp:375]     Train net output #0: loss = 2.06499 (* 1 = 2.06499 loss)
I0801 17:11:32.578074 12219 sgd_solver.cpp:136] Iteration 44300, lr = 0.0861562, m = 0.9
I0801 17:11:46.455186 12219 solver.cpp:353] Iteration 44400 (7.20628 iter/s, 13.8768s/100 iter), loss = 2.32194
I0801 17:11:46.455214 12219 solver.cpp:375]     Train net output #0: loss = 2.53129 (* 1 = 2.53129 loss)
I0801 17:11:46.455220 12219 sgd_solver.cpp:136] Iteration 44400, lr = 0.086125, m = 0.9
I0801 17:12:00.277341 12219 solver.cpp:353] Iteration 44500 (7.23496 iter/s, 13.8218s/100 iter), loss = 2.27447
I0801 17:12:00.277365 12219 solver.cpp:375]     Train net output #0: loss = 2.03054 (* 1 = 2.03054 loss)
I0801 17:12:00.277369 12219 sgd_solver.cpp:136] Iteration 44500, lr = 0.0860937, m = 0.9
I0801 17:12:14.148311 12219 solver.cpp:353] Iteration 44600 (7.2095 iter/s, 13.8706s/100 iter), loss = 2.59537
I0801 17:12:14.148392 12219 solver.cpp:375]     Train net output #0: loss = 2.36085 (* 1 = 2.36085 loss)
I0801 17:12:14.148406 12219 sgd_solver.cpp:136] Iteration 44600, lr = 0.0860625, m = 0.9
I0801 17:12:26.615805 12205 data_reader.cpp:264] Starting prefetch of epoch 1
I0801 17:12:28.039088 12219 solver.cpp:353] Iteration 44700 (7.19922 iter/s, 13.8904s/100 iter), loss = 2.2317
I0801 17:12:28.039113 12219 solver.cpp:375]     Train net output #0: loss = 2.43169 (* 1 = 2.43169 loss)
I0801 17:12:28.039117 12219 sgd_solver.cpp:136] Iteration 44700, lr = 0.0860313, m = 0.9
I0801 17:12:41.853582 12219 solver.cpp:353] Iteration 44800 (7.23898 iter/s, 13.8141s/100 iter), loss = 2.54063
I0801 17:12:41.853611 12219 solver.cpp:375]     Train net output #0: loss = 2.51989 (* 1 = 2.51989 loss)
I0801 17:12:41.853617 12219 sgd_solver.cpp:136] Iteration 44800, lr = 0.086, m = 0.9
I0801 17:12:55.702214 12219 solver.cpp:353] Iteration 44900 (7.22114 iter/s, 13.8482s/100 iter), loss = 2.06421
I0801 17:12:55.702296 12219 solver.cpp:375]     Train net output #0: loss = 2.29327 (* 1 = 2.29327 loss)
I0801 17:12:55.702303 12219 sgd_solver.cpp:136] Iteration 44900, lr = 0.0859688, m = 0.9
I0801 17:13:09.566185 12219 solver.cpp:353] Iteration 45000 (7.21315 iter/s, 13.8636s/100 iter), loss = 2.3709
I0801 17:13:09.566213 12219 solver.cpp:375]     Train net output #0: loss = 2.52846 (* 1 = 2.52846 loss)
I0801 17:13:09.566220 12219 sgd_solver.cpp:136] Iteration 45000, lr = 0.0859375, m = 0.9
I0801 17:13:23.420955 12219 solver.cpp:353] Iteration 45100 (7.21793 iter/s, 13.8544s/100 iter), loss = 2.4411
I0801 17:13:23.420984 12219 solver.cpp:375]     Train net output #0: loss = 2.69134 (* 1 = 2.69134 loss)
I0801 17:13:23.420989 12219 sgd_solver.cpp:136] Iteration 45100, lr = 0.0859063, m = 0.9
I0801 17:13:37.334151 12219 solver.cpp:353] Iteration 45200 (7.18762 iter/s, 13.9128s/100 iter), loss = 2.69256
I0801 17:13:37.334275 12219 solver.cpp:375]     Train net output #0: loss = 2.24035 (* 1 = 2.24035 loss)
I0801 17:13:37.334282 12219 sgd_solver.cpp:136] Iteration 45200, lr = 0.085875, m = 0.9
I0801 17:13:51.186142 12219 solver.cpp:353] Iteration 45300 (7.21938 iter/s, 13.8516s/100 iter), loss = 2.38784
I0801 17:13:51.186167 12219 solver.cpp:375]     Train net output #0: loss = 2.14707 (* 1 = 2.14707 loss)
I0801 17:13:51.186172 12219 sgd_solver.cpp:136] Iteration 45300, lr = 0.0858437, m = 0.9
I0801 17:14:05.126653 12219 solver.cpp:353] Iteration 45400 (7.17354 iter/s, 13.9401s/100 iter), loss = 2.16327
I0801 17:14:05.126682 12219 solver.cpp:375]     Train net output #0: loss = 2.23606 (* 1 = 2.23606 loss)
I0801 17:14:05.126688 12219 sgd_solver.cpp:136] Iteration 45400, lr = 0.0858125, m = 0.9
I0801 17:14:19.024300 12219 solver.cpp:353] Iteration 45500 (7.19566 iter/s, 13.8973s/100 iter), loss = 2.66146
I0801 17:14:19.024358 12219 solver.cpp:375]     Train net output #0: loss = 2.82895 (* 1 = 2.82895 loss)
I0801 17:14:19.024365 12219 sgd_solver.cpp:136] Iteration 45500, lr = 0.0857813, m = 0.9
I0801 17:14:32.893909 12219 solver.cpp:353] Iteration 45600 (7.21021 iter/s, 13.8692s/100 iter), loss = 2.13093
I0801 17:14:32.893936 12219 solver.cpp:375]     Train net output #0: loss = 2.0682 (* 1 = 2.0682 loss)
I0801 17:14:32.893942 12219 sgd_solver.cpp:136] Iteration 45600, lr = 0.08575, m = 0.9
I0801 17:14:46.829421 12219 solver.cpp:353] Iteration 45700 (7.17611 iter/s, 13.9351s/100 iter), loss = 2.02882
I0801 17:14:46.829445 12219 solver.cpp:375]     Train net output #0: loss = 2.11877 (* 1 = 2.11877 loss)
I0801 17:14:46.829449 12219 sgd_solver.cpp:136] Iteration 45700, lr = 0.0857188, m = 0.9
I0801 17:15:00.766113 12219 solver.cpp:353] Iteration 45800 (7.1755 iter/s, 13.9363s/100 iter), loss = 2.47759
I0801 17:15:00.766180 12219 solver.cpp:375]     Train net output #0: loss = 2.61715 (* 1 = 2.61715 loss)
I0801 17:15:00.766186 12219 sgd_solver.cpp:136] Iteration 45800, lr = 0.0856875, m = 0.9
I0801 17:15:14.659416 12219 solver.cpp:353] Iteration 45900 (7.19791 iter/s, 13.8929s/100 iter), loss = 2.19479
I0801 17:15:14.659442 12219 solver.cpp:375]     Train net output #0: loss = 2.15665 (* 1 = 2.15665 loss)
I0801 17:15:14.659447 12219 sgd_solver.cpp:136] Iteration 45900, lr = 0.0856562, m = 0.9
I0801 17:15:28.459795 12219 solver.cpp:550] Iteration 46000, Testing net (#0)
I0801 17:15:37.797453 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 17:15:47.897788 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.388587
I0801 17:15:47.897809 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.646529
I0801 17:15:47.897816 12219 solver.cpp:635]     Test net output #2: loss = 2.87318 (* 1 = 2.87318 loss)
I0801 17:15:47.897838 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.4375s
I0801 17:15:48.037281 12219 solver.cpp:353] Iteration 46000 (2.99608 iter/s, 33.3769s/100 iter), loss = 2.76674
I0801 17:15:48.037307 12219 solver.cpp:375]     Train net output #0: loss = 2.92634 (* 1 = 2.92634 loss)
I0801 17:15:48.037312 12219 sgd_solver.cpp:136] Iteration 46000, lr = 0.085625, m = 0.9
I0801 17:16:01.888475 12219 solver.cpp:353] Iteration 46100 (7.21979 iter/s, 13.8508s/100 iter), loss = 2.37334
I0801 17:16:01.888505 12219 solver.cpp:375]     Train net output #0: loss = 2.23727 (* 1 = 2.23727 loss)
I0801 17:16:01.888511 12219 sgd_solver.cpp:136] Iteration 46100, lr = 0.0855938, m = 0.9
I0801 17:16:15.797885 12219 solver.cpp:353] Iteration 46200 (7.18958 iter/s, 13.909s/100 iter), loss = 1.6052
I0801 17:16:15.797952 12219 solver.cpp:375]     Train net output #0: loss = 1.09224 (* 1 = 1.09224 loss)
I0801 17:16:15.797960 12219 sgd_solver.cpp:136] Iteration 46200, lr = 0.0855625, m = 0.9
I0801 17:16:29.708856 12219 solver.cpp:353] Iteration 46300 (7.18877 iter/s, 13.9106s/100 iter), loss = 2.19883
I0801 17:16:29.709034 12219 solver.cpp:375]     Train net output #0: loss = 2.15684 (* 1 = 2.15684 loss)
I0801 17:16:29.709102 12219 sgd_solver.cpp:136] Iteration 46300, lr = 0.0855312, m = 0.9
I0801 17:16:43.621608 12219 solver.cpp:353] Iteration 46400 (7.18786 iter/s, 13.9123s/100 iter), loss = 2.37447
I0801 17:16:43.621637 12219 solver.cpp:375]     Train net output #0: loss = 2.0497 (* 1 = 2.0497 loss)
I0801 17:16:43.621644 12219 sgd_solver.cpp:136] Iteration 46400, lr = 0.0855, m = 0.9
I0801 17:16:57.576098 12219 solver.cpp:353] Iteration 46500 (7.16635 iter/s, 13.9541s/100 iter), loss = 2.29872
I0801 17:16:57.576164 12219 solver.cpp:375]     Train net output #0: loss = 2.13966 (* 1 = 2.13966 loss)
I0801 17:16:57.576171 12219 sgd_solver.cpp:136] Iteration 46500, lr = 0.0854688, m = 0.9
I0801 17:17:11.484453 12219 solver.cpp:353] Iteration 46600 (7.19012 iter/s, 13.908s/100 iter), loss = 2.02787
I0801 17:17:11.484479 12219 solver.cpp:375]     Train net output #0: loss = 1.69291 (* 1 = 1.69291 loss)
I0801 17:17:11.484486 12219 sgd_solver.cpp:136] Iteration 46600, lr = 0.0854375, m = 0.9
I0801 17:17:25.423915 12219 solver.cpp:353] Iteration 46700 (7.17408 iter/s, 13.9391s/100 iter), loss = 2.53504
I0801 17:17:25.424094 12219 solver.cpp:375]     Train net output #0: loss = 2.03578 (* 1 = 2.03578 loss)
I0801 17:17:25.424116 12219 sgd_solver.cpp:136] Iteration 46700, lr = 0.0854063, m = 0.9
I0801 17:17:39.274920 12219 solver.cpp:353] Iteration 46800 (7.21989 iter/s, 13.8506s/100 iter), loss = 2.39955
I0801 17:17:39.274978 12219 solver.cpp:375]     Train net output #0: loss = 2.76085 (* 1 = 2.76085 loss)
I0801 17:17:39.274984 12219 sgd_solver.cpp:136] Iteration 46800, lr = 0.085375, m = 0.9
I0801 17:17:53.194855 12219 solver.cpp:353] Iteration 46900 (7.18414 iter/s, 13.9195s/100 iter), loss = 2.44938
I0801 17:17:53.194883 12219 solver.cpp:375]     Train net output #0: loss = 2.75528 (* 1 = 2.75528 loss)
I0801 17:17:53.194887 12219 sgd_solver.cpp:136] Iteration 46900, lr = 0.0853437, m = 0.9
I0801 17:18:07.229351 12219 solver.cpp:353] Iteration 47000 (7.1255 iter/s, 14.0341s/100 iter), loss = 2.25198
I0801 17:18:07.229375 12219 solver.cpp:375]     Train net output #0: loss = 1.92359 (* 1 = 1.92359 loss)
I0801 17:18:07.229382 12219 sgd_solver.cpp:136] Iteration 47000, lr = 0.0853125, m = 0.9
I0801 17:18:21.075402 12219 solver.cpp:353] Iteration 47100 (7.22248 iter/s, 13.8457s/100 iter), loss = 2.69408
I0801 17:18:21.075461 12219 solver.cpp:375]     Train net output #0: loss = 2.95977 (* 1 = 2.95977 loss)
I0801 17:18:21.075469 12219 sgd_solver.cpp:136] Iteration 47100, lr = 0.0852813, m = 0.9
I0801 17:18:34.961761 12219 solver.cpp:353] Iteration 47200 (7.20151 iter/s, 13.886s/100 iter), loss = 2.30055
I0801 17:18:34.961791 12219 solver.cpp:375]     Train net output #0: loss = 2.05374 (* 1 = 2.05374 loss)
I0801 17:18:34.961797 12219 sgd_solver.cpp:136] Iteration 47200, lr = 0.08525, m = 0.9
I0801 17:18:48.819224 12219 solver.cpp:353] Iteration 47300 (7.21653 iter/s, 13.8571s/100 iter), loss = 1.96624
I0801 17:18:48.819252 12219 solver.cpp:375]     Train net output #0: loss = 2.01993 (* 1 = 2.01993 loss)
I0801 17:18:48.819257 12219 sgd_solver.cpp:136] Iteration 47300, lr = 0.0852187, m = 0.9
I0801 17:19:02.759399 12219 solver.cpp:353] Iteration 47400 (7.17371 iter/s, 13.9398s/100 iter), loss = 2.11704
I0801 17:19:02.759479 12219 solver.cpp:375]     Train net output #0: loss = 2.15302 (* 1 = 2.15302 loss)
I0801 17:19:02.759486 12219 sgd_solver.cpp:136] Iteration 47400, lr = 0.0851875, m = 0.9
I0801 17:19:16.784670 12219 solver.cpp:353] Iteration 47500 (7.13019 iter/s, 14.0249s/100 iter), loss = 2.31882
I0801 17:19:16.784695 12219 solver.cpp:375]     Train net output #0: loss = 2.30644 (* 1 = 2.30644 loss)
I0801 17:19:16.784700 12219 sgd_solver.cpp:136] Iteration 47500, lr = 0.0851563, m = 0.9
I0801 17:19:30.703207 12219 solver.cpp:353] Iteration 47600 (7.18486 iter/s, 13.9181s/100 iter), loss = 3.13043
I0801 17:19:30.703233 12219 solver.cpp:375]     Train net output #0: loss = 3.25127 (* 1 = 3.25127 loss)
I0801 17:19:30.703238 12219 sgd_solver.cpp:136] Iteration 47600, lr = 0.085125, m = 0.9
I0801 17:19:44.627810 12219 solver.cpp:353] Iteration 47700 (7.18173 iter/s, 13.9242s/100 iter), loss = 2.28662
I0801 17:19:44.627881 12219 solver.cpp:375]     Train net output #0: loss = 2.12923 (* 1 = 2.12923 loss)
I0801 17:19:44.627887 12219 sgd_solver.cpp:136] Iteration 47700, lr = 0.0850938, m = 0.9
I0801 17:19:58.612138 12219 solver.cpp:353] Iteration 47800 (7.15106 iter/s, 13.9839s/100 iter), loss = 2.06555
I0801 17:19:58.612162 12219 solver.cpp:375]     Train net output #0: loss = 2.00941 (* 1 = 2.00941 loss)
I0801 17:19:58.612166 12219 sgd_solver.cpp:136] Iteration 47800, lr = 0.0850625, m = 0.9
I0801 17:20:12.477682 12219 solver.cpp:353] Iteration 47900 (7.21233 iter/s, 13.8651s/100 iter), loss = 2.22816
I0801 17:20:12.477782 12219 solver.cpp:375]     Train net output #0: loss = 2.80043 (* 1 = 2.80043 loss)
I0801 17:20:12.477802 12219 sgd_solver.cpp:136] Iteration 47900, lr = 0.0850312, m = 0.9
I0801 17:20:26.316550 12219 solver.cpp:550] Iteration 48000, Testing net (#0)
I0801 17:20:46.504286 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.393823
I0801 17:20:46.504308 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.655176
I0801 17:20:46.504313 12219 solver.cpp:635]     Test net output #2: loss = 2.79891 (* 1 = 2.79891 loss)
I0801 17:20:46.504343 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1872s
I0801 17:20:46.645692 12219 solver.cpp:353] Iteration 48000 (2.92679 iter/s, 34.1671s/100 iter), loss = 2.39392
I0801 17:20:46.645716 12219 solver.cpp:375]     Train net output #0: loss = 2.66601 (* 1 = 2.66601 loss)
I0801 17:20:46.645720 12219 sgd_solver.cpp:136] Iteration 48000, lr = 0.085, m = 0.9
I0801 17:21:00.674901 12219 solver.cpp:353] Iteration 48100 (7.12818 iter/s, 14.0288s/100 iter), loss = 2.06638
I0801 17:21:00.674996 12219 solver.cpp:375]     Train net output #0: loss = 2.3227 (* 1 = 2.3227 loss)
I0801 17:21:00.675004 12219 sgd_solver.cpp:136] Iteration 48100, lr = 0.0849688, m = 0.9
I0801 17:21:14.688946 12219 solver.cpp:353] Iteration 48200 (7.1359 iter/s, 14.0136s/100 iter), loss = 2.63312
I0801 17:21:14.689043 12219 solver.cpp:375]     Train net output #0: loss = 2.77118 (* 1 = 2.77118 loss)
I0801 17:21:14.689064 12219 sgd_solver.cpp:136] Iteration 48200, lr = 0.0849375, m = 0.9
I0801 17:21:28.695726 12219 solver.cpp:353] Iteration 48300 (7.1396 iter/s, 14.0064s/100 iter), loss = 1.87753
I0801 17:21:28.695751 12219 solver.cpp:375]     Train net output #0: loss = 1.93368 (* 1 = 1.93368 loss)
I0801 17:21:28.695757 12219 sgd_solver.cpp:136] Iteration 48300, lr = 0.0849063, m = 0.9
I0801 17:21:42.867543 12219 solver.cpp:353] Iteration 48400 (7.05646 iter/s, 14.1714s/100 iter), loss = 2.4346
I0801 17:21:42.867624 12219 solver.cpp:375]     Train net output #0: loss = 2.02496 (* 1 = 2.02496 loss)
I0801 17:21:42.867630 12219 sgd_solver.cpp:136] Iteration 48400, lr = 0.084875, m = 0.9
I0801 17:21:56.948168 12219 solver.cpp:353] Iteration 48500 (7.10216 iter/s, 14.0802s/100 iter), loss = 2.26612
I0801 17:21:56.948199 12219 solver.cpp:375]     Train net output #0: loss = 2.32896 (* 1 = 2.32896 loss)
I0801 17:21:56.948204 12219 sgd_solver.cpp:136] Iteration 48500, lr = 0.0848437, m = 0.9
I0801 17:22:11.046316 12219 solver.cpp:353] Iteration 48600 (7.09333 iter/s, 14.0978s/100 iter), loss = 2.09255
I0801 17:22:11.046341 12219 solver.cpp:375]     Train net output #0: loss = 2.23022 (* 1 = 2.23022 loss)
I0801 17:22:11.046347 12219 sgd_solver.cpp:136] Iteration 48600, lr = 0.0848125, m = 0.9
I0801 17:22:25.088057 12219 solver.cpp:353] Iteration 48700 (7.12182 iter/s, 14.0413s/100 iter), loss = 2.10228
I0801 17:22:25.088136 12219 solver.cpp:375]     Train net output #0: loss = 2.11451 (* 1 = 2.11451 loss)
I0801 17:22:25.088143 12219 sgd_solver.cpp:136] Iteration 48700, lr = 0.0847813, m = 0.9
I0801 17:22:39.131512 12219 solver.cpp:353] Iteration 48800 (7.12095 iter/s, 14.0431s/100 iter), loss = 2.32812
I0801 17:22:39.131604 12219 solver.cpp:375]     Train net output #0: loss = 2.69909 (* 1 = 2.69909 loss)
I0801 17:22:39.131629 12219 sgd_solver.cpp:136] Iteration 48800, lr = 0.08475, m = 0.9
I0801 17:22:53.191243 12219 solver.cpp:353] Iteration 48900 (7.11271 iter/s, 14.0593s/100 iter), loss = 2.57505
I0801 17:22:53.191272 12219 solver.cpp:375]     Train net output #0: loss = 2.59304 (* 1 = 2.59304 loss)
I0801 17:22:53.191277 12219 sgd_solver.cpp:136] Iteration 48900, lr = 0.0847188, m = 0.9
I0801 17:23:07.312016 12219 solver.cpp:353] Iteration 49000 (7.08196 iter/s, 14.1204s/100 iter), loss = 2.40382
I0801 17:23:07.312103 12219 solver.cpp:375]     Train net output #0: loss = 2.35635 (* 1 = 2.35635 loss)
I0801 17:23:07.312110 12219 sgd_solver.cpp:136] Iteration 49000, lr = 0.0846875, m = 0.9
I0801 17:23:21.417158 12219 solver.cpp:353] Iteration 49100 (7.08981 iter/s, 14.1048s/100 iter), loss = 2.4686
I0801 17:23:21.417186 12219 solver.cpp:375]     Train net output #0: loss = 2.59273 (* 1 = 2.59273 loss)
I0801 17:23:21.417189 12219 sgd_solver.cpp:136] Iteration 49100, lr = 0.0846563, m = 0.9
I0801 17:23:35.440426 12219 solver.cpp:353] Iteration 49200 (7.1312 iter/s, 14.0229s/100 iter), loss = 2.65861
I0801 17:23:35.440462 12219 solver.cpp:375]     Train net output #0: loss = 2.98212 (* 1 = 2.98212 loss)
I0801 17:23:35.440469 12219 sgd_solver.cpp:136] Iteration 49200, lr = 0.084625, m = 0.9
I0801 17:23:49.516865 12219 solver.cpp:353] Iteration 49300 (7.10427 iter/s, 14.076s/100 iter), loss = 2.25051
I0801 17:23:49.516974 12219 solver.cpp:375]     Train net output #0: loss = 2.35677 (* 1 = 2.35677 loss)
I0801 17:23:49.516999 12219 sgd_solver.cpp:136] Iteration 49300, lr = 0.0845938, m = 0.9
I0801 17:24:03.566036 12219 solver.cpp:353] Iteration 49400 (7.11805 iter/s, 14.0488s/100 iter), loss = 2.04754
I0801 17:24:03.566064 12219 solver.cpp:375]     Train net output #0: loss = 1.96551 (* 1 = 1.96551 loss)
I0801 17:24:03.566068 12219 sgd_solver.cpp:136] Iteration 49400, lr = 0.0845625, m = 0.9
I0801 17:24:17.616066 12219 solver.cpp:353] Iteration 49500 (7.11763 iter/s, 14.0496s/100 iter), loss = 2.05215
I0801 17:24:17.616143 12219 solver.cpp:375]     Train net output #0: loss = 1.71247 (* 1 = 1.71247 loss)
I0801 17:24:17.616164 12219 sgd_solver.cpp:136] Iteration 49500, lr = 0.0845312, m = 0.9
I0801 17:24:31.691929 12219 solver.cpp:353] Iteration 49600 (7.10456 iter/s, 14.0755s/100 iter), loss = 2.25547
I0801 17:24:31.692008 12219 solver.cpp:375]     Train net output #0: loss = 2.26594 (* 1 = 2.26594 loss)
I0801 17:24:31.692014 12219 sgd_solver.cpp:136] Iteration 49600, lr = 0.0845, m = 0.9
I0801 17:24:45.664440 12219 solver.cpp:353] Iteration 49700 (7.15711 iter/s, 13.9721s/100 iter), loss = 2.30825
I0801 17:24:45.664469 12219 solver.cpp:375]     Train net output #0: loss = 2.18833 (* 1 = 2.18833 loss)
I0801 17:24:45.664475 12219 sgd_solver.cpp:136] Iteration 49700, lr = 0.0844688, m = 0.9
I0801 17:24:59.666028 12219 solver.cpp:353] Iteration 49800 (7.14225 iter/s, 14.0012s/100 iter), loss = 2.51784
I0801 17:24:59.666059 12219 solver.cpp:375]     Train net output #0: loss = 3.02754 (* 1 = 3.02754 loss)
I0801 17:24:59.666065 12219 sgd_solver.cpp:136] Iteration 49800, lr = 0.0844375, m = 0.9
I0801 17:25:13.800277 12219 solver.cpp:353] Iteration 49900 (7.07521 iter/s, 14.1339s/100 iter), loss = 2.24629
I0801 17:25:13.800359 12219 solver.cpp:375]     Train net output #0: loss = 2.47248 (* 1 = 2.47248 loss)
I0801 17:25:13.800371 12219 sgd_solver.cpp:136] Iteration 49900, lr = 0.0844062, m = 0.9
I0801 17:25:27.657232 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_50000.caffemodel
I0801 17:25:27.851519 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_50000.solverstate
I0801 17:25:27.857249 12219 solver.cpp:550] Iteration 50000, Testing net (#0)
I0801 17:25:47.938241 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.305058
I0801 17:25:47.938370 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.546412
I0801 17:25:47.938380 12219 solver.cpp:635]     Test net output #2: loss = 3.42926 (* 1 = 3.42926 loss)
I0801 17:25:47.938400 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0806s
I0801 17:25:48.075753 12219 solver.cpp:353] Iteration 50000 (2.91762 iter/s, 34.2745s/100 iter), loss = 2.33524
I0801 17:25:48.075780 12219 solver.cpp:375]     Train net output #0: loss = 2.21383 (* 1 = 2.21383 loss)
I0801 17:25:48.075788 12219 sgd_solver.cpp:136] Iteration 50000, lr = 0.084375, m = 0.9
I0801 17:26:02.076046 12219 solver.cpp:353] Iteration 50100 (7.14291 iter/s, 13.9999s/100 iter), loss = 2.33289
I0801 17:26:02.076071 12219 solver.cpp:375]     Train net output #0: loss = 2.34898 (* 1 = 2.34898 loss)
I0801 17:26:02.076076 12219 sgd_solver.cpp:136] Iteration 50100, lr = 0.0843438, m = 0.9
I0801 17:26:16.112838 12219 solver.cpp:353] Iteration 50200 (7.12433 iter/s, 14.0364s/100 iter), loss = 2.26893
I0801 17:26:16.112864 12219 solver.cpp:375]     Train net output #0: loss = 1.94884 (* 1 = 1.94884 loss)
I0801 17:26:16.112867 12219 sgd_solver.cpp:136] Iteration 50200, lr = 0.0843125, m = 0.9
I0801 17:26:30.158036 12219 solver.cpp:353] Iteration 50300 (7.12007 iter/s, 14.0448s/100 iter), loss = 2.31765
I0801 17:26:30.158109 12219 solver.cpp:375]     Train net output #0: loss = 2.28651 (* 1 = 2.28651 loss)
I0801 17:26:30.158115 12219 sgd_solver.cpp:136] Iteration 50300, lr = 0.0842813, m = 0.9
I0801 17:26:44.201292 12219 solver.cpp:353] Iteration 50400 (7.12106 iter/s, 14.0429s/100 iter), loss = 2.70816
I0801 17:26:44.201319 12219 solver.cpp:375]     Train net output #0: loss = 2.79569 (* 1 = 2.79569 loss)
I0801 17:26:44.201326 12219 sgd_solver.cpp:136] Iteration 50400, lr = 0.08425, m = 0.9
I0801 17:26:58.257688 12219 solver.cpp:353] Iteration 50500 (7.1144 iter/s, 14.056s/100 iter), loss = 2.29285
I0801 17:26:58.257716 12219 solver.cpp:375]     Train net output #0: loss = 2.3588 (* 1 = 2.3588 loss)
I0801 17:26:58.257766 12219 sgd_solver.cpp:136] Iteration 50500, lr = 0.0842188, m = 0.9
I0801 17:27:12.200898 12219 solver.cpp:353] Iteration 50600 (7.17215 iter/s, 13.9428s/100 iter), loss = 2.12183
I0801 17:27:12.200958 12219 solver.cpp:375]     Train net output #0: loss = 2.277 (* 1 = 2.277 loss)
I0801 17:27:12.200963 12219 sgd_solver.cpp:136] Iteration 50600, lr = 0.0841875, m = 0.9
I0801 17:27:26.199656 12219 solver.cpp:353] Iteration 50700 (7.1437 iter/s, 13.9984s/100 iter), loss = 2.1166
I0801 17:27:26.199687 12219 solver.cpp:375]     Train net output #0: loss = 2.148 (* 1 = 2.148 loss)
I0801 17:27:26.199693 12219 sgd_solver.cpp:136] Iteration 50700, lr = 0.0841563, m = 0.9
I0801 17:27:40.261996 12219 solver.cpp:353] Iteration 50800 (7.11139 iter/s, 14.0619s/100 iter), loss = 2.42563
I0801 17:27:40.262024 12219 solver.cpp:375]     Train net output #0: loss = 2.54898 (* 1 = 2.54898 loss)
I0801 17:27:40.262030 12219 sgd_solver.cpp:136] Iteration 50800, lr = 0.084125, m = 0.9
I0801 17:27:54.298378 12219 solver.cpp:353] Iteration 50900 (7.12455 iter/s, 14.036s/100 iter), loss = 2.02912
I0801 17:27:54.298445 12219 solver.cpp:375]     Train net output #0: loss = 1.92829 (* 1 = 1.92829 loss)
I0801 17:27:54.298452 12219 sgd_solver.cpp:136] Iteration 50900, lr = 0.0840937, m = 0.9
I0801 17:28:08.354694 12219 solver.cpp:353] Iteration 51000 (7.11444 iter/s, 14.0559s/100 iter), loss = 2.31044
I0801 17:28:08.354719 12219 solver.cpp:375]     Train net output #0: loss = 2.77778 (* 1 = 2.77778 loss)
I0801 17:28:08.354723 12219 sgd_solver.cpp:136] Iteration 51000, lr = 0.0840625, m = 0.9
I0801 17:28:22.239753 12219 solver.cpp:353] Iteration 51100 (7.20219 iter/s, 13.8847s/100 iter), loss = 2.58549
I0801 17:28:22.239846 12219 solver.cpp:375]     Train net output #0: loss = 2.39734 (* 1 = 2.39734 loss)
I0801 17:28:22.239873 12219 sgd_solver.cpp:136] Iteration 51100, lr = 0.0840312, m = 0.9
I0801 17:28:36.300221 12219 solver.cpp:353] Iteration 51200 (7.11234 iter/s, 14.0601s/100 iter), loss = 2.24971
I0801 17:28:36.300298 12219 solver.cpp:375]     Train net output #0: loss = 2.27859 (* 1 = 2.27859 loss)
I0801 17:28:36.300305 12219 sgd_solver.cpp:136] Iteration 51200, lr = 0.084, m = 0.9
I0801 17:28:50.362491 12219 solver.cpp:353] Iteration 51300 (7.11143 iter/s, 14.0619s/100 iter), loss = 2.28889
I0801 17:28:50.362520 12219 solver.cpp:375]     Train net output #0: loss = 2.5428 (* 1 = 2.5428 loss)
I0801 17:28:50.362525 12219 sgd_solver.cpp:136] Iteration 51300, lr = 0.0839688, m = 0.9
I0801 17:29:04.454139 12219 solver.cpp:353] Iteration 51400 (7.0966 iter/s, 14.0913s/100 iter), loss = 2.32543
I0801 17:29:04.454210 12219 solver.cpp:375]     Train net output #0: loss = 2.46141 (* 1 = 2.46141 loss)
I0801 17:29:04.454227 12219 sgd_solver.cpp:136] Iteration 51400, lr = 0.0839375, m = 0.9
I0801 17:29:18.620188 12219 solver.cpp:353] Iteration 51500 (7.05933 iter/s, 14.1656s/100 iter), loss = 2.25726
I0801 17:29:18.620268 12219 solver.cpp:375]     Train net output #0: loss = 2.35165 (* 1 = 2.35165 loss)
I0801 17:29:18.620275 12219 sgd_solver.cpp:136] Iteration 51500, lr = 0.0839063, m = 0.9
I0801 17:29:32.528391 12219 solver.cpp:353] Iteration 51600 (7.1902 iter/s, 13.9078s/100 iter), loss = 2.1562
I0801 17:29:32.528420 12219 solver.cpp:375]     Train net output #0: loss = 2.1799 (* 1 = 2.1799 loss)
I0801 17:29:32.528426 12219 sgd_solver.cpp:136] Iteration 51600, lr = 0.083875, m = 0.9
I0801 17:29:46.568452 12219 solver.cpp:353] Iteration 51700 (7.12267 iter/s, 14.0397s/100 iter), loss = 2.06162
I0801 17:29:46.568480 12219 solver.cpp:375]     Train net output #0: loss = 2.19444 (* 1 = 2.19444 loss)
I0801 17:29:46.568485 12219 sgd_solver.cpp:136] Iteration 51700, lr = 0.0838438, m = 0.9
I0801 17:30:00.571929 12219 solver.cpp:353] Iteration 51800 (7.14128 iter/s, 14.0031s/100 iter), loss = 1.9203
I0801 17:30:00.572021 12219 solver.cpp:375]     Train net output #0: loss = 1.55706 (* 1 = 1.55706 loss)
I0801 17:30:00.572039 12219 sgd_solver.cpp:136] Iteration 51800, lr = 0.0838125, m = 0.9
I0801 17:30:14.692847 12219 solver.cpp:353] Iteration 51900 (7.08189 iter/s, 14.1205s/100 iter), loss = 2.65173
I0801 17:30:14.692883 12219 solver.cpp:375]     Train net output #0: loss = 2.28541 (* 1 = 2.28541 loss)
I0801 17:30:14.692889 12219 sgd_solver.cpp:136] Iteration 51900, lr = 0.0837812, m = 0.9
I0801 17:30:28.618963 12219 solver.cpp:550] Iteration 52000, Testing net (#0)
I0801 17:30:40.735484 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 17:30:48.118242 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.38447
I0801 17:30:48.118264 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.64694
I0801 17:30:48.118269 12219 solver.cpp:635]     Test net output #2: loss = 2.86233 (* 1 = 2.86233 loss)
I0801 17:30:48.118342 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.4988s
I0801 17:30:48.261965 12219 solver.cpp:353] Iteration 52000 (2.97901 iter/s, 33.5682s/100 iter), loss = 2.20535
I0801 17:30:48.261992 12219 solver.cpp:375]     Train net output #0: loss = 1.91902 (* 1 = 1.91902 loss)
I0801 17:30:48.261996 12219 sgd_solver.cpp:136] Iteration 52000, lr = 0.08375, m = 0.9
I0801 17:31:02.311656 12219 solver.cpp:353] Iteration 52100 (7.11779 iter/s, 14.0493s/100 iter), loss = 1.92972
I0801 17:31:02.311683 12219 solver.cpp:375]     Train net output #0: loss = 1.9438 (* 1 = 1.9438 loss)
I0801 17:31:02.311689 12219 sgd_solver.cpp:136] Iteration 52100, lr = 0.0837188, m = 0.9
I0801 17:31:16.329516 12219 solver.cpp:353] Iteration 52200 (7.13396 iter/s, 14.0175s/100 iter), loss = 1.98239
I0801 17:31:16.329597 12219 solver.cpp:375]     Train net output #0: loss = 1.95727 (* 1 = 1.95727 loss)
I0801 17:31:16.329604 12219 sgd_solver.cpp:136] Iteration 52200, lr = 0.0836875, m = 0.9
I0801 17:31:30.483013 12219 solver.cpp:353] Iteration 52300 (7.06559 iter/s, 14.1531s/100 iter), loss = 2.4027
I0801 17:31:30.483038 12219 solver.cpp:375]     Train net output #0: loss = 2.57939 (* 1 = 2.57939 loss)
I0801 17:31:30.483261 12219 sgd_solver.cpp:136] Iteration 52300, lr = 0.0836563, m = 0.9
I0801 17:31:44.522172 12219 solver.cpp:353] Iteration 52400 (7.12314 iter/s, 14.0388s/100 iter), loss = 2.03281
I0801 17:31:44.522200 12219 solver.cpp:375]     Train net output #0: loss = 2.0652 (* 1 = 2.0652 loss)
I0801 17:31:44.522207 12219 sgd_solver.cpp:136] Iteration 52400, lr = 0.083625, m = 0.9
I0801 17:31:58.467876 12219 solver.cpp:353] Iteration 52500 (7.17087 iter/s, 13.9453s/100 iter), loss = 2.32247
I0801 17:31:58.467957 12219 solver.cpp:375]     Train net output #0: loss = 1.79133 (* 1 = 1.79133 loss)
I0801 17:31:58.467963 12219 sgd_solver.cpp:136] Iteration 52500, lr = 0.0835937, m = 0.9
I0801 17:32:12.497730 12219 solver.cpp:353] Iteration 52600 (7.12786 iter/s, 14.0295s/100 iter), loss = 1.98114
I0801 17:32:12.497761 12219 solver.cpp:375]     Train net output #0: loss = 2.03728 (* 1 = 2.03728 loss)
I0801 17:32:12.497768 12219 sgd_solver.cpp:136] Iteration 52600, lr = 0.0835625, m = 0.9
I0801 17:32:26.555047 12219 solver.cpp:353] Iteration 52700 (7.11393 iter/s, 14.0569s/100 iter), loss = 2.11434
I0801 17:32:26.555070 12219 solver.cpp:375]     Train net output #0: loss = 1.82667 (* 1 = 1.82667 loss)
I0801 17:32:26.555075 12219 sgd_solver.cpp:136] Iteration 52700, lr = 0.0835313, m = 0.9
I0801 17:32:40.528004 12219 solver.cpp:353] Iteration 52800 (7.15688 iter/s, 13.9726s/100 iter), loss = 2.26976
I0801 17:32:40.528062 12219 solver.cpp:375]     Train net output #0: loss = 1.93458 (* 1 = 1.93458 loss)
I0801 17:32:40.528069 12219 sgd_solver.cpp:136] Iteration 52800, lr = 0.0835, m = 0.9
I0801 17:32:54.453151 12219 solver.cpp:353] Iteration 52900 (7.18145 iter/s, 13.9248s/100 iter), loss = 2.39839
I0801 17:32:54.453177 12219 solver.cpp:375]     Train net output #0: loss = 2.39572 (* 1 = 2.39572 loss)
I0801 17:32:54.453182 12219 sgd_solver.cpp:136] Iteration 52900, lr = 0.0834688, m = 0.9
I0801 17:33:08.367913 12219 solver.cpp:353] Iteration 53000 (7.18681 iter/s, 13.9144s/100 iter), loss = 2.25615
I0801 17:33:08.367941 12219 solver.cpp:375]     Train net output #0: loss = 2.02598 (* 1 = 2.02598 loss)
I0801 17:33:08.367947 12219 sgd_solver.cpp:136] Iteration 53000, lr = 0.0834375, m = 0.9
I0801 17:33:22.395797 12219 solver.cpp:353] Iteration 53100 (7.12886 iter/s, 14.0275s/100 iter), loss = 2.12187
I0801 17:33:22.395860 12219 solver.cpp:375]     Train net output #0: loss = 2.17856 (* 1 = 2.17856 loss)
I0801 17:33:22.395867 12219 sgd_solver.cpp:136] Iteration 53100, lr = 0.0834063, m = 0.9
I0801 17:33:36.341941 12219 solver.cpp:353] Iteration 53200 (7.17065 iter/s, 13.9457s/100 iter), loss = 2.01986
I0801 17:33:36.341970 12219 solver.cpp:375]     Train net output #0: loss = 1.97259 (* 1 = 1.97259 loss)
I0801 17:33:36.341977 12219 sgd_solver.cpp:136] Iteration 53200, lr = 0.083375, m = 0.9
I0801 17:33:50.385216 12219 solver.cpp:353] Iteration 53300 (7.12104 iter/s, 14.0429s/100 iter), loss = 2.15797
I0801 17:33:50.385243 12219 solver.cpp:375]     Train net output #0: loss = 2.13947 (* 1 = 2.13947 loss)
I0801 17:33:50.385247 12219 sgd_solver.cpp:136] Iteration 53300, lr = 0.0833438, m = 0.9
I0801 17:34:04.295348 12219 solver.cpp:353] Iteration 53400 (7.1892 iter/s, 13.9097s/100 iter), loss = 2.45877
I0801 17:34:04.295409 12219 solver.cpp:375]     Train net output #0: loss = 2.3542 (* 1 = 2.3542 loss)
I0801 17:34:04.295415 12219 sgd_solver.cpp:136] Iteration 53400, lr = 0.0833125, m = 0.9
I0801 17:34:18.210448 12219 solver.cpp:353] Iteration 53500 (7.18664 iter/s, 13.9147s/100 iter), loss = 2.36721
I0801 17:34:18.210472 12219 solver.cpp:375]     Train net output #0: loss = 2.44085 (* 1 = 2.44085 loss)
I0801 17:34:18.210476 12219 sgd_solver.cpp:136] Iteration 53500, lr = 0.0832812, m = 0.9
I0801 17:34:32.304513 12219 solver.cpp:353] Iteration 53600 (7.09538 iter/s, 14.0937s/100 iter), loss = 2.13349
I0801 17:34:32.304539 12219 solver.cpp:375]     Train net output #0: loss = 2.2098 (* 1 = 2.2098 loss)
I0801 17:34:32.304545 12219 sgd_solver.cpp:136] Iteration 53600, lr = 0.08325, m = 0.9
I0801 17:34:46.218369 12219 solver.cpp:353] Iteration 53700 (7.18728 iter/s, 13.9135s/100 iter), loss = 2.15295
I0801 17:34:46.218482 12219 solver.cpp:375]     Train net output #0: loss = 2.22138 (* 1 = 2.22138 loss)
I0801 17:34:46.218498 12219 sgd_solver.cpp:136] Iteration 53700, lr = 0.0832188, m = 0.9
I0801 17:35:00.208235 12219 solver.cpp:353] Iteration 53800 (7.14823 iter/s, 13.9895s/100 iter), loss = 2.18954
I0801 17:35:00.208268 12219 solver.cpp:375]     Train net output #0: loss = 2.72148 (* 1 = 2.72148 loss)
I0801 17:35:00.208276 12219 sgd_solver.cpp:136] Iteration 53800, lr = 0.0831875, m = 0.9
I0801 17:35:14.298257 12219 solver.cpp:353] Iteration 53900 (7.09742 iter/s, 14.0896s/100 iter), loss = 2.27008
I0801 17:35:14.298285 12219 solver.cpp:375]     Train net output #0: loss = 2.28704 (* 1 = 2.28704 loss)
I0801 17:35:14.298291 12219 sgd_solver.cpp:136] Iteration 53900, lr = 0.0831563, m = 0.9
I0801 17:35:28.056385 12219 solver.cpp:550] Iteration 54000, Testing net (#0)
I0801 17:35:47.846129 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.318823
I0801 17:35:47.846168 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.572529
I0801 17:35:47.846180 12219 solver.cpp:635]     Test net output #2: loss = 3.37695 (* 1 = 3.37695 loss)
I0801 17:35:47.846216 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7893s
I0801 17:35:47.989537 12219 solver.cpp:353] Iteration 54000 (2.96821 iter/s, 33.6904s/100 iter), loss = 2.08999
I0801 17:35:47.989565 12219 solver.cpp:375]     Train net output #0: loss = 2.29607 (* 1 = 2.29607 loss)
I0801 17:35:47.989572 12219 sgd_solver.cpp:136] Iteration 54000, lr = 0.083125, m = 0.9
I0801 17:36:02.025065 12219 solver.cpp:353] Iteration 54100 (7.12497 iter/s, 14.0351s/100 iter), loss = 2.00207
I0801 17:36:02.025130 12219 solver.cpp:375]     Train net output #0: loss = 2.30438 (* 1 = 2.30438 loss)
I0801 17:36:02.025137 12219 sgd_solver.cpp:136] Iteration 54100, lr = 0.0830938, m = 0.9
I0801 17:36:16.031188 12219 solver.cpp:353] Iteration 54200 (7.13994 iter/s, 14.0057s/100 iter), loss = 2.66486
I0801 17:36:16.031462 12219 solver.cpp:375]     Train net output #0: loss = 2.27113 (* 1 = 2.27113 loss)
I0801 17:36:16.031576 12219 sgd_solver.cpp:136] Iteration 54200, lr = 0.0830625, m = 0.9
I0801 17:36:29.986431 12219 solver.cpp:353] Iteration 54300 (7.16596 iter/s, 13.9549s/100 iter), loss = 2.09028
I0801 17:36:29.986459 12219 solver.cpp:375]     Train net output #0: loss = 1.83896 (* 1 = 1.83896 loss)
I0801 17:36:29.986465 12219 sgd_solver.cpp:136] Iteration 54300, lr = 0.0830313, m = 0.9
I0801 17:36:43.919819 12219 solver.cpp:353] Iteration 54400 (7.1772 iter/s, 13.933s/100 iter), loss = 2.3058
I0801 17:36:43.919874 12219 solver.cpp:375]     Train net output #0: loss = 2.43251 (* 1 = 2.43251 loss)
I0801 17:36:43.919880 12219 sgd_solver.cpp:136] Iteration 54400, lr = 0.083, m = 0.9
I0801 17:36:58.029361 12219 solver.cpp:353] Iteration 54500 (7.0876 iter/s, 14.1091s/100 iter), loss = 2.34548
I0801 17:36:58.029510 12219 solver.cpp:375]     Train net output #0: loss = 2.69754 (* 1 = 2.69754 loss)
I0801 17:36:58.029526 12219 sgd_solver.cpp:136] Iteration 54500, lr = 0.0829687, m = 0.9
I0801 17:37:12.094378 12219 solver.cpp:353] Iteration 54600 (7.11004 iter/s, 14.0646s/100 iter), loss = 2.13289
I0801 17:37:12.094411 12219 solver.cpp:375]     Train net output #0: loss = 2.10593 (* 1 = 2.10593 loss)
I0801 17:37:12.094418 12219 sgd_solver.cpp:136] Iteration 54600, lr = 0.0829375, m = 0.9
I0801 17:37:26.227457 12219 solver.cpp:353] Iteration 54700 (7.07579 iter/s, 14.1327s/100 iter), loss = 2.18795
I0801 17:37:26.227520 12219 solver.cpp:375]     Train net output #0: loss = 2.23309 (* 1 = 2.23309 loss)
I0801 17:37:26.227526 12219 sgd_solver.cpp:136] Iteration 54700, lr = 0.0829063, m = 0.9
I0801 17:37:40.162425 12219 solver.cpp:353] Iteration 54800 (7.17639 iter/s, 13.9346s/100 iter), loss = 1.98291
I0801 17:37:40.162449 12219 solver.cpp:375]     Train net output #0: loss = 2.10151 (* 1 = 2.10151 loss)
I0801 17:37:40.162456 12219 sgd_solver.cpp:136] Iteration 54800, lr = 0.082875, m = 0.9
I0801 17:37:54.228574 12219 solver.cpp:353] Iteration 54900 (7.10946 iter/s, 14.0658s/100 iter), loss = 2.57829
I0801 17:37:54.228597 12219 solver.cpp:375]     Train net output #0: loss = 2.67287 (* 1 = 2.67287 loss)
I0801 17:37:54.228601 12219 sgd_solver.cpp:136] Iteration 54900, lr = 0.0828438, m = 0.9
I0801 17:38:08.358006 12219 solver.cpp:353] Iteration 55000 (7.07762 iter/s, 14.129s/100 iter), loss = 1.99764
I0801 17:38:08.360865 12219 solver.cpp:375]     Train net output #0: loss = 2.22127 (* 1 = 2.22127 loss)
I0801 17:38:08.360890 12219 sgd_solver.cpp:136] Iteration 55000, lr = 0.0828125, m = 0.9
I0801 17:38:22.378790 12219 solver.cpp:353] Iteration 55100 (7.13246 iter/s, 14.0204s/100 iter), loss = 2.21412
I0801 17:38:22.378861 12219 solver.cpp:375]     Train net output #0: loss = 1.95813 (* 1 = 1.95813 loss)
I0801 17:38:22.378880 12219 sgd_solver.cpp:136] Iteration 55100, lr = 0.0827812, m = 0.9
I0801 17:38:36.378340 12219 solver.cpp:353] Iteration 55200 (7.14329 iter/s, 13.9991s/100 iter), loss = 2.20313
I0801 17:38:36.378368 12219 solver.cpp:375]     Train net output #0: loss = 2.57457 (* 1 = 2.57457 loss)
I0801 17:38:36.378374 12219 sgd_solver.cpp:136] Iteration 55200, lr = 0.08275, m = 0.9
I0801 17:38:50.361822 12219 solver.cpp:353] Iteration 55300 (7.15149 iter/s, 13.9831s/100 iter), loss = 2.10164
I0801 17:38:50.361917 12219 solver.cpp:375]     Train net output #0: loss = 2.23758 (* 1 = 2.23758 loss)
I0801 17:38:50.361923 12219 sgd_solver.cpp:136] Iteration 55300, lr = 0.0827188, m = 0.9
I0801 17:39:04.369839 12219 solver.cpp:353] Iteration 55400 (7.13897 iter/s, 14.0076s/100 iter), loss = 2.43904
I0801 17:39:04.369865 12219 solver.cpp:375]     Train net output #0: loss = 2.53025 (* 1 = 2.53025 loss)
I0801 17:39:04.369871 12219 sgd_solver.cpp:136] Iteration 55400, lr = 0.0826875, m = 0.9
I0801 17:39:18.476749 12219 solver.cpp:353] Iteration 55500 (7.08892 iter/s, 14.1065s/100 iter), loss = 2.27797
I0801 17:39:18.476780 12219 solver.cpp:375]     Train net output #0: loss = 2.09991 (* 1 = 2.09991 loss)
I0801 17:39:18.476784 12219 sgd_solver.cpp:136] Iteration 55500, lr = 0.0826563, m = 0.9
I0801 17:39:32.663250 12219 solver.cpp:353] Iteration 55600 (7.04915 iter/s, 14.1861s/100 iter), loss = 2.60471
I0801 17:39:32.663306 12219 solver.cpp:375]     Train net output #0: loss = 2.84696 (* 1 = 2.84696 loss)
I0801 17:39:32.663313 12219 sgd_solver.cpp:136] Iteration 55600, lr = 0.082625, m = 0.9
I0801 17:39:46.692749 12219 solver.cpp:353] Iteration 55700 (7.12804 iter/s, 14.0291s/100 iter), loss = 2.49497
I0801 17:39:46.692777 12219 solver.cpp:375]     Train net output #0: loss = 2.55305 (* 1 = 2.55305 loss)
I0801 17:39:46.692785 12219 sgd_solver.cpp:136] Iteration 55700, lr = 0.0825938, m = 0.9
I0801 17:40:00.656615 12219 solver.cpp:353] Iteration 55800 (7.16154 iter/s, 13.9635s/100 iter), loss = 2.3911
I0801 17:40:00.656639 12219 solver.cpp:375]     Train net output #0: loss = 2.52548 (* 1 = 2.52548 loss)
I0801 17:40:00.656643 12219 sgd_solver.cpp:136] Iteration 55800, lr = 0.0825625, m = 0.9
I0801 17:40:14.620592 12219 solver.cpp:353] Iteration 55900 (7.16148 iter/s, 13.9636s/100 iter), loss = 2.06461
I0801 17:40:14.620729 12219 solver.cpp:375]     Train net output #0: loss = 2.09709 (* 1 = 2.09709 loss)
I0801 17:40:14.620749 12219 sgd_solver.cpp:136] Iteration 55900, lr = 0.0825313, m = 0.9
I0801 17:40:28.526042 12219 solver.cpp:550] Iteration 56000, Testing net (#0)
I0801 17:40:48.725483 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.368411
I0801 17:40:48.725579 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.624882
I0801 17:40:48.725587 12219 solver.cpp:635]     Test net output #2: loss = 2.95014 (* 1 = 2.95014 loss)
I0801 17:40:48.725608 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.199s
I0801 17:40:48.863204 12219 solver.cpp:353] Iteration 56000 (2.92042 iter/s, 34.2417s/100 iter), loss = 1.97607
I0801 17:40:48.863231 12219 solver.cpp:375]     Train net output #0: loss = 2.05303 (* 1 = 2.05303 loss)
I0801 17:40:48.863239 12219 sgd_solver.cpp:136] Iteration 56000, lr = 0.0825, m = 0.9
I0801 17:41:02.884217 12219 solver.cpp:353] Iteration 56100 (7.13235 iter/s, 14.0206s/100 iter), loss = 2.17245
I0801 17:41:02.884243 12219 solver.cpp:375]     Train net output #0: loss = 2.32738 (* 1 = 2.32738 loss)
I0801 17:41:02.884248 12219 sgd_solver.cpp:136] Iteration 56100, lr = 0.0824687, m = 0.9
I0801 17:41:16.860601 12219 solver.cpp:353] Iteration 56200 (7.15513 iter/s, 13.976s/100 iter), loss = 2.18992
I0801 17:41:16.860625 12219 solver.cpp:375]     Train net output #0: loss = 2.59114 (* 1 = 2.59114 loss)
I0801 17:41:16.860630 12219 sgd_solver.cpp:136] Iteration 56200, lr = 0.0824375, m = 0.9
I0801 17:41:30.996757 12219 solver.cpp:353] Iteration 56300 (7.07426 iter/s, 14.1358s/100 iter), loss = 2.61171
I0801 17:41:30.996839 12219 solver.cpp:375]     Train net output #0: loss = 2.99785 (* 1 = 2.99785 loss)
I0801 17:41:30.996845 12219 sgd_solver.cpp:136] Iteration 56300, lr = 0.0824062, m = 0.9
I0801 17:41:45.006652 12219 solver.cpp:353] Iteration 56400 (7.13801 iter/s, 14.0095s/100 iter), loss = 2.26279
I0801 17:41:45.006681 12219 solver.cpp:375]     Train net output #0: loss = 1.84819 (* 1 = 1.84819 loss)
I0801 17:41:45.006686 12219 sgd_solver.cpp:136] Iteration 56400, lr = 0.082375, m = 0.9
I0801 17:41:59.053897 12219 solver.cpp:353] Iteration 56500 (7.11903 iter/s, 14.0469s/100 iter), loss = 2.07493
I0801 17:41:59.053922 12219 solver.cpp:375]     Train net output #0: loss = 2.09877 (* 1 = 2.09877 loss)
I0801 17:41:59.053926 12219 sgd_solver.cpp:136] Iteration 56500, lr = 0.0823437, m = 0.9
I0801 17:42:13.135525 12219 solver.cpp:353] Iteration 56600 (7.10165 iter/s, 14.0812s/100 iter), loss = 1.99752
I0801 17:42:13.135581 12219 solver.cpp:375]     Train net output #0: loss = 1.82244 (* 1 = 1.82244 loss)
I0801 17:42:13.135586 12219 sgd_solver.cpp:136] Iteration 56600, lr = 0.0823125, m = 0.9
I0801 17:42:27.057066 12219 solver.cpp:353] Iteration 56700 (7.18331 iter/s, 13.9212s/100 iter), loss = 2.35243
I0801 17:42:27.057090 12219 solver.cpp:375]     Train net output #0: loss = 2.73662 (* 1 = 2.73662 loss)
I0801 17:42:27.057093 12219 sgd_solver.cpp:136] Iteration 56700, lr = 0.0822813, m = 0.9
I0801 17:42:41.159468 12219 solver.cpp:353] Iteration 56800 (7.09119 iter/s, 14.102s/100 iter), loss = 2.21968
I0801 17:42:41.159493 12219 solver.cpp:375]     Train net output #0: loss = 2.45847 (* 1 = 2.45847 loss)
I0801 17:42:41.159499 12219 sgd_solver.cpp:136] Iteration 56800, lr = 0.08225, m = 0.9
I0801 17:42:55.270514 12219 solver.cpp:353] Iteration 56900 (7.08685 iter/s, 14.1107s/100 iter), loss = 2.0536
I0801 17:42:55.270601 12219 solver.cpp:375]     Train net output #0: loss = 2.08558 (* 1 = 2.08558 loss)
I0801 17:42:55.270608 12219 sgd_solver.cpp:136] Iteration 56900, lr = 0.0822188, m = 0.9
I0801 17:43:09.230144 12219 solver.cpp:353] Iteration 57000 (7.16371 iter/s, 13.9592s/100 iter), loss = 1.97882
I0801 17:43:09.230195 12219 solver.cpp:375]     Train net output #0: loss = 2.01143 (* 1 = 2.01143 loss)
I0801 17:43:09.230206 12219 sgd_solver.cpp:136] Iteration 57000, lr = 0.0821875, m = 0.9
I0801 17:43:23.387027 12219 solver.cpp:353] Iteration 57100 (7.0639 iter/s, 14.1565s/100 iter), loss = 2.17685
I0801 17:43:23.387061 12219 solver.cpp:375]     Train net output #0: loss = 2.00683 (* 1 = 2.00683 loss)
I0801 17:43:23.387068 12219 sgd_solver.cpp:136] Iteration 57100, lr = 0.0821563, m = 0.9
I0801 17:43:37.316161 12219 solver.cpp:353] Iteration 57200 (7.1794 iter/s, 13.9288s/100 iter), loss = 2.22028
I0801 17:43:37.316280 12219 solver.cpp:375]     Train net output #0: loss = 2.00616 (* 1 = 2.00616 loss)
I0801 17:43:37.316303 12219 sgd_solver.cpp:136] Iteration 57200, lr = 0.082125, m = 0.9
I0801 17:43:51.341040 12219 solver.cpp:353] Iteration 57300 (7.13038 iter/s, 14.0245s/100 iter), loss = 2.16912
I0801 17:43:51.341068 12219 solver.cpp:375]     Train net output #0: loss = 2.35173 (* 1 = 2.35173 loss)
I0801 17:43:51.341074 12219 sgd_solver.cpp:136] Iteration 57300, lr = 0.0820938, m = 0.9
I0801 17:44:05.331719 12219 solver.cpp:353] Iteration 57400 (7.14782 iter/s, 13.9903s/100 iter), loss = 2.32538
I0801 17:44:05.331748 12219 solver.cpp:375]     Train net output #0: loss = 2.29598 (* 1 = 2.29598 loss)
I0801 17:44:05.331754 12219 sgd_solver.cpp:136] Iteration 57400, lr = 0.0820625, m = 0.9
I0801 17:44:19.393183 12219 solver.cpp:353] Iteration 57500 (7.11183 iter/s, 14.0611s/100 iter), loss = 1.70174
I0801 17:44:19.393261 12219 solver.cpp:375]     Train net output #0: loss = 1.45321 (* 1 = 1.45321 loss)
I0801 17:44:19.393266 12219 sgd_solver.cpp:136] Iteration 57500, lr = 0.0820312, m = 0.9
I0801 17:44:33.388787 12219 solver.cpp:353] Iteration 57600 (7.1453 iter/s, 13.9952s/100 iter), loss = 2.2215
I0801 17:44:33.388825 12219 solver.cpp:375]     Train net output #0: loss = 2.74164 (* 1 = 2.74164 loss)
I0801 17:44:33.388831 12219 sgd_solver.cpp:136] Iteration 57600, lr = 0.082, m = 0.9
I0801 17:44:47.293299 12219 solver.cpp:353] Iteration 57700 (7.19211 iter/s, 13.9041s/100 iter), loss = 2.13604
I0801 17:44:47.293328 12219 solver.cpp:375]     Train net output #0: loss = 2.19232 (* 1 = 2.19232 loss)
I0801 17:44:47.293334 12219 sgd_solver.cpp:136] Iteration 57700, lr = 0.0819687, m = 0.9
I0801 17:45:01.308284 12219 solver.cpp:353] Iteration 57800 (7.13542 iter/s, 14.0146s/100 iter), loss = 2.32489
I0801 17:45:01.308339 12219 solver.cpp:375]     Train net output #0: loss = 2.3549 (* 1 = 2.3549 loss)
I0801 17:45:01.308344 12219 sgd_solver.cpp:136] Iteration 57800, lr = 0.0819375, m = 0.9
I0801 17:45:15.371481 12219 solver.cpp:353] Iteration 57900 (7.11096 iter/s, 14.0628s/100 iter), loss = 2.61641
I0801 17:45:15.371510 12219 solver.cpp:375]     Train net output #0: loss = 2.76887 (* 1 = 2.76887 loss)
I0801 17:45:15.371515 12219 sgd_solver.cpp:136] Iteration 57900, lr = 0.0819063, m = 0.9
I0801 17:45:29.225155 12219 solver.cpp:550] Iteration 58000, Testing net (#0)
I0801 17:45:44.173072 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 17:45:49.322268 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.343175
I0801 17:45:49.322288 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.593235
I0801 17:45:49.322293 12219 solver.cpp:635]     Test net output #2: loss = 3.20836 (* 1 = 3.20836 loss)
I0801 17:45:49.322360 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0967s
I0801 17:45:49.468709 12219 solver.cpp:353] Iteration 58000 (2.93287 iter/s, 34.0963s/100 iter), loss = 2.85044
I0801 17:45:49.468739 12219 solver.cpp:375]     Train net output #0: loss = 2.41552 (* 1 = 2.41552 loss)
I0801 17:45:49.468744 12219 sgd_solver.cpp:136] Iteration 58000, lr = 0.081875, m = 0.9
I0801 17:46:03.349979 12219 solver.cpp:353] Iteration 58100 (7.20415 iter/s, 13.8809s/100 iter), loss = 2.14847
I0801 17:46:03.350009 12219 solver.cpp:375]     Train net output #0: loss = 2.34228 (* 1 = 2.34228 loss)
I0801 17:46:03.350015 12219 sgd_solver.cpp:136] Iteration 58100, lr = 0.0818438, m = 0.9
I0801 17:46:17.454527 12219 solver.cpp:353] Iteration 58200 (7.09011 iter/s, 14.1042s/100 iter), loss = 2.17209
I0801 17:46:17.454759 12219 solver.cpp:375]     Train net output #0: loss = 2.12591 (* 1 = 2.12591 loss)
I0801 17:46:17.454769 12219 sgd_solver.cpp:136] Iteration 58200, lr = 0.0818125, m = 0.9
I0801 17:46:31.422431 12219 solver.cpp:353] Iteration 58300 (7.15947 iter/s, 13.9675s/100 iter), loss = 3.0528
I0801 17:46:31.422459 12219 solver.cpp:375]     Train net output #0: loss = 3.08155 (* 1 = 3.08155 loss)
I0801 17:46:31.422463 12219 sgd_solver.cpp:136] Iteration 58300, lr = 0.0817813, m = 0.9
I0801 17:46:45.423458 12219 solver.cpp:353] Iteration 58400 (7.14253 iter/s, 14.0006s/100 iter), loss = 2.46036
I0801 17:46:45.423485 12219 solver.cpp:375]     Train net output #0: loss = 2.76725 (* 1 = 2.76725 loss)
I0801 17:46:45.423491 12219 sgd_solver.cpp:136] Iteration 58400, lr = 0.08175, m = 0.9
I0801 17:46:59.539129 12219 solver.cpp:353] Iteration 58500 (7.08452 iter/s, 14.1153s/100 iter), loss = 2.3851
I0801 17:46:59.539194 12219 solver.cpp:375]     Train net output #0: loss = 2.07398 (* 1 = 2.07398 loss)
I0801 17:46:59.539247 12219 sgd_solver.cpp:136] Iteration 58500, lr = 0.0817188, m = 0.9
I0801 17:47:13.586463 12219 solver.cpp:353] Iteration 58600 (7.11899 iter/s, 14.0469s/100 iter), loss = 2.22292
I0801 17:47:13.586488 12219 solver.cpp:375]     Train net output #0: loss = 2.19498 (* 1 = 2.19498 loss)
I0801 17:47:13.586491 12219 sgd_solver.cpp:136] Iteration 58600, lr = 0.0816875, m = 0.9
I0801 17:47:27.589061 12219 solver.cpp:353] Iteration 58700 (7.14173 iter/s, 14.0022s/100 iter), loss = 2.11321
I0801 17:47:27.589088 12219 solver.cpp:375]     Train net output #0: loss = 2.03344 (* 1 = 2.03344 loss)
I0801 17:47:27.589092 12219 sgd_solver.cpp:136] Iteration 58700, lr = 0.0816563, m = 0.9
I0801 17:47:41.644227 12219 solver.cpp:353] Iteration 58800 (7.11502 iter/s, 14.0548s/100 iter), loss = 2.73621
I0801 17:47:41.644312 12219 solver.cpp:375]     Train net output #0: loss = 2.81982 (* 1 = 2.81982 loss)
I0801 17:47:41.644320 12219 sgd_solver.cpp:136] Iteration 58800, lr = 0.081625, m = 0.9
I0801 17:47:55.659044 12219 solver.cpp:353] Iteration 58900 (7.1355 iter/s, 14.0144s/100 iter), loss = 2.09273
I0801 17:47:55.659076 12219 solver.cpp:375]     Train net output #0: loss = 2.24859 (* 1 = 2.24859 loss)
I0801 17:47:55.659082 12219 sgd_solver.cpp:136] Iteration 58900, lr = 0.0815938, m = 0.9
I0801 17:48:09.616843 12219 solver.cpp:353] Iteration 59000 (7.16465 iter/s, 13.9574s/100 iter), loss = 2.4434
I0801 17:48:09.616875 12219 solver.cpp:375]     Train net output #0: loss = 2.81561 (* 1 = 2.81561 loss)
I0801 17:48:09.616883 12219 sgd_solver.cpp:136] Iteration 59000, lr = 0.0815625, m = 0.9
I0801 17:48:23.548393 12219 solver.cpp:353] Iteration 59100 (7.17815 iter/s, 13.9312s/100 iter), loss = 2.67899
I0801 17:48:23.548457 12219 solver.cpp:375]     Train net output #0: loss = 1.98893 (* 1 = 1.98893 loss)
I0801 17:48:23.548465 12219 sgd_solver.cpp:136] Iteration 59100, lr = 0.0815312, m = 0.9
I0801 17:48:37.483589 12219 solver.cpp:353] Iteration 59200 (7.17627 iter/s, 13.9348s/100 iter), loss = 2.48551
I0801 17:48:37.483614 12219 solver.cpp:375]     Train net output #0: loss = 2.43002 (* 1 = 2.43002 loss)
I0801 17:48:37.483618 12219 sgd_solver.cpp:136] Iteration 59200, lr = 0.0815, m = 0.9
I0801 17:48:51.527967 12219 solver.cpp:353] Iteration 59300 (7.12048 iter/s, 14.044s/100 iter), loss = 2.34264
I0801 17:48:51.527993 12219 solver.cpp:375]     Train net output #0: loss = 2.10669 (* 1 = 2.10669 loss)
I0801 17:48:51.527999 12219 sgd_solver.cpp:136] Iteration 59300, lr = 0.0814688, m = 0.9
I0801 17:49:05.479130 12219 solver.cpp:353] Iteration 59400 (7.16806 iter/s, 13.9508s/100 iter), loss = 2.53358
I0801 17:49:05.479188 12219 solver.cpp:375]     Train net output #0: loss = 2.63122 (* 1 = 2.63122 loss)
I0801 17:49:05.479195 12219 sgd_solver.cpp:136] Iteration 59400, lr = 0.0814375, m = 0.9
I0801 17:49:19.497571 12219 solver.cpp:353] Iteration 59500 (7.13366 iter/s, 14.0181s/100 iter), loss = 2.21884
I0801 17:49:19.497596 12219 solver.cpp:375]     Train net output #0: loss = 2.29665 (* 1 = 2.29665 loss)
I0801 17:49:19.497602 12219 sgd_solver.cpp:136] Iteration 59500, lr = 0.0814063, m = 0.9
I0801 17:49:31.608201 12205 data_reader.cpp:264] Starting prefetch of epoch 2
I0801 17:49:33.372799 12219 solver.cpp:353] Iteration 59600 (7.20729 iter/s, 13.8748s/100 iter), loss = 2.20848
I0801 17:49:33.372839 12219 solver.cpp:375]     Train net output #0: loss = 2.32936 (* 1 = 2.32936 loss)
I0801 17:49:33.372846 12219 sgd_solver.cpp:136] Iteration 59600, lr = 0.081375, m = 0.9
I0801 17:49:47.365778 12219 solver.cpp:353] Iteration 59700 (7.14664 iter/s, 13.9926s/100 iter), loss = 2.45833
I0801 17:49:47.365839 12219 solver.cpp:375]     Train net output #0: loss = 2.37256 (* 1 = 2.37256 loss)
I0801 17:49:47.365845 12219 sgd_solver.cpp:136] Iteration 59700, lr = 0.0813438, m = 0.9
I0801 17:50:01.360924 12219 solver.cpp:353] Iteration 59800 (7.14553 iter/s, 13.9948s/100 iter), loss = 2.53838
I0801 17:50:01.360965 12219 solver.cpp:375]     Train net output #0: loss = 2.39554 (* 1 = 2.39554 loss)
I0801 17:50:01.360973 12219 sgd_solver.cpp:136] Iteration 59800, lr = 0.0813125, m = 0.9
I0801 17:50:15.233850 12219 solver.cpp:353] Iteration 59900 (7.20848 iter/s, 13.8725s/100 iter), loss = 2.14359
I0801 17:50:15.233880 12219 solver.cpp:375]     Train net output #0: loss = 2.0671 (* 1 = 2.0671 loss)
I0801 17:50:15.233886 12219 sgd_solver.cpp:136] Iteration 59900, lr = 0.0812813, m = 0.9
I0801 17:50:29.009681 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_60000.caffemodel
I0801 17:50:29.098554 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_60000.solverstate
I0801 17:50:29.107372 12219 solver.cpp:550] Iteration 60000, Testing net (#0)
I0801 17:50:48.762544 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.375117
I0801 17:50:48.762564 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.631176
I0801 17:50:48.762570 12219 solver.cpp:635]     Test net output #2: loss = 2.97809 (* 1 = 2.97809 loss)
I0801 17:50:48.762629 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6547s
I0801 17:50:48.905331 12219 solver.cpp:353] Iteration 60000 (2.96995 iter/s, 33.6706s/100 iter), loss = 2.68469
I0801 17:50:48.905364 12219 solver.cpp:375]     Train net output #0: loss = 3.0647 (* 1 = 3.0647 loss)
I0801 17:50:48.905369 12219 sgd_solver.cpp:136] Iteration 60000, lr = 0.08125, m = 0.9
I0801 17:51:02.902503 12219 solver.cpp:353] Iteration 60100 (7.1445 iter/s, 13.9968s/100 iter), loss = 2.52425
I0801 17:51:02.902556 12219 solver.cpp:375]     Train net output #0: loss = 2.41454 (* 1 = 2.41454 loss)
I0801 17:51:02.902564 12219 sgd_solver.cpp:136] Iteration 60100, lr = 0.0812187, m = 0.9
I0801 17:51:16.852072 12219 solver.cpp:353] Iteration 60200 (7.16888 iter/s, 13.9492s/100 iter), loss = 2.38292
I0801 17:51:16.852121 12219 solver.cpp:375]     Train net output #0: loss = 1.94559 (* 1 = 1.94559 loss)
I0801 17:51:16.852136 12219 sgd_solver.cpp:136] Iteration 60200, lr = 0.0811875, m = 0.9
I0801 17:51:30.879906 12219 solver.cpp:353] Iteration 60300 (7.12888 iter/s, 14.0274s/100 iter), loss = 2.02641
I0801 17:51:30.879931 12219 solver.cpp:375]     Train net output #0: loss = 2.1178 (* 1 = 2.1178 loss)
I0801 17:51:30.879935 12219 sgd_solver.cpp:136] Iteration 60300, lr = 0.0811562, m = 0.9
I0801 17:51:44.828981 12219 solver.cpp:353] Iteration 60400 (7.16913 iter/s, 13.9487s/100 iter), loss = 2.15214
I0801 17:51:44.829036 12219 solver.cpp:375]     Train net output #0: loss = 2.10756 (* 1 = 2.10756 loss)
I0801 17:51:44.829043 12219 sgd_solver.cpp:136] Iteration 60400, lr = 0.081125, m = 0.9
I0801 17:51:58.820632 12219 solver.cpp:353] Iteration 60500 (7.14733 iter/s, 13.9912s/100 iter), loss = 1.89978
I0801 17:51:58.820663 12219 solver.cpp:375]     Train net output #0: loss = 1.69024 (* 1 = 1.69024 loss)
I0801 17:51:58.820669 12219 sgd_solver.cpp:136] Iteration 60500, lr = 0.0810938, m = 0.9
I0801 17:52:12.799949 12219 solver.cpp:353] Iteration 60600 (7.15362 iter/s, 13.9789s/100 iter), loss = 2.31815
I0801 17:52:12.800016 12219 solver.cpp:375]     Train net output #0: loss = 2.52058 (* 1 = 2.52058 loss)
I0801 17:52:12.800035 12219 sgd_solver.cpp:136] Iteration 60600, lr = 0.0810625, m = 0.9
I0801 17:52:26.840350 12219 solver.cpp:353] Iteration 60700 (7.1225 iter/s, 14.04s/100 iter), loss = 2.36115
I0801 17:52:26.840410 12219 solver.cpp:375]     Train net output #0: loss = 2.40674 (* 1 = 2.40674 loss)
I0801 17:52:26.840416 12219 sgd_solver.cpp:136] Iteration 60700, lr = 0.0810313, m = 0.9
I0801 17:52:40.982300 12219 solver.cpp:353] Iteration 60800 (7.07136 iter/s, 14.1416s/100 iter), loss = 2.28748
I0801 17:52:40.982329 12219 solver.cpp:375]     Train net output #0: loss = 2.54676 (* 1 = 2.54676 loss)
I0801 17:52:40.982336 12219 sgd_solver.cpp:136] Iteration 60800, lr = 0.081, m = 0.9
I0801 17:52:54.866226 12219 solver.cpp:353] Iteration 60900 (7.20277 iter/s, 13.8835s/100 iter), loss = 2.44132
I0801 17:52:54.866255 12219 solver.cpp:375]     Train net output #0: loss = 2.15718 (* 1 = 2.15718 loss)
I0801 17:52:54.866261 12219 sgd_solver.cpp:136] Iteration 60900, lr = 0.0809688, m = 0.9
I0801 17:53:08.897308 12219 solver.cpp:353] Iteration 61000 (7.12723 iter/s, 14.0307s/100 iter), loss = 2.37666
I0801 17:53:08.897392 12219 solver.cpp:375]     Train net output #0: loss = 2.11033 (* 1 = 2.11033 loss)
I0801 17:53:08.897399 12219 sgd_solver.cpp:136] Iteration 61000, lr = 0.0809375, m = 0.9
I0801 17:53:22.870744 12219 solver.cpp:353] Iteration 61100 (7.15663 iter/s, 13.9731s/100 iter), loss = 2.11934
I0801 17:53:22.870772 12219 solver.cpp:375]     Train net output #0: loss = 2.02978 (* 1 = 2.02978 loss)
I0801 17:53:22.870779 12219 sgd_solver.cpp:136] Iteration 61100, lr = 0.0809062, m = 0.9
I0801 17:53:36.877759 12219 solver.cpp:353] Iteration 61200 (7.13948 iter/s, 14.0066s/100 iter), loss = 2.32064
I0801 17:53:36.877785 12219 solver.cpp:375]     Train net output #0: loss = 2.84089 (* 1 = 2.84089 loss)
I0801 17:53:36.877791 12219 sgd_solver.cpp:136] Iteration 61200, lr = 0.080875, m = 0.9
I0801 17:53:50.876752 12219 solver.cpp:353] Iteration 61300 (7.14357 iter/s, 13.9986s/100 iter), loss = 2.61168
I0801 17:53:50.876845 12219 solver.cpp:375]     Train net output #0: loss = 2.41893 (* 1 = 2.41893 loss)
I0801 17:53:50.876858 12219 sgd_solver.cpp:136] Iteration 61300, lr = 0.0808437, m = 0.9
I0801 17:54:04.784543 12219 solver.cpp:353] Iteration 61400 (7.19041 iter/s, 13.9074s/100 iter), loss = 2.2811
I0801 17:54:04.784595 12219 solver.cpp:375]     Train net output #0: loss = 2.35988 (* 1 = 2.35988 loss)
I0801 17:54:04.784607 12219 sgd_solver.cpp:136] Iteration 61400, lr = 0.0808125, m = 0.9
I0801 17:54:18.746307 12219 solver.cpp:353] Iteration 61500 (7.16262 iter/s, 13.9614s/100 iter), loss = 1.95572
I0801 17:54:18.746330 12219 solver.cpp:375]     Train net output #0: loss = 2.10527 (* 1 = 2.10527 loss)
I0801 17:54:18.746335 12219 sgd_solver.cpp:136] Iteration 61500, lr = 0.0807813, m = 0.9
I0801 17:54:32.854743 12219 solver.cpp:353] Iteration 61600 (7.08815 iter/s, 14.108s/100 iter), loss = 2.14883
I0801 17:54:32.854866 12219 solver.cpp:375]     Train net output #0: loss = 2.09976 (* 1 = 2.09976 loss)
I0801 17:54:32.854887 12219 sgd_solver.cpp:136] Iteration 61600, lr = 0.08075, m = 0.9
I0801 17:54:46.933774 12219 solver.cpp:353] Iteration 61700 (7.10296 iter/s, 14.0786s/100 iter), loss = 2.37767
I0801 17:54:46.933799 12219 solver.cpp:375]     Train net output #0: loss = 2.34863 (* 1 = 2.34863 loss)
I0801 17:54:46.933804 12219 sgd_solver.cpp:136] Iteration 61700, lr = 0.0807187, m = 0.9
I0801 17:55:01.064631 12219 solver.cpp:353] Iteration 61800 (7.07691 iter/s, 14.1305s/100 iter), loss = 2.186
I0801 17:55:01.064657 12219 solver.cpp:375]     Train net output #0: loss = 2.30269 (* 1 = 2.30269 loss)
I0801 17:55:01.064663 12219 sgd_solver.cpp:136] Iteration 61800, lr = 0.0806875, m = 0.9
I0801 17:55:15.042412 12219 solver.cpp:353] Iteration 61900 (7.15441 iter/s, 13.9774s/100 iter), loss = 2.47754
I0801 17:55:15.042487 12219 solver.cpp:375]     Train net output #0: loss = 2.20473 (* 1 = 2.20473 loss)
I0801 17:55:15.042495 12219 sgd_solver.cpp:136] Iteration 61900, lr = 0.0806563, m = 0.9
I0801 17:55:29.023914 12219 solver.cpp:550] Iteration 62000, Testing net (#0)
I0801 17:55:49.305212 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.370588
I0801 17:55:49.305274 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.630646
I0801 17:55:49.305282 12219 solver.cpp:635]     Test net output #2: loss = 2.94729 (* 1 = 2.94729 loss)
I0801 17:55:49.305310 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2808s
I0801 17:55:49.470898 12219 solver.cpp:353] Iteration 62000 (2.90465 iter/s, 34.4275s/100 iter), loss = 2.46932
I0801 17:55:49.470926 12219 solver.cpp:375]     Train net output #0: loss = 2.45329 (* 1 = 2.45329 loss)
I0801 17:55:49.470929 12219 sgd_solver.cpp:136] Iteration 62000, lr = 0.080625, m = 0.9
I0801 17:56:03.525449 12219 solver.cpp:353] Iteration 62100 (7.11533 iter/s, 14.0542s/100 iter), loss = 2.18403
I0801 17:56:03.525483 12219 solver.cpp:375]     Train net output #0: loss = 2.23785 (* 1 = 2.23785 loss)
I0801 17:56:03.525490 12219 sgd_solver.cpp:136] Iteration 62100, lr = 0.0805938, m = 0.9
I0801 17:56:17.502287 12219 solver.cpp:353] Iteration 62200 (7.15489 iter/s, 13.9764s/100 iter), loss = 2.0743
I0801 17:56:17.502326 12219 solver.cpp:375]     Train net output #0: loss = 2.09716 (* 1 = 2.09716 loss)
I0801 17:56:17.502333 12219 sgd_solver.cpp:136] Iteration 62200, lr = 0.0805625, m = 0.9
I0801 17:56:31.540848 12219 solver.cpp:353] Iteration 62300 (7.12344 iter/s, 14.0382s/100 iter), loss = 2.32662
I0801 17:56:31.540953 12219 solver.cpp:375]     Train net output #0: loss = 2.78146 (* 1 = 2.78146 loss)
I0801 17:56:31.540966 12219 sgd_solver.cpp:136] Iteration 62300, lr = 0.0805313, m = 0.9
I0801 17:56:45.676928 12219 solver.cpp:353] Iteration 62400 (7.07429 iter/s, 14.1357s/100 iter), loss = 2.30411
I0801 17:56:45.676980 12219 solver.cpp:375]     Train net output #0: loss = 2.16567 (* 1 = 2.16567 loss)
I0801 17:56:45.676992 12219 sgd_solver.cpp:136] Iteration 62400, lr = 0.0805, m = 0.9
I0801 17:56:59.702438 12219 solver.cpp:353] Iteration 62500 (7.13007 iter/s, 14.0251s/100 iter), loss = 2.46153
I0801 17:56:59.702476 12219 solver.cpp:375]     Train net output #0: loss = 2.485 (* 1 = 2.485 loss)
I0801 17:56:59.702481 12219 sgd_solver.cpp:136] Iteration 62500, lr = 0.0804688, m = 0.9
I0801 17:57:13.941596 12219 solver.cpp:353] Iteration 62600 (7.02308 iter/s, 14.2388s/100 iter), loss = 2.19719
I0801 17:57:13.941653 12219 solver.cpp:375]     Train net output #0: loss = 2.06537 (* 1 = 2.06537 loss)
I0801 17:57:13.941659 12219 sgd_solver.cpp:136] Iteration 62600, lr = 0.0804375, m = 0.9
I0801 17:57:28.045738 12219 solver.cpp:353] Iteration 62700 (7.09031 iter/s, 14.1038s/100 iter), loss = 1.88102
I0801 17:57:28.045763 12219 solver.cpp:375]     Train net output #0: loss = 2.18117 (* 1 = 2.18117 loss)
I0801 17:57:28.045768 12219 sgd_solver.cpp:136] Iteration 62700, lr = 0.0804062, m = 0.9
I0801 17:57:41.961951 12219 solver.cpp:353] Iteration 62800 (7.18606 iter/s, 13.9158s/100 iter), loss = 2.35876
I0801 17:57:41.961977 12219 solver.cpp:375]     Train net output #0: loss = 2.49472 (* 1 = 2.49472 loss)
I0801 17:57:41.961980 12219 sgd_solver.cpp:136] Iteration 62800, lr = 0.080375, m = 0.9
I0801 17:57:56.107194 12219 solver.cpp:353] Iteration 62900 (7.06971 iter/s, 14.1448s/100 iter), loss = 2.27537
I0801 17:57:56.107256 12219 solver.cpp:375]     Train net output #0: loss = 2.1641 (* 1 = 2.1641 loss)
I0801 17:57:56.107264 12219 sgd_solver.cpp:136] Iteration 62900, lr = 0.0803437, m = 0.9
I0801 17:58:10.205363 12219 solver.cpp:353] Iteration 63000 (7.09332 iter/s, 14.0978s/100 iter), loss = 2.59653
I0801 17:58:10.205389 12219 solver.cpp:375]     Train net output #0: loss = 2.11485 (* 1 = 2.11485 loss)
I0801 17:58:10.205394 12219 sgd_solver.cpp:136] Iteration 63000, lr = 0.0803125, m = 0.9
I0801 17:58:24.191833 12219 solver.cpp:353] Iteration 63100 (7.14997 iter/s, 13.9861s/100 iter), loss = 2.42182
I0801 17:58:24.191862 12219 solver.cpp:375]     Train net output #0: loss = 2.09093 (* 1 = 2.09093 loss)
I0801 17:58:24.191869 12219 sgd_solver.cpp:136] Iteration 63100, lr = 0.0802813, m = 0.9
I0801 17:58:38.234774 12219 solver.cpp:353] Iteration 63200 (7.12121 iter/s, 14.0426s/100 iter), loss = 2.12756
I0801 17:58:38.234836 12219 solver.cpp:375]     Train net output #0: loss = 2.20692 (* 1 = 2.20692 loss)
I0801 17:58:38.234843 12219 sgd_solver.cpp:136] Iteration 63200, lr = 0.08025, m = 0.9
I0801 17:58:52.188446 12219 solver.cpp:353] Iteration 63300 (7.16677 iter/s, 13.9533s/100 iter), loss = 2.23747
I0801 17:58:52.188475 12219 solver.cpp:375]     Train net output #0: loss = 2.12466 (* 1 = 2.12466 loss)
I0801 17:58:52.188480 12219 sgd_solver.cpp:136] Iteration 63300, lr = 0.0802188, m = 0.9
I0801 17:59:06.300263 12219 solver.cpp:353] Iteration 63400 (7.08646 iter/s, 14.1114s/100 iter), loss = 2.11935
I0801 17:59:06.300293 12219 solver.cpp:375]     Train net output #0: loss = 2.40079 (* 1 = 2.40079 loss)
I0801 17:59:06.300299 12219 sgd_solver.cpp:136] Iteration 63400, lr = 0.0801875, m = 0.9
I0801 17:59:20.391422 12219 solver.cpp:353] Iteration 63500 (7.09684 iter/s, 14.0908s/100 iter), loss = 2.0959
I0801 17:59:20.391512 12219 solver.cpp:375]     Train net output #0: loss = 1.81584 (* 1 = 1.81584 loss)
I0801 17:59:20.391520 12219 sgd_solver.cpp:136] Iteration 63500, lr = 0.0801563, m = 0.9
I0801 17:59:34.360096 12219 solver.cpp:353] Iteration 63600 (7.15907 iter/s, 13.9683s/100 iter), loss = 2.45417
I0801 17:59:34.360188 12219 solver.cpp:375]     Train net output #0: loss = 2.42826 (* 1 = 2.42826 loss)
I0801 17:59:34.360206 12219 sgd_solver.cpp:136] Iteration 63600, lr = 0.080125, m = 0.9
I0801 17:59:48.363975 12219 solver.cpp:353] Iteration 63700 (7.14108 iter/s, 14.0035s/100 iter), loss = 2.22236
I0801 17:59:48.364001 12219 solver.cpp:375]     Train net output #0: loss = 2.29794 (* 1 = 2.29794 loss)
I0801 17:59:48.364006 12219 sgd_solver.cpp:136] Iteration 63700, lr = 0.0800938, m = 0.9
I0801 18:00:02.293334 12219 solver.cpp:353] Iteration 63800 (7.17928 iter/s, 13.929s/100 iter), loss = 2.08035
I0801 18:00:02.293391 12219 solver.cpp:375]     Train net output #0: loss = 2.19914 (* 1 = 2.19914 loss)
I0801 18:00:02.293398 12219 sgd_solver.cpp:136] Iteration 63800, lr = 0.0800625, m = 0.9
I0801 18:00:16.290926 12219 solver.cpp:353] Iteration 63900 (7.14428 iter/s, 13.9972s/100 iter), loss = 2.46877
I0801 18:00:16.290951 12219 solver.cpp:375]     Train net output #0: loss = 2.44362 (* 1 = 2.44362 loss)
I0801 18:00:16.290956 12219 sgd_solver.cpp:136] Iteration 63900, lr = 0.0800313, m = 0.9
I0801 18:00:30.186789 12219 solver.cpp:550] Iteration 64000, Testing net (#0)
I0801 18:00:47.697475 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 18:00:50.364341 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.385941
I0801 18:00:50.364365 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.646117
I0801 18:00:50.364372 12219 solver.cpp:635]     Test net output #2: loss = 2.87277 (* 1 = 2.87277 loss)
I0801 18:00:50.364423 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1771s
I0801 18:00:50.510866 12219 solver.cpp:353] Iteration 64000 (2.92235 iter/s, 34.219s/100 iter), loss = 2.0863
I0801 18:00:50.510895 12219 solver.cpp:375]     Train net output #0: loss = 2.56052 (* 1 = 2.56052 loss)
I0801 18:00:50.510901 12219 sgd_solver.cpp:136] Iteration 64000, lr = 0.08, m = 0.9
I0801 18:01:04.577313 12219 solver.cpp:353] Iteration 64100 (7.10931 iter/s, 14.0661s/100 iter), loss = 2.43849
I0801 18:01:04.577340 12219 solver.cpp:375]     Train net output #0: loss = 2.03887 (* 1 = 2.03887 loss)
I0801 18:01:04.577345 12219 sgd_solver.cpp:136] Iteration 64100, lr = 0.0799688, m = 0.9
I0801 18:01:18.533315 12219 solver.cpp:353] Iteration 64200 (7.16558 iter/s, 13.9556s/100 iter), loss = 2.15401
I0801 18:01:18.533370 12219 solver.cpp:375]     Train net output #0: loss = 2.27609 (* 1 = 2.27609 loss)
I0801 18:01:18.533375 12219 sgd_solver.cpp:136] Iteration 64200, lr = 0.0799375, m = 0.9
I0801 18:01:32.505976 12219 solver.cpp:353] Iteration 64300 (7.15703 iter/s, 13.9723s/100 iter), loss = 2.53191
I0801 18:01:32.506006 12219 solver.cpp:375]     Train net output #0: loss = 2.7807 (* 1 = 2.7807 loss)
I0801 18:01:32.506013 12219 sgd_solver.cpp:136] Iteration 64300, lr = 0.0799062, m = 0.9
I0801 18:01:46.535991 12219 solver.cpp:353] Iteration 64400 (7.12777 iter/s, 14.0296s/100 iter), loss = 2.3276
I0801 18:01:46.536016 12219 solver.cpp:375]     Train net output #0: loss = 2.11871 (* 1 = 2.11871 loss)
I0801 18:01:46.536022 12219 sgd_solver.cpp:136] Iteration 64400, lr = 0.079875, m = 0.9
I0801 18:02:00.601320 12219 solver.cpp:353] Iteration 64500 (7.10988 iter/s, 14.0649s/100 iter), loss = 2.04345
I0801 18:02:00.601393 12219 solver.cpp:375]     Train net output #0: loss = 2.38102 (* 1 = 2.38102 loss)
I0801 18:02:00.601398 12219 sgd_solver.cpp:136] Iteration 64500, lr = 0.0798438, m = 0.9
I0801 18:02:14.553050 12219 solver.cpp:353] Iteration 64600 (7.16777 iter/s, 13.9513s/100 iter), loss = 2.68339
I0801 18:02:14.553076 12219 solver.cpp:375]     Train net output #0: loss = 2.66929 (* 1 = 2.66929 loss)
I0801 18:02:14.553081 12219 sgd_solver.cpp:136] Iteration 64600, lr = 0.0798125, m = 0.9
I0801 18:02:28.529214 12219 solver.cpp:353] Iteration 64700 (7.15524 iter/s, 13.9758s/100 iter), loss = 2.69951
I0801 18:02:28.529311 12219 solver.cpp:375]     Train net output #0: loss = 2.84799 (* 1 = 2.84799 loss)
I0801 18:02:28.529337 12219 sgd_solver.cpp:136] Iteration 64700, lr = 0.0797813, m = 0.9
I0801 18:02:42.636229 12219 solver.cpp:353] Iteration 64800 (7.08887 iter/s, 14.1066s/100 iter), loss = 2.81849
I0801 18:02:42.636304 12219 solver.cpp:375]     Train net output #0: loss = 2.77727 (* 1 = 2.77727 loss)
I0801 18:02:42.636312 12219 sgd_solver.cpp:136] Iteration 64800, lr = 0.07975, m = 0.9
I0801 18:02:56.703128 12219 solver.cpp:353] Iteration 64900 (7.10909 iter/s, 14.0665s/100 iter), loss = 2.1476
I0801 18:02:56.703152 12219 solver.cpp:375]     Train net output #0: loss = 2.06331 (* 1 = 2.06331 loss)
I0801 18:02:56.703156 12219 sgd_solver.cpp:136] Iteration 64900, lr = 0.0797188, m = 0.9
I0801 18:03:10.732095 12219 solver.cpp:353] Iteration 65000 (7.12831 iter/s, 14.0286s/100 iter), loss = 1.94563
I0801 18:03:10.732204 12219 solver.cpp:375]     Train net output #0: loss = 2.25814 (* 1 = 2.25814 loss)
I0801 18:03:10.732229 12219 sgd_solver.cpp:136] Iteration 65000, lr = 0.0796875, m = 0.9
I0801 18:03:24.698010 12219 solver.cpp:353] Iteration 65100 (7.16049 iter/s, 13.9655s/100 iter), loss = 1.89225
I0801 18:03:24.698071 12219 solver.cpp:375]     Train net output #0: loss = 2.0676 (* 1 = 2.0676 loss)
I0801 18:03:24.698076 12219 sgd_solver.cpp:136] Iteration 65100, lr = 0.0796563, m = 0.9
I0801 18:03:38.628543 12219 solver.cpp:353] Iteration 65200 (7.17868 iter/s, 13.9301s/100 iter), loss = 2.3777
I0801 18:03:38.628571 12219 solver.cpp:375]     Train net output #0: loss = 2.52812 (* 1 = 2.52812 loss)
I0801 18:03:38.628577 12219 sgd_solver.cpp:136] Iteration 65200, lr = 0.079625, m = 0.9
I0801 18:03:52.720768 12219 solver.cpp:353] Iteration 65300 (7.09631 iter/s, 14.0918s/100 iter), loss = 2.18131
I0801 18:03:52.720793 12219 solver.cpp:375]     Train net output #0: loss = 2.29285 (* 1 = 2.29285 loss)
I0801 18:03:52.720798 12219 sgd_solver.cpp:136] Iteration 65300, lr = 0.0795937, m = 0.9
I0801 18:04:06.765552 12219 solver.cpp:353] Iteration 65400 (7.12028 iter/s, 14.0444s/100 iter), loss = 2.08831
I0801 18:04:06.765604 12219 solver.cpp:375]     Train net output #0: loss = 2.35989 (* 1 = 2.35989 loss)
I0801 18:04:06.765609 12219 sgd_solver.cpp:136] Iteration 65400, lr = 0.0795625, m = 0.9
I0801 18:04:20.834657 12219 solver.cpp:353] Iteration 65500 (7.10798 iter/s, 14.0687s/100 iter), loss = 1.96368
I0801 18:04:20.834686 12219 solver.cpp:375]     Train net output #0: loss = 1.85526 (* 1 = 1.85526 loss)
I0801 18:04:20.834693 12219 sgd_solver.cpp:136] Iteration 65500, lr = 0.0795313, m = 0.9
I0801 18:04:34.806885 12219 solver.cpp:353] Iteration 65600 (7.15725 iter/s, 13.9718s/100 iter), loss = 2.11703
I0801 18:04:34.806908 12219 solver.cpp:375]     Train net output #0: loss = 1.73972 (* 1 = 1.73972 loss)
I0801 18:04:34.806913 12219 sgd_solver.cpp:136] Iteration 65600, lr = 0.0795, m = 0.9
I0801 18:04:48.750138 12219 solver.cpp:353] Iteration 65700 (7.17213 iter/s, 13.9429s/100 iter), loss = 2.2355
I0801 18:04:48.750197 12219 solver.cpp:375]     Train net output #0: loss = 2.23507 (* 1 = 2.23507 loss)
I0801 18:04:48.750202 12219 sgd_solver.cpp:136] Iteration 65700, lr = 0.0794687, m = 0.9
I0801 18:05:02.678053 12219 solver.cpp:353] Iteration 65800 (7.18002 iter/s, 13.9275s/100 iter), loss = 2.2831
I0801 18:05:02.678082 12219 solver.cpp:375]     Train net output #0: loss = 1.98159 (* 1 = 1.98159 loss)
I0801 18:05:02.678087 12219 sgd_solver.cpp:136] Iteration 65800, lr = 0.0794375, m = 0.9
I0801 18:05:16.647740 12219 solver.cpp:353] Iteration 65900 (7.15855 iter/s, 13.9693s/100 iter), loss = 2.40288
I0801 18:05:16.647768 12219 solver.cpp:375]     Train net output #0: loss = 2.77195 (* 1 = 2.77195 loss)
I0801 18:05:16.647773 12219 sgd_solver.cpp:136] Iteration 65900, lr = 0.0794063, m = 0.9
I0801 18:05:30.494827 12219 solver.cpp:550] Iteration 66000, Testing net (#0)
I0801 18:05:50.390436 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.382999
I0801 18:05:50.390460 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.644882
I0801 18:05:50.390465 12219 solver.cpp:635]     Test net output #2: loss = 2.88733 (* 1 = 2.88733 loss)
I0801 18:05:50.390496 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8951s
I0801 18:05:50.538597 12219 solver.cpp:353] Iteration 66000 (2.95073 iter/s, 33.8899s/100 iter), loss = 2.30091
I0801 18:05:50.538625 12219 solver.cpp:375]     Train net output #0: loss = 2.58747 (* 1 = 2.58747 loss)
I0801 18:05:50.538630 12219 sgd_solver.cpp:136] Iteration 66000, lr = 0.079375, m = 0.9
I0801 18:06:04.596781 12219 solver.cpp:353] Iteration 66100 (7.11349 iter/s, 14.0578s/100 iter), loss = 2.0813
I0801 18:06:04.596873 12219 solver.cpp:375]     Train net output #0: loss = 1.89269 (* 1 = 1.89269 loss)
I0801 18:06:04.596880 12219 sgd_solver.cpp:136] Iteration 66100, lr = 0.0793438, m = 0.9
I0801 18:06:18.599849 12219 solver.cpp:353] Iteration 66200 (7.14149 iter/s, 14.0027s/100 iter), loss = 2.25964
I0801 18:06:18.599877 12219 solver.cpp:375]     Train net output #0: loss = 2.74935 (* 1 = 2.74935 loss)
I0801 18:06:18.599881 12219 sgd_solver.cpp:136] Iteration 66200, lr = 0.0793125, m = 0.9
I0801 18:06:32.506422 12219 solver.cpp:353] Iteration 66300 (7.19104 iter/s, 13.9062s/100 iter), loss = 2.56025
I0801 18:06:32.506449 12219 solver.cpp:375]     Train net output #0: loss = 2.57838 (* 1 = 2.57838 loss)
I0801 18:06:32.506455 12219 sgd_solver.cpp:136] Iteration 66300, lr = 0.0792812, m = 0.9
I0801 18:06:46.543278 12219 solver.cpp:353] Iteration 66400 (7.1243 iter/s, 14.0365s/100 iter), loss = 1.94551
I0801 18:06:46.543339 12219 solver.cpp:375]     Train net output #0: loss = 2.11791 (* 1 = 2.11791 loss)
I0801 18:06:46.543345 12219 sgd_solver.cpp:136] Iteration 66400, lr = 0.07925, m = 0.9
I0801 18:07:00.446864 12219 solver.cpp:353] Iteration 66500 (7.19259 iter/s, 13.9032s/100 iter), loss = 2.42274
I0801 18:07:00.446893 12219 solver.cpp:375]     Train net output #0: loss = 2.53643 (* 1 = 2.53643 loss)
I0801 18:07:00.446899 12219 sgd_solver.cpp:136] Iteration 66500, lr = 0.0792188, m = 0.9
I0801 18:07:14.572623 12219 solver.cpp:353] Iteration 66600 (7.07946 iter/s, 14.1254s/100 iter), loss = 2.03447
I0801 18:07:14.572650 12219 solver.cpp:375]     Train net output #0: loss = 2.1305 (* 1 = 2.1305 loss)
I0801 18:07:14.572657 12219 sgd_solver.cpp:136] Iteration 66600, lr = 0.0791875, m = 0.9
I0801 18:07:28.687397 12219 solver.cpp:353] Iteration 66700 (7.08497 iter/s, 14.1144s/100 iter), loss = 2.39509
I0801 18:07:28.687450 12219 solver.cpp:375]     Train net output #0: loss = 2.4272 (* 1 = 2.4272 loss)
I0801 18:07:28.687455 12219 sgd_solver.cpp:136] Iteration 66700, lr = 0.0791562, m = 0.9
I0801 18:07:42.762075 12219 solver.cpp:353] Iteration 66800 (7.10515 iter/s, 14.0743s/100 iter), loss = 1.83169
I0801 18:07:42.762104 12219 solver.cpp:375]     Train net output #0: loss = 1.83249 (* 1 = 1.83249 loss)
I0801 18:07:42.762109 12219 sgd_solver.cpp:136] Iteration 66800, lr = 0.079125, m = 0.9
I0801 18:07:56.751123 12219 solver.cpp:353] Iteration 66900 (7.14865 iter/s, 13.9887s/100 iter), loss = 2.20827
I0801 18:07:56.751153 12219 solver.cpp:375]     Train net output #0: loss = 2.27342 (* 1 = 2.27342 loss)
I0801 18:07:56.751158 12219 sgd_solver.cpp:136] Iteration 66900, lr = 0.0790937, m = 0.9
I0801 18:08:10.790637 12219 solver.cpp:353] Iteration 67000 (7.12295 iter/s, 14.0391s/100 iter), loss = 2.1863
I0801 18:08:10.791785 12219 solver.cpp:375]     Train net output #0: loss = 2.31966 (* 1 = 2.31966 loss)
I0801 18:08:10.791792 12219 sgd_solver.cpp:136] Iteration 67000, lr = 0.0790625, m = 0.9
I0801 18:08:24.822687 12219 solver.cpp:353] Iteration 67100 (7.12674 iter/s, 14.0317s/100 iter), loss = 2.1098
I0801 18:08:24.822711 12219 solver.cpp:375]     Train net output #0: loss = 1.98864 (* 1 = 1.98864 loss)
I0801 18:08:24.822715 12219 sgd_solver.cpp:136] Iteration 67100, lr = 0.0790313, m = 0.9
I0801 18:08:38.990811 12219 solver.cpp:353] Iteration 67200 (7.0583 iter/s, 14.1677s/100 iter), loss = 2.08314
I0801 18:08:38.990919 12219 solver.cpp:375]     Train net output #0: loss = 2.4431 (* 1 = 2.4431 loss)
I0801 18:08:38.990942 12219 sgd_solver.cpp:136] Iteration 67200, lr = 0.079, m = 0.9
I0801 18:08:53.005771 12219 solver.cpp:353] Iteration 67300 (7.13543 iter/s, 14.0146s/100 iter), loss = 2.01734
I0801 18:08:53.005849 12219 solver.cpp:375]     Train net output #0: loss = 1.89918 (* 1 = 1.89918 loss)
I0801 18:08:53.005856 12219 sgd_solver.cpp:136] Iteration 67300, lr = 0.0789688, m = 0.9
I0801 18:09:06.997319 12219 solver.cpp:353] Iteration 67400 (7.14737 iter/s, 13.9912s/100 iter), loss = 2.08205
I0801 18:09:06.997349 12219 solver.cpp:375]     Train net output #0: loss = 2.0496 (* 1 = 2.0496 loss)
I0801 18:09:06.997354 12219 sgd_solver.cpp:136] Iteration 67400, lr = 0.0789375, m = 0.9
I0801 18:09:20.920859 12219 solver.cpp:353] Iteration 67500 (7.18228 iter/s, 13.9232s/100 iter), loss = 2.08452
I0801 18:09:20.920887 12219 solver.cpp:375]     Train net output #0: loss = 1.89557 (* 1 = 1.89557 loss)
I0801 18:09:20.920893 12219 sgd_solver.cpp:136] Iteration 67500, lr = 0.0789063, m = 0.9
I0801 18:09:34.885799 12219 solver.cpp:353] Iteration 67600 (7.16099 iter/s, 13.9646s/100 iter), loss = 1.95208
I0801 18:09:34.885917 12219 solver.cpp:375]     Train net output #0: loss = 1.92716 (* 1 = 1.92716 loss)
I0801 18:09:34.885937 12219 sgd_solver.cpp:136] Iteration 67600, lr = 0.078875, m = 0.9
I0801 18:09:48.942670 12219 solver.cpp:353] Iteration 67700 (7.11415 iter/s, 14.0565s/100 iter), loss = 1.95749
I0801 18:09:48.942694 12219 solver.cpp:375]     Train net output #0: loss = 1.89737 (* 1 = 1.89737 loss)
I0801 18:09:48.942699 12219 sgd_solver.cpp:136] Iteration 67700, lr = 0.0788438, m = 0.9
I0801 18:10:02.934962 12219 solver.cpp:353] Iteration 67800 (7.14699 iter/s, 13.9919s/100 iter), loss = 2.09017
I0801 18:10:02.934988 12219 solver.cpp:375]     Train net output #0: loss = 2.19363 (* 1 = 2.19363 loss)
I0801 18:10:02.934993 12219 sgd_solver.cpp:136] Iteration 67800, lr = 0.0788125, m = 0.9
I0801 18:10:16.980909 12219 solver.cpp:353] Iteration 67900 (7.11969 iter/s, 14.0456s/100 iter), loss = 2.21869
I0801 18:10:16.981032 12219 solver.cpp:375]     Train net output #0: loss = 2.30044 (* 1 = 2.30044 loss)
I0801 18:10:16.981053 12219 sgd_solver.cpp:136] Iteration 67900, lr = 0.0787812, m = 0.9
I0801 18:10:30.749395 12219 solver.cpp:550] Iteration 68000, Testing net (#0)
I0801 18:10:51.017913 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.389823
I0801 18:10:51.018023 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.643293
I0801 18:10:51.018034 12219 solver.cpp:635]     Test net output #2: loss = 2.8748 (* 1 = 2.8748 loss)
I0801 18:10:51.018056 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2681s
I0801 18:10:51.159750 12219 solver.cpp:353] Iteration 68000 (2.92587 iter/s, 34.1779s/100 iter), loss = 2.5035
I0801 18:10:51.159824 12219 solver.cpp:375]     Train net output #0: loss = 2.21111 (* 1 = 2.21111 loss)
I0801 18:10:51.159842 12219 sgd_solver.cpp:136] Iteration 68000, lr = 0.07875, m = 0.9
I0801 18:11:05.163431 12219 solver.cpp:353] Iteration 68100 (7.14118 iter/s, 14.0033s/100 iter), loss = 2.31713
I0801 18:11:05.163455 12219 solver.cpp:375]     Train net output #0: loss = 2.13835 (* 1 = 2.13835 loss)
I0801 18:11:05.163460 12219 sgd_solver.cpp:136] Iteration 68100, lr = 0.0787188, m = 0.9
I0801 18:11:19.146378 12219 solver.cpp:353] Iteration 68200 (7.15177 iter/s, 13.9826s/100 iter), loss = 2.07143
I0801 18:11:19.146402 12219 solver.cpp:375]     Train net output #0: loss = 1.87971 (* 1 = 1.87971 loss)
I0801 18:11:19.146407 12219 sgd_solver.cpp:136] Iteration 68200, lr = 0.0786875, m = 0.9
I0801 18:11:33.109766 12219 solver.cpp:353] Iteration 68300 (7.16178 iter/s, 13.963s/100 iter), loss = 2.79504
I0801 18:11:33.109833 12219 solver.cpp:375]     Train net output #0: loss = 2.79238 (* 1 = 2.79238 loss)
I0801 18:11:33.109841 12219 sgd_solver.cpp:136] Iteration 68300, lr = 0.0786562, m = 0.9
I0801 18:11:47.189539 12219 solver.cpp:353] Iteration 68400 (7.10259 iter/s, 14.0794s/100 iter), loss = 2.36261
I0801 18:11:47.189568 12219 solver.cpp:375]     Train net output #0: loss = 2.41564 (* 1 = 2.41564 loss)
I0801 18:11:47.189575 12219 sgd_solver.cpp:136] Iteration 68400, lr = 0.078625, m = 0.9
I0801 18:12:01.149318 12219 solver.cpp:353] Iteration 68500 (7.16364 iter/s, 13.9594s/100 iter), loss = 2.25763
I0801 18:12:01.149343 12219 solver.cpp:375]     Train net output #0: loss = 2.63724 (* 1 = 2.63724 loss)
I0801 18:12:01.149349 12219 sgd_solver.cpp:136] Iteration 68500, lr = 0.0785938, m = 0.9
I0801 18:12:15.224112 12219 solver.cpp:353] Iteration 68600 (7.1051 iter/s, 14.0744s/100 iter), loss = 1.83139
I0801 18:12:15.224251 12219 solver.cpp:375]     Train net output #0: loss = 1.80568 (* 1 = 1.80568 loss)
I0801 18:12:15.224273 12219 sgd_solver.cpp:136] Iteration 68600, lr = 0.0785625, m = 0.9
I0801 18:12:29.246966 12219 solver.cpp:353] Iteration 68700 (7.13141 iter/s, 14.0225s/100 iter), loss = 1.99227
I0801 18:12:29.246995 12219 solver.cpp:375]     Train net output #0: loss = 1.99908 (* 1 = 1.99908 loss)
I0801 18:12:29.247001 12219 sgd_solver.cpp:136] Iteration 68700, lr = 0.0785313, m = 0.9
I0801 18:12:43.330255 12219 solver.cpp:353] Iteration 68800 (7.10081 iter/s, 14.0829s/100 iter), loss = 1.86266
I0801 18:12:43.330286 12219 solver.cpp:375]     Train net output #0: loss = 1.9028 (* 1 = 1.9028 loss)
I0801 18:12:43.330293 12219 sgd_solver.cpp:136] Iteration 68800, lr = 0.0785, m = 0.9
I0801 18:12:57.321535 12219 solver.cpp:353] Iteration 68900 (7.14751 iter/s, 13.9909s/100 iter), loss = 1.77296
I0801 18:12:57.321729 12219 solver.cpp:375]     Train net output #0: loss = 2.21016 (* 1 = 2.21016 loss)
I0801 18:12:57.321760 12219 sgd_solver.cpp:136] Iteration 68900, lr = 0.0784688, m = 0.9
I0801 18:13:11.408716 12219 solver.cpp:353] Iteration 69000 (7.09885 iter/s, 14.0868s/100 iter), loss = 2.45165
I0801 18:13:11.408745 12219 solver.cpp:375]     Train net output #0: loss = 2.40778 (* 1 = 2.40778 loss)
I0801 18:13:11.408751 12219 sgd_solver.cpp:136] Iteration 69000, lr = 0.0784375, m = 0.9
I0801 18:13:25.383800 12219 solver.cpp:353] Iteration 69100 (7.15579 iter/s, 13.9747s/100 iter), loss = 2.23165
I0801 18:13:25.383829 12219 solver.cpp:375]     Train net output #0: loss = 2.55687 (* 1 = 2.55687 loss)
I0801 18:13:25.383834 12219 sgd_solver.cpp:136] Iteration 69100, lr = 0.0784063, m = 0.9
I0801 18:13:39.471974 12219 solver.cpp:353] Iteration 69200 (7.09835 iter/s, 14.0878s/100 iter), loss = 2.16986
I0801 18:13:39.472039 12219 solver.cpp:375]     Train net output #0: loss = 1.65321 (* 1 = 1.65321 loss)
I0801 18:13:39.472045 12219 sgd_solver.cpp:136] Iteration 69200, lr = 0.078375, m = 0.9
I0801 18:13:53.425279 12219 solver.cpp:353] Iteration 69300 (7.16697 iter/s, 13.9529s/100 iter), loss = 2.32411
I0801 18:13:53.425309 12219 solver.cpp:375]     Train net output #0: loss = 1.9883 (* 1 = 1.9883 loss)
I0801 18:13:53.425315 12219 sgd_solver.cpp:136] Iteration 69300, lr = 0.0783437, m = 0.9
I0801 18:14:07.389101 12219 solver.cpp:353] Iteration 69400 (7.16156 iter/s, 13.9634s/100 iter), loss = 2.43532
I0801 18:14:07.389130 12219 solver.cpp:375]     Train net output #0: loss = 1.73555 (* 1 = 1.73555 loss)
I0801 18:14:07.389137 12219 sgd_solver.cpp:136] Iteration 69400, lr = 0.0783125, m = 0.9
I0801 18:14:21.515583 12219 solver.cpp:353] Iteration 69500 (7.0791 iter/s, 14.1261s/100 iter), loss = 2.22263
I0801 18:14:21.515669 12219 solver.cpp:375]     Train net output #0: loss = 2.24748 (* 1 = 2.24748 loss)
I0801 18:14:21.515681 12219 sgd_solver.cpp:136] Iteration 69500, lr = 0.0782812, m = 0.9
I0801 18:14:35.584039 12219 solver.cpp:353] Iteration 69600 (7.10829 iter/s, 14.0681s/100 iter), loss = 1.81808
I0801 18:14:35.584311 12219 solver.cpp:375]     Train net output #0: loss = 1.97436 (* 1 = 1.97436 loss)
I0801 18:14:35.584425 12219 sgd_solver.cpp:136] Iteration 69600, lr = 0.07825, m = 0.9
I0801 18:14:49.585662 12219 solver.cpp:353] Iteration 69700 (7.14223 iter/s, 14.0012s/100 iter), loss = 2.20265
I0801 18:14:49.585690 12219 solver.cpp:375]     Train net output #0: loss = 1.88117 (* 1 = 1.88117 loss)
I0801 18:14:49.585697 12219 sgd_solver.cpp:136] Iteration 69700, lr = 0.0782188, m = 0.9
I0801 18:15:03.511997 12219 solver.cpp:353] Iteration 69800 (7.18084 iter/s, 13.926s/100 iter), loss = 2.49263
I0801 18:15:03.512114 12219 solver.cpp:375]     Train net output #0: loss = 2.71989 (* 1 = 2.71989 loss)
I0801 18:15:03.512120 12219 sgd_solver.cpp:136] Iteration 69800, lr = 0.0781875, m = 0.9
I0801 18:15:17.534085 12219 solver.cpp:353] Iteration 69900 (7.1318 iter/s, 14.0217s/100 iter), loss = 1.70984
I0801 18:15:17.534113 12219 solver.cpp:375]     Train net output #0: loss = 2.06391 (* 1 = 2.06391 loss)
I0801 18:15:17.534119 12219 sgd_solver.cpp:136] Iteration 69900, lr = 0.0781563, m = 0.9
I0801 18:15:31.450007 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_70000.caffemodel
I0801 18:15:31.607589 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_70000.solverstate
I0801 18:15:31.615147 12219 solver.cpp:550] Iteration 70000, Testing net (#0)
I0801 18:15:51.556506 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.401058
I0801 18:15:51.556622 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.669293
I0801 18:15:51.556632 12219 solver.cpp:635]     Test net output #2: loss = 2.76344 (* 1 = 2.76344 loss)
I0801 18:15:51.556651 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.941s
I0801 18:15:51.695628 12219 solver.cpp:353] Iteration 70000 (2.92735 iter/s, 34.1606s/100 iter), loss = 2.04831
I0801 18:15:51.695655 12219 solver.cpp:375]     Train net output #0: loss = 2.12126 (* 1 = 2.12126 loss)
I0801 18:15:51.695659 12219 sgd_solver.cpp:136] Iteration 70000, lr = 0.078125, m = 0.9
I0801 18:16:05.816012 12219 solver.cpp:353] Iteration 70100 (7.08217 iter/s, 14.12s/100 iter), loss = 2.38875
I0801 18:16:05.816043 12219 solver.cpp:375]     Train net output #0: loss = 2.30484 (* 1 = 2.30484 loss)
I0801 18:16:05.816049 12219 sgd_solver.cpp:136] Iteration 70100, lr = 0.0780938, m = 0.9
I0801 18:16:19.757674 12219 solver.cpp:353] Iteration 70200 (7.17294 iter/s, 13.9413s/100 iter), loss = 2.03824
I0801 18:16:19.757700 12219 solver.cpp:375]     Train net output #0: loss = 2.2752 (* 1 = 2.2752 loss)
I0801 18:16:19.757705 12219 sgd_solver.cpp:136] Iteration 70200, lr = 0.0780625, m = 0.9
I0801 18:16:33.742719 12219 solver.cpp:353] Iteration 70300 (7.1507 iter/s, 13.9847s/100 iter), loss = 2.25565
I0801 18:16:33.742842 12219 solver.cpp:375]     Train net output #0: loss = 1.7761 (* 1 = 1.7761 loss)
I0801 18:16:33.742848 12219 sgd_solver.cpp:136] Iteration 70300, lr = 0.0780312, m = 0.9
I0801 18:16:47.797081 12219 solver.cpp:353] Iteration 70400 (7.11543 iter/s, 14.054s/100 iter), loss = 1.93486
I0801 18:16:47.797125 12219 solver.cpp:375]     Train net output #0: loss = 1.8714 (* 1 = 1.8714 loss)
I0801 18:16:47.797132 12219 sgd_solver.cpp:136] Iteration 70400, lr = 0.078, m = 0.9
I0801 18:17:01.818660 12219 solver.cpp:353] Iteration 70500 (7.13206 iter/s, 14.0212s/100 iter), loss = 1.81444
I0801 18:17:01.818894 12219 solver.cpp:375]     Train net output #0: loss = 1.85329 (* 1 = 1.85329 loss)
I0801 18:17:01.819016 12219 sgd_solver.cpp:136] Iteration 70500, lr = 0.0779688, m = 0.9
I0801 18:17:15.740645 12219 solver.cpp:353] Iteration 70600 (7.18308 iter/s, 13.9216s/100 iter), loss = 2.71985
I0801 18:17:15.740737 12219 solver.cpp:375]     Train net output #0: loss = 2.50384 (* 1 = 2.50384 loss)
I0801 18:17:15.740756 12219 sgd_solver.cpp:136] Iteration 70600, lr = 0.0779375, m = 0.9
I0801 18:17:29.637723 12219 solver.cpp:353] Iteration 70700 (7.19596 iter/s, 13.8967s/100 iter), loss = 2.49141
I0801 18:17:29.637744 12219 solver.cpp:375]     Train net output #0: loss = 2.20187 (* 1 = 2.20187 loss)
I0801 18:17:29.637749 12219 sgd_solver.cpp:136] Iteration 70700, lr = 0.0779063, m = 0.9
I0801 18:17:41.798977 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 18:17:43.755283 12219 solver.cpp:353] Iteration 70800 (7.08357 iter/s, 14.1172s/100 iter), loss = 2.2699
I0801 18:17:43.755311 12219 solver.cpp:375]     Train net output #0: loss = 2.09642 (* 1 = 2.09642 loss)
I0801 18:17:43.755316 12219 sgd_solver.cpp:136] Iteration 70800, lr = 0.077875, m = 0.9
I0801 18:17:57.772850 12219 solver.cpp:353] Iteration 70900 (7.13411 iter/s, 14.0172s/100 iter), loss = 1.85372
I0801 18:17:57.776868 12219 solver.cpp:375]     Train net output #0: loss = 1.6092 (* 1 = 1.6092 loss)
I0801 18:17:57.776895 12219 sgd_solver.cpp:136] Iteration 70900, lr = 0.0778437, m = 0.9
I0801 18:18:11.860838 12219 solver.cpp:353] Iteration 71000 (7.09844 iter/s, 14.0876s/100 iter), loss = 1.66679
I0801 18:18:11.860863 12219 solver.cpp:375]     Train net output #0: loss = 1.70696 (* 1 = 1.70696 loss)
I0801 18:18:11.860869 12219 sgd_solver.cpp:136] Iteration 71000, lr = 0.0778125, m = 0.9
I0801 18:18:25.930132 12219 solver.cpp:353] Iteration 71100 (7.10787 iter/s, 14.0689s/100 iter), loss = 1.81586
I0801 18:18:25.930157 12219 solver.cpp:375]     Train net output #0: loss = 2.04499 (* 1 = 2.04499 loss)
I0801 18:18:25.930161 12219 sgd_solver.cpp:136] Iteration 71100, lr = 0.0777813, m = 0.9
I0801 18:18:39.886360 12219 solver.cpp:353] Iteration 71200 (7.16546 iter/s, 13.9558s/100 iter), loss = 2.08848
I0801 18:18:39.886441 12219 solver.cpp:375]     Train net output #0: loss = 1.8142 (* 1 = 1.8142 loss)
I0801 18:18:39.886447 12219 sgd_solver.cpp:136] Iteration 71200, lr = 0.07775, m = 0.9
I0801 18:18:53.831815 12219 solver.cpp:353] Iteration 71300 (7.17099 iter/s, 13.9451s/100 iter), loss = 1.89907
I0801 18:18:53.831842 12219 solver.cpp:375]     Train net output #0: loss = 1.99485 (* 1 = 1.99485 loss)
I0801 18:18:53.831848 12219 sgd_solver.cpp:136] Iteration 71300, lr = 0.0777187, m = 0.9
I0801 18:19:07.824854 12219 solver.cpp:353] Iteration 71400 (7.14661 iter/s, 13.9927s/100 iter), loss = 2.46088
I0801 18:19:07.824890 12219 solver.cpp:375]     Train net output #0: loss = 2.91588 (* 1 = 2.91588 loss)
I0801 18:19:07.824897 12219 sgd_solver.cpp:136] Iteration 71400, lr = 0.0776875, m = 0.9
I0801 18:19:21.872588 12219 solver.cpp:353] Iteration 71500 (7.11878 iter/s, 14.0473s/100 iter), loss = 1.99541
I0801 18:19:21.872671 12219 solver.cpp:375]     Train net output #0: loss = 1.98399 (* 1 = 1.98399 loss)
I0801 18:19:21.872678 12219 sgd_solver.cpp:136] Iteration 71500, lr = 0.0776563, m = 0.9
I0801 18:19:36.001746 12219 solver.cpp:353] Iteration 71600 (7.07776 iter/s, 14.1288s/100 iter), loss = 2.04426
I0801 18:19:36.001778 12219 solver.cpp:375]     Train net output #0: loss = 1.98598 (* 1 = 1.98598 loss)
I0801 18:19:36.001785 12219 sgd_solver.cpp:136] Iteration 71600, lr = 0.077625, m = 0.9
I0801 18:19:49.897655 12219 solver.cpp:353] Iteration 71700 (7.19656 iter/s, 13.8955s/100 iter), loss = 2.16888
I0801 18:19:49.897680 12219 solver.cpp:375]     Train net output #0: loss = 2.16251 (* 1 = 2.16251 loss)
I0801 18:19:49.897687 12219 sgd_solver.cpp:136] Iteration 71700, lr = 0.0775938, m = 0.9
I0801 18:20:03.852057 12219 solver.cpp:353] Iteration 71800 (7.16639 iter/s, 13.954s/100 iter), loss = 2.45979
I0801 18:20:03.852114 12219 solver.cpp:375]     Train net output #0: loss = 2.37305 (* 1 = 2.37305 loss)
I0801 18:20:03.852119 12219 sgd_solver.cpp:136] Iteration 71800, lr = 0.0775625, m = 0.9
I0801 18:20:17.861519 12219 solver.cpp:353] Iteration 71900 (7.13823 iter/s, 14.0091s/100 iter), loss = 2.43568
I0801 18:20:17.861549 12219 solver.cpp:375]     Train net output #0: loss = 2.27269 (* 1 = 2.27269 loss)
I0801 18:20:17.861555 12219 sgd_solver.cpp:136] Iteration 71900, lr = 0.0775312, m = 0.9
I0801 18:20:31.691148 12219 solver.cpp:550] Iteration 72000, Testing net (#0)
I0801 18:20:51.440336 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.406235
I0801 18:20:51.440389 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.664823
I0801 18:20:51.440395 12219 solver.cpp:635]     Test net output #2: loss = 2.78348 (* 1 = 2.78348 loss)
I0801 18:20:51.440443 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7488s
I0801 18:20:51.596319 12219 solver.cpp:353] Iteration 72000 (2.96438 iter/s, 33.7339s/100 iter), loss = 2.13623
I0801 18:20:51.596346 12219 solver.cpp:375]     Train net output #0: loss = 1.88008 (* 1 = 1.88008 loss)
I0801 18:20:51.596354 12219 sgd_solver.cpp:136] Iteration 72000, lr = 0.0775, m = 0.9
I0801 18:21:05.555097 12219 solver.cpp:353] Iteration 72100 (7.16415 iter/s, 13.9584s/100 iter), loss = 2.26014
I0801 18:21:05.555125 12219 solver.cpp:375]     Train net output #0: loss = 2.16562 (* 1 = 2.16562 loss)
I0801 18:21:05.555131 12219 sgd_solver.cpp:136] Iteration 72100, lr = 0.0774688, m = 0.9
I0801 18:21:19.571779 12219 solver.cpp:353] Iteration 72200 (7.13456 iter/s, 14.0163s/100 iter), loss = 2.10301
I0801 18:21:19.571832 12219 solver.cpp:375]     Train net output #0: loss = 2.0543 (* 1 = 2.0543 loss)
I0801 18:21:19.571868 12219 sgd_solver.cpp:136] Iteration 72200, lr = 0.0774375, m = 0.9
I0801 18:21:33.581991 12219 solver.cpp:353] Iteration 72300 (7.13785 iter/s, 14.0098s/100 iter), loss = 2.18872
I0801 18:21:33.582062 12219 solver.cpp:375]     Train net output #0: loss = 2.00348 (* 1 = 2.00348 loss)
I0801 18:21:33.582069 12219 sgd_solver.cpp:136] Iteration 72300, lr = 0.0774062, m = 0.9
I0801 18:21:47.530599 12219 solver.cpp:353] Iteration 72400 (7.16937 iter/s, 13.9482s/100 iter), loss = 2.31479
I0801 18:21:47.530627 12219 solver.cpp:375]     Train net output #0: loss = 2.45905 (* 1 = 2.45905 loss)
I0801 18:21:47.530630 12219 sgd_solver.cpp:136] Iteration 72400, lr = 0.077375, m = 0.9
I0801 18:22:01.431176 12219 solver.cpp:353] Iteration 72500 (7.19415 iter/s, 13.9002s/100 iter), loss = 2.01927
I0801 18:22:01.431238 12219 solver.cpp:375]     Train net output #0: loss = 2.08796 (* 1 = 2.08796 loss)
I0801 18:22:01.431257 12219 sgd_solver.cpp:136] Iteration 72500, lr = 0.0773438, m = 0.9
I0801 18:22:15.262698 12219 solver.cpp:353] Iteration 72600 (7.23006 iter/s, 13.8311s/100 iter), loss = 2.05575
I0801 18:22:15.262784 12219 solver.cpp:375]     Train net output #0: loss = 2.29806 (* 1 = 2.29806 loss)
I0801 18:22:15.262797 12219 sgd_solver.cpp:136] Iteration 72600, lr = 0.0773125, m = 0.9
I0801 18:22:29.343456 12219 solver.cpp:353] Iteration 72700 (7.1021 iter/s, 14.0804s/100 iter), loss = 2.28059
I0801 18:22:29.343487 12219 solver.cpp:375]     Train net output #0: loss = 2.10583 (* 1 = 2.10583 loss)
I0801 18:22:29.343493 12219 sgd_solver.cpp:136] Iteration 72700, lr = 0.0772813, m = 0.9
I0801 18:22:43.514223 12219 solver.cpp:353] Iteration 72800 (7.05698 iter/s, 14.1704s/100 iter), loss = 2.00221
I0801 18:22:43.514278 12219 solver.cpp:375]     Train net output #0: loss = 2.25191 (* 1 = 2.25191 loss)
I0801 18:22:43.514292 12219 sgd_solver.cpp:136] Iteration 72800, lr = 0.07725, m = 0.9
I0801 18:22:57.564007 12219 solver.cpp:353] Iteration 72900 (7.11774 iter/s, 14.0494s/100 iter), loss = 2.23168
I0801 18:22:57.564069 12219 solver.cpp:375]     Train net output #0: loss = 2.47809 (* 1 = 2.47809 loss)
I0801 18:22:57.564074 12219 sgd_solver.cpp:136] Iteration 72900, lr = 0.0772187, m = 0.9
I0801 18:23:11.563966 12219 solver.cpp:353] Iteration 73000 (7.14308 iter/s, 13.9996s/100 iter), loss = 2.05583
I0801 18:23:11.563995 12219 solver.cpp:375]     Train net output #0: loss = 2.26191 (* 1 = 2.26191 loss)
I0801 18:23:11.564002 12219 sgd_solver.cpp:136] Iteration 73000, lr = 0.0771875, m = 0.9
I0801 18:23:25.484501 12219 solver.cpp:353] Iteration 73100 (7.18384 iter/s, 13.9201s/100 iter), loss = 2.28049
I0801 18:23:25.484529 12219 solver.cpp:375]     Train net output #0: loss = 2.08425 (* 1 = 2.08425 loss)
I0801 18:23:25.484535 12219 sgd_solver.cpp:136] Iteration 73100, lr = 0.0771563, m = 0.9
I0801 18:23:39.556697 12219 solver.cpp:353] Iteration 73200 (7.10641 iter/s, 14.0718s/100 iter), loss = 2.03177
I0801 18:23:39.556754 12219 solver.cpp:375]     Train net output #0: loss = 2.10715 (* 1 = 2.10715 loss)
I0801 18:23:39.556761 12219 sgd_solver.cpp:136] Iteration 73200, lr = 0.077125, m = 0.9
I0801 18:23:53.585999 12219 solver.cpp:353] Iteration 73300 (7.12813 iter/s, 14.0289s/100 iter), loss = 1.85402
I0801 18:23:53.586025 12219 solver.cpp:375]     Train net output #0: loss = 1.84646 (* 1 = 1.84646 loss)
I0801 18:23:53.586030 12219 sgd_solver.cpp:136] Iteration 73300, lr = 0.0770938, m = 0.9
I0801 18:24:07.634327 12219 solver.cpp:353] Iteration 73400 (7.11848 iter/s, 14.0479s/100 iter), loss = 1.88886
I0801 18:24:07.634354 12219 solver.cpp:375]     Train net output #0: loss = 1.88079 (* 1 = 1.88079 loss)
I0801 18:24:07.634361 12219 sgd_solver.cpp:136] Iteration 73400, lr = 0.0770625, m = 0.9
I0801 18:24:21.683434 12219 solver.cpp:353] Iteration 73500 (7.11809 iter/s, 14.0487s/100 iter), loss = 2.36585
I0801 18:24:21.683498 12219 solver.cpp:375]     Train net output #0: loss = 2.08248 (* 1 = 2.08248 loss)
I0801 18:24:21.683506 12219 sgd_solver.cpp:136] Iteration 73500, lr = 0.0770312, m = 0.9
I0801 18:24:35.786124 12219 solver.cpp:353] Iteration 73600 (7.09104 iter/s, 14.1023s/100 iter), loss = 1.73558
I0801 18:24:35.786218 12219 solver.cpp:375]     Train net output #0: loss = 1.52158 (* 1 = 1.52158 loss)
I0801 18:24:35.786237 12219 sgd_solver.cpp:136] Iteration 73600, lr = 0.077, m = 0.9
I0801 18:24:49.800241 12219 solver.cpp:353] Iteration 73700 (7.13586 iter/s, 14.0137s/100 iter), loss = 2.25783
I0801 18:24:49.800267 12219 solver.cpp:375]     Train net output #0: loss = 2.46733 (* 1 = 2.46733 loss)
I0801 18:24:49.800309 12219 sgd_solver.cpp:136] Iteration 73700, lr = 0.0769688, m = 0.9
I0801 18:25:03.826524 12219 solver.cpp:353] Iteration 73800 (7.12967 iter/s, 14.0259s/100 iter), loss = 2.25276
I0801 18:25:03.826607 12219 solver.cpp:375]     Train net output #0: loss = 2.50858 (* 1 = 2.50858 loss)
I0801 18:25:03.826614 12219 sgd_solver.cpp:136] Iteration 73800, lr = 0.0769375, m = 0.9
I0801 18:25:17.980625 12219 solver.cpp:353] Iteration 73900 (7.06529 iter/s, 14.1537s/100 iter), loss = 2.05651
I0801 18:25:17.980700 12219 solver.cpp:375]     Train net output #0: loss = 2.02743 (* 1 = 2.02743 loss)
I0801 18:25:17.980720 12219 sgd_solver.cpp:136] Iteration 73900, lr = 0.0769063, m = 0.9
I0801 18:25:31.908409 12219 solver.cpp:550] Iteration 74000, Testing net (#0)
I0801 18:25:36.959498 12207 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 18:25:52.229598 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.403941
I0801 18:25:52.229622 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.670823
I0801 18:25:52.229629 12219 solver.cpp:635]     Test net output #2: loss = 2.7231 (* 1 = 2.7231 loss)
I0801 18:25:52.229650 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3207s
I0801 18:25:52.385198 12219 solver.cpp:353] Iteration 74000 (2.90667 iter/s, 34.4036s/100 iter), loss = 2.02596
I0801 18:25:52.385231 12219 solver.cpp:375]     Train net output #0: loss = 1.65785 (* 1 = 1.65785 loss)
I0801 18:25:52.385237 12219 sgd_solver.cpp:136] Iteration 74000, lr = 0.076875, m = 0.9
I0801 18:26:06.546025 12219 solver.cpp:353] Iteration 74100 (7.06193 iter/s, 14.1604s/100 iter), loss = 2.43551
I0801 18:26:06.546053 12219 solver.cpp:375]     Train net output #0: loss = 2.39387 (* 1 = 2.39387 loss)
I0801 18:26:06.546061 12219 sgd_solver.cpp:136] Iteration 74100, lr = 0.0768438, m = 0.9
I0801 18:26:20.556640 12219 solver.cpp:353] Iteration 74200 (7.13764 iter/s, 14.0102s/100 iter), loss = 2.43363
I0801 18:26:20.556701 12219 solver.cpp:375]     Train net output #0: loss = 2.50845 (* 1 = 2.50845 loss)
I0801 18:26:20.556707 12219 sgd_solver.cpp:136] Iteration 74200, lr = 0.0768125, m = 0.9
I0801 18:26:34.711594 12219 solver.cpp:353] Iteration 74300 (7.06486 iter/s, 14.1546s/100 iter), loss = 2.10095
I0801 18:26:34.711621 12219 solver.cpp:375]     Train net output #0: loss = 2.45561 (* 1 = 2.45561 loss)
I0801 18:26:34.711625 12219 sgd_solver.cpp:136] Iteration 74300, lr = 0.0767813, m = 0.9
I0801 18:26:48.682781 12219 solver.cpp:353] Iteration 74400 (7.15779 iter/s, 13.9708s/100 iter), loss = 1.85051
I0801 18:26:48.682833 12219 solver.cpp:375]     Train net output #0: loss = 1.77142 (* 1 = 1.77142 loss)
I0801 18:26:48.682845 12219 sgd_solver.cpp:136] Iteration 74400, lr = 0.07675, m = 0.9
I0801 18:27:02.815785 12219 solver.cpp:353] Iteration 74500 (7.07583 iter/s, 14.1326s/100 iter), loss = 2.32986
I0801 18:27:02.815856 12219 solver.cpp:375]     Train net output #0: loss = 2.87724 (* 1 = 2.87724 loss)
I0801 18:27:02.815863 12219 sgd_solver.cpp:136] Iteration 74500, lr = 0.0767187, m = 0.9
I0801 18:27:16.854391 12219 solver.cpp:353] Iteration 74600 (7.12341 iter/s, 14.0382s/100 iter), loss = 1.96036
I0801 18:27:16.854418 12219 solver.cpp:375]     Train net output #0: loss = 1.85777 (* 1 = 1.85777 loss)
I0801 18:27:16.854424 12219 sgd_solver.cpp:136] Iteration 74600, lr = 0.0766875, m = 0.9
I0801 18:27:30.866801 12219 solver.cpp:353] Iteration 74700 (7.13673 iter/s, 14.012s/100 iter), loss = 2.02806
I0801 18:27:30.866829 12219 solver.cpp:375]     Train net output #0: loss = 1.92957 (* 1 = 1.92957 loss)
I0801 18:27:30.866835 12219 sgd_solver.cpp:136] Iteration 74700, lr = 0.0766563, m = 0.9
I0801 18:27:45.068230 12219 solver.cpp:353] Iteration 74800 (7.04174 iter/s, 14.201s/100 iter), loss = 2.36319
I0801 18:27:45.068310 12219 solver.cpp:375]     Train net output #0: loss = 2.54767 (* 1 = 2.54767 loss)
I0801 18:27:45.068321 12219 sgd_solver.cpp:136] Iteration 74800, lr = 0.076625, m = 0.9
I0801 18:27:59.039321 12219 solver.cpp:353] Iteration 74900 (7.15783 iter/s, 13.9707s/100 iter), loss = 2.35359
I0801 18:27:59.039346 12219 solver.cpp:375]     Train net output #0: loss = 2.56572 (* 1 = 2.56572 loss)
I0801 18:27:59.039352 12219 sgd_solver.cpp:136] Iteration 74900, lr = 0.0765937, m = 0.9
I0801 18:28:13.089418 12219 solver.cpp:353] Iteration 75000 (7.11759 iter/s, 14.0497s/100 iter), loss = 1.89462
I0801 18:28:13.089485 12219 solver.cpp:375]     Train net output #0: loss = 1.84466 (* 1 = 1.84466 loss)
I0801 18:28:13.089504 12219 sgd_solver.cpp:136] Iteration 75000, lr = 0.0765625, m = 0.9
I0801 18:28:27.135720 12219 solver.cpp:353] Iteration 75100 (7.11951 iter/s, 14.0459s/100 iter), loss = 1.54318
I0801 18:28:27.135785 12219 solver.cpp:375]     Train net output #0: loss = 1.60316 (* 1 = 1.60316 loss)
I0801 18:28:27.135792 12219 sgd_solver.cpp:136] Iteration 75100, lr = 0.0765313, m = 0.9
I0801 18:28:41.185299 12219 solver.cpp:353] Iteration 75200 (7.11785 iter/s, 14.0492s/100 iter), loss = 2.19457
I0801 18:28:41.185326 12219 solver.cpp:375]     Train net output #0: loss = 2.17978 (* 1 = 2.17978 loss)
I0801 18:28:41.185331 12219 sgd_solver.cpp:136] Iteration 75200, lr = 0.0765, m = 0.9
I0801 18:28:55.245867 12219 solver.cpp:353] Iteration 75300 (7.11229 iter/s, 14.0602s/100 iter), loss = 2.1662
I0801 18:28:55.245896 12219 solver.cpp:375]     Train net output #0: loss = 2.52967 (* 1 = 2.52967 loss)
I0801 18:28:55.245901 12219 sgd_solver.cpp:136] Iteration 75300, lr = 0.0764688, m = 0.9
I0801 18:29:09.191660 12219 solver.cpp:353] Iteration 75400 (7.17082 iter/s, 13.9454s/100 iter), loss = 2.54666
I0801 18:29:09.191709 12219 solver.cpp:375]     Train net output #0: loss = 2.58844 (* 1 = 2.58844 loss)
I0801 18:29:09.191715 12219 sgd_solver.cpp:136] Iteration 75400, lr = 0.0764375, m = 0.9
I0801 18:29:23.231881 12219 solver.cpp:353] Iteration 75500 (7.12259 iter/s, 14.0398s/100 iter), loss = 2.10765
I0801 18:29:23.231911 12219 solver.cpp:375]     Train net output #0: loss = 2.3047 (* 1 = 2.3047 loss)
I0801 18:29:23.231916 12219 sgd_solver.cpp:136] Iteration 75500, lr = 0.0764063, m = 0.9
I0801 18:29:37.199425 12219 solver.cpp:353] Iteration 75600 (7.15965 iter/s, 13.9672s/100 iter), loss = 2.01665
I0801 18:29:37.199476 12219 solver.cpp:375]     Train net output #0: loss = 2.17749 (* 1 = 2.17749 loss)
I0801 18:29:37.199489 12219 sgd_solver.cpp:136] Iteration 75600, lr = 0.076375, m = 0.9
I0801 18:29:51.245725 12219 solver.cpp:353] Iteration 75700 (7.11951 iter/s, 14.0459s/100 iter), loss = 1.95238
I0801 18:29:51.245784 12219 solver.cpp:375]     Train net output #0: loss = 1.94082 (* 1 = 1.94082 loss)
I0801 18:29:51.245791 12219 sgd_solver.cpp:136] Iteration 75700, lr = 0.0763438, m = 0.9
I0801 18:30:05.413538 12219 solver.cpp:353] Iteration 75800 (7.05845 iter/s, 14.1674s/100 iter), loss = 1.94142
I0801 18:30:05.413563 12219 solver.cpp:375]     Train net output #0: loss = 2.08576 (* 1 = 2.08576 loss)
I0801 18:30:05.413568 12219 sgd_solver.cpp:136] Iteration 75800, lr = 0.0763125, m = 0.9
I0801 18:30:19.438474 12219 solver.cpp:353] Iteration 75900 (7.13036 iter/s, 14.0245s/100 iter), loss = 1.91718
I0801 18:30:19.438503 12219 solver.cpp:375]     Train net output #0: loss = 1.64129 (* 1 = 1.64129 loss)
I0801 18:30:19.438509 12219 sgd_solver.cpp:136] Iteration 75900, lr = 0.0762812, m = 0.9
I0801 18:30:33.316570 12219 solver.cpp:550] Iteration 76000, Testing net (#0)
I0801 18:30:53.807081 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.411529
I0801 18:30:53.807109 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.66247
I0801 18:30:53.807117 12219 solver.cpp:635]     Test net output #2: loss = 2.77804 (* 1 = 2.77804 loss)
I0801 18:30:53.807142 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.49s
I0801 18:30:53.962733 12219 solver.cpp:353] Iteration 76000 (2.89659 iter/s, 34.5233s/100 iter), loss = 2.23761
I0801 18:30:53.962759 12219 solver.cpp:375]     Train net output #0: loss = 2.11486 (* 1 = 2.11486 loss)
I0801 18:30:53.962764 12219 sgd_solver.cpp:136] Iteration 76000, lr = 0.07625, m = 0.9
I0801 18:31:08.072244 12219 solver.cpp:353] Iteration 76100 (7.08762 iter/s, 14.1091s/100 iter), loss = 1.90652
I0801 18:31:08.072304 12219 solver.cpp:375]     Train net output #0: loss = 1.67592 (* 1 = 1.67592 loss)
I0801 18:31:08.072310 12219 sgd_solver.cpp:136] Iteration 76100, lr = 0.0762187, m = 0.9
I0801 18:31:22.006494 12219 solver.cpp:353] Iteration 76200 (7.17676 iter/s, 13.9339s/100 iter), loss = 1.86891
I0801 18:31:22.006547 12219 solver.cpp:375]     Train net output #0: loss = 2.14046 (* 1 = 2.14046 loss)
I0801 18:31:22.006559 12219 sgd_solver.cpp:136] Iteration 76200, lr = 0.0761875, m = 0.9
I0801 18:31:35.974876 12219 solver.cpp:353] Iteration 76300 (7.15922 iter/s, 13.968s/100 iter), loss = 1.95013
I0801 18:31:35.974902 12219 solver.cpp:375]     Train net output #0: loss = 2.12532 (* 1 = 2.12532 loss)
I0801 18:31:35.974908 12219 sgd_solver.cpp:136] Iteration 76300, lr = 0.0761563, m = 0.9
I0801 18:31:50.001644 12219 solver.cpp:353] Iteration 76400 (7.12942 iter/s, 14.0264s/100 iter), loss = 1.84679
I0801 18:31:50.001744 12219 solver.cpp:375]     Train net output #0: loss = 1.76194 (* 1 = 1.76194 loss)
I0801 18:31:50.001757 12219 sgd_solver.cpp:136] Iteration 76400, lr = 0.076125, m = 0.9
I0801 18:32:04.135846 12219 solver.cpp:353] Iteration 76500 (7.07523 iter/s, 14.1338s/100 iter), loss = 1.98629
I0801 18:32:04.135897 12219 solver.cpp:375]     Train net output #0: loss = 1.79924 (* 1 = 1.79924 loss)
I0801 18:32:04.135910 12219 sgd_solver.cpp:136] Iteration 76500, lr = 0.0760938, m = 0.9
I0801 18:32:18.111769 12219 solver.cpp:353] Iteration 76600 (7.15536 iter/s, 13.9755s/100 iter), loss = 1.95654
I0801 18:32:18.111795 12219 solver.cpp:375]     Train net output #0: loss = 1.81098 (* 1 = 1.81098 loss)
I0801 18:32:18.111842 12219 sgd_solver.cpp:136] Iteration 76600, lr = 0.0760625, m = 0.9
I0801 18:32:32.013798 12219 solver.cpp:353] Iteration 76700 (7.1934 iter/s, 13.9016s/100 iter), loss = 2.02151
I0801 18:32:32.013857 12219 solver.cpp:375]     Train net output #0: loss = 2.10494 (* 1 = 2.10494 loss)
I0801 18:32:32.013864 12219 sgd_solver.cpp:136] Iteration 76700, lr = 0.0760313, m = 0.9
I0801 18:32:45.994187 12219 solver.cpp:353] Iteration 76800 (7.15307 iter/s, 13.98s/100 iter), loss = 1.91595
I0801 18:32:45.994215 12219 solver.cpp:375]     Train net output #0: loss = 1.83832 (* 1 = 1.83832 loss)
I0801 18:32:45.994220 12219 sgd_solver.cpp:136] Iteration 76800, lr = 0.076, m = 0.9
I0801 18:33:00.021324 12219 solver.cpp:353] Iteration 76900 (7.12924 iter/s, 14.0267s/100 iter), loss = 2.14937
I0801 18:33:00.021417 12219 solver.cpp:375]     Train net output #0: loss = 2.16482 (* 1 = 2.16482 loss)
I0801 18:33:00.021438 12219 sgd_solver.cpp:136] Iteration 76900, lr = 0.0759687, m = 0.9
I0801 18:33:14.003242 12219 solver.cpp:353] Iteration 77000 (7.15229 iter/s, 13.9815s/100 iter), loss = 2.2285
I0801 18:33:14.003294 12219 solver.cpp:375]     Train net output #0: loss = 2.16406 (* 1 = 2.16406 loss)
I0801 18:33:14.003299 12219 sgd_solver.cpp:136] Iteration 77000, lr = 0.0759375, m = 0.9
I0801 18:33:28.099246 12219 solver.cpp:353] Iteration 77100 (7.0944 iter/s, 14.0956s/100 iter), loss = 1.94375
I0801 18:33:28.099267 12219 solver.cpp:375]     Train net output #0: loss = 1.90553 (* 1 = 1.90553 loss)
I0801 18:33:28.099272 12219 sgd_solver.cpp:136] Iteration 77100, lr = 0.0759063, m = 0.9
I0801 18:33:42.059926 12219 solver.cpp:353] Iteration 77200 (7.16317 iter/s, 13.9603s/100 iter), loss = 1.71188
I0801 18:33:42.059978 12219 solver.cpp:375]     Train net output #0: loss = 1.35231 (* 1 = 1.35231 loss)
I0801 18:33:42.059990 12219 sgd_solver.cpp:136] Iteration 77200, lr = 0.075875, m = 0.9
I0801 18:33:56.021174 12219 solver.cpp:353] Iteration 77300 (7.16288 iter/s, 13.9609s/100 iter), loss = 2.03568
I0801 18:33:56.021255 12219 solver.cpp:375]     Train net output #0: loss = 2.00307 (* 1 = 2.00307 loss)
I0801 18:33:56.021261 12219 sgd_solver.cpp:136] Iteration 77300, lr = 0.0758438, m = 0.9
I0801 18:34:10.026089 12219 solver.cpp:353] Iteration 77400 (7.14055 iter/s, 14.0045s/100 iter), loss = 2.25519
I0801 18:34:10.026116 12219 solver.cpp:375]     Train net output #0: loss = 1.94992 (* 1 = 1.94992 loss)
I0801 18:34:10.026120 12219 sgd_solver.cpp:136] Iteration 77400, lr = 0.0758125, m = 0.9
I0801 18:34:24.017899 12219 solver.cpp:353] Iteration 77500 (7.14723 iter/s, 13.9914s/100 iter), loss = 2.45306
I0801 18:34:24.017925 12219 solver.cpp:375]     Train net output #0: loss = 2.52307 (* 1 = 2.52307 loss)
I0801 18:34:24.017931 12219 sgd_solver.cpp:136] Iteration 77500, lr = 0.0757812, m = 0.9
I0801 18:34:37.903244 12219 solver.cpp:353] Iteration 77600 (7.20204 iter/s, 13.885s/100 iter), loss = 1.72338
I0801 18:34:37.903321 12219 solver.cpp:375]     Train net output #0: loss = 1.74745 (* 1 = 1.74745 loss)
I0801 18:34:37.903328 12219 sgd_solver.cpp:136] Iteration 77600, lr = 0.07575, m = 0.9
I0801 18:34:51.779407 12219 solver.cpp:353] Iteration 77700 (7.2068 iter/s, 13.8758s/100 iter), loss = 2.17433
I0801 18:34:51.779434 12219 solver.cpp:375]     Train net output #0: loss = 2.07897 (* 1 = 2.07897 loss)
I0801 18:34:51.779438 12219 sgd_solver.cpp:136] Iteration 77700, lr = 0.0757188, m = 0.9
I0801 18:35:05.749631 12219 solver.cpp:353] Iteration 77800 (7.15828 iter/s, 13.9698s/100 iter), loss = 2.10294
I0801 18:35:05.749660 12219 solver.cpp:375]     Train net output #0: loss = 2.39713 (* 1 = 2.39713 loss)
I0801 18:35:05.749666 12219 sgd_solver.cpp:136] Iteration 77800, lr = 0.0756875, m = 0.9
I0801 18:35:19.796867 12219 solver.cpp:353] Iteration 77900 (7.11903 iter/s, 14.0468s/100 iter), loss = 1.90592
I0801 18:35:19.796950 12219 solver.cpp:375]     Train net output #0: loss = 1.76335 (* 1 = 1.76335 loss)
I0801 18:35:19.796957 12219 sgd_solver.cpp:136] Iteration 77900, lr = 0.0756563, m = 0.9
I0801 18:35:33.566658 12219 solver.cpp:550] Iteration 78000, Testing net (#0)
I0801 18:35:35.279613 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 18:35:53.782784 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.379412
I0801 18:35:53.782897 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.637588
I0801 18:35:53.782907 12219 solver.cpp:635]     Test net output #2: loss = 2.89273 (* 1 = 2.89273 loss)
I0801 18:35:53.782925 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2157s
I0801 18:35:53.922333 12219 solver.cpp:353] Iteration 78000 (2.93044 iter/s, 34.1245s/100 iter), loss = 1.97082
I0801 18:35:53.922358 12219 solver.cpp:375]     Train net output #0: loss = 2.04097 (* 1 = 2.04097 loss)
I0801 18:35:53.922361 12219 sgd_solver.cpp:136] Iteration 78000, lr = 0.075625, m = 0.9
I0801 18:36:07.836271 12219 solver.cpp:353] Iteration 78100 (7.18724 iter/s, 13.9135s/100 iter), loss = 2.08338
I0801 18:36:07.836298 12219 solver.cpp:375]     Train net output #0: loss = 2.30709 (* 1 = 2.30709 loss)
I0801 18:36:07.836304 12219 sgd_solver.cpp:136] Iteration 78100, lr = 0.0755938, m = 0.9
I0801 18:36:21.777693 12219 solver.cpp:353] Iteration 78200 (7.17307 iter/s, 13.941s/100 iter), loss = 2.25338
I0801 18:36:21.777752 12219 solver.cpp:375]     Train net output #0: loss = 2.33878 (* 1 = 2.33878 loss)
I0801 18:36:21.777773 12219 sgd_solver.cpp:136] Iteration 78200, lr = 0.0755625, m = 0.9
I0801 18:36:35.691001 12219 solver.cpp:353] Iteration 78300 (7.18756 iter/s, 13.9129s/100 iter), loss = 2.23985
I0801 18:36:35.691076 12219 solver.cpp:375]     Train net output #0: loss = 2.0497 (* 1 = 2.0497 loss)
I0801 18:36:35.691082 12219 sgd_solver.cpp:136] Iteration 78300, lr = 0.0755313, m = 0.9
I0801 18:36:49.744386 12219 solver.cpp:353] Iteration 78400 (7.11592 iter/s, 14.053s/100 iter), loss = 2.13265
I0801 18:36:49.744415 12219 solver.cpp:375]     Train net output #0: loss = 2.08138 (* 1 = 2.08138 loss)
I0801 18:36:49.744419 12219 sgd_solver.cpp:136] Iteration 78400, lr = 0.0755, m = 0.9
I0801 18:37:03.697814 12219 solver.cpp:353] Iteration 78500 (7.1669 iter/s, 13.953s/100 iter), loss = 1.81187
I0801 18:37:03.697844 12219 solver.cpp:375]     Train net output #0: loss = 2.09998 (* 1 = 2.09998 loss)
I0801 18:37:03.697850 12219 sgd_solver.cpp:136] Iteration 78500, lr = 0.0754687, m = 0.9
I0801 18:37:17.606525 12219 solver.cpp:353] Iteration 78600 (7.18994 iter/s, 13.9083s/100 iter), loss = 2.21136
I0801 18:37:17.606583 12219 solver.cpp:375]     Train net output #0: loss = 2.50109 (* 1 = 2.50109 loss)
I0801 18:37:17.606590 12219 sgd_solver.cpp:136] Iteration 78600, lr = 0.0754375, m = 0.9
I0801 18:37:31.571120 12219 solver.cpp:353] Iteration 78700 (7.16116 iter/s, 13.9642s/100 iter), loss = 2.31626
I0801 18:37:31.571146 12219 solver.cpp:375]     Train net output #0: loss = 2.37145 (* 1 = 2.37145 loss)
I0801 18:37:31.571151 12219 sgd_solver.cpp:136] Iteration 78700, lr = 0.0754063, m = 0.9
I0801 18:37:45.654237 12219 solver.cpp:353] Iteration 78800 (7.1009 iter/s, 14.0827s/100 iter), loss = 2.47256
I0801 18:37:45.654306 12219 solver.cpp:375]     Train net output #0: loss = 2.5995 (* 1 = 2.5995 loss)
I0801 18:37:45.654325 12219 sgd_solver.cpp:136] Iteration 78800, lr = 0.075375, m = 0.9
I0801 18:37:59.890877 12219 solver.cpp:353] Iteration 78900 (7.02433 iter/s, 14.2362s/100 iter), loss = 1.86521
I0801 18:37:59.890960 12219 solver.cpp:375]     Train net output #0: loss = 1.887 (* 1 = 1.887 loss)
I0801 18:37:59.890969 12219 sgd_solver.cpp:136] Iteration 78900, lr = 0.0753438, m = 0.9
I0801 18:38:13.936422 12219 solver.cpp:353] Iteration 79000 (7.11989 iter/s, 14.0452s/100 iter), loss = 1.88696
I0801 18:38:13.936451 12219 solver.cpp:375]     Train net output #0: loss = 1.94405 (* 1 = 1.94405 loss)
I0801 18:38:13.936457 12219 sgd_solver.cpp:136] Iteration 79000, lr = 0.0753125, m = 0.9
I0801 18:38:27.869060 12219 solver.cpp:353] Iteration 79100 (7.17759 iter/s, 13.9323s/100 iter), loss = 2.20472
I0801 18:38:27.869086 12219 solver.cpp:375]     Train net output #0: loss = 1.97606 (* 1 = 1.97606 loss)
I0801 18:38:27.869092 12219 sgd_solver.cpp:136] Iteration 79100, lr = 0.0752813, m = 0.9
I0801 18:38:41.827219 12219 solver.cpp:353] Iteration 79200 (7.16447 iter/s, 13.9578s/100 iter), loss = 2.33331
I0801 18:38:41.827302 12219 solver.cpp:375]     Train net output #0: loss = 2.25223 (* 1 = 2.25223 loss)
I0801 18:38:41.827309 12219 sgd_solver.cpp:136] Iteration 79200, lr = 0.07525, m = 0.9
I0801 18:38:55.886188 12219 solver.cpp:353] Iteration 79300 (7.11309 iter/s, 14.0586s/100 iter), loss = 1.78684
I0801 18:38:55.886215 12219 solver.cpp:375]     Train net output #0: loss = 2.0148 (* 1 = 2.0148 loss)
I0801 18:38:55.886220 12219 sgd_solver.cpp:136] Iteration 79300, lr = 0.0752188, m = 0.9
I0801 18:39:10.031466 12219 solver.cpp:353] Iteration 79400 (7.06969 iter/s, 14.1449s/100 iter), loss = 2.33154
I0801 18:39:10.031493 12219 solver.cpp:375]     Train net output #0: loss = 2.56845 (* 1 = 2.56845 loss)
I0801 18:39:10.031500 12219 sgd_solver.cpp:136] Iteration 79400, lr = 0.0751875, m = 0.9
I0801 18:39:24.023064 12219 solver.cpp:353] Iteration 79500 (7.14734 iter/s, 13.9912s/100 iter), loss = 2.26193
I0801 18:39:24.023138 12219 solver.cpp:375]     Train net output #0: loss = 2.20235 (* 1 = 2.20235 loss)
I0801 18:39:24.023146 12219 sgd_solver.cpp:136] Iteration 79500, lr = 0.0751562, m = 0.9
I0801 18:39:38.025014 12219 solver.cpp:353] Iteration 79600 (7.14206 iter/s, 14.0016s/100 iter), loss = 1.8741
I0801 18:39:38.025043 12219 solver.cpp:375]     Train net output #0: loss = 2.13274 (* 1 = 2.13274 loss)
I0801 18:39:38.025049 12219 sgd_solver.cpp:136] Iteration 79600, lr = 0.075125, m = 0.9
I0801 18:39:51.988337 12219 solver.cpp:353] Iteration 79700 (7.16182 iter/s, 13.9629s/100 iter), loss = 2.07155
I0801 18:39:51.988365 12219 solver.cpp:375]     Train net output #0: loss = 2.23637 (* 1 = 2.23637 loss)
I0801 18:39:51.988371 12219 sgd_solver.cpp:136] Iteration 79700, lr = 0.0750938, m = 0.9
I0801 18:40:06.087137 12219 solver.cpp:353] Iteration 79800 (7.093 iter/s, 14.0984s/100 iter), loss = 1.92693
I0801 18:40:06.087213 12219 solver.cpp:375]     Train net output #0: loss = 1.57316 (* 1 = 1.57316 loss)
I0801 18:40:06.087220 12219 sgd_solver.cpp:136] Iteration 79800, lr = 0.0750625, m = 0.9
I0801 18:40:20.090065 12219 solver.cpp:353] Iteration 79900 (7.14156 iter/s, 14.0025s/100 iter), loss = 2.57044
I0801 18:40:20.090132 12219 solver.cpp:375]     Train net output #0: loss = 2.52756 (* 1 = 2.52756 loss)
I0801 18:40:20.090152 12219 sgd_solver.cpp:136] Iteration 79900, lr = 0.0750313, m = 0.9
I0801 18:40:34.077704 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_80000.caffemodel
I0801 18:40:34.222100 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_80000.solverstate
I0801 18:40:34.226969 12219 solver.cpp:550] Iteration 80000, Testing net (#0)
I0801 18:40:53.883924 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.387235
I0801 18:40:53.883970 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.642881
I0801 18:40:53.883978 12219 solver.cpp:635]     Test net output #2: loss = 2.87637 (* 1 = 2.87637 loss)
I0801 18:40:53.883999 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6565s
I0801 18:40:54.022084 12219 solver.cpp:353] Iteration 80000 (2.94715 iter/s, 33.9311s/100 iter), loss = 1.84858
I0801 18:40:54.022110 12219 solver.cpp:375]     Train net output #0: loss = 1.95944 (* 1 = 1.95944 loss)
I0801 18:40:54.022115 12219 sgd_solver.cpp:136] Iteration 80000, lr = 0.075, m = 0.9
I0801 18:41:08.066566 12219 solver.cpp:353] Iteration 80100 (7.12043 iter/s, 14.0441s/100 iter), loss = 2.26132
I0801 18:41:08.066593 12219 solver.cpp:375]     Train net output #0: loss = 2.33259 (* 1 = 2.33259 loss)
I0801 18:41:08.066601 12219 sgd_solver.cpp:136] Iteration 80100, lr = 0.0749687, m = 0.9
I0801 18:41:22.096834 12219 solver.cpp:353] Iteration 80200 (7.12765 iter/s, 14.0299s/100 iter), loss = 2.10192
I0801 18:41:22.096863 12219 solver.cpp:375]     Train net output #0: loss = 2.34158 (* 1 = 2.34158 loss)
I0801 18:41:22.096869 12219 sgd_solver.cpp:136] Iteration 80200, lr = 0.0749375, m = 0.9
I0801 18:41:36.278563 12219 solver.cpp:353] Iteration 80300 (7.05152 iter/s, 14.1813s/100 iter), loss = 1.88523
I0801 18:41:36.278625 12219 solver.cpp:375]     Train net output #0: loss = 1.80456 (* 1 = 1.80456 loss)
I0801 18:41:36.278631 12219 sgd_solver.cpp:136] Iteration 80300, lr = 0.0749063, m = 0.9
I0801 18:41:50.368480 12219 solver.cpp:353] Iteration 80400 (7.09747 iter/s, 14.0895s/100 iter), loss = 1.76497
I0801 18:41:50.368566 12219 solver.cpp:375]     Train net output #0: loss = 1.71553 (* 1 = 1.71553 loss)
I0801 18:41:50.368585 12219 sgd_solver.cpp:136] Iteration 80400, lr = 0.074875, m = 0.9
I0801 18:42:04.294746 12219 solver.cpp:353] Iteration 80500 (7.18087 iter/s, 13.9259s/100 iter), loss = 2.16299
I0801 18:42:04.294776 12219 solver.cpp:375]     Train net output #0: loss = 2.03706 (* 1 = 2.03706 loss)
I0801 18:42:04.294782 12219 sgd_solver.cpp:136] Iteration 80500, lr = 0.0748438, m = 0.9
I0801 18:42:18.350229 12219 solver.cpp:353] Iteration 80600 (7.11486 iter/s, 14.0551s/100 iter), loss = 2.90549
I0801 18:42:18.350304 12219 solver.cpp:375]     Train net output #0: loss = 2.94152 (* 1 = 2.94152 loss)
I0801 18:42:18.350311 12219 sgd_solver.cpp:136] Iteration 80600, lr = 0.0748125, m = 0.9
I0801 18:42:32.458222 12219 solver.cpp:353] Iteration 80700 (7.08838 iter/s, 14.1076s/100 iter), loss = 2.25847
I0801 18:42:32.458248 12219 solver.cpp:375]     Train net output #0: loss = 2.66003 (* 1 = 2.66003 loss)
I0801 18:42:32.458252 12219 sgd_solver.cpp:136] Iteration 80700, lr = 0.0747813, m = 0.9
I0801 18:42:46.549943 12219 solver.cpp:353] Iteration 80800 (7.09656 iter/s, 14.0913s/100 iter), loss = 1.87447
I0801 18:42:46.549965 12219 solver.cpp:375]     Train net output #0: loss = 2.03387 (* 1 = 2.03387 loss)
I0801 18:42:46.549970 12219 sgd_solver.cpp:136] Iteration 80800, lr = 0.07475, m = 0.9
I0801 18:43:00.786309 12219 solver.cpp:353] Iteration 80900 (7.02446 iter/s, 14.236s/100 iter), loss = 1.94083
I0801 18:43:00.786370 12219 solver.cpp:375]     Train net output #0: loss = 2.02304 (* 1 = 2.02304 loss)
I0801 18:43:00.786376 12219 sgd_solver.cpp:136] Iteration 80900, lr = 0.0747188, m = 0.9
I0801 18:43:14.747587 12219 solver.cpp:353] Iteration 81000 (7.16287 iter/s, 13.9609s/100 iter), loss = 2.07198
I0801 18:43:14.747617 12219 solver.cpp:375]     Train net output #0: loss = 1.95205 (* 1 = 1.95205 loss)
I0801 18:43:14.747620 12219 sgd_solver.cpp:136] Iteration 81000, lr = 0.0746875, m = 0.9
I0801 18:43:28.777638 12219 solver.cpp:353] Iteration 81100 (7.12775 iter/s, 14.0297s/100 iter), loss = 2.05898
I0801 18:43:28.777663 12219 solver.cpp:375]     Train net output #0: loss = 1.90606 (* 1 = 1.90606 loss)
I0801 18:43:28.777667 12219 sgd_solver.cpp:136] Iteration 81100, lr = 0.0746562, m = 0.9
I0801 18:43:43.025295 12219 solver.cpp:353] Iteration 81200 (7.01889 iter/s, 14.2473s/100 iter), loss = 2.19122
I0801 18:43:43.025372 12219 solver.cpp:375]     Train net output #0: loss = 2.18994 (* 1 = 2.18994 loss)
I0801 18:43:43.025378 12219 sgd_solver.cpp:136] Iteration 81200, lr = 0.074625, m = 0.9
I0801 18:43:57.025328 12219 solver.cpp:353] Iteration 81300 (7.14304 iter/s, 13.9996s/100 iter), loss = 2.11257
I0801 18:43:57.025352 12219 solver.cpp:375]     Train net output #0: loss = 1.61588 (* 1 = 1.61588 loss)
I0801 18:43:57.025358 12219 sgd_solver.cpp:136] Iteration 81300, lr = 0.0745937, m = 0.9
I0801 18:44:11.154742 12219 solver.cpp:353] Iteration 81400 (7.07763 iter/s, 14.129s/100 iter), loss = 2.11276
I0801 18:44:11.154767 12219 solver.cpp:375]     Train net output #0: loss = 2.16338 (* 1 = 2.16338 loss)
I0801 18:44:11.154772 12219 sgd_solver.cpp:136] Iteration 81400, lr = 0.0745625, m = 0.9
I0801 18:44:25.124146 12219 solver.cpp:353] Iteration 81500 (7.1587 iter/s, 13.969s/100 iter), loss = 2.18107
I0801 18:44:25.124214 12219 solver.cpp:375]     Train net output #0: loss = 2.10017 (* 1 = 2.10017 loss)
I0801 18:44:25.124220 12219 sgd_solver.cpp:136] Iteration 81500, lr = 0.0745312, m = 0.9
I0801 18:44:39.325594 12219 solver.cpp:353] Iteration 81600 (7.04173 iter/s, 14.2011s/100 iter), loss = 2.03431
I0801 18:44:39.325620 12219 solver.cpp:375]     Train net output #0: loss = 2.07195 (* 1 = 2.07195 loss)
I0801 18:44:39.325625 12219 sgd_solver.cpp:136] Iteration 81600, lr = 0.0745, m = 0.9
I0801 18:44:53.362779 12219 solver.cpp:353] Iteration 81700 (7.12413 iter/s, 14.0368s/100 iter), loss = 1.86782
I0801 18:44:53.362807 12219 solver.cpp:375]     Train net output #0: loss = 1.96952 (* 1 = 1.96952 loss)
I0801 18:44:53.362812 12219 sgd_solver.cpp:136] Iteration 81700, lr = 0.0744688, m = 0.9
I0801 18:45:07.359067 12219 solver.cpp:353] Iteration 81800 (7.14495 iter/s, 13.9959s/100 iter), loss = 2.50311
I0801 18:45:07.359145 12219 solver.cpp:375]     Train net output #0: loss = 2.05613 (* 1 = 2.05613 loss)
I0801 18:45:07.359154 12219 sgd_solver.cpp:136] Iteration 81800, lr = 0.0744375, m = 0.9
I0801 18:45:21.338618 12219 solver.cpp:353] Iteration 81900 (7.1535 iter/s, 13.9792s/100 iter), loss = 2.12466
I0801 18:45:21.338709 12219 solver.cpp:375]     Train net output #0: loss = 2.26865 (* 1 = 2.26865 loss)
I0801 18:45:21.338734 12219 sgd_solver.cpp:136] Iteration 81900, lr = 0.0744063, m = 0.9
I0801 18:45:35.119120 12219 solver.cpp:550] Iteration 82000, Testing net (#0)
I0801 18:45:55.301407 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.385235
I0801 18:45:55.301530 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.646764
I0801 18:45:55.301539 12219 solver.cpp:635]     Test net output #2: loss = 2.90241 (* 1 = 2.90241 loss)
I0801 18:45:55.301558 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1819s
I0801 18:45:55.454663 12219 solver.cpp:353] Iteration 82000 (2.93125 iter/s, 34.1151s/100 iter), loss = 1.94358
I0801 18:45:55.454687 12219 solver.cpp:375]     Train net output #0: loss = 1.83994 (* 1 = 1.83994 loss)
I0801 18:45:55.454691 12219 sgd_solver.cpp:136] Iteration 82000, lr = 0.074375, m = 0.9
I0801 18:46:09.529444 12219 solver.cpp:353] Iteration 82100 (7.1051 iter/s, 14.0744s/100 iter), loss = 2.27581
I0801 18:46:09.529541 12219 solver.cpp:375]     Train net output #0: loss = 2.4216 (* 1 = 2.4216 loss)
I0801 18:46:09.529561 12219 sgd_solver.cpp:136] Iteration 82100, lr = 0.0743438, m = 0.9
I0801 18:46:23.543277 12219 solver.cpp:353] Iteration 82200 (7.136 iter/s, 14.0134s/100 iter), loss = 2.08652
I0801 18:46:23.543304 12219 solver.cpp:375]     Train net output #0: loss = 1.87236 (* 1 = 1.87236 loss)
I0801 18:46:23.543309 12219 sgd_solver.cpp:136] Iteration 82200, lr = 0.0743125, m = 0.9
I0801 18:46:37.474568 12219 solver.cpp:353] Iteration 82300 (7.17829 iter/s, 13.9309s/100 iter), loss = 2.0784
I0801 18:46:37.474661 12219 solver.cpp:375]     Train net output #0: loss = 1.73569 (* 1 = 1.73569 loss)
I0801 18:46:37.474676 12219 sgd_solver.cpp:136] Iteration 82300, lr = 0.0742813, m = 0.9
I0801 18:46:51.452137 12219 solver.cpp:353] Iteration 82400 (7.15452 iter/s, 13.9772s/100 iter), loss = 1.63808
I0801 18:46:51.452165 12219 solver.cpp:375]     Train net output #0: loss = 1.79577 (* 1 = 1.79577 loss)
I0801 18:46:51.452172 12219 sgd_solver.cpp:136] Iteration 82400, lr = 0.07425, m = 0.9
I0801 18:47:05.624333 12219 solver.cpp:353] Iteration 82500 (7.05627 iter/s, 14.1718s/100 iter), loss = 2.02111
I0801 18:47:05.624362 12219 solver.cpp:375]     Train net output #0: loss = 1.90213 (* 1 = 1.90213 loss)
I0801 18:47:05.624368 12219 sgd_solver.cpp:136] Iteration 82500, lr = 0.0742188, m = 0.9
I0801 18:47:19.770170 12219 solver.cpp:353] Iteration 82600 (7.06942 iter/s, 14.1454s/100 iter), loss = 2.21733
I0801 18:47:19.770246 12219 solver.cpp:375]     Train net output #0: loss = 2.16942 (* 1 = 2.16942 loss)
I0801 18:47:19.770252 12219 sgd_solver.cpp:136] Iteration 82600, lr = 0.0741875, m = 0.9
I0801 18:47:33.729365 12219 solver.cpp:353] Iteration 82700 (7.16394 iter/s, 13.9588s/100 iter), loss = 2.38871
I0801 18:47:33.729430 12219 solver.cpp:375]     Train net output #0: loss = 2.46829 (* 1 = 2.46829 loss)
I0801 18:47:33.729475 12219 sgd_solver.cpp:136] Iteration 82700, lr = 0.0741562, m = 0.9
I0801 18:47:47.758790 12219 solver.cpp:353] Iteration 82800 (7.12807 iter/s, 14.029s/100 iter), loss = 2.28452
I0801 18:47:47.758816 12219 solver.cpp:375]     Train net output #0: loss = 2.3901 (* 1 = 2.3901 loss)
I0801 18:47:47.758821 12219 sgd_solver.cpp:136] Iteration 82800, lr = 0.074125, m = 0.9
I0801 18:48:01.681411 12219 solver.cpp:353] Iteration 82900 (7.18275 iter/s, 13.9222s/100 iter), loss = 2.04719
I0801 18:48:01.681466 12219 solver.cpp:375]     Train net output #0: loss = 2.30019 (* 1 = 2.30019 loss)
I0801 18:48:01.681471 12219 sgd_solver.cpp:136] Iteration 82900, lr = 0.0740938, m = 0.9
I0801 18:48:15.665439 12219 solver.cpp:353] Iteration 83000 (7.15121 iter/s, 13.9836s/100 iter), loss = 1.91542
I0801 18:48:15.665464 12219 solver.cpp:375]     Train net output #0: loss = 1.9623 (* 1 = 1.9623 loss)
I0801 18:48:15.665468 12219 sgd_solver.cpp:136] Iteration 83000, lr = 0.0740625, m = 0.9
I0801 18:48:29.687341 12219 solver.cpp:353] Iteration 83100 (7.1319 iter/s, 14.0215s/100 iter), loss = 2.65416
I0801 18:48:29.687376 12219 solver.cpp:375]     Train net output #0: loss = 3.0393 (* 1 = 3.0393 loss)
I0801 18:48:29.687382 12219 sgd_solver.cpp:136] Iteration 83100, lr = 0.0740312, m = 0.9
I0801 18:48:43.606828 12219 solver.cpp:353] Iteration 83200 (7.18437 iter/s, 13.9191s/100 iter), loss = 1.89857
I0801 18:48:43.606906 12219 solver.cpp:375]     Train net output #0: loss = 2.29597 (* 1 = 2.29597 loss)
I0801 18:48:43.606914 12219 sgd_solver.cpp:136] Iteration 83200, lr = 0.074, m = 0.9
I0801 18:48:57.646157 12219 solver.cpp:353] Iteration 83300 (7.12304 iter/s, 14.0389s/100 iter), loss = 1.79489
I0801 18:48:57.646181 12219 solver.cpp:375]     Train net output #0: loss = 1.73451 (* 1 = 1.73451 loss)
I0801 18:48:57.646185 12219 sgd_solver.cpp:136] Iteration 83300, lr = 0.0739688, m = 0.9
I0801 18:49:11.571077 12219 solver.cpp:353] Iteration 83400 (7.18157 iter/s, 13.9245s/100 iter), loss = 2.86632
I0801 18:49:11.571101 12219 solver.cpp:375]     Train net output #0: loss = 3.11158 (* 1 = 3.11158 loss)
I0801 18:49:11.571105 12219 sgd_solver.cpp:136] Iteration 83400, lr = 0.0739375, m = 0.9
I0801 18:49:25.617377 12219 solver.cpp:353] Iteration 83500 (7.11951 iter/s, 14.0459s/100 iter), loss = 2.17478
I0801 18:49:25.617432 12219 solver.cpp:375]     Train net output #0: loss = 2.3626 (* 1 = 2.3626 loss)
I0801 18:49:25.617440 12219 sgd_solver.cpp:136] Iteration 83500, lr = 0.0739063, m = 0.9
I0801 18:49:39.517993 12219 solver.cpp:353] Iteration 83600 (7.19413 iter/s, 13.9002s/100 iter), loss = 2.47696
I0801 18:49:39.518018 12219 solver.cpp:375]     Train net output #0: loss = 2.35144 (* 1 = 2.35144 loss)
I0801 18:49:39.518023 12219 sgd_solver.cpp:136] Iteration 83600, lr = 0.073875, m = 0.9
I0801 18:49:53.530246 12219 solver.cpp:353] Iteration 83700 (7.13681 iter/s, 14.0119s/100 iter), loss = 2.21615
I0801 18:49:53.530274 12219 solver.cpp:375]     Train net output #0: loss = 2.45649 (* 1 = 2.45649 loss)
I0801 18:49:53.530278 12219 sgd_solver.cpp:136] Iteration 83700, lr = 0.0738438, m = 0.9
I0801 18:50:07.478173 12219 solver.cpp:353] Iteration 83800 (7.16972 iter/s, 13.9475s/100 iter), loss = 2.41734
I0801 18:50:07.478232 12219 solver.cpp:375]     Train net output #0: loss = 2.51975 (* 1 = 2.51975 loss)
I0801 18:50:07.478238 12219 sgd_solver.cpp:136] Iteration 83800, lr = 0.0738125, m = 0.9
I0801 18:50:21.457962 12219 solver.cpp:353] Iteration 83900 (7.15338 iter/s, 13.9794s/100 iter), loss = 1.99169
I0801 18:50:21.457988 12219 solver.cpp:375]     Train net output #0: loss = 1.98031 (* 1 = 1.98031 loss)
I0801 18:50:21.457993 12219 sgd_solver.cpp:136] Iteration 83900, lr = 0.0737813, m = 0.9
I0801 18:50:35.345919 12219 solver.cpp:550] Iteration 84000, Testing net (#0)
I0801 18:50:39.479985 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 18:50:55.693785 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.413941
I0801 18:50:55.693805 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.668352
I0801 18:50:55.693810 12219 solver.cpp:635]     Test net output #2: loss = 2.72387 (* 1 = 2.72387 loss)
I0801 18:50:55.693842 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3474s
I0801 18:50:55.838984 12219 solver.cpp:353] Iteration 84000 (2.90866 iter/s, 34.3801s/100 iter), loss = 2.00866
I0801 18:50:55.839011 12219 solver.cpp:375]     Train net output #0: loss = 2.19055 (* 1 = 2.19055 loss)
I0801 18:50:55.839015 12219 sgd_solver.cpp:136] Iteration 84000, lr = 0.07375, m = 0.9
I0801 18:51:09.872102 12219 solver.cpp:353] Iteration 84100 (7.1262 iter/s, 14.0327s/100 iter), loss = 2.25863
I0801 18:51:09.872165 12219 solver.cpp:375]     Train net output #0: loss = 2.01624 (* 1 = 2.01624 loss)
I0801 18:51:09.872172 12219 sgd_solver.cpp:136] Iteration 84100, lr = 0.0737187, m = 0.9
I0801 18:51:23.828564 12219 solver.cpp:353] Iteration 84200 (7.16534 iter/s, 13.9561s/100 iter), loss = 2.10336
I0801 18:51:23.828586 12219 solver.cpp:375]     Train net output #0: loss = 2.56942 (* 1 = 2.56942 loss)
I0801 18:51:23.828593 12219 sgd_solver.cpp:136] Iteration 84200, lr = 0.0736875, m = 0.9
I0801 18:51:37.770278 12219 solver.cpp:353] Iteration 84300 (7.17292 iter/s, 13.9413s/100 iter), loss = 2.39253
I0801 18:51:37.770378 12219 solver.cpp:375]     Train net output #0: loss = 2.5163 (* 1 = 2.5163 loss)
I0801 18:51:37.770398 12219 sgd_solver.cpp:136] Iteration 84300, lr = 0.0736563, m = 0.9
I0801 18:51:51.755993 12219 solver.cpp:353] Iteration 84400 (7.15035 iter/s, 13.9853s/100 iter), loss = 1.99112
I0801 18:51:51.756065 12219 solver.cpp:375]     Train net output #0: loss = 2.09054 (* 1 = 2.09054 loss)
I0801 18:51:51.756072 12219 sgd_solver.cpp:136] Iteration 84400, lr = 0.073625, m = 0.9
I0801 18:52:05.654054 12219 solver.cpp:353] Iteration 84500 (7.19545 iter/s, 13.8977s/100 iter), loss = 2.44784
I0801 18:52:05.654121 12219 solver.cpp:375]     Train net output #0: loss = 2.14016 (* 1 = 2.14016 loss)
I0801 18:52:05.654145 12219 sgd_solver.cpp:136] Iteration 84500, lr = 0.0735938, m = 0.9
I0801 18:52:19.651623 12219 solver.cpp:353] Iteration 84600 (7.1443 iter/s, 13.9972s/100 iter), loss = 2.11424
I0801 18:52:19.651645 12219 solver.cpp:375]     Train net output #0: loss = 1.79412 (* 1 = 1.79412 loss)
I0801 18:52:19.651649 12219 sgd_solver.cpp:136] Iteration 84600, lr = 0.0735625, m = 0.9
I0801 18:52:33.564129 12219 solver.cpp:353] Iteration 84700 (7.18798 iter/s, 13.9121s/100 iter), loss = 2.14474
I0801 18:52:33.564189 12219 solver.cpp:375]     Train net output #0: loss = 1.96858 (* 1 = 1.96858 loss)
I0801 18:52:33.564196 12219 sgd_solver.cpp:136] Iteration 84700, lr = 0.0735312, m = 0.9
I0801 18:52:47.583566 12219 solver.cpp:353] Iteration 84800 (7.13315 iter/s, 14.019s/100 iter), loss = 2.05857
I0801 18:52:47.583595 12219 solver.cpp:375]     Train net output #0: loss = 1.4874 (* 1 = 1.4874 loss)
I0801 18:52:47.583601 12219 sgd_solver.cpp:136] Iteration 84800, lr = 0.0735, m = 0.9
I0801 18:53:01.752622 12219 solver.cpp:353] Iteration 84900 (7.05783 iter/s, 14.1687s/100 iter), loss = 2.31145
I0801 18:53:01.752648 12219 solver.cpp:375]     Train net output #0: loss = 2.24235 (* 1 = 2.24235 loss)
I0801 18:53:01.752651 12219 sgd_solver.cpp:136] Iteration 84900, lr = 0.0734688, m = 0.9
I0801 18:53:15.801714 12219 solver.cpp:353] Iteration 85000 (7.11809 iter/s, 14.0487s/100 iter), loss = 2.1348
I0801 18:53:15.801833 12219 solver.cpp:375]     Train net output #0: loss = 1.93754 (* 1 = 1.93754 loss)
I0801 18:53:15.801853 12219 sgd_solver.cpp:136] Iteration 85000, lr = 0.0734375, m = 0.9
I0801 18:53:29.821259 12219 solver.cpp:353] Iteration 85100 (7.1331 iter/s, 14.0192s/100 iter), loss = 1.98123
I0801 18:53:29.821286 12219 solver.cpp:375]     Train net output #0: loss = 2.06115 (* 1 = 2.06115 loss)
I0801 18:53:29.821292 12219 sgd_solver.cpp:136] Iteration 85100, lr = 0.0734062, m = 0.9
I0801 18:53:43.762905 12219 solver.cpp:353] Iteration 85200 (7.17295 iter/s, 13.9413s/100 iter), loss = 1.79285
I0801 18:53:43.762930 12219 solver.cpp:375]     Train net output #0: loss = 1.93491 (* 1 = 1.93491 loss)
I0801 18:53:43.762936 12219 sgd_solver.cpp:136] Iteration 85200, lr = 0.073375, m = 0.9
I0801 18:53:57.931687 12219 solver.cpp:353] Iteration 85300 (7.05797 iter/s, 14.1684s/100 iter), loss = 2.2855
I0801 18:53:57.931774 12219 solver.cpp:375]     Train net output #0: loss = 2.06496 (* 1 = 2.06496 loss)
I0801 18:53:57.931782 12219 sgd_solver.cpp:136] Iteration 85300, lr = 0.0733438, m = 0.9
I0801 18:54:11.982916 12219 solver.cpp:353] Iteration 85400 (7.11701 iter/s, 14.0508s/100 iter), loss = 2.08372
I0801 18:54:11.983687 12219 solver.cpp:375]     Train net output #0: loss = 2.10643 (* 1 = 2.10643 loss)
I0801 18:54:11.983695 12219 sgd_solver.cpp:136] Iteration 85400, lr = 0.0733125, m = 0.9
I0801 18:54:26.141932 12219 solver.cpp:353] Iteration 85500 (7.06283 iter/s, 14.1586s/100 iter), loss = 2.31409
I0801 18:54:26.141961 12219 solver.cpp:375]     Train net output #0: loss = 2.39717 (* 1 = 2.39717 loss)
I0801 18:54:26.141968 12219 sgd_solver.cpp:136] Iteration 85500, lr = 0.0732813, m = 0.9
I0801 18:54:40.218834 12219 solver.cpp:353] Iteration 85600 (7.10403 iter/s, 14.0765s/100 iter), loss = 2.26735
I0801 18:54:40.220907 12219 solver.cpp:375]     Train net output #0: loss = 2.08079 (* 1 = 2.08079 loss)
I0801 18:54:40.220918 12219 sgd_solver.cpp:136] Iteration 85600, lr = 0.07325, m = 0.9
I0801 18:54:54.160595 12219 solver.cpp:353] Iteration 85700 (7.17289 iter/s, 13.9414s/100 iter), loss = 2.03403
I0801 18:54:54.160621 12219 solver.cpp:375]     Train net output #0: loss = 2.27582 (* 1 = 2.27582 loss)
I0801 18:54:54.160626 12219 sgd_solver.cpp:136] Iteration 85700, lr = 0.0732188, m = 0.9
I0801 18:55:08.247305 12219 solver.cpp:353] Iteration 85800 (7.09909 iter/s, 14.0863s/100 iter), loss = 1.92336
I0801 18:55:08.247385 12219 solver.cpp:375]     Train net output #0: loss = 2.25815 (* 1 = 2.25815 loss)
I0801 18:55:08.247406 12219 sgd_solver.cpp:136] Iteration 85800, lr = 0.0731875, m = 0.9
I0801 18:55:22.311262 12219 solver.cpp:353] Iteration 85900 (7.11057 iter/s, 14.0636s/100 iter), loss = 2.23802
I0801 18:55:22.311362 12219 solver.cpp:375]     Train net output #0: loss = 2.53762 (* 1 = 2.53762 loss)
I0801 18:55:22.311370 12219 sgd_solver.cpp:136] Iteration 85900, lr = 0.0731563, m = 0.9
I0801 18:55:36.107483 12219 solver.cpp:550] Iteration 86000, Testing net (#0)
I0801 18:55:56.599781 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.396294
I0801 18:55:56.599895 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.661117
I0801 18:55:56.599905 12219 solver.cpp:635]     Test net output #2: loss = 2.79879 (* 1 = 2.79879 loss)
I0801 18:55:56.599925 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4919s
I0801 18:55:56.745270 12219 solver.cpp:353] Iteration 86000 (2.90418 iter/s, 34.4331s/100 iter), loss = 2.16224
I0801 18:55:56.745296 12219 solver.cpp:375]     Train net output #0: loss = 2.51611 (* 1 = 2.51611 loss)
I0801 18:55:56.745302 12219 sgd_solver.cpp:136] Iteration 86000, lr = 0.073125, m = 0.9
I0801 18:56:10.781391 12219 solver.cpp:353] Iteration 86100 (7.12467 iter/s, 14.0357s/100 iter), loss = 2.17243
I0801 18:56:10.781479 12219 solver.cpp:375]     Train net output #0: loss = 2.02159 (* 1 = 2.02159 loss)
I0801 18:56:10.781498 12219 sgd_solver.cpp:136] Iteration 86100, lr = 0.0730937, m = 0.9
I0801 18:56:24.966675 12219 solver.cpp:353] Iteration 86200 (7.04976 iter/s, 14.1849s/100 iter), loss = 2.33917
I0801 18:56:24.966706 12219 solver.cpp:375]     Train net output #0: loss = 2.13916 (* 1 = 2.13916 loss)
I0801 18:56:24.966712 12219 sgd_solver.cpp:136] Iteration 86200, lr = 0.0730625, m = 0.9
I0801 18:56:39.040334 12219 solver.cpp:353] Iteration 86300 (7.10567 iter/s, 14.0733s/100 iter), loss = 2.12272
I0801 18:56:39.040417 12219 solver.cpp:375]     Train net output #0: loss = 2.17569 (* 1 = 2.17569 loss)
I0801 18:56:39.040426 12219 sgd_solver.cpp:136] Iteration 86300, lr = 0.0730312, m = 0.9
I0801 18:56:53.138753 12219 solver.cpp:353] Iteration 86400 (7.09319 iter/s, 14.098s/100 iter), loss = 2.09561
I0801 18:56:53.138780 12219 solver.cpp:375]     Train net output #0: loss = 2.06594 (* 1 = 2.06594 loss)
I0801 18:56:53.138787 12219 sgd_solver.cpp:136] Iteration 86400, lr = 0.073, m = 0.9
I0801 18:57:07.150883 12219 solver.cpp:353] Iteration 86500 (7.13687 iter/s, 14.0117s/100 iter), loss = 2.15619
I0801 18:57:07.151127 12219 solver.cpp:375]     Train net output #0: loss = 2.27148 (* 1 = 2.27148 loss)
I0801 18:57:07.151239 12219 sgd_solver.cpp:136] Iteration 86500, lr = 0.0729688, m = 0.9
I0801 18:57:21.203160 12219 solver.cpp:353] Iteration 86600 (7.11648 iter/s, 14.0519s/100 iter), loss = 2.24118
I0801 18:57:21.203241 12219 solver.cpp:375]     Train net output #0: loss = 2.09065 (* 1 = 2.09065 loss)
I0801 18:57:21.203248 12219 sgd_solver.cpp:136] Iteration 86600, lr = 0.0729375, m = 0.9
I0801 18:57:35.132858 12219 solver.cpp:353] Iteration 86700 (7.1791 iter/s, 13.9293s/100 iter), loss = 1.95068
I0801 18:57:35.132886 12219 solver.cpp:375]     Train net output #0: loss = 1.68586 (* 1 = 1.68586 loss)
I0801 18:57:35.132892 12219 sgd_solver.cpp:136] Iteration 86700, lr = 0.0729062, m = 0.9
I0801 18:57:49.167209 12219 solver.cpp:353] Iteration 86800 (7.12557 iter/s, 14.034s/100 iter), loss = 2.24934
I0801 18:57:49.167237 12219 solver.cpp:375]     Train net output #0: loss = 2.37317 (* 1 = 2.37317 loss)
I0801 18:57:49.167240 12219 sgd_solver.cpp:136] Iteration 86800, lr = 0.072875, m = 0.9
I0801 18:58:03.194056 12219 solver.cpp:353] Iteration 86900 (7.12938 iter/s, 14.0265s/100 iter), loss = 2.03147
I0801 18:58:03.194126 12219 solver.cpp:375]     Train net output #0: loss = 1.87187 (* 1 = 1.87187 loss)
I0801 18:58:03.194131 12219 sgd_solver.cpp:136] Iteration 86900, lr = 0.0728438, m = 0.9
I0801 18:58:17.269553 12219 solver.cpp:353] Iteration 87000 (7.10474 iter/s, 14.0751s/100 iter), loss = 1.90657
I0801 18:58:17.269578 12219 solver.cpp:375]     Train net output #0: loss = 2.0528 (* 1 = 2.0528 loss)
I0801 18:58:17.269584 12219 sgd_solver.cpp:136] Iteration 87000, lr = 0.0728125, m = 0.9
I0801 18:58:31.163580 12219 solver.cpp:353] Iteration 87100 (7.19754 iter/s, 13.8936s/100 iter), loss = 1.84964
I0801 18:58:31.163604 12219 solver.cpp:375]     Train net output #0: loss = 2.04889 (* 1 = 2.04889 loss)
I0801 18:58:31.163607 12219 sgd_solver.cpp:136] Iteration 87100, lr = 0.0727813, m = 0.9
I0801 18:58:45.167996 12219 solver.cpp:353] Iteration 87200 (7.1408 iter/s, 14.004s/100 iter), loss = 2.03153
I0801 18:58:45.168056 12219 solver.cpp:375]     Train net output #0: loss = 1.91926 (* 1 = 1.91926 loss)
I0801 18:58:45.168061 12219 sgd_solver.cpp:136] Iteration 87200, lr = 0.07275, m = 0.9
I0801 18:58:59.289832 12219 solver.cpp:353] Iteration 87300 (7.08143 iter/s, 14.1214s/100 iter), loss = 2.65184
I0801 18:58:59.289858 12219 solver.cpp:375]     Train net output #0: loss = 3.03663 (* 1 = 3.03663 loss)
I0801 18:58:59.289863 12219 sgd_solver.cpp:136] Iteration 87300, lr = 0.0727188, m = 0.9
I0801 18:59:13.293467 12219 solver.cpp:353] Iteration 87400 (7.1412 iter/s, 14.0033s/100 iter), loss = 2.24697
I0801 18:59:13.293496 12219 solver.cpp:375]     Train net output #0: loss = 2.42794 (* 1 = 2.42794 loss)
I0801 18:59:13.293503 12219 sgd_solver.cpp:136] Iteration 87400, lr = 0.0726875, m = 0.9
I0801 18:59:27.264031 12219 solver.cpp:353] Iteration 87500 (7.15811 iter/s, 13.9702s/100 iter), loss = 2.0828
I0801 18:59:27.264086 12219 solver.cpp:375]     Train net output #0: loss = 2.41192 (* 1 = 2.41192 loss)
I0801 18:59:27.264094 12219 sgd_solver.cpp:136] Iteration 87500, lr = 0.0726563, m = 0.9
I0801 18:59:41.236848 12219 solver.cpp:353] Iteration 87600 (7.15695 iter/s, 13.9724s/100 iter), loss = 1.99513
I0801 18:59:41.236876 12219 solver.cpp:375]     Train net output #0: loss = 2.25754 (* 1 = 2.25754 loss)
I0801 18:59:41.236882 12219 sgd_solver.cpp:136] Iteration 87600, lr = 0.072625, m = 0.9
I0801 18:59:55.299726 12219 solver.cpp:353] Iteration 87700 (7.11112 iter/s, 14.0625s/100 iter), loss = 2.09566
I0801 18:59:55.299751 12219 solver.cpp:375]     Train net output #0: loss = 1.95447 (* 1 = 1.95447 loss)
I0801 18:59:55.299757 12219 sgd_solver.cpp:136] Iteration 87700, lr = 0.0725937, m = 0.9
I0801 19:00:09.329165 12219 solver.cpp:353] Iteration 87800 (7.12807 iter/s, 14.0291s/100 iter), loss = 2.60253
I0801 19:00:09.329251 12219 solver.cpp:375]     Train net output #0: loss = 2.83207 (* 1 = 2.83207 loss)
I0801 19:00:09.329258 12219 sgd_solver.cpp:136] Iteration 87800, lr = 0.0725625, m = 0.9
I0801 19:00:23.471804 12219 solver.cpp:353] Iteration 87900 (7.07101 iter/s, 14.1422s/100 iter), loss = 2.26187
I0801 19:00:23.471894 12219 solver.cpp:375]     Train net output #0: loss = 2.1657 (* 1 = 2.1657 loss)
I0801 19:00:23.471913 12219 sgd_solver.cpp:136] Iteration 87900, lr = 0.0725312, m = 0.9
I0801 19:00:37.320065 12219 solver.cpp:550] Iteration 88000, Testing net (#0)
I0801 19:00:39.933703 12207 data_reader.cpp:264] Starting prefetch of epoch 5
I0801 19:00:57.219449 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.37647
I0801 19:00:57.219473 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.635294
I0801 19:00:57.219478 12219 solver.cpp:635]     Test net output #2: loss = 2.92251 (* 1 = 2.92251 loss)
I0801 19:00:57.219570 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.899s
I0801 19:00:57.366839 12219 solver.cpp:353] Iteration 88000 (2.95037 iter/s, 33.8941s/100 iter), loss = 1.87057
I0801 19:00:57.366866 12219 solver.cpp:375]     Train net output #0: loss = 1.89916 (* 1 = 1.89916 loss)
I0801 19:00:57.366873 12219 sgd_solver.cpp:136] Iteration 88000, lr = 0.0725, m = 0.9
I0801 19:01:11.444607 12219 solver.cpp:353] Iteration 88100 (7.1036 iter/s, 14.0774s/100 iter), loss = 1.87612
I0801 19:01:11.444679 12219 solver.cpp:375]     Train net output #0: loss = 1.66491 (* 1 = 1.66491 loss)
I0801 19:01:11.444687 12219 sgd_solver.cpp:136] Iteration 88100, lr = 0.0724688, m = 0.9
I0801 19:01:25.629422 12219 solver.cpp:353] Iteration 88200 (7.04999 iter/s, 14.1844s/100 iter), loss = 1.9304
I0801 19:01:25.629487 12219 solver.cpp:375]     Train net output #0: loss = 1.83681 (* 1 = 1.83681 loss)
I0801 19:01:25.629508 12219 sgd_solver.cpp:136] Iteration 88200, lr = 0.0724375, m = 0.9
I0801 19:01:39.699089 12219 solver.cpp:353] Iteration 88300 (7.10768 iter/s, 14.0693s/100 iter), loss = 2.41841
I0801 19:01:39.699116 12219 solver.cpp:375]     Train net output #0: loss = 2.75462 (* 1 = 2.75462 loss)
I0801 19:01:39.699122 12219 sgd_solver.cpp:136] Iteration 88300, lr = 0.0724063, m = 0.9
I0801 19:01:53.730489 12219 solver.cpp:353] Iteration 88400 (7.12707 iter/s, 14.031s/100 iter), loss = 2.48323
I0801 19:01:53.730587 12219 solver.cpp:375]     Train net output #0: loss = 2.74538 (* 1 = 2.74538 loss)
I0801 19:01:53.730593 12219 sgd_solver.cpp:136] Iteration 88400, lr = 0.072375, m = 0.9
I0801 19:02:07.805405 12219 solver.cpp:353] Iteration 88500 (7.10503 iter/s, 14.0745s/100 iter), loss = 2.02162
I0801 19:02:07.805431 12219 solver.cpp:375]     Train net output #0: loss = 2.01192 (* 1 = 2.01192 loss)
I0801 19:02:07.805435 12219 sgd_solver.cpp:136] Iteration 88500, lr = 0.0723438, m = 0.9
I0801 19:02:21.847165 12219 solver.cpp:353] Iteration 88600 (7.12181 iter/s, 14.0414s/100 iter), loss = 2.13352
I0801 19:02:21.847192 12219 solver.cpp:375]     Train net output #0: loss = 2.26968 (* 1 = 2.26968 loss)
I0801 19:02:21.847198 12219 sgd_solver.cpp:136] Iteration 88600, lr = 0.0723125, m = 0.9
I0801 19:02:35.856269 12219 solver.cpp:353] Iteration 88700 (7.13842 iter/s, 14.0087s/100 iter), loss = 2.23673
I0801 19:02:35.856343 12219 solver.cpp:375]     Train net output #0: loss = 2.60407 (* 1 = 2.60407 loss)
I0801 19:02:35.856350 12219 sgd_solver.cpp:136] Iteration 88700, lr = 0.0722813, m = 0.9
I0801 19:02:49.954216 12219 solver.cpp:353] Iteration 88800 (7.09342 iter/s, 14.0976s/100 iter), loss = 2.08597
I0801 19:02:49.954242 12219 solver.cpp:375]     Train net output #0: loss = 1.98418 (* 1 = 1.98418 loss)
I0801 19:02:49.954248 12219 sgd_solver.cpp:136] Iteration 88800, lr = 0.07225, m = 0.9
I0801 19:03:03.925124 12219 solver.cpp:353] Iteration 88900 (7.15793 iter/s, 13.9705s/100 iter), loss = 2.34968
I0801 19:03:03.925158 12219 solver.cpp:375]     Train net output #0: loss = 1.70204 (* 1 = 1.70204 loss)
I0801 19:03:03.925165 12219 sgd_solver.cpp:136] Iteration 88900, lr = 0.0722188, m = 0.9
I0801 19:03:17.938984 12219 solver.cpp:353] Iteration 89000 (7.13599 iter/s, 14.0135s/100 iter), loss = 2.24778
I0801 19:03:17.939299 12219 solver.cpp:375]     Train net output #0: loss = 2.52176 (* 1 = 2.52176 loss)
I0801 19:03:17.939414 12219 sgd_solver.cpp:136] Iteration 89000, lr = 0.0721875, m = 0.9
I0801 19:03:31.959167 12219 solver.cpp:353] Iteration 89100 (7.13277 iter/s, 14.0198s/100 iter), loss = 1.81453
I0801 19:03:31.959193 12219 solver.cpp:375]     Train net output #0: loss = 2.31957 (* 1 = 2.31957 loss)
I0801 19:03:31.959197 12219 sgd_solver.cpp:136] Iteration 89100, lr = 0.0721563, m = 0.9
I0801 19:03:46.029942 12219 solver.cpp:353] Iteration 89200 (7.10713 iter/s, 14.0704s/100 iter), loss = 2.58602
I0801 19:03:46.029970 12219 solver.cpp:375]     Train net output #0: loss = 2.22601 (* 1 = 2.22601 loss)
I0801 19:03:46.029976 12219 sgd_solver.cpp:136] Iteration 89200, lr = 0.072125, m = 0.9
I0801 19:04:00.062778 12219 solver.cpp:353] Iteration 89300 (7.12634 iter/s, 14.0324s/100 iter), loss = 2.12411
I0801 19:04:00.062855 12219 solver.cpp:375]     Train net output #0: loss = 1.83489 (* 1 = 1.83489 loss)
I0801 19:04:00.062862 12219 sgd_solver.cpp:136] Iteration 89300, lr = 0.0720937, m = 0.9
I0801 19:04:14.037261 12219 solver.cpp:353] Iteration 89400 (7.1561 iter/s, 13.9741s/100 iter), loss = 1.97727
I0801 19:04:14.037286 12219 solver.cpp:375]     Train net output #0: loss = 1.91013 (* 1 = 1.91013 loss)
I0801 19:04:14.037291 12219 sgd_solver.cpp:136] Iteration 89400, lr = 0.0720625, m = 0.9
I0801 19:04:27.966164 12219 solver.cpp:353] Iteration 89500 (7.17951 iter/s, 13.9285s/100 iter), loss = 2.02887
I0801 19:04:27.966194 12219 solver.cpp:375]     Train net output #0: loss = 1.68789 (* 1 = 1.68789 loss)
I0801 19:04:27.966199 12219 sgd_solver.cpp:136] Iteration 89500, lr = 0.0720313, m = 0.9
I0801 19:04:41.961850 12219 solver.cpp:353] Iteration 89600 (7.14526 iter/s, 13.9953s/100 iter), loss = 2.20795
I0801 19:04:41.961941 12219 solver.cpp:375]     Train net output #0: loss = 2.23197 (* 1 = 2.23197 loss)
I0801 19:04:41.961953 12219 sgd_solver.cpp:136] Iteration 89600, lr = 0.072, m = 0.9
I0801 19:04:55.893110 12219 solver.cpp:353] Iteration 89700 (7.1783 iter/s, 13.9309s/100 iter), loss = 2.06643
I0801 19:04:55.893141 12219 solver.cpp:375]     Train net output #0: loss = 2.01928 (* 1 = 2.01928 loss)
I0801 19:04:55.893147 12219 sgd_solver.cpp:136] Iteration 89700, lr = 0.0719687, m = 0.9
I0801 19:05:09.815101 12219 solver.cpp:353] Iteration 89800 (7.18308 iter/s, 13.9216s/100 iter), loss = 2.34071
I0801 19:05:09.815131 12219 solver.cpp:375]     Train net output #0: loss = 2.50109 (* 1 = 2.50109 loss)
I0801 19:05:09.815136 12219 sgd_solver.cpp:136] Iteration 89800, lr = 0.0719375, m = 0.9
I0801 19:05:23.703512 12219 solver.cpp:353] Iteration 89900 (7.20045 iter/s, 13.888s/100 iter), loss = 2.16225
I0801 19:05:23.703629 12219 solver.cpp:375]     Train net output #0: loss = 2.5371 (* 1 = 2.5371 loss)
I0801 19:05:23.703649 12219 sgd_solver.cpp:136] Iteration 89900, lr = 0.0719063, m = 0.9
I0801 19:05:37.543606 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_90000.caffemodel
I0801 19:05:37.654088 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_90000.solverstate
I0801 19:05:37.661012 12219 solver.cpp:550] Iteration 90000, Testing net (#0)
I0801 19:05:43.985606 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 19:05:57.519117 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.397
I0801 19:05:57.519209 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.649882
I0801 19:05:57.519218 12219 solver.cpp:635]     Test net output #2: loss = 2.82837 (* 1 = 2.82837 loss)
I0801 19:05:57.519238 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8577s
I0801 19:05:57.661952 12219 solver.cpp:353] Iteration 90000 (2.94486 iter/s, 33.9575s/100 iter), loss = 2.23763
I0801 19:05:57.661978 12219 solver.cpp:375]     Train net output #0: loss = 2.33187 (* 1 = 2.33187 loss)
I0801 19:05:57.661983 12219 sgd_solver.cpp:136] Iteration 90000, lr = 0.071875, m = 0.9
I0801 19:06:11.757253 12219 solver.cpp:353] Iteration 90100 (7.09476 iter/s, 14.0949s/100 iter), loss = 2.15657
I0801 19:06:11.757282 12219 solver.cpp:375]     Train net output #0: loss = 2.13454 (* 1 = 2.13454 loss)
I0801 19:06:11.757289 12219 sgd_solver.cpp:136] Iteration 90100, lr = 0.0718438, m = 0.9
I0801 19:06:25.753392 12219 solver.cpp:353] Iteration 90200 (7.14503 iter/s, 13.9957s/100 iter), loss = 2.20661
I0801 19:06:25.753422 12219 solver.cpp:375]     Train net output #0: loss = 2.2863 (* 1 = 2.2863 loss)
I0801 19:06:25.753427 12219 sgd_solver.cpp:136] Iteration 90200, lr = 0.0718125, m = 0.9
I0801 19:06:39.680954 12219 solver.cpp:353] Iteration 90300 (7.18021 iter/s, 13.9272s/100 iter), loss = 1.8284
I0801 19:06:39.681015 12219 solver.cpp:375]     Train net output #0: loss = 1.72743 (* 1 = 1.72743 loss)
I0801 19:06:39.681021 12219 sgd_solver.cpp:136] Iteration 90300, lr = 0.0717813, m = 0.9
I0801 19:06:53.673861 12219 solver.cpp:353] Iteration 90400 (7.14668 iter/s, 13.9925s/100 iter), loss = 2.12555
I0801 19:06:53.673889 12219 solver.cpp:375]     Train net output #0: loss = 1.92449 (* 1 = 1.92449 loss)
I0801 19:06:53.673895 12219 sgd_solver.cpp:136] Iteration 90400, lr = 0.07175, m = 0.9
I0801 19:07:07.753341 12219 solver.cpp:353] Iteration 90500 (7.10273 iter/s, 14.0791s/100 iter), loss = 1.91748
I0801 19:07:07.753370 12219 solver.cpp:375]     Train net output #0: loss = 2.29472 (* 1 = 2.29472 loss)
I0801 19:07:07.753376 12219 sgd_solver.cpp:136] Iteration 90500, lr = 0.0717188, m = 0.9
I0801 19:07:21.735131 12219 solver.cpp:353] Iteration 90600 (7.15236 iter/s, 13.9814s/100 iter), loss = 2.00926
I0801 19:07:21.735200 12219 solver.cpp:375]     Train net output #0: loss = 1.69679 (* 1 = 1.69679 loss)
I0801 19:07:21.735206 12219 sgd_solver.cpp:136] Iteration 90600, lr = 0.0716875, m = 0.9
I0801 19:07:35.740900 12219 solver.cpp:353] Iteration 90700 (7.14011 iter/s, 14.0054s/100 iter), loss = 1.981
I0801 19:07:35.740954 12219 solver.cpp:375]     Train net output #0: loss = 2.01414 (* 1 = 2.01414 loss)
I0801 19:07:35.740970 12219 sgd_solver.cpp:136] Iteration 90700, lr = 0.0716562, m = 0.9
I0801 19:07:49.619384 12219 solver.cpp:353] Iteration 90800 (7.2056 iter/s, 13.8781s/100 iter), loss = 2.31789
I0801 19:07:49.619411 12219 solver.cpp:375]     Train net output #0: loss = 1.98466 (* 1 = 1.98466 loss)
I0801 19:07:49.619416 12219 sgd_solver.cpp:136] Iteration 90800, lr = 0.071625, m = 0.9
I0801 19:08:03.710222 12219 solver.cpp:353] Iteration 90900 (7.097 iter/s, 14.0905s/100 iter), loss = 2.87281
I0801 19:08:03.710307 12219 solver.cpp:375]     Train net output #0: loss = 2.91431 (* 1 = 2.91431 loss)
I0801 19:08:03.710314 12219 sgd_solver.cpp:136] Iteration 90900, lr = 0.0715938, m = 0.9
I0801 19:08:17.816907 12219 solver.cpp:353] Iteration 91000 (7.08903 iter/s, 14.1063s/100 iter), loss = 2.55694
I0801 19:08:17.816932 12219 solver.cpp:375]     Train net output #0: loss = 2.91728 (* 1 = 2.91728 loss)
I0801 19:08:17.816937 12219 sgd_solver.cpp:136] Iteration 91000, lr = 0.0715625, m = 0.9
I0801 19:08:31.811018 12219 solver.cpp:353] Iteration 91100 (7.14606 iter/s, 13.9937s/100 iter), loss = 2.23182
I0801 19:08:31.811072 12219 solver.cpp:375]     Train net output #0: loss = 2.36577 (* 1 = 2.36577 loss)
I0801 19:08:31.811085 12219 sgd_solver.cpp:136] Iteration 91100, lr = 0.0715313, m = 0.9
I0801 19:08:45.796108 12219 solver.cpp:353] Iteration 91200 (7.15067 iter/s, 13.9847s/100 iter), loss = 1.98263
I0801 19:08:45.796175 12219 solver.cpp:375]     Train net output #0: loss = 1.73879 (* 1 = 1.73879 loss)
I0801 19:08:45.796181 12219 sgd_solver.cpp:136] Iteration 91200, lr = 0.0715, m = 0.9
I0801 19:08:59.833827 12219 solver.cpp:353] Iteration 91300 (7.12386 iter/s, 14.0373s/100 iter), loss = 1.96937
I0801 19:08:59.833855 12219 solver.cpp:375]     Train net output #0: loss = 2.19947 (* 1 = 2.19947 loss)
I0801 19:08:59.833860 12219 sgd_solver.cpp:136] Iteration 91300, lr = 0.0714687, m = 0.9
I0801 19:09:13.975634 12219 solver.cpp:353] Iteration 91400 (7.07143 iter/s, 14.1414s/100 iter), loss = 1.80408
I0801 19:09:13.975658 12219 solver.cpp:375]     Train net output #0: loss = 1.82367 (* 1 = 1.82367 loss)
I0801 19:09:13.975663 12219 sgd_solver.cpp:136] Iteration 91400, lr = 0.0714375, m = 0.9
I0801 19:09:28.112586 12219 solver.cpp:353] Iteration 91500 (7.07386 iter/s, 14.1366s/100 iter), loss = 1.9945
I0801 19:09:28.112643 12219 solver.cpp:375]     Train net output #0: loss = 1.87816 (* 1 = 1.87816 loss)
I0801 19:09:28.112650 12219 sgd_solver.cpp:136] Iteration 91500, lr = 0.0714063, m = 0.9
I0801 19:09:42.120169 12219 solver.cpp:353] Iteration 91600 (7.13919 iter/s, 14.0072s/100 iter), loss = 1.75675
I0801 19:09:42.120196 12219 solver.cpp:375]     Train net output #0: loss = 1.79351 (* 1 = 1.79351 loss)
I0801 19:09:42.120203 12219 sgd_solver.cpp:136] Iteration 91600, lr = 0.071375, m = 0.9
I0801 19:09:56.125447 12219 solver.cpp:353] Iteration 91700 (7.14036 iter/s, 14.0049s/100 iter), loss = 1.82573
I0801 19:09:56.125543 12219 solver.cpp:375]     Train net output #0: loss = 1.76314 (* 1 = 1.76314 loss)
I0801 19:09:56.125571 12219 sgd_solver.cpp:136] Iteration 91700, lr = 0.0713437, m = 0.9
I0801 19:10:10.063592 12219 solver.cpp:353] Iteration 91800 (7.17475 iter/s, 13.9378s/100 iter), loss = 1.99251
I0801 19:10:10.063729 12219 solver.cpp:375]     Train net output #0: loss = 1.96024 (* 1 = 1.96024 loss)
I0801 19:10:10.063750 12219 sgd_solver.cpp:136] Iteration 91800, lr = 0.0713125, m = 0.9
I0801 19:10:24.102298 12219 solver.cpp:353] Iteration 91900 (7.12336 iter/s, 14.0383s/100 iter), loss = 2.24948
I0801 19:10:24.102324 12219 solver.cpp:375]     Train net output #0: loss = 2.36969 (* 1 = 2.36969 loss)
I0801 19:10:24.102329 12219 sgd_solver.cpp:136] Iteration 91900, lr = 0.0712813, m = 0.9
I0801 19:10:37.996551 12219 solver.cpp:550] Iteration 92000, Testing net (#0)
I0801 19:10:58.344074 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.389823
I0801 19:10:58.344179 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.654235
I0801 19:10:58.344202 12219 solver.cpp:635]     Test net output #2: loss = 2.81364 (* 1 = 2.81364 loss)
I0801 19:10:58.344243 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3471s
I0801 19:10:58.488101 12219 solver.cpp:353] Iteration 92000 (2.90826 iter/s, 34.3849s/100 iter), loss = 2.01117
I0801 19:10:58.488126 12219 solver.cpp:375]     Train net output #0: loss = 1.92767 (* 1 = 1.92767 loss)
I0801 19:10:58.488131 12219 sgd_solver.cpp:136] Iteration 92000, lr = 0.07125, m = 0.9
I0801 19:11:12.526967 12219 solver.cpp:353] Iteration 92100 (7.12328 iter/s, 14.0385s/100 iter), loss = 2.10052
I0801 19:11:12.526990 12219 solver.cpp:375]     Train net output #0: loss = 1.65719 (* 1 = 1.65719 loss)
I0801 19:11:12.526994 12219 sgd_solver.cpp:136] Iteration 92100, lr = 0.0712188, m = 0.9
I0801 19:11:26.451056 12219 solver.cpp:353] Iteration 92200 (7.182 iter/s, 13.9237s/100 iter), loss = 2.22885
I0801 19:11:26.451081 12219 solver.cpp:375]     Train net output #0: loss = 2.28587 (* 1 = 2.28587 loss)
I0801 19:11:26.451086 12219 sgd_solver.cpp:136] Iteration 92200, lr = 0.0711875, m = 0.9
I0801 19:11:40.557607 12219 solver.cpp:353] Iteration 92300 (7.0891 iter/s, 14.1062s/100 iter), loss = 2.63067
I0801 19:11:40.557721 12219 solver.cpp:375]     Train net output #0: loss = 2.31176 (* 1 = 2.31176 loss)
I0801 19:11:40.557740 12219 sgd_solver.cpp:136] Iteration 92300, lr = 0.0711563, m = 0.9
I0801 19:11:54.549680 12219 solver.cpp:353] Iteration 92400 (7.1471 iter/s, 13.9917s/100 iter), loss = 1.93715
I0801 19:11:54.549705 12219 solver.cpp:375]     Train net output #0: loss = 1.73219 (* 1 = 1.73219 loss)
I0801 19:11:54.549710 12219 sgd_solver.cpp:136] Iteration 92400, lr = 0.071125, m = 0.9
I0801 19:12:08.615140 12219 solver.cpp:353] Iteration 92500 (7.10981 iter/s, 14.0651s/100 iter), loss = 1.86197
I0801 19:12:08.615162 12219 solver.cpp:375]     Train net output #0: loss = 1.66788 (* 1 = 1.66788 loss)
I0801 19:12:08.615167 12219 sgd_solver.cpp:136] Iteration 92500, lr = 0.0710938, m = 0.9
I0801 19:12:22.691961 12219 solver.cpp:353] Iteration 92600 (7.10408 iter/s, 14.0764s/100 iter), loss = 2.12523
I0801 19:12:22.692041 12219 solver.cpp:375]     Train net output #0: loss = 2.28757 (* 1 = 2.28757 loss)
I0801 19:12:22.692049 12219 sgd_solver.cpp:136] Iteration 92600, lr = 0.0710625, m = 0.9
I0801 19:12:36.701380 12219 solver.cpp:353] Iteration 92700 (7.13825 iter/s, 14.009s/100 iter), loss = 2.12399
I0801 19:12:36.701408 12219 solver.cpp:375]     Train net output #0: loss = 1.52301 (* 1 = 1.52301 loss)
I0801 19:12:36.701414 12219 sgd_solver.cpp:136] Iteration 92700, lr = 0.0710313, m = 0.9
I0801 19:12:50.746425 12219 solver.cpp:353] Iteration 92800 (7.12015 iter/s, 14.0447s/100 iter), loss = 2.38611
I0801 19:12:50.746451 12219 solver.cpp:375]     Train net output #0: loss = 2.73325 (* 1 = 2.73325 loss)
I0801 19:12:50.746455 12219 sgd_solver.cpp:136] Iteration 92800, lr = 0.071, m = 0.9
I0801 19:13:04.724560 12219 solver.cpp:353] Iteration 92900 (7.15423 iter/s, 13.9778s/100 iter), loss = 2.31032
I0801 19:13:04.724617 12219 solver.cpp:375]     Train net output #0: loss = 2.32234 (* 1 = 2.32234 loss)
I0801 19:13:04.724623 12219 sgd_solver.cpp:136] Iteration 92900, lr = 0.0709687, m = 0.9
I0801 19:13:18.793948 12219 solver.cpp:353] Iteration 93000 (7.10783 iter/s, 14.069s/100 iter), loss = 2.14429
I0801 19:13:18.793974 12219 solver.cpp:375]     Train net output #0: loss = 2.47462 (* 1 = 2.47462 loss)
I0801 19:13:18.793982 12219 sgd_solver.cpp:136] Iteration 93000, lr = 0.0709375, m = 0.9
I0801 19:13:32.695489 12219 solver.cpp:353] Iteration 93100 (7.19364 iter/s, 13.9012s/100 iter), loss = 2.11381
I0801 19:13:32.695518 12219 solver.cpp:375]     Train net output #0: loss = 2.25659 (* 1 = 2.25659 loss)
I0801 19:13:32.695524 12219 sgd_solver.cpp:136] Iteration 93100, lr = 0.0709062, m = 0.9
I0801 19:13:46.756430 12219 solver.cpp:353] Iteration 93200 (7.1121 iter/s, 14.0606s/100 iter), loss = 1.83207
I0801 19:13:46.756547 12219 solver.cpp:375]     Train net output #0: loss = 1.93944 (* 1 = 1.93944 loss)
I0801 19:13:46.756556 12219 sgd_solver.cpp:136] Iteration 93200, lr = 0.070875, m = 0.9
I0801 19:14:00.778677 12219 solver.cpp:353] Iteration 93300 (7.13172 iter/s, 14.0219s/100 iter), loss = 1.96934
I0801 19:14:00.778703 12219 solver.cpp:375]     Train net output #0: loss = 1.73259 (* 1 = 1.73259 loss)
I0801 19:14:00.778709 12219 sgd_solver.cpp:136] Iteration 93300, lr = 0.0708437, m = 0.9
I0801 19:14:14.939659 12219 solver.cpp:353] Iteration 93400 (7.06185 iter/s, 14.1606s/100 iter), loss = 2.5429
I0801 19:14:14.939687 12219 solver.cpp:375]     Train net output #0: loss = 2.6766 (* 1 = 2.6766 loss)
I0801 19:14:14.939692 12219 sgd_solver.cpp:136] Iteration 93400, lr = 0.0708125, m = 0.9
I0801 19:14:28.948030 12219 solver.cpp:353] Iteration 93500 (7.13879 iter/s, 14.008s/100 iter), loss = 2.15561
I0801 19:14:28.948107 12219 solver.cpp:375]     Train net output #0: loss = 2.15735 (* 1 = 2.15735 loss)
I0801 19:14:28.948115 12219 sgd_solver.cpp:136] Iteration 93500, lr = 0.0707813, m = 0.9
I0801 19:14:42.896749 12219 solver.cpp:353] Iteration 93600 (7.16932 iter/s, 13.9483s/100 iter), loss = 2.33049
I0801 19:14:42.896880 12219 solver.cpp:375]     Train net output #0: loss = 2.22374 (* 1 = 2.22374 loss)
I0801 19:14:42.896904 12219 sgd_solver.cpp:136] Iteration 93600, lr = 0.07075, m = 0.9
I0801 19:14:56.918068 12219 solver.cpp:353] Iteration 93700 (7.13219 iter/s, 14.0209s/100 iter), loss = 1.88552
I0801 19:14:56.918092 12219 solver.cpp:375]     Train net output #0: loss = 1.96358 (* 1 = 1.96358 loss)
I0801 19:14:56.918097 12219 sgd_solver.cpp:136] Iteration 93700, lr = 0.0707188, m = 0.9
I0801 19:15:10.903900 12219 solver.cpp:353] Iteration 93800 (7.15029 iter/s, 13.9854s/100 iter), loss = 1.80896
I0801 19:15:10.903983 12219 solver.cpp:375]     Train net output #0: loss = 1.6475 (* 1 = 1.6475 loss)
I0801 19:15:10.903990 12219 sgd_solver.cpp:136] Iteration 93800, lr = 0.0706875, m = 0.9
I0801 19:15:24.899475 12219 solver.cpp:353] Iteration 93900 (7.14531 iter/s, 13.9952s/100 iter), loss = 2.03877
I0801 19:15:24.899504 12219 solver.cpp:375]     Train net output #0: loss = 2.14196 (* 1 = 2.14196 loss)
I0801 19:15:24.899511 12219 sgd_solver.cpp:136] Iteration 93900, lr = 0.0706563, m = 0.9
I0801 19:15:38.864847 12219 solver.cpp:550] Iteration 94000, Testing net (#0)
I0801 19:15:58.795912 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.410882
I0801 19:15:58.796017 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.67194
I0801 19:15:58.796027 12219 solver.cpp:635]     Test net output #2: loss = 2.71713 (* 1 = 2.71713 loss)
I0801 19:15:58.796046 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9329s
I0801 19:15:58.942644 12219 solver.cpp:353] Iteration 94000 (2.93753 iter/s, 34.0422s/100 iter), loss = 2.4436
I0801 19:15:58.942669 12219 solver.cpp:375]     Train net output #0: loss = 2.91889 (* 1 = 2.91889 loss)
I0801 19:15:58.942673 12219 sgd_solver.cpp:136] Iteration 94000, lr = 0.070625, m = 0.9
I0801 19:16:12.991720 12219 solver.cpp:353] Iteration 94100 (7.1181 iter/s, 14.0487s/100 iter), loss = 2.44623
I0801 19:16:12.991745 12219 solver.cpp:375]     Train net output #0: loss = 2.32643 (* 1 = 2.32643 loss)
I0801 19:16:12.991750 12219 sgd_solver.cpp:136] Iteration 94100, lr = 0.0705938, m = 0.9
I0801 19:16:26.941545 12219 solver.cpp:353] Iteration 94200 (7.16875 iter/s, 13.9494s/100 iter), loss = 2.35008
I0801 19:16:26.941571 12219 solver.cpp:375]     Train net output #0: loss = 2.04982 (* 1 = 2.04982 loss)
I0801 19:16:26.941576 12219 sgd_solver.cpp:136] Iteration 94200, lr = 0.0705625, m = 0.9
I0801 19:16:40.938179 12219 solver.cpp:353] Iteration 94300 (7.14477 iter/s, 13.9962s/100 iter), loss = 2.19974
I0801 19:16:40.938454 12219 solver.cpp:375]     Train net output #0: loss = 2.69295 (* 1 = 2.69295 loss)
I0801 19:16:40.938462 12219 sgd_solver.cpp:136] Iteration 94300, lr = 0.0705312, m = 0.9
I0801 19:16:54.989801 12219 solver.cpp:353] Iteration 94400 (7.11681 iter/s, 14.0512s/100 iter), loss = 2.33946
I0801 19:16:54.989830 12219 solver.cpp:375]     Train net output #0: loss = 2.77632 (* 1 = 2.77632 loss)
I0801 19:16:54.989837 12219 sgd_solver.cpp:136] Iteration 94400, lr = 0.0705, m = 0.9
I0801 19:17:08.968672 12219 solver.cpp:353] Iteration 94500 (7.15385 iter/s, 13.9785s/100 iter), loss = 2.54234
I0801 19:17:08.968703 12219 solver.cpp:375]     Train net output #0: loss = 2.20858 (* 1 = 2.20858 loss)
I0801 19:17:08.968709 12219 sgd_solver.cpp:136] Iteration 94500, lr = 0.0704687, m = 0.9
I0801 19:17:22.998085 12219 solver.cpp:353] Iteration 94600 (7.12809 iter/s, 14.029s/100 iter), loss = 1.6589
I0801 19:17:22.998157 12219 solver.cpp:375]     Train net output #0: loss = 2.00337 (* 1 = 2.00337 loss)
I0801 19:17:22.998164 12219 sgd_solver.cpp:136] Iteration 94600, lr = 0.0704375, m = 0.9
I0801 19:17:37.001359 12219 solver.cpp:353] Iteration 94700 (7.14138 iter/s, 14.0029s/100 iter), loss = 2.31067
I0801 19:17:37.001387 12219 solver.cpp:375]     Train net output #0: loss = 2.35302 (* 1 = 2.35302 loss)
I0801 19:17:37.001391 12219 sgd_solver.cpp:136] Iteration 94700, lr = 0.0704063, m = 0.9
I0801 19:17:51.058552 12219 solver.cpp:353] Iteration 94800 (7.11399 iter/s, 14.0568s/100 iter), loss = 1.56112
I0801 19:17:51.058580 12219 solver.cpp:375]     Train net output #0: loss = 1.62757 (* 1 = 1.62757 loss)
I0801 19:17:51.058586 12219 sgd_solver.cpp:136] Iteration 94800, lr = 0.070375, m = 0.9
I0801 19:18:05.030086 12219 solver.cpp:353] Iteration 94900 (7.15761 iter/s, 13.9711s/100 iter), loss = 1.90258
I0801 19:18:05.030174 12219 solver.cpp:375]     Train net output #0: loss = 1.93776 (* 1 = 1.93776 loss)
I0801 19:18:05.030190 12219 sgd_solver.cpp:136] Iteration 94900, lr = 0.0703438, m = 0.9
I0801 19:18:19.004062 12219 solver.cpp:353] Iteration 95000 (7.15636 iter/s, 13.9736s/100 iter), loss = 2.31672
I0801 19:18:19.004089 12219 solver.cpp:375]     Train net output #0: loss = 2.08633 (* 1 = 2.08633 loss)
I0801 19:18:19.004096 12219 sgd_solver.cpp:136] Iteration 95000, lr = 0.0703125, m = 0.9
I0801 19:18:33.004824 12219 solver.cpp:353] Iteration 95100 (7.14267 iter/s, 14.0004s/100 iter), loss = 1.96929
I0801 19:18:33.004935 12219 solver.cpp:375]     Train net output #0: loss = 1.82591 (* 1 = 1.82591 loss)
I0801 19:18:33.004954 12219 sgd_solver.cpp:136] Iteration 95100, lr = 0.0702813, m = 0.9
I0801 19:18:46.998602 12219 solver.cpp:353] Iteration 95200 (7.14623 iter/s, 13.9934s/100 iter), loss = 2.03271
I0801 19:18:47.004879 12219 solver.cpp:375]     Train net output #0: loss = 1.9563 (* 1 = 1.9563 loss)
I0801 19:18:47.004901 12219 sgd_solver.cpp:136] Iteration 95200, lr = 0.07025, m = 0.9
I0801 19:19:00.987421 12219 solver.cpp:353] Iteration 95300 (7.14876 iter/s, 13.9884s/100 iter), loss = 1.84585
I0801 19:19:00.987449 12219 solver.cpp:375]     Train net output #0: loss = 2.03408 (* 1 = 2.03408 loss)
I0801 19:19:00.987453 12219 sgd_solver.cpp:136] Iteration 95300, lr = 0.0702188, m = 0.9
I0801 19:19:14.899701 12219 solver.cpp:353] Iteration 95400 (7.18809 iter/s, 13.9119s/100 iter), loss = 2.31123
I0801 19:19:14.899726 12219 solver.cpp:375]     Train net output #0: loss = 2.12161 (* 1 = 2.12161 loss)
I0801 19:19:14.899730 12219 sgd_solver.cpp:136] Iteration 95400, lr = 0.0701875, m = 0.9
I0801 19:19:28.885896 12219 solver.cpp:353] Iteration 95500 (7.1501 iter/s, 13.9858s/100 iter), loss = 2.35264
I0801 19:19:28.886054 12219 solver.cpp:375]     Train net output #0: loss = 2.09396 (* 1 = 2.09396 loss)
I0801 19:19:28.886081 12219 sgd_solver.cpp:136] Iteration 95500, lr = 0.0701563, m = 0.9
I0801 19:19:42.978490 12219 solver.cpp:353] Iteration 95600 (7.09612 iter/s, 14.0922s/100 iter), loss = 1.9219
I0801 19:19:42.978528 12219 solver.cpp:375]     Train net output #0: loss = 1.898 (* 1 = 1.898 loss)
I0801 19:19:42.978535 12219 sgd_solver.cpp:136] Iteration 95600, lr = 0.070125, m = 0.9
I0801 19:19:57.026108 12219 solver.cpp:353] Iteration 95700 (7.11884 iter/s, 14.0472s/100 iter), loss = 2.1935
I0801 19:19:57.026134 12219 solver.cpp:375]     Train net output #0: loss = 1.94552 (* 1 = 1.94552 loss)
I0801 19:19:57.026141 12219 sgd_solver.cpp:136] Iteration 95700, lr = 0.0700938, m = 0.9
I0801 19:20:11.060796 12219 solver.cpp:353] Iteration 95800 (7.1254 iter/s, 14.0343s/100 iter), loss = 2.14275
I0801 19:20:11.060854 12219 solver.cpp:375]     Train net output #0: loss = 2.2031 (* 1 = 2.2031 loss)
I0801 19:20:11.060859 12219 sgd_solver.cpp:136] Iteration 95800, lr = 0.0700625, m = 0.9
I0801 19:20:25.229037 12219 solver.cpp:353] Iteration 95900 (7.05823 iter/s, 14.1678s/100 iter), loss = 2.02783
I0801 19:20:25.229063 12219 solver.cpp:375]     Train net output #0: loss = 2.04224 (* 1 = 2.04224 loss)
I0801 19:20:25.229068 12219 sgd_solver.cpp:136] Iteration 95900, lr = 0.0700312, m = 0.9
I0801 19:20:38.978384 12219 solver.cpp:550] Iteration 96000, Testing net (#0)
I0801 19:20:47.903976 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 19:20:58.867323 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.41547
I0801 19:20:58.867350 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.66947
I0801 19:20:58.867357 12219 solver.cpp:635]     Test net output #2: loss = 2.75432 (* 1 = 2.75432 loss)
I0801 19:20:58.867382 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8885s
I0801 19:20:59.062091 12219 solver.cpp:353] Iteration 96000 (2.95577 iter/s, 33.8321s/100 iter), loss = 2.52978
I0801 19:20:59.062120 12219 solver.cpp:375]     Train net output #0: loss = 2.76976 (* 1 = 2.76976 loss)
I0801 19:20:59.062126 12219 sgd_solver.cpp:136] Iteration 96000, lr = 0.07, m = 0.9
I0801 19:21:13.011832 12219 solver.cpp:353] Iteration 96100 (7.16879 iter/s, 13.9494s/100 iter), loss = 2.23578
I0801 19:21:13.011859 12219 solver.cpp:375]     Train net output #0: loss = 2.27592 (* 1 = 2.27592 loss)
I0801 19:21:13.011864 12219 sgd_solver.cpp:136] Iteration 96100, lr = 0.0699688, m = 0.9
I0801 19:21:27.082479 12219 solver.cpp:353] Iteration 96200 (7.10719 iter/s, 14.0703s/100 iter), loss = 2.08655
I0801 19:21:27.082561 12219 solver.cpp:375]     Train net output #0: loss = 1.65872 (* 1 = 1.65872 loss)
I0801 19:21:27.082573 12219 sgd_solver.cpp:136] Iteration 96200, lr = 0.0699375, m = 0.9
I0801 19:21:41.034463 12219 solver.cpp:353] Iteration 96300 (7.16764 iter/s, 13.9516s/100 iter), loss = 1.97877
I0801 19:21:41.034487 12219 solver.cpp:375]     Train net output #0: loss = 1.99514 (* 1 = 1.99514 loss)
I0801 19:21:41.034492 12219 sgd_solver.cpp:136] Iteration 96300, lr = 0.0699062, m = 0.9
I0801 19:21:54.964113 12219 solver.cpp:353] Iteration 96400 (7.17913 iter/s, 13.9293s/100 iter), loss = 2.00745
I0801 19:21:54.964156 12219 solver.cpp:375]     Train net output #0: loss = 1.9075 (* 1 = 1.9075 loss)
I0801 19:21:54.964164 12219 sgd_solver.cpp:136] Iteration 96400, lr = 0.069875, m = 0.9
I0801 19:22:08.990236 12219 solver.cpp:353] Iteration 96500 (7.12975 iter/s, 14.0257s/100 iter), loss = 2.5407
I0801 19:22:08.990535 12219 solver.cpp:375]     Train net output #0: loss = 2.60151 (* 1 = 2.60151 loss)
I0801 19:22:08.990648 12219 sgd_solver.cpp:136] Iteration 96500, lr = 0.0698438, m = 0.9
I0801 19:22:22.942203 12219 solver.cpp:353] Iteration 96600 (7.16764 iter/s, 13.9516s/100 iter), loss = 1.9114
I0801 19:22:22.942256 12219 solver.cpp:375]     Train net output #0: loss = 1.9359 (* 1 = 1.9359 loss)
I0801 19:22:22.942268 12219 sgd_solver.cpp:136] Iteration 96600, lr = 0.0698125, m = 0.9
I0801 19:22:36.878355 12219 solver.cpp:353] Iteration 96700 (7.17578 iter/s, 13.9358s/100 iter), loss = 2.05594
I0801 19:22:36.878382 12219 solver.cpp:375]     Train net output #0: loss = 2.10771 (* 1 = 2.10771 loss)
I0801 19:22:36.878389 12219 sgd_solver.cpp:136] Iteration 96700, lr = 0.0697813, m = 0.9
I0801 19:22:50.753906 12219 solver.cpp:353] Iteration 96800 (7.20712 iter/s, 13.8752s/100 iter), loss = 1.9909
I0801 19:22:50.754006 12219 solver.cpp:375]     Train net output #0: loss = 1.46009 (* 1 = 1.46009 loss)
I0801 19:22:50.754014 12219 sgd_solver.cpp:136] Iteration 96800, lr = 0.06975, m = 0.9
I0801 19:23:04.641875 12219 solver.cpp:353] Iteration 96900 (7.20068 iter/s, 13.8876s/100 iter), loss = 1.52094
I0801 19:23:04.641906 12219 solver.cpp:375]     Train net output #0: loss = 1.37353 (* 1 = 1.37353 loss)
I0801 19:23:04.641911 12219 sgd_solver.cpp:136] Iteration 96900, lr = 0.0697188, m = 0.9
I0801 19:23:18.606096 12219 solver.cpp:353] Iteration 97000 (7.16136 iter/s, 13.9638s/100 iter), loss = 2.39222
I0801 19:23:18.606123 12219 solver.cpp:375]     Train net output #0: loss = 2.09478 (* 1 = 2.09478 loss)
I0801 19:23:18.606127 12219 sgd_solver.cpp:136] Iteration 97000, lr = 0.0696875, m = 0.9
I0801 19:23:32.661996 12219 solver.cpp:353] Iteration 97100 (7.11465 iter/s, 14.0555s/100 iter), loss = 2.21251
I0801 19:23:32.662096 12219 solver.cpp:375]     Train net output #0: loss = 2.0313 (* 1 = 2.0313 loss)
I0801 19:23:32.662108 12219 sgd_solver.cpp:136] Iteration 97100, lr = 0.0696563, m = 0.9
I0801 19:23:46.691848 12219 solver.cpp:353] Iteration 97200 (7.12785 iter/s, 14.0295s/100 iter), loss = 2.01829
I0801 19:23:46.691872 12219 solver.cpp:375]     Train net output #0: loss = 2.04773 (* 1 = 2.04773 loss)
I0801 19:23:46.691876 12219 sgd_solver.cpp:136] Iteration 97200, lr = 0.069625, m = 0.9
I0801 19:24:00.623234 12219 solver.cpp:353] Iteration 97300 (7.17823 iter/s, 13.931s/100 iter), loss = 2.24594
I0801 19:24:00.623262 12219 solver.cpp:375]     Train net output #0: loss = 2.21626 (* 1 = 2.21626 loss)
I0801 19:24:00.623267 12219 sgd_solver.cpp:136] Iteration 97300, lr = 0.0695937, m = 0.9
I0801 19:24:14.604324 12219 solver.cpp:353] Iteration 97400 (7.15271 iter/s, 13.9807s/100 iter), loss = 2.13251
I0801 19:24:14.604387 12219 solver.cpp:375]     Train net output #0: loss = 1.58035 (* 1 = 1.58035 loss)
I0801 19:24:14.604394 12219 sgd_solver.cpp:136] Iteration 97400, lr = 0.0695625, m = 0.9
I0801 19:24:28.567342 12219 solver.cpp:353] Iteration 97500 (7.16197 iter/s, 13.9626s/100 iter), loss = 1.65896
I0801 19:24:28.567371 12219 solver.cpp:375]     Train net output #0: loss = 1.51793 (* 1 = 1.51793 loss)
I0801 19:24:28.567375 12219 sgd_solver.cpp:136] Iteration 97500, lr = 0.0695313, m = 0.9
I0801 19:24:42.702399 12219 solver.cpp:353] Iteration 97600 (7.0748 iter/s, 14.1347s/100 iter), loss = 1.80322
I0801 19:24:42.702422 12219 solver.cpp:375]     Train net output #0: loss = 1.76869 (* 1 = 1.76869 loss)
I0801 19:24:42.702426 12219 sgd_solver.cpp:136] Iteration 97600, lr = 0.0695, m = 0.9
I0801 19:24:56.710829 12219 solver.cpp:353] Iteration 97700 (7.13875 iter/s, 14.008s/100 iter), loss = 2.35833
I0801 19:24:56.710907 12219 solver.cpp:375]     Train net output #0: loss = 2.27889 (* 1 = 2.27889 loss)
I0801 19:24:56.710921 12219 sgd_solver.cpp:136] Iteration 97700, lr = 0.0694688, m = 0.9
I0801 19:25:10.691012 12219 solver.cpp:353] Iteration 97800 (7.15318 iter/s, 13.9798s/100 iter), loss = 2.05185
I0801 19:25:10.691040 12219 solver.cpp:375]     Train net output #0: loss = 1.55617 (* 1 = 1.55617 loss)
I0801 19:25:10.691046 12219 sgd_solver.cpp:136] Iteration 97800, lr = 0.0694375, m = 0.9
I0801 19:25:24.680891 12219 solver.cpp:353] Iteration 97900 (7.14822 iter/s, 13.9895s/100 iter), loss = 2.22274
I0801 19:25:24.680917 12219 solver.cpp:375]     Train net output #0: loss = 2.45192 (* 1 = 2.45192 loss)
I0801 19:25:24.680922 12219 sgd_solver.cpp:136] Iteration 97900, lr = 0.0694062, m = 0.9
I0801 19:25:38.607234 12219 solver.cpp:550] Iteration 98000, Testing net (#0)
I0801 19:25:59.104804 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.349881
I0801 19:25:59.104835 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.608764
I0801 19:25:59.104842 12219 solver.cpp:635]     Test net output #2: loss = 3.12501 (* 1 = 3.12501 loss)
I0801 19:25:59.104889 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4971s
I0801 19:25:59.253675 12219 solver.cpp:353] Iteration 98000 (2.89253 iter/s, 34.5718s/100 iter), loss = 2.21574
I0801 19:25:59.253718 12219 solver.cpp:375]     Train net output #0: loss = 2.17839 (* 1 = 2.17839 loss)
I0801 19:25:59.253727 12219 sgd_solver.cpp:136] Iteration 98000, lr = 0.069375, m = 0.9
I0801 19:26:13.317394 12219 solver.cpp:353] Iteration 98100 (7.11069 iter/s, 14.0633s/100 iter), loss = 2.02247
I0801 19:26:13.317481 12219 solver.cpp:375]     Train net output #0: loss = 1.85793 (* 1 = 1.85793 loss)
I0801 19:26:13.317494 12219 sgd_solver.cpp:136] Iteration 98100, lr = 0.0693437, m = 0.9
I0801 19:26:27.294647 12219 solver.cpp:353] Iteration 98200 (7.15468 iter/s, 13.9769s/100 iter), loss = 1.9901
I0801 19:26:27.294670 12219 solver.cpp:375]     Train net output #0: loss = 1.93376 (* 1 = 1.93376 loss)
I0801 19:26:27.294677 12219 sgd_solver.cpp:136] Iteration 98200, lr = 0.0693125, m = 0.9
I0801 19:26:41.249838 12219 solver.cpp:353] Iteration 98300 (7.16599 iter/s, 13.9548s/100 iter), loss = 2.35074
I0801 19:26:41.249905 12219 solver.cpp:375]     Train net output #0: loss = 2.03024 (* 1 = 2.03024 loss)
I0801 19:26:41.249920 12219 sgd_solver.cpp:136] Iteration 98300, lr = 0.0692813, m = 0.9
I0801 19:26:55.325033 12219 solver.cpp:353] Iteration 98400 (7.10489 iter/s, 14.0748s/100 iter), loss = 2.23365
I0801 19:26:55.325139 12219 solver.cpp:375]     Train net output #0: loss = 2.13411 (* 1 = 2.13411 loss)
I0801 19:26:55.325160 12219 sgd_solver.cpp:136] Iteration 98400, lr = 0.06925, m = 0.9
I0801 19:27:09.319856 12219 solver.cpp:353] Iteration 98500 (7.1457 iter/s, 13.9944s/100 iter), loss = 2.36296
I0801 19:27:09.319893 12219 solver.cpp:375]     Train net output #0: loss = 1.91696 (* 1 = 1.91696 loss)
I0801 19:27:09.319900 12219 sgd_solver.cpp:136] Iteration 98500, lr = 0.0692187, m = 0.9
I0801 19:27:23.389860 12219 solver.cpp:353] Iteration 98600 (7.10752 iter/s, 14.0696s/100 iter), loss = 2.63672
I0801 19:27:23.389889 12219 solver.cpp:375]     Train net output #0: loss = 2.41445 (* 1 = 2.41445 loss)
I0801 19:27:23.389894 12219 sgd_solver.cpp:136] Iteration 98600, lr = 0.0691875, m = 0.9
I0801 19:27:37.393573 12219 solver.cpp:353] Iteration 98700 (7.14116 iter/s, 14.0033s/100 iter), loss = 2.00427
I0801 19:27:37.393671 12219 solver.cpp:375]     Train net output #0: loss = 1.64506 (* 1 = 1.64506 loss)
I0801 19:27:37.393682 12219 sgd_solver.cpp:136] Iteration 98700, lr = 0.0691563, m = 0.9
I0801 19:27:51.508971 12219 solver.cpp:353] Iteration 98800 (7.08466 iter/s, 14.115s/100 iter), loss = 2.10843
I0801 19:27:51.509048 12219 solver.cpp:375]     Train net output #0: loss = 2.4623 (* 1 = 2.4623 loss)
I0801 19:27:51.509068 12219 sgd_solver.cpp:136] Iteration 98800, lr = 0.069125, m = 0.9
I0801 19:28:05.558640 12219 solver.cpp:353] Iteration 98900 (7.1178 iter/s, 14.0493s/100 iter), loss = 2.15472
I0801 19:28:05.558873 12219 solver.cpp:375]     Train net output #0: loss = 1.92837 (* 1 = 1.92837 loss)
I0801 19:28:05.558987 12219 sgd_solver.cpp:136] Iteration 98900, lr = 0.0690938, m = 0.9
I0801 19:28:19.680848 12219 solver.cpp:353] Iteration 99000 (7.08124 iter/s, 14.1218s/100 iter), loss = 2.38499
I0801 19:28:19.680939 12219 solver.cpp:375]     Train net output #0: loss = 2.43851 (* 1 = 2.43851 loss)
I0801 19:28:19.680958 12219 sgd_solver.cpp:136] Iteration 99000, lr = 0.0690625, m = 0.9
I0801 19:28:33.816879 12219 solver.cpp:353] Iteration 99100 (7.07432 iter/s, 14.1356s/100 iter), loss = 2.28091
I0801 19:28:33.816967 12219 solver.cpp:375]     Train net output #0: loss = 2.39962 (* 1 = 2.39962 loss)
I0801 19:28:33.816987 12219 sgd_solver.cpp:136] Iteration 99100, lr = 0.0690313, m = 0.9
I0801 19:28:47.841888 12219 solver.cpp:353] Iteration 99200 (7.13032 iter/s, 14.0246s/100 iter), loss = 2.14667
I0801 19:28:47.841912 12219 solver.cpp:375]     Train net output #0: loss = 2.13722 (* 1 = 2.13722 loss)
I0801 19:28:47.841919 12219 sgd_solver.cpp:136] Iteration 99200, lr = 0.069, m = 0.9
I0801 19:29:01.793524 12219 solver.cpp:353] Iteration 99300 (7.16782 iter/s, 13.9513s/100 iter), loss = 2.37438
I0801 19:29:01.793602 12219 solver.cpp:375]     Train net output #0: loss = 2.15113 (* 1 = 2.15113 loss)
I0801 19:29:01.793668 12219 sgd_solver.cpp:136] Iteration 99300, lr = 0.0689688, m = 0.9
I0801 19:29:15.817500 12219 solver.cpp:353] Iteration 99400 (7.13084 iter/s, 14.0236s/100 iter), loss = 2.25346
I0801 19:29:15.817529 12219 solver.cpp:375]     Train net output #0: loss = 2.28585 (* 1 = 2.28585 loss)
I0801 19:29:15.817535 12219 sgd_solver.cpp:136] Iteration 99400, lr = 0.0689375, m = 0.9
I0801 19:29:29.845881 12219 solver.cpp:353] Iteration 99500 (7.1286 iter/s, 14.028s/100 iter), loss = 2.35069
I0801 19:29:29.845911 12219 solver.cpp:375]     Train net output #0: loss = 2.43246 (* 1 = 2.43246 loss)
I0801 19:29:29.845916 12219 sgd_solver.cpp:136] Iteration 99500, lr = 0.0689062, m = 0.9
I0801 19:29:43.890699 12219 solver.cpp:353] Iteration 99600 (7.12026 iter/s, 14.0444s/100 iter), loss = 1.96626
I0801 19:29:43.890781 12219 solver.cpp:375]     Train net output #0: loss = 1.85651 (* 1 = 1.85651 loss)
I0801 19:29:43.890789 12219 sgd_solver.cpp:136] Iteration 99600, lr = 0.068875, m = 0.9
I0801 19:29:57.888947 12219 solver.cpp:353] Iteration 99700 (7.14395 iter/s, 13.9978s/100 iter), loss = 2.1435
I0801 19:29:57.888999 12219 solver.cpp:375]     Train net output #0: loss = 2.23993 (* 1 = 2.23993 loss)
I0801 19:29:57.889012 12219 sgd_solver.cpp:136] Iteration 99700, lr = 0.0688437, m = 0.9
I0801 19:30:11.870900 12219 solver.cpp:353] Iteration 99800 (7.15227 iter/s, 13.9816s/100 iter), loss = 1.88886
I0801 19:30:11.870925 12219 solver.cpp:375]     Train net output #0: loss = 1.53682 (* 1 = 1.53682 loss)
I0801 19:30:11.870930 12219 sgd_solver.cpp:136] Iteration 99800, lr = 0.0688125, m = 0.9
I0801 19:30:25.881805 12219 solver.cpp:353] Iteration 99900 (7.13749 iter/s, 14.0105s/100 iter), loss = 2.06723
I0801 19:30:25.881865 12219 solver.cpp:375]     Train net output #0: loss = 1.84852 (* 1 = 1.84852 loss)
I0801 19:30:25.881872 12219 sgd_solver.cpp:136] Iteration 99900, lr = 0.0687812, m = 0.9
I0801 19:30:39.789405 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_100000.caffemodel
I0801 19:30:39.957499 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_100000.solverstate
I0801 19:30:39.963201 12219 solver.cpp:550] Iteration 100000, Testing net (#0)
I0801 19:30:58.594713 12207 data_reader.cpp:264] Starting prefetch of epoch 6
I0801 19:30:59.709342 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.416823
I0801 19:30:59.709364 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.676823
I0801 19:30:59.709370 12219 solver.cpp:635]     Test net output #2: loss = 2.66449 (* 1 = 2.66449 loss)
I0801 19:30:59.709391 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7457s
I0801 19:30:59.853971 12219 solver.cpp:353] Iteration 100000 (2.94367 iter/s, 33.9712s/100 iter), loss = 1.66675
I0801 19:30:59.853997 12219 solver.cpp:375]     Train net output #0: loss = 1.75377 (* 1 = 1.75377 loss)
I0801 19:30:59.854002 12219 sgd_solver.cpp:136] Iteration 100000, lr = 0.06875, m = 0.9
I0801 19:31:13.888495 12219 solver.cpp:353] Iteration 100100 (7.12548 iter/s, 14.0341s/100 iter), loss = 2.64885
I0801 19:31:13.888658 12219 solver.cpp:375]     Train net output #0: loss = 2.37954 (* 1 = 2.37954 loss)
I0801 19:31:13.888677 12219 sgd_solver.cpp:136] Iteration 100100, lr = 0.0687188, m = 0.9
I0801 19:31:28.026675 12219 solver.cpp:353] Iteration 100200 (7.07324 iter/s, 14.1378s/100 iter), loss = 2.3104
I0801 19:31:28.026774 12219 solver.cpp:375]     Train net output #0: loss = 2.46179 (* 1 = 2.46179 loss)
I0801 19:31:28.026796 12219 sgd_solver.cpp:136] Iteration 100200, lr = 0.0686875, m = 0.9
I0801 19:31:41.963328 12219 solver.cpp:353] Iteration 100300 (7.17552 iter/s, 13.9363s/100 iter), loss = 1.65998
I0801 19:31:41.963485 12219 solver.cpp:375]     Train net output #0: loss = 1.58405 (* 1 = 1.58405 loss)
I0801 19:31:41.963505 12219 sgd_solver.cpp:136] Iteration 100300, lr = 0.0686563, m = 0.9
I0801 19:31:56.020949 12219 solver.cpp:353] Iteration 100400 (7.11378 iter/s, 14.0572s/100 iter), loss = 2.4856
I0801 19:31:56.020978 12219 solver.cpp:375]     Train net output #0: loss = 2.72592 (* 1 = 2.72592 loss)
I0801 19:31:56.020984 12219 sgd_solver.cpp:136] Iteration 100400, lr = 0.068625, m = 0.9
I0801 19:32:09.930457 12219 solver.cpp:353] Iteration 100500 (7.18953 iter/s, 13.9091s/100 iter), loss = 2.30955
I0801 19:32:09.930480 12219 solver.cpp:375]     Train net output #0: loss = 2.93187 (* 1 = 2.93187 loss)
I0801 19:32:09.930485 12219 sgd_solver.cpp:136] Iteration 100500, lr = 0.0685938, m = 0.9
I0801 19:32:23.861690 12219 solver.cpp:353] Iteration 100600 (7.17831 iter/s, 13.9308s/100 iter), loss = 2.47782
I0801 19:32:23.861752 12219 solver.cpp:375]     Train net output #0: loss = 2.80422 (* 1 = 2.80422 loss)
I0801 19:32:23.861759 12219 sgd_solver.cpp:136] Iteration 100600, lr = 0.0685625, m = 0.9
I0801 19:32:37.839118 12219 solver.cpp:353] Iteration 100700 (7.15459 iter/s, 13.977s/100 iter), loss = 1.87196
I0801 19:32:37.839151 12219 solver.cpp:375]     Train net output #0: loss = 2.47241 (* 1 = 2.47241 loss)
I0801 19:32:37.839157 12219 sgd_solver.cpp:136] Iteration 100700, lr = 0.0685313, m = 0.9
I0801 19:32:51.927239 12219 solver.cpp:353] Iteration 100800 (7.09837 iter/s, 14.0877s/100 iter), loss = 1.76476
I0801 19:32:51.927268 12219 solver.cpp:375]     Train net output #0: loss = 1.62667 (* 1 = 1.62667 loss)
I0801 19:32:51.927273 12219 sgd_solver.cpp:136] Iteration 100800, lr = 0.0685, m = 0.9
I0801 19:33:06.158164 12219 solver.cpp:353] Iteration 100900 (7.02715 iter/s, 14.2305s/100 iter), loss = 1.80119
I0801 19:33:06.158238 12219 solver.cpp:375]     Train net output #0: loss = 2.07401 (* 1 = 2.07401 loss)
I0801 19:33:06.158246 12219 sgd_solver.cpp:136] Iteration 100900, lr = 0.0684687, m = 0.9
I0801 19:33:20.100021 12219 solver.cpp:353] Iteration 101000 (7.17284 iter/s, 13.9415s/100 iter), loss = 2.80783
I0801 19:33:20.100045 12219 solver.cpp:375]     Train net output #0: loss = 2.84899 (* 1 = 2.84899 loss)
I0801 19:33:20.100049 12219 sgd_solver.cpp:136] Iteration 101000, lr = 0.0684375, m = 0.9
I0801 19:33:34.063554 12219 solver.cpp:353] Iteration 101100 (7.16171 iter/s, 13.9631s/100 iter), loss = 2.11745
I0801 19:33:34.063577 12219 solver.cpp:375]     Train net output #0: loss = 2.01038 (* 1 = 2.01038 loss)
I0801 19:33:34.063583 12219 sgd_solver.cpp:136] Iteration 101100, lr = 0.0684062, m = 0.9
I0801 19:33:48.096510 12219 solver.cpp:353] Iteration 101200 (7.12628 iter/s, 14.0326s/100 iter), loss = 1.84737
I0801 19:33:48.096567 12219 solver.cpp:375]     Train net output #0: loss = 1.81453 (* 1 = 1.81453 loss)
I0801 19:33:48.096573 12219 sgd_solver.cpp:136] Iteration 101200, lr = 0.068375, m = 0.9
I0801 19:34:02.018051 12219 solver.cpp:353] Iteration 101300 (7.18331 iter/s, 13.9212s/100 iter), loss = 2.16876
I0801 19:34:02.018076 12219 solver.cpp:375]     Train net output #0: loss = 2.21892 (* 1 = 2.21892 loss)
I0801 19:34:02.018080 12219 sgd_solver.cpp:136] Iteration 101300, lr = 0.0683438, m = 0.9
I0801 19:34:16.062706 12219 solver.cpp:353] Iteration 101400 (7.12034 iter/s, 14.0443s/100 iter), loss = 1.74316
I0801 19:34:16.062731 12219 solver.cpp:375]     Train net output #0: loss = 1.72462 (* 1 = 1.72462 loss)
I0801 19:34:16.062736 12219 sgd_solver.cpp:136] Iteration 101400, lr = 0.0683125, m = 0.9
I0801 19:34:30.081687 12219 solver.cpp:353] Iteration 101500 (7.13338 iter/s, 14.0186s/100 iter), loss = 2.04528
I0801 19:34:30.081909 12219 solver.cpp:375]     Train net output #0: loss = 2.08258 (* 1 = 2.08258 loss)
I0801 19:34:30.081918 12219 sgd_solver.cpp:136] Iteration 101500, lr = 0.0682813, m = 0.9
I0801 19:34:44.044862 12219 solver.cpp:353] Iteration 101600 (7.16189 iter/s, 13.9628s/100 iter), loss = 1.69642
I0801 19:34:44.045112 12219 solver.cpp:375]     Train net output #0: loss = 1.79132 (* 1 = 1.79132 loss)
I0801 19:34:44.045243 12219 sgd_solver.cpp:136] Iteration 101600, lr = 0.06825, m = 0.9
I0801 19:34:58.058981 12219 solver.cpp:353] Iteration 101700 (7.13586 iter/s, 14.0137s/100 iter), loss = 1.80271
I0801 19:34:58.059010 12219 solver.cpp:375]     Train net output #0: loss = 1.38322 (* 1 = 1.38322 loss)
I0801 19:34:58.059016 12219 sgd_solver.cpp:136] Iteration 101700, lr = 0.0682188, m = 0.9
I0801 19:35:12.013299 12219 solver.cpp:353] Iteration 101800 (7.16645 iter/s, 13.9539s/100 iter), loss = 2.20894
I0801 19:35:12.013372 12219 solver.cpp:375]     Train net output #0: loss = 2.54845 (* 1 = 2.54845 loss)
I0801 19:35:12.013380 12219 sgd_solver.cpp:136] Iteration 101800, lr = 0.0681875, m = 0.9
I0801 19:35:26.033120 12219 solver.cpp:353] Iteration 101900 (7.13295 iter/s, 14.0194s/100 iter), loss = 2.33377
I0801 19:35:26.033149 12219 solver.cpp:375]     Train net output #0: loss = 2.40132 (* 1 = 2.40132 loss)
I0801 19:35:26.033156 12219 sgd_solver.cpp:136] Iteration 101900, lr = 0.0681563, m = 0.9
I0801 19:35:39.829071 12219 solver.cpp:550] Iteration 102000, Testing net (#0)
I0801 19:35:51.316781 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 19:35:59.509430 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.397823
I0801 19:35:59.509460 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.659175
I0801 19:35:59.509469 12219 solver.cpp:635]     Test net output #2: loss = 2.81182 (* 1 = 2.81182 loss)
I0801 19:35:59.509493 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6799s
I0801 19:35:59.652449 12219 solver.cpp:353] Iteration 102000 (2.97456 iter/s, 33.6184s/100 iter), loss = 2.75654
I0801 19:35:59.652477 12219 solver.cpp:375]     Train net output #0: loss = 3.42476 (* 1 = 3.42476 loss)
I0801 19:35:59.652505 12219 sgd_solver.cpp:136] Iteration 102000, lr = 0.068125, m = 0.9
I0801 19:36:13.617063 12219 solver.cpp:353] Iteration 102100 (7.16115 iter/s, 13.9642s/100 iter), loss = 1.76382
I0801 19:36:13.617091 12219 solver.cpp:375]     Train net output #0: loss = 1.72704 (* 1 = 1.72704 loss)
I0801 19:36:13.617097 12219 sgd_solver.cpp:136] Iteration 102100, lr = 0.0680938, m = 0.9
I0801 19:36:27.493350 12219 solver.cpp:353] Iteration 102200 (7.20674 iter/s, 13.8759s/100 iter), loss = 2.00968
I0801 19:36:27.493428 12219 solver.cpp:375]     Train net output #0: loss = 2.02636 (* 1 = 2.02636 loss)
I0801 19:36:27.493435 12219 sgd_solver.cpp:136] Iteration 102200, lr = 0.0680625, m = 0.9
I0801 19:36:41.426791 12219 solver.cpp:353] Iteration 102300 (7.17718 iter/s, 13.9331s/100 iter), loss = 2.60193
I0801 19:36:41.426822 12219 solver.cpp:375]     Train net output #0: loss = 3.01128 (* 1 = 3.01128 loss)
I0801 19:36:41.426828 12219 sgd_solver.cpp:136] Iteration 102300, lr = 0.0680313, m = 0.9
I0801 19:36:55.434190 12219 solver.cpp:353] Iteration 102400 (7.13928 iter/s, 14.007s/100 iter), loss = 1.82931
I0801 19:36:55.434212 12219 solver.cpp:375]     Train net output #0: loss = 2.10541 (* 1 = 2.10541 loss)
I0801 19:36:55.434216 12219 sgd_solver.cpp:136] Iteration 102400, lr = 0.068, m = 0.9
I0801 19:37:09.405443 12219 solver.cpp:353] Iteration 102500 (7.15775 iter/s, 13.9709s/100 iter), loss = 1.98869
I0801 19:37:09.405508 12219 solver.cpp:375]     Train net output #0: loss = 1.8502 (* 1 = 1.8502 loss)
I0801 19:37:09.405515 12219 sgd_solver.cpp:136] Iteration 102500, lr = 0.0679687, m = 0.9
I0801 19:37:23.456353 12219 solver.cpp:353] Iteration 102600 (7.11718 iter/s, 14.0505s/100 iter), loss = 1.76093
I0801 19:37:23.456383 12219 solver.cpp:375]     Train net output #0: loss = 1.50687 (* 1 = 1.50687 loss)
I0801 19:37:23.456389 12219 sgd_solver.cpp:136] Iteration 102600, lr = 0.0679375, m = 0.9
I0801 19:37:37.420595 12219 solver.cpp:353] Iteration 102700 (7.16135 iter/s, 13.9639s/100 iter), loss = 2.31926
I0801 19:37:37.420701 12219 solver.cpp:375]     Train net output #0: loss = 2.49889 (* 1 = 2.49889 loss)
I0801 19:37:37.420722 12219 sgd_solver.cpp:136] Iteration 102700, lr = 0.0679063, m = 0.9
I0801 19:37:51.421303 12219 solver.cpp:353] Iteration 102800 (7.14269 iter/s, 14.0003s/100 iter), loss = 2.13377
I0801 19:37:51.421406 12219 solver.cpp:375]     Train net output #0: loss = 1.77075 (* 1 = 1.77075 loss)
I0801 19:37:51.421414 12219 sgd_solver.cpp:136] Iteration 102800, lr = 0.067875, m = 0.9
I0801 19:38:05.312497 12219 solver.cpp:353] Iteration 102900 (7.19901 iter/s, 13.8908s/100 iter), loss = 2.06787
I0801 19:38:05.312526 12219 solver.cpp:375]     Train net output #0: loss = 1.93035 (* 1 = 1.93035 loss)
I0801 19:38:05.312533 12219 sgd_solver.cpp:136] Iteration 102900, lr = 0.0678438, m = 0.9
I0801 19:38:19.181686 12219 solver.cpp:353] Iteration 103000 (7.21042 iter/s, 13.8688s/100 iter), loss = 2.13053
I0801 19:38:19.181710 12219 solver.cpp:375]     Train net output #0: loss = 1.53307 (* 1 = 1.53307 loss)
I0801 19:38:19.181715 12219 sgd_solver.cpp:136] Iteration 103000, lr = 0.0678125, m = 0.9
I0801 19:38:33.262534 12219 solver.cpp:353] Iteration 103100 (7.10204 iter/s, 14.0805s/100 iter), loss = 2.03287
I0801 19:38:33.262610 12219 solver.cpp:375]     Train net output #0: loss = 1.93709 (* 1 = 1.93709 loss)
I0801 19:38:33.262617 12219 sgd_solver.cpp:136] Iteration 103100, lr = 0.0677812, m = 0.9
I0801 19:38:47.342030 12219 solver.cpp:353] Iteration 103200 (7.10273 iter/s, 14.0791s/100 iter), loss = 2.0179
I0801 19:38:47.342061 12219 solver.cpp:375]     Train net output #0: loss = 1.7375 (* 1 = 1.7375 loss)
I0801 19:38:47.342067 12219 sgd_solver.cpp:136] Iteration 103200, lr = 0.06775, m = 0.9
I0801 19:39:01.496775 12219 solver.cpp:353] Iteration 103300 (7.06496 iter/s, 14.1544s/100 iter), loss = 2.10343
I0801 19:39:01.496801 12219 solver.cpp:375]     Train net output #0: loss = 2.38939 (* 1 = 2.38939 loss)
I0801 19:39:01.496805 12219 sgd_solver.cpp:136] Iteration 103300, lr = 0.0677188, m = 0.9
I0801 19:39:15.516278 12219 solver.cpp:353] Iteration 103400 (7.13312 iter/s, 14.0191s/100 iter), loss = 2.03408
I0801 19:39:15.516332 12219 solver.cpp:375]     Train net output #0: loss = 2.54338 (* 1 = 2.54338 loss)
I0801 19:39:15.516340 12219 sgd_solver.cpp:136] Iteration 103400, lr = 0.0676875, m = 0.9
I0801 19:39:29.480226 12219 solver.cpp:353] Iteration 103500 (7.16149 iter/s, 13.9636s/100 iter), loss = 1.89013
I0801 19:39:29.480249 12219 solver.cpp:375]     Train net output #0: loss = 1.96596 (* 1 = 1.96596 loss)
I0801 19:39:29.480253 12219 sgd_solver.cpp:136] Iteration 103500, lr = 0.0676562, m = 0.9
I0801 19:39:43.429895 12219 solver.cpp:353] Iteration 103600 (7.16883 iter/s, 13.9493s/100 iter), loss = 1.79972
I0801 19:39:43.429925 12219 solver.cpp:375]     Train net output #0: loss = 1.61985 (* 1 = 1.61985 loss)
I0801 19:39:43.429932 12219 sgd_solver.cpp:136] Iteration 103600, lr = 0.067625, m = 0.9
I0801 19:39:57.615614 12219 solver.cpp:353] Iteration 103700 (7.04954 iter/s, 14.1853s/100 iter), loss = 1.72465
I0801 19:39:57.615768 12219 solver.cpp:375]     Train net output #0: loss = 1.96918 (* 1 = 1.96918 loss)
I0801 19:39:57.615789 12219 sgd_solver.cpp:136] Iteration 103700, lr = 0.0675938, m = 0.9
I0801 19:40:11.654225 12219 solver.cpp:353] Iteration 103800 (7.12341 iter/s, 14.0382s/100 iter), loss = 2.00692
I0801 19:40:11.654251 12219 solver.cpp:375]     Train net output #0: loss = 1.89309 (* 1 = 1.89309 loss)
I0801 19:40:11.654254 12219 sgd_solver.cpp:136] Iteration 103800, lr = 0.0675625, m = 0.9
I0801 19:40:25.641700 12219 solver.cpp:353] Iteration 103900 (7.14945 iter/s, 13.9871s/100 iter), loss = 2.16032
I0801 19:40:25.641801 12219 solver.cpp:375]     Train net output #0: loss = 2.13851 (* 1 = 2.13851 loss)
I0801 19:40:25.641822 12219 sgd_solver.cpp:136] Iteration 103900, lr = 0.0675313, m = 0.9
I0801 19:40:39.503206 12219 solver.cpp:550] Iteration 104000, Testing net (#0)
I0801 19:40:59.637274 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.394353
I0801 19:40:59.637300 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.652646
I0801 19:40:59.637305 12219 solver.cpp:635]     Test net output #2: loss = 2.82633 (* 1 = 2.82633 loss)
I0801 19:40:59.637323 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1336s
I0801 19:40:59.781846 12219 solver.cpp:353] Iteration 104000 (2.92918 iter/s, 34.1392s/100 iter), loss = 1.94115
I0801 19:40:59.781873 12219 solver.cpp:375]     Train net output #0: loss = 1.70816 (* 1 = 1.70816 loss)
I0801 19:40:59.781879 12219 sgd_solver.cpp:136] Iteration 104000, lr = 0.0675, m = 0.9
I0801 19:41:13.924495 12219 solver.cpp:353] Iteration 104100 (7.07101 iter/s, 14.1423s/100 iter), loss = 1.75938
I0801 19:41:13.924588 12219 solver.cpp:375]     Train net output #0: loss = 1.60134 (* 1 = 1.60134 loss)
I0801 19:41:13.924595 12219 sgd_solver.cpp:136] Iteration 104100, lr = 0.0674688, m = 0.9
I0801 19:41:27.987493 12219 solver.cpp:353] Iteration 104200 (7.11106 iter/s, 14.0626s/100 iter), loss = 2.17345
I0801 19:41:27.987521 12219 solver.cpp:375]     Train net output #0: loss = 2.43346 (* 1 = 2.43346 loss)
I0801 19:41:27.987525 12219 sgd_solver.cpp:136] Iteration 104200, lr = 0.0674375, m = 0.9
I0801 19:41:41.911154 12219 solver.cpp:353] Iteration 104300 (7.18222 iter/s, 13.9233s/100 iter), loss = 2.01701
I0801 19:41:41.911182 12219 solver.cpp:375]     Train net output #0: loss = 2.33541 (* 1 = 2.33541 loss)
I0801 19:41:41.911190 12219 sgd_solver.cpp:136] Iteration 104300, lr = 0.0674063, m = 0.9
I0801 19:41:55.929692 12219 solver.cpp:353] Iteration 104400 (7.13361 iter/s, 14.0182s/100 iter), loss = 2.60597
I0801 19:41:55.929769 12219 solver.cpp:375]     Train net output #0: loss = 2.5963 (* 1 = 2.5963 loss)
I0801 19:41:55.929775 12219 sgd_solver.cpp:136] Iteration 104400, lr = 0.067375, m = 0.9
I0801 19:42:10.080524 12219 solver.cpp:353] Iteration 104500 (7.06692 iter/s, 14.1504s/100 iter), loss = 1.95514
I0801 19:42:10.080550 12219 solver.cpp:375]     Train net output #0: loss = 1.54394 (* 1 = 1.54394 loss)
I0801 19:42:10.080555 12219 sgd_solver.cpp:136] Iteration 104500, lr = 0.0673437, m = 0.9
I0801 19:42:24.095708 12219 solver.cpp:353] Iteration 104600 (7.13532 iter/s, 14.0148s/100 iter), loss = 2.16979
I0801 19:42:24.095736 12219 solver.cpp:375]     Train net output #0: loss = 2.40311 (* 1 = 2.40311 loss)
I0801 19:42:24.095741 12219 sgd_solver.cpp:136] Iteration 104600, lr = 0.0673125, m = 0.9
I0801 19:42:38.202009 12219 solver.cpp:353] Iteration 104700 (7.08923 iter/s, 14.1059s/100 iter), loss = 1.85297
I0801 19:42:38.202106 12219 solver.cpp:375]     Train net output #0: loss = 2.15266 (* 1 = 2.15266 loss)
I0801 19:42:38.202113 12219 sgd_solver.cpp:136] Iteration 104700, lr = 0.0672812, m = 0.9
I0801 19:42:52.262555 12219 solver.cpp:353] Iteration 104800 (7.1123 iter/s, 14.0602s/100 iter), loss = 2.0583
I0801 19:42:52.262585 12219 solver.cpp:375]     Train net output #0: loss = 1.79245 (* 1 = 1.79245 loss)
I0801 19:42:52.262591 12219 sgd_solver.cpp:136] Iteration 104800, lr = 0.06725, m = 0.9
I0801 19:43:06.351361 12219 solver.cpp:353] Iteration 104900 (7.09803 iter/s, 14.0884s/100 iter), loss = 2.20719
I0801 19:43:06.351389 12219 solver.cpp:375]     Train net output #0: loss = 2.13591 (* 1 = 2.13591 loss)
I0801 19:43:06.351393 12219 sgd_solver.cpp:136] Iteration 104900, lr = 0.0672188, m = 0.9
I0801 19:43:20.368855 12219 solver.cpp:353] Iteration 105000 (7.13414 iter/s, 14.0171s/100 iter), loss = 1.69179
I0801 19:43:20.372875 12219 solver.cpp:375]     Train net output #0: loss = 1.72997 (* 1 = 1.72997 loss)
I0801 19:43:20.372895 12219 sgd_solver.cpp:136] Iteration 105000, lr = 0.0671875, m = 0.9
I0801 19:43:34.417573 12219 solver.cpp:353] Iteration 105100 (7.11828 iter/s, 14.0483s/100 iter), loss = 1.94172
I0801 19:43:34.417605 12219 solver.cpp:375]     Train net output #0: loss = 1.61228 (* 1 = 1.61228 loss)
I0801 19:43:34.417610 12219 sgd_solver.cpp:136] Iteration 105100, lr = 0.0671562, m = 0.9
I0801 19:43:48.495810 12219 solver.cpp:353] Iteration 105200 (7.10336 iter/s, 14.0779s/100 iter), loss = 2.3705
I0801 19:43:48.495833 12219 solver.cpp:375]     Train net output #0: loss = 2.37279 (* 1 = 2.37279 loss)
I0801 19:43:48.495837 12219 sgd_solver.cpp:136] Iteration 105200, lr = 0.067125, m = 0.9
I0801 19:44:02.578716 12219 solver.cpp:353] Iteration 105300 (7.101 iter/s, 14.0825s/100 iter), loss = 2.25956
I0801 19:44:02.580178 12219 solver.cpp:375]     Train net output #0: loss = 2.0267 (* 1 = 2.0267 loss)
I0801 19:44:02.580186 12219 sgd_solver.cpp:136] Iteration 105300, lr = 0.0670938, m = 0.9
I0801 19:44:16.574579 12219 solver.cpp:353] Iteration 105400 (7.14517 iter/s, 13.9955s/100 iter), loss = 2.22293
I0801 19:44:16.574609 12219 solver.cpp:375]     Train net output #0: loss = 2.04103 (* 1 = 2.04103 loss)
I0801 19:44:16.574615 12219 sgd_solver.cpp:136] Iteration 105400, lr = 0.0670625, m = 0.9
I0801 19:44:30.677199 12219 solver.cpp:353] Iteration 105500 (7.09108 iter/s, 14.1022s/100 iter), loss = 1.80394
I0801 19:44:30.677228 12219 solver.cpp:375]     Train net output #0: loss = 1.77104 (* 1 = 1.77104 loss)
I0801 19:44:30.677234 12219 sgd_solver.cpp:136] Iteration 105500, lr = 0.0670313, m = 0.9
I0801 19:44:44.661470 12219 solver.cpp:353] Iteration 105600 (7.15109 iter/s, 13.9839s/100 iter), loss = 1.90486
I0801 19:44:44.661562 12219 solver.cpp:375]     Train net output #0: loss = 1.51556 (* 1 = 1.51556 loss)
I0801 19:44:44.661571 12219 sgd_solver.cpp:136] Iteration 105600, lr = 0.067, m = 0.9
I0801 19:44:58.709969 12219 solver.cpp:353] Iteration 105700 (7.1184 iter/s, 14.0481s/100 iter), loss = 2.52676
I0801 19:44:58.710002 12219 solver.cpp:375]     Train net output #0: loss = 2.56932 (* 1 = 2.56932 loss)
I0801 19:44:58.710007 12219 sgd_solver.cpp:136] Iteration 105700, lr = 0.0669688, m = 0.9
I0801 19:45:12.687954 12219 solver.cpp:353] Iteration 105800 (7.1543 iter/s, 13.9776s/100 iter), loss = 2.10654
I0801 19:45:12.687984 12219 solver.cpp:375]     Train net output #0: loss = 2.21958 (* 1 = 2.21958 loss)
I0801 19:45:12.687990 12219 sgd_solver.cpp:136] Iteration 105800, lr = 0.0669375, m = 0.9
I0801 19:45:26.599992 12219 solver.cpp:353] Iteration 105900 (7.18822 iter/s, 13.9117s/100 iter), loss = 1.95407
I0801 19:45:26.600051 12219 solver.cpp:375]     Train net output #0: loss = 2.40937 (* 1 = 2.40937 loss)
I0801 19:45:26.600059 12219 sgd_solver.cpp:136] Iteration 105900, lr = 0.0669063, m = 0.9
I0801 19:45:40.477068 12219 solver.cpp:550] Iteration 106000, Testing net (#0)
I0801 19:46:00.565405 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.417529
I0801 19:46:00.565500 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.677764
I0801 19:46:00.565510 12219 solver.cpp:635]     Test net output #2: loss = 2.64922 (* 1 = 2.64922 loss)
I0801 19:46:00.565563 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0879s
I0801 19:46:00.719775 12219 solver.cpp:353] Iteration 106000 (2.93093 iter/s, 34.1189s/100 iter), loss = 2.28774
I0801 19:46:00.719811 12219 solver.cpp:375]     Train net output #0: loss = 2.12806 (* 1 = 2.12806 loss)
I0801 19:46:00.719817 12219 sgd_solver.cpp:136] Iteration 106000, lr = 0.066875, m = 0.9
I0801 19:46:14.825951 12219 solver.cpp:353] Iteration 106100 (7.08929 iter/s, 14.1058s/100 iter), loss = 2.10871
I0801 19:46:14.825980 12219 solver.cpp:375]     Train net output #0: loss = 2.36663 (* 1 = 2.36663 loss)
I0801 19:46:14.825984 12219 sgd_solver.cpp:136] Iteration 106100, lr = 0.0668437, m = 0.9
I0801 19:46:28.787979 12219 solver.cpp:353] Iteration 106200 (7.16248 iter/s, 13.9616s/100 iter), loss = 2.15481
I0801 19:46:28.788008 12219 solver.cpp:375]     Train net output #0: loss = 2.01456 (* 1 = 2.01456 loss)
I0801 19:46:28.788014 12219 sgd_solver.cpp:136] Iteration 106200, lr = 0.0668125, m = 0.9
I0801 19:46:42.771469 12219 solver.cpp:353] Iteration 106300 (7.15149 iter/s, 13.9831s/100 iter), loss = 1.58017
I0801 19:46:42.771594 12219 solver.cpp:375]     Train net output #0: loss = 1.53384 (* 1 = 1.53384 loss)
I0801 19:46:42.771615 12219 sgd_solver.cpp:136] Iteration 106300, lr = 0.0667812, m = 0.9
I0801 19:46:56.824915 12219 solver.cpp:353] Iteration 106400 (7.11589 iter/s, 14.0531s/100 iter), loss = 2.00108
I0801 19:46:56.824952 12219 solver.cpp:375]     Train net output #0: loss = 2.40872 (* 1 = 2.40872 loss)
I0801 19:46:56.824959 12219 sgd_solver.cpp:136] Iteration 106400, lr = 0.06675, m = 0.9
I0801 19:47:10.832849 12219 solver.cpp:353] Iteration 106500 (7.13901 iter/s, 14.0075s/100 iter), loss = 2.02481
I0801 19:47:10.832872 12219 solver.cpp:375]     Train net output #0: loss = 1.85233 (* 1 = 1.85233 loss)
I0801 19:47:10.832876 12219 sgd_solver.cpp:136] Iteration 106500, lr = 0.0667187, m = 0.9
I0801 19:47:24.809516 12219 solver.cpp:353] Iteration 106600 (7.15498 iter/s, 13.9763s/100 iter), loss = 2.30924
I0801 19:47:24.809654 12219 solver.cpp:375]     Train net output #0: loss = 2.46125 (* 1 = 2.46125 loss)
I0801 19:47:24.809679 12219 sgd_solver.cpp:136] Iteration 106600, lr = 0.0666875, m = 0.9
I0801 19:47:38.782107 12219 solver.cpp:353] Iteration 106700 (7.15707 iter/s, 13.9722s/100 iter), loss = 2.29168
I0801 19:47:38.782133 12219 solver.cpp:375]     Train net output #0: loss = 2.13373 (* 1 = 2.13373 loss)
I0801 19:47:38.782137 12219 sgd_solver.cpp:136] Iteration 106700, lr = 0.0666563, m = 0.9
I0801 19:47:52.844780 12219 solver.cpp:353] Iteration 106800 (7.11122 iter/s, 14.0623s/100 iter), loss = 2.30435
I0801 19:47:52.844805 12219 solver.cpp:375]     Train net output #0: loss = 2.00431 (* 1 = 2.00431 loss)
I0801 19:47:52.844811 12219 sgd_solver.cpp:136] Iteration 106800, lr = 0.066625, m = 0.9
I0801 19:48:06.840728 12219 solver.cpp:353] Iteration 106900 (7.14512 iter/s, 13.9956s/100 iter), loss = 2.83361
I0801 19:48:06.840790 12219 solver.cpp:375]     Train net output #0: loss = 2.74862 (* 1 = 2.74862 loss)
I0801 19:48:06.840797 12219 sgd_solver.cpp:136] Iteration 106900, lr = 0.0665938, m = 0.9
I0801 19:48:20.916119 12219 solver.cpp:353] Iteration 107000 (7.10479 iter/s, 14.075s/100 iter), loss = 2.44831
I0801 19:48:20.916149 12219 solver.cpp:375]     Train net output #0: loss = 2.67557 (* 1 = 2.67557 loss)
I0801 19:48:20.916157 12219 sgd_solver.cpp:136] Iteration 107000, lr = 0.0665625, m = 0.9
I0801 19:48:34.836977 12219 solver.cpp:353] Iteration 107100 (7.18366 iter/s, 13.9205s/100 iter), loss = 2.02308
I0801 19:48:34.837016 12219 solver.cpp:375]     Train net output #0: loss = 2.05712 (* 1 = 2.05712 loss)
I0801 19:48:34.837023 12219 sgd_solver.cpp:136] Iteration 107100, lr = 0.0665313, m = 0.9
I0801 19:48:48.763309 12219 solver.cpp:353] Iteration 107200 (7.18084 iter/s, 13.9259s/100 iter), loss = 2.44936
I0801 19:48:48.763382 12219 solver.cpp:375]     Train net output #0: loss = 2.17802 (* 1 = 2.17802 loss)
I0801 19:48:48.763389 12219 sgd_solver.cpp:136] Iteration 107200, lr = 0.0665, m = 0.9
I0801 19:49:02.669456 12219 solver.cpp:353] Iteration 107300 (7.19126 iter/s, 13.9058s/100 iter), loss = 1.96952
I0801 19:49:02.669479 12219 solver.cpp:375]     Train net output #0: loss = 1.98059 (* 1 = 1.98059 loss)
I0801 19:49:02.669484 12219 sgd_solver.cpp:136] Iteration 107300, lr = 0.0664688, m = 0.9
I0801 19:49:16.700528 12219 solver.cpp:353] Iteration 107400 (7.12724 iter/s, 14.0307s/100 iter), loss = 1.91468
I0801 19:49:16.700554 12219 solver.cpp:375]     Train net output #0: loss = 2.09041 (* 1 = 2.09041 loss)
I0801 19:49:16.700558 12219 sgd_solver.cpp:136] Iteration 107400, lr = 0.0664375, m = 0.9
I0801 19:49:30.685586 12219 solver.cpp:353] Iteration 107500 (7.15069 iter/s, 13.9847s/100 iter), loss = 2.30987
I0801 19:49:30.685645 12219 solver.cpp:375]     Train net output #0: loss = 2.71897 (* 1 = 2.71897 loss)
I0801 19:49:30.685652 12219 sgd_solver.cpp:136] Iteration 107500, lr = 0.0664062, m = 0.9
I0801 19:49:44.704962 12219 solver.cpp:353] Iteration 107600 (7.13318 iter/s, 14.019s/100 iter), loss = 1.95774
I0801 19:49:44.704991 12219 solver.cpp:375]     Train net output #0: loss = 2.05476 (* 1 = 2.05476 loss)
I0801 19:49:44.704998 12219 sgd_solver.cpp:136] Iteration 107600, lr = 0.066375, m = 0.9
I0801 19:49:58.715770 12219 solver.cpp:353] Iteration 107700 (7.13754 iter/s, 14.0104s/100 iter), loss = 1.93843
I0801 19:49:58.715797 12219 solver.cpp:375]     Train net output #0: loss = 2.1376 (* 1 = 2.1376 loss)
I0801 19:49:58.715801 12219 sgd_solver.cpp:136] Iteration 107700, lr = 0.0663437, m = 0.9
I0801 19:50:12.717098 12219 solver.cpp:353] Iteration 107800 (7.14238 iter/s, 14.0009s/100 iter), loss = 2.15239
I0801 19:50:12.717176 12219 solver.cpp:375]     Train net output #0: loss = 2.3474 (* 1 = 2.3474 loss)
I0801 19:50:12.717183 12219 sgd_solver.cpp:136] Iteration 107800, lr = 0.0663125, m = 0.9
I0801 19:50:26.680156 12219 solver.cpp:353] Iteration 107900 (7.16195 iter/s, 13.9627s/100 iter), loss = 2.33495
I0801 19:50:26.680188 12219 solver.cpp:375]     Train net output #0: loss = 2.46469 (* 1 = 2.46469 loss)
I0801 19:50:26.680196 12219 sgd_solver.cpp:136] Iteration 107900, lr = 0.0662813, m = 0.9
I0801 19:50:40.499608 12219 solver.cpp:550] Iteration 108000, Testing net (#0)
I0801 19:50:54.742036 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 19:51:00.213906 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.429588
I0801 19:51:00.213930 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.689234
I0801 19:51:00.213938 12219 solver.cpp:635]     Test net output #2: loss = 2.60603 (* 1 = 2.60603 loss)
I0801 19:51:00.213989 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7138s
I0801 19:51:00.366008 12219 solver.cpp:353] Iteration 108000 (2.96869 iter/s, 33.6849s/100 iter), loss = 1.7462
I0801 19:51:00.366035 12219 solver.cpp:375]     Train net output #0: loss = 1.61458 (* 1 = 1.61458 loss)
I0801 19:51:00.366042 12219 sgd_solver.cpp:136] Iteration 108000, lr = 0.06625, m = 0.9
I0801 19:51:14.281975 12219 solver.cpp:353] Iteration 108100 (7.18619 iter/s, 13.9156s/100 iter), loss = 2.24908
I0801 19:51:14.282004 12219 solver.cpp:375]     Train net output #0: loss = 2.37916 (* 1 = 2.37916 loss)
I0801 19:51:14.282011 12219 sgd_solver.cpp:136] Iteration 108100, lr = 0.0662187, m = 0.9
I0801 19:51:28.205673 12219 solver.cpp:353] Iteration 108200 (7.1822 iter/s, 13.9233s/100 iter), loss = 1.96101
I0801 19:51:28.205770 12219 solver.cpp:375]     Train net output #0: loss = 1.84135 (* 1 = 1.84135 loss)
I0801 19:51:28.205777 12219 sgd_solver.cpp:136] Iteration 108200, lr = 0.0661875, m = 0.9
I0801 19:51:42.151576 12219 solver.cpp:353] Iteration 108300 (7.17076 iter/s, 13.9455s/100 iter), loss = 1.98786
I0801 19:51:42.151600 12219 solver.cpp:375]     Train net output #0: loss = 1.98717 (* 1 = 1.98717 loss)
I0801 19:51:42.151604 12219 sgd_solver.cpp:136] Iteration 108300, lr = 0.0661563, m = 0.9
I0801 19:51:56.152879 12219 solver.cpp:353] Iteration 108400 (7.14239 iter/s, 14.0009s/100 iter), loss = 2.4045
I0801 19:51:56.152907 12219 solver.cpp:375]     Train net output #0: loss = 2.38903 (* 1 = 2.38903 loss)
I0801 19:51:56.152914 12219 sgd_solver.cpp:136] Iteration 108400, lr = 0.066125, m = 0.9
I0801 19:52:10.164021 12219 solver.cpp:353] Iteration 108500 (7.13738 iter/s, 14.0108s/100 iter), loss = 2.18884
I0801 19:52:10.164080 12219 solver.cpp:375]     Train net output #0: loss = 2.67471 (* 1 = 2.67471 loss)
I0801 19:52:10.164088 12219 sgd_solver.cpp:136] Iteration 108500, lr = 0.0660938, m = 0.9
I0801 19:52:24.069430 12219 solver.cpp:353] Iteration 108600 (7.19165 iter/s, 13.905s/100 iter), loss = 1.92468
I0801 19:52:24.069460 12219 solver.cpp:375]     Train net output #0: loss = 2.23432 (* 1 = 2.23432 loss)
I0801 19:52:24.069466 12219 sgd_solver.cpp:136] Iteration 108600, lr = 0.0660625, m = 0.9
I0801 19:52:38.062158 12219 solver.cpp:353] Iteration 108700 (7.14677 iter/s, 13.9923s/100 iter), loss = 2.16351
I0801 19:52:38.062189 12219 solver.cpp:375]     Train net output #0: loss = 2.18462 (* 1 = 2.18462 loss)
I0801 19:52:38.062194 12219 sgd_solver.cpp:136] Iteration 108700, lr = 0.0660313, m = 0.9
I0801 19:52:52.041188 12219 solver.cpp:353] Iteration 108800 (7.15377 iter/s, 13.9786s/100 iter), loss = 2.33695
I0801 19:52:52.041697 12219 solver.cpp:375]     Train net output #0: loss = 2.2247 (* 1 = 2.2247 loss)
I0801 19:52:52.041724 12219 sgd_solver.cpp:136] Iteration 108800, lr = 0.066, m = 0.9
I0801 19:53:06.013581 12219 solver.cpp:353] Iteration 108900 (7.15717 iter/s, 13.972s/100 iter), loss = 2.35571
I0801 19:53:06.013669 12219 solver.cpp:375]     Train net output #0: loss = 2.408 (* 1 = 2.408 loss)
I0801 19:53:06.013690 12219 sgd_solver.cpp:136] Iteration 108900, lr = 0.0659688, m = 0.9
I0801 19:53:19.992806 12219 solver.cpp:353] Iteration 109000 (7.15367 iter/s, 13.9788s/100 iter), loss = 2.07723
I0801 19:53:19.992878 12219 solver.cpp:375]     Train net output #0: loss = 2.10917 (* 1 = 2.10917 loss)
I0801 19:53:19.992892 12219 sgd_solver.cpp:136] Iteration 109000, lr = 0.0659375, m = 0.9
I0801 19:53:33.884647 12219 solver.cpp:353] Iteration 109100 (7.19867 iter/s, 13.8915s/100 iter), loss = 2.35565
I0801 19:53:33.884714 12219 solver.cpp:375]     Train net output #0: loss = 2.56871 (* 1 = 2.56871 loss)
I0801 19:53:33.884721 12219 sgd_solver.cpp:136] Iteration 109100, lr = 0.0659062, m = 0.9
I0801 19:53:47.943351 12219 solver.cpp:353] Iteration 109200 (7.11323 iter/s, 14.0583s/100 iter), loss = 2.03751
I0801 19:53:47.943379 12219 solver.cpp:375]     Train net output #0: loss = 2.31113 (* 1 = 2.31113 loss)
I0801 19:53:47.943385 12219 sgd_solver.cpp:136] Iteration 109200, lr = 0.065875, m = 0.9
I0801 19:54:02.068238 12219 solver.cpp:353] Iteration 109300 (7.0799 iter/s, 14.1245s/100 iter), loss = 1.95092
I0801 19:54:02.068270 12219 solver.cpp:375]     Train net output #0: loss = 2.2452 (* 1 = 2.2452 loss)
I0801 19:54:02.068275 12219 sgd_solver.cpp:136] Iteration 109300, lr = 0.0658438, m = 0.9
I0801 19:54:16.158740 12219 solver.cpp:353] Iteration 109400 (7.09717 iter/s, 14.0901s/100 iter), loss = 1.95139
I0801 19:54:16.158812 12219 solver.cpp:375]     Train net output #0: loss = 1.80932 (* 1 = 1.80932 loss)
I0801 19:54:16.158818 12219 sgd_solver.cpp:136] Iteration 109400, lr = 0.0658125, m = 0.9
I0801 19:54:30.270968 12219 solver.cpp:353] Iteration 109500 (7.08625 iter/s, 14.1118s/100 iter), loss = 1.78122
I0801 19:54:30.270998 12219 solver.cpp:375]     Train net output #0: loss = 1.64083 (* 1 = 1.64083 loss)
I0801 19:54:30.271003 12219 sgd_solver.cpp:136] Iteration 109500, lr = 0.0657813, m = 0.9
I0801 19:54:44.245494 12219 solver.cpp:353] Iteration 109600 (7.15608 iter/s, 13.9741s/100 iter), loss = 1.80962
I0801 19:54:44.245525 12219 solver.cpp:375]     Train net output #0: loss = 1.61792 (* 1 = 1.61792 loss)
I0801 19:54:44.245532 12219 sgd_solver.cpp:136] Iteration 109600, lr = 0.06575, m = 0.9
I0801 19:54:58.365545 12219 solver.cpp:353] Iteration 109700 (7.08232 iter/s, 14.1197s/100 iter), loss = 2.16482
I0801 19:54:58.365613 12219 solver.cpp:375]     Train net output #0: loss = 2.20469 (* 1 = 2.20469 loss)
I0801 19:54:58.365620 12219 sgd_solver.cpp:136] Iteration 109700, lr = 0.0657187, m = 0.9
I0801 19:55:12.613690 12219 solver.cpp:353] Iteration 109800 (7.01866 iter/s, 14.2477s/100 iter), loss = 2.31989
I0801 19:55:12.613808 12219 solver.cpp:375]     Train net output #0: loss = 2.50267 (* 1 = 2.50267 loss)
I0801 19:55:12.613834 12219 sgd_solver.cpp:136] Iteration 109800, lr = 0.0656875, m = 0.9
I0801 19:55:26.778918 12219 solver.cpp:353] Iteration 109900 (7.05973 iter/s, 14.1648s/100 iter), loss = 1.98356
I0801 19:55:26.778947 12219 solver.cpp:375]     Train net output #0: loss = 2.16092 (* 1 = 2.16092 loss)
I0801 19:55:26.778954 12219 sgd_solver.cpp:136] Iteration 109900, lr = 0.0656563, m = 0.9
I0801 19:55:40.603471 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_110000.caffemodel
I0801 19:55:40.632122 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_110000.solverstate
I0801 19:55:40.638149 12219 solver.cpp:550] Iteration 110000, Testing net (#0)
I0801 19:56:00.403488 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.346411
I0801 19:56:00.403578 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.601588
I0801 19:56:00.403600 12219 solver.cpp:635]     Test net output #2: loss = 3.19986 (* 1 = 3.19986 loss)
I0801 19:56:00.403673 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.765s
I0801 19:56:00.566051 12219 solver.cpp:353] Iteration 110000 (2.95979 iter/s, 33.7862s/100 iter), loss = 2.17877
I0801 19:56:00.566088 12219 solver.cpp:375]     Train net output #0: loss = 2.56722 (* 1 = 2.56722 loss)
I0801 19:56:00.566094 12219 sgd_solver.cpp:136] Iteration 110000, lr = 0.065625, m = 0.9
I0801 19:56:14.630617 12219 solver.cpp:353] Iteration 110100 (7.11026 iter/s, 14.0642s/100 iter), loss = 2.03408
I0801 19:56:14.630827 12219 solver.cpp:375]     Train net output #0: loss = 1.54358 (* 1 = 1.54358 loss)
I0801 19:56:14.630836 12219 sgd_solver.cpp:136] Iteration 110100, lr = 0.0655937, m = 0.9
I0801 19:56:28.645475 12219 solver.cpp:353] Iteration 110200 (7.13548 iter/s, 14.0145s/100 iter), loss = 2.17768
I0801 19:56:28.645504 12219 solver.cpp:375]     Train net output #0: loss = 2.22615 (* 1 = 2.22615 loss)
I0801 19:56:28.645510 12219 sgd_solver.cpp:136] Iteration 110200, lr = 0.0655625, m = 0.9
I0801 19:56:42.733067 12219 solver.cpp:353] Iteration 110300 (7.09864 iter/s, 14.0872s/100 iter), loss = 2.0895
I0801 19:56:42.733090 12219 solver.cpp:375]     Train net output #0: loss = 1.88492 (* 1 = 1.88492 loss)
I0801 19:56:42.733096 12219 sgd_solver.cpp:136] Iteration 110300, lr = 0.0655313, m = 0.9
I0801 19:56:56.762958 12219 solver.cpp:353] Iteration 110400 (7.12784 iter/s, 14.0295s/100 iter), loss = 2.00047
I0801 19:56:56.763037 12219 solver.cpp:375]     Train net output #0: loss = 2.0092 (* 1 = 2.0092 loss)
I0801 19:56:56.763046 12219 sgd_solver.cpp:136] Iteration 110400, lr = 0.0655, m = 0.9
I0801 19:57:10.818761 12219 solver.cpp:353] Iteration 110500 (7.1147 iter/s, 14.0554s/100 iter), loss = 1.34989
I0801 19:57:10.818787 12219 solver.cpp:375]     Train net output #0: loss = 1.25728 (* 1 = 1.25728 loss)
I0801 19:57:10.818794 12219 sgd_solver.cpp:136] Iteration 110500, lr = 0.0654688, m = 0.9
I0801 19:57:24.900405 12219 solver.cpp:353] Iteration 110600 (7.10164 iter/s, 14.0813s/100 iter), loss = 2.23258
I0801 19:57:24.900434 12219 solver.cpp:375]     Train net output #0: loss = 1.96661 (* 1 = 1.96661 loss)
I0801 19:57:24.900439 12219 sgd_solver.cpp:136] Iteration 110600, lr = 0.0654375, m = 0.9
I0801 19:57:38.922786 12219 solver.cpp:353] Iteration 110700 (7.13166 iter/s, 14.022s/100 iter), loss = 2.0858
I0801 19:57:38.922869 12219 solver.cpp:375]     Train net output #0: loss = 2.03943 (* 1 = 2.03943 loss)
I0801 19:57:38.922876 12219 sgd_solver.cpp:136] Iteration 110700, lr = 0.0654063, m = 0.9
I0801 19:57:52.975597 12219 solver.cpp:353] Iteration 110800 (7.11621 iter/s, 14.0524s/100 iter), loss = 2.31498
I0801 19:57:52.975625 12219 solver.cpp:375]     Train net output #0: loss = 2.74381 (* 1 = 2.74381 loss)
I0801 19:57:52.975630 12219 sgd_solver.cpp:136] Iteration 110800, lr = 0.065375, m = 0.9
I0801 19:58:06.973961 12219 solver.cpp:353] Iteration 110900 (7.14389 iter/s, 13.998s/100 iter), loss = 2.25705
I0801 19:58:06.973989 12219 solver.cpp:375]     Train net output #0: loss = 2.45807 (* 1 = 2.45807 loss)
I0801 19:58:06.973994 12219 sgd_solver.cpp:136] Iteration 110900, lr = 0.0653438, m = 0.9
I0801 19:58:20.896237 12219 solver.cpp:353] Iteration 111000 (7.18293 iter/s, 13.9219s/100 iter), loss = 1.91895
I0801 19:58:20.896292 12219 solver.cpp:375]     Train net output #0: loss = 2.0337 (* 1 = 2.0337 loss)
I0801 19:58:20.896299 12219 sgd_solver.cpp:136] Iteration 111000, lr = 0.0653125, m = 0.9
I0801 19:58:34.946593 12219 solver.cpp:353] Iteration 111100 (7.11745 iter/s, 14.05s/100 iter), loss = 2.24994
I0801 19:58:34.946619 12219 solver.cpp:375]     Train net output #0: loss = 2.68668 (* 1 = 2.68668 loss)
I0801 19:58:34.946624 12219 sgd_solver.cpp:136] Iteration 111100, lr = 0.0652812, m = 0.9
I0801 19:58:49.008373 12219 solver.cpp:353] Iteration 111200 (7.11167 iter/s, 14.0614s/100 iter), loss = 2.12867
I0801 19:58:49.008400 12219 solver.cpp:375]     Train net output #0: loss = 1.88823 (* 1 = 1.88823 loss)
I0801 19:58:49.008406 12219 sgd_solver.cpp:136] Iteration 111200, lr = 0.06525, m = 0.9
I0801 19:59:03.015213 12219 solver.cpp:353] Iteration 111300 (7.13957 iter/s, 14.0065s/100 iter), loss = 2.22249
I0801 19:59:03.015295 12219 solver.cpp:375]     Train net output #0: loss = 2.59972 (* 1 = 2.59972 loss)
I0801 19:59:03.015302 12219 sgd_solver.cpp:136] Iteration 111300, lr = 0.0652187, m = 0.9
I0801 19:59:17.002116 12219 solver.cpp:353] Iteration 111400 (7.14974 iter/s, 13.9865s/100 iter), loss = 2.17114
I0801 19:59:17.002143 12219 solver.cpp:375]     Train net output #0: loss = 2.16427 (* 1 = 2.16427 loss)
I0801 19:59:17.002147 12219 sgd_solver.cpp:136] Iteration 111400, lr = 0.0651875, m = 0.9
I0801 19:59:31.003077 12219 solver.cpp:353] Iteration 111500 (7.14256 iter/s, 14.0006s/100 iter), loss = 2.19312
I0801 19:59:31.003105 12219 solver.cpp:375]     Train net output #0: loss = 1.99013 (* 1 = 1.99013 loss)
I0801 19:59:31.003110 12219 sgd_solver.cpp:136] Iteration 111500, lr = 0.0651563, m = 0.9
I0801 19:59:45.002647 12219 solver.cpp:353] Iteration 111600 (7.14327 iter/s, 13.9992s/100 iter), loss = 1.65528
I0801 19:59:45.002717 12219 solver.cpp:375]     Train net output #0: loss = 1.79173 (* 1 = 1.79173 loss)
I0801 19:59:45.002723 12219 sgd_solver.cpp:136] Iteration 111600, lr = 0.065125, m = 0.9
I0801 19:59:59.018477 12219 solver.cpp:353] Iteration 111700 (7.13498 iter/s, 14.0154s/100 iter), loss = 1.922
I0801 19:59:59.018504 12219 solver.cpp:375]     Train net output #0: loss = 2.12926 (* 1 = 2.12926 loss)
I0801 19:59:59.018510 12219 sgd_solver.cpp:136] Iteration 111700, lr = 0.0650937, m = 0.9
I0801 20:00:13.070541 12219 solver.cpp:353] Iteration 111800 (7.11659 iter/s, 14.0517s/100 iter), loss = 1.7001
I0801 20:00:13.070593 12219 solver.cpp:375]     Train net output #0: loss = 1.52208 (* 1 = 1.52208 loss)
I0801 20:00:13.070606 12219 sgd_solver.cpp:136] Iteration 111800, lr = 0.0650625, m = 0.9
I0801 20:00:27.017289 12219 solver.cpp:353] Iteration 111900 (7.17033 iter/s, 13.9464s/100 iter), loss = 1.98319
I0801 20:00:27.017355 12219 solver.cpp:375]     Train net output #0: loss = 1.62487 (* 1 = 1.62487 loss)
I0801 20:00:27.017362 12219 sgd_solver.cpp:136] Iteration 111900, lr = 0.0650313, m = 0.9
I0801 20:00:40.844375 12219 solver.cpp:550] Iteration 112000, Testing net (#0)
I0801 20:01:00.631103 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.410117
I0801 20:01:00.631194 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.669234
I0801 20:01:00.631203 12219 solver.cpp:635]     Test net output #2: loss = 2.75088 (* 1 = 2.75088 loss)
I0801 20:01:00.631255 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7863s
I0801 20:01:00.777530 12219 solver.cpp:353] Iteration 112000 (2.96215 iter/s, 33.7593s/100 iter), loss = 2.14724
I0801 20:01:00.777556 12219 solver.cpp:375]     Train net output #0: loss = 2.2487 (* 1 = 2.2487 loss)
I0801 20:01:00.777560 12219 sgd_solver.cpp:136] Iteration 112000, lr = 0.065, m = 0.9
I0801 20:01:14.694717 12219 solver.cpp:353] Iteration 112100 (7.18556 iter/s, 13.9168s/100 iter), loss = 2.15691
I0801 20:01:14.694783 12219 solver.cpp:375]     Train net output #0: loss = 2.35412 (* 1 = 2.35412 loss)
I0801 20:01:14.694802 12219 sgd_solver.cpp:136] Iteration 112100, lr = 0.0649688, m = 0.9
I0801 20:01:28.537211 12219 solver.cpp:353] Iteration 112200 (7.22434 iter/s, 13.8421s/100 iter), loss = 1.86154
I0801 20:01:28.537245 12219 solver.cpp:375]     Train net output #0: loss = 1.73948 (* 1 = 1.73948 loss)
I0801 20:01:28.537251 12219 sgd_solver.cpp:136] Iteration 112200, lr = 0.0649375, m = 0.9
I0801 20:01:42.487699 12219 solver.cpp:353] Iteration 112300 (7.16841 iter/s, 13.9501s/100 iter), loss = 2.06233
I0801 20:01:42.487778 12219 solver.cpp:375]     Train net output #0: loss = 2.08218 (* 1 = 2.08218 loss)
I0801 20:01:42.487785 12219 sgd_solver.cpp:136] Iteration 112300, lr = 0.0649063, m = 0.9
I0801 20:01:56.514845 12219 solver.cpp:353] Iteration 112400 (7.12923 iter/s, 14.0268s/100 iter), loss = 2.07785
I0801 20:01:56.514870 12219 solver.cpp:375]     Train net output #0: loss = 2.05997 (* 1 = 2.05997 loss)
I0801 20:01:56.514876 12219 sgd_solver.cpp:136] Iteration 112400, lr = 0.064875, m = 0.9
I0801 20:02:10.418191 12219 solver.cpp:353] Iteration 112500 (7.19271 iter/s, 13.903s/100 iter), loss = 2.44524
I0801 20:02:10.418218 12219 solver.cpp:375]     Train net output #0: loss = 2.22404 (* 1 = 2.22404 loss)
I0801 20:02:10.418226 12219 sgd_solver.cpp:136] Iteration 112500, lr = 0.0648438, m = 0.9
I0801 20:02:24.246990 12219 solver.cpp:353] Iteration 112600 (7.23149 iter/s, 13.8284s/100 iter), loss = 2.12848
I0801 20:02:24.247066 12219 solver.cpp:375]     Train net output #0: loss = 2.02982 (* 1 = 2.02982 loss)
I0801 20:02:24.247073 12219 sgd_solver.cpp:136] Iteration 112600, lr = 0.0648125, m = 0.9
I0801 20:02:38.090553 12219 solver.cpp:353] Iteration 112700 (7.22377 iter/s, 13.8432s/100 iter), loss = 1.88098
I0801 20:02:38.090643 12219 solver.cpp:375]     Train net output #0: loss = 2.01242 (* 1 = 2.01242 loss)
I0801 20:02:38.090662 12219 sgd_solver.cpp:136] Iteration 112700, lr = 0.0647812, m = 0.9
I0801 20:02:51.985211 12219 solver.cpp:353] Iteration 112800 (7.19721 iter/s, 13.8943s/100 iter), loss = 1.88888
I0801 20:02:51.985240 12219 solver.cpp:375]     Train net output #0: loss = 1.97721 (* 1 = 1.97721 loss)
I0801 20:02:51.985247 12219 sgd_solver.cpp:136] Iteration 112800, lr = 0.06475, m = 0.9
I0801 20:03:05.887935 12219 solver.cpp:353] Iteration 112900 (7.19303 iter/s, 13.9023s/100 iter), loss = 2.20108
I0801 20:03:05.888000 12219 solver.cpp:375]     Train net output #0: loss = 1.93944 (* 1 = 1.93944 loss)
I0801 20:03:05.888006 12219 sgd_solver.cpp:136] Iteration 112900, lr = 0.0647187, m = 0.9
I0801 20:03:19.769183 12219 solver.cpp:353] Iteration 113000 (7.20416 iter/s, 13.8809s/100 iter), loss = 2.09988
I0801 20:03:19.769207 12219 solver.cpp:375]     Train net output #0: loss = 1.83873 (* 1 = 1.83873 loss)
I0801 20:03:19.769212 12219 sgd_solver.cpp:136] Iteration 113000, lr = 0.0646875, m = 0.9
I0801 20:03:33.653839 12219 solver.cpp:353] Iteration 113100 (7.20239 iter/s, 13.8843s/100 iter), loss = 1.89513
I0801 20:03:33.653863 12219 solver.cpp:375]     Train net output #0: loss = 2.09924 (* 1 = 2.09924 loss)
I0801 20:03:33.653867 12219 sgd_solver.cpp:136] Iteration 113100, lr = 0.0646563, m = 0.9
I0801 20:03:47.585286 12219 solver.cpp:353] Iteration 113200 (7.1782 iter/s, 13.9311s/100 iter), loss = 2.11326
I0801 20:03:47.585410 12219 solver.cpp:375]     Train net output #0: loss = 1.93292 (* 1 = 1.93292 loss)
I0801 20:03:47.585433 12219 sgd_solver.cpp:136] Iteration 113200, lr = 0.064625, m = 0.9
I0801 20:04:01.543433 12219 solver.cpp:353] Iteration 113300 (7.16447 iter/s, 13.9578s/100 iter), loss = 2.33718
I0801 20:04:01.543462 12219 solver.cpp:375]     Train net output #0: loss = 1.95835 (* 1 = 1.95835 loss)
I0801 20:04:01.543467 12219 sgd_solver.cpp:136] Iteration 113300, lr = 0.0645938, m = 0.9
I0801 20:04:15.509179 12219 solver.cpp:353] Iteration 113400 (7.16057 iter/s, 13.9654s/100 iter), loss = 2.01184
I0801 20:04:15.509207 12219 solver.cpp:375]     Train net output #0: loss = 2.07326 (* 1 = 2.07326 loss)
I0801 20:04:15.509213 12219 sgd_solver.cpp:136] Iteration 113400, lr = 0.0645625, m = 0.9
I0801 20:04:29.478493 12219 solver.cpp:353] Iteration 113500 (7.15875 iter/s, 13.9689s/100 iter), loss = 1.87836
I0801 20:04:29.478591 12219 solver.cpp:375]     Train net output #0: loss = 1.74264 (* 1 = 1.74264 loss)
I0801 20:04:29.478602 12219 sgd_solver.cpp:136] Iteration 113500, lr = 0.0645313, m = 0.9
I0801 20:04:43.440176 12219 solver.cpp:353] Iteration 113600 (7.16266 iter/s, 13.9613s/100 iter), loss = 1.88486
I0801 20:04:43.440201 12219 solver.cpp:375]     Train net output #0: loss = 1.93757 (* 1 = 1.93757 loss)
I0801 20:04:43.440206 12219 sgd_solver.cpp:136] Iteration 113600, lr = 0.0645, m = 0.9
I0801 20:04:57.407117 12219 solver.cpp:353] Iteration 113700 (7.15996 iter/s, 13.9666s/100 iter), loss = 2.0393
I0801 20:04:57.407142 12219 solver.cpp:375]     Train net output #0: loss = 2.24008 (* 1 = 2.24008 loss)
I0801 20:04:57.407148 12219 sgd_solver.cpp:136] Iteration 113700, lr = 0.0644688, m = 0.9
I0801 20:05:11.413774 12219 solver.cpp:353] Iteration 113800 (7.13966 iter/s, 14.0063s/100 iter), loss = 2.05727
I0801 20:05:11.413833 12219 solver.cpp:375]     Train net output #0: loss = 2.3528 (* 1 = 2.3528 loss)
I0801 20:05:11.413839 12219 sgd_solver.cpp:136] Iteration 113800, lr = 0.0644375, m = 0.9
I0801 20:05:25.332789 12219 solver.cpp:353] Iteration 113900 (7.18462 iter/s, 13.9186s/100 iter), loss = 2.20906
I0801 20:05:25.332826 12219 solver.cpp:375]     Train net output #0: loss = 1.99541 (* 1 = 1.99541 loss)
I0801 20:05:25.332834 12219 sgd_solver.cpp:136] Iteration 113900, lr = 0.0644063, m = 0.9
I0801 20:05:39.155952 12219 solver.cpp:550] Iteration 114000, Testing net (#0)
I0801 20:05:56.070004 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 20:05:58.366490 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.417588
I0801 20:05:58.366514 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.678587
I0801 20:05:58.366519 12219 solver.cpp:635]     Test net output #2: loss = 2.65259 (* 1 = 2.65259 loss)
I0801 20:05:58.366539 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.2101s
I0801 20:05:58.505182 12219 solver.cpp:353] Iteration 114000 (3.01464 iter/s, 33.1715s/100 iter), loss = 1.53842
I0801 20:05:58.505209 12219 solver.cpp:375]     Train net output #0: loss = 1.37668 (* 1 = 1.37668 loss)
I0801 20:05:58.505215 12219 sgd_solver.cpp:136] Iteration 114000, lr = 0.064375, m = 0.9
I0801 20:06:12.345006 12219 solver.cpp:353] Iteration 114100 (7.22573 iter/s, 13.8394s/100 iter), loss = 1.96419
I0801 20:06:12.345036 12219 solver.cpp:375]     Train net output #0: loss = 1.92242 (* 1 = 1.92242 loss)
I0801 20:06:12.345042 12219 sgd_solver.cpp:136] Iteration 114100, lr = 0.0643438, m = 0.9
I0801 20:06:26.270957 12219 solver.cpp:353] Iteration 114200 (7.18104 iter/s, 13.9256s/100 iter), loss = 2.03639
I0801 20:06:26.271011 12219 solver.cpp:375]     Train net output #0: loss = 2.03487 (* 1 = 2.03487 loss)
I0801 20:06:26.271016 12219 sgd_solver.cpp:136] Iteration 114200, lr = 0.0643125, m = 0.9
I0801 20:06:27.739084 12205 data_reader.cpp:264] Starting prefetch of epoch 3
I0801 20:06:40.210736 12219 solver.cpp:353] Iteration 114300 (7.17391 iter/s, 13.9394s/100 iter), loss = 2.23443
I0801 20:06:40.210763 12219 solver.cpp:375]     Train net output #0: loss = 2.69234 (* 1 = 2.69234 loss)
I0801 20:06:40.210770 12219 sgd_solver.cpp:136] Iteration 114300, lr = 0.0642812, m = 0.9
I0801 20:06:54.096762 12219 solver.cpp:353] Iteration 114400 (7.20168 iter/s, 13.8856s/100 iter), loss = 2.1387
I0801 20:06:54.096791 12219 solver.cpp:375]     Train net output #0: loss = 2.43821 (* 1 = 2.43821 loss)
I0801 20:06:54.096797 12219 sgd_solver.cpp:136] Iteration 114400, lr = 0.06425, m = 0.9
I0801 20:07:07.975577 12219 solver.cpp:353] Iteration 114500 (7.20543 iter/s, 13.8784s/100 iter), loss = 2.67807
I0801 20:07:07.975636 12219 solver.cpp:375]     Train net output #0: loss = 2.80546 (* 1 = 2.80546 loss)
I0801 20:07:07.975642 12219 sgd_solver.cpp:136] Iteration 114500, lr = 0.0642188, m = 0.9
I0801 20:07:21.869580 12219 solver.cpp:353] Iteration 114600 (7.19756 iter/s, 13.8936s/100 iter), loss = 2.16169
I0801 20:07:21.869611 12219 solver.cpp:375]     Train net output #0: loss = 2.00186 (* 1 = 2.00186 loss)
I0801 20:07:21.869616 12219 sgd_solver.cpp:136] Iteration 114600, lr = 0.0641875, m = 0.9
I0801 20:07:35.842051 12219 solver.cpp:353] Iteration 114700 (7.15713 iter/s, 13.9721s/100 iter), loss = 1.7658
I0801 20:07:35.842075 12219 solver.cpp:375]     Train net output #0: loss = 1.74482 (* 1 = 1.74482 loss)
I0801 20:07:35.842079 12219 sgd_solver.cpp:136] Iteration 114700, lr = 0.0641562, m = 0.9
I0801 20:07:49.715261 12219 solver.cpp:353] Iteration 114800 (7.20834 iter/s, 13.8728s/100 iter), loss = 2.18577
I0801 20:07:49.715325 12219 solver.cpp:375]     Train net output #0: loss = 2.25649 (* 1 = 2.25649 loss)
I0801 20:07:49.715332 12219 sgd_solver.cpp:136] Iteration 114800, lr = 0.064125, m = 0.9
I0801 20:08:03.680192 12219 solver.cpp:353] Iteration 114900 (7.16099 iter/s, 13.9645s/100 iter), loss = 1.73029
I0801 20:08:03.680222 12219 solver.cpp:375]     Train net output #0: loss = 1.90984 (* 1 = 1.90984 loss)
I0801 20:08:03.680227 12219 sgd_solver.cpp:136] Iteration 114900, lr = 0.0640938, m = 0.9
I0801 20:08:17.587499 12219 solver.cpp:353] Iteration 115000 (7.19066 iter/s, 13.9069s/100 iter), loss = 2.03904
I0801 20:08:17.587524 12219 solver.cpp:375]     Train net output #0: loss = 1.92141 (* 1 = 1.92141 loss)
I0801 20:08:17.587529 12219 sgd_solver.cpp:136] Iteration 115000, lr = 0.0640625, m = 0.9
I0801 20:08:31.600661 12219 solver.cpp:353] Iteration 115100 (7.13634 iter/s, 14.0128s/100 iter), loss = 2.30785
I0801 20:08:31.600757 12219 solver.cpp:375]     Train net output #0: loss = 1.96808 (* 1 = 1.96808 loss)
I0801 20:08:31.600770 12219 sgd_solver.cpp:136] Iteration 115100, lr = 0.0640313, m = 0.9
I0801 20:08:45.526531 12219 solver.cpp:353] Iteration 115200 (7.18109 iter/s, 13.9255s/100 iter), loss = 2.19704
I0801 20:08:45.526561 12219 solver.cpp:375]     Train net output #0: loss = 2.30553 (* 1 = 2.30553 loss)
I0801 20:08:45.526566 12219 sgd_solver.cpp:136] Iteration 115200, lr = 0.064, m = 0.9
I0801 20:08:59.477393 12219 solver.cpp:353] Iteration 115300 (7.16821 iter/s, 13.9505s/100 iter), loss = 2.2658
I0801 20:08:59.477421 12219 solver.cpp:375]     Train net output #0: loss = 2.64665 (* 1 = 2.64665 loss)
I0801 20:08:59.477427 12219 sgd_solver.cpp:136] Iteration 115300, lr = 0.0639688, m = 0.9
I0801 20:09:13.395875 12219 solver.cpp:353] Iteration 115400 (7.18489 iter/s, 13.9181s/100 iter), loss = 1.41375
I0801 20:09:13.395967 12219 solver.cpp:375]     Train net output #0: loss = 1.51509 (* 1 = 1.51509 loss)
I0801 20:09:13.395973 12219 sgd_solver.cpp:136] Iteration 115400, lr = 0.0639375, m = 0.9
I0801 20:09:27.262315 12219 solver.cpp:353] Iteration 115500 (7.21185 iter/s, 13.8661s/100 iter), loss = 2.15985
I0801 20:09:27.262347 12219 solver.cpp:375]     Train net output #0: loss = 2.00793 (* 1 = 2.00793 loss)
I0801 20:09:27.262354 12219 sgd_solver.cpp:136] Iteration 115500, lr = 0.0639063, m = 0.9
I0801 20:09:41.174752 12219 solver.cpp:353] Iteration 115600 (7.18802 iter/s, 13.912s/100 iter), loss = 2.48123
I0801 20:09:41.174780 12219 solver.cpp:375]     Train net output #0: loss = 2.75499 (* 1 = 2.75499 loss)
I0801 20:09:41.174787 12219 sgd_solver.cpp:136] Iteration 115600, lr = 0.063875, m = 0.9
I0801 20:09:55.139322 12219 solver.cpp:353] Iteration 115700 (7.16118 iter/s, 13.9642s/100 iter), loss = 1.60392
I0801 20:09:55.139390 12219 solver.cpp:375]     Train net output #0: loss = 1.28782 (* 1 = 1.28782 loss)
I0801 20:09:55.139397 12219 sgd_solver.cpp:136] Iteration 115700, lr = 0.0638437, m = 0.9
I0801 20:10:09.163403 12219 solver.cpp:353] Iteration 115800 (7.13079 iter/s, 14.0237s/100 iter), loss = 2.55655
I0801 20:10:09.163466 12219 solver.cpp:375]     Train net output #0: loss = 3.15521 (* 1 = 3.15521 loss)
I0801 20:10:09.163482 12219 sgd_solver.cpp:136] Iteration 115800, lr = 0.0638125, m = 0.9
I0801 20:10:23.341150 12219 solver.cpp:353] Iteration 115900 (7.0535 iter/s, 14.1774s/100 iter), loss = 2.10005
I0801 20:10:23.341177 12219 solver.cpp:375]     Train net output #0: loss = 2.45092 (* 1 = 2.45092 loss)
I0801 20:10:23.341183 12219 sgd_solver.cpp:136] Iteration 115900, lr = 0.0637813, m = 0.9
I0801 20:10:37.282142 12219 solver.cpp:550] Iteration 116000, Testing net (#0)
I0801 20:10:57.346206 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.400294
I0801 20:10:57.346230 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.65394
I0801 20:10:57.346237 12219 solver.cpp:635]     Test net output #2: loss = 2.83564 (* 1 = 2.83564 loss)
I0801 20:10:57.346261 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0636s
I0801 20:10:57.493876 12219 solver.cpp:353] Iteration 116000 (2.9281 iter/s, 34.1518s/100 iter), loss = 1.81357
I0801 20:10:57.493950 12219 solver.cpp:375]     Train net output #0: loss = 2.18704 (* 1 = 2.18704 loss)
I0801 20:10:57.493971 12219 sgd_solver.cpp:136] Iteration 116000, lr = 0.06375, m = 0.9
I0801 20:11:11.465687 12219 solver.cpp:353] Iteration 116100 (7.15747 iter/s, 13.9714s/100 iter), loss = 2.27825
I0801 20:11:11.465760 12219 solver.cpp:375]     Train net output #0: loss = 1.77141 (* 1 = 1.77141 loss)
I0801 20:11:11.465767 12219 sgd_solver.cpp:136] Iteration 116100, lr = 0.0637188, m = 0.9
I0801 20:11:25.583542 12219 solver.cpp:353] Iteration 116200 (7.08342 iter/s, 14.1175s/100 iter), loss = 2.06373
I0801 20:11:25.583654 12219 solver.cpp:375]     Train net output #0: loss = 2.01816 (* 1 = 2.01816 loss)
I0801 20:11:25.583674 12219 sgd_solver.cpp:136] Iteration 116200, lr = 0.0636875, m = 0.9
I0801 20:11:39.706657 12219 solver.cpp:353] Iteration 116300 (7.08079 iter/s, 14.1227s/100 iter), loss = 2.39574
I0801 20:11:39.706686 12219 solver.cpp:375]     Train net output #0: loss = 2.75266 (* 1 = 2.75266 loss)
I0801 20:11:39.706692 12219 sgd_solver.cpp:136] Iteration 116300, lr = 0.0636562, m = 0.9
I0801 20:11:53.763587 12219 solver.cpp:353] Iteration 116400 (7.11413 iter/s, 14.0565s/100 iter), loss = 2.22273
I0801 20:11:53.763672 12219 solver.cpp:375]     Train net output #0: loss = 2.10051 (* 1 = 2.10051 loss)
I0801 20:11:53.763679 12219 sgd_solver.cpp:136] Iteration 116400, lr = 0.063625, m = 0.9
I0801 20:12:07.685626 12219 solver.cpp:353] Iteration 116500 (7.18305 iter/s, 13.9217s/100 iter), loss = 2.01621
I0801 20:12:07.685649 12219 solver.cpp:375]     Train net output #0: loss = 1.91189 (* 1 = 1.91189 loss)
I0801 20:12:07.685653 12219 sgd_solver.cpp:136] Iteration 116500, lr = 0.0635938, m = 0.9
I0801 20:12:21.644131 12219 solver.cpp:353] Iteration 116600 (7.16429 iter/s, 13.9581s/100 iter), loss = 2.04382
I0801 20:12:21.644155 12219 solver.cpp:375]     Train net output #0: loss = 2.09989 (* 1 = 2.09989 loss)
I0801 20:12:21.644160 12219 sgd_solver.cpp:136] Iteration 116600, lr = 0.0635625, m = 0.9
I0801 20:12:35.668220 12219 solver.cpp:353] Iteration 116700 (7.13079 iter/s, 14.0237s/100 iter), loss = 1.67796
I0801 20:12:35.668381 12219 solver.cpp:375]     Train net output #0: loss = 1.72363 (* 1 = 1.72363 loss)
I0801 20:12:35.668402 12219 sgd_solver.cpp:136] Iteration 116700, lr = 0.0635312, m = 0.9
I0801 20:12:49.778055 12219 solver.cpp:353] Iteration 116800 (7.08745 iter/s, 14.1094s/100 iter), loss = 2.1349
I0801 20:12:49.778081 12219 solver.cpp:375]     Train net output #0: loss = 2.11188 (* 1 = 2.11188 loss)
I0801 20:12:49.778087 12219 sgd_solver.cpp:136] Iteration 116800, lr = 0.0635, m = 0.9
I0801 20:13:03.934135 12219 solver.cpp:353] Iteration 116900 (7.0643 iter/s, 14.1557s/100 iter), loss = 2.09001
I0801 20:13:03.934161 12219 solver.cpp:375]     Train net output #0: loss = 2.13771 (* 1 = 2.13771 loss)
I0801 20:13:03.934166 12219 sgd_solver.cpp:136] Iteration 116900, lr = 0.0634688, m = 0.9
I0801 20:13:17.967026 12219 solver.cpp:353] Iteration 117000 (7.12631 iter/s, 14.0325s/100 iter), loss = 1.83187
I0801 20:13:17.967154 12219 solver.cpp:375]     Train net output #0: loss = 1.9869 (* 1 = 1.9869 loss)
I0801 20:13:17.967178 12219 sgd_solver.cpp:136] Iteration 117000, lr = 0.0634375, m = 0.9
I0801 20:13:31.988737 12219 solver.cpp:353] Iteration 117100 (7.13199 iter/s, 14.0213s/100 iter), loss = 1.5526
I0801 20:13:31.988764 12219 solver.cpp:375]     Train net output #0: loss = 1.5491 (* 1 = 1.5491 loss)
I0801 20:13:31.988768 12219 sgd_solver.cpp:136] Iteration 117100, lr = 0.0634063, m = 0.9
I0801 20:13:45.957506 12219 solver.cpp:353] Iteration 117200 (7.15902 iter/s, 13.9684s/100 iter), loss = 2.23904
I0801 20:13:45.957532 12219 solver.cpp:375]     Train net output #0: loss = 2.06018 (* 1 = 2.06018 loss)
I0801 20:13:45.957538 12219 sgd_solver.cpp:136] Iteration 117200, lr = 0.063375, m = 0.9
I0801 20:13:59.947917 12219 solver.cpp:353] Iteration 117300 (7.14795 iter/s, 13.99s/100 iter), loss = 1.71475
I0801 20:13:59.948000 12219 solver.cpp:375]     Train net output #0: loss = 1.80391 (* 1 = 1.80391 loss)
I0801 20:13:59.948007 12219 sgd_solver.cpp:136] Iteration 117300, lr = 0.0633438, m = 0.9
I0801 20:14:14.064183 12219 solver.cpp:353] Iteration 117400 (7.08422 iter/s, 14.1159s/100 iter), loss = 2.25135
I0801 20:14:14.064208 12219 solver.cpp:375]     Train net output #0: loss = 2.03414 (* 1 = 2.03414 loss)
I0801 20:14:14.064213 12219 sgd_solver.cpp:136] Iteration 117400, lr = 0.0633125, m = 0.9
I0801 20:14:28.060046 12219 solver.cpp:353] Iteration 117500 (7.14516 iter/s, 13.9955s/100 iter), loss = 2.13832
I0801 20:14:28.060071 12219 solver.cpp:375]     Train net output #0: loss = 1.57813 (* 1 = 1.57813 loss)
I0801 20:14:28.060075 12219 sgd_solver.cpp:136] Iteration 117500, lr = 0.0632813, m = 0.9
I0801 20:14:42.068763 12219 solver.cpp:353] Iteration 117600 (7.13861 iter/s, 14.0083s/100 iter), loss = 1.78585
I0801 20:14:42.068837 12219 solver.cpp:375]     Train net output #0: loss = 1.7554 (* 1 = 1.7554 loss)
I0801 20:14:42.068845 12219 sgd_solver.cpp:136] Iteration 117600, lr = 0.06325, m = 0.9
I0801 20:14:56.214522 12219 solver.cpp:353] Iteration 117700 (7.06945 iter/s, 14.1454s/100 iter), loss = 1.85904
I0801 20:14:56.214551 12219 solver.cpp:375]     Train net output #0: loss = 1.79347 (* 1 = 1.79347 loss)
I0801 20:14:56.214558 12219 sgd_solver.cpp:136] Iteration 117700, lr = 0.0632188, m = 0.9
I0801 20:15:10.339488 12219 solver.cpp:353] Iteration 117800 (7.07986 iter/s, 14.1246s/100 iter), loss = 1.9496
I0801 20:15:10.339514 12219 solver.cpp:375]     Train net output #0: loss = 2.02544 (* 1 = 2.02544 loss)
I0801 20:15:10.339519 12219 sgd_solver.cpp:136] Iteration 117800, lr = 0.0631875, m = 0.9
I0801 20:15:24.426743 12219 solver.cpp:353] Iteration 117900 (7.09881 iter/s, 14.0869s/100 iter), loss = 1.70929
I0801 20:15:24.426846 12219 solver.cpp:375]     Train net output #0: loss = 1.65755 (* 1 = 1.65755 loss)
I0801 20:15:24.426864 12219 sgd_solver.cpp:136] Iteration 117900, lr = 0.0631562, m = 0.9
I0801 20:15:38.280591 12219 solver.cpp:550] Iteration 118000, Testing net (#0)
I0801 20:15:58.320171 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.422647
I0801 20:15:58.320267 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.684646
I0801 20:15:58.320276 12219 solver.cpp:635]     Test net output #2: loss = 2.65816 (* 1 = 2.65816 loss)
I0801 20:15:58.320297 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0392s
I0801 20:15:58.485339 12219 solver.cpp:353] Iteration 118000 (2.9362 iter/s, 34.0577s/100 iter), loss = 2.18203
I0801 20:15:58.485364 12219 solver.cpp:375]     Train net output #0: loss = 2.14391 (* 1 = 2.14391 loss)
I0801 20:15:58.485368 12219 sgd_solver.cpp:136] Iteration 118000, lr = 0.063125, m = 0.9
I0801 20:16:12.476474 12219 solver.cpp:353] Iteration 118100 (7.14758 iter/s, 13.9907s/100 iter), loss = 2.35179
I0801 20:16:12.476495 12219 solver.cpp:375]     Train net output #0: loss = 2.44103 (* 1 = 2.44103 loss)
I0801 20:16:12.476500 12219 sgd_solver.cpp:136] Iteration 118100, lr = 0.0630937, m = 0.9
I0801 20:16:26.507191 12219 solver.cpp:353] Iteration 118200 (7.12742 iter/s, 14.0303s/100 iter), loss = 2.22026
I0801 20:16:26.507259 12219 solver.cpp:375]     Train net output #0: loss = 1.81742 (* 1 = 1.81742 loss)
I0801 20:16:26.507278 12219 sgd_solver.cpp:136] Iteration 118200, lr = 0.0630625, m = 0.9
I0801 20:16:40.513283 12219 solver.cpp:353] Iteration 118300 (7.13995 iter/s, 14.0057s/100 iter), loss = 1.90002
I0801 20:16:40.513339 12219 solver.cpp:375]     Train net output #0: loss = 2.0194 (* 1 = 2.0194 loss)
I0801 20:16:40.513345 12219 sgd_solver.cpp:136] Iteration 118300, lr = 0.0630312, m = 0.9
I0801 20:16:54.504583 12219 solver.cpp:353] Iteration 118400 (7.1475 iter/s, 13.9909s/100 iter), loss = 2.04358
I0801 20:16:54.504608 12219 solver.cpp:375]     Train net output #0: loss = 1.98817 (* 1 = 1.98817 loss)
I0801 20:16:54.504612 12219 sgd_solver.cpp:136] Iteration 118400, lr = 0.063, m = 0.9
I0801 20:17:08.444512 12219 solver.cpp:353] Iteration 118500 (7.17384 iter/s, 13.9395s/100 iter), loss = 2.20588
I0801 20:17:08.444543 12219 solver.cpp:375]     Train net output #0: loss = 2.51172 (* 1 = 2.51172 loss)
I0801 20:17:08.444550 12219 sgd_solver.cpp:136] Iteration 118500, lr = 0.0629688, m = 0.9
I0801 20:17:22.528558 12219 solver.cpp:353] Iteration 118600 (7.10043 iter/s, 14.0837s/100 iter), loss = 1.73598
I0801 20:17:22.528678 12219 solver.cpp:375]     Train net output #0: loss = 1.89929 (* 1 = 1.89929 loss)
I0801 20:17:22.528686 12219 sgd_solver.cpp:136] Iteration 118600, lr = 0.0629375, m = 0.9
I0801 20:17:36.521551 12219 solver.cpp:353] Iteration 118700 (7.14663 iter/s, 13.9926s/100 iter), loss = 2.22064
I0801 20:17:36.521577 12219 solver.cpp:375]     Train net output #0: loss = 2.35309 (* 1 = 2.35309 loss)
I0801 20:17:36.521584 12219 sgd_solver.cpp:136] Iteration 118700, lr = 0.0629063, m = 0.9
I0801 20:17:50.474558 12219 solver.cpp:353] Iteration 118800 (7.16711 iter/s, 13.9526s/100 iter), loss = 1.96094
I0801 20:17:50.474586 12219 solver.cpp:375]     Train net output #0: loss = 1.9906 (* 1 = 1.9906 loss)
I0801 20:17:50.474589 12219 sgd_solver.cpp:136] Iteration 118800, lr = 0.062875, m = 0.9
I0801 20:18:04.441326 12219 solver.cpp:353] Iteration 118900 (7.16005 iter/s, 13.9664s/100 iter), loss = 1.71512
I0801 20:18:04.441431 12219 solver.cpp:375]     Train net output #0: loss = 1.59883 (* 1 = 1.59883 loss)
I0801 20:18:04.441438 12219 sgd_solver.cpp:136] Iteration 118900, lr = 0.0628438, m = 0.9
I0801 20:18:18.533846 12219 solver.cpp:353] Iteration 119000 (7.09616 iter/s, 14.0921s/100 iter), loss = 1.89032
I0801 20:18:18.533874 12219 solver.cpp:375]     Train net output #0: loss = 2.00134 (* 1 = 2.00134 loss)
I0801 20:18:18.533879 12219 sgd_solver.cpp:136] Iteration 119000, lr = 0.0628125, m = 0.9
I0801 20:18:32.576002 12219 solver.cpp:353] Iteration 119100 (7.12161 iter/s, 14.0418s/100 iter), loss = 2.20177
I0801 20:18:32.576031 12219 solver.cpp:375]     Train net output #0: loss = 2.66488 (* 1 = 2.66488 loss)
I0801 20:18:32.576036 12219 sgd_solver.cpp:136] Iteration 119100, lr = 0.0627813, m = 0.9
I0801 20:18:46.697074 12219 solver.cpp:353] Iteration 119200 (7.08181 iter/s, 14.1207s/100 iter), loss = 1.63315
I0801 20:18:46.697177 12219 solver.cpp:375]     Train net output #0: loss = 1.32271 (* 1 = 1.32271 loss)
I0801 20:18:46.697197 12219 sgd_solver.cpp:136] Iteration 119200, lr = 0.06275, m = 0.9
I0801 20:19:00.813500 12219 solver.cpp:353] Iteration 119300 (7.08414 iter/s, 14.116s/100 iter), loss = 1.75916
I0801 20:19:00.813535 12219 solver.cpp:375]     Train net output #0: loss = 1.90579 (* 1 = 1.90579 loss)
I0801 20:19:00.813541 12219 sgd_solver.cpp:136] Iteration 119300, lr = 0.0627187, m = 0.9
I0801 20:19:14.759491 12219 solver.cpp:353] Iteration 119400 (7.17072 iter/s, 13.9456s/100 iter), loss = 1.80147
I0801 20:19:14.759517 12219 solver.cpp:375]     Train net output #0: loss = 1.49946 (* 1 = 1.49946 loss)
I0801 20:19:14.759523 12219 sgd_solver.cpp:136] Iteration 119400, lr = 0.0626875, m = 0.9
I0801 20:19:28.797785 12219 solver.cpp:353] Iteration 119500 (7.12358 iter/s, 14.0379s/100 iter), loss = 2.00031
I0801 20:19:28.797865 12219 solver.cpp:375]     Train net output #0: loss = 1.60866 (* 1 = 1.60866 loss)
I0801 20:19:28.797874 12219 sgd_solver.cpp:136] Iteration 119500, lr = 0.0626562, m = 0.9
I0801 20:19:42.735944 12219 solver.cpp:353] Iteration 119600 (7.17474 iter/s, 13.9378s/100 iter), loss = 1.86734
I0801 20:19:42.735970 12219 solver.cpp:375]     Train net output #0: loss = 2.16394 (* 1 = 2.16394 loss)
I0801 20:19:42.735975 12219 sgd_solver.cpp:136] Iteration 119600, lr = 0.062625, m = 0.9
I0801 20:19:56.841703 12219 solver.cpp:353] Iteration 119700 (7.0895 iter/s, 14.1054s/100 iter), loss = 1.75996
I0801 20:19:56.841727 12219 solver.cpp:375]     Train net output #0: loss = 1.56182 (* 1 = 1.56182 loss)
I0801 20:19:56.841732 12219 sgd_solver.cpp:136] Iteration 119700, lr = 0.0625938, m = 0.9
I0801 20:20:10.788233 12219 solver.cpp:353] Iteration 119800 (7.17044 iter/s, 13.9461s/100 iter), loss = 2.08446
I0801 20:20:10.788283 12219 solver.cpp:375]     Train net output #0: loss = 1.6699 (* 1 = 1.6699 loss)
I0801 20:20:10.788288 12219 sgd_solver.cpp:136] Iteration 119800, lr = 0.0625625, m = 0.9
I0801 20:20:24.756513 12219 solver.cpp:353] Iteration 119900 (7.15928 iter/s, 13.9679s/100 iter), loss = 1.86225
I0801 20:20:24.756541 12219 solver.cpp:375]     Train net output #0: loss = 1.97879 (* 1 = 1.97879 loss)
I0801 20:20:24.756546 12219 sgd_solver.cpp:136] Iteration 119900, lr = 0.0625313, m = 0.9
I0801 20:20:38.613204 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_120000.caffemodel
I0801 20:20:38.697630 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_120000.solverstate
I0801 20:20:38.702301 12219 solver.cpp:550] Iteration 120000, Testing net (#0)
I0801 20:20:58.712184 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.429235
I0801 20:20:58.712308 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.685999
I0801 20:20:58.712317 12219 solver.cpp:635]     Test net output #2: loss = 2.59279 (* 1 = 2.59279 loss)
I0801 20:20:58.712335 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0095s
I0801 20:20:58.850819 12219 solver.cpp:353] Iteration 120000 (2.93312 iter/s, 34.0934s/100 iter), loss = 2.1686
I0801 20:20:58.850847 12219 solver.cpp:375]     Train net output #0: loss = 2.20483 (* 1 = 2.20483 loss)
I0801 20:20:58.850853 12219 sgd_solver.cpp:136] Iteration 120000, lr = 0.0625, m = 0.9
I0801 20:21:12.768877 12219 solver.cpp:353] Iteration 120100 (7.18511 iter/s, 13.9177s/100 iter), loss = 2.13614
I0801 20:21:12.768929 12219 solver.cpp:375]     Train net output #0: loss = 2.58544 (* 1 = 2.58544 loss)
I0801 20:21:12.768942 12219 sgd_solver.cpp:136] Iteration 120100, lr = 0.0624687, m = 0.9
I0801 20:21:26.745725 12219 solver.cpp:353] Iteration 120200 (7.15489 iter/s, 13.9765s/100 iter), loss = 2.60522
I0801 20:21:26.745751 12219 solver.cpp:375]     Train net output #0: loss = 2.56324 (* 1 = 2.56324 loss)
I0801 20:21:26.745756 12219 sgd_solver.cpp:136] Iteration 120200, lr = 0.0624375, m = 0.9
I0801 20:21:40.669239 12219 solver.cpp:353] Iteration 120300 (7.18229 iter/s, 13.9231s/100 iter), loss = 2.47218
I0801 20:21:40.669313 12219 solver.cpp:375]     Train net output #0: loss = 1.58647 (* 1 = 1.58647 loss)
I0801 20:21:40.669320 12219 sgd_solver.cpp:136] Iteration 120300, lr = 0.0624063, m = 0.9
I0801 20:21:54.641909 12219 solver.cpp:353] Iteration 120400 (7.15703 iter/s, 13.9723s/100 iter), loss = 2.01851
I0801 20:21:54.641933 12219 solver.cpp:375]     Train net output #0: loss = 1.54863 (* 1 = 1.54863 loss)
I0801 20:21:54.641937 12219 sgd_solver.cpp:136] Iteration 120400, lr = 0.062375, m = 0.9
I0801 20:22:08.632622 12219 solver.cpp:353] Iteration 120500 (7.1478 iter/s, 13.9903s/100 iter), loss = 1.97958
I0801 20:22:08.632652 12219 solver.cpp:375]     Train net output #0: loss = 1.79396 (* 1 = 1.79396 loss)
I0801 20:22:08.632658 12219 sgd_solver.cpp:136] Iteration 120500, lr = 0.0623438, m = 0.9
I0801 20:22:22.611742 12219 solver.cpp:353] Iteration 120600 (7.15372 iter/s, 13.9787s/100 iter), loss = 1.93427
I0801 20:22:22.611805 12219 solver.cpp:375]     Train net output #0: loss = 1.69938 (* 1 = 1.69938 loss)
I0801 20:22:22.611812 12219 sgd_solver.cpp:136] Iteration 120600, lr = 0.0623125, m = 0.9
I0801 20:22:36.562003 12219 solver.cpp:353] Iteration 120700 (7.16852 iter/s, 13.9499s/100 iter), loss = 1.74414
I0801 20:22:36.562031 12219 solver.cpp:375]     Train net output #0: loss = 1.33871 (* 1 = 1.33871 loss)
I0801 20:22:36.562034 12219 sgd_solver.cpp:136] Iteration 120700, lr = 0.0622813, m = 0.9
I0801 20:22:50.436790 12219 solver.cpp:353] Iteration 120800 (7.20752 iter/s, 13.8744s/100 iter), loss = 2.3905
I0801 20:22:50.436823 12219 solver.cpp:375]     Train net output #0: loss = 2.35671 (* 1 = 2.35671 loss)
I0801 20:22:50.436827 12219 sgd_solver.cpp:136] Iteration 120800, lr = 0.06225, m = 0.9
I0801 20:23:04.368860 12219 solver.cpp:353] Iteration 120900 (7.17788 iter/s, 13.9317s/100 iter), loss = 1.81306
I0801 20:23:04.368938 12219 solver.cpp:375]     Train net output #0: loss = 1.86971 (* 1 = 1.86971 loss)
I0801 20:23:04.368952 12219 sgd_solver.cpp:136] Iteration 120900, lr = 0.0622188, m = 0.9
I0801 20:23:18.375377 12219 solver.cpp:353] Iteration 121000 (7.13973 iter/s, 14.0061s/100 iter), loss = 1.91485
I0801 20:23:18.375403 12219 solver.cpp:375]     Train net output #0: loss = 1.67127 (* 1 = 1.67127 loss)
I0801 20:23:18.375408 12219 sgd_solver.cpp:136] Iteration 121000, lr = 0.0621875, m = 0.9
I0801 20:23:32.365761 12219 solver.cpp:353] Iteration 121100 (7.14796 iter/s, 13.99s/100 iter), loss = 2.02851
I0801 20:23:32.365787 12219 solver.cpp:375]     Train net output #0: loss = 2.11917 (* 1 = 2.11917 loss)
I0801 20:23:32.365792 12219 sgd_solver.cpp:136] Iteration 121100, lr = 0.0621562, m = 0.9
I0801 20:23:46.274852 12219 solver.cpp:353] Iteration 121200 (7.18975 iter/s, 13.9087s/100 iter), loss = 2.59805
I0801 20:23:46.274960 12219 solver.cpp:375]     Train net output #0: loss = 2.33194 (* 1 = 2.33194 loss)
I0801 20:23:46.274966 12219 sgd_solver.cpp:136] Iteration 121200, lr = 0.062125, m = 0.9
I0801 20:24:00.261387 12219 solver.cpp:353] Iteration 121300 (7.14993 iter/s, 13.9862s/100 iter), loss = 2.11381
I0801 20:24:00.261416 12219 solver.cpp:375]     Train net output #0: loss = 1.77817 (* 1 = 1.77817 loss)
I0801 20:24:00.261420 12219 sgd_solver.cpp:136] Iteration 121300, lr = 0.0620937, m = 0.9
I0801 20:24:14.388746 12219 solver.cpp:353] Iteration 121400 (7.07866 iter/s, 14.127s/100 iter), loss = 1.67464
I0801 20:24:14.388775 12219 solver.cpp:375]     Train net output #0: loss = 1.29417 (* 1 = 1.29417 loss)
I0801 20:24:14.388782 12219 sgd_solver.cpp:136] Iteration 121400, lr = 0.0620625, m = 0.9
I0801 20:24:28.485627 12219 solver.cpp:353] Iteration 121500 (7.09396 iter/s, 14.0965s/100 iter), loss = 2.12396
I0801 20:24:28.485683 12219 solver.cpp:375]     Train net output #0: loss = 2.08923 (* 1 = 2.08923 loss)
I0801 20:24:28.485690 12219 sgd_solver.cpp:136] Iteration 121500, lr = 0.0620313, m = 0.9
I0801 20:24:42.160010 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 20:24:42.661592 12219 solver.cpp:353] Iteration 121600 (7.05439 iter/s, 14.1756s/100 iter), loss = 2.18905
I0801 20:24:42.661618 12219 solver.cpp:375]     Train net output #0: loss = 2.15634 (* 1 = 2.15634 loss)
I0801 20:24:42.661623 12219 sgd_solver.cpp:136] Iteration 121600, lr = 0.062, m = 0.9
I0801 20:24:56.663921 12219 solver.cpp:353] Iteration 121700 (7.14186 iter/s, 14.0019s/100 iter), loss = 2.01745
I0801 20:24:56.663947 12219 solver.cpp:375]     Train net output #0: loss = 2.02433 (* 1 = 2.02433 loss)
I0801 20:24:56.663952 12219 sgd_solver.cpp:136] Iteration 121700, lr = 0.0619688, m = 0.9
I0801 20:25:10.738869 12219 solver.cpp:353] Iteration 121800 (7.10502 iter/s, 14.0746s/100 iter), loss = 2.14157
I0801 20:25:10.738952 12219 solver.cpp:375]     Train net output #0: loss = 1.93755 (* 1 = 1.93755 loss)
I0801 20:25:10.738960 12219 sgd_solver.cpp:136] Iteration 121800, lr = 0.0619375, m = 0.9
I0801 20:25:24.747308 12219 solver.cpp:353] Iteration 121900 (7.13876 iter/s, 14.008s/100 iter), loss = 2.27179
I0801 20:25:24.747336 12219 solver.cpp:375]     Train net output #0: loss = 2.37377 (* 1 = 2.37377 loss)
I0801 20:25:24.747342 12219 sgd_solver.cpp:136] Iteration 121900, lr = 0.0619063, m = 0.9
I0801 20:25:38.631817 12219 solver.cpp:550] Iteration 122000, Testing net (#0)
I0801 20:25:58.731992 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.433706
I0801 20:25:58.732061 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.688705
I0801 20:25:58.732069 12219 solver.cpp:635]     Test net output #2: loss = 2.57861 (* 1 = 2.57861 loss)
I0801 20:25:58.732085 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0997s
I0801 20:25:58.873010 12219 solver.cpp:353] Iteration 122000 (2.93042 iter/s, 34.1248s/100 iter), loss = 1.62882
I0801 20:25:58.873035 12219 solver.cpp:375]     Train net output #0: loss = 1.43435 (* 1 = 1.43435 loss)
I0801 20:25:58.873039 12219 sgd_solver.cpp:136] Iteration 122000, lr = 0.061875, m = 0.9
I0801 20:26:12.869751 12219 solver.cpp:353] Iteration 122100 (7.14472 iter/s, 13.9964s/100 iter), loss = 2.15046
I0801 20:26:12.869781 12219 solver.cpp:375]     Train net output #0: loss = 2.00987 (* 1 = 2.00987 loss)
I0801 20:26:12.869787 12219 sgd_solver.cpp:136] Iteration 122100, lr = 0.0618438, m = 0.9
I0801 20:26:26.820881 12219 solver.cpp:353] Iteration 122200 (7.16808 iter/s, 13.9507s/100 iter), loss = 1.72709
I0801 20:26:26.821019 12219 solver.cpp:375]     Train net output #0: loss = 1.78994 (* 1 = 1.78994 loss)
I0801 20:26:26.821046 12219 sgd_solver.cpp:136] Iteration 122200, lr = 0.0618125, m = 0.9
I0801 20:26:40.931531 12219 solver.cpp:353] Iteration 122300 (7.08704 iter/s, 14.1103s/100 iter), loss = 1.88673
I0801 20:26:40.931602 12219 solver.cpp:375]     Train net output #0: loss = 1.9761 (* 1 = 1.9761 loss)
I0801 20:26:40.931608 12219 sgd_solver.cpp:136] Iteration 122300, lr = 0.0617813, m = 0.9
I0801 20:26:54.994757 12219 solver.cpp:353] Iteration 122400 (7.11094 iter/s, 14.0628s/100 iter), loss = 1.88079
I0801 20:26:54.994781 12219 solver.cpp:375]     Train net output #0: loss = 2.02952 (* 1 = 2.02952 loss)
I0801 20:26:54.994786 12219 sgd_solver.cpp:136] Iteration 122400, lr = 0.06175, m = 0.9
I0801 20:27:09.006238 12219 solver.cpp:353] Iteration 122500 (7.1372 iter/s, 14.0111s/100 iter), loss = 2.23375
I0801 20:27:09.006264 12219 solver.cpp:375]     Train net output #0: loss = 2.11249 (* 1 = 2.11249 loss)
I0801 20:27:09.006268 12219 sgd_solver.cpp:136] Iteration 122500, lr = 0.0617188, m = 0.9
I0801 20:27:22.969904 12219 solver.cpp:353] Iteration 122600 (7.16164 iter/s, 13.9633s/100 iter), loss = 2.07198
I0801 20:27:22.969972 12219 solver.cpp:375]     Train net output #0: loss = 1.9685 (* 1 = 1.9685 loss)
I0801 20:27:22.969981 12219 sgd_solver.cpp:136] Iteration 122600, lr = 0.0616875, m = 0.9
I0801 20:27:36.988972 12219 solver.cpp:353] Iteration 122700 (7.13334 iter/s, 14.0187s/100 iter), loss = 2.23194
I0801 20:27:36.989027 12219 solver.cpp:375]     Train net output #0: loss = 2.41413 (* 1 = 2.41413 loss)
I0801 20:27:36.989064 12219 sgd_solver.cpp:136] Iteration 122700, lr = 0.0616562, m = 0.9
I0801 20:27:51.061986 12219 solver.cpp:353] Iteration 122800 (7.106 iter/s, 14.0726s/100 iter), loss = 2.5716
I0801 20:27:51.062091 12219 solver.cpp:375]     Train net output #0: loss = 2.38611 (* 1 = 2.38611 loss)
I0801 20:27:51.062113 12219 sgd_solver.cpp:136] Iteration 122800, lr = 0.061625, m = 0.9
I0801 20:28:05.174783 12219 solver.cpp:353] Iteration 122900 (7.08596 iter/s, 14.1124s/100 iter), loss = 1.75886
I0801 20:28:05.174863 12219 solver.cpp:375]     Train net output #0: loss = 2.13963 (* 1 = 2.13963 loss)
I0801 20:28:05.174870 12219 sgd_solver.cpp:136] Iteration 122900, lr = 0.0615937, m = 0.9
I0801 20:28:19.200853 12219 solver.cpp:353] Iteration 123000 (7.12978 iter/s, 14.0257s/100 iter), loss = 1.9275
I0801 20:28:19.200881 12219 solver.cpp:375]     Train net output #0: loss = 1.94614 (* 1 = 1.94614 loss)
I0801 20:28:19.200886 12219 sgd_solver.cpp:136] Iteration 123000, lr = 0.0615625, m = 0.9
I0801 20:28:33.209807 12219 solver.cpp:353] Iteration 123100 (7.13849 iter/s, 14.0086s/100 iter), loss = 2.079
I0801 20:28:33.209836 12219 solver.cpp:375]     Train net output #0: loss = 2.40633 (* 1 = 2.40633 loss)
I0801 20:28:33.209841 12219 sgd_solver.cpp:136] Iteration 123100, lr = 0.0615312, m = 0.9
I0801 20:28:47.117679 12219 solver.cpp:353] Iteration 123200 (7.19037 iter/s, 13.9075s/100 iter), loss = 1.99879
I0801 20:28:47.117744 12219 solver.cpp:375]     Train net output #0: loss = 2.09814 (* 1 = 2.09814 loss)
I0801 20:28:47.117751 12219 sgd_solver.cpp:136] Iteration 123200, lr = 0.0615, m = 0.9
I0801 20:29:01.109652 12219 solver.cpp:353] Iteration 123300 (7.14715 iter/s, 13.9916s/100 iter), loss = 1.85044
I0801 20:29:01.109678 12219 solver.cpp:375]     Train net output #0: loss = 1.63079 (* 1 = 1.63079 loss)
I0801 20:29:01.109681 12219 sgd_solver.cpp:136] Iteration 123300, lr = 0.0614688, m = 0.9
I0801 20:29:15.117213 12219 solver.cpp:353] Iteration 123400 (7.13919 iter/s, 14.0072s/100 iter), loss = 2.04305
I0801 20:29:15.117239 12219 solver.cpp:375]     Train net output #0: loss = 1.93859 (* 1 = 1.93859 loss)
I0801 20:29:15.117245 12219 sgd_solver.cpp:136] Iteration 123400, lr = 0.0614375, m = 0.9
I0801 20:29:29.197194 12219 solver.cpp:353] Iteration 123500 (7.10248 iter/s, 14.0796s/100 iter), loss = 1.88949
I0801 20:29:29.197248 12219 solver.cpp:375]     Train net output #0: loss = 1.58705 (* 1 = 1.58705 loss)
I0801 20:29:29.197253 12219 sgd_solver.cpp:136] Iteration 123500, lr = 0.0614063, m = 0.9
I0801 20:29:43.184729 12219 solver.cpp:353] Iteration 123600 (7.14942 iter/s, 13.9872s/100 iter), loss = 1.90526
I0801 20:29:43.184757 12219 solver.cpp:375]     Train net output #0: loss = 1.99801 (* 1 = 1.99801 loss)
I0801 20:29:43.184763 12219 sgd_solver.cpp:136] Iteration 123600, lr = 0.061375, m = 0.9
I0801 20:29:57.178594 12219 solver.cpp:353] Iteration 123700 (7.14618 iter/s, 13.9935s/100 iter), loss = 2.22686
I0801 20:29:57.178624 12219 solver.cpp:375]     Train net output #0: loss = 2.50561 (* 1 = 2.50561 loss)
I0801 20:29:57.178630 12219 sgd_solver.cpp:136] Iteration 123700, lr = 0.0613438, m = 0.9
I0801 20:30:11.328150 12219 solver.cpp:353] Iteration 123800 (7.06755 iter/s, 14.1492s/100 iter), loss = 1.76532
I0801 20:30:11.328227 12219 solver.cpp:375]     Train net output #0: loss = 1.88295 (* 1 = 1.88295 loss)
I0801 20:30:11.328233 12219 sgd_solver.cpp:136] Iteration 123800, lr = 0.0613125, m = 0.9
I0801 20:30:25.492800 12219 solver.cpp:353] Iteration 123900 (7.06002 iter/s, 14.1643s/100 iter), loss = 2.20085
I0801 20:30:25.492849 12219 solver.cpp:375]     Train net output #0: loss = 2.56714 (* 1 = 2.56714 loss)
I0801 20:30:25.492857 12219 sgd_solver.cpp:136] Iteration 123900, lr = 0.0612813, m = 0.9
I0801 20:30:39.392451 12219 solver.cpp:550] Iteration 124000, Testing net (#0)
I0801 20:30:59.535838 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.413529
I0801 20:30:59.535914 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.675704
I0801 20:30:59.535924 12219 solver.cpp:635]     Test net output #2: loss = 2.6742 (* 1 = 2.6742 loss)
I0801 20:30:59.535989 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.143s
I0801 20:30:59.684413 12219 solver.cpp:353] Iteration 124000 (2.92477 iter/s, 34.1907s/100 iter), loss = 2.08686
I0801 20:30:59.684442 12219 solver.cpp:375]     Train net output #0: loss = 2.11346 (* 1 = 2.11346 loss)
I0801 20:30:59.684449 12219 sgd_solver.cpp:136] Iteration 124000, lr = 0.06125, m = 0.9
I0801 20:31:13.662081 12219 solver.cpp:353] Iteration 124100 (7.15447 iter/s, 13.9773s/100 iter), loss = 2.27085
I0801 20:31:13.662143 12219 solver.cpp:375]     Train net output #0: loss = 2.24863 (* 1 = 2.24863 loss)
I0801 20:31:13.662158 12219 sgd_solver.cpp:136] Iteration 124100, lr = 0.0612187, m = 0.9
I0801 20:31:27.760251 12219 solver.cpp:353] Iteration 124200 (7.09331 iter/s, 14.0978s/100 iter), loss = 1.95118
I0801 20:31:27.760279 12219 solver.cpp:375]     Train net output #0: loss = 1.65429 (* 1 = 1.65429 loss)
I0801 20:31:27.760285 12219 sgd_solver.cpp:136] Iteration 124200, lr = 0.0611875, m = 0.9
I0801 20:31:41.846264 12219 solver.cpp:353] Iteration 124300 (7.09944 iter/s, 14.0856s/100 iter), loss = 2.05628
I0801 20:31:41.846370 12219 solver.cpp:375]     Train net output #0: loss = 2.27042 (* 1 = 2.27042 loss)
I0801 20:31:41.846384 12219 sgd_solver.cpp:136] Iteration 124300, lr = 0.0611563, m = 0.9
I0801 20:31:55.843735 12219 solver.cpp:353] Iteration 124400 (7.14434 iter/s, 13.9971s/100 iter), loss = 2.05832
I0801 20:31:55.843763 12219 solver.cpp:375]     Train net output #0: loss = 2.21201 (* 1 = 2.21201 loss)
I0801 20:31:55.843770 12219 sgd_solver.cpp:136] Iteration 124400, lr = 0.061125, m = 0.9
I0801 20:32:09.808253 12219 solver.cpp:353] Iteration 124500 (7.1612 iter/s, 13.9641s/100 iter), loss = 1.95643
I0801 20:32:09.808279 12219 solver.cpp:375]     Train net output #0: loss = 1.73669 (* 1 = 1.73669 loss)
I0801 20:32:09.808284 12219 sgd_solver.cpp:136] Iteration 124500, lr = 0.0610937, m = 0.9
I0801 20:32:23.736271 12219 solver.cpp:353] Iteration 124600 (7.17997 iter/s, 13.9276s/100 iter), loss = 1.97132
I0801 20:32:23.736340 12219 solver.cpp:375]     Train net output #0: loss = 1.76478 (* 1 = 1.76478 loss)
I0801 20:32:23.736346 12219 sgd_solver.cpp:136] Iteration 124600, lr = 0.0610625, m = 0.9
I0801 20:32:37.754612 12219 solver.cpp:353] Iteration 124700 (7.13371 iter/s, 14.018s/100 iter), loss = 2.28379
I0801 20:32:37.754637 12219 solver.cpp:375]     Train net output #0: loss = 2.07329 (* 1 = 2.07329 loss)
I0801 20:32:37.754642 12219 sgd_solver.cpp:136] Iteration 124700, lr = 0.0610312, m = 0.9
I0801 20:32:51.869596 12219 solver.cpp:353] Iteration 124800 (7.08486 iter/s, 14.1146s/100 iter), loss = 1.96579
I0801 20:32:51.869621 12219 solver.cpp:375]     Train net output #0: loss = 1.72373 (* 1 = 1.72373 loss)
I0801 20:32:51.869627 12219 sgd_solver.cpp:136] Iteration 124800, lr = 0.061, m = 0.9
I0801 20:33:05.816378 12219 solver.cpp:353] Iteration 124900 (7.17031 iter/s, 13.9464s/100 iter), loss = 2.05751
I0801 20:33:05.816463 12219 solver.cpp:375]     Train net output #0: loss = 2.17312 (* 1 = 2.17312 loss)
I0801 20:33:05.816470 12219 sgd_solver.cpp:136] Iteration 124900, lr = 0.0609688, m = 0.9
I0801 20:33:19.774233 12219 solver.cpp:353] Iteration 125000 (7.16462 iter/s, 13.9575s/100 iter), loss = 2.34522
I0801 20:33:19.774267 12219 solver.cpp:375]     Train net output #0: loss = 1.88055 (* 1 = 1.88055 loss)
I0801 20:33:19.774274 12219 sgd_solver.cpp:136] Iteration 125000, lr = 0.0609375, m = 0.9
I0801 20:33:33.770416 12219 solver.cpp:353] Iteration 125100 (7.145 iter/s, 13.9958s/100 iter), loss = 2.07261
I0801 20:33:33.770452 12219 solver.cpp:375]     Train net output #0: loss = 1.85774 (* 1 = 1.85774 loss)
I0801 20:33:33.770458 12219 sgd_solver.cpp:136] Iteration 125100, lr = 0.0609063, m = 0.9
I0801 20:33:47.817174 12219 solver.cpp:353] Iteration 125200 (7.11928 iter/s, 14.0464s/100 iter), loss = 1.55793
I0801 20:33:47.817234 12219 solver.cpp:375]     Train net output #0: loss = 1.54141 (* 1 = 1.54141 loss)
I0801 20:33:47.817240 12219 sgd_solver.cpp:136] Iteration 125200, lr = 0.060875, m = 0.9
I0801 20:34:01.823925 12219 solver.cpp:353] Iteration 125300 (7.13961 iter/s, 14.0064s/100 iter), loss = 2.36011
I0801 20:34:01.823954 12219 solver.cpp:375]     Train net output #0: loss = 2.19759 (* 1 = 2.19759 loss)
I0801 20:34:01.823959 12219 sgd_solver.cpp:136] Iteration 125300, lr = 0.0608438, m = 0.9
I0801 20:34:15.835816 12219 solver.cpp:353] Iteration 125400 (7.13699 iter/s, 14.0115s/100 iter), loss = 2.26291
I0801 20:34:15.835841 12219 solver.cpp:375]     Train net output #0: loss = 2.30998 (* 1 = 2.30998 loss)
I0801 20:34:15.835847 12219 sgd_solver.cpp:136] Iteration 125400, lr = 0.0608125, m = 0.9
I0801 20:34:29.792258 12219 solver.cpp:353] Iteration 125500 (7.16535 iter/s, 13.9561s/100 iter), loss = 2.27096
I0801 20:34:29.792337 12219 solver.cpp:375]     Train net output #0: loss = 2.06586 (* 1 = 2.06586 loss)
I0801 20:34:29.792346 12219 sgd_solver.cpp:136] Iteration 125500, lr = 0.0607813, m = 0.9
I0801 20:34:43.931519 12219 solver.cpp:353] Iteration 125600 (7.0727 iter/s, 14.1389s/100 iter), loss = 2.36403
I0801 20:34:43.931546 12219 solver.cpp:375]     Train net output #0: loss = 2.40875 (* 1 = 2.40875 loss)
I0801 20:34:43.931553 12219 sgd_solver.cpp:136] Iteration 125600, lr = 0.06075, m = 0.9
I0801 20:34:57.998687 12219 solver.cpp:353] Iteration 125700 (7.10895 iter/s, 14.0668s/100 iter), loss = 1.90448
I0801 20:34:57.998720 12219 solver.cpp:375]     Train net output #0: loss = 1.99834 (* 1 = 1.99834 loss)
I0801 20:34:57.998726 12219 sgd_solver.cpp:136] Iteration 125700, lr = 0.0607188, m = 0.9
I0801 20:35:12.041975 12219 solver.cpp:353] Iteration 125800 (7.12104 iter/s, 14.0429s/100 iter), loss = 1.90408
I0801 20:35:12.042073 12219 solver.cpp:375]     Train net output #0: loss = 2.1529 (* 1 = 2.1529 loss)
I0801 20:35:12.042089 12219 sgd_solver.cpp:136] Iteration 125800, lr = 0.0606875, m = 0.9
I0801 20:35:26.089221 12219 solver.cpp:353] Iteration 125900 (7.11903 iter/s, 14.0469s/100 iter), loss = 1.96593
I0801 20:35:26.089243 12219 solver.cpp:375]     Train net output #0: loss = 1.74516 (* 1 = 1.74516 loss)
I0801 20:35:26.089249 12219 sgd_solver.cpp:136] Iteration 125900, lr = 0.0606562, m = 0.9
I0801 20:35:39.907856 12219 solver.cpp:550] Iteration 126000, Testing net (#0)
I0801 20:35:59.996490 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.42347
I0801 20:35:59.996596 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.682999
I0801 20:35:59.996605 12219 solver.cpp:635]     Test net output #2: loss = 2.65472 (* 1 = 2.65472 loss)
I0801 20:35:59.996623 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0882s
I0801 20:36:00.142101 12219 solver.cpp:353] Iteration 126000 (2.93669 iter/s, 34.0519s/100 iter), loss = 2.44222
I0801 20:36:00.142129 12219 solver.cpp:375]     Train net output #0: loss = 2.22423 (* 1 = 2.22423 loss)
I0801 20:36:00.142133 12219 sgd_solver.cpp:136] Iteration 126000, lr = 0.060625, m = 0.9
I0801 20:36:14.121127 12219 solver.cpp:353] Iteration 126100 (7.15378 iter/s, 13.9786s/100 iter), loss = 1.98678
I0801 20:36:14.121291 12219 solver.cpp:375]     Train net output #0: loss = 1.87666 (* 1 = 1.87666 loss)
I0801 20:36:14.121311 12219 sgd_solver.cpp:136] Iteration 126100, lr = 0.0605938, m = 0.9
I0801 20:36:28.057534 12219 solver.cpp:353] Iteration 126200 (7.17565 iter/s, 13.936s/100 iter), loss = 2.23709
I0801 20:36:28.057561 12219 solver.cpp:375]     Train net output #0: loss = 2.34288 (* 1 = 2.34288 loss)
I0801 20:36:28.057567 12219 sgd_solver.cpp:136] Iteration 126200, lr = 0.0605625, m = 0.9
I0801 20:36:41.925635 12219 solver.cpp:353] Iteration 126300 (7.21099 iter/s, 13.8677s/100 iter), loss = 2.20838
I0801 20:36:41.925844 12219 solver.cpp:375]     Train net output #0: loss = 2.29162 (* 1 = 2.29162 loss)
I0801 20:36:41.925873 12219 sgd_solver.cpp:136] Iteration 126300, lr = 0.0605312, m = 0.9
I0801 20:36:55.838290 12219 solver.cpp:353] Iteration 126400 (7.1879 iter/s, 13.9123s/100 iter), loss = 1.97474
I0801 20:36:55.838317 12219 solver.cpp:375]     Train net output #0: loss = 1.7087 (* 1 = 1.7087 loss)
I0801 20:36:55.838323 12219 sgd_solver.cpp:136] Iteration 126400, lr = 0.0605, m = 0.9
I0801 20:37:09.807119 12219 solver.cpp:353] Iteration 126500 (7.15899 iter/s, 13.9684s/100 iter), loss = 2.28978
I0801 20:37:09.807148 12219 solver.cpp:375]     Train net output #0: loss = 2.01181 (* 1 = 2.01181 loss)
I0801 20:37:09.807154 12219 sgd_solver.cpp:136] Iteration 126500, lr = 0.0604688, m = 0.9
I0801 20:37:23.851934 12219 solver.cpp:353] Iteration 126600 (7.12026 iter/s, 14.0444s/100 iter), loss = 2.17804
I0801 20:37:23.851996 12219 solver.cpp:375]     Train net output #0: loss = 2.27127 (* 1 = 2.27127 loss)
I0801 20:37:23.852004 12219 sgd_solver.cpp:136] Iteration 126600, lr = 0.0604375, m = 0.9
I0801 20:37:37.829722 12219 solver.cpp:353] Iteration 126700 (7.1544 iter/s, 13.9774s/100 iter), loss = 2.10409
I0801 20:37:37.829746 12219 solver.cpp:375]     Train net output #0: loss = 1.99944 (* 1 = 1.99944 loss)
I0801 20:37:37.829751 12219 sgd_solver.cpp:136] Iteration 126700, lr = 0.0604062, m = 0.9
I0801 20:37:51.743769 12219 solver.cpp:353] Iteration 126800 (7.18718 iter/s, 13.9137s/100 iter), loss = 1.70732
I0801 20:37:51.743798 12219 solver.cpp:375]     Train net output #0: loss = 1.99958 (* 1 = 1.99958 loss)
I0801 20:37:51.743801 12219 sgd_solver.cpp:136] Iteration 126800, lr = 0.060375, m = 0.9
I0801 20:38:05.756387 12219 solver.cpp:353] Iteration 126900 (7.13662 iter/s, 14.0122s/100 iter), loss = 1.68384
I0801 20:38:05.757170 12219 solver.cpp:375]     Train net output #0: loss = 1.60612 (* 1 = 1.60612 loss)
I0801 20:38:05.757177 12219 sgd_solver.cpp:136] Iteration 126900, lr = 0.0603438, m = 0.9
I0801 20:38:19.705381 12219 solver.cpp:353] Iteration 127000 (7.16917 iter/s, 13.9486s/100 iter), loss = 1.99455
I0801 20:38:19.705407 12219 solver.cpp:375]     Train net output #0: loss = 2.17142 (* 1 = 2.17142 loss)
I0801 20:38:19.705412 12219 sgd_solver.cpp:136] Iteration 127000, lr = 0.0603125, m = 0.9
I0801 20:38:33.652794 12219 solver.cpp:353] Iteration 127100 (7.16999 iter/s, 13.947s/100 iter), loss = 1.69866
I0801 20:38:33.652833 12219 solver.cpp:375]     Train net output #0: loss = 1.91726 (* 1 = 1.91726 loss)
I0801 20:38:33.652839 12219 sgd_solver.cpp:136] Iteration 127100, lr = 0.0602813, m = 0.9
I0801 20:38:47.633677 12219 solver.cpp:353] Iteration 127200 (7.15282 iter/s, 13.9805s/100 iter), loss = 1.91087
I0801 20:38:47.633792 12219 solver.cpp:375]     Train net output #0: loss = 1.91987 (* 1 = 1.91987 loss)
I0801 20:38:47.633812 12219 sgd_solver.cpp:136] Iteration 127200, lr = 0.06025, m = 0.9
I0801 20:39:01.603463 12219 solver.cpp:353] Iteration 127300 (7.1585 iter/s, 13.9694s/100 iter), loss = 1.85031
I0801 20:39:01.603492 12219 solver.cpp:375]     Train net output #0: loss = 2.05312 (* 1 = 2.05312 loss)
I0801 20:39:01.603498 12219 sgd_solver.cpp:136] Iteration 127300, lr = 0.0602188, m = 0.9
I0801 20:39:15.588791 12219 solver.cpp:353] Iteration 127400 (7.15055 iter/s, 13.9849s/100 iter), loss = 1.8919
I0801 20:39:15.588825 12219 solver.cpp:375]     Train net output #0: loss = 2.02559 (* 1 = 2.02559 loss)
I0801 20:39:15.588831 12219 sgd_solver.cpp:136] Iteration 127400, lr = 0.0601875, m = 0.9
I0801 20:39:29.674325 12219 solver.cpp:353] Iteration 127500 (7.09968 iter/s, 14.0851s/100 iter), loss = 2.04097
I0801 20:39:29.674388 12219 solver.cpp:375]     Train net output #0: loss = 2.19308 (* 1 = 2.19308 loss)
I0801 20:39:29.674394 12219 sgd_solver.cpp:136] Iteration 127500, lr = 0.0601563, m = 0.9
I0801 20:39:43.796133 12219 solver.cpp:353] Iteration 127600 (7.08144 iter/s, 14.1214s/100 iter), loss = 1.97881
I0801 20:39:43.796162 12219 solver.cpp:375]     Train net output #0: loss = 2.35846 (* 1 = 2.35846 loss)
I0801 20:39:43.796169 12219 sgd_solver.cpp:136] Iteration 127600, lr = 0.060125, m = 0.9
I0801 20:39:57.871589 12219 solver.cpp:353] Iteration 127700 (7.10476 iter/s, 14.0751s/100 iter), loss = 1.96916
I0801 20:39:57.871732 12219 solver.cpp:375]     Train net output #0: loss = 2.30128 (* 1 = 2.30128 loss)
I0801 20:39:57.871749 12219 sgd_solver.cpp:136] Iteration 127700, lr = 0.0600937, m = 0.9
I0801 20:40:11.852558 12219 solver.cpp:353] Iteration 127800 (7.15278 iter/s, 13.9806s/100 iter), loss = 2.10714
I0801 20:40:11.852640 12219 solver.cpp:375]     Train net output #0: loss = 2.14099 (* 1 = 2.14099 loss)
I0801 20:40:11.852653 12219 sgd_solver.cpp:136] Iteration 127800, lr = 0.0600625, m = 0.9
I0801 20:40:25.801908 12219 solver.cpp:353] Iteration 127900 (7.16899 iter/s, 13.949s/100 iter), loss = 1.99384
I0801 20:40:25.801962 12219 solver.cpp:375]     Train net output #0: loss = 1.82151 (* 1 = 1.82151 loss)
I0801 20:40:25.801975 12219 sgd_solver.cpp:136] Iteration 127900, lr = 0.0600312, m = 0.9
I0801 20:40:39.749929 12219 solver.cpp:550] Iteration 128000, Testing net (#0)
I0801 20:40:42.004024 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 20:40:59.665428 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.414
I0801 20:40:59.665452 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.675116
I0801 20:40:59.665457 12219 solver.cpp:635]     Test net output #2: loss = 2.71181 (* 1 = 2.71181 loss)
I0801 20:40:59.665546 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9151s
I0801 20:40:59.821318 12219 solver.cpp:353] Iteration 128000 (2.93958 iter/s, 34.0185s/100 iter), loss = 2.17704
I0801 20:40:59.821344 12219 solver.cpp:375]     Train net output #0: loss = 2.32569 (* 1 = 2.32569 loss)
I0801 20:40:59.821349 12219 sgd_solver.cpp:136] Iteration 128000, lr = 0.06, m = 0.9
I0801 20:41:13.906419 12219 solver.cpp:353] Iteration 128100 (7.0999 iter/s, 14.0847s/100 iter), loss = 1.78411
I0801 20:41:13.906500 12219 solver.cpp:375]     Train net output #0: loss = 1.89823 (* 1 = 1.89823 loss)
I0801 20:41:13.906507 12219 sgd_solver.cpp:136] Iteration 128100, lr = 0.0599687, m = 0.9
I0801 20:41:27.967202 12219 solver.cpp:353] Iteration 128200 (7.11218 iter/s, 14.0604s/100 iter), loss = 1.70255
I0801 20:41:27.967229 12219 solver.cpp:375]     Train net output #0: loss = 1.45064 (* 1 = 1.45064 loss)
I0801 20:41:27.967236 12219 sgd_solver.cpp:136] Iteration 128200, lr = 0.0599375, m = 0.9
I0801 20:41:42.008996 12219 solver.cpp:353] Iteration 128300 (7.12179 iter/s, 14.0414s/100 iter), loss = 1.82736
I0801 20:41:42.009024 12219 solver.cpp:375]     Train net output #0: loss = 1.71917 (* 1 = 1.71917 loss)
I0801 20:41:42.009029 12219 sgd_solver.cpp:136] Iteration 128300, lr = 0.0599063, m = 0.9
I0801 20:41:56.041481 12219 solver.cpp:353] Iteration 128400 (7.12652 iter/s, 14.0321s/100 iter), loss = 2.09839
I0801 20:41:56.041549 12219 solver.cpp:375]     Train net output #0: loss = 2.30146 (* 1 = 2.30146 loss)
I0801 20:41:56.041555 12219 sgd_solver.cpp:136] Iteration 128400, lr = 0.059875, m = 0.9
I0801 20:42:10.166798 12219 solver.cpp:353] Iteration 128500 (7.07968 iter/s, 14.1249s/100 iter), loss = 2.32402
I0801 20:42:10.166822 12219 solver.cpp:375]     Train net output #0: loss = 2.34651 (* 1 = 2.34651 loss)
I0801 20:42:10.166828 12219 sgd_solver.cpp:136] Iteration 128500, lr = 0.0598437, m = 0.9
I0801 20:42:24.200793 12219 solver.cpp:353] Iteration 128600 (7.12575 iter/s, 14.0336s/100 iter), loss = 2.03831
I0801 20:42:24.200882 12219 solver.cpp:375]     Train net output #0: loss = 1.62454 (* 1 = 1.62454 loss)
I0801 20:42:24.200904 12219 sgd_solver.cpp:136] Iteration 128600, lr = 0.0598125, m = 0.9
I0801 20:42:38.118234 12219 solver.cpp:353] Iteration 128700 (7.18542 iter/s, 13.9171s/100 iter), loss = 1.81599
I0801 20:42:38.118367 12219 solver.cpp:375]     Train net output #0: loss = 1.35386 (* 1 = 1.35386 loss)
I0801 20:42:38.118386 12219 sgd_solver.cpp:136] Iteration 128700, lr = 0.0597813, m = 0.9
I0801 20:42:52.093626 12219 solver.cpp:353] Iteration 128800 (7.15563 iter/s, 13.975s/100 iter), loss = 1.81233
I0801 20:42:52.093653 12219 solver.cpp:375]     Train net output #0: loss = 1.8141 (* 1 = 1.8141 loss)
I0801 20:42:52.093658 12219 sgd_solver.cpp:136] Iteration 128800, lr = 0.05975, m = 0.9
I0801 20:43:06.185791 12219 solver.cpp:353] Iteration 128900 (7.09634 iter/s, 14.0918s/100 iter), loss = 2.14092
I0801 20:43:06.185883 12219 solver.cpp:375]     Train net output #0: loss = 2.01554 (* 1 = 2.01554 loss)
I0801 20:43:06.185904 12219 sgd_solver.cpp:136] Iteration 128900, lr = 0.0597188, m = 0.9
I0801 20:43:20.252980 12219 solver.cpp:353] Iteration 129000 (7.10894 iter/s, 14.0668s/100 iter), loss = 1.87359
I0801 20:43:20.256920 12219 solver.cpp:375]     Train net output #0: loss = 1.90275 (* 1 = 1.90275 loss)
I0801 20:43:20.256945 12219 sgd_solver.cpp:136] Iteration 129000, lr = 0.0596875, m = 0.9
I0801 20:43:34.310616 12219 solver.cpp:353] Iteration 129100 (7.11377 iter/s, 14.0572s/100 iter), loss = 2.37883
I0801 20:43:34.310642 12219 solver.cpp:375]     Train net output #0: loss = 2.23545 (* 1 = 2.23545 loss)
I0801 20:43:34.310647 12219 sgd_solver.cpp:136] Iteration 129100, lr = 0.0596563, m = 0.9
I0801 20:43:35.412525 12205 data_reader.cpp:264] Starting prefetch of epoch 4
I0801 20:43:48.210378 12219 solver.cpp:353] Iteration 129200 (7.19457 iter/s, 13.8994s/100 iter), loss = 2.10874
I0801 20:43:48.210402 12219 solver.cpp:375]     Train net output #0: loss = 1.89048 (* 1 = 1.89048 loss)
I0801 20:43:48.210405 12219 sgd_solver.cpp:136] Iteration 129200, lr = 0.059625, m = 0.9
I0801 20:44:02.275271 12219 solver.cpp:353] Iteration 129300 (7.1101 iter/s, 14.0645s/100 iter), loss = 1.77779
I0801 20:44:02.275362 12219 solver.cpp:375]     Train net output #0: loss = 1.82684 (* 1 = 1.82684 loss)
I0801 20:44:02.275368 12219 sgd_solver.cpp:136] Iteration 129300, lr = 0.0595937, m = 0.9
I0801 20:44:16.297024 12219 solver.cpp:353] Iteration 129400 (7.13197 iter/s, 14.0214s/100 iter), loss = 2.21246
I0801 20:44:16.297049 12219 solver.cpp:375]     Train net output #0: loss = 2.04333 (* 1 = 2.04333 loss)
I0801 20:44:16.297052 12219 sgd_solver.cpp:136] Iteration 129400, lr = 0.0595625, m = 0.9
I0801 20:44:30.340111 12219 solver.cpp:353] Iteration 129500 (7.12114 iter/s, 14.0427s/100 iter), loss = 1.92276
I0801 20:44:30.340137 12219 solver.cpp:375]     Train net output #0: loss = 2.33413 (* 1 = 2.33413 loss)
I0801 20:44:30.340140 12219 sgd_solver.cpp:136] Iteration 129500, lr = 0.0595312, m = 0.9
I0801 20:44:44.367131 12219 solver.cpp:353] Iteration 129600 (7.12929 iter/s, 14.0266s/100 iter), loss = 2.53091
I0801 20:44:44.367200 12219 solver.cpp:375]     Train net output #0: loss = 3.06234 (* 1 = 3.06234 loss)
I0801 20:44:44.367208 12219 sgd_solver.cpp:136] Iteration 129600, lr = 0.0595, m = 0.9
I0801 20:44:58.311005 12219 solver.cpp:353] Iteration 129700 (7.1718 iter/s, 13.9435s/100 iter), loss = 1.85793
I0801 20:44:58.311033 12219 solver.cpp:375]     Train net output #0: loss = 2.0497 (* 1 = 2.0497 loss)
I0801 20:44:58.311039 12219 sgd_solver.cpp:136] Iteration 129700, lr = 0.0594687, m = 0.9
I0801 20:45:12.340615 12219 solver.cpp:353] Iteration 129800 (7.12798 iter/s, 14.0292s/100 iter), loss = 2.35136
I0801 20:45:12.340638 12219 solver.cpp:375]     Train net output #0: loss = 2.36911 (* 1 = 2.36911 loss)
I0801 20:45:12.340642 12219 sgd_solver.cpp:136] Iteration 129800, lr = 0.0594375, m = 0.9
I0801 20:45:26.499940 12219 solver.cpp:353] Iteration 129900 (7.06268 iter/s, 14.1589s/100 iter), loss = 2.23581
I0801 20:45:26.500129 12219 solver.cpp:375]     Train net output #0: loss = 2.31611 (* 1 = 2.31611 loss)
I0801 20:45:26.500159 12219 sgd_solver.cpp:136] Iteration 129900, lr = 0.0594063, m = 0.9
I0801 20:45:40.362283 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_130000.caffemodel
I0801 20:45:40.499610 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_130000.solverstate
I0801 20:45:40.506101 12219 solver.cpp:550] Iteration 130000, Testing net (#0)
I0801 20:46:00.525231 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.424059
I0801 20:46:00.525306 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.680764
I0801 20:46:00.525317 12219 solver.cpp:635]     Test net output #2: loss = 2.6589 (* 1 = 2.6589 loss)
I0801 20:46:00.525373 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0187s
I0801 20:46:00.692723 12219 solver.cpp:353] Iteration 130000 (2.92467 iter/s, 34.1919s/100 iter), loss = 1.87121
I0801 20:46:00.692754 12219 solver.cpp:375]     Train net output #0: loss = 2.32184 (* 1 = 2.32184 loss)
I0801 20:46:00.692759 12219 sgd_solver.cpp:136] Iteration 130000, lr = 0.059375, m = 0.9
I0801 20:46:14.628270 12219 solver.cpp:353] Iteration 130100 (7.17609 iter/s, 13.9352s/100 iter), loss = 2.11108
I0801 20:46:14.628296 12219 solver.cpp:375]     Train net output #0: loss = 2.18189 (* 1 = 2.18189 loss)
I0801 20:46:14.628301 12219 sgd_solver.cpp:136] Iteration 130100, lr = 0.0593438, m = 0.9
I0801 20:46:28.788312 12219 solver.cpp:353] Iteration 130200 (7.06233 iter/s, 14.1596s/100 iter), loss = 2.30313
I0801 20:46:28.788341 12219 solver.cpp:375]     Train net output #0: loss = 2.18663 (* 1 = 2.18663 loss)
I0801 20:46:28.788347 12219 sgd_solver.cpp:136] Iteration 130200, lr = 0.0593125, m = 0.9
I0801 20:46:42.845774 12219 solver.cpp:353] Iteration 130300 (7.11385 iter/s, 14.0571s/100 iter), loss = 2.18261
I0801 20:46:42.845870 12219 solver.cpp:375]     Train net output #0: loss = 1.98357 (* 1 = 1.98357 loss)
I0801 20:46:42.845888 12219 sgd_solver.cpp:136] Iteration 130300, lr = 0.0592813, m = 0.9
I0801 20:46:56.947144 12219 solver.cpp:353] Iteration 130400 (7.0917 iter/s, 14.101s/100 iter), loss = 1.72616
I0801 20:46:56.947167 12219 solver.cpp:375]     Train net output #0: loss = 1.92425 (* 1 = 1.92425 loss)
I0801 20:46:56.947173 12219 sgd_solver.cpp:136] Iteration 130400, lr = 0.05925, m = 0.9
I0801 20:47:10.896317 12219 solver.cpp:353] Iteration 130500 (7.16908 iter/s, 13.9488s/100 iter), loss = 1.96883
I0801 20:47:10.896344 12219 solver.cpp:375]     Train net output #0: loss = 2.40065 (* 1 = 2.40065 loss)
I0801 20:47:10.896349 12219 sgd_solver.cpp:136] Iteration 130500, lr = 0.0592188, m = 0.9
I0801 20:47:24.856884 12219 solver.cpp:353] Iteration 130600 (7.16323 iter/s, 13.9602s/100 iter), loss = 2.53274
I0801 20:47:24.856940 12219 solver.cpp:375]     Train net output #0: loss = 3.00698 (* 1 = 3.00698 loss)
I0801 20:47:24.856946 12219 sgd_solver.cpp:136] Iteration 130600, lr = 0.0591875, m = 0.9
I0801 20:47:38.820931 12219 solver.cpp:353] Iteration 130700 (7.16144 iter/s, 13.9637s/100 iter), loss = 2.03923
I0801 20:47:38.820958 12219 solver.cpp:375]     Train net output #0: loss = 2.3241 (* 1 = 2.3241 loss)
I0801 20:47:38.820963 12219 sgd_solver.cpp:136] Iteration 130700, lr = 0.0591563, m = 0.9
I0801 20:47:52.840065 12219 solver.cpp:353] Iteration 130800 (7.1333 iter/s, 14.0187s/100 iter), loss = 2.13994
I0801 20:47:52.840091 12219 solver.cpp:375]     Train net output #0: loss = 2.26021 (* 1 = 2.26021 loss)
I0801 20:47:52.840097 12219 sgd_solver.cpp:136] Iteration 130800, lr = 0.059125, m = 0.9
I0801 20:48:06.861059 12219 solver.cpp:353] Iteration 130900 (7.13236 iter/s, 14.0206s/100 iter), loss = 1.92825
I0801 20:48:06.861254 12219 solver.cpp:375]     Train net output #0: loss = 1.99244 (* 1 = 1.99244 loss)
I0801 20:48:06.861325 12219 sgd_solver.cpp:136] Iteration 130900, lr = 0.0590938, m = 0.9
I0801 20:48:20.830368 12219 solver.cpp:353] Iteration 131000 (7.15875 iter/s, 13.9689s/100 iter), loss = 2.49904
I0801 20:48:20.830396 12219 solver.cpp:375]     Train net output #0: loss = 2.89297 (* 1 = 2.89297 loss)
I0801 20:48:20.830402 12219 sgd_solver.cpp:136] Iteration 131000, lr = 0.0590625, m = 0.9
I0801 20:48:34.787111 12219 solver.cpp:353] Iteration 131100 (7.16519 iter/s, 13.9564s/100 iter), loss = 2.12296
I0801 20:48:34.787335 12219 solver.cpp:375]     Train net output #0: loss = 2.38167 (* 1 = 2.38167 loss)
I0801 20:48:34.787425 12219 sgd_solver.cpp:136] Iteration 131100, lr = 0.0590312, m = 0.9
I0801 20:48:48.888242 12219 solver.cpp:353] Iteration 131200 (7.09182 iter/s, 14.1007s/100 iter), loss = 2.001
I0801 20:48:48.888679 12219 solver.cpp:375]     Train net output #0: loss = 2.39062 (* 1 = 2.39062 loss)
I0801 20:48:48.888685 12219 sgd_solver.cpp:136] Iteration 131200, lr = 0.059, m = 0.9
I0801 20:49:02.911937 12219 solver.cpp:353] Iteration 131300 (7.13098 iter/s, 14.0233s/100 iter), loss = 2.05834
I0801 20:49:02.911965 12219 solver.cpp:375]     Train net output #0: loss = 2.0879 (* 1 = 2.0879 loss)
I0801 20:49:02.911972 12219 sgd_solver.cpp:136] Iteration 131300, lr = 0.0589687, m = 0.9
I0801 20:49:17.026906 12219 solver.cpp:353] Iteration 131400 (7.08487 iter/s, 14.1146s/100 iter), loss = 2.03169
I0801 20:49:17.026933 12219 solver.cpp:375]     Train net output #0: loss = 2.17198 (* 1 = 2.17198 loss)
I0801 20:49:17.026939 12219 sgd_solver.cpp:136] Iteration 131400, lr = 0.0589375, m = 0.9
I0801 20:49:31.038319 12219 solver.cpp:353] Iteration 131500 (7.13723 iter/s, 14.011s/100 iter), loss = 2.44906
I0801 20:49:31.038370 12219 solver.cpp:375]     Train net output #0: loss = 2.26801 (* 1 = 2.26801 loss)
I0801 20:49:31.038374 12219 sgd_solver.cpp:136] Iteration 131500, lr = 0.0589063, m = 0.9
I0801 20:49:44.981680 12219 solver.cpp:353] Iteration 131600 (7.17207 iter/s, 13.943s/100 iter), loss = 1.43937
I0801 20:49:44.981704 12219 solver.cpp:375]     Train net output #0: loss = 1.29876 (* 1 = 1.29876 loss)
I0801 20:49:44.981709 12219 sgd_solver.cpp:136] Iteration 131600, lr = 0.058875, m = 0.9
I0801 20:49:59.003649 12219 solver.cpp:353] Iteration 131700 (7.13186 iter/s, 14.0216s/100 iter), loss = 2.159
I0801 20:49:59.003679 12219 solver.cpp:375]     Train net output #0: loss = 2.31489 (* 1 = 2.31489 loss)
I0801 20:49:59.003684 12219 sgd_solver.cpp:136] Iteration 131700, lr = 0.0588438, m = 0.9
I0801 20:50:12.976567 12219 solver.cpp:353] Iteration 131800 (7.1569 iter/s, 13.9725s/100 iter), loss = 2.27928
I0801 20:50:12.976637 12219 solver.cpp:375]     Train net output #0: loss = 2.62897 (* 1 = 2.62897 loss)
I0801 20:50:12.976644 12219 sgd_solver.cpp:136] Iteration 131800, lr = 0.0588125, m = 0.9
I0801 20:50:27.026152 12219 solver.cpp:353] Iteration 131900 (7.11784 iter/s, 14.0492s/100 iter), loss = 2.15929
I0801 20:50:27.026181 12219 solver.cpp:375]     Train net output #0: loss = 2.20907 (* 1 = 2.20907 loss)
I0801 20:50:27.026186 12219 sgd_solver.cpp:136] Iteration 131900, lr = 0.0587813, m = 0.9
I0801 20:50:40.957096 12219 solver.cpp:550] Iteration 132000, Testing net (#0)
I0801 20:51:00.793992 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.41647
I0801 20:51:00.794057 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.674235
I0801 20:51:00.794066 12219 solver.cpp:635]     Test net output #2: loss = 2.73589 (* 1 = 2.73589 loss)
I0801 20:51:00.794119 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8365s
I0801 20:51:00.938922 12219 solver.cpp:353] Iteration 132000 (2.94882 iter/s, 33.9118s/100 iter), loss = 1.91689
I0801 20:51:00.938946 12219 solver.cpp:375]     Train net output #0: loss = 1.94554 (* 1 = 1.94554 loss)
I0801 20:51:00.938951 12219 sgd_solver.cpp:136] Iteration 132000, lr = 0.05875, m = 0.9
I0801 20:51:14.962849 12219 solver.cpp:353] Iteration 132100 (7.13087 iter/s, 14.0235s/100 iter), loss = 2.51891
I0801 20:51:14.962890 12219 solver.cpp:375]     Train net output #0: loss = 2.21294 (* 1 = 2.21294 loss)
I0801 20:51:14.962896 12219 sgd_solver.cpp:136] Iteration 132100, lr = 0.0587188, m = 0.9
I0801 20:51:28.938202 12219 solver.cpp:353] Iteration 132200 (7.15565 iter/s, 13.975s/100 iter), loss = 1.82459
I0801 20:51:28.938247 12219 solver.cpp:375]     Train net output #0: loss = 1.50453 (* 1 = 1.50453 loss)
I0801 20:51:28.938261 12219 sgd_solver.cpp:136] Iteration 132200, lr = 0.0586875, m = 0.9
I0801 20:51:42.967017 12219 solver.cpp:353] Iteration 132300 (7.12838 iter/s, 14.0284s/100 iter), loss = 2.29676
I0801 20:51:42.967090 12219 solver.cpp:375]     Train net output #0: loss = 2.88594 (* 1 = 2.88594 loss)
I0801 20:51:42.967098 12219 sgd_solver.cpp:136] Iteration 132300, lr = 0.0586563, m = 0.9
I0801 20:51:56.965787 12219 solver.cpp:353] Iteration 132400 (7.14368 iter/s, 13.9984s/100 iter), loss = 2.22332
I0801 20:51:56.965813 12219 solver.cpp:375]     Train net output #0: loss = 2.09223 (* 1 = 2.09223 loss)
I0801 20:51:56.965816 12219 sgd_solver.cpp:136] Iteration 132400, lr = 0.058625, m = 0.9
I0801 20:52:11.002188 12219 solver.cpp:353] Iteration 132500 (7.12453 iter/s, 14.036s/100 iter), loss = 2.00514
I0801 20:52:11.002223 12219 solver.cpp:375]     Train net output #0: loss = 2.01463 (* 1 = 2.01463 loss)
I0801 20:52:11.002228 12219 sgd_solver.cpp:136] Iteration 132500, lr = 0.0585938, m = 0.9
I0801 20:52:24.967027 12219 solver.cpp:353] Iteration 132600 (7.16104 iter/s, 13.9645s/100 iter), loss = 1.78646
I0801 20:52:24.972867 12219 solver.cpp:375]     Train net output #0: loss = 1.87599 (* 1 = 1.87599 loss)
I0801 20:52:24.972894 12219 sgd_solver.cpp:136] Iteration 132600, lr = 0.0585625, m = 0.9
I0801 20:52:38.960132 12219 solver.cpp:353] Iteration 132700 (7.14658 iter/s, 13.9927s/100 iter), loss = 1.97848
I0801 20:52:38.960161 12219 solver.cpp:375]     Train net output #0: loss = 1.96784 (* 1 = 1.96784 loss)
I0801 20:52:38.960167 12219 sgd_solver.cpp:136] Iteration 132700, lr = 0.0585313, m = 0.9
I0801 20:52:52.954435 12219 solver.cpp:353] Iteration 132800 (7.14596 iter/s, 13.9939s/100 iter), loss = 1.94224
I0801 20:52:52.954465 12219 solver.cpp:375]     Train net output #0: loss = 1.53586 (* 1 = 1.53586 loss)
I0801 20:52:52.954473 12219 sgd_solver.cpp:136] Iteration 132800, lr = 0.0585, m = 0.9
I0801 20:53:06.897150 12219 solver.cpp:353] Iteration 132900 (7.17241 iter/s, 13.9423s/100 iter), loss = 1.96685
I0801 20:53:06.897233 12219 solver.cpp:375]     Train net output #0: loss = 1.84964 (* 1 = 1.84964 loss)
I0801 20:53:06.897240 12219 sgd_solver.cpp:136] Iteration 132900, lr = 0.0584687, m = 0.9
I0801 20:53:20.847285 12219 solver.cpp:353] Iteration 133000 (7.16859 iter/s, 13.9498s/100 iter), loss = 1.66146
I0801 20:53:20.847311 12219 solver.cpp:375]     Train net output #0: loss = 1.80961 (* 1 = 1.80961 loss)
I0801 20:53:20.847316 12219 sgd_solver.cpp:136] Iteration 133000, lr = 0.0584375, m = 0.9
I0801 20:53:34.756470 12219 solver.cpp:353] Iteration 133100 (7.18969 iter/s, 13.9088s/100 iter), loss = 1.97995
I0801 20:53:34.756500 12219 solver.cpp:375]     Train net output #0: loss = 2.23469 (* 1 = 2.23469 loss)
I0801 20:53:34.756506 12219 sgd_solver.cpp:136] Iteration 133100, lr = 0.0584062, m = 0.9
I0801 20:53:48.691956 12219 solver.cpp:353] Iteration 133200 (7.17612 iter/s, 13.9351s/100 iter), loss = 1.98839
I0801 20:53:48.692549 12219 solver.cpp:375]     Train net output #0: loss = 1.94709 (* 1 = 1.94709 loss)
I0801 20:53:48.692556 12219 sgd_solver.cpp:136] Iteration 133200, lr = 0.058375, m = 0.9
I0801 20:54:02.805603 12219 solver.cpp:353] Iteration 133300 (7.08554 iter/s, 14.1133s/100 iter), loss = 2.28725
I0801 20:54:02.805631 12219 solver.cpp:375]     Train net output #0: loss = 2.55162 (* 1 = 2.55162 loss)
I0801 20:54:02.805637 12219 sgd_solver.cpp:136] Iteration 133300, lr = 0.0583437, m = 0.9
I0801 20:54:16.838627 12219 solver.cpp:353] Iteration 133400 (7.12624 iter/s, 14.0326s/100 iter), loss = 2.09179
I0801 20:54:16.838654 12219 solver.cpp:375]     Train net output #0: loss = 1.96095 (* 1 = 1.96095 loss)
I0801 20:54:16.838660 12219 sgd_solver.cpp:136] Iteration 133400, lr = 0.0583125, m = 0.9
I0801 20:54:30.837851 12219 solver.cpp:353] Iteration 133500 (7.14345 iter/s, 13.9988s/100 iter), loss = 1.87314
I0801 20:54:30.838075 12219 solver.cpp:375]     Train net output #0: loss = 1.92464 (* 1 = 1.92464 loss)
I0801 20:54:30.838083 12219 sgd_solver.cpp:136] Iteration 133500, lr = 0.0582813, m = 0.9
I0801 20:54:45.006644 12219 solver.cpp:353] Iteration 133600 (7.05796 iter/s, 14.1684s/100 iter), loss = 2.25077
I0801 20:54:45.006685 12219 solver.cpp:375]     Train net output #0: loss = 2.1844 (* 1 = 2.1844 loss)
I0801 20:54:45.006690 12219 sgd_solver.cpp:136] Iteration 133600, lr = 0.05825, m = 0.9
I0801 20:54:59.155642 12219 solver.cpp:353] Iteration 133700 (7.06783 iter/s, 14.1486s/100 iter), loss = 2.14255
I0801 20:54:59.155763 12219 solver.cpp:375]     Train net output #0: loss = 1.90482 (* 1 = 1.90482 loss)
I0801 20:54:59.155789 12219 sgd_solver.cpp:136] Iteration 133700, lr = 0.0582188, m = 0.9
I0801 20:55:13.146255 12219 solver.cpp:353] Iteration 133800 (7.14785 iter/s, 13.9902s/100 iter), loss = 1.59513
I0801 20:55:13.146389 12219 solver.cpp:375]     Train net output #0: loss = 1.6892 (* 1 = 1.6892 loss)
I0801 20:55:13.146416 12219 sgd_solver.cpp:136] Iteration 133800, lr = 0.0581875, m = 0.9
I0801 20:55:27.152137 12219 solver.cpp:353] Iteration 133900 (7.14005 iter/s, 14.0055s/100 iter), loss = 2.03392
I0801 20:55:27.152163 12219 solver.cpp:375]     Train net output #0: loss = 2.34027 (* 1 = 2.34027 loss)
I0801 20:55:27.152169 12219 sgd_solver.cpp:136] Iteration 133900, lr = 0.0581563, m = 0.9
I0801 20:55:40.982764 12219 solver.cpp:550] Iteration 134000, Testing net (#0)
I0801 20:55:45.563215 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 20:56:01.226080 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.399647
I0801 20:56:01.226107 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.657941
I0801 20:56:01.226114 12219 solver.cpp:635]     Test net output #2: loss = 2.80556 (* 1 = 2.80556 loss)
I0801 20:56:01.226169 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2429s
I0801 20:56:01.383728 12219 solver.cpp:353] Iteration 134000 (2.92136 iter/s, 34.2307s/100 iter), loss = 1.8885
I0801 20:56:01.383842 12219 solver.cpp:375]     Train net output #0: loss = 1.65043 (* 1 = 1.65043 loss)
I0801 20:56:01.383867 12219 sgd_solver.cpp:136] Iteration 134000, lr = 0.058125, m = 0.9
I0801 20:56:15.410816 12219 solver.cpp:353] Iteration 134100 (7.12926 iter/s, 14.0267s/100 iter), loss = 2.44549
I0801 20:56:15.410840 12219 solver.cpp:375]     Train net output #0: loss = 2.68611 (* 1 = 2.68611 loss)
I0801 20:56:15.410845 12219 sgd_solver.cpp:136] Iteration 134100, lr = 0.0580938, m = 0.9
I0801 20:56:29.388289 12219 solver.cpp:353] Iteration 134200 (7.15457 iter/s, 13.9771s/100 iter), loss = 1.75057
I0801 20:56:29.388350 12219 solver.cpp:375]     Train net output #0: loss = 2.00687 (* 1 = 2.00687 loss)
I0801 20:56:29.388356 12219 sgd_solver.cpp:136] Iteration 134200, lr = 0.0580625, m = 0.9
I0801 20:56:43.318249 12219 solver.cpp:353] Iteration 134300 (7.17897 iter/s, 13.9296s/100 iter), loss = 1.75218
I0801 20:56:43.318287 12219 solver.cpp:375]     Train net output #0: loss = 1.64361 (* 1 = 1.64361 loss)
I0801 20:56:43.318294 12219 sgd_solver.cpp:136] Iteration 134300, lr = 0.0580312, m = 0.9
I0801 20:56:57.383369 12219 solver.cpp:353] Iteration 134400 (7.10998 iter/s, 14.0647s/100 iter), loss = 2.28163
I0801 20:56:57.383461 12219 solver.cpp:375]     Train net output #0: loss = 2.52691 (* 1 = 2.52691 loss)
I0801 20:56:57.383483 12219 sgd_solver.cpp:136] Iteration 134400, lr = 0.058, m = 0.9
I0801 20:57:11.364483 12219 solver.cpp:353] Iteration 134500 (7.1527 iter/s, 13.9807s/100 iter), loss = 1.8817
I0801 20:57:11.364562 12219 solver.cpp:375]     Train net output #0: loss = 2.06527 (* 1 = 2.06527 loss)
I0801 20:57:11.364568 12219 sgd_solver.cpp:136] Iteration 134500, lr = 0.0579687, m = 0.9
I0801 20:57:25.546785 12219 solver.cpp:353] Iteration 134600 (7.05123 iter/s, 14.1819s/100 iter), loss = 2.30523
I0801 20:57:25.546808 12219 solver.cpp:375]     Train net output #0: loss = 1.99028 (* 1 = 1.99028 loss)
I0801 20:57:25.546813 12219 sgd_solver.cpp:136] Iteration 134600, lr = 0.0579375, m = 0.9
I0801 20:57:39.544258 12219 solver.cpp:353] Iteration 134700 (7.14434 iter/s, 13.9971s/100 iter), loss = 2.09538
I0801 20:57:39.544282 12219 solver.cpp:375]     Train net output #0: loss = 2.34369 (* 1 = 2.34369 loss)
I0801 20:57:39.544287 12219 sgd_solver.cpp:136] Iteration 134700, lr = 0.0579062, m = 0.9
I0801 20:57:53.509927 12219 solver.cpp:353] Iteration 134800 (7.16061 iter/s, 13.9653s/100 iter), loss = 1.6832
I0801 20:57:53.509982 12219 solver.cpp:375]     Train net output #0: loss = 1.98122 (* 1 = 1.98122 loss)
I0801 20:57:53.509987 12219 sgd_solver.cpp:136] Iteration 134800, lr = 0.057875, m = 0.9
I0801 20:58:07.551131 12219 solver.cpp:353] Iteration 134900 (7.12209 iter/s, 14.0408s/100 iter), loss = 1.87076
I0801 20:58:07.551200 12219 solver.cpp:375]     Train net output #0: loss = 1.90056 (* 1 = 1.90056 loss)
I0801 20:58:07.551219 12219 sgd_solver.cpp:136] Iteration 134900, lr = 0.0578438, m = 0.9
I0801 20:58:21.675740 12219 solver.cpp:353] Iteration 135000 (7.08004 iter/s, 14.1242s/100 iter), loss = 2.43869
I0801 20:58:21.675770 12219 solver.cpp:375]     Train net output #0: loss = 2.95129 (* 1 = 2.95129 loss)
I0801 20:58:21.675776 12219 sgd_solver.cpp:136] Iteration 135000, lr = 0.0578125, m = 0.9
I0801 20:58:35.643307 12219 solver.cpp:353] Iteration 135100 (7.15964 iter/s, 13.9672s/100 iter), loss = 2.44398
I0801 20:58:35.643365 12219 solver.cpp:375]     Train net output #0: loss = 2.34468 (* 1 = 2.34468 loss)
I0801 20:58:35.643371 12219 sgd_solver.cpp:136] Iteration 135100, lr = 0.0577812, m = 0.9
I0801 20:58:49.749197 12219 solver.cpp:353] Iteration 135200 (7.08943 iter/s, 14.1055s/100 iter), loss = 2.41695
I0801 20:58:49.749224 12219 solver.cpp:375]     Train net output #0: loss = 2.43853 (* 1 = 2.43853 loss)
I0801 20:58:49.749230 12219 sgd_solver.cpp:136] Iteration 135200, lr = 0.05775, m = 0.9
I0801 20:59:03.665717 12219 solver.cpp:353] Iteration 135300 (7.1859 iter/s, 13.9161s/100 iter), loss = 1.90896
I0801 20:59:03.665745 12219 solver.cpp:375]     Train net output #0: loss = 1.84013 (* 1 = 1.84013 loss)
I0801 20:59:03.665750 12219 sgd_solver.cpp:136] Iteration 135300, lr = 0.0577188, m = 0.9
I0801 20:59:17.662345 12219 solver.cpp:353] Iteration 135400 (7.14477 iter/s, 13.9962s/100 iter), loss = 1.92678
I0801 20:59:17.662401 12219 solver.cpp:375]     Train net output #0: loss = 2.2509 (* 1 = 2.2509 loss)
I0801 20:59:17.662407 12219 sgd_solver.cpp:136] Iteration 135400, lr = 0.0576875, m = 0.9
I0801 20:59:31.703567 12219 solver.cpp:353] Iteration 135500 (7.12208 iter/s, 14.0408s/100 iter), loss = 1.625
I0801 20:59:31.703593 12219 solver.cpp:375]     Train net output #0: loss = 1.21849 (* 1 = 1.21849 loss)
I0801 20:59:31.703598 12219 sgd_solver.cpp:136] Iteration 135500, lr = 0.0576563, m = 0.9
I0801 20:59:45.816537 12219 solver.cpp:353] Iteration 135600 (7.08588 iter/s, 14.1126s/100 iter), loss = 2.1502
I0801 20:59:45.816565 12219 solver.cpp:375]     Train net output #0: loss = 2.04803 (* 1 = 2.04803 loss)
I0801 20:59:45.816571 12219 sgd_solver.cpp:136] Iteration 135600, lr = 0.057625, m = 0.9
I0801 20:59:59.767916 12219 solver.cpp:353] Iteration 135700 (7.16795 iter/s, 13.951s/100 iter), loss = 2.13388
I0801 20:59:59.767983 12219 solver.cpp:375]     Train net output #0: loss = 2.52589 (* 1 = 2.52589 loss)
I0801 20:59:59.767989 12219 sgd_solver.cpp:136] Iteration 135700, lr = 0.0575938, m = 0.9
I0801 21:00:13.806918 12219 solver.cpp:353] Iteration 135800 (7.12321 iter/s, 14.0386s/100 iter), loss = 2.14968
I0801 21:00:13.807018 12219 solver.cpp:375]     Train net output #0: loss = 2.58843 (* 1 = 2.58843 loss)
I0801 21:00:13.807039 12219 sgd_solver.cpp:136] Iteration 135800, lr = 0.0575625, m = 0.9
I0801 21:00:27.764468 12219 solver.cpp:353] Iteration 135900 (7.16478 iter/s, 13.9572s/100 iter), loss = 1.32918
I0801 21:00:27.764550 12219 solver.cpp:375]     Train net output #0: loss = 1.4615 (* 1 = 1.4615 loss)
I0801 21:00:27.764570 12219 sgd_solver.cpp:136] Iteration 135900, lr = 0.0575312, m = 0.9
I0801 21:00:41.692122 12219 solver.cpp:550] Iteration 136000, Testing net (#0)
I0801 21:01:02.253056 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.453706
I0801 21:01:02.253077 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.714058
I0801 21:01:02.253083 12219 solver.cpp:635]     Test net output #2: loss = 2.48477 (* 1 = 2.48477 loss)
I0801 21:01:02.253139 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.5605s
I0801 21:01:02.411933 12219 solver.cpp:353] Iteration 136000 (2.88629 iter/s, 34.6465s/100 iter), loss = 1.74947
I0801 21:01:02.412003 12219 solver.cpp:375]     Train net output #0: loss = 1.49831 (* 1 = 1.49831 loss)
I0801 21:01:02.412024 12219 sgd_solver.cpp:136] Iteration 136000, lr = 0.0575, m = 0.9
I0801 21:01:16.360028 12219 solver.cpp:353] Iteration 136100 (7.16964 iter/s, 13.9477s/100 iter), loss = 2.10874
I0801 21:01:16.360085 12219 solver.cpp:375]     Train net output #0: loss = 1.96684 (* 1 = 1.96684 loss)
I0801 21:01:16.360090 12219 sgd_solver.cpp:136] Iteration 136100, lr = 0.0574687, m = 0.9
I0801 21:01:30.295465 12219 solver.cpp:353] Iteration 136200 (7.17615 iter/s, 13.9351s/100 iter), loss = 1.56455
I0801 21:01:30.295490 12219 solver.cpp:375]     Train net output #0: loss = 1.57382 (* 1 = 1.57382 loss)
I0801 21:01:30.295495 12219 sgd_solver.cpp:136] Iteration 136200, lr = 0.0574375, m = 0.9
I0801 21:01:44.416582 12219 solver.cpp:353] Iteration 136300 (7.08179 iter/s, 14.1207s/100 iter), loss = 1.88664
I0801 21:01:44.416610 12219 solver.cpp:375]     Train net output #0: loss = 1.83872 (* 1 = 1.83872 loss)
I0801 21:01:44.416615 12219 sgd_solver.cpp:136] Iteration 136300, lr = 0.0574062, m = 0.9
I0801 21:01:58.465950 12219 solver.cpp:353] Iteration 136400 (7.11795 iter/s, 14.049s/100 iter), loss = 1.97488
I0801 21:01:58.466015 12219 solver.cpp:375]     Train net output #0: loss = 1.83014 (* 1 = 1.83014 loss)
I0801 21:01:58.466022 12219 sgd_solver.cpp:136] Iteration 136400, lr = 0.057375, m = 0.9
I0801 21:02:12.613067 12219 solver.cpp:353] Iteration 136500 (7.06877 iter/s, 14.1467s/100 iter), loss = 2.05878
I0801 21:02:12.613132 12219 solver.cpp:375]     Train net output #0: loss = 1.96376 (* 1 = 1.96376 loss)
I0801 21:02:12.613147 12219 sgd_solver.cpp:136] Iteration 136500, lr = 0.0573438, m = 0.9
I0801 21:02:26.595727 12219 solver.cpp:353] Iteration 136600 (7.15191 iter/s, 13.9823s/100 iter), loss = 1.72963
I0801 21:02:26.595815 12219 solver.cpp:375]     Train net output #0: loss = 1.63762 (* 1 = 1.63762 loss)
I0801 21:02:26.595837 12219 sgd_solver.cpp:136] Iteration 136600, lr = 0.0573125, m = 0.9
I0801 21:02:40.631671 12219 solver.cpp:353] Iteration 136700 (7.12476 iter/s, 14.0356s/100 iter), loss = 1.94162
I0801 21:02:40.631775 12219 solver.cpp:375]     Train net output #0: loss = 1.89374 (* 1 = 1.89374 loss)
I0801 21:02:40.631788 12219 sgd_solver.cpp:136] Iteration 136700, lr = 0.0572813, m = 0.9
I0801 21:02:54.697459 12219 solver.cpp:353] Iteration 136800 (7.10964 iter/s, 14.0654s/100 iter), loss = 2.15709
I0801 21:02:54.697489 12219 solver.cpp:375]     Train net output #0: loss = 2.28737 (* 1 = 2.28737 loss)
I0801 21:02:54.697496 12219 sgd_solver.cpp:136] Iteration 136800, lr = 0.05725, m = 0.9
I0801 21:03:08.726163 12219 solver.cpp:353] Iteration 136900 (7.12844 iter/s, 14.0283s/100 iter), loss = 1.75155
I0801 21:03:08.726218 12219 solver.cpp:375]     Train net output #0: loss = 1.53593 (* 1 = 1.53593 loss)
I0801 21:03:08.726229 12219 sgd_solver.cpp:136] Iteration 136900, lr = 0.0572188, m = 0.9
I0801 21:03:22.623944 12219 solver.cpp:353] Iteration 137000 (7.19559 iter/s, 13.8974s/100 iter), loss = 1.92122
I0801 21:03:22.624009 12219 solver.cpp:375]     Train net output #0: loss = 2.07762 (* 1 = 2.07762 loss)
I0801 21:03:22.624016 12219 sgd_solver.cpp:136] Iteration 137000, lr = 0.0571875, m = 0.9
I0801 21:03:36.634435 12219 solver.cpp:353] Iteration 137100 (7.13771 iter/s, 14.0101s/100 iter), loss = 1.82319
I0801 21:03:36.634460 12219 solver.cpp:375]     Train net output #0: loss = 2.14426 (* 1 = 2.14426 loss)
I0801 21:03:36.634464 12219 sgd_solver.cpp:136] Iteration 137100, lr = 0.0571563, m = 0.9
I0801 21:03:50.580128 12219 solver.cpp:353] Iteration 137200 (7.17087 iter/s, 13.9453s/100 iter), loss = 2.04704
I0801 21:03:50.580154 12219 solver.cpp:375]     Train net output #0: loss = 2.20449 (* 1 = 2.20449 loss)
I0801 21:03:50.580160 12219 sgd_solver.cpp:136] Iteration 137200, lr = 0.057125, m = 0.9
I0801 21:04:04.684854 12219 solver.cpp:353] Iteration 137300 (7.09002 iter/s, 14.1043s/100 iter), loss = 1.60717
I0801 21:04:04.684922 12219 solver.cpp:375]     Train net output #0: loss = 1.70964 (* 1 = 1.70964 loss)
I0801 21:04:04.684931 12219 sgd_solver.cpp:136] Iteration 137300, lr = 0.0570938, m = 0.9
I0801 21:04:18.693931 12219 solver.cpp:353] Iteration 137400 (7.13843 iter/s, 14.0087s/100 iter), loss = 2.50104
I0801 21:04:18.693976 12219 solver.cpp:375]     Train net output #0: loss = 2.54545 (* 1 = 2.54545 loss)
I0801 21:04:18.693986 12219 sgd_solver.cpp:136] Iteration 137400, lr = 0.0570625, m = 0.9
I0801 21:04:32.693199 12219 solver.cpp:353] Iteration 137500 (7.14342 iter/s, 13.9989s/100 iter), loss = 1.50084
I0801 21:04:32.693251 12219 solver.cpp:375]     Train net output #0: loss = 1.63971 (* 1 = 1.63971 loss)
I0801 21:04:32.693264 12219 sgd_solver.cpp:136] Iteration 137500, lr = 0.0570313, m = 0.9
I0801 21:04:46.676875 12219 solver.cpp:353] Iteration 137600 (7.15139 iter/s, 13.9833s/100 iter), loss = 2.07457
I0801 21:04:46.676985 12219 solver.cpp:375]     Train net output #0: loss = 2.06495 (* 1 = 2.06495 loss)
I0801 21:04:46.677000 12219 sgd_solver.cpp:136] Iteration 137600, lr = 0.057, m = 0.9
I0801 21:05:00.653162 12219 solver.cpp:353] Iteration 137700 (7.15517 iter/s, 13.9759s/100 iter), loss = 1.85025
I0801 21:05:00.653187 12219 solver.cpp:375]     Train net output #0: loss = 1.63652 (* 1 = 1.63652 loss)
I0801 21:05:00.653193 12219 sgd_solver.cpp:136] Iteration 137700, lr = 0.0569687, m = 0.9
I0801 21:05:14.618646 12219 solver.cpp:353] Iteration 137800 (7.16071 iter/s, 13.9651s/100 iter), loss = 1.98321
I0801 21:05:14.618676 12219 solver.cpp:375]     Train net output #0: loss = 2.04543 (* 1 = 2.04543 loss)
I0801 21:05:14.618682 12219 sgd_solver.cpp:136] Iteration 137800, lr = 0.0569375, m = 0.9
I0801 21:05:28.605923 12219 solver.cpp:353] Iteration 137900 (7.14955 iter/s, 13.9869s/100 iter), loss = 1.63894
I0801 21:05:28.605983 12219 solver.cpp:375]     Train net output #0: loss = 1.589 (* 1 = 1.589 loss)
I0801 21:05:28.605989 12219 sgd_solver.cpp:136] Iteration 137900, lr = 0.0569062, m = 0.9
I0801 21:05:42.507437 12219 solver.cpp:550] Iteration 138000, Testing net (#0)
I0801 21:06:02.162362 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.424705
I0801 21:06:02.162475 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.68241
I0801 21:06:02.162484 12219 solver.cpp:635]     Test net output #2: loss = 2.66154 (* 1 = 2.66154 loss)
I0801 21:06:02.162506 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6545s
I0801 21:06:02.326403 12219 solver.cpp:353] Iteration 138000 (2.96564 iter/s, 33.7196s/100 iter), loss = 1.84845
I0801 21:06:02.326505 12219 solver.cpp:375]     Train net output #0: loss = 1.93449 (* 1 = 1.93449 loss)
I0801 21:06:02.326527 12219 sgd_solver.cpp:136] Iteration 138000, lr = 0.056875, m = 0.9
I0801 21:06:16.360427 12219 solver.cpp:353] Iteration 138100 (7.12573 iter/s, 14.0336s/100 iter), loss = 1.40897
I0801 21:06:16.360528 12219 solver.cpp:375]     Train net output #0: loss = 1.33433 (* 1 = 1.33433 loss)
I0801 21:06:16.360549 12219 sgd_solver.cpp:136] Iteration 138100, lr = 0.0568437, m = 0.9
I0801 21:06:30.377889 12219 solver.cpp:353] Iteration 138200 (7.13415 iter/s, 14.0171s/100 iter), loss = 1.80165
I0801 21:06:30.377918 12219 solver.cpp:375]     Train net output #0: loss = 1.37365 (* 1 = 1.37365 loss)
I0801 21:06:30.377924 12219 sgd_solver.cpp:136] Iteration 138200, lr = 0.0568125, m = 0.9
I0801 21:06:44.307368 12219 solver.cpp:353] Iteration 138300 (7.17922 iter/s, 13.9291s/100 iter), loss = 2.05419
I0801 21:06:44.307466 12219 solver.cpp:375]     Train net output #0: loss = 2.08461 (* 1 = 2.08461 loss)
I0801 21:06:44.307474 12219 sgd_solver.cpp:136] Iteration 138300, lr = 0.0567813, m = 0.9
I0801 21:06:58.213580 12219 solver.cpp:353] Iteration 138400 (7.19123 iter/s, 13.9058s/100 iter), loss = 1.75487
I0801 21:06:58.213630 12219 solver.cpp:375]     Train net output #0: loss = 2.04664 (* 1 = 2.04664 loss)
I0801 21:06:58.213642 12219 sgd_solver.cpp:136] Iteration 138400, lr = 0.05675, m = 0.9
I0801 21:07:12.113705 12219 solver.cpp:353] Iteration 138500 (7.19438 iter/s, 13.8997s/100 iter), loss = 2.15771
I0801 21:07:12.113732 12219 solver.cpp:375]     Train net output #0: loss = 2.16361 (* 1 = 2.16361 loss)
I0801 21:07:12.113736 12219 sgd_solver.cpp:136] Iteration 138500, lr = 0.0567187, m = 0.9
I0801 21:07:26.022011 12219 solver.cpp:353] Iteration 138600 (7.19015 iter/s, 13.9079s/100 iter), loss = 2.05711
I0801 21:07:26.022804 12219 solver.cpp:375]     Train net output #0: loss = 1.788 (* 1 = 1.788 loss)
I0801 21:07:26.022811 12219 sgd_solver.cpp:136] Iteration 138600, lr = 0.0566875, m = 0.9
I0801 21:07:40.021235 12219 solver.cpp:353] Iteration 138700 (7.14345 iter/s, 13.9988s/100 iter), loss = 2.30598
I0801 21:07:40.021275 12219 solver.cpp:375]     Train net output #0: loss = 1.84087 (* 1 = 1.84087 loss)
I0801 21:07:40.021281 12219 sgd_solver.cpp:136] Iteration 138700, lr = 0.0566563, m = 0.9
I0801 21:07:54.042943 12219 solver.cpp:353] Iteration 138800 (7.13199 iter/s, 14.0213s/100 iter), loss = 2.29668
I0801 21:07:54.042985 12219 solver.cpp:375]     Train net output #0: loss = 2.41083 (* 1 = 2.41083 loss)
I0801 21:07:54.042992 12219 sgd_solver.cpp:136] Iteration 138800, lr = 0.056625, m = 0.9
I0801 21:08:08.058167 12219 solver.cpp:353] Iteration 138900 (7.13529 iter/s, 14.0148s/100 iter), loss = 2.2305
I0801 21:08:08.058269 12219 solver.cpp:375]     Train net output #0: loss = 2.08183 (* 1 = 2.08183 loss)
I0801 21:08:08.058275 12219 sgd_solver.cpp:136] Iteration 138900, lr = 0.0565938, m = 0.9
I0801 21:08:22.001572 12219 solver.cpp:353] Iteration 139000 (7.17205 iter/s, 13.943s/100 iter), loss = 2.18606
I0801 21:08:22.001621 12219 solver.cpp:375]     Train net output #0: loss = 2.06261 (* 1 = 2.06261 loss)
I0801 21:08:22.001634 12219 sgd_solver.cpp:136] Iteration 139000, lr = 0.0565625, m = 0.9
I0801 21:08:35.893337 12219 solver.cpp:353] Iteration 139100 (7.19871 iter/s, 13.8914s/100 iter), loss = 2.12616
I0801 21:08:35.893365 12219 solver.cpp:375]     Train net output #0: loss = 2.42215 (* 1 = 2.42215 loss)
I0801 21:08:35.893371 12219 sgd_solver.cpp:136] Iteration 139100, lr = 0.0565313, m = 0.9
I0801 21:08:49.801409 12219 solver.cpp:353] Iteration 139200 (7.19027 iter/s, 13.9077s/100 iter), loss = 1.88754
I0801 21:08:49.801481 12219 solver.cpp:375]     Train net output #0: loss = 1.94369 (* 1 = 1.94369 loss)
I0801 21:08:49.801488 12219 sgd_solver.cpp:136] Iteration 139200, lr = 0.0565, m = 0.9
I0801 21:09:03.735260 12219 solver.cpp:353] Iteration 139300 (7.17696 iter/s, 13.9335s/100 iter), loss = 1.92
I0801 21:09:03.735290 12219 solver.cpp:375]     Train net output #0: loss = 1.74602 (* 1 = 1.74602 loss)
I0801 21:09:03.735296 12219 sgd_solver.cpp:136] Iteration 139300, lr = 0.0564688, m = 0.9
I0801 21:09:17.920336 12219 solver.cpp:353] Iteration 139400 (7.04986 iter/s, 14.1847s/100 iter), loss = 2.19161
I0801 21:09:17.920361 12219 solver.cpp:375]     Train net output #0: loss = 2.22137 (* 1 = 2.22137 loss)
I0801 21:09:17.920366 12219 sgd_solver.cpp:136] Iteration 139400, lr = 0.0564375, m = 0.9
I0801 21:09:31.881291 12219 solver.cpp:353] Iteration 139500 (7.16303 iter/s, 13.9606s/100 iter), loss = 1.81001
I0801 21:09:31.881376 12219 solver.cpp:375]     Train net output #0: loss = 1.99684 (* 1 = 1.99684 loss)
I0801 21:09:31.881382 12219 sgd_solver.cpp:136] Iteration 139500, lr = 0.0564062, m = 0.9
I0801 21:09:45.902977 12219 solver.cpp:353] Iteration 139600 (7.13201 iter/s, 14.0213s/100 iter), loss = 2.02214
I0801 21:09:45.903165 12219 solver.cpp:375]     Train net output #0: loss = 1.95429 (* 1 = 1.95429 loss)
I0801 21:09:45.903187 12219 sgd_solver.cpp:136] Iteration 139600, lr = 0.056375, m = 0.9
I0801 21:09:59.991786 12219 solver.cpp:353] Iteration 139700 (7.09803 iter/s, 14.0884s/100 iter), loss = 1.99178
I0801 21:09:59.991812 12219 solver.cpp:375]     Train net output #0: loss = 1.60777 (* 1 = 1.60777 loss)
I0801 21:09:59.991818 12219 sgd_solver.cpp:136] Iteration 139700, lr = 0.0563437, m = 0.9
I0801 21:10:14.056916 12219 solver.cpp:353] Iteration 139800 (7.10998 iter/s, 14.0647s/100 iter), loss = 2.16754
I0801 21:10:14.057036 12219 solver.cpp:375]     Train net output #0: loss = 2.08544 (* 1 = 2.08544 loss)
I0801 21:10:14.057057 12219 sgd_solver.cpp:136] Iteration 139800, lr = 0.0563125, m = 0.9
I0801 21:10:28.039119 12219 solver.cpp:353] Iteration 139900 (7.15214 iter/s, 13.9818s/100 iter), loss = 1.80727
I0801 21:10:28.039144 12219 solver.cpp:375]     Train net output #0: loss = 1.72378 (* 1 = 1.72378 loss)
I0801 21:10:28.039147 12219 sgd_solver.cpp:136] Iteration 139900, lr = 0.0562812, m = 0.9
I0801 21:10:41.857921 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_140000.caffemodel
I0801 21:10:41.872676 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_140000.solverstate
I0801 21:10:41.877746 12219 solver.cpp:550] Iteration 140000, Testing net (#0)
I0801 21:10:49.166791 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 21:11:02.321715 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.440353
I0801 21:11:02.321744 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.696175
I0801 21:11:02.321751 12219 solver.cpp:635]     Test net output #2: loss = 2.55695 (* 1 = 2.55695 loss)
I0801 21:11:02.321777 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4435s
I0801 21:11:02.472267 12219 solver.cpp:353] Iteration 140000 (2.90426 iter/s, 34.4322s/100 iter), loss = 2.17499
I0801 21:11:02.472295 12219 solver.cpp:375]     Train net output #0: loss = 2.49287 (* 1 = 2.49287 loss)
I0801 21:11:02.472301 12219 sgd_solver.cpp:136] Iteration 140000, lr = 0.05625, m = 0.9
I0801 21:11:16.641206 12219 solver.cpp:353] Iteration 140100 (7.05789 iter/s, 14.1685s/100 iter), loss = 2.16185
I0801 21:11:16.641234 12219 solver.cpp:375]     Train net output #0: loss = 2.57184 (* 1 = 2.57184 loss)
I0801 21:11:16.641240 12219 sgd_solver.cpp:136] Iteration 140100, lr = 0.0562188, m = 0.9
I0801 21:11:30.725821 12219 solver.cpp:353] Iteration 140200 (7.10014 iter/s, 14.0842s/100 iter), loss = 2.32113
I0801 21:11:30.725898 12219 solver.cpp:375]     Train net output #0: loss = 2.50099 (* 1 = 2.50099 loss)
I0801 21:11:30.725905 12219 sgd_solver.cpp:136] Iteration 140200, lr = 0.0561875, m = 0.9
I0801 21:11:44.735538 12219 solver.cpp:353] Iteration 140300 (7.1381 iter/s, 14.0093s/100 iter), loss = 2.04274
I0801 21:11:44.735566 12219 solver.cpp:375]     Train net output #0: loss = 2.49065 (* 1 = 2.49065 loss)
I0801 21:11:44.735572 12219 sgd_solver.cpp:136] Iteration 140300, lr = 0.0561563, m = 0.9
I0801 21:11:58.721724 12219 solver.cpp:353] Iteration 140400 (7.15011 iter/s, 13.9858s/100 iter), loss = 2.26748
I0801 21:11:58.721751 12219 solver.cpp:375]     Train net output #0: loss = 2.27351 (* 1 = 2.27351 loss)
I0801 21:11:58.721756 12219 sgd_solver.cpp:136] Iteration 140400, lr = 0.056125, m = 0.9
I0801 21:12:12.672719 12219 solver.cpp:353] Iteration 140500 (7.16814 iter/s, 13.9506s/100 iter), loss = 2.1183
I0801 21:12:12.672935 12219 solver.cpp:375]     Train net output #0: loss = 2.07721 (* 1 = 2.07721 loss)
I0801 21:12:12.672963 12219 sgd_solver.cpp:136] Iteration 140500, lr = 0.0560938, m = 0.9
I0801 21:12:26.726001 12219 solver.cpp:353] Iteration 140600 (7.11598 iter/s, 14.0529s/100 iter), loss = 2.01677
I0801 21:12:26.726032 12219 solver.cpp:375]     Train net output #0: loss = 2.14889 (* 1 = 2.14889 loss)
I0801 21:12:26.726037 12219 sgd_solver.cpp:136] Iteration 140600, lr = 0.0560625, m = 0.9
I0801 21:12:40.773960 12219 solver.cpp:353] Iteration 140700 (7.11867 iter/s, 14.0476s/100 iter), loss = 1.89115
I0801 21:12:40.773988 12219 solver.cpp:375]     Train net output #0: loss = 1.78376 (* 1 = 1.78376 loss)
I0801 21:12:40.773994 12219 sgd_solver.cpp:136] Iteration 140700, lr = 0.0560313, m = 0.9
I0801 21:12:54.887706 12219 solver.cpp:353] Iteration 140800 (7.08548 iter/s, 14.1134s/100 iter), loss = 1.85123
I0801 21:12:54.887774 12219 solver.cpp:375]     Train net output #0: loss = 1.96889 (* 1 = 1.96889 loss)
I0801 21:12:54.887780 12219 sgd_solver.cpp:136] Iteration 140800, lr = 0.056, m = 0.9
I0801 21:13:08.923514 12219 solver.cpp:353] Iteration 140900 (7.12483 iter/s, 14.0354s/100 iter), loss = 2.29878
I0801 21:13:08.923542 12219 solver.cpp:375]     Train net output #0: loss = 2.53471 (* 1 = 2.53471 loss)
I0801 21:13:08.923547 12219 sgd_solver.cpp:136] Iteration 140900, lr = 0.0559688, m = 0.9
I0801 21:13:23.042580 12219 solver.cpp:353] Iteration 141000 (7.08281 iter/s, 14.1187s/100 iter), loss = 2.11172
I0801 21:13:23.042608 12219 solver.cpp:375]     Train net output #0: loss = 1.62154 (* 1 = 1.62154 loss)
I0801 21:13:23.042614 12219 sgd_solver.cpp:136] Iteration 141000, lr = 0.0559375, m = 0.9
I0801 21:13:37.003211 12219 solver.cpp:353] Iteration 141100 (7.1632 iter/s, 13.9602s/100 iter), loss = 2.24362
I0801 21:13:37.003269 12219 solver.cpp:375]     Train net output #0: loss = 2.64767 (* 1 = 2.64767 loss)
I0801 21:13:37.003276 12219 sgd_solver.cpp:136] Iteration 141100, lr = 0.0559062, m = 0.9
I0801 21:13:51.195786 12219 solver.cpp:353] Iteration 141200 (7.04613 iter/s, 14.1922s/100 iter), loss = 2.34612
I0801 21:13:51.195814 12219 solver.cpp:375]     Train net output #0: loss = 2.16308 (* 1 = 2.16308 loss)
I0801 21:13:51.195822 12219 sgd_solver.cpp:136] Iteration 141200, lr = 0.055875, m = 0.9
I0801 21:14:05.330098 12219 solver.cpp:353] Iteration 141300 (7.07518 iter/s, 14.1339s/100 iter), loss = 1.90329
I0801 21:14:05.330353 12219 solver.cpp:375]     Train net output #0: loss = 1.73239 (* 1 = 1.73239 loss)
I0801 21:14:05.330454 12219 sgd_solver.cpp:136] Iteration 141300, lr = 0.0558437, m = 0.9
I0801 21:14:19.275094 12219 solver.cpp:353] Iteration 141400 (7.17123 iter/s, 13.9446s/100 iter), loss = 1.94293
I0801 21:14:19.275178 12219 solver.cpp:375]     Train net output #0: loss = 1.98926 (* 1 = 1.98926 loss)
I0801 21:14:19.275190 12219 sgd_solver.cpp:136] Iteration 141400, lr = 0.0558125, m = 0.9
I0801 21:14:33.296551 12219 solver.cpp:353] Iteration 141500 (7.13212 iter/s, 14.0211s/100 iter), loss = 2.10741
I0801 21:14:33.296576 12219 solver.cpp:375]     Train net output #0: loss = 2.07072 (* 1 = 2.07072 loss)
I0801 21:14:33.296581 12219 sgd_solver.cpp:136] Iteration 141500, lr = 0.0557813, m = 0.9
I0801 21:14:47.365825 12219 solver.cpp:353] Iteration 141600 (7.10788 iter/s, 14.0689s/100 iter), loss = 2.40376
I0801 21:14:47.365854 12219 solver.cpp:375]     Train net output #0: loss = 2.58558 (* 1 = 2.58558 loss)
I0801 21:14:47.365860 12219 sgd_solver.cpp:136] Iteration 141600, lr = 0.05575, m = 0.9
I0801 21:15:01.410120 12219 solver.cpp:353] Iteration 141700 (7.12053 iter/s, 14.0439s/100 iter), loss = 2.14793
I0801 21:15:01.410195 12219 solver.cpp:375]     Train net output #0: loss = 2.12111 (* 1 = 2.12111 loss)
I0801 21:15:01.410217 12219 sgd_solver.cpp:136] Iteration 141700, lr = 0.0557187, m = 0.9
I0801 21:15:15.375476 12219 solver.cpp:353] Iteration 141800 (7.16077 iter/s, 13.965s/100 iter), loss = 1.65163
I0801 21:15:15.375552 12219 solver.cpp:375]     Train net output #0: loss = 1.80461 (* 1 = 1.80461 loss)
I0801 21:15:15.375573 12219 sgd_solver.cpp:136] Iteration 141800, lr = 0.0556875, m = 0.9
I0801 21:15:29.488852 12219 solver.cpp:353] Iteration 141900 (7.08567 iter/s, 14.113s/100 iter), loss = 2.2224
I0801 21:15:29.488880 12219 solver.cpp:375]     Train net output #0: loss = 1.67263 (* 1 = 1.67263 loss)
I0801 21:15:29.488886 12219 sgd_solver.cpp:136] Iteration 141900, lr = 0.0556563, m = 0.9
I0801 21:15:43.383256 12219 solver.cpp:550] Iteration 142000, Testing net (#0)
I0801 21:16:03.660555 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.446118
I0801 21:16:03.660589 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.703469
I0801 21:16:03.660596 12219 solver.cpp:635]     Test net output #2: loss = 2.52772 (* 1 = 2.52772 loss)
I0801 21:16:03.660640 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2768s
I0801 21:16:03.840230 12219 solver.cpp:353] Iteration 142000 (2.91117 iter/s, 34.3504s/100 iter), loss = 2.12157
I0801 21:16:03.840260 12219 solver.cpp:375]     Train net output #0: loss = 2.51952 (* 1 = 2.51952 loss)
I0801 21:16:03.840265 12219 sgd_solver.cpp:136] Iteration 142000, lr = 0.055625, m = 0.9
I0801 21:16:17.991778 12219 solver.cpp:353] Iteration 142100 (7.06656 iter/s, 14.1512s/100 iter), loss = 1.72878
I0801 21:16:17.991849 12219 solver.cpp:375]     Train net output #0: loss = 1.74577 (* 1 = 1.74577 loss)
I0801 21:16:17.991858 12219 sgd_solver.cpp:136] Iteration 142100, lr = 0.0555938, m = 0.9
I0801 21:16:31.960958 12219 solver.cpp:353] Iteration 142200 (7.15881 iter/s, 13.9688s/100 iter), loss = 1.80253
I0801 21:16:31.961035 12219 solver.cpp:375]     Train net output #0: loss = 1.82332 (* 1 = 1.82332 loss)
I0801 21:16:31.961056 12219 sgd_solver.cpp:136] Iteration 142200, lr = 0.0555625, m = 0.9
I0801 21:16:45.950367 12219 solver.cpp:353] Iteration 142300 (7.14846 iter/s, 13.989s/100 iter), loss = 1.88919
I0801 21:16:45.950413 12219 solver.cpp:375]     Train net output #0: loss = 1.77306 (* 1 = 1.77306 loss)
I0801 21:16:45.950422 12219 sgd_solver.cpp:136] Iteration 142300, lr = 0.0555313, m = 0.9
I0801 21:17:00.079435 12219 solver.cpp:353] Iteration 142400 (7.0778 iter/s, 14.1287s/100 iter), loss = 2.08606
I0801 21:17:00.079509 12219 solver.cpp:375]     Train net output #0: loss = 2.44139 (* 1 = 2.44139 loss)
I0801 21:17:00.079516 12219 sgd_solver.cpp:136] Iteration 142400, lr = 0.0555, m = 0.9
I0801 21:17:14.176198 12219 solver.cpp:353] Iteration 142500 (7.09402 iter/s, 14.0964s/100 iter), loss = 2.44657
I0801 21:17:14.176223 12219 solver.cpp:375]     Train net output #0: loss = 2.44606 (* 1 = 2.44606 loss)
I0801 21:17:14.176229 12219 sgd_solver.cpp:136] Iteration 142500, lr = 0.0554687, m = 0.9
I0801 21:17:28.272218 12219 solver.cpp:353] Iteration 142600 (7.0944 iter/s, 14.0956s/100 iter), loss = 2.06004
I0801 21:17:28.272243 12219 solver.cpp:375]     Train net output #0: loss = 1.55833 (* 1 = 1.55833 loss)
I0801 21:17:28.272248 12219 sgd_solver.cpp:136] Iteration 142600, lr = 0.0554375, m = 0.9
I0801 21:17:42.286193 12219 solver.cpp:353] Iteration 142700 (7.13593 iter/s, 14.0136s/100 iter), loss = 1.66616
I0801 21:17:42.286294 12219 solver.cpp:375]     Train net output #0: loss = 1.35976 (* 1 = 1.35976 loss)
I0801 21:17:42.286300 12219 sgd_solver.cpp:136] Iteration 142700, lr = 0.0554063, m = 0.9
I0801 21:17:56.263880 12219 solver.cpp:353] Iteration 142800 (7.15446 iter/s, 13.9773s/100 iter), loss = 1.79646
I0801 21:17:56.263907 12219 solver.cpp:375]     Train net output #0: loss = 1.6245 (* 1 = 1.6245 loss)
I0801 21:17:56.263913 12219 sgd_solver.cpp:136] Iteration 142800, lr = 0.055375, m = 0.9
I0801 21:18:10.255373 12219 solver.cpp:353] Iteration 142900 (7.1474 iter/s, 13.9911s/100 iter), loss = 2.17004
I0801 21:18:10.255400 12219 solver.cpp:375]     Train net output #0: loss = 2.57812 (* 1 = 2.57812 loss)
I0801 21:18:10.255406 12219 sgd_solver.cpp:136] Iteration 142900, lr = 0.0553437, m = 0.9
I0801 21:18:24.326514 12219 solver.cpp:353] Iteration 143000 (7.10694 iter/s, 14.0708s/100 iter), loss = 1.90971
I0801 21:18:24.326619 12219 solver.cpp:375]     Train net output #0: loss = 1.64903 (* 1 = 1.64903 loss)
I0801 21:18:24.326627 12219 sgd_solver.cpp:136] Iteration 143000, lr = 0.0553125, m = 0.9
I0801 21:18:38.381099 12219 solver.cpp:353] Iteration 143100 (7.11531 iter/s, 14.0542s/100 iter), loss = 2.26267
I0801 21:18:38.381124 12219 solver.cpp:375]     Train net output #0: loss = 1.96244 (* 1 = 1.96244 loss)
I0801 21:18:38.381127 12219 sgd_solver.cpp:136] Iteration 143100, lr = 0.0552812, m = 0.9
I0801 21:18:52.295797 12219 solver.cpp:353] Iteration 143200 (7.18684 iter/s, 13.9143s/100 iter), loss = 1.938
I0801 21:18:52.295822 12219 solver.cpp:375]     Train net output #0: loss = 1.98669 (* 1 = 1.98669 loss)
I0801 21:18:52.295826 12219 sgd_solver.cpp:136] Iteration 143200, lr = 0.05525, m = 0.9
I0801 21:19:06.279036 12219 solver.cpp:353] Iteration 143300 (7.15161 iter/s, 13.9829s/100 iter), loss = 1.9396
I0801 21:19:06.279109 12219 solver.cpp:375]     Train net output #0: loss = 1.61326 (* 1 = 1.61326 loss)
I0801 21:19:06.279116 12219 sgd_solver.cpp:136] Iteration 143300, lr = 0.0552188, m = 0.9
I0801 21:19:20.327461 12219 solver.cpp:353] Iteration 143400 (7.11843 iter/s, 14.048s/100 iter), loss = 2.20325
I0801 21:19:20.327556 12219 solver.cpp:375]     Train net output #0: loss = 2.48635 (* 1 = 2.48635 loss)
I0801 21:19:20.327575 12219 sgd_solver.cpp:136] Iteration 143400, lr = 0.0551875, m = 0.9
I0801 21:19:34.376951 12219 solver.cpp:353] Iteration 143500 (7.11789 iter/s, 14.0491s/100 iter), loss = 1.82051
I0801 21:19:34.376976 12219 solver.cpp:375]     Train net output #0: loss = 2.08182 (* 1 = 2.08182 loss)
I0801 21:19:34.376981 12219 sgd_solver.cpp:136] Iteration 143500, lr = 0.0551562, m = 0.9
I0801 21:19:48.425899 12219 solver.cpp:353] Iteration 143600 (7.11817 iter/s, 14.0486s/100 iter), loss = 2.32737
I0801 21:19:48.428879 12219 solver.cpp:375]     Train net output #0: loss = 2.04377 (* 1 = 2.04377 loss)
I0801 21:19:48.428889 12219 sgd_solver.cpp:136] Iteration 143600, lr = 0.055125, m = 0.9
I0801 21:20:02.336076 12219 solver.cpp:353] Iteration 143700 (7.18918 iter/s, 13.9098s/100 iter), loss = 1.92201
I0801 21:20:02.336104 12219 solver.cpp:375]     Train net output #0: loss = 2.12585 (* 1 = 2.12585 loss)
I0801 21:20:02.336109 12219 sgd_solver.cpp:136] Iteration 143700, lr = 0.0550938, m = 0.9
I0801 21:20:16.395323 12219 solver.cpp:353] Iteration 143800 (7.11295 iter/s, 14.0589s/100 iter), loss = 1.74258
I0801 21:20:16.395349 12219 solver.cpp:375]     Train net output #0: loss = 1.4391 (* 1 = 1.4391 loss)
I0801 21:20:16.395354 12219 sgd_solver.cpp:136] Iteration 143800, lr = 0.0550625, m = 0.9
I0801 21:20:30.437325 12219 solver.cpp:353] Iteration 143900 (7.12169 iter/s, 14.0416s/100 iter), loss = 2.36978
I0801 21:20:30.437450 12219 solver.cpp:375]     Train net output #0: loss = 2.07056 (* 1 = 2.07056 loss)
I0801 21:20:30.437471 12219 sgd_solver.cpp:136] Iteration 143900, lr = 0.0550313, m = 0.9
I0801 21:20:44.295855 12219 solver.cpp:550] Iteration 144000, Testing net (#0)
I0801 21:20:55.010514 12207 data_reader.cpp:264] Starting prefetch of epoch 7
I0801 21:21:04.234911 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.445529
I0801 21:21:04.234946 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.706528
I0801 21:21:04.234951 12219 solver.cpp:635]     Test net output #2: loss = 2.49654 (* 1 = 2.49654 loss)
I0801 21:21:04.234971 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9386s
I0801 21:21:04.373150 12219 solver.cpp:353] Iteration 144000 (2.94682 iter/s, 33.9349s/100 iter), loss = 1.77471
I0801 21:21:04.373178 12219 solver.cpp:375]     Train net output #0: loss = 1.81547 (* 1 = 1.81547 loss)
I0801 21:21:04.373183 12219 sgd_solver.cpp:136] Iteration 144000, lr = 0.055, m = 0.9
I0801 21:21:18.354604 12219 solver.cpp:353] Iteration 144100 (7.15253 iter/s, 13.9811s/100 iter), loss = 1.80908
I0801 21:21:18.354707 12219 solver.cpp:375]     Train net output #0: loss = 1.65681 (* 1 = 1.65681 loss)
I0801 21:21:18.354732 12219 sgd_solver.cpp:136] Iteration 144100, lr = 0.0549688, m = 0.9
I0801 21:21:32.339622 12219 solver.cpp:353] Iteration 144200 (7.15071 iter/s, 13.9846s/100 iter), loss = 2.06108
I0801 21:21:32.339658 12219 solver.cpp:375]     Train net output #0: loss = 1.79866 (* 1 = 1.79866 loss)
I0801 21:21:32.339664 12219 sgd_solver.cpp:136] Iteration 144200, lr = 0.0549375, m = 0.9
I0801 21:21:46.322048 12219 solver.cpp:353] Iteration 144300 (7.15203 iter/s, 13.982s/100 iter), loss = 2.05429
I0801 21:21:46.322119 12219 solver.cpp:375]     Train net output #0: loss = 2.73932 (* 1 = 2.73932 loss)
I0801 21:21:46.322124 12219 sgd_solver.cpp:136] Iteration 144300, lr = 0.0549062, m = 0.9
I0801 21:22:00.357352 12219 solver.cpp:353] Iteration 144400 (7.12509 iter/s, 14.0349s/100 iter), loss = 1.78246
I0801 21:22:00.357380 12219 solver.cpp:375]     Train net output #0: loss = 1.80082 (* 1 = 1.80082 loss)
I0801 21:22:00.357384 12219 sgd_solver.cpp:136] Iteration 144400, lr = 0.054875, m = 0.9
I0801 21:22:14.304474 12219 solver.cpp:353] Iteration 144500 (7.17013 iter/s, 13.9467s/100 iter), loss = 1.68573
I0801 21:22:14.304571 12219 solver.cpp:375]     Train net output #0: loss = 1.90758 (* 1 = 1.90758 loss)
I0801 21:22:14.304594 12219 sgd_solver.cpp:136] Iteration 144500, lr = 0.0548437, m = 0.9
I0801 21:22:28.250814 12219 solver.cpp:353] Iteration 144600 (7.17054 iter/s, 13.946s/100 iter), loss = 1.98701
I0801 21:22:28.250880 12219 solver.cpp:375]     Train net output #0: loss = 2.11068 (* 1 = 2.11068 loss)
I0801 21:22:28.250887 12219 sgd_solver.cpp:136] Iteration 144600, lr = 0.0548125, m = 0.9
I0801 21:22:42.296692 12219 solver.cpp:353] Iteration 144700 (7.11972 iter/s, 14.0455s/100 iter), loss = 1.66484
I0801 21:22:42.296717 12219 solver.cpp:375]     Train net output #0: loss = 2.03349 (* 1 = 2.03349 loss)
I0801 21:22:42.296722 12219 sgd_solver.cpp:136] Iteration 144700, lr = 0.0547812, m = 0.9
I0801 21:22:56.286355 12219 solver.cpp:353] Iteration 144800 (7.14833 iter/s, 13.9893s/100 iter), loss = 1.97111
I0801 21:22:56.286382 12219 solver.cpp:375]     Train net output #0: loss = 2.11735 (* 1 = 2.11735 loss)
I0801 21:22:56.286388 12219 sgd_solver.cpp:136] Iteration 144800, lr = 0.05475, m = 0.9
I0801 21:23:10.298928 12219 solver.cpp:353] Iteration 144900 (7.13664 iter/s, 14.0122s/100 iter), loss = 2.32371
I0801 21:23:10.299021 12219 solver.cpp:375]     Train net output #0: loss = 2.2539 (* 1 = 2.2539 loss)
I0801 21:23:10.299028 12219 sgd_solver.cpp:136] Iteration 144900, lr = 0.0547188, m = 0.9
I0801 21:23:24.220733 12219 solver.cpp:353] Iteration 145000 (7.18317 iter/s, 13.9214s/100 iter), loss = 1.81781
I0801 21:23:24.220757 12219 solver.cpp:375]     Train net output #0: loss = 2.07696 (* 1 = 2.07696 loss)
I0801 21:23:24.220763 12219 sgd_solver.cpp:136] Iteration 145000, lr = 0.0546875, m = 0.9
I0801 21:23:38.091505 12219 solver.cpp:353] Iteration 145100 (7.2096 iter/s, 13.8704s/100 iter), loss = 2.39388
I0801 21:23:38.091532 12219 solver.cpp:375]     Train net output #0: loss = 2.16293 (* 1 = 2.16293 loss)
I0801 21:23:38.091538 12219 sgd_solver.cpp:136] Iteration 145100, lr = 0.0546562, m = 0.9
I0801 21:23:52.066056 12219 solver.cpp:353] Iteration 145200 (7.15606 iter/s, 13.9742s/100 iter), loss = 2.07391
I0801 21:23:52.066126 12219 solver.cpp:375]     Train net output #0: loss = 2.60234 (* 1 = 2.60234 loss)
I0801 21:23:52.066133 12219 sgd_solver.cpp:136] Iteration 145200, lr = 0.054625, m = 0.9
I0801 21:24:05.987265 12219 solver.cpp:353] Iteration 145300 (7.18348 iter/s, 13.9208s/100 iter), loss = 2.28067
I0801 21:24:05.987301 12219 solver.cpp:375]     Train net output #0: loss = 2.43647 (* 1 = 2.43647 loss)
I0801 21:24:05.987308 12219 sgd_solver.cpp:136] Iteration 145300, lr = 0.0545938, m = 0.9
I0801 21:24:19.928619 12219 solver.cpp:353] Iteration 145400 (7.1731 iter/s, 13.941s/100 iter), loss = 2.13415
I0801 21:24:19.928689 12219 solver.cpp:375]     Train net output #0: loss = 2.08266 (* 1 = 2.08266 loss)
I0801 21:24:19.928707 12219 sgd_solver.cpp:136] Iteration 145400, lr = 0.0545625, m = 0.9
I0801 21:24:33.858258 12219 solver.cpp:353] Iteration 145500 (7.17914 iter/s, 13.9293s/100 iter), loss = 1.77785
I0801 21:24:33.858392 12219 solver.cpp:375]     Train net output #0: loss = 1.64417 (* 1 = 1.64417 loss)
I0801 21:24:33.858412 12219 sgd_solver.cpp:136] Iteration 145500, lr = 0.0545313, m = 0.9
I0801 21:24:47.737541 12219 solver.cpp:353] Iteration 145600 (7.20518 iter/s, 13.8789s/100 iter), loss = 1.93723
I0801 21:24:47.737566 12219 solver.cpp:375]     Train net output #0: loss = 2.23883 (* 1 = 2.23883 loss)
I0801 21:24:47.737572 12219 sgd_solver.cpp:136] Iteration 145600, lr = 0.0545, m = 0.9
I0801 21:25:01.768107 12219 solver.cpp:353] Iteration 145700 (7.12749 iter/s, 14.0302s/100 iter), loss = 2.12266
I0801 21:25:01.768205 12219 solver.cpp:375]     Train net output #0: loss = 2.11557 (* 1 = 2.11557 loss)
I0801 21:25:01.768226 12219 sgd_solver.cpp:136] Iteration 145700, lr = 0.0544688, m = 0.9
I0801 21:25:15.933266 12219 solver.cpp:353] Iteration 145800 (7.05977 iter/s, 14.1648s/100 iter), loss = 2.13192
I0801 21:25:15.933343 12219 solver.cpp:375]     Train net output #0: loss = 2.32848 (* 1 = 2.32848 loss)
I0801 21:25:15.933351 12219 sgd_solver.cpp:136] Iteration 145800, lr = 0.0544375, m = 0.9
I0801 21:25:29.967218 12219 solver.cpp:353] Iteration 145900 (7.12577 iter/s, 14.0336s/100 iter), loss = 2.45054
I0801 21:25:29.967311 12219 solver.cpp:375]     Train net output #0: loss = 2.55089 (* 1 = 2.55089 loss)
I0801 21:25:29.967330 12219 sgd_solver.cpp:136] Iteration 145900, lr = 0.0544063, m = 0.9
I0801 21:25:43.906605 12219 solver.cpp:550] Iteration 146000, Testing net (#0)
I0801 21:25:53.682103 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 21:26:04.345393 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.437588
I0801 21:26:04.345422 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.69447
I0801 21:26:04.345429 12219 solver.cpp:635]     Test net output #2: loss = 2.57225 (* 1 = 2.57225 loss)
I0801 21:26:04.345453 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4383s
I0801 21:26:04.502970 12219 solver.cpp:353] Iteration 146000 (2.89563 iter/s, 34.5348s/100 iter), loss = 1.86223
I0801 21:26:04.502995 12219 solver.cpp:375]     Train net output #0: loss = 1.78807 (* 1 = 1.78807 loss)
I0801 21:26:04.502997 12219 sgd_solver.cpp:136] Iteration 146000, lr = 0.054375, m = 0.9
I0801 21:26:18.631906 12219 solver.cpp:353] Iteration 146100 (7.07787 iter/s, 14.1285s/100 iter), loss = 1.68821
I0801 21:26:18.631933 12219 solver.cpp:375]     Train net output #0: loss = 1.33754 (* 1 = 1.33754 loss)
I0801 21:26:18.631938 12219 sgd_solver.cpp:136] Iteration 146100, lr = 0.0543437, m = 0.9
I0801 21:26:32.754307 12219 solver.cpp:353] Iteration 146200 (7.08115 iter/s, 14.122s/100 iter), loss = 1.94434
I0801 21:26:32.754395 12219 solver.cpp:375]     Train net output #0: loss = 2.21565 (* 1 = 2.21565 loss)
I0801 21:26:32.754410 12219 sgd_solver.cpp:136] Iteration 146200, lr = 0.0543125, m = 0.9
I0801 21:26:46.798624 12219 solver.cpp:353] Iteration 146300 (7.12051 iter/s, 14.0439s/100 iter), loss = 1.86604
I0801 21:26:46.798718 12219 solver.cpp:375]     Train net output #0: loss = 1.74036 (* 1 = 1.74036 loss)
I0801 21:26:46.798738 12219 sgd_solver.cpp:136] Iteration 146300, lr = 0.0542812, m = 0.9
I0801 21:27:00.729912 12219 solver.cpp:353] Iteration 146400 (7.17828 iter/s, 13.9309s/100 iter), loss = 2.1843
I0801 21:27:00.729938 12219 solver.cpp:375]     Train net output #0: loss = 2.19686 (* 1 = 2.19686 loss)
I0801 21:27:00.729943 12219 sgd_solver.cpp:136] Iteration 146400, lr = 0.05425, m = 0.9
I0801 21:27:14.749080 12219 solver.cpp:353] Iteration 146500 (7.13329 iter/s, 14.0188s/100 iter), loss = 1.72736
I0801 21:27:14.749179 12219 solver.cpp:375]     Train net output #0: loss = 1.77663 (* 1 = 1.77663 loss)
I0801 21:27:14.749198 12219 sgd_solver.cpp:136] Iteration 146500, lr = 0.0542188, m = 0.9
I0801 21:27:28.711982 12219 solver.cpp:353] Iteration 146600 (7.16203 iter/s, 13.9625s/100 iter), loss = 2.26645
I0801 21:27:28.712007 12219 solver.cpp:375]     Train net output #0: loss = 2.34101 (* 1 = 2.34101 loss)
I0801 21:27:28.712013 12219 sgd_solver.cpp:136] Iteration 146600, lr = 0.0541875, m = 0.9
I0801 21:27:42.714588 12219 solver.cpp:353] Iteration 146700 (7.14172 iter/s, 14.0022s/100 iter), loss = 1.99516
I0801 21:27:42.714803 12219 solver.cpp:375]     Train net output #0: loss = 2.3341 (* 1 = 2.3341 loss)
I0801 21:27:42.714920 12219 sgd_solver.cpp:136] Iteration 146700, lr = 0.0541563, m = 0.9
I0801 21:27:56.727107 12219 solver.cpp:353] Iteration 146800 (7.13668 iter/s, 14.0121s/100 iter), loss = 2.06179
I0801 21:27:56.727203 12219 solver.cpp:375]     Train net output #0: loss = 2.29845 (* 1 = 2.29845 loss)
I0801 21:27:56.727211 12219 sgd_solver.cpp:136] Iteration 146800, lr = 0.054125, m = 0.9
I0801 21:28:10.711612 12219 solver.cpp:353] Iteration 146900 (7.15097 iter/s, 13.9841s/100 iter), loss = 1.74429
I0801 21:28:10.711639 12219 solver.cpp:375]     Train net output #0: loss = 1.77578 (* 1 = 1.77578 loss)
I0801 21:28:10.711645 12219 sgd_solver.cpp:136] Iteration 146900, lr = 0.0540938, m = 0.9
I0801 21:28:24.731286 12219 solver.cpp:353] Iteration 147000 (7.13303 iter/s, 14.0193s/100 iter), loss = 2.53015
I0801 21:28:24.731312 12219 solver.cpp:375]     Train net output #0: loss = 2.7245 (* 1 = 2.7245 loss)
I0801 21:28:24.731317 12219 sgd_solver.cpp:136] Iteration 147000, lr = 0.0540625, m = 0.9
I0801 21:28:38.784358 12219 solver.cpp:353] Iteration 147100 (7.11608 iter/s, 14.0527s/100 iter), loss = 1.93835
I0801 21:28:38.784412 12219 solver.cpp:375]     Train net output #0: loss = 1.53535 (* 1 = 1.53535 loss)
I0801 21:28:38.784417 12219 sgd_solver.cpp:136] Iteration 147100, lr = 0.0540313, m = 0.9
I0801 21:28:52.868343 12219 solver.cpp:353] Iteration 147200 (7.10046 iter/s, 14.0836s/100 iter), loss = 2.33279
I0801 21:28:52.868371 12219 solver.cpp:375]     Train net output #0: loss = 2.40339 (* 1 = 2.40339 loss)
I0801 21:28:52.868376 12219 sgd_solver.cpp:136] Iteration 147200, lr = 0.054, m = 0.9
I0801 21:29:06.969142 12219 solver.cpp:353] Iteration 147300 (7.09199 iter/s, 14.1004s/100 iter), loss = 1.77881
I0801 21:29:06.969202 12219 solver.cpp:375]     Train net output #0: loss = 1.79883 (* 1 = 1.79883 loss)
I0801 21:29:06.969214 12219 sgd_solver.cpp:136] Iteration 147300, lr = 0.0539688, m = 0.9
I0801 21:29:21.022022 12219 solver.cpp:353] Iteration 147400 (7.11617 iter/s, 14.0525s/100 iter), loss = 2.11582
I0801 21:29:21.022096 12219 solver.cpp:375]     Train net output #0: loss = 1.94376 (* 1 = 1.94376 loss)
I0801 21:29:21.022104 12219 sgd_solver.cpp:136] Iteration 147400, lr = 0.0539375, m = 0.9
I0801 21:29:35.065387 12219 solver.cpp:353] Iteration 147500 (7.12099 iter/s, 14.043s/100 iter), loss = 1.89204
I0801 21:29:35.065412 12219 solver.cpp:375]     Train net output #0: loss = 1.5344 (* 1 = 1.5344 loss)
I0801 21:29:35.065418 12219 sgd_solver.cpp:136] Iteration 147500, lr = 0.0539063, m = 0.9
I0801 21:29:49.130441 12219 solver.cpp:353] Iteration 147600 (7.11001 iter/s, 14.0647s/100 iter), loss = 1.93661
I0801 21:29:49.130538 12219 solver.cpp:375]     Train net output #0: loss = 2.09896 (* 1 = 2.09896 loss)
I0801 21:29:49.130559 12219 sgd_solver.cpp:136] Iteration 147600, lr = 0.053875, m = 0.9
I0801 21:30:03.265892 12219 solver.cpp:353] Iteration 147700 (7.07461 iter/s, 14.1351s/100 iter), loss = 2.35811
I0801 21:30:03.265955 12219 solver.cpp:375]     Train net output #0: loss = 2.59127 (* 1 = 2.59127 loss)
I0801 21:30:03.265960 12219 sgd_solver.cpp:136] Iteration 147700, lr = 0.0538437, m = 0.9
I0801 21:30:17.350850 12219 solver.cpp:353] Iteration 147800 (7.09997 iter/s, 14.0846s/100 iter), loss = 2.24079
I0801 21:30:17.350875 12219 solver.cpp:375]     Train net output #0: loss = 2.30407 (* 1 = 2.30407 loss)
I0801 21:30:17.350880 12219 sgd_solver.cpp:136] Iteration 147800, lr = 0.0538125, m = 0.9
I0801 21:30:31.370753 12219 solver.cpp:353] Iteration 147900 (7.13291 iter/s, 14.0195s/100 iter), loss = 2.20317
I0801 21:30:31.370781 12219 solver.cpp:375]     Train net output #0: loss = 2.51716 (* 1 = 2.51716 loss)
I0801 21:30:31.370787 12219 sgd_solver.cpp:136] Iteration 147900, lr = 0.0537812, m = 0.9
I0801 21:30:45.225298 12219 solver.cpp:550] Iteration 148000, Testing net (#0)
I0801 21:31:05.720618 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.435706
I0801 21:31:05.720643 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.694822
I0801 21:31:05.720649 12219 solver.cpp:635]     Test net output #2: loss = 2.61534 (* 1 = 2.61534 loss)
I0801 21:31:05.720667 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4948s
I0801 21:31:05.870565 12219 solver.cpp:353] Iteration 148000 (2.89865 iter/s, 34.4989s/100 iter), loss = 1.69288
I0801 21:31:05.870595 12219 solver.cpp:375]     Train net output #0: loss = 1.85026 (* 1 = 1.85026 loss)
I0801 21:31:05.870600 12219 sgd_solver.cpp:136] Iteration 148000, lr = 0.05375, m = 0.9
I0801 21:31:19.918201 12219 solver.cpp:353] Iteration 148100 (7.11883 iter/s, 14.0472s/100 iter), loss = 1.99546
I0801 21:31:19.918314 12219 solver.cpp:375]     Train net output #0: loss = 2.10245 (* 1 = 2.10245 loss)
I0801 21:31:19.918334 12219 sgd_solver.cpp:136] Iteration 148100, lr = 0.0537187, m = 0.9
I0801 21:31:33.887202 12219 solver.cpp:353] Iteration 148200 (7.15891 iter/s, 13.9686s/100 iter), loss = 1.85929
I0801 21:31:33.887233 12219 solver.cpp:375]     Train net output #0: loss = 1.87962 (* 1 = 1.87962 loss)
I0801 21:31:33.887239 12219 sgd_solver.cpp:136] Iteration 148200, lr = 0.0536875, m = 0.9
I0801 21:31:47.847084 12219 solver.cpp:353] Iteration 148300 (7.16358 iter/s, 13.9595s/100 iter), loss = 1.93073
I0801 21:31:47.847107 12219 solver.cpp:375]     Train net output #0: loss = 1.7148 (* 1 = 1.7148 loss)
I0801 21:31:47.847111 12219 sgd_solver.cpp:136] Iteration 148300, lr = 0.0536563, m = 0.9
I0801 21:32:01.946676 12219 solver.cpp:353] Iteration 148400 (7.0926 iter/s, 14.0992s/100 iter), loss = 2.04949
I0801 21:32:01.946776 12219 solver.cpp:375]     Train net output #0: loss = 2.06957 (* 1 = 2.06957 loss)
I0801 21:32:01.946782 12219 sgd_solver.cpp:136] Iteration 148400, lr = 0.053625, m = 0.9
I0801 21:32:16.068953 12219 solver.cpp:353] Iteration 148500 (7.0812 iter/s, 14.1219s/100 iter), loss = 1.75978
I0801 21:32:16.068981 12219 solver.cpp:375]     Train net output #0: loss = 1.66466 (* 1 = 1.66466 loss)
I0801 21:32:16.068987 12219 sgd_solver.cpp:136] Iteration 148500, lr = 0.0535938, m = 0.9
I0801 21:32:30.142869 12219 solver.cpp:353] Iteration 148600 (7.10554 iter/s, 14.0735s/100 iter), loss = 1.9808
I0801 21:32:30.142921 12219 solver.cpp:375]     Train net output #0: loss = 1.50859 (* 1 = 1.50859 loss)
I0801 21:32:30.142935 12219 sgd_solver.cpp:136] Iteration 148600, lr = 0.0535625, m = 0.9
I0801 21:32:44.098533 12219 solver.cpp:353] Iteration 148700 (7.16575 iter/s, 13.9553s/100 iter), loss = 1.94699
I0801 21:32:44.098595 12219 solver.cpp:375]     Train net output #0: loss = 2.09136 (* 1 = 2.09136 loss)
I0801 21:32:44.098603 12219 sgd_solver.cpp:136] Iteration 148700, lr = 0.0535313, m = 0.9
I0801 21:32:58.081138 12219 solver.cpp:353] Iteration 148800 (7.15194 iter/s, 13.9822s/100 iter), loss = 1.83028
I0801 21:32:58.081174 12219 solver.cpp:375]     Train net output #0: loss = 1.79006 (* 1 = 1.79006 loss)
I0801 21:32:58.081181 12219 sgd_solver.cpp:136] Iteration 148800, lr = 0.0535, m = 0.9
I0801 21:33:12.104748 12219 solver.cpp:353] Iteration 148900 (7.13103 iter/s, 14.0232s/100 iter), loss = 1.80105
I0801 21:33:12.104775 12219 solver.cpp:375]     Train net output #0: loss = 1.71218 (* 1 = 1.71218 loss)
I0801 21:33:12.104782 12219 sgd_solver.cpp:136] Iteration 148900, lr = 0.0534688, m = 0.9
I0801 21:33:26.214363 12219 solver.cpp:353] Iteration 149000 (7.08756 iter/s, 14.1092s/100 iter), loss = 2.24771
I0801 21:33:26.214488 12219 solver.cpp:375]     Train net output #0: loss = 2.21534 (* 1 = 2.21534 loss)
I0801 21:33:26.214507 12219 sgd_solver.cpp:136] Iteration 149000, lr = 0.0534375, m = 0.9
I0801 21:33:40.335297 12219 solver.cpp:353] Iteration 149100 (7.08188 iter/s, 14.1205s/100 iter), loss = 2.05937
I0801 21:33:40.335326 12219 solver.cpp:375]     Train net output #0: loss = 2.28622 (* 1 = 2.28622 loss)
I0801 21:33:40.335331 12219 sgd_solver.cpp:136] Iteration 149100, lr = 0.0534062, m = 0.9
I0801 21:33:54.389320 12219 solver.cpp:353] Iteration 149200 (7.1156 iter/s, 14.0536s/100 iter), loss = 1.86292
I0801 21:33:54.389346 12219 solver.cpp:375]     Train net output #0: loss = 2.03365 (* 1 = 2.03365 loss)
I0801 21:33:54.389351 12219 sgd_solver.cpp:136] Iteration 149200, lr = 0.053375, m = 0.9
I0801 21:34:08.349102 12219 solver.cpp:353] Iteration 149300 (7.16363 iter/s, 13.9594s/100 iter), loss = 1.88479
I0801 21:34:08.349170 12219 solver.cpp:375]     Train net output #0: loss = 1.60356 (* 1 = 1.60356 loss)
I0801 21:34:08.349177 12219 sgd_solver.cpp:136] Iteration 149300, lr = 0.0533438, m = 0.9
I0801 21:34:22.366044 12219 solver.cpp:353] Iteration 149400 (7.13442 iter/s, 14.0166s/100 iter), loss = 2.30918
I0801 21:34:22.366068 12219 solver.cpp:375]     Train net output #0: loss = 2.37102 (* 1 = 2.37102 loss)
I0801 21:34:22.366072 12219 sgd_solver.cpp:136] Iteration 149400, lr = 0.0533125, m = 0.9
I0801 21:34:36.401424 12219 solver.cpp:353] Iteration 149500 (7.12505 iter/s, 14.035s/100 iter), loss = 1.78167
I0801 21:34:36.401448 12219 solver.cpp:375]     Train net output #0: loss = 1.6154 (* 1 = 1.6154 loss)
I0801 21:34:36.401453 12219 sgd_solver.cpp:136] Iteration 149500, lr = 0.0532812, m = 0.9
I0801 21:34:50.456743 12219 solver.cpp:353] Iteration 149600 (7.11494 iter/s, 14.0549s/100 iter), loss = 1.62637
I0801 21:34:50.456806 12219 solver.cpp:375]     Train net output #0: loss = 1.54312 (* 1 = 1.54312 loss)
I0801 21:34:50.456812 12219 sgd_solver.cpp:136] Iteration 149600, lr = 0.05325, m = 0.9
I0801 21:35:04.476011 12219 solver.cpp:353] Iteration 149700 (7.13323 iter/s, 14.0189s/100 iter), loss = 1.91935
I0801 21:35:04.476231 12219 solver.cpp:375]     Train net output #0: loss = 1.78947 (* 1 = 1.78947 loss)
I0801 21:35:04.476342 12219 sgd_solver.cpp:136] Iteration 149700, lr = 0.0532187, m = 0.9
I0801 21:35:18.340432 12219 solver.cpp:353] Iteration 149800 (7.2129 iter/s, 13.864s/100 iter), loss = 1.81256
I0801 21:35:18.340461 12219 solver.cpp:375]     Train net output #0: loss = 1.77981 (* 1 = 1.77981 loss)
I0801 21:35:18.340466 12219 sgd_solver.cpp:136] Iteration 149800, lr = 0.0531875, m = 0.9
I0801 21:35:32.331912 12219 solver.cpp:353] Iteration 149900 (7.1474 iter/s, 13.9911s/100 iter), loss = 1.92915
I0801 21:35:32.332141 12219 solver.cpp:375]     Train net output #0: loss = 1.96205 (* 1 = 1.96205 loss)
I0801 21:35:32.332155 12219 sgd_solver.cpp:136] Iteration 149900, lr = 0.0531563, m = 0.9
I0801 21:35:46.184165 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_150000.caffemodel
I0801 21:35:46.310158 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_150000.solverstate
I0801 21:35:46.315110 12219 solver.cpp:550] Iteration 150000, Testing net (#0)
I0801 21:36:06.319770 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.446941
I0801 21:36:06.319829 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.707293
I0801 21:36:06.319836 12219 solver.cpp:635]     Test net output #2: loss = 2.51809 (* 1 = 2.51809 loss)
I0801 21:36:06.319855 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0042s
I0801 21:36:06.466675 12219 solver.cpp:353] Iteration 150000 (2.92964 iter/s, 34.1338s/100 iter), loss = 1.74269
I0801 21:36:06.466698 12219 solver.cpp:375]     Train net output #0: loss = 1.81255 (* 1 = 1.81255 loss)
I0801 21:36:06.466704 12219 sgd_solver.cpp:136] Iteration 150000, lr = 0.053125, m = 0.9
I0801 21:36:20.566051 12219 solver.cpp:353] Iteration 150100 (7.09271 iter/s, 14.099s/100 iter), loss = 1.72721
I0801 21:36:20.566076 12219 solver.cpp:375]     Train net output #0: loss = 2.04181 (* 1 = 2.04181 loss)
I0801 21:36:20.566081 12219 sgd_solver.cpp:136] Iteration 150100, lr = 0.0530938, m = 0.9
I0801 21:36:34.457484 12219 solver.cpp:353] Iteration 150200 (7.19888 iter/s, 13.8911s/100 iter), loss = 1.81854
I0801 21:36:34.457511 12219 solver.cpp:375]     Train net output #0: loss = 1.79797 (* 1 = 1.79797 loss)
I0801 21:36:34.457515 12219 sgd_solver.cpp:136] Iteration 150200, lr = 0.0530625, m = 0.9
I0801 21:36:48.416201 12219 solver.cpp:353] Iteration 150300 (7.16418 iter/s, 13.9583s/100 iter), loss = 2.04819
I0801 21:36:48.416303 12219 solver.cpp:375]     Train net output #0: loss = 1.95508 (* 1 = 1.95508 loss)
I0801 21:36:48.416311 12219 sgd_solver.cpp:136] Iteration 150300, lr = 0.0530313, m = 0.9
I0801 21:37:02.391916 12219 solver.cpp:353] Iteration 150400 (7.15546 iter/s, 13.9753s/100 iter), loss = 2.18248
I0801 21:37:02.391945 12219 solver.cpp:375]     Train net output #0: loss = 2.277 (* 1 = 2.277 loss)
I0801 21:37:02.391952 12219 sgd_solver.cpp:136] Iteration 150400, lr = 0.053, m = 0.9
I0801 21:37:16.373327 12219 solver.cpp:353] Iteration 150500 (7.15255 iter/s, 13.981s/100 iter), loss = 1.89555
I0801 21:37:16.373359 12219 solver.cpp:375]     Train net output #0: loss = 1.77068 (* 1 = 1.77068 loss)
I0801 21:37:16.373365 12219 sgd_solver.cpp:136] Iteration 150500, lr = 0.0529688, m = 0.9
I0801 21:37:30.357316 12219 solver.cpp:353] Iteration 150600 (7.15123 iter/s, 13.9836s/100 iter), loss = 1.62092
I0801 21:37:30.357554 12219 solver.cpp:375]     Train net output #0: loss = 1.72739 (* 1 = 1.72739 loss)
I0801 21:37:30.357563 12219 sgd_solver.cpp:136] Iteration 150600, lr = 0.0529375, m = 0.9
I0801 21:37:44.275013 12219 solver.cpp:353] Iteration 150700 (7.18529 iter/s, 13.9173s/100 iter), loss = 2.07764
I0801 21:37:44.275063 12219 solver.cpp:375]     Train net output #0: loss = 2.48717 (* 1 = 2.48717 loss)
I0801 21:37:44.275075 12219 sgd_solver.cpp:136] Iteration 150700, lr = 0.0529063, m = 0.9
I0801 21:37:58.320535 12219 solver.cpp:353] Iteration 150800 (7.1199 iter/s, 14.0451s/100 iter), loss = 2.42087
I0801 21:37:58.320560 12219 solver.cpp:375]     Train net output #0: loss = 2.79599 (* 1 = 2.79599 loss)
I0801 21:37:58.320564 12219 sgd_solver.cpp:136] Iteration 150800, lr = 0.052875, m = 0.9
I0801 21:38:12.274938 12219 solver.cpp:353] Iteration 150900 (7.16639 iter/s, 13.954s/100 iter), loss = 1.8389
I0801 21:38:12.275002 12219 solver.cpp:375]     Train net output #0: loss = 1.66125 (* 1 = 1.66125 loss)
I0801 21:38:12.275007 12219 sgd_solver.cpp:136] Iteration 150900, lr = 0.0528437, m = 0.9
I0801 21:38:26.259973 12219 solver.cpp:353] Iteration 151000 (7.15069 iter/s, 13.9847s/100 iter), loss = 1.81278
I0801 21:38:26.259999 12219 solver.cpp:375]     Train net output #0: loss = 1.97142 (* 1 = 1.97142 loss)
I0801 21:38:26.260004 12219 sgd_solver.cpp:136] Iteration 151000, lr = 0.0528125, m = 0.9
I0801 21:38:40.211100 12219 solver.cpp:353] Iteration 151100 (7.16807 iter/s, 13.9507s/100 iter), loss = 2.03327
I0801 21:38:40.211125 12219 solver.cpp:375]     Train net output #0: loss = 1.96396 (* 1 = 1.96396 loss)
I0801 21:38:40.211129 12219 sgd_solver.cpp:136] Iteration 151100, lr = 0.0527813, m = 0.9
I0801 21:38:54.091038 12219 solver.cpp:353] Iteration 151200 (7.20484 iter/s, 13.8796s/100 iter), loss = 1.99485
I0801 21:38:54.091116 12219 solver.cpp:375]     Train net output #0: loss = 1.96449 (* 1 = 1.96449 loss)
I0801 21:38:54.091123 12219 sgd_solver.cpp:136] Iteration 151200, lr = 0.05275, m = 0.9
I0801 21:39:08.084980 12219 solver.cpp:353] Iteration 151300 (7.14614 iter/s, 13.9936s/100 iter), loss = 2.03876
I0801 21:39:08.085005 12219 solver.cpp:375]     Train net output #0: loss = 2.17749 (* 1 = 2.17749 loss)
I0801 21:39:08.085011 12219 sgd_solver.cpp:136] Iteration 151300, lr = 0.0527187, m = 0.9
I0801 21:39:22.118263 12219 solver.cpp:353] Iteration 151400 (7.12611 iter/s, 14.0329s/100 iter), loss = 1.79839
I0801 21:39:22.118289 12219 solver.cpp:375]     Train net output #0: loss = 2.04856 (* 1 = 2.04856 loss)
I0801 21:39:22.118295 12219 sgd_solver.cpp:136] Iteration 151400, lr = 0.0526875, m = 0.9
I0801 21:39:36.079149 12219 solver.cpp:353] Iteration 151500 (7.16306 iter/s, 13.9605s/100 iter), loss = 2.47648
I0801 21:39:36.079213 12219 solver.cpp:375]     Train net output #0: loss = 2.90835 (* 1 = 2.90835 loss)
I0801 21:39:36.079219 12219 sgd_solver.cpp:136] Iteration 151500, lr = 0.0526563, m = 0.9
I0801 21:39:49.994856 12219 solver.cpp:353] Iteration 151600 (7.18632 iter/s, 13.9153s/100 iter), loss = 2.06301
I0801 21:39:49.994881 12219 solver.cpp:375]     Train net output #0: loss = 2.09484 (* 1 = 2.09484 loss)
I0801 21:39:49.994887 12219 sgd_solver.cpp:136] Iteration 151600, lr = 0.052625, m = 0.9
I0801 21:40:03.926084 12219 solver.cpp:353] Iteration 151700 (7.17831 iter/s, 13.9308s/100 iter), loss = 2.22485
I0801 21:40:03.926110 12219 solver.cpp:375]     Train net output #0: loss = 2.27455 (* 1 = 2.27455 loss)
I0801 21:40:03.926115 12219 sgd_solver.cpp:136] Iteration 151700, lr = 0.0525937, m = 0.9
I0801 21:40:18.012990 12219 solver.cpp:353] Iteration 151800 (7.09898 iter/s, 14.0865s/100 iter), loss = 1.63871
I0801 21:40:18.013084 12219 solver.cpp:375]     Train net output #0: loss = 1.79139 (* 1 = 1.79139 loss)
I0801 21:40:18.013092 12219 sgd_solver.cpp:136] Iteration 151800, lr = 0.0525625, m = 0.9
I0801 21:40:32.044117 12219 solver.cpp:353] Iteration 151900 (7.1272 iter/s, 14.0307s/100 iter), loss = 2.38153
I0801 21:40:32.044142 12219 solver.cpp:375]     Train net output #0: loss = 2.58796 (* 1 = 2.58796 loss)
I0801 21:40:32.044148 12219 sgd_solver.cpp:136] Iteration 151900, lr = 0.0525313, m = 0.9
I0801 21:40:45.985251 12219 solver.cpp:550] Iteration 152000, Testing net (#0)
I0801 21:40:58.265712 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 21:41:05.871850 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.395882
I0801 21:41:05.871876 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.653705
I0801 21:41:05.871881 12219 solver.cpp:635]     Test net output #2: loss = 2.85196 (* 1 = 2.85196 loss)
I0801 21:41:05.871956 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8862s
I0801 21:41:06.017201 12219 solver.cpp:353] Iteration 152000 (2.94359 iter/s, 33.9722s/100 iter), loss = 1.88462
I0801 21:41:06.017230 12219 solver.cpp:375]     Train net output #0: loss = 1.72791 (* 1 = 1.72791 loss)
I0801 21:41:06.017235 12219 sgd_solver.cpp:136] Iteration 152000, lr = 0.0525, m = 0.9
I0801 21:41:19.971004 12219 solver.cpp:353] Iteration 152100 (7.1667 iter/s, 13.9534s/100 iter), loss = 2.3155
I0801 21:41:19.971029 12219 solver.cpp:375]     Train net output #0: loss = 2.57509 (* 1 = 2.57509 loss)
I0801 21:41:19.971032 12219 sgd_solver.cpp:136] Iteration 152100, lr = 0.0524688, m = 0.9
I0801 21:41:34.099658 12219 solver.cpp:353] Iteration 152200 (7.07801 iter/s, 14.1283s/100 iter), loss = 1.9705
I0801 21:41:34.099740 12219 solver.cpp:375]     Train net output #0: loss = 1.86003 (* 1 = 1.86003 loss)
I0801 21:41:34.099753 12219 sgd_solver.cpp:136] Iteration 152200, lr = 0.0524375, m = 0.9
I0801 21:41:48.169864 12219 solver.cpp:353] Iteration 152300 (7.10741 iter/s, 14.0698s/100 iter), loss = 1.77075
I0801 21:41:48.169893 12219 solver.cpp:375]     Train net output #0: loss = 1.64243 (* 1 = 1.64243 loss)
I0801 21:41:48.169896 12219 sgd_solver.cpp:136] Iteration 152300, lr = 0.0524063, m = 0.9
I0801 21:42:02.203531 12219 solver.cpp:353] Iteration 152400 (7.12592 iter/s, 14.0333s/100 iter), loss = 2.26019
I0801 21:42:02.203616 12219 solver.cpp:375]     Train net output #0: loss = 2.19451 (* 1 = 2.19451 loss)
I0801 21:42:02.203637 12219 sgd_solver.cpp:136] Iteration 152400, lr = 0.052375, m = 0.9
I0801 21:42:16.108748 12219 solver.cpp:353] Iteration 152500 (7.19174 iter/s, 13.9048s/100 iter), loss = 2.00334
I0801 21:42:16.108835 12219 solver.cpp:375]     Train net output #0: loss = 2.33222 (* 1 = 2.33222 loss)
I0801 21:42:16.108849 12219 sgd_solver.cpp:136] Iteration 152500, lr = 0.0523438, m = 0.9
I0801 21:42:30.185359 12219 solver.cpp:353] Iteration 152600 (7.10418 iter/s, 14.0762s/100 iter), loss = 2.03905
I0801 21:42:30.185395 12219 solver.cpp:375]     Train net output #0: loss = 2.25404 (* 1 = 2.25404 loss)
I0801 21:42:30.185398 12219 sgd_solver.cpp:136] Iteration 152600, lr = 0.0523125, m = 0.9
I0801 21:42:44.266180 12219 solver.cpp:353] Iteration 152700 (7.10206 iter/s, 14.0804s/100 iter), loss = 1.68903
I0801 21:42:44.266240 12219 solver.cpp:375]     Train net output #0: loss = 1.97077 (* 1 = 1.97077 loss)
I0801 21:42:44.266247 12219 sgd_solver.cpp:136] Iteration 152700, lr = 0.0522812, m = 0.9
I0801 21:42:58.385697 12219 solver.cpp:353] Iteration 152800 (7.08258 iter/s, 14.1191s/100 iter), loss = 1.76553
I0801 21:42:58.385758 12219 solver.cpp:375]     Train net output #0: loss = 1.818 (* 1 = 1.818 loss)
I0801 21:42:58.385838 12219 sgd_solver.cpp:136] Iteration 152800, lr = 0.05225, m = 0.9
I0801 21:43:12.537127 12219 solver.cpp:353] Iteration 152900 (7.06662 iter/s, 14.151s/100 iter), loss = 1.96116
I0801 21:43:12.537153 12219 solver.cpp:375]     Train net output #0: loss = 1.95613 (* 1 = 1.95613 loss)
I0801 21:43:12.537158 12219 sgd_solver.cpp:136] Iteration 152900, lr = 0.0522187, m = 0.9
I0801 21:43:26.484649 12219 solver.cpp:353] Iteration 153000 (7.16993 iter/s, 13.9471s/100 iter), loss = 2.45127
I0801 21:43:26.484678 12219 solver.cpp:375]     Train net output #0: loss = 2.36182 (* 1 = 2.36182 loss)
I0801 21:43:26.484684 12219 sgd_solver.cpp:136] Iteration 153000, lr = 0.0521875, m = 0.9
I0801 21:43:40.496459 12219 solver.cpp:353] Iteration 153100 (7.13703 iter/s, 14.0114s/100 iter), loss = 1.98815
I0801 21:43:40.496577 12219 solver.cpp:375]     Train net output #0: loss = 2.42292 (* 1 = 2.42292 loss)
I0801 21:43:40.496592 12219 sgd_solver.cpp:136] Iteration 153100, lr = 0.0521562, m = 0.9
I0801 21:43:54.598558 12219 solver.cpp:353] Iteration 153200 (7.09134 iter/s, 14.1017s/100 iter), loss = 1.82257
I0801 21:43:54.598587 12219 solver.cpp:375]     Train net output #0: loss = 1.76218 (* 1 = 1.76218 loss)
I0801 21:43:54.598592 12219 sgd_solver.cpp:136] Iteration 153200, lr = 0.052125, m = 0.9
I0801 21:44:08.616662 12219 solver.cpp:353] Iteration 153300 (7.13383 iter/s, 14.0177s/100 iter), loss = 2.01302
I0801 21:44:08.616688 12219 solver.cpp:375]     Train net output #0: loss = 1.9585 (* 1 = 1.9585 loss)
I0801 21:44:08.616694 12219 sgd_solver.cpp:136] Iteration 153300, lr = 0.0520938, m = 0.9
I0801 21:44:22.675531 12219 solver.cpp:353] Iteration 153400 (7.11314 iter/s, 14.0585s/100 iter), loss = 2.43524
I0801 21:44:22.680907 12219 solver.cpp:375]     Train net output #0: loss = 2.48698 (* 1 = 2.48698 loss)
I0801 21:44:22.680928 12219 sgd_solver.cpp:136] Iteration 153400, lr = 0.0520625, m = 0.9
I0801 21:44:36.663923 12219 solver.cpp:353] Iteration 153500 (7.14898 iter/s, 13.988s/100 iter), loss = 1.57731
I0801 21:44:36.664167 12219 solver.cpp:375]     Train net output #0: loss = 1.30927 (* 1 = 1.30927 loss)
I0801 21:44:36.664279 12219 sgd_solver.cpp:136] Iteration 153500, lr = 0.0520312, m = 0.9
I0801 21:44:50.705021 12219 solver.cpp:353] Iteration 153600 (7.12215 iter/s, 14.0407s/100 iter), loss = 1.86142
I0801 21:44:50.705049 12219 solver.cpp:375]     Train net output #0: loss = 1.54965 (* 1 = 1.54965 loss)
I0801 21:44:50.705055 12219 sgd_solver.cpp:136] Iteration 153600, lr = 0.052, m = 0.9
I0801 21:45:04.857513 12219 solver.cpp:353] Iteration 153700 (7.06609 iter/s, 14.1521s/100 iter), loss = 2.07225
I0801 21:45:04.857575 12219 solver.cpp:375]     Train net output #0: loss = 1.85534 (* 1 = 1.85534 loss)
I0801 21:45:04.857583 12219 sgd_solver.cpp:136] Iteration 153700, lr = 0.0519688, m = 0.9
I0801 21:45:18.892796 12219 solver.cpp:353] Iteration 153800 (7.1251 iter/s, 14.0349s/100 iter), loss = 1.92705
I0801 21:45:18.892865 12219 solver.cpp:375]     Train net output #0: loss = 2.21843 (* 1 = 2.21843 loss)
I0801 21:45:18.892879 12219 sgd_solver.cpp:136] Iteration 153800, lr = 0.0519375, m = 0.9
I0801 21:45:32.885284 12219 solver.cpp:353] Iteration 153900 (7.14688 iter/s, 13.9921s/100 iter), loss = 1.83547
I0801 21:45:32.885313 12219 solver.cpp:375]     Train net output #0: loss = 1.96143 (* 1 = 1.96143 loss)
I0801 21:45:32.885316 12219 sgd_solver.cpp:136] Iteration 153900, lr = 0.0519063, m = 0.9
I0801 21:45:46.773773 12219 solver.cpp:550] Iteration 154000, Testing net (#0)
I0801 21:46:07.063071 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.433882
I0801 21:46:07.063094 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.692352
I0801 21:46:07.063100 12219 solver.cpp:635]     Test net output #2: loss = 2.5807 (* 1 = 2.5807 loss)
I0801 21:46:07.063176 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2889s
I0801 21:46:07.227252 12219 solver.cpp:353] Iteration 154000 (2.91197 iter/s, 34.341s/100 iter), loss = 1.76076
I0801 21:46:07.227452 12219 solver.cpp:375]     Train net output #0: loss = 1.85519 (* 1 = 1.85519 loss)
I0801 21:46:07.227560 12219 sgd_solver.cpp:136] Iteration 154000, lr = 0.051875, m = 0.9
I0801 21:46:21.308481 12219 solver.cpp:353] Iteration 154100 (7.10185 iter/s, 14.0808s/100 iter), loss = 1.84014
I0801 21:46:21.308601 12219 solver.cpp:375]     Train net output #0: loss = 1.60965 (* 1 = 1.60965 loss)
I0801 21:46:21.308607 12219 sgd_solver.cpp:136] Iteration 154100, lr = 0.0518438, m = 0.9
I0801 21:46:35.263217 12219 solver.cpp:353] Iteration 154200 (7.16622 iter/s, 13.9544s/100 iter), loss = 1.92793
I0801 21:46:35.263245 12219 solver.cpp:375]     Train net output #0: loss = 1.99404 (* 1 = 1.99404 loss)
I0801 21:46:35.263252 12219 sgd_solver.cpp:136] Iteration 154200, lr = 0.0518125, m = 0.9
I0801 21:46:49.223502 12219 solver.cpp:353] Iteration 154300 (7.16337 iter/s, 13.9599s/100 iter), loss = 2.10667
I0801 21:46:49.223531 12219 solver.cpp:375]     Train net output #0: loss = 2.36564 (* 1 = 2.36564 loss)
I0801 21:46:49.223536 12219 sgd_solver.cpp:136] Iteration 154300, lr = 0.0517812, m = 0.9
I0801 21:47:03.197942 12219 solver.cpp:353] Iteration 154400 (7.15612 iter/s, 13.9741s/100 iter), loss = 1.95643
I0801 21:47:03.198026 12219 solver.cpp:375]     Train net output #0: loss = 1.86237 (* 1 = 1.86237 loss)
I0801 21:47:03.198040 12219 sgd_solver.cpp:136] Iteration 154400, lr = 0.05175, m = 0.9
I0801 21:47:17.141402 12219 solver.cpp:353] Iteration 154500 (7.17202 iter/s, 13.9431s/100 iter), loss = 1.92782
I0801 21:47:17.141429 12219 solver.cpp:375]     Train net output #0: loss = 1.87387 (* 1 = 1.87387 loss)
I0801 21:47:17.141436 12219 sgd_solver.cpp:136] Iteration 154500, lr = 0.0517187, m = 0.9
I0801 21:47:31.244910 12219 solver.cpp:353] Iteration 154600 (7.09063 iter/s, 14.1031s/100 iter), loss = 1.70399
I0801 21:47:31.244936 12219 solver.cpp:375]     Train net output #0: loss = 2.15964 (* 1 = 2.15964 loss)
I0801 21:47:31.244942 12219 sgd_solver.cpp:136] Iteration 154600, lr = 0.0516875, m = 0.9
I0801 21:47:45.218911 12219 solver.cpp:353] Iteration 154700 (7.15634 iter/s, 13.9736s/100 iter), loss = 2.25611
I0801 21:47:45.218969 12219 solver.cpp:375]     Train net output #0: loss = 1.97339 (* 1 = 1.97339 loss)
I0801 21:47:45.218976 12219 sgd_solver.cpp:136] Iteration 154700, lr = 0.0516562, m = 0.9
I0801 21:47:59.181151 12219 solver.cpp:353] Iteration 154800 (7.16237 iter/s, 13.9619s/100 iter), loss = 1.80521
I0801 21:47:59.181177 12219 solver.cpp:375]     Train net output #0: loss = 1.95254 (* 1 = 1.95254 loss)
I0801 21:47:59.181182 12219 sgd_solver.cpp:136] Iteration 154800, lr = 0.051625, m = 0.9
I0801 21:48:13.226569 12219 solver.cpp:353] Iteration 154900 (7.11995 iter/s, 14.045s/100 iter), loss = 1.70675
I0801 21:48:13.226593 12219 solver.cpp:375]     Train net output #0: loss = 1.3144 (* 1 = 1.3144 loss)
I0801 21:48:13.226598 12219 sgd_solver.cpp:136] Iteration 154900, lr = 0.0515938, m = 0.9
I0801 21:48:27.168848 12219 solver.cpp:353] Iteration 155000 (7.17263 iter/s, 13.9419s/100 iter), loss = 1.64986
I0801 21:48:27.168928 12219 solver.cpp:375]     Train net output #0: loss = 1.45301 (* 1 = 1.45301 loss)
I0801 21:48:27.168936 12219 sgd_solver.cpp:136] Iteration 155000, lr = 0.0515625, m = 0.9
I0801 21:48:41.192448 12219 solver.cpp:353] Iteration 155100 (7.13103 iter/s, 14.0232s/100 iter), loss = 1.79862
I0801 21:48:41.192474 12219 solver.cpp:375]     Train net output #0: loss = 1.84342 (* 1 = 1.84342 loss)
I0801 21:48:41.192478 12219 sgd_solver.cpp:136] Iteration 155100, lr = 0.0515313, m = 0.9
I0801 21:48:55.182632 12219 solver.cpp:353] Iteration 155200 (7.14806 iter/s, 13.9898s/100 iter), loss = 1.72888
I0801 21:48:55.182662 12219 solver.cpp:375]     Train net output #0: loss = 1.41244 (* 1 = 1.41244 loss)
I0801 21:48:55.182668 12219 sgd_solver.cpp:136] Iteration 155200, lr = 0.0515, m = 0.9
I0801 21:49:09.162699 12219 solver.cpp:353] Iteration 155300 (7.15324 iter/s, 13.9797s/100 iter), loss = 2.04883
I0801 21:49:09.162787 12219 solver.cpp:375]     Train net output #0: loss = 1.68367 (* 1 = 1.68367 loss)
I0801 21:49:09.162794 12219 sgd_solver.cpp:136] Iteration 155300, lr = 0.0514688, m = 0.9
I0801 21:49:23.129483 12219 solver.cpp:353] Iteration 155400 (7.16004 iter/s, 13.9664s/100 iter), loss = 1.95189
I0801 21:49:23.129509 12219 solver.cpp:375]     Train net output #0: loss = 1.66328 (* 1 = 1.66328 loss)
I0801 21:49:23.129515 12219 sgd_solver.cpp:136] Iteration 155400, lr = 0.0514375, m = 0.9
I0801 21:49:37.089918 12219 solver.cpp:353] Iteration 155500 (7.1633 iter/s, 13.9601s/100 iter), loss = 1.79313
I0801 21:49:37.089946 12219 solver.cpp:375]     Train net output #0: loss = 2.12223 (* 1 = 2.12223 loss)
I0801 21:49:37.089949 12219 sgd_solver.cpp:136] Iteration 155500, lr = 0.0514063, m = 0.9
I0801 21:49:51.085801 12219 solver.cpp:353] Iteration 155600 (7.14515 iter/s, 13.9955s/100 iter), loss = 2.16029
I0801 21:49:51.085871 12219 solver.cpp:375]     Train net output #0: loss = 2.05784 (* 1 = 2.05784 loss)
I0801 21:49:51.085878 12219 sgd_solver.cpp:136] Iteration 155600, lr = 0.051375, m = 0.9
I0801 21:50:05.142665 12219 solver.cpp:353] Iteration 155700 (7.11416 iter/s, 14.0565s/100 iter), loss = 2.34464
I0801 21:50:05.142689 12219 solver.cpp:375]     Train net output #0: loss = 2.29628 (* 1 = 2.29628 loss)
I0801 21:50:05.142695 12219 sgd_solver.cpp:136] Iteration 155700, lr = 0.0513438, m = 0.9
I0801 21:50:19.195571 12219 solver.cpp:353] Iteration 155800 (7.11616 iter/s, 14.0525s/100 iter), loss = 1.76446
I0801 21:50:19.195665 12219 solver.cpp:375]     Train net output #0: loss = 2.25943 (* 1 = 2.25943 loss)
I0801 21:50:19.195685 12219 sgd_solver.cpp:136] Iteration 155800, lr = 0.0513125, m = 0.9
I0801 21:50:33.248478 12219 solver.cpp:353] Iteration 155900 (7.11616 iter/s, 14.0525s/100 iter), loss = 2.03292
I0801 21:50:33.248565 12219 solver.cpp:375]     Train net output #0: loss = 2.19158 (* 1 = 2.19158 loss)
I0801 21:50:33.248579 12219 sgd_solver.cpp:136] Iteration 155900, lr = 0.0512813, m = 0.9
I0801 21:50:47.086172 12219 solver.cpp:550] Iteration 156000, Testing net (#0)
I0801 21:51:06.979635 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.450647
I0801 21:51:06.979755 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.708175
I0801 21:51:06.979764 12219 solver.cpp:635]     Test net output #2: loss = 2.49385 (* 1 = 2.49385 loss)
I0801 21:51:06.979784 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8931s
I0801 21:51:07.130517 12219 solver.cpp:353] Iteration 156000 (2.9515 iter/s, 33.8811s/100 iter), loss = 1.75712
I0801 21:51:07.130542 12219 solver.cpp:375]     Train net output #0: loss = 1.44961 (* 1 = 1.44961 loss)
I0801 21:51:07.130548 12219 sgd_solver.cpp:136] Iteration 156000, lr = 0.05125, m = 0.9
I0801 21:51:21.142161 12219 solver.cpp:353] Iteration 156100 (7.13712 iter/s, 14.0113s/100 iter), loss = 2.21379
I0801 21:51:21.142190 12219 solver.cpp:375]     Train net output #0: loss = 1.95634 (* 1 = 1.95634 loss)
I0801 21:51:21.142196 12219 sgd_solver.cpp:136] Iteration 156100, lr = 0.0512187, m = 0.9
I0801 21:51:35.175115 12219 solver.cpp:353] Iteration 156200 (7.12629 iter/s, 14.0326s/100 iter), loss = 2.10648
I0801 21:51:35.175169 12219 solver.cpp:375]     Train net output #0: loss = 2.07061 (* 1 = 2.07061 loss)
I0801 21:51:35.175182 12219 sgd_solver.cpp:136] Iteration 156200, lr = 0.0511875, m = 0.9
I0801 21:51:49.145536 12219 solver.cpp:353] Iteration 156300 (7.15818 iter/s, 13.97s/100 iter), loss = 2.36892
I0801 21:51:49.145598 12219 solver.cpp:375]     Train net output #0: loss = 2.78871 (* 1 = 2.78871 loss)
I0801 21:51:49.145606 12219 sgd_solver.cpp:136] Iteration 156300, lr = 0.0511562, m = 0.9
I0801 21:52:03.146661 12219 solver.cpp:353] Iteration 156400 (7.14248 iter/s, 14.0007s/100 iter), loss = 1.78258
I0801 21:52:03.146700 12219 solver.cpp:375]     Train net output #0: loss = 1.7252 (* 1 = 1.7252 loss)
I0801 21:52:03.146708 12219 sgd_solver.cpp:136] Iteration 156400, lr = 0.051125, m = 0.9
I0801 21:52:17.128082 12219 solver.cpp:353] Iteration 156500 (7.15255 iter/s, 13.981s/100 iter), loss = 1.62894
I0801 21:52:17.128188 12219 solver.cpp:375]     Train net output #0: loss = 1.7972 (* 1 = 1.7972 loss)
I0801 21:52:17.128216 12219 sgd_solver.cpp:136] Iteration 156500, lr = 0.0510938, m = 0.9
I0801 21:52:31.118700 12219 solver.cpp:353] Iteration 156600 (7.14784 iter/s, 13.9902s/100 iter), loss = 1.90261
I0801 21:52:31.118829 12219 solver.cpp:375]     Train net output #0: loss = 2.00967 (* 1 = 2.00967 loss)
I0801 21:52:31.118850 12219 sgd_solver.cpp:136] Iteration 156600, lr = 0.0510625, m = 0.9
I0801 21:52:45.085322 12219 solver.cpp:353] Iteration 156700 (7.16012 iter/s, 13.9662s/100 iter), loss = 1.7438
I0801 21:52:45.085346 12219 solver.cpp:375]     Train net output #0: loss = 1.38154 (* 1 = 1.38154 loss)
I0801 21:52:45.085350 12219 sgd_solver.cpp:136] Iteration 156700, lr = 0.0510313, m = 0.9
I0801 21:52:59.113503 12219 solver.cpp:353] Iteration 156800 (7.1287 iter/s, 14.0278s/100 iter), loss = 2.07824
I0801 21:52:59.113528 12219 solver.cpp:375]     Train net output #0: loss = 2.21164 (* 1 = 2.21164 loss)
I0801 21:52:59.113533 12219 sgd_solver.cpp:136] Iteration 156800, lr = 0.051, m = 0.9
I0801 21:53:13.078006 12219 solver.cpp:353] Iteration 156900 (7.16121 iter/s, 13.9641s/100 iter), loss = 1.83827
I0801 21:53:13.078064 12219 solver.cpp:375]     Train net output #0: loss = 1.84255 (* 1 = 1.84255 loss)
I0801 21:53:13.078071 12219 sgd_solver.cpp:136] Iteration 156900, lr = 0.0509688, m = 0.9
I0801 21:53:27.038700 12219 solver.cpp:353] Iteration 157000 (7.16316 iter/s, 13.9603s/100 iter), loss = 1.9304
I0801 21:53:27.038758 12219 solver.cpp:375]     Train net output #0: loss = 1.6598 (* 1 = 1.6598 loss)
I0801 21:53:27.038770 12219 sgd_solver.cpp:136] Iteration 157000, lr = 0.0509375, m = 0.9
I0801 21:53:41.059090 12219 solver.cpp:353] Iteration 157100 (7.13266 iter/s, 14.02s/100 iter), loss = 1.86787
I0801 21:53:41.059178 12219 solver.cpp:375]     Train net output #0: loss = 2.28425 (* 1 = 2.28425 loss)
I0801 21:53:41.059198 12219 sgd_solver.cpp:136] Iteration 157100, lr = 0.0509063, m = 0.9
I0801 21:53:55.012135 12219 solver.cpp:353] Iteration 157200 (7.16709 iter/s, 13.9527s/100 iter), loss = 2.29945
I0801 21:53:55.012218 12219 solver.cpp:375]     Train net output #0: loss = 2.76004 (* 1 = 2.76004 loss)
I0801 21:53:55.012231 12219 sgd_solver.cpp:136] Iteration 157200, lr = 0.050875, m = 0.9
I0801 21:54:08.952893 12219 solver.cpp:353] Iteration 157300 (7.17341 iter/s, 13.9404s/100 iter), loss = 2.16605
I0801 21:54:08.953086 12219 solver.cpp:375]     Train net output #0: loss = 1.95742 (* 1 = 1.95742 loss)
I0801 21:54:08.953174 12219 sgd_solver.cpp:136] Iteration 157300, lr = 0.0508438, m = 0.9
I0801 21:54:22.871071 12219 solver.cpp:353] Iteration 157400 (7.18504 iter/s, 13.9178s/100 iter), loss = 1.90463
I0801 21:54:22.871107 12219 solver.cpp:375]     Train net output #0: loss = 1.91404 (* 1 = 1.91404 loss)
I0801 21:54:22.871114 12219 sgd_solver.cpp:136] Iteration 157400, lr = 0.0508125, m = 0.9
I0801 21:54:36.924959 12219 solver.cpp:353] Iteration 157500 (7.11566 iter/s, 14.0535s/100 iter), loss = 1.81197
I0801 21:54:36.925040 12219 solver.cpp:375]     Train net output #0: loss = 2.00469 (* 1 = 2.00469 loss)
I0801 21:54:36.925047 12219 sgd_solver.cpp:136] Iteration 157500, lr = 0.0507812, m = 0.9
I0801 21:54:50.898826 12219 solver.cpp:353] Iteration 157600 (7.15641 iter/s, 13.9735s/100 iter), loss = 1.98542
I0801 21:54:50.898900 12219 solver.cpp:375]     Train net output #0: loss = 1.93306 (* 1 = 1.93306 loss)
I0801 21:54:50.898921 12219 sgd_solver.cpp:136] Iteration 157600, lr = 0.05075, m = 0.9
I0801 21:55:04.799401 12219 solver.cpp:353] Iteration 157700 (7.19415 iter/s, 13.9002s/100 iter), loss = 2.27558
I0801 21:55:04.799428 12219 solver.cpp:375]     Train net output #0: loss = 2.54556 (* 1 = 2.54556 loss)
I0801 21:55:04.799434 12219 sgd_solver.cpp:136] Iteration 157700, lr = 0.0507188, m = 0.9
I0801 21:55:18.710893 12219 solver.cpp:353] Iteration 157800 (7.1885 iter/s, 13.9111s/100 iter), loss = 2.17553
I0801 21:55:18.710958 12219 solver.cpp:375]     Train net output #0: loss = 2.27027 (* 1 = 2.27027 loss)
I0801 21:55:18.710965 12219 sgd_solver.cpp:136] Iteration 157800, lr = 0.0506875, m = 0.9
I0801 21:55:32.689043 12219 solver.cpp:353] Iteration 157900 (7.15422 iter/s, 13.9778s/100 iter), loss = 1.98181
I0801 21:55:32.689103 12219 solver.cpp:375]     Train net output #0: loss = 1.91296 (* 1 = 1.91296 loss)
I0801 21:55:32.689116 12219 sgd_solver.cpp:136] Iteration 157900, lr = 0.0506562, m = 0.9
I0801 21:55:46.643585 12219 solver.cpp:550] Iteration 158000, Testing net (#0)
I0801 21:55:54.508874 12207 data_reader.cpp:264] Starting prefetch of epoch 8
I0801 21:56:01.405208 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 21:56:06.760639 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.458706
I0801 21:56:06.760666 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.714116
I0801 21:56:06.760673 12219 solver.cpp:635]     Test net output #2: loss = 2.47247 (* 1 = 2.47247 loss)
I0801 21:56:06.760726 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1166s
I0801 21:56:06.902254 12219 solver.cpp:353] Iteration 158000 (2.92293 iter/s, 34.2123s/100 iter), loss = 1.95138
I0801 21:56:06.902281 12219 solver.cpp:375]     Train net output #0: loss = 1.57397 (* 1 = 1.57397 loss)
I0801 21:56:06.902287 12219 sgd_solver.cpp:136] Iteration 158000, lr = 0.050625, m = 0.9
I0801 21:56:20.825542 12219 solver.cpp:353] Iteration 158100 (7.18241 iter/s, 13.9229s/100 iter), loss = 1.83143
I0801 21:56:20.825646 12219 solver.cpp:375]     Train net output #0: loss = 1.81385 (* 1 = 1.81385 loss)
I0801 21:56:20.825669 12219 sgd_solver.cpp:136] Iteration 158100, lr = 0.0505937, m = 0.9
I0801 21:56:34.803342 12219 solver.cpp:353] Iteration 158200 (7.1544 iter/s, 13.9774s/100 iter), loss = 1.94299
I0801 21:56:34.803413 12219 solver.cpp:375]     Train net output #0: loss = 1.78999 (* 1 = 1.78999 loss)
I0801 21:56:34.803422 12219 sgd_solver.cpp:136] Iteration 158200, lr = 0.0505625, m = 0.9
I0801 21:56:48.906443 12219 solver.cpp:353] Iteration 158300 (7.09083 iter/s, 14.1027s/100 iter), loss = 1.94523
I0801 21:56:48.906469 12219 solver.cpp:375]     Train net output #0: loss = 1.90818 (* 1 = 1.90818 loss)
I0801 21:56:48.906476 12219 sgd_solver.cpp:136] Iteration 158300, lr = 0.0505312, m = 0.9
I0801 21:57:02.895462 12219 solver.cpp:353] Iteration 158400 (7.14866 iter/s, 13.9886s/100 iter), loss = 2.36588
I0801 21:57:02.895489 12219 solver.cpp:375]     Train net output #0: loss = 2.2951 (* 1 = 2.2951 loss)
I0801 21:57:02.895494 12219 sgd_solver.cpp:136] Iteration 158400, lr = 0.0505, m = 0.9
I0801 21:57:16.887531 12219 solver.cpp:353] Iteration 158500 (7.1471 iter/s, 13.9917s/100 iter), loss = 1.93385
I0801 21:57:16.887594 12219 solver.cpp:375]     Train net output #0: loss = 2.27548 (* 1 = 2.27548 loss)
I0801 21:57:16.887601 12219 sgd_solver.cpp:136] Iteration 158500, lr = 0.0504688, m = 0.9
I0801 21:57:30.822067 12219 solver.cpp:353] Iteration 158600 (7.17661 iter/s, 13.9342s/100 iter), loss = 1.94049
I0801 21:57:30.822095 12219 solver.cpp:375]     Train net output #0: loss = 1.68762 (* 1 = 1.68762 loss)
I0801 21:57:30.822100 12219 sgd_solver.cpp:136] Iteration 158600, lr = 0.0504375, m = 0.9
I0801 21:57:44.927645 12219 solver.cpp:353] Iteration 158700 (7.08959 iter/s, 14.1052s/100 iter), loss = 1.973
I0801 21:57:44.927673 12219 solver.cpp:375]     Train net output #0: loss = 1.97303 (* 1 = 1.97303 loss)
I0801 21:57:44.927680 12219 sgd_solver.cpp:136] Iteration 158700, lr = 0.0504063, m = 0.9
I0801 21:57:59.018651 12219 solver.cpp:353] Iteration 158800 (7.09692 iter/s, 14.0906s/100 iter), loss = 2.10852
I0801 21:57:59.018712 12219 solver.cpp:375]     Train net output #0: loss = 1.96882 (* 1 = 1.96882 loss)
I0801 21:57:59.018718 12219 sgd_solver.cpp:136] Iteration 158800, lr = 0.050375, m = 0.9
I0801 21:58:13.036202 12219 solver.cpp:353] Iteration 158900 (7.13411 iter/s, 14.0172s/100 iter), loss = 1.77208
I0801 21:58:13.036231 12219 solver.cpp:375]     Train net output #0: loss = 1.81271 (* 1 = 1.81271 loss)
I0801 21:58:13.036237 12219 sgd_solver.cpp:136] Iteration 158900, lr = 0.0503438, m = 0.9
I0801 21:58:27.065757 12219 solver.cpp:353] Iteration 159000 (7.12801 iter/s, 14.0292s/100 iter), loss = 2.24562
I0801 21:58:27.065783 12219 solver.cpp:375]     Train net output #0: loss = 2.3764 (* 1 = 2.3764 loss)
I0801 21:58:27.065788 12219 sgd_solver.cpp:136] Iteration 159000, lr = 0.0503125, m = 0.9
I0801 21:58:41.012377 12219 solver.cpp:353] Iteration 159100 (7.17039 iter/s, 13.9462s/100 iter), loss = 1.8436
I0801 21:58:41.012454 12219 solver.cpp:375]     Train net output #0: loss = 1.91214 (* 1 = 1.91214 loss)
I0801 21:58:41.012460 12219 sgd_solver.cpp:136] Iteration 159100, lr = 0.0502813, m = 0.9
I0801 21:58:55.043619 12219 solver.cpp:353] Iteration 159200 (7.12716 iter/s, 14.0308s/100 iter), loss = 2.19239
I0801 21:58:55.043648 12219 solver.cpp:375]     Train net output #0: loss = 2.43247 (* 1 = 2.43247 loss)
I0801 21:58:55.043655 12219 sgd_solver.cpp:136] Iteration 159200, lr = 0.05025, m = 0.9
I0801 21:59:09.101155 12219 solver.cpp:353] Iteration 159300 (7.11382 iter/s, 14.0572s/100 iter), loss = 1.92585
I0801 21:59:09.101183 12219 solver.cpp:375]     Train net output #0: loss = 2.00736 (* 1 = 2.00736 loss)
I0801 21:59:09.101189 12219 sgd_solver.cpp:136] Iteration 159300, lr = 0.0502187, m = 0.9
I0801 21:59:23.157702 12219 solver.cpp:353] Iteration 159400 (7.11432 iter/s, 14.0562s/100 iter), loss = 2.33095
I0801 21:59:23.157788 12219 solver.cpp:375]     Train net output #0: loss = 2.22713 (* 1 = 2.22713 loss)
I0801 21:59:23.157794 12219 sgd_solver.cpp:136] Iteration 159400, lr = 0.0501875, m = 0.9
I0801 21:59:37.162714 12219 solver.cpp:353] Iteration 159500 (7.1405 iter/s, 14.0046s/100 iter), loss = 1.75794
I0801 21:59:37.162737 12219 solver.cpp:375]     Train net output #0: loss = 1.73385 (* 1 = 1.73385 loss)
I0801 21:59:37.162741 12219 sgd_solver.cpp:136] Iteration 159500, lr = 0.0501562, m = 0.9
I0801 21:59:51.092257 12219 solver.cpp:353] Iteration 159600 (7.17918 iter/s, 13.9292s/100 iter), loss = 2.26857
I0801 21:59:51.092280 12219 solver.cpp:375]     Train net output #0: loss = 2.31574 (* 1 = 2.31574 loss)
I0801 21:59:51.092284 12219 sgd_solver.cpp:136] Iteration 159600, lr = 0.050125, m = 0.9
I0801 22:00:05.177067 12219 solver.cpp:353] Iteration 159700 (7.10004 iter/s, 14.0844s/100 iter), loss = 1.97415
I0801 22:00:05.177125 12219 solver.cpp:375]     Train net output #0: loss = 1.93043 (* 1 = 1.93043 loss)
I0801 22:00:05.177131 12219 sgd_solver.cpp:136] Iteration 159700, lr = 0.0500937, m = 0.9
I0801 22:00:19.296756 12219 solver.cpp:353] Iteration 159800 (7.0825 iter/s, 14.1193s/100 iter), loss = 2.16647
I0801 22:00:19.296780 12219 solver.cpp:375]     Train net output #0: loss = 2.10042 (* 1 = 2.10042 loss)
I0801 22:00:19.296784 12219 sgd_solver.cpp:136] Iteration 159800, lr = 0.0500625, m = 0.9
I0801 22:00:33.337621 12219 solver.cpp:353] Iteration 159900 (7.12226 iter/s, 14.0405s/100 iter), loss = 1.46799
I0801 22:00:33.337646 12219 solver.cpp:375]     Train net output #0: loss = 1.45324 (* 1 = 1.45324 loss)
I0801 22:00:33.337649 12219 sgd_solver.cpp:136] Iteration 159900, lr = 0.0500313, m = 0.9
I0801 22:00:47.271034 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_160000.caffemodel
I0801 22:00:47.304257 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_160000.solverstate
I0801 22:00:47.311434 12219 solver.cpp:550] Iteration 160000, Testing net (#0)
I0801 22:01:07.440265 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.43547
I0801 22:01:07.440292 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.692057
I0801 22:01:07.440301 12219 solver.cpp:635]     Test net output #2: loss = 2.60447 (* 1 = 2.60447 loss)
I0801 22:01:07.440326 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1283s
I0801 22:01:07.599795 12219 solver.cpp:353] Iteration 160000 (2.91875 iter/s, 34.2612s/100 iter), loss = 1.84291
I0801 22:01:07.599849 12219 solver.cpp:375]     Train net output #0: loss = 2.0762 (* 1 = 2.0762 loss)
I0801 22:01:07.599861 12219 sgd_solver.cpp:136] Iteration 160000, lr = 0.05, m = 0.9
I0801 22:01:21.633759 12219 solver.cpp:353] Iteration 160100 (7.12577 iter/s, 14.0336s/100 iter), loss = 1.67378
I0801 22:01:21.633877 12219 solver.cpp:375]     Train net output #0: loss = 1.75788 (* 1 = 1.75788 loss)
I0801 22:01:21.633888 12219 sgd_solver.cpp:136] Iteration 160100, lr = 0.0499687, m = 0.9
I0801 22:01:35.616102 12219 solver.cpp:353] Iteration 160200 (7.15208 iter/s, 13.982s/100 iter), loss = 2.04151
I0801 22:01:35.616221 12219 solver.cpp:375]     Train net output #0: loss = 1.98703 (* 1 = 1.98703 loss)
I0801 22:01:35.616245 12219 sgd_solver.cpp:136] Iteration 160200, lr = 0.0499375, m = 0.9
I0801 22:01:49.694514 12219 solver.cpp:353] Iteration 160300 (7.10327 iter/s, 14.078s/100 iter), loss = 1.96047
I0801 22:01:49.694540 12219 solver.cpp:375]     Train net output #0: loss = 2.32495 (* 1 = 2.32495 loss)
I0801 22:01:49.694543 12219 sgd_solver.cpp:136] Iteration 160300, lr = 0.0499063, m = 0.9
I0801 22:02:03.678458 12219 solver.cpp:353] Iteration 160400 (7.15125 iter/s, 13.9836s/100 iter), loss = 1.80468
I0801 22:02:03.678544 12219 solver.cpp:375]     Train net output #0: loss = 1.71963 (* 1 = 1.71963 loss)
I0801 22:02:03.678550 12219 sgd_solver.cpp:136] Iteration 160400, lr = 0.049875, m = 0.9
I0801 22:02:17.593580 12219 solver.cpp:353] Iteration 160500 (7.18662 iter/s, 13.9147s/100 iter), loss = 2.32346
I0801 22:02:17.593613 12219 solver.cpp:375]     Train net output #0: loss = 2.30156 (* 1 = 2.30156 loss)
I0801 22:02:17.593621 12219 sgd_solver.cpp:136] Iteration 160500, lr = 0.0498438, m = 0.9
I0801 22:02:31.618600 12219 solver.cpp:353] Iteration 160600 (7.13031 iter/s, 14.0246s/100 iter), loss = 1.81244
I0801 22:02:31.618631 12219 solver.cpp:375]     Train net output #0: loss = 1.81385 (* 1 = 1.81385 loss)
I0801 22:02:31.618635 12219 sgd_solver.cpp:136] Iteration 160600, lr = 0.0498125, m = 0.9
I0801 22:02:45.513183 12219 solver.cpp:353] Iteration 160700 (7.19725 iter/s, 13.8942s/100 iter), loss = 1.5812
I0801 22:02:45.513280 12219 solver.cpp:375]     Train net output #0: loss = 1.51663 (* 1 = 1.51663 loss)
I0801 22:02:45.513288 12219 sgd_solver.cpp:136] Iteration 160700, lr = 0.0497813, m = 0.9
I0801 22:02:59.509079 12219 solver.cpp:353] Iteration 160800 (7.14515 iter/s, 13.9955s/100 iter), loss = 2.05789
I0801 22:02:59.509109 12219 solver.cpp:375]     Train net output #0: loss = 2.36378 (* 1 = 2.36378 loss)
I0801 22:02:59.509114 12219 sgd_solver.cpp:136] Iteration 160800, lr = 0.04975, m = 0.9
I0801 22:03:13.429409 12219 solver.cpp:353] Iteration 160900 (7.18394 iter/s, 13.9199s/100 iter), loss = 1.82657
I0801 22:03:13.429438 12219 solver.cpp:375]     Train net output #0: loss = 1.87159 (* 1 = 1.87159 loss)
I0801 22:03:13.429445 12219 sgd_solver.cpp:136] Iteration 160900, lr = 0.0497187, m = 0.9
I0801 22:03:27.407235 12219 solver.cpp:353] Iteration 161000 (7.15438 iter/s, 13.9774s/100 iter), loss = 1.76343
I0801 22:03:27.407296 12219 solver.cpp:375]     Train net output #0: loss = 1.68346 (* 1 = 1.68346 loss)
I0801 22:03:27.407302 12219 sgd_solver.cpp:136] Iteration 161000, lr = 0.0496875, m = 0.9
I0801 22:03:41.460201 12219 solver.cpp:353] Iteration 161100 (7.11613 iter/s, 14.0526s/100 iter), loss = 2.02699
I0801 22:03:41.460225 12219 solver.cpp:375]     Train net output #0: loss = 1.73537 (* 1 = 1.73537 loss)
I0801 22:03:41.460229 12219 sgd_solver.cpp:136] Iteration 161100, lr = 0.0496562, m = 0.9
I0801 22:03:55.461755 12219 solver.cpp:353] Iteration 161200 (7.14226 iter/s, 14.0012s/100 iter), loss = 1.67
I0801 22:03:55.461784 12219 solver.cpp:375]     Train net output #0: loss = 1.57634 (* 1 = 1.57634 loss)
I0801 22:03:55.461789 12219 sgd_solver.cpp:136] Iteration 161200, lr = 0.049625, m = 0.9
I0801 22:04:09.460307 12219 solver.cpp:353] Iteration 161300 (7.14379 iter/s, 13.9982s/100 iter), loss = 1.96493
I0801 22:04:09.460362 12219 solver.cpp:375]     Train net output #0: loss = 1.99103 (* 1 = 1.99103 loss)
I0801 22:04:09.460369 12219 sgd_solver.cpp:136] Iteration 161300, lr = 0.0495938, m = 0.9
I0801 22:04:23.423509 12219 solver.cpp:353] Iteration 161400 (7.16188 iter/s, 13.9628s/100 iter), loss = 2.01702
I0801 22:04:23.423539 12219 solver.cpp:375]     Train net output #0: loss = 2.23322 (* 1 = 2.23322 loss)
I0801 22:04:23.423547 12219 sgd_solver.cpp:136] Iteration 161400, lr = 0.0495625, m = 0.9
I0801 22:04:37.411875 12219 solver.cpp:353] Iteration 161500 (7.14899 iter/s, 13.988s/100 iter), loss = 2.0733
I0801 22:04:37.411896 12219 solver.cpp:375]     Train net output #0: loss = 1.87471 (* 1 = 1.87471 loss)
I0801 22:04:37.411900 12219 sgd_solver.cpp:136] Iteration 161500, lr = 0.0495313, m = 0.9
I0801 22:04:51.362321 12219 solver.cpp:353] Iteration 161600 (7.16843 iter/s, 13.9501s/100 iter), loss = 1.72606
I0801 22:04:51.362799 12219 solver.cpp:375]     Train net output #0: loss = 1.64446 (* 1 = 1.64446 loss)
I0801 22:04:51.362807 12219 sgd_solver.cpp:136] Iteration 161600, lr = 0.0495, m = 0.9
I0801 22:05:05.418634 12219 solver.cpp:353] Iteration 161700 (7.11443 iter/s, 14.0559s/100 iter), loss = 1.82279
I0801 22:05:05.418659 12219 solver.cpp:375]     Train net output #0: loss = 2.02927 (* 1 = 2.02927 loss)
I0801 22:05:05.418665 12219 sgd_solver.cpp:136] Iteration 161700, lr = 0.0494688, m = 0.9
I0801 22:05:19.497817 12219 solver.cpp:353] Iteration 161800 (7.10288 iter/s, 14.0788s/100 iter), loss = 1.67562
I0801 22:05:19.497841 12219 solver.cpp:375]     Train net output #0: loss = 1.68813 (* 1 = 1.68813 loss)
I0801 22:05:19.497848 12219 sgd_solver.cpp:136] Iteration 161800, lr = 0.0494375, m = 0.9
I0801 22:05:33.441037 12219 solver.cpp:353] Iteration 161900 (7.17214 iter/s, 13.9428s/100 iter), loss = 1.78591
I0801 22:05:33.441097 12219 solver.cpp:375]     Train net output #0: loss = 1.74232 (* 1 = 1.74232 loss)
I0801 22:05:33.441104 12219 sgd_solver.cpp:136] Iteration 161900, lr = 0.0494062, m = 0.9
I0801 22:05:47.266743 12219 solver.cpp:550] Iteration 162000, Testing net (#0)
I0801 22:06:07.385309 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.444412
I0801 22:06:07.385388 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.701411
I0801 22:06:07.385399 12219 solver.cpp:635]     Test net output #2: loss = 2.53201 (* 1 = 2.53201 loss)
I0801 22:06:07.385424 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1182s
I0801 22:06:07.531544 12219 solver.cpp:353] Iteration 162000 (2.93345 iter/s, 34.0896s/100 iter), loss = 1.84411
I0801 22:06:07.531572 12219 solver.cpp:375]     Train net output #0: loss = 1.81301 (* 1 = 1.81301 loss)
I0801 22:06:07.531579 12219 sgd_solver.cpp:136] Iteration 162000, lr = 0.049375, m = 0.9
I0801 22:06:21.543750 12219 solver.cpp:353] Iteration 162100 (7.13683 iter/s, 14.0118s/100 iter), loss = 1.89696
I0801 22:06:21.543777 12219 solver.cpp:375]     Train net output #0: loss = 1.80834 (* 1 = 1.80834 loss)
I0801 22:06:21.543783 12219 sgd_solver.cpp:136] Iteration 162100, lr = 0.0493438, m = 0.9
I0801 22:06:35.469558 12219 solver.cpp:353] Iteration 162200 (7.18111 iter/s, 13.9254s/100 iter), loss = 2.09108
I0801 22:06:35.469588 12219 solver.cpp:375]     Train net output #0: loss = 2.28131 (* 1 = 2.28131 loss)
I0801 22:06:35.469593 12219 sgd_solver.cpp:136] Iteration 162200, lr = 0.0493125, m = 0.9
I0801 22:06:49.412861 12219 solver.cpp:353] Iteration 162300 (7.1721 iter/s, 13.9429s/100 iter), loss = 2.16499
I0801 22:06:49.412925 12219 solver.cpp:375]     Train net output #0: loss = 1.81628 (* 1 = 1.81628 loss)
I0801 22:06:49.412932 12219 sgd_solver.cpp:136] Iteration 162300, lr = 0.0492813, m = 0.9
I0801 22:07:03.432863 12219 solver.cpp:353] Iteration 162400 (7.13286 iter/s, 14.0196s/100 iter), loss = 1.89509
I0801 22:07:03.432893 12219 solver.cpp:375]     Train net output #0: loss = 2.053 (* 1 = 2.053 loss)
I0801 22:07:03.432898 12219 sgd_solver.cpp:136] Iteration 162400, lr = 0.04925, m = 0.9
I0801 22:07:17.391649 12219 solver.cpp:353] Iteration 162500 (7.16414 iter/s, 13.9584s/100 iter), loss = 2.23219
I0801 22:07:17.391717 12219 solver.cpp:375]     Train net output #0: loss = 2.5327 (* 1 = 2.5327 loss)
I0801 22:07:17.391736 12219 sgd_solver.cpp:136] Iteration 162500, lr = 0.0492188, m = 0.9
I0801 22:07:31.300178 12219 solver.cpp:353] Iteration 162600 (7.19003 iter/s, 13.9081s/100 iter), loss = 1.39779
I0801 22:07:31.300258 12219 solver.cpp:375]     Train net output #0: loss = 1.46824 (* 1 = 1.46824 loss)
I0801 22:07:31.300266 12219 sgd_solver.cpp:136] Iteration 162600, lr = 0.0491875, m = 0.9
I0801 22:07:45.387877 12219 solver.cpp:353] Iteration 162700 (7.09858 iter/s, 14.0873s/100 iter), loss = 2.11869
I0801 22:07:45.387905 12219 solver.cpp:375]     Train net output #0: loss = 1.96312 (* 1 = 1.96312 loss)
I0801 22:07:45.387910 12219 sgd_solver.cpp:136] Iteration 162700, lr = 0.0491562, m = 0.9
I0801 22:07:59.366394 12219 solver.cpp:353] Iteration 162800 (7.15403 iter/s, 13.9781s/100 iter), loss = 1.87497
I0801 22:07:59.366420 12219 solver.cpp:375]     Train net output #0: loss = 1.77917 (* 1 = 1.77917 loss)
I0801 22:07:59.366425 12219 sgd_solver.cpp:136] Iteration 162800, lr = 0.049125, m = 0.9
I0801 22:08:13.366168 12219 solver.cpp:353] Iteration 162900 (7.14317 iter/s, 13.9994s/100 iter), loss = 2.09424
I0801 22:08:13.366222 12219 solver.cpp:375]     Train net output #0: loss = 2.27066 (* 1 = 2.27066 loss)
I0801 22:08:13.366230 12219 sgd_solver.cpp:136] Iteration 162900, lr = 0.0490937, m = 0.9
I0801 22:08:27.402925 12219 solver.cpp:353] Iteration 163000 (7.12435 iter/s, 14.0364s/100 iter), loss = 1.86909
I0801 22:08:27.402951 12219 solver.cpp:375]     Train net output #0: loss = 1.59176 (* 1 = 1.59176 loss)
I0801 22:08:27.402954 12219 sgd_solver.cpp:136] Iteration 163000, lr = 0.0490625, m = 0.9
I0801 22:08:41.400552 12219 solver.cpp:353] Iteration 163100 (7.14426 iter/s, 13.9972s/100 iter), loss = 2.18709
I0801 22:08:41.400576 12219 solver.cpp:375]     Train net output #0: loss = 2.06017 (* 1 = 2.06017 loss)
I0801 22:08:41.400583 12219 sgd_solver.cpp:136] Iteration 163100, lr = 0.0490313, m = 0.9
I0801 22:08:55.371889 12219 solver.cpp:353] Iteration 163200 (7.15771 iter/s, 13.971s/100 iter), loss = 1.63996
I0801 22:08:55.371971 12219 solver.cpp:375]     Train net output #0: loss = 1.07979 (* 1 = 1.07979 loss)
I0801 22:08:55.371985 12219 sgd_solver.cpp:136] Iteration 163200, lr = 0.049, m = 0.9
I0801 22:09:09.222733 12219 solver.cpp:353] Iteration 163300 (7.21998 iter/s, 13.8505s/100 iter), loss = 2.09763
I0801 22:09:09.222786 12219 solver.cpp:375]     Train net output #0: loss = 2.13903 (* 1 = 2.13903 loss)
I0801 22:09:09.222798 12219 sgd_solver.cpp:136] Iteration 163300, lr = 0.0489688, m = 0.9
I0801 22:09:23.218395 12219 solver.cpp:353] Iteration 163400 (7.14527 iter/s, 13.9953s/100 iter), loss = 1.76257
I0801 22:09:23.218420 12219 solver.cpp:375]     Train net output #0: loss = 2.12621 (* 1 = 2.12621 loss)
I0801 22:09:23.218425 12219 sgd_solver.cpp:136] Iteration 163400, lr = 0.0489375, m = 0.9
I0801 22:09:37.085340 12219 solver.cpp:353] Iteration 163500 (7.21159 iter/s, 13.8666s/100 iter), loss = 1.81092
I0801 22:09:37.085397 12219 solver.cpp:375]     Train net output #0: loss = 1.77763 (* 1 = 1.77763 loss)
I0801 22:09:37.085403 12219 sgd_solver.cpp:136] Iteration 163500, lr = 0.0489062, m = 0.9
I0801 22:09:51.045845 12219 solver.cpp:353] Iteration 163600 (7.16326 iter/s, 13.9601s/100 iter), loss = 1.70443
I0801 22:09:51.045868 12219 solver.cpp:375]     Train net output #0: loss = 2.12628 (* 1 = 2.12628 loss)
I0801 22:09:51.045872 12219 sgd_solver.cpp:136] Iteration 163600, lr = 0.048875, m = 0.9
I0801 22:10:04.987601 12219 solver.cpp:353] Iteration 163700 (7.17289 iter/s, 13.9414s/100 iter), loss = 2.01931
I0801 22:10:04.987623 12219 solver.cpp:375]     Train net output #0: loss = 1.6037 (* 1 = 1.6037 loss)
I0801 22:10:04.987628 12219 sgd_solver.cpp:136] Iteration 163700, lr = 0.0488437, m = 0.9
I0801 22:10:18.949359 12219 solver.cpp:353] Iteration 163800 (7.16261 iter/s, 13.9614s/100 iter), loss = 1.96695
I0801 22:10:18.949414 12219 solver.cpp:375]     Train net output #0: loss = 1.76836 (* 1 = 1.76836 loss)
I0801 22:10:18.949419 12219 sgd_solver.cpp:136] Iteration 163800, lr = 0.0488125, m = 0.9
I0801 22:10:33.041172 12219 solver.cpp:353] Iteration 163900 (7.09651 iter/s, 14.0914s/100 iter), loss = 1.80342
I0801 22:10:33.041223 12219 solver.cpp:375]     Train net output #0: loss = 1.91204 (* 1 = 1.91204 loss)
I0801 22:10:33.041234 12219 sgd_solver.cpp:136] Iteration 163900, lr = 0.0487813, m = 0.9
I0801 22:10:46.972412 12219 solver.cpp:550] Iteration 164000, Testing net (#0)
I0801 22:11:04.909653 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 22:11:07.342838 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.432
I0801 22:11:07.342881 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.688823
I0801 22:11:07.342893 12219 solver.cpp:635]     Test net output #2: loss = 2.61813 (* 1 = 2.61813 loss)
I0801 22:11:07.342965 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.37s
I0801 22:11:07.499421 12219 solver.cpp:353] Iteration 164000 (2.90214 iter/s, 34.4573s/100 iter), loss = 2.1055
I0801 22:11:07.499449 12219 solver.cpp:375]     Train net output #0: loss = 2.42807 (* 1 = 2.42807 loss)
I0801 22:11:07.499452 12219 sgd_solver.cpp:136] Iteration 164000, lr = 0.04875, m = 0.9
I0801 22:11:21.551429 12219 solver.cpp:353] Iteration 164100 (7.11662 iter/s, 14.0516s/100 iter), loss = 2.07148
I0801 22:11:21.551455 12219 solver.cpp:375]     Train net output #0: loss = 2.09022 (* 1 = 2.09022 loss)
I0801 22:11:21.551461 12219 sgd_solver.cpp:136] Iteration 164100, lr = 0.0487188, m = 0.9
I0801 22:11:35.509047 12219 solver.cpp:353] Iteration 164200 (7.16474 iter/s, 13.9572s/100 iter), loss = 2.32205
I0801 22:11:35.509105 12219 solver.cpp:375]     Train net output #0: loss = 2.61892 (* 1 = 2.61892 loss)
I0801 22:11:35.509112 12219 sgd_solver.cpp:136] Iteration 164200, lr = 0.0486875, m = 0.9
I0801 22:11:49.505012 12219 solver.cpp:353] Iteration 164300 (7.14511 iter/s, 13.9956s/100 iter), loss = 1.93946
I0801 22:11:49.505039 12219 solver.cpp:375]     Train net output #0: loss = 1.71179 (* 1 = 1.71179 loss)
I0801 22:11:49.505048 12219 sgd_solver.cpp:136] Iteration 164300, lr = 0.0486563, m = 0.9
I0801 22:12:03.594310 12219 solver.cpp:353] Iteration 164400 (7.09778 iter/s, 14.0889s/100 iter), loss = 1.83347
I0801 22:12:03.594334 12219 solver.cpp:375]     Train net output #0: loss = 1.78313 (* 1 = 1.78313 loss)
I0801 22:12:03.594338 12219 sgd_solver.cpp:136] Iteration 164400, lr = 0.048625, m = 0.9
I0801 22:12:17.647074 12219 solver.cpp:353] Iteration 164500 (7.11623 iter/s, 14.0524s/100 iter), loss = 2.17362
I0801 22:12:17.647178 12219 solver.cpp:375]     Train net output #0: loss = 2.52709 (* 1 = 2.52709 loss)
I0801 22:12:17.647186 12219 sgd_solver.cpp:136] Iteration 164500, lr = 0.0485937, m = 0.9
I0801 22:12:31.664193 12219 solver.cpp:353] Iteration 164600 (7.13433 iter/s, 14.0167s/100 iter), loss = 1.9357
I0801 22:12:31.664293 12219 solver.cpp:375]     Train net output #0: loss = 2.65919 (* 1 = 2.65919 loss)
I0801 22:12:31.664314 12219 sgd_solver.cpp:136] Iteration 164600, lr = 0.0485625, m = 0.9
I0801 22:12:45.716893 12219 solver.cpp:353] Iteration 164700 (7.11626 iter/s, 14.0523s/100 iter), loss = 2.12544
I0801 22:12:45.716984 12219 solver.cpp:375]     Train net output #0: loss = 2.5242 (* 1 = 2.5242 loss)
I0801 22:12:45.717003 12219 sgd_solver.cpp:136] Iteration 164700, lr = 0.0485313, m = 0.9
I0801 22:12:59.770946 12219 solver.cpp:353] Iteration 164800 (7.11558 iter/s, 14.0537s/100 iter), loss = 2.36885
I0801 22:12:59.771036 12219 solver.cpp:375]     Train net output #0: loss = 2.33941 (* 1 = 2.33941 loss)
I0801 22:12:59.771051 12219 sgd_solver.cpp:136] Iteration 164800, lr = 0.0485, m = 0.9
I0801 22:13:13.781102 12219 solver.cpp:353] Iteration 164900 (7.13787 iter/s, 14.0098s/100 iter), loss = 1.89736
I0801 22:13:13.781126 12219 solver.cpp:375]     Train net output #0: loss = 1.82826 (* 1 = 1.82826 loss)
I0801 22:13:13.781131 12219 sgd_solver.cpp:136] Iteration 164900, lr = 0.0484687, m = 0.9
I0801 22:13:27.829007 12219 solver.cpp:353] Iteration 165000 (7.11869 iter/s, 14.0475s/100 iter), loss = 1.75908
I0801 22:13:27.829186 12219 solver.cpp:375]     Train net output #0: loss = 1.58566 (* 1 = 1.58566 loss)
I0801 22:13:27.829215 12219 sgd_solver.cpp:136] Iteration 165000, lr = 0.0484375, m = 0.9
I0801 22:13:41.866374 12219 solver.cpp:353] Iteration 165100 (7.12404 iter/s, 14.037s/100 iter), loss = 1.97617
I0801 22:13:41.866479 12219 solver.cpp:375]     Train net output #0: loss = 2.30374 (* 1 = 2.30374 loss)
I0801 22:13:41.866487 12219 sgd_solver.cpp:136] Iteration 165100, lr = 0.0484063, m = 0.9
I0801 22:13:55.823912 12219 solver.cpp:353] Iteration 165200 (7.16478 iter/s, 13.9572s/100 iter), loss = 2.06922
I0801 22:13:55.823943 12219 solver.cpp:375]     Train net output #0: loss = 2.27198 (* 1 = 2.27198 loss)
I0801 22:13:55.823949 12219 sgd_solver.cpp:136] Iteration 165200, lr = 0.048375, m = 0.9
I0801 22:14:09.837438 12219 solver.cpp:353] Iteration 165300 (7.13616 iter/s, 14.0131s/100 iter), loss = 1.76106
I0801 22:14:09.837491 12219 solver.cpp:375]     Train net output #0: loss = 2.00665 (* 1 = 2.00665 loss)
I0801 22:14:09.837502 12219 sgd_solver.cpp:136] Iteration 165300, lr = 0.0483437, m = 0.9
I0801 22:14:23.718482 12219 solver.cpp:353] Iteration 165400 (7.20427 iter/s, 13.8807s/100 iter), loss = 1.84288
I0801 22:14:23.718569 12219 solver.cpp:375]     Train net output #0: loss = 1.8958 (* 1 = 1.8958 loss)
I0801 22:14:23.718576 12219 sgd_solver.cpp:136] Iteration 165400, lr = 0.0483125, m = 0.9
I0801 22:14:37.757854 12219 solver.cpp:353] Iteration 165500 (7.12302 iter/s, 14.039s/100 iter), loss = 1.75697
I0801 22:14:37.757884 12219 solver.cpp:375]     Train net output #0: loss = 1.50652 (* 1 = 1.50652 loss)
I0801 22:14:37.757889 12219 sgd_solver.cpp:136] Iteration 165500, lr = 0.0482813, m = 0.9
I0801 22:14:51.677098 12219 solver.cpp:353] Iteration 165600 (7.1845 iter/s, 13.9188s/100 iter), loss = 1.80122
I0801 22:14:51.677178 12219 solver.cpp:375]     Train net output #0: loss = 1.60418 (* 1 = 1.60418 loss)
I0801 22:14:51.677201 12219 sgd_solver.cpp:136] Iteration 165600, lr = 0.04825, m = 0.9
I0801 22:15:05.605031 12219 solver.cpp:353] Iteration 165700 (7.18001 iter/s, 13.9276s/100 iter), loss = 1.70809
I0801 22:15:05.605109 12219 solver.cpp:375]     Train net output #0: loss = 1.6632 (* 1 = 1.6632 loss)
I0801 22:15:05.605116 12219 sgd_solver.cpp:136] Iteration 165700, lr = 0.0482188, m = 0.9
I0801 22:15:19.708237 12219 solver.cpp:353] Iteration 165800 (7.09078 iter/s, 14.1028s/100 iter), loss = 2.15667
I0801 22:15:19.708263 12219 solver.cpp:375]     Train net output #0: loss = 1.81205 (* 1 = 1.81205 loss)
I0801 22:15:19.708308 12219 sgd_solver.cpp:136] Iteration 165800, lr = 0.0481875, m = 0.9
I0801 22:15:33.681325 12219 solver.cpp:353] Iteration 165900 (7.15681 iter/s, 13.9727s/100 iter), loss = 1.66273
I0801 22:15:33.681355 12219 solver.cpp:375]     Train net output #0: loss = 1.38186 (* 1 = 1.38186 loss)
I0801 22:15:33.681361 12219 sgd_solver.cpp:136] Iteration 165900, lr = 0.0481563, m = 0.9
I0801 22:15:47.561784 12219 solver.cpp:550] Iteration 166000, Testing net (#0)
I0801 22:16:07.370215 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.452764
I0801 22:16:07.370252 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.704646
I0801 22:16:07.370257 12219 solver.cpp:635]     Test net output #2: loss = 2.56593 (* 1 = 2.56593 loss)
I0801 22:16:07.373232 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8109s
I0801 22:16:07.509783 12219 solver.cpp:353] Iteration 166000 (2.95617 iter/s, 33.8275s/100 iter), loss = 1.87881
I0801 22:16:07.509807 12219 solver.cpp:375]     Train net output #0: loss = 1.6953 (* 1 = 1.6953 loss)
I0801 22:16:07.509812 12219 sgd_solver.cpp:136] Iteration 166000, lr = 0.048125, m = 0.9
I0801 22:16:21.556016 12219 solver.cpp:353] Iteration 166100 (7.11954 iter/s, 14.0459s/100 iter), loss = 2.4857
I0801 22:16:21.556080 12219 solver.cpp:375]     Train net output #0: loss = 2.11004 (* 1 = 2.11004 loss)
I0801 22:16:21.556087 12219 sgd_solver.cpp:136] Iteration 166100, lr = 0.0480937, m = 0.9
I0801 22:16:35.760398 12219 solver.cpp:353] Iteration 166200 (7.04027 iter/s, 14.204s/100 iter), loss = 1.92964
I0801 22:16:35.760427 12219 solver.cpp:375]     Train net output #0: loss = 1.95442 (* 1 = 1.95442 loss)
I0801 22:16:35.760433 12219 sgd_solver.cpp:136] Iteration 166200, lr = 0.0480625, m = 0.9
I0801 22:16:49.766397 12219 solver.cpp:353] Iteration 166300 (7.13999 iter/s, 14.0056s/100 iter), loss = 1.8701
I0801 22:16:49.766456 12219 solver.cpp:375]     Train net output #0: loss = 2.15828 (* 1 = 2.15828 loss)
I0801 22:16:49.766469 12219 sgd_solver.cpp:136] Iteration 166300, lr = 0.0480313, m = 0.9
I0801 22:17:03.826845 12219 solver.cpp:353] Iteration 166400 (7.11234 iter/s, 14.0601s/100 iter), loss = 1.92368
I0801 22:17:03.826927 12219 solver.cpp:375]     Train net output #0: loss = 2.08342 (* 1 = 2.08342 loss)
I0801 22:17:03.826934 12219 sgd_solver.cpp:136] Iteration 166400, lr = 0.048, m = 0.9
I0801 22:17:17.784948 12219 solver.cpp:353] Iteration 166500 (7.16449 iter/s, 13.9577s/100 iter), loss = 1.87509
I0801 22:17:17.785018 12219 solver.cpp:375]     Train net output #0: loss = 1.55607 (* 1 = 1.55607 loss)
I0801 22:17:17.785037 12219 sgd_solver.cpp:136] Iteration 166500, lr = 0.0479688, m = 0.9
I0801 22:17:31.746516 12219 solver.cpp:353] Iteration 166600 (7.16272 iter/s, 13.9612s/100 iter), loss = 1.77811
I0801 22:17:31.746567 12219 solver.cpp:375]     Train net output #0: loss = 2.20257 (* 1 = 2.20257 loss)
I0801 22:17:31.746580 12219 sgd_solver.cpp:136] Iteration 166600, lr = 0.0479375, m = 0.9
I0801 22:17:45.763401 12219 solver.cpp:353] Iteration 166700 (7.13445 iter/s, 14.0165s/100 iter), loss = 1.95094
I0801 22:17:45.763463 12219 solver.cpp:375]     Train net output #0: loss = 2.02244 (* 1 = 2.02244 loss)
I0801 22:17:45.763470 12219 sgd_solver.cpp:136] Iteration 166700, lr = 0.0479062, m = 0.9
I0801 22:17:59.720113 12219 solver.cpp:353] Iteration 166800 (7.16521 iter/s, 13.9563s/100 iter), loss = 1.80243
I0801 22:17:59.720142 12219 solver.cpp:375]     Train net output #0: loss = 1.81985 (* 1 = 1.81985 loss)
I0801 22:17:59.720147 12219 sgd_solver.cpp:136] Iteration 166800, lr = 0.047875, m = 0.9
I0801 22:18:13.818591 12219 solver.cpp:353] Iteration 166900 (7.09315 iter/s, 14.0981s/100 iter), loss = 1.68217
I0801 22:18:13.818619 12219 solver.cpp:375]     Train net output #0: loss = 1.58904 (* 1 = 1.58904 loss)
I0801 22:18:13.818624 12219 sgd_solver.cpp:136] Iteration 166900, lr = 0.0478438, m = 0.9
I0801 22:18:27.856503 12219 solver.cpp:353] Iteration 167000 (7.12376 iter/s, 14.0375s/100 iter), loss = 1.86368
I0801 22:18:27.856555 12219 solver.cpp:375]     Train net output #0: loss = 2.0607 (* 1 = 2.0607 loss)
I0801 22:18:27.856560 12219 sgd_solver.cpp:136] Iteration 167000, lr = 0.0478125, m = 0.9
I0801 22:18:41.827848 12219 solver.cpp:353] Iteration 167100 (7.1577 iter/s, 13.971s/100 iter), loss = 2.03554
I0801 22:18:41.827874 12219 solver.cpp:375]     Train net output #0: loss = 1.85535 (* 1 = 1.85535 loss)
I0801 22:18:41.827880 12219 sgd_solver.cpp:136] Iteration 167100, lr = 0.0477813, m = 0.9
I0801 22:18:55.839627 12219 solver.cpp:353] Iteration 167200 (7.13705 iter/s, 14.0114s/100 iter), loss = 2.23507
I0801 22:18:55.839658 12219 solver.cpp:375]     Train net output #0: loss = 2.70384 (* 1 = 2.70384 loss)
I0801 22:18:55.839663 12219 sgd_solver.cpp:136] Iteration 167200, lr = 0.04775, m = 0.9
I0801 22:19:09.748323 12219 solver.cpp:353] Iteration 167300 (7.18994 iter/s, 13.9083s/100 iter), loss = 1.43727
I0801 22:19:09.748407 12219 solver.cpp:375]     Train net output #0: loss = 1.49914 (* 1 = 1.49914 loss)
I0801 22:19:09.748421 12219 sgd_solver.cpp:136] Iteration 167300, lr = 0.0477188, m = 0.9
I0801 22:19:23.802394 12219 solver.cpp:353] Iteration 167400 (7.11557 iter/s, 14.0537s/100 iter), loss = 2.1826
I0801 22:19:23.802419 12219 solver.cpp:375]     Train net output #0: loss = 2.23945 (* 1 = 2.23945 loss)
I0801 22:19:23.802425 12219 sgd_solver.cpp:136] Iteration 167400, lr = 0.0476875, m = 0.9
I0801 22:19:37.783774 12219 solver.cpp:353] Iteration 167500 (7.15256 iter/s, 13.981s/100 iter), loss = 1.94977
I0801 22:19:37.783799 12219 solver.cpp:375]     Train net output #0: loss = 1.66011 (* 1 = 1.66011 loss)
I0801 22:19:37.783803 12219 sgd_solver.cpp:136] Iteration 167500, lr = 0.0476562, m = 0.9
I0801 22:19:51.835809 12219 solver.cpp:353] Iteration 167600 (7.1166 iter/s, 14.0517s/100 iter), loss = 1.8028
I0801 22:19:51.835880 12219 solver.cpp:375]     Train net output #0: loss = 1.8421 (* 1 = 1.8421 loss)
I0801 22:19:51.835887 12219 sgd_solver.cpp:136] Iteration 167600, lr = 0.047625, m = 0.9
I0801 22:20:05.950024 12219 solver.cpp:353] Iteration 167700 (7.08525 iter/s, 14.1138s/100 iter), loss = 1.78446
I0801 22:20:05.950052 12219 solver.cpp:375]     Train net output #0: loss = 1.60534 (* 1 = 1.60534 loss)
I0801 22:20:05.950058 12219 sgd_solver.cpp:136] Iteration 167700, lr = 0.0475938, m = 0.9
I0801 22:20:20.028187 12219 solver.cpp:353] Iteration 167800 (7.10339 iter/s, 14.0778s/100 iter), loss = 1.8834
I0801 22:20:20.028365 12219 solver.cpp:375]     Train net output #0: loss = 1.52015 (* 1 = 1.52015 loss)
I0801 22:20:20.028385 12219 sgd_solver.cpp:136] Iteration 167800, lr = 0.0475625, m = 0.9
I0801 22:20:34.127384 12219 solver.cpp:353] Iteration 167900 (7.09279 iter/s, 14.0988s/100 iter), loss = 1.81162
I0801 22:20:34.127463 12219 solver.cpp:375]     Train net output #0: loss = 1.79094 (* 1 = 1.79094 loss)
I0801 22:20:34.127471 12219 sgd_solver.cpp:136] Iteration 167900, lr = 0.0475312, m = 0.9
I0801 22:20:47.920719 12219 solver.cpp:550] Iteration 168000, Testing net (#0)
I0801 22:21:07.758260 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.436588
I0801 22:21:07.758324 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.696175
I0801 22:21:07.758332 12219 solver.cpp:635]     Test net output #2: loss = 2.56293 (* 1 = 2.56293 loss)
I0801 22:21:07.758349 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8371s
I0801 22:21:07.898594 12219 solver.cpp:353] Iteration 168000 (2.96118 iter/s, 33.7703s/100 iter), loss = 2.30845
I0801 22:21:07.898619 12219 solver.cpp:375]     Train net output #0: loss = 2.73537 (* 1 = 2.73537 loss)
I0801 22:21:07.898623 12219 sgd_solver.cpp:136] Iteration 168000, lr = 0.0475, m = 0.9
I0801 22:21:21.907325 12219 solver.cpp:353] Iteration 168100 (7.13861 iter/s, 14.0083s/100 iter), loss = 1.92146
I0801 22:21:21.907371 12219 solver.cpp:375]     Train net output #0: loss = 1.97444 (* 1 = 1.97444 loss)
I0801 22:21:21.907382 12219 sgd_solver.cpp:136] Iteration 168100, lr = 0.0474688, m = 0.9
I0801 22:21:35.862562 12219 solver.cpp:353] Iteration 168200 (7.16597 iter/s, 13.9549s/100 iter), loss = 1.58573
I0801 22:21:35.862598 12219 solver.cpp:375]     Train net output #0: loss = 1.69731 (* 1 = 1.69731 loss)
I0801 22:21:35.862603 12219 sgd_solver.cpp:136] Iteration 168200, lr = 0.0474375, m = 0.9
I0801 22:21:49.861644 12219 solver.cpp:353] Iteration 168300 (7.14352 iter/s, 13.9987s/100 iter), loss = 1.90383
I0801 22:21:49.861698 12219 solver.cpp:375]     Train net output #0: loss = 1.69303 (* 1 = 1.69303 loss)
I0801 22:21:49.861706 12219 sgd_solver.cpp:136] Iteration 168300, lr = 0.0474063, m = 0.9
I0801 22:22:03.755530 12219 solver.cpp:353] Iteration 168400 (7.19761 iter/s, 13.8935s/100 iter), loss = 1.73006
I0801 22:22:03.755555 12219 solver.cpp:375]     Train net output #0: loss = 1.84665 (* 1 = 1.84665 loss)
I0801 22:22:03.755560 12219 sgd_solver.cpp:136] Iteration 168400, lr = 0.047375, m = 0.9
I0801 22:22:17.728626 12219 solver.cpp:353] Iteration 168500 (7.15681 iter/s, 13.9727s/100 iter), loss = 1.56715
I0801 22:22:17.728655 12219 solver.cpp:375]     Train net output #0: loss = 1.81661 (* 1 = 1.81661 loss)
I0801 22:22:17.728662 12219 sgd_solver.cpp:136] Iteration 168500, lr = 0.0473437, m = 0.9
I0801 22:22:31.761955 12219 solver.cpp:353] Iteration 168600 (7.12609 iter/s, 14.0329s/100 iter), loss = 1.89511
I0801 22:22:31.762012 12219 solver.cpp:375]     Train net output #0: loss = 2.03272 (* 1 = 2.03272 loss)
I0801 22:22:31.762018 12219 sgd_solver.cpp:136] Iteration 168600, lr = 0.0473125, m = 0.9
I0801 22:22:45.858291 12219 solver.cpp:353] Iteration 168700 (7.09423 iter/s, 14.096s/100 iter), loss = 1.91796
I0801 22:22:45.858315 12219 solver.cpp:375]     Train net output #0: loss = 1.82006 (* 1 = 1.82006 loss)
I0801 22:22:45.858319 12219 sgd_solver.cpp:136] Iteration 168700, lr = 0.0472812, m = 0.9
I0801 22:22:59.892849 12219 solver.cpp:353] Iteration 168800 (7.12546 iter/s, 14.0342s/100 iter), loss = 1.83688
I0801 22:22:59.892913 12219 solver.cpp:375]     Train net output #0: loss = 1.99089 (* 1 = 1.99089 loss)
I0801 22:22:59.892940 12219 sgd_solver.cpp:136] Iteration 168800, lr = 0.04725, m = 0.9
I0801 22:23:13.789695 12219 solver.cpp:353] Iteration 168900 (7.19607 iter/s, 13.8965s/100 iter), loss = 2.02009
I0801 22:23:13.789767 12219 solver.cpp:375]     Train net output #0: loss = 2.06932 (* 1 = 2.06932 loss)
I0801 22:23:13.789772 12219 sgd_solver.cpp:136] Iteration 168900, lr = 0.0472188, m = 0.9
I0801 22:23:27.727887 12219 solver.cpp:353] Iteration 169000 (7.17473 iter/s, 13.9378s/100 iter), loss = 1.64222
I0801 22:23:27.727915 12219 solver.cpp:375]     Train net output #0: loss = 1.78157 (* 1 = 1.78157 loss)
I0801 22:23:27.727918 12219 sgd_solver.cpp:136] Iteration 169000, lr = 0.0471875, m = 0.9
I0801 22:23:41.746632 12219 solver.cpp:353] Iteration 169100 (7.1335 iter/s, 14.0184s/100 iter), loss = 2.00387
I0801 22:23:41.746724 12219 solver.cpp:375]     Train net output #0: loss = 2.55899 (* 1 = 2.55899 loss)
I0801 22:23:41.746744 12219 sgd_solver.cpp:136] Iteration 169100, lr = 0.0471563, m = 0.9
I0801 22:23:55.650208 12219 solver.cpp:353] Iteration 169200 (7.19259 iter/s, 13.9032s/100 iter), loss = 1.75896
I0801 22:23:55.650265 12219 solver.cpp:375]     Train net output #0: loss = 1.61267 (* 1 = 1.61267 loss)
I0801 22:23:55.650272 12219 sgd_solver.cpp:136] Iteration 169200, lr = 0.047125, m = 0.9
I0801 22:24:09.617132 12219 solver.cpp:353] Iteration 169300 (7.15997 iter/s, 13.9665s/100 iter), loss = 1.94702
I0801 22:24:09.617159 12219 solver.cpp:375]     Train net output #0: loss = 1.95756 (* 1 = 1.95756 loss)
I0801 22:24:09.617166 12219 sgd_solver.cpp:136] Iteration 169300, lr = 0.0470937, m = 0.9
I0801 22:24:23.574014 12219 solver.cpp:353] Iteration 169400 (7.16512 iter/s, 13.9565s/100 iter), loss = 2.02576
I0801 22:24:23.574044 12219 solver.cpp:375]     Train net output #0: loss = 1.47958 (* 1 = 1.47958 loss)
I0801 22:24:23.574050 12219 sgd_solver.cpp:136] Iteration 169400, lr = 0.0470625, m = 0.9
I0801 22:24:37.561661 12219 solver.cpp:353] Iteration 169500 (7.14936 iter/s, 13.9873s/100 iter), loss = 1.65124
I0801 22:24:37.561740 12219 solver.cpp:375]     Train net output #0: loss = 1.65351 (* 1 = 1.65351 loss)
I0801 22:24:37.561748 12219 sgd_solver.cpp:136] Iteration 169500, lr = 0.0470312, m = 0.9
I0801 22:24:51.488695 12219 solver.cpp:353] Iteration 169600 (7.18047 iter/s, 13.9267s/100 iter), loss = 2.23975
I0801 22:24:51.488724 12219 solver.cpp:375]     Train net output #0: loss = 1.52561 (* 1 = 1.52561 loss)
I0801 22:24:51.488730 12219 sgd_solver.cpp:136] Iteration 169600, lr = 0.047, m = 0.9
I0801 22:25:05.502542 12219 solver.cpp:353] Iteration 169700 (7.13599 iter/s, 14.0135s/100 iter), loss = 1.57085
I0801 22:25:05.502570 12219 solver.cpp:375]     Train net output #0: loss = 1.50786 (* 1 = 1.50786 loss)
I0801 22:25:05.502574 12219 sgd_solver.cpp:136] Iteration 169700, lr = 0.0469688, m = 0.9
I0801 22:25:19.451393 12219 solver.cpp:353] Iteration 169800 (7.16924 iter/s, 13.9485s/100 iter), loss = 1.73418
I0801 22:25:19.451459 12219 solver.cpp:375]     Train net output #0: loss = 2.13112 (* 1 = 2.13112 loss)
I0801 22:25:19.451465 12219 sgd_solver.cpp:136] Iteration 169800, lr = 0.0469375, m = 0.9
I0801 22:25:33.431926 12219 solver.cpp:353] Iteration 169900 (7.153 iter/s, 13.9802s/100 iter), loss = 2.08485
I0801 22:25:33.431954 12219 solver.cpp:375]     Train net output #0: loss = 1.90044 (* 1 = 1.90044 loss)
I0801 22:25:33.431960 12219 sgd_solver.cpp:136] Iteration 169900, lr = 0.0469063, m = 0.9
I0801 22:25:47.349201 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_170000.caffemodel
I0801 22:25:47.466410 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_170000.solverstate
I0801 22:25:47.470865 12219 solver.cpp:550] Iteration 170000, Testing net (#0)
I0801 22:26:07.596118 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.434352
I0801 22:26:07.596247 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.696763
I0801 22:26:07.596257 12219 solver.cpp:635]     Test net output #2: loss = 2.61026 (* 1 = 2.61026 loss)
I0801 22:26:07.596283 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1249s
I0801 22:26:07.748512 12219 solver.cpp:353] Iteration 170000 (2.91412 iter/s, 34.3157s/100 iter), loss = 1.85396
I0801 22:26:07.748539 12219 solver.cpp:375]     Train net output #0: loss = 1.95808 (* 1 = 1.95808 loss)
I0801 22:26:07.748545 12219 sgd_solver.cpp:136] Iteration 170000, lr = 0.046875, m = 0.9
I0801 22:26:21.809720 12219 solver.cpp:353] Iteration 170100 (7.11196 iter/s, 14.0608s/100 iter), loss = 1.78093
I0801 22:26:21.809752 12219 solver.cpp:375]     Train net output #0: loss = 2.09521 (* 1 = 2.09521 loss)
I0801 22:26:21.809757 12219 sgd_solver.cpp:136] Iteration 170100, lr = 0.0468437, m = 0.9
I0801 22:26:35.874572 12219 solver.cpp:353] Iteration 170200 (7.11012 iter/s, 14.0645s/100 iter), loss = 1.78935
I0801 22:26:35.874598 12219 solver.cpp:375]     Train net output #0: loss = 1.88111 (* 1 = 1.88111 loss)
I0801 22:26:35.874603 12219 sgd_solver.cpp:136] Iteration 170200, lr = 0.0468125, m = 0.9
I0801 22:26:49.985218 12219 solver.cpp:353] Iteration 170300 (7.08704 iter/s, 14.1103s/100 iter), loss = 1.63823
I0801 22:26:49.985280 12219 solver.cpp:375]     Train net output #0: loss = 1.67994 (* 1 = 1.67994 loss)
I0801 22:26:49.985285 12219 sgd_solver.cpp:136] Iteration 170300, lr = 0.0467812, m = 0.9
I0801 22:27:04.065696 12219 solver.cpp:353] Iteration 170400 (7.10222 iter/s, 14.0801s/100 iter), loss = 1.83344
I0801 22:27:04.065788 12219 solver.cpp:375]     Train net output #0: loss = 1.82842 (* 1 = 1.82842 loss)
I0801 22:27:04.065806 12219 sgd_solver.cpp:136] Iteration 170400, lr = 0.04675, m = 0.9
I0801 22:27:18.169373 12219 solver.cpp:353] Iteration 170500 (7.09055 iter/s, 14.1033s/100 iter), loss = 1.61062
I0801 22:27:18.169404 12219 solver.cpp:375]     Train net output #0: loss = 1.56586 (* 1 = 1.56586 loss)
I0801 22:27:18.169409 12219 sgd_solver.cpp:136] Iteration 170500, lr = 0.0467188, m = 0.9
I0801 22:27:32.338327 12219 solver.cpp:353] Iteration 170600 (7.05788 iter/s, 14.1686s/100 iter), loss = 1.92429
I0801 22:27:32.338394 12219 solver.cpp:375]     Train net output #0: loss = 1.4903 (* 1 = 1.4903 loss)
I0801 22:27:32.338402 12219 sgd_solver.cpp:136] Iteration 170600, lr = 0.0466875, m = 0.9
I0801 22:27:38.258949 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 22:27:46.363654 12219 solver.cpp:353] Iteration 170700 (7.13015 iter/s, 14.0249s/100 iter), loss = 1.99146
I0801 22:27:46.363680 12219 solver.cpp:375]     Train net output #0: loss = 1.97946 (* 1 = 1.97946 loss)
I0801 22:27:46.363687 12219 sgd_solver.cpp:136] Iteration 170700, lr = 0.0466563, m = 0.9
I0801 22:28:00.354681 12219 solver.cpp:353] Iteration 170800 (7.14764 iter/s, 13.9906s/100 iter), loss = 1.79071
I0801 22:28:00.354719 12219 solver.cpp:375]     Train net output #0: loss = 1.69226 (* 1 = 1.69226 loss)
I0801 22:28:00.354725 12219 sgd_solver.cpp:136] Iteration 170800, lr = 0.046625, m = 0.9
I0801 22:28:14.452754 12219 solver.cpp:353] Iteration 170900 (7.09336 iter/s, 14.0977s/100 iter), loss = 1.88232
I0801 22:28:14.452823 12219 solver.cpp:375]     Train net output #0: loss = 2.28038 (* 1 = 2.28038 loss)
I0801 22:28:14.452831 12219 sgd_solver.cpp:136] Iteration 170900, lr = 0.0465938, m = 0.9
I0801 22:28:28.405280 12219 solver.cpp:353] Iteration 171000 (7.16736 iter/s, 13.9521s/100 iter), loss = 2.11123
I0801 22:28:28.405304 12219 solver.cpp:375]     Train net output #0: loss = 2.2722 (* 1 = 2.2722 loss)
I0801 22:28:28.405308 12219 sgd_solver.cpp:136] Iteration 171000, lr = 0.0465625, m = 0.9
I0801 22:28:42.599540 12219 solver.cpp:353] Iteration 171100 (7.04529 iter/s, 14.1939s/100 iter), loss = 2.2133
I0801 22:28:42.599566 12219 solver.cpp:375]     Train net output #0: loss = 1.90443 (* 1 = 1.90443 loss)
I0801 22:28:42.599570 12219 sgd_solver.cpp:136] Iteration 171100, lr = 0.0465312, m = 0.9
I0801 22:28:56.625758 12219 solver.cpp:353] Iteration 171200 (7.1297 iter/s, 14.0258s/100 iter), loss = 1.79242
I0801 22:28:56.625824 12219 solver.cpp:375]     Train net output #0: loss = 1.66341 (* 1 = 1.66341 loss)
I0801 22:28:56.625831 12219 sgd_solver.cpp:136] Iteration 171200, lr = 0.0465, m = 0.9
I0801 22:29:10.729766 12219 solver.cpp:353] Iteration 171300 (7.09038 iter/s, 14.1036s/100 iter), loss = 1.57453
I0801 22:29:10.729862 12219 solver.cpp:375]     Train net output #0: loss = 1.10195 (* 1 = 1.10195 loss)
I0801 22:29:10.729881 12219 sgd_solver.cpp:136] Iteration 171300, lr = 0.0464688, m = 0.9
I0801 22:29:24.766530 12219 solver.cpp:353] Iteration 171400 (7.12434 iter/s, 14.0364s/100 iter), loss = 2.12239
I0801 22:29:24.766559 12219 solver.cpp:375]     Train net output #0: loss = 1.93233 (* 1 = 1.93233 loss)
I0801 22:29:24.766566 12219 sgd_solver.cpp:136] Iteration 171400, lr = 0.0464375, m = 0.9
I0801 22:29:38.878386 12219 solver.cpp:353] Iteration 171500 (7.08643 iter/s, 14.1115s/100 iter), loss = 2.04287
I0801 22:29:38.878509 12219 solver.cpp:375]     Train net output #0: loss = 1.99188 (* 1 = 1.99188 loss)
I0801 22:29:38.878527 12219 sgd_solver.cpp:136] Iteration 171500, lr = 0.0464063, m = 0.9
I0801 22:29:52.964570 12219 solver.cpp:353] Iteration 171600 (7.09935 iter/s, 14.0858s/100 iter), loss = 1.95987
I0801 22:29:52.964598 12219 solver.cpp:375]     Train net output #0: loss = 2.13192 (* 1 = 2.13192 loss)
I0801 22:29:52.964604 12219 sgd_solver.cpp:136] Iteration 171600, lr = 0.046375, m = 0.9
I0801 22:30:06.954401 12219 solver.cpp:353] Iteration 171700 (7.14824 iter/s, 13.9895s/100 iter), loss = 1.87333
I0801 22:30:06.954457 12219 solver.cpp:375]     Train net output #0: loss = 2.00855 (* 1 = 2.00855 loss)
I0801 22:30:06.954468 12219 sgd_solver.cpp:136] Iteration 171700, lr = 0.0463438, m = 0.9
I0801 22:30:20.995601 12219 solver.cpp:353] Iteration 171800 (7.12209 iter/s, 14.0408s/100 iter), loss = 1.92223
I0801 22:30:20.995682 12219 solver.cpp:375]     Train net output #0: loss = 2.36005 (* 1 = 2.36005 loss)
I0801 22:30:20.995689 12219 sgd_solver.cpp:136] Iteration 171800, lr = 0.0463125, m = 0.9
I0801 22:30:35.183892 12219 solver.cpp:353] Iteration 171900 (7.04826 iter/s, 14.1879s/100 iter), loss = 1.89905
I0801 22:30:35.183919 12219 solver.cpp:375]     Train net output #0: loss = 2.19371 (* 1 = 2.19371 loss)
I0801 22:30:35.183926 12219 sgd_solver.cpp:136] Iteration 171900, lr = 0.0462812, m = 0.9
I0801 22:30:49.148232 12219 solver.cpp:550] Iteration 172000, Testing net (#0)
I0801 22:30:54.926065 12207 data_reader.cpp:264] Starting prefetch of epoch 9
I0801 22:31:09.526331 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.469294
I0801 22:31:09.526355 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.72741
I0801 22:31:09.526360 12219 solver.cpp:635]     Test net output #2: loss = 2.38183 (* 1 = 2.38183 loss)
I0801 22:31:09.528874 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3801s
I0801 22:31:09.666530 12219 solver.cpp:353] Iteration 172000 (2.90009 iter/s, 34.4817s/100 iter), loss = 1.99428
I0801 22:31:09.666560 12219 solver.cpp:375]     Train net output #0: loss = 1.96879 (* 1 = 1.96879 loss)
I0801 22:31:09.666568 12219 sgd_solver.cpp:136] Iteration 172000, lr = 0.04625, m = 0.9
I0801 22:31:23.630378 12219 solver.cpp:353] Iteration 172100 (7.16155 iter/s, 13.9635s/100 iter), loss = 1.79751
I0801 22:31:23.630401 12219 solver.cpp:375]     Train net output #0: loss = 2.1148 (* 1 = 2.1148 loss)
I0801 22:31:23.630406 12219 sgd_solver.cpp:136] Iteration 172100, lr = 0.0462188, m = 0.9
I0801 22:31:37.672508 12219 solver.cpp:353] Iteration 172200 (7.12162 iter/s, 14.0417s/100 iter), loss = 1.8198
I0801 22:31:37.672564 12219 solver.cpp:375]     Train net output #0: loss = 1.72779 (* 1 = 1.72779 loss)
I0801 22:31:37.672570 12219 sgd_solver.cpp:136] Iteration 172200, lr = 0.0461875, m = 0.9
I0801 22:31:51.706714 12219 solver.cpp:353] Iteration 172300 (7.12564 iter/s, 14.0338s/100 iter), loss = 2.27554
I0801 22:31:51.706768 12219 solver.cpp:375]     Train net output #0: loss = 2.62881 (* 1 = 2.62881 loss)
I0801 22:31:51.706780 12219 sgd_solver.cpp:136] Iteration 172300, lr = 0.0461563, m = 0.9
I0801 22:32:05.748235 12219 solver.cpp:353] Iteration 172400 (7.12193 iter/s, 14.0411s/100 iter), loss = 2.05528
I0801 22:32:05.748263 12219 solver.cpp:375]     Train net output #0: loss = 1.99416 (* 1 = 1.99416 loss)
I0801 22:32:05.748268 12219 sgd_solver.cpp:136] Iteration 172400, lr = 0.046125, m = 0.9
I0801 22:32:19.805310 12219 solver.cpp:353] Iteration 172500 (7.11405 iter/s, 14.0567s/100 iter), loss = 1.8729
I0801 22:32:19.805384 12219 solver.cpp:375]     Train net output #0: loss = 1.6765 (* 1 = 1.6765 loss)
I0801 22:32:19.805392 12219 sgd_solver.cpp:136] Iteration 172500, lr = 0.0460938, m = 0.9
I0801 22:32:33.854445 12219 solver.cpp:353] Iteration 172600 (7.11807 iter/s, 14.0488s/100 iter), loss = 1.94716
I0801 22:32:33.854470 12219 solver.cpp:375]     Train net output #0: loss = 1.90612 (* 1 = 1.90612 loss)
I0801 22:32:33.854473 12219 sgd_solver.cpp:136] Iteration 172600, lr = 0.0460625, m = 0.9
I0801 22:32:47.889622 12219 solver.cpp:353] Iteration 172700 (7.12515 iter/s, 14.0348s/100 iter), loss = 1.95581
I0801 22:32:47.889653 12219 solver.cpp:375]     Train net output #0: loss = 1.6124 (* 1 = 1.6124 loss)
I0801 22:32:47.889658 12219 sgd_solver.cpp:136] Iteration 172700, lr = 0.0460312, m = 0.9
I0801 22:33:01.997434 12219 solver.cpp:353] Iteration 172800 (7.08847 iter/s, 14.1074s/100 iter), loss = 2.13466
I0801 22:33:01.997545 12219 solver.cpp:375]     Train net output #0: loss = 2.08562 (* 1 = 2.08562 loss)
I0801 22:33:01.997552 12219 sgd_solver.cpp:136] Iteration 172800, lr = 0.046, m = 0.9
I0801 22:33:16.077720 12219 solver.cpp:353] Iteration 172900 (7.10232 iter/s, 14.0799s/100 iter), loss = 2.07534
I0801 22:33:16.077745 12219 solver.cpp:375]     Train net output #0: loss = 1.97164 (* 1 = 1.97164 loss)
I0801 22:33:16.077749 12219 sgd_solver.cpp:136] Iteration 172900, lr = 0.0459687, m = 0.9
I0801 22:33:30.114703 12219 solver.cpp:353] Iteration 173000 (7.12423 iter/s, 14.0366s/100 iter), loss = 1.74506
I0801 22:33:30.114728 12219 solver.cpp:375]     Train net output #0: loss = 1.91279 (* 1 = 1.91279 loss)
I0801 22:33:30.114764 12219 sgd_solver.cpp:136] Iteration 173000, lr = 0.0459375, m = 0.9
I0801 22:33:44.075636 12219 solver.cpp:353] Iteration 173100 (7.16304 iter/s, 13.9606s/100 iter), loss = 1.93961
I0801 22:33:44.075717 12219 solver.cpp:375]     Train net output #0: loss = 2.11004 (* 1 = 2.11004 loss)
I0801 22:33:44.075724 12219 sgd_solver.cpp:136] Iteration 173100, lr = 0.0459063, m = 0.9
I0801 22:33:58.094341 12219 solver.cpp:353] Iteration 173200 (7.13352 iter/s, 14.0183s/100 iter), loss = 2.1562
I0801 22:33:58.094368 12219 solver.cpp:375]     Train net output #0: loss = 2.06801 (* 1 = 2.06801 loss)
I0801 22:33:58.094374 12219 sgd_solver.cpp:136] Iteration 173200, lr = 0.045875, m = 0.9
I0801 22:34:12.233441 12219 solver.cpp:353] Iteration 173300 (7.07278 iter/s, 14.1387s/100 iter), loss = 1.87274
I0801 22:34:12.233467 12219 solver.cpp:375]     Train net output #0: loss = 1.68913 (* 1 = 1.68913 loss)
I0801 22:34:12.233470 12219 sgd_solver.cpp:136] Iteration 173300, lr = 0.0458438, m = 0.9
I0801 22:34:26.256913 12219 solver.cpp:353] Iteration 173400 (7.13109 iter/s, 14.0231s/100 iter), loss = 1.74061
I0801 22:34:26.256973 12219 solver.cpp:375]     Train net output #0: loss = 1.84635 (* 1 = 1.84635 loss)
I0801 22:34:26.256979 12219 sgd_solver.cpp:136] Iteration 173400, lr = 0.0458125, m = 0.9
I0801 22:34:40.400939 12219 solver.cpp:353] Iteration 173500 (7.07031 iter/s, 14.1436s/100 iter), loss = 1.932
I0801 22:34:40.400967 12219 solver.cpp:375]     Train net output #0: loss = 2.05986 (* 1 = 2.05986 loss)
I0801 22:34:40.400974 12219 sgd_solver.cpp:136] Iteration 173500, lr = 0.0457813, m = 0.9
I0801 22:34:54.283452 12219 solver.cpp:353] Iteration 173600 (7.2035 iter/s, 13.8821s/100 iter), loss = 1.64362
I0801 22:34:54.283476 12219 solver.cpp:375]     Train net output #0: loss = 1.82908 (* 1 = 1.82908 loss)
I0801 22:34:54.283483 12219 sgd_solver.cpp:136] Iteration 173600, lr = 0.04575, m = 0.9
I0801 22:35:08.290489 12219 solver.cpp:353] Iteration 173700 (7.13946 iter/s, 14.0067s/100 iter), loss = 1.64577
I0801 22:35:08.290573 12219 solver.cpp:375]     Train net output #0: loss = 1.4792 (* 1 = 1.4792 loss)
I0801 22:35:08.290582 12219 sgd_solver.cpp:136] Iteration 173700, lr = 0.0457187, m = 0.9
I0801 22:35:22.316058 12219 solver.cpp:353] Iteration 173800 (7.13003 iter/s, 14.0252s/100 iter), loss = 1.54325
I0801 22:35:22.316084 12219 solver.cpp:375]     Train net output #0: loss = 1.65616 (* 1 = 1.65616 loss)
I0801 22:35:22.316090 12219 sgd_solver.cpp:136] Iteration 173800, lr = 0.0456875, m = 0.9
I0801 22:35:36.290735 12219 solver.cpp:353] Iteration 173900 (7.156 iter/s, 13.9743s/100 iter), loss = 1.89357
I0801 22:35:36.290763 12219 solver.cpp:375]     Train net output #0: loss = 2.24301 (* 1 = 2.24301 loss)
I0801 22:35:36.290832 12219 sgd_solver.cpp:136] Iteration 173900, lr = 0.0456563, m = 0.9
I0801 22:35:50.123661 12219 solver.cpp:550] Iteration 174000, Testing net (#0)
I0801 22:36:09.645560 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.478471
I0801 22:36:09.645583 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.729234
I0801 22:36:09.645591 12219 solver.cpp:635]     Test net output #2: loss = 2.34108 (* 1 = 2.34108 loss)
I0801 22:36:09.645612 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.5214s
I0801 22:36:09.789054 12219 solver.cpp:353] Iteration 174000 (2.9853 iter/s, 33.4974s/100 iter), loss = 1.8849
I0801 22:36:09.789104 12219 solver.cpp:375]     Train net output #0: loss = 1.78227 (* 1 = 1.78227 loss)
I0801 22:36:09.789116 12219 sgd_solver.cpp:136] Iteration 174000, lr = 0.045625, m = 0.9
I0801 22:36:23.736954 12219 solver.cpp:353] Iteration 174100 (7.16974 iter/s, 13.9475s/100 iter), loss = 2.5909
I0801 22:36:23.737056 12219 solver.cpp:375]     Train net output #0: loss = 2.33594 (* 1 = 2.33594 loss)
I0801 22:36:23.737063 12219 sgd_solver.cpp:136] Iteration 174100, lr = 0.0455937, m = 0.9
I0801 22:36:37.768208 12219 solver.cpp:353] Iteration 174200 (7.12714 iter/s, 14.0309s/100 iter), loss = 2.05035
I0801 22:36:37.768235 12219 solver.cpp:375]     Train net output #0: loss = 1.82756 (* 1 = 1.82756 loss)
I0801 22:36:37.768239 12219 sgd_solver.cpp:136] Iteration 174200, lr = 0.0455625, m = 0.9
I0801 22:36:51.870967 12219 solver.cpp:353] Iteration 174300 (7.091 iter/s, 14.1024s/100 iter), loss = 1.92487
I0801 22:36:51.870995 12219 solver.cpp:375]     Train net output #0: loss = 1.71929 (* 1 = 1.71929 loss)
I0801 22:36:51.871002 12219 sgd_solver.cpp:136] Iteration 174300, lr = 0.0455313, m = 0.9
I0801 22:37:05.814141 12219 solver.cpp:353] Iteration 174400 (7.17217 iter/s, 13.9428s/100 iter), loss = 1.95744
I0801 22:37:05.814211 12219 solver.cpp:375]     Train net output #0: loss = 2.297 (* 1 = 2.297 loss)
I0801 22:37:05.814218 12219 sgd_solver.cpp:136] Iteration 174400, lr = 0.0455, m = 0.9
I0801 22:37:19.813086 12219 solver.cpp:353] Iteration 174500 (7.14359 iter/s, 13.9986s/100 iter), loss = 1.91047
I0801 22:37:19.813113 12219 solver.cpp:375]     Train net output #0: loss = 1.94837 (* 1 = 1.94837 loss)
I0801 22:37:19.813119 12219 sgd_solver.cpp:136] Iteration 174500, lr = 0.0454687, m = 0.9
I0801 22:37:33.865166 12219 solver.cpp:353] Iteration 174600 (7.11658 iter/s, 14.0517s/100 iter), loss = 1.88058
I0801 22:37:33.865195 12219 solver.cpp:375]     Train net output #0: loss = 1.94035 (* 1 = 1.94035 loss)
I0801 22:37:33.865201 12219 sgd_solver.cpp:136] Iteration 174600, lr = 0.0454375, m = 0.9
I0801 22:37:47.858672 12219 solver.cpp:353] Iteration 174700 (7.14637 iter/s, 13.9931s/100 iter), loss = 1.81944
I0801 22:37:47.858790 12219 solver.cpp:375]     Train net output #0: loss = 1.63413 (* 1 = 1.63413 loss)
I0801 22:37:47.858803 12219 sgd_solver.cpp:136] Iteration 174700, lr = 0.0454063, m = 0.9
I0801 22:38:01.849067 12219 solver.cpp:353] Iteration 174800 (7.14795 iter/s, 13.99s/100 iter), loss = 1.97743
I0801 22:38:01.849093 12219 solver.cpp:375]     Train net output #0: loss = 1.76512 (* 1 = 1.76512 loss)
I0801 22:38:01.849236 12219 sgd_solver.cpp:136] Iteration 174800, lr = 0.045375, m = 0.9
I0801 22:38:15.745234 12219 solver.cpp:353] Iteration 174900 (7.19642 iter/s, 13.8958s/100 iter), loss = 1.46621
I0801 22:38:15.745259 12219 solver.cpp:375]     Train net output #0: loss = 1.02572 (* 1 = 1.02572 loss)
I0801 22:38:15.745262 12219 sgd_solver.cpp:136] Iteration 174900, lr = 0.0453438, m = 0.9
I0801 22:38:29.637450 12219 solver.cpp:353] Iteration 175000 (7.19847 iter/s, 13.8918s/100 iter), loss = 1.54827
I0801 22:38:29.637531 12219 solver.cpp:375]     Train net output #0: loss = 1.10954 (* 1 = 1.10954 loss)
I0801 22:38:29.637537 12219 sgd_solver.cpp:136] Iteration 175000, lr = 0.0453125, m = 0.9
I0801 22:38:43.589179 12219 solver.cpp:353] Iteration 175100 (7.16777 iter/s, 13.9513s/100 iter), loss = 2.07996
I0801 22:38:43.589205 12219 solver.cpp:375]     Train net output #0: loss = 2.30114 (* 1 = 2.30114 loss)
I0801 22:38:43.589211 12219 sgd_solver.cpp:136] Iteration 175100, lr = 0.0452813, m = 0.9
I0801 22:38:57.559666 12219 solver.cpp:353] Iteration 175200 (7.15814 iter/s, 13.9701s/100 iter), loss = 1.77302
I0801 22:38:57.559695 12219 solver.cpp:375]     Train net output #0: loss = 2.06096 (* 1 = 2.06096 loss)
I0801 22:38:57.559701 12219 sgd_solver.cpp:136] Iteration 175200, lr = 0.04525, m = 0.9
I0801 22:39:11.520359 12219 solver.cpp:353] Iteration 175300 (7.16316 iter/s, 13.9603s/100 iter), loss = 2.15103
I0801 22:39:11.520431 12219 solver.cpp:375]     Train net output #0: loss = 2.2051 (* 1 = 2.2051 loss)
I0801 22:39:11.520437 12219 sgd_solver.cpp:136] Iteration 175300, lr = 0.0452187, m = 0.9
I0801 22:39:25.417270 12219 solver.cpp:353] Iteration 175400 (7.19604 iter/s, 13.8965s/100 iter), loss = 1.87762
I0801 22:39:25.417301 12219 solver.cpp:375]     Train net output #0: loss = 1.5528 (* 1 = 1.5528 loss)
I0801 22:39:25.417307 12219 sgd_solver.cpp:136] Iteration 175400, lr = 0.0451875, m = 0.9
I0801 22:39:39.252027 12219 solver.cpp:353] Iteration 175500 (7.22837 iter/s, 13.8344s/100 iter), loss = 1.47908
I0801 22:39:39.252056 12219 solver.cpp:375]     Train net output #0: loss = 1.37865 (* 1 = 1.37865 loss)
I0801 22:39:39.252063 12219 sgd_solver.cpp:136] Iteration 175500, lr = 0.0451563, m = 0.9
I0801 22:39:53.197841 12219 solver.cpp:353] Iteration 175600 (7.1708 iter/s, 13.9454s/100 iter), loss = 1.89615
I0801 22:39:53.197903 12219 solver.cpp:375]     Train net output #0: loss = 2.07335 (* 1 = 2.07335 loss)
I0801 22:39:53.197911 12219 sgd_solver.cpp:136] Iteration 175600, lr = 0.045125, m = 0.9
I0801 22:40:07.168030 12219 solver.cpp:353] Iteration 175700 (7.1583 iter/s, 13.9698s/100 iter), loss = 1.99231
I0801 22:40:07.168059 12219 solver.cpp:375]     Train net output #0: loss = 2.08909 (* 1 = 2.08909 loss)
I0801 22:40:07.168066 12219 sgd_solver.cpp:136] Iteration 175700, lr = 0.0450938, m = 0.9
I0801 22:40:21.200681 12219 solver.cpp:353] Iteration 175800 (7.12643 iter/s, 14.0323s/100 iter), loss = 1.88392
I0801 22:40:21.200704 12219 solver.cpp:375]     Train net output #0: loss = 1.88343 (* 1 = 1.88343 loss)
I0801 22:40:21.200708 12219 sgd_solver.cpp:136] Iteration 175800, lr = 0.0450625, m = 0.9
I0801 22:40:35.328322 12219 solver.cpp:353] Iteration 175900 (7.07852 iter/s, 14.1272s/100 iter), loss = 2.07395
I0801 22:40:35.328407 12219 solver.cpp:375]     Train net output #0: loss = 2.33074 (* 1 = 2.33074 loss)
I0801 22:40:35.328413 12219 sgd_solver.cpp:136] Iteration 175900, lr = 0.0450312, m = 0.9
I0801 22:40:49.162376 12219 solver.cpp:550] Iteration 176000, Testing net (#0)
I0801 22:41:09.463060 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.453941
I0801 22:41:09.463110 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.708351
I0801 22:41:09.463117 12219 solver.cpp:635]     Test net output #2: loss = 2.48783 (* 1 = 2.48783 loss)
I0801 22:41:09.463138 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3002s
I0801 22:41:09.606045 12219 solver.cpp:353] Iteration 176000 (2.91743 iter/s, 34.2768s/100 iter), loss = 1.77631
I0801 22:41:09.606073 12219 solver.cpp:375]     Train net output #0: loss = 1.7477 (* 1 = 1.7477 loss)
I0801 22:41:09.606079 12219 sgd_solver.cpp:136] Iteration 176000, lr = 0.045, m = 0.9
I0801 22:41:23.792716 12219 solver.cpp:353] Iteration 176100 (7.04906 iter/s, 14.1863s/100 iter), loss = 1.85886
I0801 22:41:23.792742 12219 solver.cpp:375]     Train net output #0: loss = 1.72469 (* 1 = 1.72469 loss)
I0801 22:41:23.792747 12219 sgd_solver.cpp:136] Iteration 176100, lr = 0.0449688, m = 0.9
I0801 22:41:37.900480 12219 solver.cpp:353] Iteration 176200 (7.08849 iter/s, 14.1074s/100 iter), loss = 2.00727
I0801 22:41:37.900511 12219 solver.cpp:375]     Train net output #0: loss = 2.06297 (* 1 = 2.06297 loss)
I0801 22:41:37.900517 12219 sgd_solver.cpp:136] Iteration 176200, lr = 0.0449375, m = 0.9
I0801 22:41:51.851588 12219 solver.cpp:353] Iteration 176300 (7.16808 iter/s, 13.9507s/100 iter), loss = 1.9625
I0801 22:41:51.851661 12219 solver.cpp:375]     Train net output #0: loss = 2.09816 (* 1 = 2.09816 loss)
I0801 22:41:51.851670 12219 sgd_solver.cpp:136] Iteration 176300, lr = 0.0449063, m = 0.9
I0801 22:42:05.857231 12219 solver.cpp:353] Iteration 176400 (7.14017 iter/s, 14.0053s/100 iter), loss = 2.03504
I0801 22:42:05.857256 12219 solver.cpp:375]     Train net output #0: loss = 2.04245 (* 1 = 2.04245 loss)
I0801 22:42:05.857260 12219 sgd_solver.cpp:136] Iteration 176400, lr = 0.044875, m = 0.9
I0801 22:42:19.932838 12219 solver.cpp:353] Iteration 176500 (7.10468 iter/s, 14.0752s/100 iter), loss = 1.84219
I0801 22:42:19.932865 12219 solver.cpp:375]     Train net output #0: loss = 2.17667 (* 1 = 2.17667 loss)
I0801 22:42:19.932869 12219 sgd_solver.cpp:136] Iteration 176500, lr = 0.0448438, m = 0.9
I0801 22:42:33.968575 12219 solver.cpp:353] Iteration 176600 (7.12487 iter/s, 14.0354s/100 iter), loss = 2.11342
I0801 22:42:33.968657 12219 solver.cpp:375]     Train net output #0: loss = 2.54496 (* 1 = 2.54496 loss)
I0801 22:42:33.968664 12219 sgd_solver.cpp:136] Iteration 176600, lr = 0.0448125, m = 0.9
I0801 22:42:47.969480 12219 solver.cpp:353] Iteration 176700 (7.14259 iter/s, 14.0005s/100 iter), loss = 1.9341
I0801 22:42:47.969550 12219 solver.cpp:375]     Train net output #0: loss = 1.73533 (* 1 = 1.73533 loss)
I0801 22:42:47.969568 12219 sgd_solver.cpp:136] Iteration 176700, lr = 0.0447812, m = 0.9
I0801 22:43:02.045410 12219 solver.cpp:353] Iteration 176800 (7.10452 iter/s, 14.0755s/100 iter), loss = 1.95145
I0801 22:43:02.045436 12219 solver.cpp:375]     Train net output #0: loss = 1.99662 (* 1 = 1.99662 loss)
I0801 22:43:02.045442 12219 sgd_solver.cpp:136] Iteration 176800, lr = 0.04475, m = 0.9
I0801 22:43:16.195948 12219 solver.cpp:353] Iteration 176900 (7.06706 iter/s, 14.1502s/100 iter), loss = 1.7349
I0801 22:43:16.196048 12219 solver.cpp:375]     Train net output #0: loss = 1.88374 (* 1 = 1.88374 loss)
I0801 22:43:16.196069 12219 sgd_solver.cpp:136] Iteration 176900, lr = 0.0447187, m = 0.9
I0801 22:43:30.383318 12219 solver.cpp:353] Iteration 177000 (7.04871 iter/s, 14.187s/100 iter), loss = 2.04399
I0801 22:43:30.383347 12219 solver.cpp:375]     Train net output #0: loss = 2.33557 (* 1 = 2.33557 loss)
I0801 22:43:30.383352 12219 sgd_solver.cpp:136] Iteration 177000, lr = 0.0446875, m = 0.9
I0801 22:43:44.539742 12219 solver.cpp:353] Iteration 177100 (7.06412 iter/s, 14.156s/100 iter), loss = 1.78357
I0801 22:43:44.539770 12219 solver.cpp:375]     Train net output #0: loss = 2.04433 (* 1 = 2.04433 loss)
I0801 22:43:44.539777 12219 sgd_solver.cpp:136] Iteration 177100, lr = 0.0446563, m = 0.9
I0801 22:43:58.630441 12219 solver.cpp:353] Iteration 177200 (7.09707 iter/s, 14.0903s/100 iter), loss = 1.64704
I0801 22:43:58.630555 12219 solver.cpp:375]     Train net output #0: loss = 2.03241 (* 1 = 2.03241 loss)
I0801 22:43:58.630576 12219 sgd_solver.cpp:136] Iteration 177200, lr = 0.044625, m = 0.9
I0801 22:44:12.695322 12219 solver.cpp:353] Iteration 177300 (7.1101 iter/s, 14.0645s/100 iter), loss = 2.00469
I0801 22:44:12.695351 12219 solver.cpp:375]     Train net output #0: loss = 1.79836 (* 1 = 1.79836 loss)
I0801 22:44:12.695355 12219 sgd_solver.cpp:136] Iteration 177300, lr = 0.0445938, m = 0.9
I0801 22:44:26.760735 12219 solver.cpp:353] Iteration 177400 (7.10984 iter/s, 14.065s/100 iter), loss = 1.55901
I0801 22:44:26.760762 12219 solver.cpp:375]     Train net output #0: loss = 1.43677 (* 1 = 1.43677 loss)
I0801 22:44:26.760766 12219 sgd_solver.cpp:136] Iteration 177400, lr = 0.0445625, m = 0.9
I0801 22:44:40.834897 12219 solver.cpp:353] Iteration 177500 (7.10541 iter/s, 14.0738s/100 iter), loss = 1.75882
I0801 22:44:40.835000 12219 solver.cpp:375]     Train net output #0: loss = 2.02279 (* 1 = 2.02279 loss)
I0801 22:44:40.835013 12219 sgd_solver.cpp:136] Iteration 177500, lr = 0.0445313, m = 0.9
I0801 22:44:54.806526 12219 solver.cpp:353] Iteration 177600 (7.15756 iter/s, 13.9713s/100 iter), loss = 1.74202
I0801 22:44:54.806551 12219 solver.cpp:375]     Train net output #0: loss = 1.97382 (* 1 = 1.97382 loss)
I0801 22:44:54.806556 12219 sgd_solver.cpp:136] Iteration 177600, lr = 0.0445, m = 0.9
I0801 22:45:08.846264 12219 solver.cpp:353] Iteration 177700 (7.12283 iter/s, 14.0394s/100 iter), loss = 1.69546
I0801 22:45:08.846288 12219 solver.cpp:375]     Train net output #0: loss = 1.78046 (* 1 = 1.78046 loss)
I0801 22:45:08.846292 12219 sgd_solver.cpp:136] Iteration 177700, lr = 0.0444687, m = 0.9
I0801 22:45:22.951953 12219 solver.cpp:353] Iteration 177800 (7.08953 iter/s, 14.1053s/100 iter), loss = 1.82118
I0801 22:45:22.952008 12219 solver.cpp:375]     Train net output #0: loss = 1.54978 (* 1 = 1.54978 loss)
I0801 22:45:22.952013 12219 sgd_solver.cpp:136] Iteration 177800, lr = 0.0444375, m = 0.9
I0801 22:45:37.038625 12219 solver.cpp:353] Iteration 177900 (7.0991 iter/s, 14.0863s/100 iter), loss = 1.57057
I0801 22:45:37.038696 12219 solver.cpp:375]     Train net output #0: loss = 1.95788 (* 1 = 1.95788 loss)
I0801 22:45:37.038714 12219 sgd_solver.cpp:136] Iteration 177900, lr = 0.0444062, m = 0.9
I0801 22:45:51.108741 12219 solver.cpp:550] Iteration 178000, Testing net (#0)
I0801 22:45:51.855777 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 22:46:11.116832 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.455588
I0801 22:46:11.116880 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.711646
I0801 22:46:11.116886 12219 solver.cpp:635]     Test net output #2: loss = 2.53376 (* 1 = 2.53376 loss)
I0801 22:46:11.116905 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0076s
I0801 22:46:11.268120 12219 solver.cpp:353] Iteration 178000 (2.92154 iter/s, 34.2286s/100 iter), loss = 1.86609
I0801 22:46:11.268146 12219 solver.cpp:375]     Train net output #0: loss = 1.49694 (* 1 = 1.49694 loss)
I0801 22:46:11.268152 12219 sgd_solver.cpp:136] Iteration 178000, lr = 0.044375, m = 0.9
I0801 22:46:25.243154 12219 solver.cpp:353] Iteration 178100 (7.15581 iter/s, 13.9747s/100 iter), loss = 1.60949
I0801 22:46:25.243178 12219 solver.cpp:375]     Train net output #0: loss = 1.69873 (* 1 = 1.69873 loss)
I0801 22:46:25.243185 12219 sgd_solver.cpp:136] Iteration 178100, lr = 0.0443438, m = 0.9
I0801 22:46:39.355037 12219 solver.cpp:353] Iteration 178200 (7.08642 iter/s, 14.1115s/100 iter), loss = 2.40879
I0801 22:46:39.355059 12219 solver.cpp:375]     Train net output #0: loss = 2.82029 (* 1 = 2.82029 loss)
I0801 22:46:39.355065 12219 sgd_solver.cpp:136] Iteration 178200, lr = 0.0443125, m = 0.9
I0801 22:46:53.378701 12219 solver.cpp:353] Iteration 178300 (7.131 iter/s, 14.0233s/100 iter), loss = 2.07707
I0801 22:46:53.378765 12219 solver.cpp:375]     Train net output #0: loss = 2.36718 (* 1 = 2.36718 loss)
I0801 22:46:53.378772 12219 sgd_solver.cpp:136] Iteration 178300, lr = 0.0442813, m = 0.9
I0801 22:47:07.463104 12219 solver.cpp:353] Iteration 178400 (7.10025 iter/s, 14.084s/100 iter), loss = 1.97251
I0801 22:47:07.463132 12219 solver.cpp:375]     Train net output #0: loss = 1.81102 (* 1 = 1.81102 loss)
I0801 22:47:07.463137 12219 sgd_solver.cpp:136] Iteration 178400, lr = 0.04425, m = 0.9
I0801 22:47:21.493268 12219 solver.cpp:353] Iteration 178500 (7.12769 iter/s, 14.0298s/100 iter), loss = 1.42008
I0801 22:47:21.493294 12219 solver.cpp:375]     Train net output #0: loss = 1.44766 (* 1 = 1.44766 loss)
I0801 22:47:21.493299 12219 sgd_solver.cpp:136] Iteration 178500, lr = 0.0442187, m = 0.9
I0801 22:47:35.512956 12219 solver.cpp:353] Iteration 178600 (7.13302 iter/s, 14.0193s/100 iter), loss = 1.70148
I0801 22:47:35.513041 12219 solver.cpp:375]     Train net output #0: loss = 1.8422 (* 1 = 1.8422 loss)
I0801 22:47:35.513048 12219 sgd_solver.cpp:136] Iteration 178600, lr = 0.0441875, m = 0.9
I0801 22:47:49.495985 12219 solver.cpp:353] Iteration 178700 (7.15172 iter/s, 13.9826s/100 iter), loss = 1.9561
I0801 22:47:49.496012 12219 solver.cpp:375]     Train net output #0: loss = 2.09438 (* 1 = 2.09438 loss)
I0801 22:47:49.496018 12219 sgd_solver.cpp:136] Iteration 178700, lr = 0.0441562, m = 0.9
I0801 22:48:03.638072 12219 solver.cpp:353] Iteration 178800 (7.07129 iter/s, 14.1417s/100 iter), loss = 1.63454
I0801 22:48:03.638108 12219 solver.cpp:375]     Train net output #0: loss = 1.62215 (* 1 = 1.62215 loss)
I0801 22:48:03.638114 12219 sgd_solver.cpp:136] Iteration 178800, lr = 0.044125, m = 0.9
I0801 22:48:17.568847 12219 solver.cpp:353] Iteration 178900 (7.17855 iter/s, 13.9304s/100 iter), loss = 1.73919
I0801 22:48:17.568953 12219 solver.cpp:375]     Train net output #0: loss = 1.58536 (* 1 = 1.58536 loss)
I0801 22:48:17.568972 12219 sgd_solver.cpp:136] Iteration 178900, lr = 0.0440938, m = 0.9
I0801 22:48:31.771284 12219 solver.cpp:353] Iteration 179000 (7.04123 iter/s, 14.2021s/100 iter), loss = 1.66821
I0801 22:48:31.771312 12219 solver.cpp:375]     Train net output #0: loss = 1.72555 (* 1 = 1.72555 loss)
I0801 22:48:31.771317 12219 sgd_solver.cpp:136] Iteration 179000, lr = 0.0440625, m = 0.9
I0801 22:48:45.770395 12219 solver.cpp:353] Iteration 179100 (7.14351 iter/s, 13.9987s/100 iter), loss = 2.23678
I0801 22:48:45.770442 12219 solver.cpp:375]     Train net output #0: loss = 2.1746 (* 1 = 2.1746 loss)
I0801 22:48:45.770453 12219 sgd_solver.cpp:136] Iteration 179100, lr = 0.0440313, m = 0.9
I0801 22:48:59.743821 12219 solver.cpp:353] Iteration 179200 (7.15663 iter/s, 13.9731s/100 iter), loss = 1.56704
I0801 22:48:59.743880 12219 solver.cpp:375]     Train net output #0: loss = 1.77275 (* 1 = 1.77275 loss)
I0801 22:48:59.743888 12219 sgd_solver.cpp:136] Iteration 179200, lr = 0.044, m = 0.9
I0801 22:49:13.812264 12219 solver.cpp:353] Iteration 179300 (7.1083 iter/s, 14.0681s/100 iter), loss = 2.01832
I0801 22:49:13.812294 12219 solver.cpp:375]     Train net output #0: loss = 2.53907 (* 1 = 2.53907 loss)
I0801 22:49:13.812299 12219 sgd_solver.cpp:136] Iteration 179300, lr = 0.0439687, m = 0.9
I0801 22:49:27.872426 12219 solver.cpp:353] Iteration 179400 (7.11249 iter/s, 14.0598s/100 iter), loss = 1.99594
I0801 22:49:27.872454 12219 solver.cpp:375]     Train net output #0: loss = 2.17782 (* 1 = 2.17782 loss)
I0801 22:49:27.872462 12219 sgd_solver.cpp:136] Iteration 179400, lr = 0.0439375, m = 0.9
I0801 22:49:41.801026 12219 solver.cpp:353] Iteration 179500 (7.17967 iter/s, 13.9282s/100 iter), loss = 1.83066
I0801 22:49:41.801111 12219 solver.cpp:375]     Train net output #0: loss = 1.66543 (* 1 = 1.66543 loss)
I0801 22:49:41.801118 12219 sgd_solver.cpp:136] Iteration 179500, lr = 0.0439062, m = 0.9
I0801 22:49:55.896625 12219 solver.cpp:353] Iteration 179600 (7.09461 iter/s, 14.0952s/100 iter), loss = 2.06304
I0801 22:49:55.896679 12219 solver.cpp:375]     Train net output #0: loss = 1.93398 (* 1 = 1.93398 loss)
I0801 22:49:55.896692 12219 sgd_solver.cpp:136] Iteration 179600, lr = 0.043875, m = 0.9
I0801 22:50:09.938652 12219 solver.cpp:353] Iteration 179700 (7.12167 iter/s, 14.0416s/100 iter), loss = 2.06878
I0801 22:50:09.938680 12219 solver.cpp:375]     Train net output #0: loss = 1.98718 (* 1 = 1.98718 loss)
I0801 22:50:09.938686 12219 sgd_solver.cpp:136] Iteration 179700, lr = 0.0438438, m = 0.9
I0801 22:50:24.114564 12219 solver.cpp:353] Iteration 179800 (7.05441 iter/s, 14.1755s/100 iter), loss = 1.72996
I0801 22:50:24.114627 12219 solver.cpp:375]     Train net output #0: loss = 1.71905 (* 1 = 1.71905 loss)
I0801 22:50:24.114634 12219 sgd_solver.cpp:136] Iteration 179800, lr = 0.0438125, m = 0.9
I0801 22:50:38.091775 12219 solver.cpp:353] Iteration 179900 (7.1547 iter/s, 13.9768s/100 iter), loss = 2.56898
I0801 22:50:38.091833 12219 solver.cpp:375]     Train net output #0: loss = 3.03295 (* 1 = 3.03295 loss)
I0801 22:50:38.091845 12219 sgd_solver.cpp:136] Iteration 179900, lr = 0.0437813, m = 0.9
I0801 22:50:51.861407 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_180000.caffemodel
I0801 22:50:51.971483 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_180000.solverstate
I0801 22:50:51.977087 12219 solver.cpp:550] Iteration 180000, Testing net (#0)
I0801 22:51:11.939155 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.432529
I0801 22:51:11.939282 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.694352
I0801 22:51:11.939292 12219 solver.cpp:635]     Test net output #2: loss = 2.61167 (* 1 = 2.61167 loss)
I0801 22:51:11.939345 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9617s
I0801 22:51:12.101188 12219 solver.cpp:353] Iteration 180000 (2.94044 iter/s, 34.0085s/100 iter), loss = 1.69209
I0801 22:51:12.101215 12219 solver.cpp:375]     Train net output #0: loss = 1.29672 (* 1 = 1.29672 loss)
I0801 22:51:12.101219 12219 sgd_solver.cpp:136] Iteration 180000, lr = 0.04375, m = 0.9
I0801 22:51:26.265878 12219 solver.cpp:353] Iteration 180100 (7.06 iter/s, 14.1643s/100 iter), loss = 1.50882
I0801 22:51:26.265907 12219 solver.cpp:375]     Train net output #0: loss = 1.81107 (* 1 = 1.81107 loss)
I0801 22:51:26.265913 12219 sgd_solver.cpp:136] Iteration 180100, lr = 0.0437188, m = 0.9
I0801 22:51:40.333086 12219 solver.cpp:353] Iteration 180200 (7.10893 iter/s, 14.0668s/100 iter), loss = 1.58073
I0801 22:51:40.333113 12219 solver.cpp:375]     Train net output #0: loss = 1.46465 (* 1 = 1.46465 loss)
I0801 22:51:40.333118 12219 sgd_solver.cpp:136] Iteration 180200, lr = 0.0436875, m = 0.9
I0801 22:51:54.285537 12219 solver.cpp:353] Iteration 180300 (7.1674 iter/s, 13.9521s/100 iter), loss = 2.26166
I0801 22:51:54.285616 12219 solver.cpp:375]     Train net output #0: loss = 2.1618 (* 1 = 2.1618 loss)
I0801 22:51:54.285624 12219 sgd_solver.cpp:136] Iteration 180300, lr = 0.0436562, m = 0.9
I0801 22:52:08.291059 12219 solver.cpp:353] Iteration 180400 (7.14024 iter/s, 14.0051s/100 iter), loss = 1.8712
I0801 22:52:08.291091 12219 solver.cpp:375]     Train net output #0: loss = 1.5949 (* 1 = 1.5949 loss)
I0801 22:52:08.291095 12219 sgd_solver.cpp:136] Iteration 180400, lr = 0.043625, m = 0.9
I0801 22:52:22.284693 12219 solver.cpp:353] Iteration 180500 (7.1463 iter/s, 13.9933s/100 iter), loss = 1.58597
I0801 22:52:22.284723 12219 solver.cpp:375]     Train net output #0: loss = 1.61237 (* 1 = 1.61237 loss)
I0801 22:52:22.284729 12219 sgd_solver.cpp:136] Iteration 180500, lr = 0.0435938, m = 0.9
I0801 22:52:36.315352 12219 solver.cpp:353] Iteration 180600 (7.12744 iter/s, 14.0303s/100 iter), loss = 1.96866
I0801 22:52:36.315433 12219 solver.cpp:375]     Train net output #0: loss = 2.38715 (* 1 = 2.38715 loss)
I0801 22:52:36.315440 12219 sgd_solver.cpp:136] Iteration 180600, lr = 0.0435625, m = 0.9
I0801 22:52:50.352996 12219 solver.cpp:353] Iteration 180700 (7.1239 iter/s, 14.0373s/100 iter), loss = 2.13473
I0801 22:52:50.353025 12219 solver.cpp:375]     Train net output #0: loss = 2.26438 (* 1 = 2.26438 loss)
I0801 22:52:50.353083 12219 sgd_solver.cpp:136] Iteration 180700, lr = 0.0435313, m = 0.9
I0801 22:53:04.322654 12219 solver.cpp:353] Iteration 180800 (7.15857 iter/s, 13.9693s/100 iter), loss = 2.11738
I0801 22:53:04.322681 12219 solver.cpp:375]     Train net output #0: loss = 2.30873 (* 1 = 2.30873 loss)
I0801 22:53:04.322688 12219 sgd_solver.cpp:136] Iteration 180800, lr = 0.0435, m = 0.9
I0801 22:53:18.340654 12219 solver.cpp:353] Iteration 180900 (7.13388 iter/s, 14.0176s/100 iter), loss = 1.82463
I0801 22:53:18.340755 12219 solver.cpp:375]     Train net output #0: loss = 1.36241 (* 1 = 1.36241 loss)
I0801 22:53:18.340764 12219 sgd_solver.cpp:136] Iteration 180900, lr = 0.0434688, m = 0.9
I0801 22:53:32.302754 12219 solver.cpp:353] Iteration 181000 (7.16244 iter/s, 13.9617s/100 iter), loss = 2.20062
I0801 22:53:32.302781 12219 solver.cpp:375]     Train net output #0: loss = 2.11162 (* 1 = 2.11162 loss)
I0801 22:53:32.302788 12219 sgd_solver.cpp:136] Iteration 181000, lr = 0.0434375, m = 0.9
I0801 22:53:46.206190 12219 solver.cpp:353] Iteration 181100 (7.19266 iter/s, 13.9031s/100 iter), loss = 2.03158
I0801 22:53:46.206220 12219 solver.cpp:375]     Train net output #0: loss = 2.19362 (* 1 = 2.19362 loss)
I0801 22:53:46.206226 12219 sgd_solver.cpp:136] Iteration 181100, lr = 0.0434062, m = 0.9
I0801 22:54:00.254165 12219 solver.cpp:353] Iteration 181200 (7.11866 iter/s, 14.0476s/100 iter), loss = 1.5347
I0801 22:54:00.254297 12219 solver.cpp:375]     Train net output #0: loss = 1.84644 (* 1 = 1.84644 loss)
I0801 22:54:00.254317 12219 sgd_solver.cpp:136] Iteration 181200, lr = 0.043375, m = 0.9
I0801 22:54:14.230836 12219 solver.cpp:353] Iteration 181300 (7.15498 iter/s, 13.9763s/100 iter), loss = 2.28575
I0801 22:54:14.230865 12219 solver.cpp:375]     Train net output #0: loss = 2.36011 (* 1 = 2.36011 loss)
I0801 22:54:14.230872 12219 sgd_solver.cpp:136] Iteration 181300, lr = 0.0433438, m = 0.9
I0801 22:54:28.292889 12219 solver.cpp:353] Iteration 181400 (7.11153 iter/s, 14.0617s/100 iter), loss = 1.8715
I0801 22:54:28.292915 12219 solver.cpp:375]     Train net output #0: loss = 1.81902 (* 1 = 1.81902 loss)
I0801 22:54:28.292919 12219 sgd_solver.cpp:136] Iteration 181400, lr = 0.0433125, m = 0.9
I0801 22:54:42.199375 12219 solver.cpp:353] Iteration 181500 (7.19108 iter/s, 13.9061s/100 iter), loss = 2.09686
I0801 22:54:42.199429 12219 solver.cpp:375]     Train net output #0: loss = 2.27606 (* 1 = 2.27606 loss)
I0801 22:54:42.199434 12219 sgd_solver.cpp:136] Iteration 181500, lr = 0.0432813, m = 0.9
I0801 22:54:56.161285 12219 solver.cpp:353] Iteration 181600 (7.16254 iter/s, 13.9615s/100 iter), loss = 1.76556
I0801 22:54:56.161321 12219 solver.cpp:375]     Train net output #0: loss = 1.84011 (* 1 = 1.84011 loss)
I0801 22:54:56.161329 12219 sgd_solver.cpp:136] Iteration 181600, lr = 0.04325, m = 0.9
I0801 22:55:10.039511 12219 solver.cpp:353] Iteration 181700 (7.20573 iter/s, 13.8778s/100 iter), loss = 2.31621
I0801 22:55:10.039631 12219 solver.cpp:375]     Train net output #0: loss = 2.45227 (* 1 = 2.45227 loss)
I0801 22:55:10.039652 12219 sgd_solver.cpp:136] Iteration 181700, lr = 0.0432188, m = 0.9
I0801 22:55:23.995530 12219 solver.cpp:353] Iteration 181800 (7.16556 iter/s, 13.9556s/100 iter), loss = 1.60262
I0801 22:55:23.995592 12219 solver.cpp:375]     Train net output #0: loss = 1.47876 (* 1 = 1.47876 loss)
I0801 22:55:23.995599 12219 sgd_solver.cpp:136] Iteration 181800, lr = 0.0431875, m = 0.9
I0801 22:55:38.033246 12219 solver.cpp:353] Iteration 181900 (7.12387 iter/s, 14.0373s/100 iter), loss = 1.97425
I0801 22:55:38.033282 12219 solver.cpp:375]     Train net output #0: loss = 1.92579 (* 1 = 1.92579 loss)
I0801 22:55:38.033288 12219 sgd_solver.cpp:136] Iteration 181900, lr = 0.0431562, m = 0.9
I0801 22:55:51.919885 12219 solver.cpp:550] Iteration 182000, Testing net (#0)
I0801 22:56:12.526346 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.444
I0801 22:56:12.526433 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.702116
I0801 22:56:12.526443 12219 solver.cpp:635]     Test net output #2: loss = 2.526 (* 1 = 2.526 loss)
I0801 22:56:12.526463 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.606s
I0801 22:56:12.670534 12219 solver.cpp:353] Iteration 182000 (2.88714 iter/s, 34.6364s/100 iter), loss = 2.08374
I0801 22:56:12.670590 12219 solver.cpp:375]     Train net output #0: loss = 1.93828 (* 1 = 1.93828 loss)
I0801 22:56:12.670606 12219 sgd_solver.cpp:136] Iteration 182000, lr = 0.043125, m = 0.9
I0801 22:56:26.744776 12219 solver.cpp:353] Iteration 182100 (7.10537 iter/s, 14.0739s/100 iter), loss = 1.71627
I0801 22:56:26.744810 12219 solver.cpp:375]     Train net output #0: loss = 2.26397 (* 1 = 2.26397 loss)
I0801 22:56:26.744822 12219 sgd_solver.cpp:136] Iteration 182100, lr = 0.0430938, m = 0.9
I0801 22:56:40.793848 12219 solver.cpp:353] Iteration 182200 (7.11811 iter/s, 14.0487s/100 iter), loss = 1.72342
I0801 22:56:40.793900 12219 solver.cpp:375]     Train net output #0: loss = 1.66827 (* 1 = 1.66827 loss)
I0801 22:56:40.793913 12219 sgd_solver.cpp:136] Iteration 182200, lr = 0.0430625, m = 0.9
I0801 22:56:54.810755 12219 solver.cpp:353] Iteration 182300 (7.13444 iter/s, 14.0165s/100 iter), loss = 2.20078
I0801 22:56:54.810847 12219 solver.cpp:375]     Train net output #0: loss = 2.5762 (* 1 = 2.5762 loss)
I0801 22:56:54.810853 12219 sgd_solver.cpp:136] Iteration 182300, lr = 0.0430313, m = 0.9
I0801 22:57:08.846499 12219 solver.cpp:353] Iteration 182400 (7.12486 iter/s, 14.0354s/100 iter), loss = 1.47857
I0801 22:57:08.846529 12219 solver.cpp:375]     Train net output #0: loss = 1.32739 (* 1 = 1.32739 loss)
I0801 22:57:08.846535 12219 sgd_solver.cpp:136] Iteration 182400, lr = 0.043, m = 0.9
I0801 22:57:22.980937 12219 solver.cpp:353] Iteration 182500 (7.07512 iter/s, 14.134s/100 iter), loss = 2.04576
I0801 22:57:22.980964 12219 solver.cpp:375]     Train net output #0: loss = 1.93796 (* 1 = 1.93796 loss)
I0801 22:57:22.980971 12219 sgd_solver.cpp:136] Iteration 182500, lr = 0.0429688, m = 0.9
I0801 22:57:37.028143 12219 solver.cpp:353] Iteration 182600 (7.11905 iter/s, 14.0468s/100 iter), loss = 1.41226
I0801 22:57:37.028219 12219 solver.cpp:375]     Train net output #0: loss = 1.24883 (* 1 = 1.24883 loss)
I0801 22:57:37.028226 12219 sgd_solver.cpp:136] Iteration 182600, lr = 0.0429375, m = 0.9
I0801 22:57:51.015106 12219 solver.cpp:353] Iteration 182700 (7.14971 iter/s, 13.9866s/100 iter), loss = 1.52655
I0801 22:57:51.015131 12219 solver.cpp:375]     Train net output #0: loss = 1.00373 (* 1 = 1.00373 loss)
I0801 22:57:51.015136 12219 sgd_solver.cpp:136] Iteration 182700, lr = 0.0429063, m = 0.9
I0801 22:58:05.048868 12219 solver.cpp:353] Iteration 182800 (7.12587 iter/s, 14.0334s/100 iter), loss = 1.97918
I0801 22:58:05.048897 12219 solver.cpp:375]     Train net output #0: loss = 1.82581 (* 1 = 1.82581 loss)
I0801 22:58:05.048903 12219 sgd_solver.cpp:136] Iteration 182800, lr = 0.042875, m = 0.9
I0801 22:58:19.050796 12219 solver.cpp:353] Iteration 182900 (7.14207 iter/s, 14.0015s/100 iter), loss = 2.16315
I0801 22:58:19.051640 12219 solver.cpp:375]     Train net output #0: loss = 2.04159 (* 1 = 2.04159 loss)
I0801 22:58:19.051662 12219 sgd_solver.cpp:136] Iteration 182900, lr = 0.0428437, m = 0.9
I0801 22:58:33.205088 12219 solver.cpp:353] Iteration 183000 (7.06519 iter/s, 14.1539s/100 iter), loss = 2.1044
I0801 22:58:33.205114 12219 solver.cpp:375]     Train net output #0: loss = 2.43065 (* 1 = 2.43065 loss)
I0801 22:58:33.205118 12219 sgd_solver.cpp:136] Iteration 183000, lr = 0.0428125, m = 0.9
I0801 22:58:47.252645 12219 solver.cpp:353] Iteration 183100 (7.11887 iter/s, 14.0472s/100 iter), loss = 1.85206
I0801 22:58:47.252681 12219 solver.cpp:375]     Train net output #0: loss = 1.737 (* 1 = 1.737 loss)
I0801 22:58:47.252687 12219 sgd_solver.cpp:136] Iteration 183100, lr = 0.0427813, m = 0.9
I0801 22:59:01.301395 12219 solver.cpp:353] Iteration 183200 (7.11827 iter/s, 14.0484s/100 iter), loss = 1.99806
I0801 22:59:01.304853 12219 solver.cpp:375]     Train net output #0: loss = 1.99328 (* 1 = 1.99328 loss)
I0801 22:59:01.304867 12219 sgd_solver.cpp:136] Iteration 183200, lr = 0.04275, m = 0.9
I0801 22:59:15.462812 12219 solver.cpp:353] Iteration 183300 (7.06163 iter/s, 14.161s/100 iter), loss = 2.32053
I0801 22:59:15.462838 12219 solver.cpp:375]     Train net output #0: loss = 2.06058 (* 1 = 2.06058 loss)
I0801 22:59:15.462844 12219 sgd_solver.cpp:136] Iteration 183300, lr = 0.0427187, m = 0.9
I0801 22:59:29.585213 12219 solver.cpp:353] Iteration 183400 (7.08114 iter/s, 14.122s/100 iter), loss = 1.98899
I0801 22:59:29.585254 12219 solver.cpp:375]     Train net output #0: loss = 2.20641 (* 1 = 2.20641 loss)
I0801 22:59:29.585261 12219 sgd_solver.cpp:136] Iteration 183400, lr = 0.0426875, m = 0.9
I0801 22:59:43.707168 12219 solver.cpp:353] Iteration 183500 (7.08136 iter/s, 14.1216s/100 iter), loss = 2.05731
I0801 22:59:43.707243 12219 solver.cpp:375]     Train net output #0: loss = 2.27475 (* 1 = 2.27475 loss)
I0801 22:59:43.707250 12219 sgd_solver.cpp:136] Iteration 183500, lr = 0.0426563, m = 0.9
I0801 22:59:57.688477 12219 solver.cpp:353] Iteration 183600 (7.1526 iter/s, 13.9809s/100 iter), loss = 1.95502
I0801 22:59:57.688505 12219 solver.cpp:375]     Train net output #0: loss = 1.90224 (* 1 = 1.90224 loss)
I0801 22:59:57.688511 12219 sgd_solver.cpp:136] Iteration 183600, lr = 0.042625, m = 0.9
I0801 23:00:11.829658 12219 solver.cpp:353] Iteration 183700 (7.07174 iter/s, 14.1408s/100 iter), loss = 1.66225
I0801 23:00:11.829686 12219 solver.cpp:375]     Train net output #0: loss = 1.59687 (* 1 = 1.59687 loss)
I0801 23:00:11.829690 12219 sgd_solver.cpp:136] Iteration 183700, lr = 0.0425937, m = 0.9
I0801 23:00:26.020730 12219 solver.cpp:353] Iteration 183800 (7.04688 iter/s, 14.1907s/100 iter), loss = 1.75952
I0801 23:00:26.020797 12219 solver.cpp:375]     Train net output #0: loss = 1.52976 (* 1 = 1.52976 loss)
I0801 23:00:26.020804 12219 sgd_solver.cpp:136] Iteration 183800, lr = 0.0425625, m = 0.9
I0801 23:00:40.094518 12219 solver.cpp:353] Iteration 183900 (7.1056 iter/s, 14.0734s/100 iter), loss = 1.71577
I0801 23:00:40.094542 12219 solver.cpp:375]     Train net output #0: loss = 1.6474 (* 1 = 1.6474 loss)
I0801 23:00:40.094547 12219 sgd_solver.cpp:136] Iteration 183900, lr = 0.0425313, m = 0.9
I0801 23:00:54.007772 12219 solver.cpp:550] Iteration 184000, Testing net (#0)
I0801 23:00:56.778293 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 23:01:14.154363 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.462235
I0801 23:01:14.154386 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.723469
I0801 23:01:14.154392 12219 solver.cpp:635]     Test net output #2: loss = 2.40313 (* 1 = 2.40313 loss)
I0801 23:01:14.154489 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1462s
I0801 23:01:14.295179 12219 solver.cpp:353] Iteration 184000 (2.924 iter/s, 34.1997s/100 iter), loss = 1.73672
I0801 23:01:14.295249 12219 solver.cpp:375]     Train net output #0: loss = 1.9932 (* 1 = 1.9932 loss)
I0801 23:01:14.295269 12219 sgd_solver.cpp:136] Iteration 184000, lr = 0.0425, m = 0.9
I0801 23:01:28.411272 12219 solver.cpp:353] Iteration 184100 (7.08431 iter/s, 14.1157s/100 iter), loss = 2.1563
I0801 23:01:28.411356 12219 solver.cpp:375]     Train net output #0: loss = 2.44983 (* 1 = 2.44983 loss)
I0801 23:01:28.411365 12219 sgd_solver.cpp:136] Iteration 184100, lr = 0.0424688, m = 0.9
I0801 23:01:42.378813 12219 solver.cpp:353] Iteration 184200 (7.15965 iter/s, 13.9672s/100 iter), loss = 1.82094
I0801 23:01:42.378837 12219 solver.cpp:375]     Train net output #0: loss = 1.66348 (* 1 = 1.66348 loss)
I0801 23:01:42.378841 12219 sgd_solver.cpp:136] Iteration 184200, lr = 0.0424375, m = 0.9
I0801 23:01:56.557049 12219 solver.cpp:353] Iteration 184300 (7.05326 iter/s, 14.1778s/100 iter), loss = 1.63606
I0801 23:01:56.557085 12219 solver.cpp:375]     Train net output #0: loss = 1.68098 (* 1 = 1.68098 loss)
I0801 23:01:56.557095 12219 sgd_solver.cpp:136] Iteration 184300, lr = 0.0424062, m = 0.9
I0801 23:02:10.616664 12219 solver.cpp:353] Iteration 184400 (7.11277 iter/s, 14.0592s/100 iter), loss = 1.60743
I0801 23:02:10.616725 12219 solver.cpp:375]     Train net output #0: loss = 1.99737 (* 1 = 1.99737 loss)
I0801 23:02:10.616732 12219 sgd_solver.cpp:136] Iteration 184400, lr = 0.042375, m = 0.9
I0801 23:02:24.695560 12219 solver.cpp:353] Iteration 184500 (7.10302 iter/s, 14.0785s/100 iter), loss = 1.9639
I0801 23:02:24.695646 12219 solver.cpp:375]     Train net output #0: loss = 1.81112 (* 1 = 1.81112 loss)
I0801 23:02:24.695668 12219 sgd_solver.cpp:136] Iteration 184500, lr = 0.0423437, m = 0.9
I0801 23:02:38.758004 12219 solver.cpp:353] Iteration 184600 (7.11134 iter/s, 14.0621s/100 iter), loss = 1.44204
I0801 23:02:38.758049 12219 solver.cpp:375]     Train net output #0: loss = 1.16794 (* 1 = 1.16794 loss)
I0801 23:02:38.758060 12219 sgd_solver.cpp:136] Iteration 184600, lr = 0.0423125, m = 0.9
I0801 23:02:52.860604 12219 solver.cpp:353] Iteration 184700 (7.09108 iter/s, 14.1022s/100 iter), loss = 1.65857
I0801 23:02:52.860677 12219 solver.cpp:375]     Train net output #0: loss = 1.52325 (* 1 = 1.52325 loss)
I0801 23:02:52.860683 12219 sgd_solver.cpp:136] Iteration 184700, lr = 0.0422813, m = 0.9
I0801 23:03:06.905726 12219 solver.cpp:353] Iteration 184800 (7.1201 iter/s, 14.0447s/100 iter), loss = 1.61791
I0801 23:03:06.905750 12219 solver.cpp:375]     Train net output #0: loss = 1.61979 (* 1 = 1.61979 loss)
I0801 23:03:06.905756 12219 sgd_solver.cpp:136] Iteration 184800, lr = 0.04225, m = 0.9
I0801 23:03:20.917125 12219 solver.cpp:353] Iteration 184900 (7.13724 iter/s, 14.011s/100 iter), loss = 1.58144
I0801 23:03:20.917153 12219 solver.cpp:375]     Train net output #0: loss = 1.66752 (* 1 = 1.66752 loss)
I0801 23:03:20.917160 12219 sgd_solver.cpp:136] Iteration 184900, lr = 0.0422188, m = 0.9
I0801 23:03:35.099939 12219 solver.cpp:353] Iteration 185000 (7.05098 iter/s, 14.1824s/100 iter), loss = 1.97434
I0801 23:03:35.099998 12219 solver.cpp:375]     Train net output #0: loss = 2.0935 (* 1 = 2.0935 loss)
I0801 23:03:35.100003 12219 sgd_solver.cpp:136] Iteration 185000, lr = 0.0421875, m = 0.9
I0801 23:03:49.169942 12219 solver.cpp:353] Iteration 185100 (7.10751 iter/s, 14.0696s/100 iter), loss = 2.15326
I0801 23:03:49.169966 12219 solver.cpp:375]     Train net output #0: loss = 1.83642 (* 1 = 1.83642 loss)
I0801 23:03:49.169970 12219 sgd_solver.cpp:136] Iteration 185100, lr = 0.0421562, m = 0.9
I0801 23:04:03.221012 12219 solver.cpp:353] Iteration 185200 (7.11709 iter/s, 14.0507s/100 iter), loss = 2.08017
I0801 23:04:03.221041 12219 solver.cpp:375]     Train net output #0: loss = 2.08215 (* 1 = 2.08215 loss)
I0801 23:04:03.221047 12219 sgd_solver.cpp:136] Iteration 185200, lr = 0.042125, m = 0.9
I0801 23:04:17.222920 12219 solver.cpp:353] Iteration 185300 (7.14208 iter/s, 14.0015s/100 iter), loss = 1.84692
I0801 23:04:17.225198 12219 solver.cpp:375]     Train net output #0: loss = 1.87412 (* 1 = 1.87412 loss)
I0801 23:04:17.225208 12219 sgd_solver.cpp:136] Iteration 185300, lr = 0.0420938, m = 0.9
I0801 23:04:31.227685 12219 solver.cpp:353] Iteration 185400 (7.14062 iter/s, 14.0044s/100 iter), loss = 1.85126
I0801 23:04:31.227712 12219 solver.cpp:375]     Train net output #0: loss = 1.86246 (* 1 = 1.86246 loss)
I0801 23:04:31.227716 12219 sgd_solver.cpp:136] Iteration 185400, lr = 0.0420625, m = 0.9
I0801 23:04:45.256860 12219 solver.cpp:353] Iteration 185500 (7.1282 iter/s, 14.0288s/100 iter), loss = 1.92474
I0801 23:04:45.256886 12219 solver.cpp:375]     Train net output #0: loss = 2.18121 (* 1 = 2.18121 loss)
I0801 23:04:45.256892 12219 sgd_solver.cpp:136] Iteration 185500, lr = 0.0420313, m = 0.9
I0801 23:04:59.235147 12219 solver.cpp:353] Iteration 185600 (7.15415 iter/s, 13.9779s/100 iter), loss = 1.49257
I0801 23:04:59.235235 12219 solver.cpp:375]     Train net output #0: loss = 1.64349 (* 1 = 1.64349 loss)
I0801 23:04:59.235256 12219 sgd_solver.cpp:136] Iteration 185600, lr = 0.042, m = 0.9
I0801 23:05:13.216985 12219 solver.cpp:353] Iteration 185700 (7.15233 iter/s, 13.9815s/100 iter), loss = 1.38372
I0801 23:05:13.217015 12219 solver.cpp:375]     Train net output #0: loss = 1.35771 (* 1 = 1.35771 loss)
I0801 23:05:13.217020 12219 sgd_solver.cpp:136] Iteration 185700, lr = 0.0419688, m = 0.9
I0801 23:05:27.300333 12219 solver.cpp:353] Iteration 185800 (7.10078 iter/s, 14.083s/100 iter), loss = 1.64665
I0801 23:05:27.300357 12219 solver.cpp:375]     Train net output #0: loss = 1.62005 (* 1 = 1.62005 loss)
I0801 23:05:27.300364 12219 sgd_solver.cpp:136] Iteration 185800, lr = 0.0419375, m = 0.9
I0801 23:05:41.367733 12219 solver.cpp:353] Iteration 185900 (7.10883 iter/s, 14.067s/100 iter), loss = 1.80732
I0801 23:05:41.367791 12219 solver.cpp:375]     Train net output #0: loss = 1.71851 (* 1 = 1.71851 loss)
I0801 23:05:41.367799 12219 sgd_solver.cpp:136] Iteration 185900, lr = 0.0419062, m = 0.9
I0801 23:05:55.289286 12219 solver.cpp:550] Iteration 186000, Testing net (#0)
I0801 23:05:58.416086 12207 data_reader.cpp:264] Starting prefetch of epoch 10
I0801 23:06:15.204774 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.443235
I0801 23:06:15.204864 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.695469
I0801 23:06:15.204872 12219 solver.cpp:635]     Test net output #2: loss = 2.56805 (* 1 = 2.56805 loss)
I0801 23:06:15.204890 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9151s
I0801 23:06:15.342545 12219 solver.cpp:353] Iteration 186000 (2.94344 iter/s, 33.9739s/100 iter), loss = 1.70531
I0801 23:06:15.342569 12219 solver.cpp:375]     Train net output #0: loss = 1.97775 (* 1 = 1.97775 loss)
I0801 23:06:15.342573 12219 sgd_solver.cpp:136] Iteration 186000, lr = 0.041875, m = 0.9
I0801 23:06:29.440315 12219 solver.cpp:353] Iteration 186100 (7.09352 iter/s, 14.0974s/100 iter), loss = 1.90498
I0801 23:06:29.440342 12219 solver.cpp:375]     Train net output #0: loss = 1.94861 (* 1 = 1.94861 loss)
I0801 23:06:29.440347 12219 sgd_solver.cpp:136] Iteration 186100, lr = 0.0418437, m = 0.9
I0801 23:06:43.468011 12219 solver.cpp:353] Iteration 186200 (7.12895 iter/s, 14.0273s/100 iter), loss = 1.87546
I0801 23:06:43.468040 12219 solver.cpp:375]     Train net output #0: loss = 1.73153 (* 1 = 1.73153 loss)
I0801 23:06:43.468046 12219 sgd_solver.cpp:136] Iteration 186200, lr = 0.0418125, m = 0.9
I0801 23:06:57.549659 12219 solver.cpp:353] Iteration 186300 (7.10164 iter/s, 14.0813s/100 iter), loss = 1.72364
I0801 23:06:57.549741 12219 solver.cpp:375]     Train net output #0: loss = 1.7152 (* 1 = 1.7152 loss)
I0801 23:06:57.549747 12219 sgd_solver.cpp:136] Iteration 186300, lr = 0.0417813, m = 0.9
I0801 23:07:11.580221 12219 solver.cpp:353] Iteration 186400 (7.12749 iter/s, 14.0302s/100 iter), loss = 1.81936
I0801 23:07:11.580246 12219 solver.cpp:375]     Train net output #0: loss = 1.59311 (* 1 = 1.59311 loss)
I0801 23:07:11.580251 12219 sgd_solver.cpp:136] Iteration 186400, lr = 0.04175, m = 0.9
I0801 23:07:25.635382 12219 solver.cpp:353] Iteration 186500 (7.11502 iter/s, 14.0548s/100 iter), loss = 1.61813
I0801 23:07:25.635411 12219 solver.cpp:375]     Train net output #0: loss = 1.65459 (* 1 = 1.65459 loss)
I0801 23:07:25.635417 12219 sgd_solver.cpp:136] Iteration 186500, lr = 0.0417188, m = 0.9
I0801 23:07:39.625845 12219 solver.cpp:353] Iteration 186600 (7.14792 iter/s, 13.9901s/100 iter), loss = 2.23846
I0801 23:07:39.625900 12219 solver.cpp:375]     Train net output #0: loss = 2.64449 (* 1 = 2.64449 loss)
I0801 23:07:39.625905 12219 sgd_solver.cpp:136] Iteration 186600, lr = 0.0416875, m = 0.9
I0801 23:07:53.653622 12219 solver.cpp:353] Iteration 186700 (7.12891 iter/s, 14.0274s/100 iter), loss = 1.82243
I0801 23:07:53.653653 12219 solver.cpp:375]     Train net output #0: loss = 1.71531 (* 1 = 1.71531 loss)
I0801 23:07:53.653659 12219 sgd_solver.cpp:136] Iteration 186700, lr = 0.0416563, m = 0.9
I0801 23:08:07.563084 12219 solver.cpp:353] Iteration 186800 (7.18955 iter/s, 13.9091s/100 iter), loss = 1.74464
I0801 23:08:07.563112 12219 solver.cpp:375]     Train net output #0: loss = 1.93046 (* 1 = 1.93046 loss)
I0801 23:08:07.563118 12219 sgd_solver.cpp:136] Iteration 186800, lr = 0.041625, m = 0.9
I0801 23:08:21.536931 12219 solver.cpp:353] Iteration 186900 (7.15642 iter/s, 13.9735s/100 iter), loss = 1.42944
I0801 23:08:21.536986 12219 solver.cpp:375]     Train net output #0: loss = 1.31164 (* 1 = 1.31164 loss)
I0801 23:08:21.536993 12219 sgd_solver.cpp:136] Iteration 186900, lr = 0.0415937, m = 0.9
I0801 23:08:35.458863 12219 solver.cpp:353] Iteration 187000 (7.18311 iter/s, 13.9216s/100 iter), loss = 1.89679
I0801 23:08:35.458890 12219 solver.cpp:375]     Train net output #0: loss = 1.7958 (* 1 = 1.7958 loss)
I0801 23:08:35.458895 12219 sgd_solver.cpp:136] Iteration 187000, lr = 0.0415625, m = 0.9
I0801 23:08:49.484905 12219 solver.cpp:353] Iteration 187100 (7.12979 iter/s, 14.0257s/100 iter), loss = 1.97561
I0801 23:08:49.484930 12219 solver.cpp:375]     Train net output #0: loss = 2.24639 (* 1 = 2.24639 loss)
I0801 23:08:49.484935 12219 sgd_solver.cpp:136] Iteration 187100, lr = 0.0415313, m = 0.9
I0801 23:09:03.478292 12219 solver.cpp:353] Iteration 187200 (7.14644 iter/s, 13.993s/100 iter), loss = 1.83636
I0801 23:09:03.478368 12219 solver.cpp:375]     Train net output #0: loss = 1.71584 (* 1 = 1.71584 loss)
I0801 23:09:03.478375 12219 sgd_solver.cpp:136] Iteration 187200, lr = 0.0415, m = 0.9
I0801 23:09:17.433176 12219 solver.cpp:353] Iteration 187300 (7.16614 iter/s, 13.9545s/100 iter), loss = 2.05902
I0801 23:09:17.433205 12219 solver.cpp:375]     Train net output #0: loss = 1.91272 (* 1 = 1.91272 loss)
I0801 23:09:17.433212 12219 sgd_solver.cpp:136] Iteration 187300, lr = 0.0414688, m = 0.9
I0801 23:09:31.371206 12219 solver.cpp:353] Iteration 187400 (7.17481 iter/s, 13.9376s/100 iter), loss = 1.92809
I0801 23:09:31.371237 12219 solver.cpp:375]     Train net output #0: loss = 1.9672 (* 1 = 1.9672 loss)
I0801 23:09:31.371243 12219 sgd_solver.cpp:136] Iteration 187400, lr = 0.0414375, m = 0.9
I0801 23:09:45.408836 12219 solver.cpp:353] Iteration 187500 (7.1239 iter/s, 14.0372s/100 iter), loss = 2.07914
I0801 23:09:45.408900 12219 solver.cpp:375]     Train net output #0: loss = 1.91791 (* 1 = 1.91791 loss)
I0801 23:09:45.408906 12219 sgd_solver.cpp:136] Iteration 187500, lr = 0.0414063, m = 0.9
I0801 23:09:59.409634 12219 solver.cpp:353] Iteration 187600 (7.14264 iter/s, 14.0004s/100 iter), loss = 1.93118
I0801 23:09:59.409663 12219 solver.cpp:375]     Train net output #0: loss = 2.1809 (* 1 = 2.1809 loss)
I0801 23:09:59.409669 12219 sgd_solver.cpp:136] Iteration 187600, lr = 0.041375, m = 0.9
I0801 23:10:13.386435 12219 solver.cpp:353] Iteration 187700 (7.1549 iter/s, 13.9764s/100 iter), loss = 1.67615
I0801 23:10:13.386462 12219 solver.cpp:375]     Train net output #0: loss = 1.63352 (* 1 = 1.63352 loss)
I0801 23:10:13.386467 12219 sgd_solver.cpp:136] Iteration 187700, lr = 0.0413437, m = 0.9
I0801 23:10:27.306696 12219 solver.cpp:353] Iteration 187800 (7.18397 iter/s, 13.9199s/100 iter), loss = 1.9172
I0801 23:10:27.306752 12219 solver.cpp:375]     Train net output #0: loss = 2.37416 (* 1 = 2.37416 loss)
I0801 23:10:27.306757 12219 sgd_solver.cpp:136] Iteration 187800, lr = 0.0413125, m = 0.9
I0801 23:10:41.279886 12219 solver.cpp:353] Iteration 187900 (7.15676 iter/s, 13.9728s/100 iter), loss = 1.91608
I0801 23:10:41.279986 12219 solver.cpp:375]     Train net output #0: loss = 1.24894 (* 1 = 1.24894 loss)
I0801 23:10:41.280009 12219 sgd_solver.cpp:136] Iteration 187900, lr = 0.0412812, m = 0.9
I0801 23:10:55.142340 12219 solver.cpp:550] Iteration 188000, Testing net (#0)
I0801 23:11:15.321377 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.421412
I0801 23:11:15.321467 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.684587
I0801 23:11:15.321476 12219 solver.cpp:635]     Test net output #2: loss = 2.64218 (* 1 = 2.64218 loss)
I0801 23:11:15.321496 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1786s
I0801 23:11:15.463680 12219 solver.cpp:353] Iteration 188000 (2.92544 iter/s, 34.1829s/100 iter), loss = 1.93194
I0801 23:11:15.463706 12219 solver.cpp:375]     Train net output #0: loss = 2.04839 (* 1 = 2.04839 loss)
I0801 23:11:15.463711 12219 sgd_solver.cpp:136] Iteration 188000, lr = 0.04125, m = 0.9
I0801 23:11:29.503569 12219 solver.cpp:353] Iteration 188100 (7.12276 iter/s, 14.0395s/100 iter), loss = 1.80066
I0801 23:11:29.503656 12219 solver.cpp:375]     Train net output #0: loss = 1.67754 (* 1 = 1.67754 loss)
I0801 23:11:29.503675 12219 sgd_solver.cpp:136] Iteration 188100, lr = 0.0412188, m = 0.9
I0801 23:11:43.441576 12219 solver.cpp:353] Iteration 188200 (7.17483 iter/s, 13.9376s/100 iter), loss = 2.01364
I0801 23:11:43.441606 12219 solver.cpp:375]     Train net output #0: loss = 1.94627 (* 1 = 1.94627 loss)
I0801 23:11:43.441612 12219 sgd_solver.cpp:136] Iteration 188200, lr = 0.0411875, m = 0.9
I0801 23:11:57.466820 12219 solver.cpp:353] Iteration 188300 (7.1302 iter/s, 14.0249s/100 iter), loss = 1.83398
I0801 23:11:57.466912 12219 solver.cpp:375]     Train net output #0: loss = 2.04479 (* 1 = 2.04479 loss)
I0801 23:11:57.466922 12219 sgd_solver.cpp:136] Iteration 188300, lr = 0.0411563, m = 0.9
I0801 23:12:11.496743 12219 solver.cpp:353] Iteration 188400 (7.12782 iter/s, 14.0295s/100 iter), loss = 2.21774
I0801 23:12:11.496773 12219 solver.cpp:375]     Train net output #0: loss = 2.15918 (* 1 = 2.15918 loss)
I0801 23:12:11.496778 12219 sgd_solver.cpp:136] Iteration 188400, lr = 0.041125, m = 0.9
I0801 23:12:25.528687 12219 solver.cpp:353] Iteration 188500 (7.12679 iter/s, 14.0316s/100 iter), loss = 2.0264
I0801 23:12:25.528712 12219 solver.cpp:375]     Train net output #0: loss = 2.65706 (* 1 = 2.65706 loss)
I0801 23:12:25.528717 12219 sgd_solver.cpp:136] Iteration 188500, lr = 0.0410937, m = 0.9
I0801 23:12:39.552801 12219 solver.cpp:353] Iteration 188600 (7.13077 iter/s, 14.0237s/100 iter), loss = 1.77522
I0801 23:12:39.552862 12219 solver.cpp:375]     Train net output #0: loss = 1.83667 (* 1 = 1.83667 loss)
I0801 23:12:39.552868 12219 sgd_solver.cpp:136] Iteration 188600, lr = 0.0410625, m = 0.9
I0801 23:12:53.658201 12219 solver.cpp:353] Iteration 188700 (7.08968 iter/s, 14.105s/100 iter), loss = 1.50927
I0801 23:12:53.658227 12219 solver.cpp:375]     Train net output #0: loss = 1.89931 (* 1 = 1.89931 loss)
I0801 23:12:53.658233 12219 sgd_solver.cpp:136] Iteration 188700, lr = 0.0410312, m = 0.9
I0801 23:13:07.877040 12219 solver.cpp:353] Iteration 188800 (7.03312 iter/s, 14.2184s/100 iter), loss = 1.91803
I0801 23:13:07.877070 12219 solver.cpp:375]     Train net output #0: loss = 2.17634 (* 1 = 2.17634 loss)
I0801 23:13:07.877076 12219 sgd_solver.cpp:136] Iteration 188800, lr = 0.041, m = 0.9
I0801 23:13:21.933655 12219 solver.cpp:353] Iteration 188900 (7.11428 iter/s, 14.0562s/100 iter), loss = 1.59812
I0801 23:13:21.933712 12219 solver.cpp:375]     Train net output #0: loss = 1.44391 (* 1 = 1.44391 loss)
I0801 23:13:21.933718 12219 sgd_solver.cpp:136] Iteration 188900, lr = 0.0409688, m = 0.9
I0801 23:13:36.011677 12219 solver.cpp:353] Iteration 189000 (7.10346 iter/s, 14.0776s/100 iter), loss = 2.25713
I0801 23:13:36.011705 12219 solver.cpp:375]     Train net output #0: loss = 2.38079 (* 1 = 2.38079 loss)
I0801 23:13:36.011709 12219 sgd_solver.cpp:136] Iteration 189000, lr = 0.0409375, m = 0.9
I0801 23:13:50.116307 12219 solver.cpp:353] Iteration 189100 (7.09006 iter/s, 14.1042s/100 iter), loss = 1.69208
I0801 23:13:50.116336 12219 solver.cpp:375]     Train net output #0: loss = 1.67412 (* 1 = 1.67412 loss)
I0801 23:13:50.116343 12219 sgd_solver.cpp:136] Iteration 189100, lr = 0.0409063, m = 0.9
I0801 23:14:04.087054 12219 solver.cpp:353] Iteration 189200 (7.15801 iter/s, 13.9704s/100 iter), loss = 1.68857
I0801 23:14:04.087160 12219 solver.cpp:375]     Train net output #0: loss = 1.46214 (* 1 = 1.46214 loss)
I0801 23:14:04.087167 12219 sgd_solver.cpp:136] Iteration 189200, lr = 0.040875, m = 0.9
I0801 23:14:18.176184 12219 solver.cpp:353] Iteration 189300 (7.09786 iter/s, 14.0887s/100 iter), loss = 2.04724
I0801 23:14:18.176208 12219 solver.cpp:375]     Train net output #0: loss = 2.22529 (* 1 = 2.22529 loss)
I0801 23:14:18.176211 12219 sgd_solver.cpp:136] Iteration 189300, lr = 0.0408438, m = 0.9
I0801 23:14:32.243443 12219 solver.cpp:353] Iteration 189400 (7.1089 iter/s, 14.0669s/100 iter), loss = 1.67891
I0801 23:14:32.243471 12219 solver.cpp:375]     Train net output #0: loss = 1.74346 (* 1 = 1.74346 loss)
I0801 23:14:32.243477 12219 sgd_solver.cpp:136] Iteration 189400, lr = 0.0408125, m = 0.9
I0801 23:14:46.259299 12219 solver.cpp:353] Iteration 189500 (7.13497 iter/s, 14.0155s/100 iter), loss = 2.12214
I0801 23:14:46.259364 12219 solver.cpp:375]     Train net output #0: loss = 1.86207 (* 1 = 1.86207 loss)
I0801 23:14:46.259371 12219 sgd_solver.cpp:136] Iteration 189500, lr = 0.0407812, m = 0.9
I0801 23:15:00.274570 12219 solver.cpp:353] Iteration 189600 (7.13527 iter/s, 14.0149s/100 iter), loss = 1.5761
I0801 23:15:00.274792 12219 solver.cpp:375]     Train net output #0: loss = 1.67317 (* 1 = 1.67317 loss)
I0801 23:15:00.274904 12219 sgd_solver.cpp:136] Iteration 189600, lr = 0.04075, m = 0.9
I0801 23:15:14.295809 12219 solver.cpp:353] Iteration 189700 (7.13223 iter/s, 14.0209s/100 iter), loss = 1.14634
I0801 23:15:14.295835 12219 solver.cpp:375]     Train net output #0: loss = 0.960665 (* 1 = 0.960665 loss)
I0801 23:15:14.295841 12219 sgd_solver.cpp:136] Iteration 189700, lr = 0.0407188, m = 0.9
I0801 23:15:28.357403 12219 solver.cpp:353] Iteration 189800 (7.11177 iter/s, 14.0612s/100 iter), loss = 1.99014
I0801 23:15:28.357501 12219 solver.cpp:375]     Train net output #0: loss = 2.11925 (* 1 = 2.11925 loss)
I0801 23:15:28.357509 12219 sgd_solver.cpp:136] Iteration 189800, lr = 0.0406875, m = 0.9
I0801 23:15:42.402760 12219 solver.cpp:353] Iteration 189900 (7.11998 iter/s, 14.045s/100 iter), loss = 1.91488
I0801 23:15:42.402801 12219 solver.cpp:375]     Train net output #0: loss = 2.07884 (* 1 = 2.07884 loss)
I0801 23:15:42.402807 12219 sgd_solver.cpp:136] Iteration 189900, lr = 0.0406562, m = 0.9
I0801 23:15:56.351277 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_190000.caffemodel
I0801 23:15:56.418635 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_190000.solverstate
I0801 23:15:56.429970 12219 solver.cpp:550] Iteration 190000, Testing net (#0)
I0801 23:16:01.281065 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 23:16:16.561686 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.459411
I0801 23:16:16.561709 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.712823
I0801 23:16:16.561714 12219 solver.cpp:635]     Test net output #2: loss = 2.51794 (* 1 = 2.51794 loss)
I0801 23:16:16.561781 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1313s
I0801 23:16:16.704848 12219 solver.cpp:353] Iteration 190000 (2.91535 iter/s, 34.3012s/100 iter), loss = 2.10667
I0801 23:16:16.704898 12219 solver.cpp:375]     Train net output #0: loss = 2.16623 (* 1 = 2.16623 loss)
I0801 23:16:16.704911 12219 sgd_solver.cpp:136] Iteration 190000, lr = 0.040625, m = 0.9
I0801 23:16:30.797315 12219 solver.cpp:353] Iteration 190100 (7.09619 iter/s, 14.0921s/100 iter), loss = 2.15105
I0801 23:16:30.797348 12219 solver.cpp:375]     Train net output #0: loss = 1.86447 (* 1 = 1.86447 loss)
I0801 23:16:30.797353 12219 sgd_solver.cpp:136] Iteration 190100, lr = 0.0405938, m = 0.9
I0801 23:16:44.896275 12219 solver.cpp:353] Iteration 190200 (7.09292 iter/s, 14.0986s/100 iter), loss = 1.84451
I0801 23:16:44.896355 12219 solver.cpp:375]     Train net output #0: loss = 1.76773 (* 1 = 1.76773 loss)
I0801 23:16:44.896368 12219 sgd_solver.cpp:136] Iteration 190200, lr = 0.0405625, m = 0.9
I0801 23:16:58.924823 12219 solver.cpp:353] Iteration 190300 (7.12852 iter/s, 14.0282s/100 iter), loss = 1.85752
I0801 23:16:58.924849 12219 solver.cpp:375]     Train net output #0: loss = 1.76141 (* 1 = 1.76141 loss)
I0801 23:16:58.924854 12219 sgd_solver.cpp:136] Iteration 190300, lr = 0.0405312, m = 0.9
I0801 23:17:13.013845 12219 solver.cpp:353] Iteration 190400 (7.09791 iter/s, 14.0886s/100 iter), loss = 2.01634
I0801 23:17:13.013871 12219 solver.cpp:375]     Train net output #0: loss = 2.06179 (* 1 = 2.06179 loss)
I0801 23:17:13.013877 12219 sgd_solver.cpp:136] Iteration 190400, lr = 0.0405, m = 0.9
I0801 23:17:27.056339 12219 solver.cpp:353] Iteration 190500 (7.12144 iter/s, 14.0421s/100 iter), loss = 2.10716
I0801 23:17:27.056403 12219 solver.cpp:375]     Train net output #0: loss = 2.07894 (* 1 = 2.07894 loss)
I0801 23:17:27.056411 12219 sgd_solver.cpp:136] Iteration 190500, lr = 0.0404688, m = 0.9
I0801 23:17:41.113318 12219 solver.cpp:353] Iteration 190600 (7.1141 iter/s, 14.0566s/100 iter), loss = 1.56476
I0801 23:17:41.113346 12219 solver.cpp:375]     Train net output #0: loss = 1.40179 (* 1 = 1.40179 loss)
I0801 23:17:41.113353 12219 sgd_solver.cpp:136] Iteration 190600, lr = 0.0404375, m = 0.9
I0801 23:17:55.219568 12219 solver.cpp:353] Iteration 190700 (7.08925 iter/s, 14.1059s/100 iter), loss = 1.77495
I0801 23:17:55.219599 12219 solver.cpp:375]     Train net output #0: loss = 1.78809 (* 1 = 1.78809 loss)
I0801 23:17:55.219604 12219 sgd_solver.cpp:136] Iteration 190700, lr = 0.0404063, m = 0.9
I0801 23:18:09.360204 12219 solver.cpp:353] Iteration 190800 (7.07201 iter/s, 14.1403s/100 iter), loss = 1.71819
I0801 23:18:09.360306 12219 solver.cpp:375]     Train net output #0: loss = 1.5276 (* 1 = 1.5276 loss)
I0801 23:18:09.360313 12219 sgd_solver.cpp:136] Iteration 190800, lr = 0.040375, m = 0.9
I0801 23:18:23.406189 12219 solver.cpp:353] Iteration 190900 (7.11967 iter/s, 14.0456s/100 iter), loss = 1.9522
I0801 23:18:23.406219 12219 solver.cpp:375]     Train net output #0: loss = 2.35479 (* 1 = 2.35479 loss)
I0801 23:18:23.406225 12219 sgd_solver.cpp:136] Iteration 190900, lr = 0.0403438, m = 0.9
I0801 23:18:37.322540 12219 solver.cpp:353] Iteration 191000 (7.18599 iter/s, 13.916s/100 iter), loss = 1.89531
I0801 23:18:37.322569 12219 solver.cpp:375]     Train net output #0: loss = 1.64503 (* 1 = 1.64503 loss)
I0801 23:18:37.322576 12219 sgd_solver.cpp:136] Iteration 191000, lr = 0.0403125, m = 0.9
I0801 23:18:51.293658 12219 solver.cpp:353] Iteration 191100 (7.15782 iter/s, 13.9707s/100 iter), loss = 1.908
I0801 23:18:51.293833 12219 solver.cpp:375]     Train net output #0: loss = 1.85932 (* 1 = 1.85932 loss)
I0801 23:18:51.293849 12219 sgd_solver.cpp:136] Iteration 191100, lr = 0.0402812, m = 0.9
I0801 23:19:05.344386 12219 solver.cpp:353] Iteration 191200 (7.11726 iter/s, 14.0503s/100 iter), loss = 2.14087
I0801 23:19:05.344414 12219 solver.cpp:375]     Train net output #0: loss = 2.06269 (* 1 = 2.06269 loss)
I0801 23:19:05.344421 12219 sgd_solver.cpp:136] Iteration 191200, lr = 0.04025, m = 0.9
I0801 23:19:19.417054 12219 solver.cpp:353] Iteration 191300 (7.10617 iter/s, 14.0723s/100 iter), loss = 1.99119
I0801 23:19:19.417083 12219 solver.cpp:375]     Train net output #0: loss = 1.67628 (* 1 = 1.67628 loss)
I0801 23:19:19.417086 12219 sgd_solver.cpp:136] Iteration 191300, lr = 0.0402188, m = 0.9
I0801 23:19:33.399096 12219 solver.cpp:353] Iteration 191400 (7.15223 iter/s, 13.9817s/100 iter), loss = 1.55514
I0801 23:19:33.399220 12219 solver.cpp:375]     Train net output #0: loss = 1.92361 (* 1 = 1.92361 loss)
I0801 23:19:33.399242 12219 sgd_solver.cpp:136] Iteration 191400, lr = 0.0401875, m = 0.9
I0801 23:19:47.295671 12219 solver.cpp:353] Iteration 191500 (7.19621 iter/s, 13.8962s/100 iter), loss = 1.64416
I0801 23:19:47.295698 12219 solver.cpp:375]     Train net output #0: loss = 1.77021 (* 1 = 1.77021 loss)
I0801 23:19:47.295704 12219 sgd_solver.cpp:136] Iteration 191500, lr = 0.0401563, m = 0.9
I0801 23:20:01.368001 12219 solver.cpp:353] Iteration 191600 (7.10634 iter/s, 14.0719s/100 iter), loss = 1.79936
I0801 23:20:01.368031 12219 solver.cpp:375]     Train net output #0: loss = 1.99914 (* 1 = 1.99914 loss)
I0801 23:20:01.368037 12219 sgd_solver.cpp:136] Iteration 191600, lr = 0.040125, m = 0.9
I0801 23:20:15.484319 12219 solver.cpp:353] Iteration 191700 (7.08419 iter/s, 14.1159s/100 iter), loss = 1.82063
I0801 23:20:15.484378 12219 solver.cpp:375]     Train net output #0: loss = 2.14559 (* 1 = 2.14559 loss)
I0801 23:20:15.484385 12219 sgd_solver.cpp:136] Iteration 191700, lr = 0.0400937, m = 0.9
I0801 23:20:29.481542 12219 solver.cpp:353] Iteration 191800 (7.14447 iter/s, 13.9968s/100 iter), loss = 1.691
I0801 23:20:29.481570 12219 solver.cpp:375]     Train net output #0: loss = 1.50901 (* 1 = 1.50901 loss)
I0801 23:20:29.481573 12219 sgd_solver.cpp:136] Iteration 191800, lr = 0.0400625, m = 0.9
I0801 23:20:43.500118 12219 solver.cpp:353] Iteration 191900 (7.13358 iter/s, 14.0182s/100 iter), loss = 1.93314
I0801 23:20:43.500146 12219 solver.cpp:375]     Train net output #0: loss = 1.70692 (* 1 = 1.70692 loss)
I0801 23:20:43.500152 12219 sgd_solver.cpp:136] Iteration 191900, lr = 0.0400313, m = 0.9
I0801 23:20:57.324921 12219 solver.cpp:550] Iteration 192000, Testing net (#0)
I0801 23:21:17.292758 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.471176
I0801 23:21:17.292784 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.725528
I0801 23:21:17.292791 12219 solver.cpp:635]     Test net output #2: loss = 2.37827 (* 1 = 2.37827 loss)
I0801 23:21:17.292840 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9674s
I0801 23:21:17.430167 12219 solver.cpp:353] Iteration 192000 (2.94732 iter/s, 33.9291s/100 iter), loss = 1.59744
I0801 23:21:17.430194 12219 solver.cpp:375]     Train net output #0: loss = 1.54405 (* 1 = 1.54405 loss)
I0801 23:21:17.430199 12219 sgd_solver.cpp:136] Iteration 192000, lr = 0.04, m = 0.9
I0801 23:21:31.440402 12219 solver.cpp:353] Iteration 192100 (7.13783 iter/s, 14.0099s/100 iter), loss = 1.45327
I0801 23:21:31.440479 12219 solver.cpp:375]     Train net output #0: loss = 1.44963 (* 1 = 1.44963 loss)
I0801 23:21:31.440491 12219 sgd_solver.cpp:136] Iteration 192100, lr = 0.0399688, m = 0.9
I0801 23:21:45.481374 12219 solver.cpp:353] Iteration 192200 (7.12221 iter/s, 14.0406s/100 iter), loss = 2.08915
I0801 23:21:45.481400 12219 solver.cpp:375]     Train net output #0: loss = 2.19882 (* 1 = 2.19882 loss)
I0801 23:21:45.481405 12219 sgd_solver.cpp:136] Iteration 192200, lr = 0.0399375, m = 0.9
I0801 23:21:59.473613 12219 solver.cpp:353] Iteration 192300 (7.14701 iter/s, 13.9919s/100 iter), loss = 1.79382
I0801 23:21:59.473639 12219 solver.cpp:375]     Train net output #0: loss = 1.78975 (* 1 = 1.78975 loss)
I0801 23:21:59.473646 12219 sgd_solver.cpp:136] Iteration 192300, lr = 0.0399063, m = 0.9
I0801 23:22:13.466401 12219 solver.cpp:353] Iteration 192400 (7.14673 iter/s, 13.9924s/100 iter), loss = 1.77993
I0801 23:22:13.466506 12219 solver.cpp:375]     Train net output #0: loss = 1.91495 (* 1 = 1.91495 loss)
I0801 23:22:13.466513 12219 sgd_solver.cpp:136] Iteration 192400, lr = 0.039875, m = 0.9
I0801 23:22:27.529361 12219 solver.cpp:353] Iteration 192500 (7.11107 iter/s, 14.0626s/100 iter), loss = 1.74702
I0801 23:22:27.529386 12219 solver.cpp:375]     Train net output #0: loss = 1.62972 (* 1 = 1.62972 loss)
I0801 23:22:27.529389 12219 sgd_solver.cpp:136] Iteration 192500, lr = 0.0398437, m = 0.9
I0801 23:22:41.507823 12219 solver.cpp:353] Iteration 192600 (7.15406 iter/s, 13.9781s/100 iter), loss = 1.77429
I0801 23:22:41.507849 12219 solver.cpp:375]     Train net output #0: loss = 2.01227 (* 1 = 2.01227 loss)
I0801 23:22:41.507854 12219 sgd_solver.cpp:136] Iteration 192600, lr = 0.0398125, m = 0.9
I0801 23:22:55.526819 12219 solver.cpp:353] Iteration 192700 (7.13337 iter/s, 14.0186s/100 iter), loss = 1.93519
I0801 23:22:55.526937 12219 solver.cpp:375]     Train net output #0: loss = 1.53094 (* 1 = 1.53094 loss)
I0801 23:22:55.526960 12219 sgd_solver.cpp:136] Iteration 192700, lr = 0.0397813, m = 0.9
I0801 23:23:09.491946 12219 solver.cpp:353] Iteration 192800 (7.16089 iter/s, 13.9647s/100 iter), loss = 1.63546
I0801 23:23:09.491973 12219 solver.cpp:375]     Train net output #0: loss = 2.1334 (* 1 = 2.1334 loss)
I0801 23:23:09.491978 12219 sgd_solver.cpp:136] Iteration 192800, lr = 0.03975, m = 0.9
I0801 23:23:23.582406 12219 solver.cpp:353] Iteration 192900 (7.09719 iter/s, 14.0901s/100 iter), loss = 1.79016
I0801 23:23:23.582433 12219 solver.cpp:375]     Train net output #0: loss = 1.64123 (* 1 = 1.64123 loss)
I0801 23:23:23.582437 12219 sgd_solver.cpp:136] Iteration 192900, lr = 0.0397187, m = 0.9
I0801 23:23:37.585288 12219 solver.cpp:353] Iteration 193000 (7.14158 iter/s, 14.0025s/100 iter), loss = 1.62835
I0801 23:23:37.585373 12219 solver.cpp:375]     Train net output #0: loss = 1.50805 (* 1 = 1.50805 loss)
I0801 23:23:37.585379 12219 sgd_solver.cpp:136] Iteration 193000, lr = 0.0396875, m = 0.9
I0801 23:23:51.534335 12219 solver.cpp:353] Iteration 193100 (7.16914 iter/s, 13.9487s/100 iter), loss = 2.38974
I0801 23:23:51.534363 12219 solver.cpp:375]     Train net output #0: loss = 2.40921 (* 1 = 2.40921 loss)
I0801 23:23:51.534368 12219 sgd_solver.cpp:136] Iteration 193100, lr = 0.0396563, m = 0.9
I0801 23:24:05.569706 12219 solver.cpp:353] Iteration 193200 (7.12505 iter/s, 14.035s/100 iter), loss = 1.59765
I0801 23:24:05.569735 12219 solver.cpp:375]     Train net output #0: loss = 1.5058 (* 1 = 1.5058 loss)
I0801 23:24:05.569741 12219 sgd_solver.cpp:136] Iteration 193200, lr = 0.039625, m = 0.9
I0801 23:24:19.494948 12219 solver.cpp:353] Iteration 193300 (7.1814 iter/s, 13.9249s/100 iter), loss = 1.99039
I0801 23:24:19.495024 12219 solver.cpp:375]     Train net output #0: loss = 1.93572 (* 1 = 1.93572 loss)
I0801 23:24:19.495031 12219 sgd_solver.cpp:136] Iteration 193300, lr = 0.0395938, m = 0.9
I0801 23:24:33.461532 12219 solver.cpp:353] Iteration 193400 (7.16014 iter/s, 13.9662s/100 iter), loss = 2.06004
I0801 23:24:33.461558 12219 solver.cpp:375]     Train net output #0: loss = 2.14263 (* 1 = 2.14263 loss)
I0801 23:24:33.461562 12219 sgd_solver.cpp:136] Iteration 193400, lr = 0.0395625, m = 0.9
I0801 23:24:47.525472 12219 solver.cpp:353] Iteration 193500 (7.11058 iter/s, 14.0636s/100 iter), loss = 1.51634
I0801 23:24:47.525502 12219 solver.cpp:375]     Train net output #0: loss = 1.6993 (* 1 = 1.6993 loss)
I0801 23:24:47.525508 12219 sgd_solver.cpp:136] Iteration 193500, lr = 0.0395312, m = 0.9
I0801 23:25:01.456364 12219 solver.cpp:353] Iteration 193600 (7.17849 iter/s, 13.9305s/100 iter), loss = 1.95954
I0801 23:25:01.456434 12219 solver.cpp:375]     Train net output #0: loss = 2.06415 (* 1 = 2.06415 loss)
I0801 23:25:01.456440 12219 sgd_solver.cpp:136] Iteration 193600, lr = 0.0395, m = 0.9
I0801 23:25:15.378706 12219 solver.cpp:353] Iteration 193700 (7.18289 iter/s, 13.922s/100 iter), loss = 1.58043
I0801 23:25:15.378733 12219 solver.cpp:375]     Train net output #0: loss = 1.83508 (* 1 = 1.83508 loss)
I0801 23:25:15.378738 12219 sgd_solver.cpp:136] Iteration 193700, lr = 0.0394687, m = 0.9
I0801 23:25:29.316627 12219 solver.cpp:353] Iteration 193800 (7.17487 iter/s, 13.9375s/100 iter), loss = 1.72997
I0801 23:25:29.316674 12219 solver.cpp:375]     Train net output #0: loss = 2.04307 (* 1 = 2.04307 loss)
I0801 23:25:29.316686 12219 sgd_solver.cpp:136] Iteration 193800, lr = 0.0394375, m = 0.9
I0801 23:25:43.217347 12219 solver.cpp:353] Iteration 193900 (7.19407 iter/s, 13.9003s/100 iter), loss = 1.73505
I0801 23:25:43.217406 12219 solver.cpp:375]     Train net output #0: loss = 1.7818 (* 1 = 1.7818 loss)
I0801 23:25:43.217414 12219 sgd_solver.cpp:136] Iteration 193900, lr = 0.0394063, m = 0.9
I0801 23:25:57.036193 12219 solver.cpp:550] Iteration 194000, Testing net (#0)
I0801 23:26:17.511188 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.451118
I0801 23:26:17.511240 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.702999
I0801 23:26:17.511245 12219 solver.cpp:635]     Test net output #2: loss = 2.52476 (* 1 = 2.52476 loss)
I0801 23:26:17.511265 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4745s
I0801 23:26:17.651242 12219 solver.cpp:353] Iteration 194000 (2.90419 iter/s, 34.433s/100 iter), loss = 1.99345
I0801 23:26:17.651273 12219 solver.cpp:375]     Train net output #0: loss = 2.33136 (* 1 = 2.33136 loss)
I0801 23:26:17.651280 12219 sgd_solver.cpp:136] Iteration 194000, lr = 0.039375, m = 0.9
I0801 23:26:31.760509 12219 solver.cpp:353] Iteration 194100 (7.08774 iter/s, 14.1089s/100 iter), loss = 1.79982
I0801 23:26:31.760538 12219 solver.cpp:375]     Train net output #0: loss = 1.35415 (* 1 = 1.35415 loss)
I0801 23:26:31.760545 12219 sgd_solver.cpp:136] Iteration 194100, lr = 0.0393438, m = 0.9
I0801 23:26:45.790925 12219 solver.cpp:353] Iteration 194200 (7.12757 iter/s, 14.03s/100 iter), loss = 1.73645
I0801 23:26:45.790951 12219 solver.cpp:375]     Train net output #0: loss = 1.75125 (* 1 = 1.75125 loss)
I0801 23:26:45.790956 12219 sgd_solver.cpp:136] Iteration 194200, lr = 0.0393125, m = 0.9
I0801 23:26:59.753480 12219 solver.cpp:353] Iteration 194300 (7.16221 iter/s, 13.9622s/100 iter), loss = 1.84146
I0801 23:26:59.753545 12219 solver.cpp:375]     Train net output #0: loss = 2.0991 (* 1 = 2.0991 loss)
I0801 23:26:59.753551 12219 sgd_solver.cpp:136] Iteration 194300, lr = 0.0392812, m = 0.9
I0801 23:27:13.820443 12219 solver.cpp:353] Iteration 194400 (7.10905 iter/s, 14.0666s/100 iter), loss = 1.71904
I0801 23:27:13.820474 12219 solver.cpp:375]     Train net output #0: loss = 1.57416 (* 1 = 1.57416 loss)
I0801 23:27:13.820478 12219 sgd_solver.cpp:136] Iteration 194400, lr = 0.03925, m = 0.9
I0801 23:27:27.826776 12219 solver.cpp:353] Iteration 194500 (7.13982 iter/s, 14.006s/100 iter), loss = 1.63978
I0801 23:27:27.826804 12219 solver.cpp:375]     Train net output #0: loss = 1.78553 (* 1 = 1.78553 loss)
I0801 23:27:27.826810 12219 sgd_solver.cpp:136] Iteration 194500, lr = 0.0392187, m = 0.9
I0801 23:27:41.896112 12219 solver.cpp:353] Iteration 194600 (7.10785 iter/s, 14.069s/100 iter), loss = 1.8597
I0801 23:27:41.896201 12219 solver.cpp:375]     Train net output #0: loss = 1.86612 (* 1 = 1.86612 loss)
I0801 23:27:41.896209 12219 sgd_solver.cpp:136] Iteration 194600, lr = 0.0391875, m = 0.9
I0801 23:27:55.909879 12219 solver.cpp:353] Iteration 194700 (7.13604 iter/s, 14.0134s/100 iter), loss = 1.76931
I0801 23:27:55.909909 12219 solver.cpp:375]     Train net output #0: loss = 1.78805 (* 1 = 1.78805 loss)
I0801 23:27:55.909914 12219 sgd_solver.cpp:136] Iteration 194700, lr = 0.0391563, m = 0.9
I0801 23:28:09.824894 12219 solver.cpp:353] Iteration 194800 (7.18668 iter/s, 13.9146s/100 iter), loss = 1.9188
I0801 23:28:09.824918 12219 solver.cpp:375]     Train net output #0: loss = 2.27899 (* 1 = 2.27899 loss)
I0801 23:28:09.824921 12219 sgd_solver.cpp:136] Iteration 194800, lr = 0.039125, m = 0.9
I0801 23:28:24.060545 12219 solver.cpp:353] Iteration 194900 (7.02481 iter/s, 14.2353s/100 iter), loss = 2.20318
I0801 23:28:24.060626 12219 solver.cpp:375]     Train net output #0: loss = 1.97818 (* 1 = 1.97818 loss)
I0801 23:28:24.060632 12219 sgd_solver.cpp:136] Iteration 194900, lr = 0.0390938, m = 0.9
I0801 23:28:38.136224 12219 solver.cpp:353] Iteration 195000 (7.10465 iter/s, 14.0753s/100 iter), loss = 1.97523
I0801 23:28:38.136255 12219 solver.cpp:375]     Train net output #0: loss = 1.91972 (* 1 = 1.91972 loss)
I0801 23:28:38.136261 12219 sgd_solver.cpp:136] Iteration 195000, lr = 0.0390625, m = 0.9
I0801 23:28:52.219413 12219 solver.cpp:353] Iteration 195100 (7.10086 iter/s, 14.0828s/100 iter), loss = 1.92341
I0801 23:28:52.219462 12219 solver.cpp:375]     Train net output #0: loss = 1.69049 (* 1 = 1.69049 loss)
I0801 23:28:52.219475 12219 sgd_solver.cpp:136] Iteration 195100, lr = 0.0390312, m = 0.9
I0801 23:29:06.199206 12219 solver.cpp:353] Iteration 195200 (7.15337 iter/s, 13.9794s/100 iter), loss = 1.77719
I0801 23:29:06.199265 12219 solver.cpp:375]     Train net output #0: loss = 1.84468 (* 1 = 1.84468 loss)
I0801 23:29:06.199271 12219 sgd_solver.cpp:136] Iteration 195200, lr = 0.039, m = 0.9
I0801 23:29:20.087929 12219 solver.cpp:353] Iteration 195300 (7.20028 iter/s, 13.8883s/100 iter), loss = 1.90442
I0801 23:29:20.087954 12219 solver.cpp:375]     Train net output #0: loss = 1.86691 (* 1 = 1.86691 loss)
I0801 23:29:20.087960 12219 sgd_solver.cpp:136] Iteration 195300, lr = 0.0389687, m = 0.9
I0801 23:29:34.234886 12219 solver.cpp:353] Iteration 195400 (7.06885 iter/s, 14.1466s/100 iter), loss = 1.76473
I0801 23:29:34.234913 12219 solver.cpp:375]     Train net output #0: loss = 1.67263 (* 1 = 1.67263 loss)
I0801 23:29:34.234920 12219 sgd_solver.cpp:136] Iteration 195400, lr = 0.0389375, m = 0.9
I0801 23:29:48.231039 12219 solver.cpp:353] Iteration 195500 (7.14501 iter/s, 13.9958s/100 iter), loss = 2.14194
I0801 23:29:48.231106 12219 solver.cpp:375]     Train net output #0: loss = 2.39195 (* 1 = 2.39195 loss)
I0801 23:29:48.231112 12219 sgd_solver.cpp:136] Iteration 195500, lr = 0.0389063, m = 0.9
I0801 23:30:02.369904 12219 solver.cpp:353] Iteration 195600 (7.0729 iter/s, 14.1385s/100 iter), loss = 2.32769
I0801 23:30:02.369935 12219 solver.cpp:375]     Train net output #0: loss = 2.5883 (* 1 = 2.5883 loss)
I0801 23:30:02.369941 12219 sgd_solver.cpp:136] Iteration 195600, lr = 0.038875, m = 0.9
I0801 23:30:16.337291 12219 solver.cpp:353] Iteration 195700 (7.15973 iter/s, 13.967s/100 iter), loss = 2.07215
I0801 23:30:16.337318 12219 solver.cpp:375]     Train net output #0: loss = 2.00494 (* 1 = 2.00494 loss)
I0801 23:30:16.337324 12219 sgd_solver.cpp:136] Iteration 195700, lr = 0.0388438, m = 0.9
I0801 23:30:30.324888 12219 solver.cpp:353] Iteration 195800 (7.14939 iter/s, 13.9872s/100 iter), loss = 2.01484
I0801 23:30:30.325522 12219 solver.cpp:375]     Train net output #0: loss = 1.77183 (* 1 = 1.77183 loss)
I0801 23:30:30.325635 12219 sgd_solver.cpp:136] Iteration 195800, lr = 0.0388125, m = 0.9
I0801 23:30:44.385704 12219 solver.cpp:353] Iteration 195900 (7.11215 iter/s, 14.0604s/100 iter), loss = 1.68354
I0801 23:30:44.385895 12219 solver.cpp:375]     Train net output #0: loss = 1.79722 (* 1 = 1.79722 loss)
I0801 23:30:44.386011 12219 sgd_solver.cpp:136] Iteration 195900, lr = 0.0387813, m = 0.9
I0801 23:30:58.383118 12219 solver.cpp:550] Iteration 196000, Testing net (#0)
I0801 23:31:05.965073 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 23:31:18.862120 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.474941
I0801 23:31:18.862146 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.728469
I0801 23:31:18.862154 12219 solver.cpp:635]     Test net output #2: loss = 2.37995 (* 1 = 2.37995 loss)
I0801 23:31:18.862236 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4786s
I0801 23:31:19.001317 12219 solver.cpp:353] Iteration 196000 (2.88895 iter/s, 34.6147s/100 iter), loss = 1.83584
I0801 23:31:19.001343 12219 solver.cpp:375]     Train net output #0: loss = 2.01241 (* 1 = 2.01241 loss)
I0801 23:31:19.001348 12219 sgd_solver.cpp:136] Iteration 196000, lr = 0.03875, m = 0.9
I0801 23:31:32.961405 12219 solver.cpp:353] Iteration 196100 (7.16347 iter/s, 13.9597s/100 iter), loss = 1.49645
I0801 23:31:32.961429 12219 solver.cpp:375]     Train net output #0: loss = 1.18231 (* 1 = 1.18231 loss)
I0801 23:31:32.961436 12219 sgd_solver.cpp:136] Iteration 196100, lr = 0.0387187, m = 0.9
I0801 23:31:47.106645 12219 solver.cpp:353] Iteration 196200 (7.06971 iter/s, 14.1449s/100 iter), loss = 1.70312
I0801 23:31:47.106705 12219 solver.cpp:375]     Train net output #0: loss = 1.62206 (* 1 = 1.62206 loss)
I0801 23:31:47.106712 12219 sgd_solver.cpp:136] Iteration 196200, lr = 0.0386875, m = 0.9
I0801 23:32:01.160876 12219 solver.cpp:353] Iteration 196300 (7.11549 iter/s, 14.0538s/100 iter), loss = 1.95586
I0801 23:32:01.160900 12219 solver.cpp:375]     Train net output #0: loss = 1.86063 (* 1 = 1.86063 loss)
I0801 23:32:01.160904 12219 sgd_solver.cpp:136] Iteration 196300, lr = 0.0386563, m = 0.9
I0801 23:32:15.125243 12219 solver.cpp:353] Iteration 196400 (7.16128 iter/s, 13.964s/100 iter), loss = 1.95047
I0801 23:32:15.125291 12219 solver.cpp:375]     Train net output #0: loss = 1.9794 (* 1 = 1.9794 loss)
I0801 23:32:15.125304 12219 sgd_solver.cpp:136] Iteration 196400, lr = 0.038625, m = 0.9
I0801 23:32:29.136906 12219 solver.cpp:353] Iteration 196500 (7.13711 iter/s, 14.0113s/100 iter), loss = 1.9531
I0801 23:32:29.136967 12219 solver.cpp:375]     Train net output #0: loss = 1.84556 (* 1 = 1.84556 loss)
I0801 23:32:29.136976 12219 sgd_solver.cpp:136] Iteration 196500, lr = 0.0385938, m = 0.9
I0801 23:32:43.073587 12219 solver.cpp:353] Iteration 196600 (7.1755 iter/s, 13.9363s/100 iter), loss = 1.64779
I0801 23:32:43.073616 12219 solver.cpp:375]     Train net output #0: loss = 1.71128 (* 1 = 1.71128 loss)
I0801 23:32:43.073621 12219 sgd_solver.cpp:136] Iteration 196600, lr = 0.0385625, m = 0.9
I0801 23:32:57.035614 12219 solver.cpp:353] Iteration 196700 (7.16248 iter/s, 13.9616s/100 iter), loss = 1.80421
I0801 23:32:57.035642 12219 solver.cpp:375]     Train net output #0: loss = 2.06128 (* 1 = 2.06128 loss)
I0801 23:32:57.035648 12219 sgd_solver.cpp:136] Iteration 196700, lr = 0.0385313, m = 0.9
I0801 23:33:11.136155 12219 solver.cpp:353] Iteration 196800 (7.09212 iter/s, 14.1001s/100 iter), loss = 1.88282
I0801 23:33:11.136220 12219 solver.cpp:375]     Train net output #0: loss = 1.35152 (* 1 = 1.35152 loss)
I0801 23:33:11.136227 12219 sgd_solver.cpp:136] Iteration 196800, lr = 0.0385, m = 0.9
I0801 23:33:25.211414 12219 solver.cpp:353] Iteration 196900 (7.10486 iter/s, 14.0749s/100 iter), loss = 1.8805
I0801 23:33:25.211519 12219 solver.cpp:375]     Train net output #0: loss = 1.48881 (* 1 = 1.48881 loss)
I0801 23:33:25.211539 12219 sgd_solver.cpp:136] Iteration 196900, lr = 0.0384687, m = 0.9
I0801 23:33:39.209120 12219 solver.cpp:353] Iteration 197000 (7.14422 iter/s, 13.9973s/100 iter), loss = 1.72691
I0801 23:33:39.209147 12219 solver.cpp:375]     Train net output #0: loss = 1.43492 (* 1 = 1.43492 loss)
I0801 23:33:39.209153 12219 sgd_solver.cpp:136] Iteration 197000, lr = 0.0384375, m = 0.9
I0801 23:33:53.176767 12219 solver.cpp:353] Iteration 197100 (7.1596 iter/s, 13.9673s/100 iter), loss = 1.57705
I0801 23:33:53.176842 12219 solver.cpp:375]     Train net output #0: loss = 1.65762 (* 1 = 1.65762 loss)
I0801 23:33:53.176851 12219 sgd_solver.cpp:136] Iteration 197100, lr = 0.0384063, m = 0.9
I0801 23:34:07.190287 12219 solver.cpp:353] Iteration 197200 (7.13616 iter/s, 14.0131s/100 iter), loss = 1.60588
I0801 23:34:07.190376 12219 solver.cpp:375]     Train net output #0: loss = 1.74499 (* 1 = 1.74499 loss)
I0801 23:34:07.190394 12219 sgd_solver.cpp:136] Iteration 197200, lr = 0.038375, m = 0.9
I0801 23:34:21.273430 12219 solver.cpp:353] Iteration 197300 (7.10088 iter/s, 14.0828s/100 iter), loss = 2.11472
I0801 23:34:21.273458 12219 solver.cpp:375]     Train net output #0: loss = 2.0721 (* 1 = 2.0721 loss)
I0801 23:34:21.273463 12219 sgd_solver.cpp:136] Iteration 197300, lr = 0.0383438, m = 0.9
I0801 23:34:35.279788 12219 solver.cpp:353] Iteration 197400 (7.13981 iter/s, 14.006s/100 iter), loss = 1.97923
I0801 23:34:35.279846 12219 solver.cpp:375]     Train net output #0: loss = 2.24703 (* 1 = 2.24703 loss)
I0801 23:34:35.279853 12219 sgd_solver.cpp:136] Iteration 197400, lr = 0.0383125, m = 0.9
I0801 23:34:49.298436 12219 solver.cpp:353] Iteration 197500 (7.13355 iter/s, 14.0183s/100 iter), loss = 1.68105
I0801 23:34:49.298465 12219 solver.cpp:375]     Train net output #0: loss = 1.69779 (* 1 = 1.69779 loss)
I0801 23:34:49.298472 12219 sgd_solver.cpp:136] Iteration 197500, lr = 0.0382813, m = 0.9
I0801 23:35:03.275611 12219 solver.cpp:353] Iteration 197600 (7.15472 iter/s, 13.9768s/100 iter), loss = 1.99954
I0801 23:35:03.275641 12219 solver.cpp:375]     Train net output #0: loss = 2.06099 (* 1 = 2.06099 loss)
I0801 23:35:03.275647 12219 sgd_solver.cpp:136] Iteration 197600, lr = 0.03825, m = 0.9
I0801 23:35:17.259755 12219 solver.cpp:353] Iteration 197700 (7.15115 iter/s, 13.9838s/100 iter), loss = 1.7662
I0801 23:35:17.259820 12219 solver.cpp:375]     Train net output #0: loss = 1.34298 (* 1 = 1.34298 loss)
I0801 23:35:17.259827 12219 sgd_solver.cpp:136] Iteration 197700, lr = 0.0382187, m = 0.9
I0801 23:35:31.311167 12219 solver.cpp:353] Iteration 197800 (7.11692 iter/s, 14.051s/100 iter), loss = 1.81074
I0801 23:35:31.311190 12219 solver.cpp:375]     Train net output #0: loss = 1.62858 (* 1 = 1.62858 loss)
I0801 23:35:31.311194 12219 sgd_solver.cpp:136] Iteration 197800, lr = 0.0381875, m = 0.9
I0801 23:35:45.390713 12219 solver.cpp:353] Iteration 197900 (7.10269 iter/s, 14.0792s/100 iter), loss = 1.81521
I0801 23:35:45.390740 12219 solver.cpp:375]     Train net output #0: loss = 1.73842 (* 1 = 1.73842 loss)
I0801 23:35:45.390748 12219 sgd_solver.cpp:136] Iteration 197900, lr = 0.0381562, m = 0.9
I0801 23:35:59.313951 12219 solver.cpp:550] Iteration 198000, Testing net (#0)
I0801 23:36:19.319841 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.467412
I0801 23:36:19.319864 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.724705
I0801 23:36:19.319869 12219 solver.cpp:635]     Test net output #2: loss = 2.39447 (* 1 = 2.39447 loss)
I0801 23:36:19.321305 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0068s
I0801 23:36:19.459647 12219 solver.cpp:353] Iteration 198000 (2.9353 iter/s, 34.068s/100 iter), loss = 1.75017
I0801 23:36:19.459672 12219 solver.cpp:375]     Train net output #0: loss = 1.56231 (* 1 = 1.56231 loss)
I0801 23:36:19.459677 12219 sgd_solver.cpp:136] Iteration 198000, lr = 0.038125, m = 0.9
I0801 23:36:33.466622 12219 solver.cpp:353] Iteration 198100 (7.1395 iter/s, 14.0066s/100 iter), loss = 2.0812
I0801 23:36:33.466871 12219 solver.cpp:375]     Train net output #0: loss = 1.55439 (* 1 = 1.55439 loss)
I0801 23:36:33.466964 12219 sgd_solver.cpp:136] Iteration 198100, lr = 0.0380938, m = 0.9
I0801 23:36:47.482570 12219 solver.cpp:353] Iteration 198200 (7.13493 iter/s, 14.0156s/100 iter), loss = 1.77863
I0801 23:36:47.482597 12219 solver.cpp:375]     Train net output #0: loss = 1.80516 (* 1 = 1.80516 loss)
I0801 23:36:47.482604 12219 sgd_solver.cpp:136] Iteration 198200, lr = 0.0380625, m = 0.9
I0801 23:37:01.497004 12219 solver.cpp:353] Iteration 198300 (7.1357 iter/s, 14.014s/100 iter), loss = 2.05973
I0801 23:37:01.497031 12219 solver.cpp:375]     Train net output #0: loss = 1.98822 (* 1 = 1.98822 loss)
I0801 23:37:01.497037 12219 sgd_solver.cpp:136] Iteration 198300, lr = 0.0380313, m = 0.9
I0801 23:37:15.472873 12219 solver.cpp:353] Iteration 198400 (7.15539 iter/s, 13.9755s/100 iter), loss = 1.71542
I0801 23:37:15.472949 12219 solver.cpp:375]     Train net output #0: loss = 1.43978 (* 1 = 1.43978 loss)
I0801 23:37:15.472959 12219 sgd_solver.cpp:136] Iteration 198400, lr = 0.038, m = 0.9
I0801 23:37:29.553426 12219 solver.cpp:353] Iteration 198500 (7.10219 iter/s, 14.0802s/100 iter), loss = 1.897
I0801 23:37:29.553454 12219 solver.cpp:375]     Train net output #0: loss = 1.46662 (* 1 = 1.46662 loss)
I0801 23:37:29.553462 12219 sgd_solver.cpp:136] Iteration 198500, lr = 0.0379688, m = 0.9
I0801 23:37:43.742657 12219 solver.cpp:353] Iteration 198600 (7.04779 iter/s, 14.1888s/100 iter), loss = 2.09955
I0801 23:37:43.742682 12219 solver.cpp:375]     Train net output #0: loss = 2.08973 (* 1 = 2.08973 loss)
I0801 23:37:43.742686 12219 sgd_solver.cpp:136] Iteration 198600, lr = 0.0379375, m = 0.9
I0801 23:37:57.745599 12219 solver.cpp:353] Iteration 198700 (7.14155 iter/s, 14.0026s/100 iter), loss = 1.30948
I0801 23:37:57.745662 12219 solver.cpp:375]     Train net output #0: loss = 1.3734 (* 1 = 1.3734 loss)
I0801 23:37:57.745669 12219 sgd_solver.cpp:136] Iteration 198700, lr = 0.0379062, m = 0.9
I0801 23:38:11.701247 12219 solver.cpp:353] Iteration 198800 (7.16575 iter/s, 13.9553s/100 iter), loss = 2.0255
I0801 23:38:11.701297 12219 solver.cpp:375]     Train net output #0: loss = 2.20843 (* 1 = 2.20843 loss)
I0801 23:38:11.701309 12219 sgd_solver.cpp:136] Iteration 198800, lr = 0.037875, m = 0.9
I0801 23:38:25.704380 12219 solver.cpp:353] Iteration 198900 (7.14146 iter/s, 14.0027s/100 iter), loss = 1.78192
I0801 23:38:25.704409 12219 solver.cpp:375]     Train net output #0: loss = 1.80561 (* 1 = 1.80561 loss)
I0801 23:38:25.704416 12219 sgd_solver.cpp:136] Iteration 198900, lr = 0.0378438, m = 0.9
I0801 23:38:39.687837 12219 solver.cpp:353] Iteration 199000 (7.1515 iter/s, 13.9831s/100 iter), loss = 2.26868
I0801 23:38:39.687919 12219 solver.cpp:375]     Train net output #0: loss = 2.47254 (* 1 = 2.47254 loss)
I0801 23:38:39.687927 12219 sgd_solver.cpp:136] Iteration 199000, lr = 0.0378125, m = 0.9
I0801 23:38:53.693732 12219 solver.cpp:353] Iteration 199100 (7.14004 iter/s, 14.0055s/100 iter), loss = 1.66354
I0801 23:38:53.693759 12219 solver.cpp:375]     Train net output #0: loss = 1.62564 (* 1 = 1.62564 loss)
I0801 23:38:53.693765 12219 sgd_solver.cpp:136] Iteration 199100, lr = 0.0377812, m = 0.9
I0801 23:39:07.612942 12219 solver.cpp:353] Iteration 199200 (7.18451 iter/s, 13.9188s/100 iter), loss = 1.5571
I0801 23:39:07.612970 12219 solver.cpp:375]     Train net output #0: loss = 1.51213 (* 1 = 1.51213 loss)
I0801 23:39:07.612977 12219 sgd_solver.cpp:136] Iteration 199200, lr = 0.03775, m = 0.9
I0801 23:39:21.573148 12219 solver.cpp:353] Iteration 199300 (7.16341 iter/s, 13.9598s/100 iter), loss = 2.07385
I0801 23:39:21.573205 12219 solver.cpp:375]     Train net output #0: loss = 1.96346 (* 1 = 1.96346 loss)
I0801 23:39:21.573212 12219 sgd_solver.cpp:136] Iteration 199300, lr = 0.0377188, m = 0.9
I0801 23:39:35.461321 12219 solver.cpp:353] Iteration 199400 (7.20057 iter/s, 13.8878s/100 iter), loss = 1.71086
I0801 23:39:35.461349 12219 solver.cpp:375]     Train net output #0: loss = 1.86172 (* 1 = 1.86172 loss)
I0801 23:39:35.461354 12219 sgd_solver.cpp:136] Iteration 199400, lr = 0.0376875, m = 0.9
I0801 23:39:49.283327 12219 solver.cpp:353] Iteration 199500 (7.23504 iter/s, 13.8216s/100 iter), loss = 1.94449
I0801 23:39:49.283355 12219 solver.cpp:375]     Train net output #0: loss = 2.09625 (* 1 = 2.09625 loss)
I0801 23:39:49.283360 12219 sgd_solver.cpp:136] Iteration 199500, lr = 0.0376562, m = 0.9
I0801 23:40:03.345405 12219 solver.cpp:353] Iteration 199600 (7.11152 iter/s, 14.0617s/100 iter), loss = 2.06646
I0801 23:40:03.345500 12219 solver.cpp:375]     Train net output #0: loss = 2.28246 (* 1 = 2.28246 loss)
I0801 23:40:03.345507 12219 sgd_solver.cpp:136] Iteration 199600, lr = 0.037625, m = 0.9
I0801 23:40:17.280668 12219 solver.cpp:353] Iteration 199700 (7.17623 iter/s, 13.9349s/100 iter), loss = 1.87453
I0801 23:40:17.280699 12219 solver.cpp:375]     Train net output #0: loss = 1.79352 (* 1 = 1.79352 loss)
I0801 23:40:17.280704 12219 sgd_solver.cpp:136] Iteration 199700, lr = 0.0375938, m = 0.9
I0801 23:40:31.228103 12219 solver.cpp:353] Iteration 199800 (7.16997 iter/s, 13.9471s/100 iter), loss = 1.66923
I0801 23:40:31.228129 12219 solver.cpp:375]     Train net output #0: loss = 1.57128 (* 1 = 1.57128 loss)
I0801 23:40:31.228134 12219 sgd_solver.cpp:136] Iteration 199800, lr = 0.0375625, m = 0.9
I0801 23:40:45.160908 12219 solver.cpp:353] Iteration 199900 (7.1775 iter/s, 13.9324s/100 iter), loss = 1.60854
I0801 23:40:45.160970 12219 solver.cpp:375]     Train net output #0: loss = 1.98899 (* 1 = 1.98899 loss)
I0801 23:40:45.160977 12219 sgd_solver.cpp:136] Iteration 199900, lr = 0.0375313, m = 0.9
I0801 23:40:58.956549 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_200000.caffemodel
I0801 23:40:59.026756 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_200000.solverstate
I0801 23:40:59.033071 12219 solver.cpp:550] Iteration 200000, Testing net (#0)
I0801 23:40:59.344171 12207 data_reader.cpp:264] Starting prefetch of epoch 11
I0801 23:41:19.002851 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.487705
I0801 23:41:19.003147 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.740116
I0801 23:41:19.003157 12219 solver.cpp:635]     Test net output #2: loss = 2.30753 (* 1 = 2.30753 loss)
I0801 23:41:19.003181 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9696s
I0801 23:41:19.161484 12219 solver.cpp:353] Iteration 200000 (2.94121 iter/s, 33.9997s/100 iter), loss = 1.55326
I0801 23:41:19.161525 12219 solver.cpp:375]     Train net output #0: loss = 1.68378 (* 1 = 1.68378 loss)
I0801 23:41:19.161530 12219 sgd_solver.cpp:136] Iteration 200000, lr = 0.0375, m = 0.9
I0801 23:41:33.240255 12219 solver.cpp:353] Iteration 200100 (7.10308 iter/s, 14.0784s/100 iter), loss = 1.82824
I0801 23:41:33.240286 12219 solver.cpp:375]     Train net output #0: loss = 1.45534 (* 1 = 1.45534 loss)
I0801 23:41:33.240293 12219 sgd_solver.cpp:136] Iteration 200100, lr = 0.0374688, m = 0.9
I0801 23:41:47.229181 12219 solver.cpp:353] Iteration 200200 (7.14871 iter/s, 13.9885s/100 iter), loss = 1.8558
I0801 23:41:47.229210 12219 solver.cpp:375]     Train net output #0: loss = 1.49087 (* 1 = 1.49087 loss)
I0801 23:41:47.229218 12219 sgd_solver.cpp:136] Iteration 200200, lr = 0.0374375, m = 0.9
I0801 23:42:01.170393 12219 solver.cpp:353] Iteration 200300 (7.17318 iter/s, 13.9408s/100 iter), loss = 1.9842
I0801 23:42:01.170480 12219 solver.cpp:375]     Train net output #0: loss = 2.03957 (* 1 = 2.03957 loss)
I0801 23:42:01.170493 12219 sgd_solver.cpp:136] Iteration 200300, lr = 0.0374062, m = 0.9
I0801 23:42:15.176507 12219 solver.cpp:353] Iteration 200400 (7.13993 iter/s, 14.0057s/100 iter), loss = 1.74374
I0801 23:42:15.176565 12219 solver.cpp:375]     Train net output #0: loss = 2.12246 (* 1 = 2.12246 loss)
I0801 23:42:15.176586 12219 sgd_solver.cpp:136] Iteration 200400, lr = 0.037375, m = 0.9
I0801 23:42:29.205900 12219 solver.cpp:353] Iteration 200500 (7.12809 iter/s, 14.029s/100 iter), loss = 1.92314
I0801 23:42:29.205926 12219 solver.cpp:375]     Train net output #0: loss = 1.7698 (* 1 = 1.7698 loss)
I0801 23:42:29.205932 12219 sgd_solver.cpp:136] Iteration 200500, lr = 0.0373438, m = 0.9
I0801 23:42:43.253530 12219 solver.cpp:353] Iteration 200600 (7.11883 iter/s, 14.0472s/100 iter), loss = 1.44197
I0801 23:42:43.253587 12219 solver.cpp:375]     Train net output #0: loss = 1.36447 (* 1 = 1.36447 loss)
I0801 23:42:43.253593 12219 sgd_solver.cpp:136] Iteration 200600, lr = 0.0373125, m = 0.9
I0801 23:42:57.286031 12219 solver.cpp:353] Iteration 200700 (7.12651 iter/s, 14.0321s/100 iter), loss = 1.91156
I0801 23:42:57.286056 12219 solver.cpp:375]     Train net output #0: loss = 2.30018 (* 1 = 2.30018 loss)
I0801 23:42:57.286061 12219 sgd_solver.cpp:136] Iteration 200700, lr = 0.0372813, m = 0.9
I0801 23:43:11.207386 12219 solver.cpp:353] Iteration 200800 (7.18341 iter/s, 13.921s/100 iter), loss = 1.57626
I0801 23:43:11.207412 12219 solver.cpp:375]     Train net output #0: loss = 1.56689 (* 1 = 1.56689 loss)
I0801 23:43:11.207415 12219 sgd_solver.cpp:136] Iteration 200800, lr = 0.03725, m = 0.9
I0801 23:43:25.258863 12219 solver.cpp:353] Iteration 200900 (7.11688 iter/s, 14.0511s/100 iter), loss = 1.7566
I0801 23:43:25.258910 12219 solver.cpp:375]     Train net output #0: loss = 1.37595 (* 1 = 1.37595 loss)
I0801 23:43:25.258915 12219 sgd_solver.cpp:136] Iteration 200900, lr = 0.0372187, m = 0.9
I0801 23:43:39.257300 12219 solver.cpp:353] Iteration 201000 (7.14385 iter/s, 13.9981s/100 iter), loss = 1.55052
I0801 23:43:39.257328 12219 solver.cpp:375]     Train net output #0: loss = 1.03695 (* 1 = 1.03695 loss)
I0801 23:43:39.257333 12219 sgd_solver.cpp:136] Iteration 201000, lr = 0.0371875, m = 0.9
I0801 23:43:53.310111 12219 solver.cpp:353] Iteration 201100 (7.11621 iter/s, 14.0524s/100 iter), loss = 2.01592
I0801 23:43:53.310194 12219 solver.cpp:375]     Train net output #0: loss = 1.9395 (* 1 = 1.9395 loss)
I0801 23:43:53.310246 12219 sgd_solver.cpp:136] Iteration 201100, lr = 0.0371563, m = 0.9
I0801 23:44:07.433950 12219 solver.cpp:353] Iteration 201200 (7.08042 iter/s, 14.1235s/100 iter), loss = 1.75708
I0801 23:44:07.434448 12219 solver.cpp:375]     Train net output #0: loss = 1.58064 (* 1 = 1.58064 loss)
I0801 23:44:07.434456 12219 sgd_solver.cpp:136] Iteration 201200, lr = 0.037125, m = 0.9
I0801 23:44:21.421881 12219 solver.cpp:353] Iteration 201300 (7.14921 iter/s, 13.9876s/100 iter), loss = 1.713
I0801 23:44:21.421938 12219 solver.cpp:375]     Train net output #0: loss = 1.92166 (* 1 = 1.92166 loss)
I0801 23:44:21.421952 12219 sgd_solver.cpp:136] Iteration 201300, lr = 0.0370938, m = 0.9
I0801 23:44:35.495321 12219 solver.cpp:353] Iteration 201400 (7.10578 iter/s, 14.0731s/100 iter), loss = 1.9969
I0801 23:44:35.495374 12219 solver.cpp:375]     Train net output #0: loss = 2.5547 (* 1 = 2.5547 loss)
I0801 23:44:35.495386 12219 sgd_solver.cpp:136] Iteration 201400, lr = 0.0370625, m = 0.9
I0801 23:44:49.640231 12219 solver.cpp:353] Iteration 201500 (7.06987 iter/s, 14.1445s/100 iter), loss = 1.74018
I0801 23:44:49.640310 12219 solver.cpp:375]     Train net output #0: loss = 1.84625 (* 1 = 1.84625 loss)
I0801 23:44:49.640317 12219 sgd_solver.cpp:136] Iteration 201500, lr = 0.0370313, m = 0.9
I0801 23:45:03.726557 12219 solver.cpp:353] Iteration 201600 (7.09928 iter/s, 14.0859s/100 iter), loss = 1.59318
I0801 23:45:03.726588 12219 solver.cpp:375]     Train net output #0: loss = 1.58264 (* 1 = 1.58264 loss)
I0801 23:45:03.726593 12219 sgd_solver.cpp:136] Iteration 201600, lr = 0.037, m = 0.9
I0801 23:45:17.845854 12219 solver.cpp:353] Iteration 201700 (7.0827 iter/s, 14.1189s/100 iter), loss = 1.45747
I0801 23:45:17.845881 12219 solver.cpp:375]     Train net output #0: loss = 1.44212 (* 1 = 1.44212 loss)
I0801 23:45:17.845887 12219 sgd_solver.cpp:136] Iteration 201700, lr = 0.0369687, m = 0.9
I0801 23:45:31.779980 12219 solver.cpp:353] Iteration 201800 (7.17682 iter/s, 13.9337s/100 iter), loss = 2.37444
I0801 23:45:31.780062 12219 solver.cpp:375]     Train net output #0: loss = 2.78114 (* 1 = 2.78114 loss)
I0801 23:45:31.780068 12219 sgd_solver.cpp:136] Iteration 201800, lr = 0.0369375, m = 0.9
I0801 23:45:45.845078 12219 solver.cpp:353] Iteration 201900 (7.10999 iter/s, 14.0647s/100 iter), loss = 1.48527
I0801 23:45:45.845104 12219 solver.cpp:375]     Train net output #0: loss = 1.53998 (* 1 = 1.53998 loss)
I0801 23:45:45.845110 12219 sgd_solver.cpp:136] Iteration 201900, lr = 0.0369062, m = 0.9
I0801 23:45:59.784103 12219 solver.cpp:550] Iteration 202000, Testing net (#0)
I0801 23:46:10.409713 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0801 23:46:20.288274 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.479471
I0801 23:46:20.288296 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.731881
I0801 23:46:20.288303 12219 solver.cpp:635]     Test net output #2: loss = 2.34326 (* 1 = 2.34326 loss)
I0801 23:46:20.288341 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.5037s
I0801 23:46:20.437726 12219 solver.cpp:353] Iteration 202000 (2.89087 iter/s, 34.5917s/100 iter), loss = 1.93525
I0801 23:46:20.437753 12219 solver.cpp:375]     Train net output #0: loss = 1.91418 (* 1 = 1.91418 loss)
I0801 23:46:20.437759 12219 sgd_solver.cpp:136] Iteration 202000, lr = 0.036875, m = 0.9
I0801 23:46:34.388499 12219 solver.cpp:353] Iteration 202100 (7.16826 iter/s, 13.9504s/100 iter), loss = 1.76924
I0801 23:46:34.388725 12219 solver.cpp:375]     Train net output #0: loss = 1.8274 (* 1 = 1.8274 loss)
I0801 23:46:34.388857 12219 sgd_solver.cpp:136] Iteration 202100, lr = 0.0368438, m = 0.9
I0801 23:46:48.471436 12219 solver.cpp:353] Iteration 202200 (7.10098 iter/s, 14.0826s/100 iter), loss = 1.89553
I0801 23:46:48.471587 12219 solver.cpp:375]     Train net output #0: loss = 2.08338 (* 1 = 2.08338 loss)
I0801 23:46:48.471607 12219 sgd_solver.cpp:136] Iteration 202200, lr = 0.0368125, m = 0.9
I0801 23:47:02.525296 12219 solver.cpp:353] Iteration 202300 (7.11568 iter/s, 14.0535s/100 iter), loss = 1.97181
I0801 23:47:02.525321 12219 solver.cpp:375]     Train net output #0: loss = 1.98734 (* 1 = 1.98734 loss)
I0801 23:47:02.525326 12219 sgd_solver.cpp:136] Iteration 202300, lr = 0.0367813, m = 0.9
I0801 23:47:16.553654 12219 solver.cpp:353] Iteration 202400 (7.12861 iter/s, 14.028s/100 iter), loss = 1.88902
I0801 23:47:16.553706 12219 solver.cpp:375]     Train net output #0: loss = 1.37307 (* 1 = 1.37307 loss)
I0801 23:47:16.553719 12219 sgd_solver.cpp:136] Iteration 202400, lr = 0.03675, m = 0.9
I0801 23:47:30.546716 12219 solver.cpp:353] Iteration 202500 (7.14659 iter/s, 13.9927s/100 iter), loss = 1.98387
I0801 23:47:30.546797 12219 solver.cpp:375]     Train net output #0: loss = 1.78455 (* 1 = 1.78455 loss)
I0801 23:47:30.546803 12219 sgd_solver.cpp:136] Iteration 202500, lr = 0.0367188, m = 0.9
I0801 23:47:44.531405 12219 solver.cpp:353] Iteration 202600 (7.15087 iter/s, 13.9843s/100 iter), loss = 1.45889
I0801 23:47:44.531440 12219 solver.cpp:375]     Train net output #0: loss = 1.45924 (* 1 = 1.45924 loss)
I0801 23:47:44.531446 12219 sgd_solver.cpp:136] Iteration 202600, lr = 0.0366875, m = 0.9
I0801 23:47:58.531507 12219 solver.cpp:353] Iteration 202700 (7.143 iter/s, 13.9997s/100 iter), loss = 1.65938
I0801 23:47:58.531569 12219 solver.cpp:375]     Train net output #0: loss = 1.75853 (* 1 = 1.75853 loss)
I0801 23:47:58.531580 12219 sgd_solver.cpp:136] Iteration 202700, lr = 0.0366562, m = 0.9
I0801 23:48:12.650301 12219 solver.cpp:353] Iteration 202800 (7.08295 iter/s, 14.1184s/100 iter), loss = 2.10007
I0801 23:48:12.650354 12219 solver.cpp:375]     Train net output #0: loss = 2.19079 (* 1 = 2.19079 loss)
I0801 23:48:12.650360 12219 sgd_solver.cpp:136] Iteration 202800, lr = 0.036625, m = 0.9
I0801 23:48:26.758944 12219 solver.cpp:353] Iteration 202900 (7.08805 iter/s, 14.1083s/100 iter), loss = 1.73567
I0801 23:48:26.758973 12219 solver.cpp:375]     Train net output #0: loss = 1.56183 (* 1 = 1.56183 loss)
I0801 23:48:26.758977 12219 sgd_solver.cpp:136] Iteration 202900, lr = 0.0365937, m = 0.9
I0801 23:48:40.774130 12219 solver.cpp:353] Iteration 203000 (7.13531 iter/s, 14.0148s/100 iter), loss = 1.44166
I0801 23:48:40.774389 12219 solver.cpp:375]     Train net output #0: loss = 1.58965 (* 1 = 1.58965 loss)
I0801 23:48:40.774507 12219 sgd_solver.cpp:136] Iteration 203000, lr = 0.0365625, m = 0.9
I0801 23:48:54.748096 12219 solver.cpp:353] Iteration 203100 (7.15636 iter/s, 13.9736s/100 iter), loss = 1.3894
I0801 23:48:54.748172 12219 solver.cpp:375]     Train net output #0: loss = 1.16304 (* 1 = 1.16304 loss)
I0801 23:48:54.748179 12219 sgd_solver.cpp:136] Iteration 203100, lr = 0.0365313, m = 0.9
I0801 23:49:08.754698 12219 solver.cpp:353] Iteration 203200 (7.13969 iter/s, 14.0062s/100 iter), loss = 1.93217
I0801 23:49:08.754731 12219 solver.cpp:375]     Train net output #0: loss = 2.13169 (* 1 = 2.13169 loss)
I0801 23:49:08.754735 12219 sgd_solver.cpp:136] Iteration 203200, lr = 0.0365, m = 0.9
I0801 23:49:22.863350 12219 solver.cpp:353] Iteration 203300 (7.08804 iter/s, 14.1083s/100 iter), loss = 1.90168
I0801 23:49:22.863379 12219 solver.cpp:375]     Train net output #0: loss = 2.19673 (* 1 = 2.19673 loss)
I0801 23:49:22.863386 12219 sgd_solver.cpp:136] Iteration 203300, lr = 0.0364688, m = 0.9
I0801 23:49:36.976804 12219 solver.cpp:353] Iteration 203400 (7.08563 iter/s, 14.1131s/100 iter), loss = 2.27833
I0801 23:49:36.976867 12219 solver.cpp:375]     Train net output #0: loss = 2.36134 (* 1 = 2.36134 loss)
I0801 23:49:36.976874 12219 sgd_solver.cpp:136] Iteration 203400, lr = 0.0364375, m = 0.9
I0801 23:49:51.027391 12219 solver.cpp:353] Iteration 203500 (7.11733 iter/s, 14.0502s/100 iter), loss = 2.00209
I0801 23:49:51.027418 12219 solver.cpp:375]     Train net output #0: loss = 2.27043 (* 1 = 2.27043 loss)
I0801 23:49:51.027458 12219 sgd_solver.cpp:136] Iteration 203500, lr = 0.0364062, m = 0.9
I0801 23:50:05.112920 12219 solver.cpp:353] Iteration 203600 (7.09968 iter/s, 14.0851s/100 iter), loss = 1.97098
I0801 23:50:05.112947 12219 solver.cpp:375]     Train net output #0: loss = 2.1724 (* 1 = 2.1724 loss)
I0801 23:50:05.112953 12219 sgd_solver.cpp:136] Iteration 203600, lr = 0.036375, m = 0.9
I0801 23:50:19.005376 12219 solver.cpp:353] Iteration 203700 (7.19835 iter/s, 13.8921s/100 iter), loss = 2.16694
I0801 23:50:19.005455 12219 solver.cpp:375]     Train net output #0: loss = 2.29867 (* 1 = 2.29867 loss)
I0801 23:50:19.005461 12219 sgd_solver.cpp:136] Iteration 203700, lr = 0.0363437, m = 0.9
I0801 23:50:33.031524 12219 solver.cpp:353] Iteration 203800 (7.12973 iter/s, 14.0258s/100 iter), loss = 1.59091
I0801 23:50:33.031615 12219 solver.cpp:375]     Train net output #0: loss = 1.64638 (* 1 = 1.64638 loss)
I0801 23:50:33.031633 12219 sgd_solver.cpp:136] Iteration 203800, lr = 0.0363125, m = 0.9
I0801 23:50:46.972761 12219 solver.cpp:353] Iteration 203900 (7.17316 iter/s, 13.9409s/100 iter), loss = 1.81399
I0801 23:50:46.972790 12219 solver.cpp:375]     Train net output #0: loss = 1.41924 (* 1 = 1.41924 loss)
I0801 23:50:46.972867 12219 sgd_solver.cpp:136] Iteration 203900, lr = 0.0362813, m = 0.9
I0801 23:51:00.835495 12219 solver.cpp:550] Iteration 204000, Testing net (#0)
I0801 23:51:20.675529 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.488
I0801 23:51:20.675554 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.736116
I0801 23:51:20.675561 12219 solver.cpp:635]     Test net output #2: loss = 2.30459 (* 1 = 2.30459 loss)
I0801 23:51:20.675580 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8396s
I0801 23:51:20.826382 12219 solver.cpp:353] Iteration 204000 (2.95397 iter/s, 33.8527s/100 iter), loss = 2.24989
I0801 23:51:20.826412 12219 solver.cpp:375]     Train net output #0: loss = 2.00462 (* 1 = 2.00462 loss)
I0801 23:51:20.826418 12219 sgd_solver.cpp:136] Iteration 204000, lr = 0.03625, m = 0.9
I0801 23:51:34.772768 12219 solver.cpp:353] Iteration 204100 (7.17052 iter/s, 13.946s/100 iter), loss = 1.86518
I0801 23:51:34.776919 12219 solver.cpp:375]     Train net output #0: loss = 1.98793 (* 1 = 1.98793 loss)
I0801 23:51:34.776952 12219 sgd_solver.cpp:136] Iteration 204100, lr = 0.0362188, m = 0.9
I0801 23:51:48.792150 12219 solver.cpp:353] Iteration 204200 (7.13318 iter/s, 14.019s/100 iter), loss = 1.83654
I0801 23:51:48.792182 12219 solver.cpp:375]     Train net output #0: loss = 1.55704 (* 1 = 1.55704 loss)
I0801 23:51:48.792186 12219 sgd_solver.cpp:136] Iteration 204200, lr = 0.0361875, m = 0.9
I0801 23:52:02.793992 12219 solver.cpp:353] Iteration 204300 (7.14211 iter/s, 14.0015s/100 iter), loss = 1.89087
I0801 23:52:02.794054 12219 solver.cpp:375]     Train net output #0: loss = 1.93148 (* 1 = 1.93148 loss)
I0801 23:52:02.794070 12219 sgd_solver.cpp:136] Iteration 204300, lr = 0.0361562, m = 0.9
I0801 23:52:16.907379 12219 solver.cpp:353] Iteration 204400 (7.08567 iter/s, 14.113s/100 iter), loss = 1.94243
I0801 23:52:16.907541 12219 solver.cpp:375]     Train net output #0: loss = 2.21024 (* 1 = 2.21024 loss)
I0801 23:52:16.907563 12219 sgd_solver.cpp:136] Iteration 204400, lr = 0.036125, m = 0.9
I0801 23:52:30.927996 12219 solver.cpp:353] Iteration 204500 (7.13255 iter/s, 14.0202s/100 iter), loss = 1.90459
I0801 23:52:30.928072 12219 solver.cpp:375]     Train net output #0: loss = 1.92992 (* 1 = 1.92992 loss)
I0801 23:52:30.928094 12219 sgd_solver.cpp:136] Iteration 204500, lr = 0.0360937, m = 0.9
I0801 23:52:44.842083 12219 solver.cpp:353] Iteration 204600 (7.18716 iter/s, 13.9137s/100 iter), loss = 1.43197
I0801 23:52:44.842125 12219 solver.cpp:375]     Train net output #0: loss = 1.75026 (* 1 = 1.75026 loss)
I0801 23:52:44.842133 12219 sgd_solver.cpp:136] Iteration 204600, lr = 0.0360625, m = 0.9
I0801 23:52:58.809018 12219 solver.cpp:353] Iteration 204700 (7.15996 iter/s, 13.9666s/100 iter), loss = 1.82439
I0801 23:52:58.809084 12219 solver.cpp:375]     Train net output #0: loss = 2.10714 (* 1 = 2.10714 loss)
I0801 23:52:58.809092 12219 sgd_solver.cpp:136] Iteration 204700, lr = 0.0360313, m = 0.9
I0801 23:53:12.881636 12219 solver.cpp:353] Iteration 204800 (7.10619 iter/s, 14.0722s/100 iter), loss = 1.6846
I0801 23:53:12.881707 12219 solver.cpp:375]     Train net output #0: loss = 1.53179 (* 1 = 1.53179 loss)
I0801 23:53:12.881726 12219 sgd_solver.cpp:136] Iteration 204800, lr = 0.036, m = 0.9
I0801 23:53:26.844840 12219 solver.cpp:353] Iteration 204900 (7.16188 iter/s, 13.9628s/100 iter), loss = 2.17068
I0801 23:53:26.848848 12219 solver.cpp:375]     Train net output #0: loss = 2.48065 (* 1 = 2.48065 loss)
I0801 23:53:26.848856 12219 sgd_solver.cpp:136] Iteration 204900, lr = 0.0359688, m = 0.9
I0801 23:53:40.791401 12219 solver.cpp:353] Iteration 205000 (7.17042 iter/s, 13.9462s/100 iter), loss = 1.89027
I0801 23:53:40.791461 12219 solver.cpp:375]     Train net output #0: loss = 1.77527 (* 1 = 1.77527 loss)
I0801 23:53:40.791468 12219 sgd_solver.cpp:136] Iteration 205000, lr = 0.0359375, m = 0.9
I0801 23:53:54.767511 12219 solver.cpp:353] Iteration 205100 (7.15526 iter/s, 13.9757s/100 iter), loss = 1.85392
I0801 23:53:54.767539 12219 solver.cpp:375]     Train net output #0: loss = 1.87069 (* 1 = 1.87069 loss)
I0801 23:53:54.767542 12219 sgd_solver.cpp:136] Iteration 205100, lr = 0.0359063, m = 0.9
I0801 23:54:08.744184 12219 solver.cpp:353] Iteration 205200 (7.15497 iter/s, 13.9763s/100 iter), loss = 2.19855
I0801 23:54:08.744212 12219 solver.cpp:375]     Train net output #0: loss = 1.87813 (* 1 = 1.87813 loss)
I0801 23:54:08.744216 12219 sgd_solver.cpp:136] Iteration 205200, lr = 0.035875, m = 0.9
I0801 23:54:22.802673 12219 solver.cpp:353] Iteration 205300 (7.11333 iter/s, 14.0581s/100 iter), loss = 1.86322
I0801 23:54:22.802734 12219 solver.cpp:375]     Train net output #0: loss = 1.99897 (* 1 = 1.99897 loss)
I0801 23:54:22.802743 12219 sgd_solver.cpp:136] Iteration 205300, lr = 0.0358437, m = 0.9
I0801 23:54:36.756706 12219 solver.cpp:353] Iteration 205400 (7.16658 iter/s, 13.9537s/100 iter), loss = 1.89612
I0801 23:54:36.756731 12219 solver.cpp:375]     Train net output #0: loss = 1.76567 (* 1 = 1.76567 loss)
I0801 23:54:36.756736 12219 sgd_solver.cpp:136] Iteration 205400, lr = 0.0358125, m = 0.9
I0801 23:54:50.701516 12219 solver.cpp:353] Iteration 205500 (7.17132 iter/s, 13.9444s/100 iter), loss = 1.4548
I0801 23:54:50.701545 12219 solver.cpp:375]     Train net output #0: loss = 1.38172 (* 1 = 1.38172 loss)
I0801 23:54:50.701550 12219 sgd_solver.cpp:136] Iteration 205500, lr = 0.0357813, m = 0.9
I0801 23:55:04.570350 12219 solver.cpp:353] Iteration 205600 (7.21061 iter/s, 13.8685s/100 iter), loss = 1.92365
I0801 23:55:04.570438 12219 solver.cpp:375]     Train net output #0: loss = 2.03953 (* 1 = 2.03953 loss)
I0801 23:55:04.570446 12219 sgd_solver.cpp:136] Iteration 205600, lr = 0.03575, m = 0.9
I0801 23:55:18.475947 12219 solver.cpp:353] Iteration 205700 (7.19154 iter/s, 13.9052s/100 iter), loss = 2.02579
I0801 23:55:18.475977 12219 solver.cpp:375]     Train net output #0: loss = 1.87675 (* 1 = 1.87675 loss)
I0801 23:55:18.475985 12219 sgd_solver.cpp:136] Iteration 205700, lr = 0.0357188, m = 0.9
I0801 23:55:32.484563 12219 solver.cpp:353] Iteration 205800 (7.13866 iter/s, 14.0082s/100 iter), loss = 1.92295
I0801 23:55:32.484591 12219 solver.cpp:375]     Train net output #0: loss = 2.09537 (* 1 = 2.09537 loss)
I0801 23:55:32.484596 12219 sgd_solver.cpp:136] Iteration 205800, lr = 0.0356875, m = 0.9
I0801 23:55:46.408974 12219 solver.cpp:353] Iteration 205900 (7.18183 iter/s, 13.924s/100 iter), loss = 1.66888
I0801 23:55:46.409039 12219 solver.cpp:375]     Train net output #0: loss = 1.63821 (* 1 = 1.63821 loss)
I0801 23:55:46.409045 12219 sgd_solver.cpp:136] Iteration 205900, lr = 0.0356563, m = 0.9
I0801 23:56:00.135802 12219 solver.cpp:550] Iteration 206000, Testing net (#0)
I0801 23:56:19.737778 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.474294
I0801 23:56:19.737881 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.727116
I0801 23:56:19.737890 12219 solver.cpp:635]     Test net output #2: loss = 2.35087 (* 1 = 2.35087 loss)
I0801 23:56:19.737910 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6016s
I0801 23:56:19.879307 12219 solver.cpp:353] Iteration 206000 (2.9878 iter/s, 33.4694s/100 iter), loss = 2.14351
I0801 23:56:19.879330 12219 solver.cpp:375]     Train net output #0: loss = 2.13917 (* 1 = 2.13917 loss)
I0801 23:56:19.879334 12219 sgd_solver.cpp:136] Iteration 206000, lr = 0.035625, m = 0.9
I0801 23:56:34.011899 12219 solver.cpp:353] Iteration 206100 (7.07604 iter/s, 14.1322s/100 iter), loss = 1.86534
I0801 23:56:34.011927 12219 solver.cpp:375]     Train net output #0: loss = 1.64871 (* 1 = 1.64871 loss)
I0801 23:56:34.011934 12219 sgd_solver.cpp:136] Iteration 206100, lr = 0.0355937, m = 0.9
I0801 23:56:48.136569 12219 solver.cpp:353] Iteration 206200 (7.08001 iter/s, 14.1243s/100 iter), loss = 1.4619
I0801 23:56:48.136615 12219 solver.cpp:375]     Train net output #0: loss = 1.73076 (* 1 = 1.73076 loss)
I0801 23:56:48.136629 12219 sgd_solver.cpp:136] Iteration 206200, lr = 0.0355625, m = 0.9
I0801 23:57:02.217290 12219 solver.cpp:353] Iteration 206300 (7.1021 iter/s, 14.0803s/100 iter), loss = 2.03266
I0801 23:57:02.217344 12219 solver.cpp:375]     Train net output #0: loss = 1.71984 (* 1 = 1.71984 loss)
I0801 23:57:02.217348 12219 sgd_solver.cpp:136] Iteration 206300, lr = 0.0355313, m = 0.9
I0801 23:57:16.209775 12219 solver.cpp:353] Iteration 206400 (7.14689 iter/s, 13.9921s/100 iter), loss = 1.81765
I0801 23:57:16.210039 12219 solver.cpp:375]     Train net output #0: loss = 1.50295 (* 1 = 1.50295 loss)
I0801 23:57:16.210155 12219 sgd_solver.cpp:136] Iteration 206400, lr = 0.0355, m = 0.9
I0801 23:57:30.249003 12219 solver.cpp:353] Iteration 206500 (7.12309 iter/s, 14.0388s/100 iter), loss = 1.80538
I0801 23:57:30.249037 12219 solver.cpp:375]     Train net output #0: loss = 1.63031 (* 1 = 1.63031 loss)
I0801 23:57:30.249043 12219 sgd_solver.cpp:136] Iteration 206500, lr = 0.0354688, m = 0.9
I0801 23:57:44.409569 12219 solver.cpp:353] Iteration 206600 (7.06206 iter/s, 14.1602s/100 iter), loss = 1.73228
I0801 23:57:44.409664 12219 solver.cpp:375]     Train net output #0: loss = 1.67546 (* 1 = 1.67546 loss)
I0801 23:57:44.409672 12219 sgd_solver.cpp:136] Iteration 206600, lr = 0.0354375, m = 0.9
I0801 23:57:58.560420 12219 solver.cpp:353] Iteration 206700 (7.0669 iter/s, 14.1505s/100 iter), loss = 1.79655
I0801 23:57:58.560475 12219 solver.cpp:375]     Train net output #0: loss = 1.92235 (* 1 = 1.92235 loss)
I0801 23:57:58.560487 12219 sgd_solver.cpp:136] Iteration 206700, lr = 0.0354063, m = 0.9
I0801 23:58:12.560335 12219 solver.cpp:353] Iteration 206800 (7.14309 iter/s, 13.9995s/100 iter), loss = 2.05464
I0801 23:58:12.560358 12219 solver.cpp:375]     Train net output #0: loss = 2.17608 (* 1 = 2.17608 loss)
I0801 23:58:12.560361 12219 sgd_solver.cpp:136] Iteration 206800, lr = 0.035375, m = 0.9
I0801 23:58:26.491551 12219 solver.cpp:353] Iteration 206900 (7.17832 iter/s, 13.9308s/100 iter), loss = 1.43997
I0801 23:58:26.491632 12219 solver.cpp:375]     Train net output #0: loss = 1.69593 (* 1 = 1.69593 loss)
I0801 23:58:26.491639 12219 sgd_solver.cpp:136] Iteration 206900, lr = 0.0353437, m = 0.9
I0801 23:58:40.508438 12219 solver.cpp:353] Iteration 207000 (7.13444 iter/s, 14.0165s/100 iter), loss = 1.81485
I0801 23:58:40.508466 12219 solver.cpp:375]     Train net output #0: loss = 1.77038 (* 1 = 1.77038 loss)
I0801 23:58:40.508472 12219 sgd_solver.cpp:136] Iteration 207000, lr = 0.0353125, m = 0.9
I0801 23:58:54.647068 12219 solver.cpp:353] Iteration 207100 (7.07302 iter/s, 14.1382s/100 iter), loss = 2.1651
I0801 23:58:54.647099 12219 solver.cpp:375]     Train net output #0: loss = 2.14188 (* 1 = 2.14188 loss)
I0801 23:58:54.647106 12219 sgd_solver.cpp:136] Iteration 207100, lr = 0.0352813, m = 0.9
I0801 23:59:08.751713 12219 solver.cpp:353] Iteration 207200 (7.09006 iter/s, 14.1043s/100 iter), loss = 1.63211
I0801 23:59:08.751816 12219 solver.cpp:375]     Train net output #0: loss = 1.71879 (* 1 = 1.71879 loss)
I0801 23:59:08.751837 12219 sgd_solver.cpp:136] Iteration 207200, lr = 0.03525, m = 0.9
I0801 23:59:22.761256 12219 solver.cpp:353] Iteration 207300 (7.13819 iter/s, 14.0092s/100 iter), loss = 1.51988
I0801 23:59:22.761284 12219 solver.cpp:375]     Train net output #0: loss = 1.43568 (* 1 = 1.43568 loss)
I0801 23:59:22.761291 12219 sgd_solver.cpp:136] Iteration 207300, lr = 0.0352188, m = 0.9
I0801 23:59:36.797031 12219 solver.cpp:353] Iteration 207400 (7.12484 iter/s, 14.0354s/100 iter), loss = 1.48436
I0801 23:59:36.797055 12219 solver.cpp:375]     Train net output #0: loss = 1.56353 (* 1 = 1.56353 loss)
I0801 23:59:36.797060 12219 sgd_solver.cpp:136] Iteration 207400, lr = 0.0351875, m = 0.9
I0801 23:59:50.912417 12219 solver.cpp:353] Iteration 207500 (7.08466 iter/s, 14.115s/100 iter), loss = 1.46929
I0801 23:59:50.912495 12219 solver.cpp:375]     Train net output #0: loss = 1.64749 (* 1 = 1.64749 loss)
I0801 23:59:50.912503 12219 sgd_solver.cpp:136] Iteration 207500, lr = 0.0351562, m = 0.9
I0802 00:00:04.930624 12219 solver.cpp:353] Iteration 207600 (7.13377 iter/s, 14.0178s/100 iter), loss = 1.74709
I0802 00:00:04.930649 12219 solver.cpp:375]     Train net output #0: loss = 2.35305 (* 1 = 2.35305 loss)
I0802 00:00:04.930652 12219 sgd_solver.cpp:136] Iteration 207600, lr = 0.035125, m = 0.9
I0802 00:00:18.925660 12219 solver.cpp:353] Iteration 207700 (7.14558 iter/s, 13.9947s/100 iter), loss = 2.12865
I0802 00:00:18.925691 12219 solver.cpp:375]     Train net output #0: loss = 2.605 (* 1 = 2.605 loss)
I0802 00:00:18.925698 12219 sgd_solver.cpp:136] Iteration 207700, lr = 0.0350938, m = 0.9
I0802 00:00:32.899294 12219 solver.cpp:353] Iteration 207800 (7.15653 iter/s, 13.9733s/100 iter), loss = 1.78594
I0802 00:00:32.899395 12219 solver.cpp:375]     Train net output #0: loss = 1.73393 (* 1 = 1.73393 loss)
I0802 00:00:32.899401 12219 sgd_solver.cpp:136] Iteration 207800, lr = 0.0350625, m = 0.9
I0802 00:00:46.926026 12219 solver.cpp:353] Iteration 207900 (7.12944 iter/s, 14.0264s/100 iter), loss = 1.7387
I0802 00:00:46.926053 12219 solver.cpp:375]     Train net output #0: loss = 1.74573 (* 1 = 1.74573 loss)
I0802 00:00:46.926057 12219 sgd_solver.cpp:136] Iteration 207900, lr = 0.0350312, m = 0.9
I0802 00:01:00.820926 12219 solver.cpp:550] Iteration 208000, Testing net (#0)
I0802 00:01:13.950366 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 00:01:21.377889 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.490294
I0802 00:01:21.377923 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.743998
I0802 00:01:21.377931 12219 solver.cpp:635]     Test net output #2: loss = 2.28629 (* 1 = 2.28629 loss)
I0802 00:01:21.377959 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.5565s
I0802 00:01:21.532605 12219 solver.cpp:353] Iteration 208000 (2.8897 iter/s, 34.6056s/100 iter), loss = 1.89834
I0802 00:01:21.532634 12219 solver.cpp:375]     Train net output #0: loss = 1.97164 (* 1 = 1.97164 loss)
I0802 00:01:21.532639 12219 sgd_solver.cpp:136] Iteration 208000, lr = 0.035, m = 0.9
I0802 00:01:35.564556 12219 solver.cpp:353] Iteration 208100 (7.12679 iter/s, 14.0316s/100 iter), loss = 1.84008
I0802 00:01:35.564607 12219 solver.cpp:375]     Train net output #0: loss = 1.50499 (* 1 = 1.50499 loss)
I0802 00:01:35.564620 12219 sgd_solver.cpp:136] Iteration 208100, lr = 0.0349688, m = 0.9
I0802 00:01:49.606043 12219 solver.cpp:353] Iteration 208200 (7.12195 iter/s, 14.0411s/100 iter), loss = 1.52348
I0802 00:01:49.606127 12219 solver.cpp:375]     Train net output #0: loss = 1.93286 (* 1 = 1.93286 loss)
I0802 00:01:49.606133 12219 sgd_solver.cpp:136] Iteration 208200, lr = 0.0349375, m = 0.9
I0802 00:02:03.568416 12219 solver.cpp:353] Iteration 208300 (7.1623 iter/s, 13.962s/100 iter), loss = 1.61491
I0802 00:02:03.568441 12219 solver.cpp:375]     Train net output #0: loss = 1.65369 (* 1 = 1.65369 loss)
I0802 00:02:03.568446 12219 sgd_solver.cpp:136] Iteration 208300, lr = 0.0349062, m = 0.9
I0802 00:02:17.596153 12219 solver.cpp:353] Iteration 208400 (7.12893 iter/s, 14.0274s/100 iter), loss = 1.75183
I0802 00:02:17.596179 12219 solver.cpp:375]     Train net output #0: loss = 1.58486 (* 1 = 1.58486 loss)
I0802 00:02:17.596184 12219 sgd_solver.cpp:136] Iteration 208400, lr = 0.034875, m = 0.9
I0802 00:02:31.716339 12219 solver.cpp:353] Iteration 208500 (7.08225 iter/s, 14.1198s/100 iter), loss = 1.74465
I0802 00:02:31.716405 12219 solver.cpp:375]     Train net output #0: loss = 1.75291 (* 1 = 1.75291 loss)
I0802 00:02:31.716414 12219 sgd_solver.cpp:136] Iteration 208500, lr = 0.0348438, m = 0.9
I0802 00:02:45.767227 12219 solver.cpp:353] Iteration 208600 (7.11718 iter/s, 14.0505s/100 iter), loss = 2.08148
I0802 00:02:45.767412 12219 solver.cpp:375]     Train net output #0: loss = 1.81447 (* 1 = 1.81447 loss)
I0802 00:02:45.767433 12219 sgd_solver.cpp:136] Iteration 208600, lr = 0.0348125, m = 0.9
I0802 00:02:59.780582 12219 solver.cpp:353] Iteration 208700 (7.13624 iter/s, 14.013s/100 iter), loss = 1.86207
I0802 00:02:59.780609 12219 solver.cpp:375]     Train net output #0: loss = 1.89625 (* 1 = 1.89625 loss)
I0802 00:02:59.780614 12219 sgd_solver.cpp:136] Iteration 208700, lr = 0.0347812, m = 0.9
I0802 00:03:13.825637 12219 solver.cpp:353] Iteration 208800 (7.12014 iter/s, 14.0447s/100 iter), loss = 1.83727
I0802 00:03:13.825722 12219 solver.cpp:375]     Train net output #0: loss = 1.79578 (* 1 = 1.79578 loss)
I0802 00:03:13.825729 12219 sgd_solver.cpp:136] Iteration 208800, lr = 0.03475, m = 0.9
I0802 00:03:27.853989 12219 solver.cpp:353] Iteration 208900 (7.12862 iter/s, 14.028s/100 iter), loss = 2.13493
I0802 00:03:27.854020 12219 solver.cpp:375]     Train net output #0: loss = 2.30045 (* 1 = 2.30045 loss)
I0802 00:03:27.854027 12219 sgd_solver.cpp:136] Iteration 208900, lr = 0.0347188, m = 0.9
I0802 00:03:41.942134 12219 solver.cpp:353] Iteration 209000 (7.09836 iter/s, 14.0878s/100 iter), loss = 1.74355
I0802 00:03:41.942203 12219 solver.cpp:375]     Train net output #0: loss = 1.30672 (* 1 = 1.30672 loss)
I0802 00:03:41.942222 12219 sgd_solver.cpp:136] Iteration 209000, lr = 0.0346875, m = 0.9
I0802 00:03:55.945706 12219 solver.cpp:353] Iteration 209100 (7.14123 iter/s, 14.0032s/100 iter), loss = 1.62779
I0802 00:03:55.945832 12219 solver.cpp:375]     Train net output #0: loss = 1.42816 (* 1 = 1.42816 loss)
I0802 00:03:55.945863 12219 sgd_solver.cpp:136] Iteration 209100, lr = 0.0346563, m = 0.9
I0802 00:04:09.983088 12219 solver.cpp:353] Iteration 209200 (7.12403 iter/s, 14.037s/100 iter), loss = 1.45907
I0802 00:04:09.983113 12219 solver.cpp:375]     Train net output #0: loss = 1.24221 (* 1 = 1.24221 loss)
I0802 00:04:09.983116 12219 sgd_solver.cpp:136] Iteration 209200, lr = 0.034625, m = 0.9
I0802 00:04:23.941114 12219 solver.cpp:353] Iteration 209300 (7.16475 iter/s, 13.9572s/100 iter), loss = 1.52719
I0802 00:04:23.941139 12219 solver.cpp:375]     Train net output #0: loss = 1.49479 (* 1 = 1.49479 loss)
I0802 00:04:23.941144 12219 sgd_solver.cpp:136] Iteration 209300, lr = 0.0345937, m = 0.9
I0802 00:04:38.061544 12219 solver.cpp:353] Iteration 209400 (7.08213 iter/s, 14.12s/100 iter), loss = 1.64945
I0802 00:04:38.061628 12219 solver.cpp:375]     Train net output #0: loss = 1.82443 (* 1 = 1.82443 loss)
I0802 00:04:38.061635 12219 sgd_solver.cpp:136] Iteration 209400, lr = 0.0345625, m = 0.9
I0802 00:04:51.958736 12219 solver.cpp:353] Iteration 209500 (7.19589 iter/s, 13.8968s/100 iter), loss = 1.70098
I0802 00:04:51.958765 12219 solver.cpp:375]     Train net output #0: loss = 1.79933 (* 1 = 1.79933 loss)
I0802 00:04:51.958771 12219 sgd_solver.cpp:136] Iteration 209500, lr = 0.0345312, m = 0.9
I0802 00:05:05.962247 12219 solver.cpp:353] Iteration 209600 (7.14126 iter/s, 14.0031s/100 iter), loss = 2.02134
I0802 00:05:05.962276 12219 solver.cpp:375]     Train net output #0: loss = 1.67533 (* 1 = 1.67533 loss)
I0802 00:05:05.962283 12219 sgd_solver.cpp:136] Iteration 209600, lr = 0.0345, m = 0.9
I0802 00:05:19.931903 12219 solver.cpp:353] Iteration 209700 (7.15857 iter/s, 13.9693s/100 iter), loss = 1.67322
I0802 00:05:19.931955 12219 solver.cpp:375]     Train net output #0: loss = 1.68205 (* 1 = 1.68205 loss)
I0802 00:05:19.931962 12219 sgd_solver.cpp:136] Iteration 209700, lr = 0.0344688, m = 0.9
I0802 00:05:33.958758 12219 solver.cpp:353] Iteration 209800 (7.12937 iter/s, 14.0265s/100 iter), loss = 1.81332
I0802 00:05:33.958788 12219 solver.cpp:375]     Train net output #0: loss = 1.81716 (* 1 = 1.81716 loss)
I0802 00:05:33.958794 12219 sgd_solver.cpp:136] Iteration 209800, lr = 0.0344375, m = 0.9
I0802 00:05:48.058629 12219 solver.cpp:353] Iteration 209900 (7.09246 iter/s, 14.0995s/100 iter), loss = 1.6695
I0802 00:05:48.058656 12219 solver.cpp:375]     Train net output #0: loss = 1.86478 (* 1 = 1.86478 loss)
I0802 00:05:48.058661 12219 sgd_solver.cpp:136] Iteration 209900, lr = 0.0344063, m = 0.9
I0802 00:06:01.950541 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_210000.caffemodel
I0802 00:06:02.001655 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_210000.solverstate
I0802 00:06:02.008661 12219 solver.cpp:550] Iteration 210000, Testing net (#0)
I0802 00:06:21.642539 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.473
I0802 00:06:21.642560 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.719939
I0802 00:06:21.642565 12219 solver.cpp:635]     Test net output #2: loss = 2.39286 (* 1 = 2.39286 loss)
I0802 00:06:21.642583 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6334s
I0802 00:06:21.780586 12219 solver.cpp:353] Iteration 210000 (2.96551 iter/s, 33.721s/100 iter), loss = 1.93322
I0802 00:06:21.780614 12219 solver.cpp:375]     Train net output #0: loss = 1.63298 (* 1 = 1.63298 loss)
I0802 00:06:21.780620 12219 sgd_solver.cpp:136] Iteration 210000, lr = 0.034375, m = 0.9
I0802 00:06:35.700500 12219 solver.cpp:353] Iteration 210100 (7.18415 iter/s, 13.9195s/100 iter), loss = 1.74138
I0802 00:06:35.702945 12219 solver.cpp:375]     Train net output #0: loss = 2.18391 (* 1 = 2.18391 loss)
I0802 00:06:35.702967 12219 sgd_solver.cpp:136] Iteration 210100, lr = 0.0343437, m = 0.9
I0802 00:06:49.669046 12219 solver.cpp:353] Iteration 210200 (7.15914 iter/s, 13.9682s/100 iter), loss = 1.56683
I0802 00:06:49.669073 12219 solver.cpp:375]     Train net output #0: loss = 1.83529 (* 1 = 1.83529 loss)
I0802 00:06:49.669078 12219 sgd_solver.cpp:136] Iteration 210200, lr = 0.0343125, m = 0.9
I0802 00:07:03.726816 12219 solver.cpp:353] Iteration 210300 (7.1137 iter/s, 14.0574s/100 iter), loss = 1.962
I0802 00:07:03.726842 12219 solver.cpp:375]     Train net output #0: loss = 2.21345 (* 1 = 2.21345 loss)
I0802 00:07:03.726848 12219 sgd_solver.cpp:136] Iteration 210300, lr = 0.0342813, m = 0.9
I0802 00:07:17.752130 12219 solver.cpp:353] Iteration 210400 (7.13017 iter/s, 14.0249s/100 iter), loss = 1.73516
I0802 00:07:17.752343 12219 solver.cpp:375]     Train net output #0: loss = 1.81415 (* 1 = 1.81415 loss)
I0802 00:07:17.752364 12219 sgd_solver.cpp:136] Iteration 210400, lr = 0.03425, m = 0.9
I0802 00:07:31.696209 12219 solver.cpp:353] Iteration 210500 (7.17169 iter/s, 13.9437s/100 iter), loss = 1.77503
I0802 00:07:31.696235 12219 solver.cpp:375]     Train net output #0: loss = 1.81542 (* 1 = 1.81542 loss)
I0802 00:07:31.696241 12219 sgd_solver.cpp:136] Iteration 210500, lr = 0.0342188, m = 0.9
I0802 00:07:45.609071 12219 solver.cpp:353] Iteration 210600 (7.18779 iter/s, 13.9125s/100 iter), loss = 1.39064
I0802 00:07:45.609102 12219 solver.cpp:375]     Train net output #0: loss = 1.4578 (* 1 = 1.4578 loss)
I0802 00:07:45.609108 12219 sgd_solver.cpp:136] Iteration 210600, lr = 0.0341875, m = 0.9
I0802 00:07:59.623642 12219 solver.cpp:353] Iteration 210700 (7.13562 iter/s, 14.0142s/100 iter), loss = 1.77074
I0802 00:07:59.623735 12219 solver.cpp:375]     Train net output #0: loss = 1.743 (* 1 = 1.743 loss)
I0802 00:07:59.623742 12219 sgd_solver.cpp:136] Iteration 210700, lr = 0.0341563, m = 0.9
I0802 00:08:13.544750 12219 solver.cpp:353] Iteration 210800 (7.18353 iter/s, 13.9207s/100 iter), loss = 1.8467
I0802 00:08:13.544780 12219 solver.cpp:375]     Train net output #0: loss = 1.7589 (* 1 = 1.7589 loss)
I0802 00:08:13.544785 12219 sgd_solver.cpp:136] Iteration 210800, lr = 0.034125, m = 0.9
I0802 00:08:27.565845 12219 solver.cpp:353] Iteration 210900 (7.1323 iter/s, 14.0207s/100 iter), loss = 1.68059
I0802 00:08:27.565876 12219 solver.cpp:375]     Train net output #0: loss = 1.46822 (* 1 = 1.46822 loss)
I0802 00:08:27.565924 12219 sgd_solver.cpp:136] Iteration 210900, lr = 0.0340937, m = 0.9
I0802 00:08:41.592682 12219 solver.cpp:353] Iteration 211000 (7.12938 iter/s, 14.0265s/100 iter), loss = 1.64809
I0802 00:08:41.592741 12219 solver.cpp:375]     Train net output #0: loss = 1.60039 (* 1 = 1.60039 loss)
I0802 00:08:41.592748 12219 sgd_solver.cpp:136] Iteration 211000, lr = 0.0340625, m = 0.9
I0802 00:08:55.487473 12219 solver.cpp:353] Iteration 211100 (7.19714 iter/s, 13.8944s/100 iter), loss = 1.94506
I0802 00:08:55.487509 12219 solver.cpp:375]     Train net output #0: loss = 1.87722 (* 1 = 1.87722 loss)
I0802 00:08:55.487515 12219 sgd_solver.cpp:136] Iteration 211100, lr = 0.0340312, m = 0.9
I0802 00:09:09.552963 12219 solver.cpp:353] Iteration 211200 (7.10979 iter/s, 14.0651s/100 iter), loss = 1.80266
I0802 00:09:09.552999 12219 solver.cpp:375]     Train net output #0: loss = 2.01418 (* 1 = 2.01418 loss)
I0802 00:09:09.553004 12219 sgd_solver.cpp:136] Iteration 211200, lr = 0.034, m = 0.9
I0802 00:09:23.667201 12219 solver.cpp:353] Iteration 211300 (7.08524 iter/s, 14.1139s/100 iter), loss = 1.81755
I0802 00:09:23.667259 12219 solver.cpp:375]     Train net output #0: loss = 2.10811 (* 1 = 2.10811 loss)
I0802 00:09:23.667266 12219 sgd_solver.cpp:136] Iteration 211300, lr = 0.0339688, m = 0.9
I0802 00:09:37.641121 12219 solver.cpp:353] Iteration 211400 (7.15638 iter/s, 13.9735s/100 iter), loss = 1.50678
I0802 00:09:37.641146 12219 solver.cpp:375]     Train net output #0: loss = 1.50486 (* 1 = 1.50486 loss)
I0802 00:09:37.641150 12219 sgd_solver.cpp:136] Iteration 211400, lr = 0.0339375, m = 0.9
I0802 00:09:51.608220 12219 solver.cpp:353] Iteration 211500 (7.15988 iter/s, 13.9667s/100 iter), loss = 1.87737
I0802 00:09:51.608248 12219 solver.cpp:375]     Train net output #0: loss = 1.89803 (* 1 = 1.89803 loss)
I0802 00:09:51.608254 12219 sgd_solver.cpp:136] Iteration 211500, lr = 0.0339063, m = 0.9
I0802 00:10:05.565925 12219 solver.cpp:353] Iteration 211600 (7.1647 iter/s, 13.9573s/100 iter), loss = 1.41437
I0802 00:10:05.566007 12219 solver.cpp:375]     Train net output #0: loss = 1.14704 (* 1 = 1.14704 loss)
I0802 00:10:05.566021 12219 sgd_solver.cpp:136] Iteration 211600, lr = 0.033875, m = 0.9
I0802 00:10:19.549674 12219 solver.cpp:353] Iteration 211700 (7.15135 iter/s, 13.9834s/100 iter), loss = 1.55471
I0802 00:10:19.549703 12219 solver.cpp:375]     Train net output #0: loss = 1.92061 (* 1 = 1.92061 loss)
I0802 00:10:19.549710 12219 sgd_solver.cpp:136] Iteration 211700, lr = 0.0338438, m = 0.9
I0802 00:10:33.494076 12219 solver.cpp:353] Iteration 211800 (7.17153 iter/s, 13.944s/100 iter), loss = 1.77462
I0802 00:10:33.494103 12219 solver.cpp:375]     Train net output #0: loss = 1.5951 (* 1 = 1.5951 loss)
I0802 00:10:33.494110 12219 sgd_solver.cpp:136] Iteration 211800, lr = 0.0338125, m = 0.9
I0802 00:10:47.483495 12219 solver.cpp:353] Iteration 211900 (7.14845 iter/s, 13.989s/100 iter), loss = 1.81638
I0802 00:10:47.483568 12219 solver.cpp:375]     Train net output #0: loss = 1.69261 (* 1 = 1.69261 loss)
I0802 00:10:47.483573 12219 sgd_solver.cpp:136] Iteration 211900, lr = 0.0337812, m = 0.9
I0802 00:11:01.254480 12219 solver.cpp:550] Iteration 212000, Testing net (#0)
I0802 00:11:21.052597 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.47747
I0802 00:11:21.052719 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.731528
I0802 00:11:21.052728 12219 solver.cpp:635]     Test net output #2: loss = 2.34036 (* 1 = 2.34036 loss)
I0802 00:11:21.052778 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7978s
I0802 00:11:21.201910 12219 solver.cpp:353] Iteration 212000 (2.96582 iter/s, 33.7175s/100 iter), loss = 1.68478
I0802 00:11:21.201937 12219 solver.cpp:375]     Train net output #0: loss = 1.96074 (* 1 = 1.96074 loss)
I0802 00:11:21.201943 12219 sgd_solver.cpp:136] Iteration 212000, lr = 0.03375, m = 0.9
I0802 00:11:35.113137 12219 solver.cpp:353] Iteration 212100 (7.18864 iter/s, 13.9108s/100 iter), loss = 2.01475
I0802 00:11:35.113174 12219 solver.cpp:375]     Train net output #0: loss = 1.93879 (* 1 = 1.93879 loss)
I0802 00:11:35.113179 12219 sgd_solver.cpp:136] Iteration 212100, lr = 0.0337188, m = 0.9
I0802 00:11:49.141785 12219 solver.cpp:353] Iteration 212200 (7.12846 iter/s, 14.0283s/100 iter), loss = 1.82555
I0802 00:11:49.141815 12219 solver.cpp:375]     Train net output #0: loss = 1.72388 (* 1 = 1.72388 loss)
I0802 00:11:49.141821 12219 sgd_solver.cpp:136] Iteration 212200, lr = 0.0336875, m = 0.9
I0802 00:12:03.153259 12219 solver.cpp:353] Iteration 212300 (7.1372 iter/s, 14.0111s/100 iter), loss = 1.93218
I0802 00:12:03.153326 12219 solver.cpp:375]     Train net output #0: loss = 1.81153 (* 1 = 1.81153 loss)
I0802 00:12:03.153337 12219 sgd_solver.cpp:136] Iteration 212300, lr = 0.0336563, m = 0.9
I0802 00:12:17.205561 12219 solver.cpp:353] Iteration 212400 (7.11647 iter/s, 14.0519s/100 iter), loss = 1.81635
I0802 00:12:17.205595 12219 solver.cpp:375]     Train net output #0: loss = 1.64496 (* 1 = 1.64496 loss)
I0802 00:12:17.205602 12219 sgd_solver.cpp:136] Iteration 212400, lr = 0.033625, m = 0.9
I0802 00:12:31.221168 12219 solver.cpp:353] Iteration 212500 (7.1351 iter/s, 14.0152s/100 iter), loss = 1.7463
I0802 00:12:31.221237 12219 solver.cpp:375]     Train net output #0: loss = 2.12974 (* 1 = 2.12974 loss)
I0802 00:12:31.221256 12219 sgd_solver.cpp:136] Iteration 212500, lr = 0.0335938, m = 0.9
I0802 00:12:45.204726 12219 solver.cpp:353] Iteration 212600 (7.15146 iter/s, 13.9832s/100 iter), loss = 1.88183
I0802 00:12:45.204812 12219 solver.cpp:375]     Train net output #0: loss = 1.99843 (* 1 = 1.99843 loss)
I0802 00:12:45.204831 12219 sgd_solver.cpp:136] Iteration 212600, lr = 0.0335625, m = 0.9
I0802 00:12:59.287375 12219 solver.cpp:353] Iteration 212700 (7.10113 iter/s, 14.0823s/100 iter), loss = 1.52008
I0802 00:12:59.287405 12219 solver.cpp:375]     Train net output #0: loss = 1.55057 (* 1 = 1.55057 loss)
I0802 00:12:59.287408 12219 sgd_solver.cpp:136] Iteration 212700, lr = 0.0335312, m = 0.9
I0802 00:13:13.328788 12219 solver.cpp:353] Iteration 212800 (7.12199 iter/s, 14.041s/100 iter), loss = 1.74555
I0802 00:13:13.328825 12219 solver.cpp:375]     Train net output #0: loss = 1.36943 (* 1 = 1.36943 loss)
I0802 00:13:13.328831 12219 sgd_solver.cpp:136] Iteration 212800, lr = 0.0335, m = 0.9
I0802 00:13:27.460808 12219 solver.cpp:353] Iteration 212900 (7.07632 iter/s, 14.1316s/100 iter), loss = 1.66136
I0802 00:13:27.461058 12219 solver.cpp:375]     Train net output #0: loss = 1.83775 (* 1 = 1.83775 loss)
I0802 00:13:27.461072 12219 sgd_solver.cpp:136] Iteration 212900, lr = 0.0334687, m = 0.9
I0802 00:13:41.446981 12219 solver.cpp:353] Iteration 213000 (7.15011 iter/s, 13.9858s/100 iter), loss = 2.06509
I0802 00:13:41.447011 12219 solver.cpp:375]     Train net output #0: loss = 2.31391 (* 1 = 2.31391 loss)
I0802 00:13:41.447017 12219 sgd_solver.cpp:136] Iteration 213000, lr = 0.0334375, m = 0.9
I0802 00:13:55.527724 12219 solver.cpp:353] Iteration 213100 (7.10209 iter/s, 14.0804s/100 iter), loss = 1.89421
I0802 00:13:55.527750 12219 solver.cpp:375]     Train net output #0: loss = 1.88099 (* 1 = 1.88099 loss)
I0802 00:13:55.527753 12219 sgd_solver.cpp:136] Iteration 213100, lr = 0.0334063, m = 0.9
I0802 00:14:09.817579 12219 solver.cpp:353] Iteration 213200 (6.99816 iter/s, 14.2895s/100 iter), loss = 2.04903
I0802 00:14:09.817664 12219 solver.cpp:375]     Train net output #0: loss = 2.02684 (* 1 = 2.02684 loss)
I0802 00:14:09.817672 12219 sgd_solver.cpp:136] Iteration 213200, lr = 0.033375, m = 0.9
I0802 00:14:23.873008 12219 solver.cpp:353] Iteration 213300 (7.11488 iter/s, 14.055s/100 iter), loss = 2.09762
I0802 00:14:23.873034 12219 solver.cpp:375]     Train net output #0: loss = 1.77202 (* 1 = 1.77202 loss)
I0802 00:14:23.873039 12219 sgd_solver.cpp:136] Iteration 213300, lr = 0.0333438, m = 0.9
I0802 00:14:37.934803 12219 solver.cpp:353] Iteration 213400 (7.11166 iter/s, 14.0614s/100 iter), loss = 1.53486
I0802 00:14:37.934833 12219 solver.cpp:375]     Train net output #0: loss = 1.73285 (* 1 = 1.73285 loss)
I0802 00:14:37.934839 12219 sgd_solver.cpp:136] Iteration 213400, lr = 0.0333125, m = 0.9
I0802 00:14:51.922212 12219 solver.cpp:353] Iteration 213500 (7.14949 iter/s, 13.987s/100 iter), loss = 1.78496
I0802 00:14:51.922300 12219 solver.cpp:375]     Train net output #0: loss = 1.88041 (* 1 = 1.88041 loss)
I0802 00:14:51.922307 12219 sgd_solver.cpp:136] Iteration 213500, lr = 0.0332812, m = 0.9
I0802 00:14:55.490025 12205 data_reader.cpp:264] Starting prefetch of epoch 5
I0802 00:15:05.911561 12219 solver.cpp:353] Iteration 213600 (7.1485 iter/s, 13.989s/100 iter), loss = 1.65082
I0802 00:15:05.911592 12219 solver.cpp:375]     Train net output #0: loss = 1.70939 (* 1 = 1.70939 loss)
I0802 00:15:05.911597 12219 sgd_solver.cpp:136] Iteration 213600, lr = 0.03325, m = 0.9
I0802 00:15:20.055415 12219 solver.cpp:353] Iteration 213700 (7.0704 iter/s, 14.1435s/100 iter), loss = 1.51736
I0802 00:15:20.055503 12219 solver.cpp:375]     Train net output #0: loss = 1.60493 (* 1 = 1.60493 loss)
I0802 00:15:20.055522 12219 sgd_solver.cpp:136] Iteration 213700, lr = 0.0332187, m = 0.9
I0802 00:15:34.165763 12219 solver.cpp:353] Iteration 213800 (7.08719 iter/s, 14.11s/100 iter), loss = 2.14416
I0802 00:15:34.165822 12219 solver.cpp:375]     Train net output #0: loss = 1.83168 (* 1 = 1.83168 loss)
I0802 00:15:34.165828 12219 sgd_solver.cpp:136] Iteration 213800, lr = 0.0331875, m = 0.9
I0802 00:15:48.222755 12219 solver.cpp:353] Iteration 213900 (7.11409 iter/s, 14.0566s/100 iter), loss = 1.98543
I0802 00:15:48.222781 12219 solver.cpp:375]     Train net output #0: loss = 2.44185 (* 1 = 2.44185 loss)
I0802 00:15:48.222786 12219 sgd_solver.cpp:136] Iteration 213900, lr = 0.0331563, m = 0.9
I0802 00:16:02.098343 12219 solver.cpp:550] Iteration 214000, Testing net (#0)
I0802 00:16:17.629925 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 00:16:22.192531 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.488706
I0802 00:16:22.192555 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.744822
I0802 00:16:22.192564 12219 solver.cpp:635]     Test net output #2: loss = 2.29637 (* 1 = 2.29637 loss)
I0802 00:16:22.204105 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0937s
I0802 00:16:22.341047 12219 solver.cpp:353] Iteration 214000 (2.93106 iter/s, 34.1174s/100 iter), loss = 1.13823
I0802 00:16:22.341119 12219 solver.cpp:375]     Train net output #0: loss = 1.30237 (* 1 = 1.30237 loss)
I0802 00:16:22.341132 12219 sgd_solver.cpp:136] Iteration 214000, lr = 0.033125, m = 0.9
I0802 00:16:36.446339 12219 solver.cpp:353] Iteration 214100 (7.08973 iter/s, 14.1049s/100 iter), loss = 1.72498
I0802 00:16:36.446377 12219 solver.cpp:375]     Train net output #0: loss = 1.74964 (* 1 = 1.74964 loss)
I0802 00:16:36.446382 12219 sgd_solver.cpp:136] Iteration 214100, lr = 0.0330938, m = 0.9
I0802 00:16:50.558899 12219 solver.cpp:353] Iteration 214200 (7.08608 iter/s, 14.1122s/100 iter), loss = 1.93958
I0802 00:16:50.558966 12219 solver.cpp:375]     Train net output #0: loss = 1.69879 (* 1 = 1.69879 loss)
I0802 00:16:50.558974 12219 sgd_solver.cpp:136] Iteration 214200, lr = 0.0330625, m = 0.9
I0802 00:17:04.571483 12219 solver.cpp:353] Iteration 214300 (7.13664 iter/s, 14.0122s/100 iter), loss = 1.44647
I0802 00:17:04.571535 12219 solver.cpp:375]     Train net output #0: loss = 1.22974 (* 1 = 1.22974 loss)
I0802 00:17:04.571548 12219 sgd_solver.cpp:136] Iteration 214300, lr = 0.0330313, m = 0.9
I0802 00:17:18.527185 12219 solver.cpp:353] Iteration 214400 (7.16573 iter/s, 13.9553s/100 iter), loss = 1.55314
I0802 00:17:18.527211 12219 solver.cpp:375]     Train net output #0: loss = 1.93694 (* 1 = 1.93694 loss)
I0802 00:17:18.527215 12219 sgd_solver.cpp:136] Iteration 214400, lr = 0.033, m = 0.9
I0802 00:17:32.608363 12219 solver.cpp:353] Iteration 214500 (7.10187 iter/s, 14.0808s/100 iter), loss = 1.30372
I0802 00:17:32.608418 12219 solver.cpp:375]     Train net output #0: loss = 1.67201 (* 1 = 1.67201 loss)
I0802 00:17:32.608423 12219 sgd_solver.cpp:136] Iteration 214500, lr = 0.0329687, m = 0.9
I0802 00:17:46.737532 12219 solver.cpp:353] Iteration 214600 (7.07775 iter/s, 14.1288s/100 iter), loss = 2.58633
I0802 00:17:46.737560 12219 solver.cpp:375]     Train net output #0: loss = 2.37721 (* 1 = 2.37721 loss)
I0802 00:17:46.737565 12219 sgd_solver.cpp:136] Iteration 214600, lr = 0.0329375, m = 0.9
I0802 00:18:00.812641 12219 solver.cpp:353] Iteration 214700 (7.10493 iter/s, 14.0747s/100 iter), loss = 2.02094
I0802 00:18:00.812667 12219 solver.cpp:375]     Train net output #0: loss = 1.84094 (* 1 = 1.84094 loss)
I0802 00:18:00.812674 12219 sgd_solver.cpp:136] Iteration 214700, lr = 0.0329063, m = 0.9
I0802 00:18:14.825825 12219 solver.cpp:353] Iteration 214800 (7.13633 iter/s, 14.0128s/100 iter), loss = 1.92064
I0802 00:18:14.825887 12219 solver.cpp:375]     Train net output #0: loss = 2.23727 (* 1 = 2.23727 loss)
I0802 00:18:14.825893 12219 sgd_solver.cpp:136] Iteration 214800, lr = 0.032875, m = 0.9
I0802 00:18:28.902568 12219 solver.cpp:353] Iteration 214900 (7.10411 iter/s, 14.0764s/100 iter), loss = 1.89131
I0802 00:18:28.902595 12219 solver.cpp:375]     Train net output #0: loss = 1.60951 (* 1 = 1.60951 loss)
I0802 00:18:28.902598 12219 sgd_solver.cpp:136] Iteration 214900, lr = 0.0328437, m = 0.9
I0802 00:18:42.939363 12219 solver.cpp:353] Iteration 215000 (7.12434 iter/s, 14.0364s/100 iter), loss = 1.6586
I0802 00:18:42.939393 12219 solver.cpp:375]     Train net output #0: loss = 1.51491 (* 1 = 1.51491 loss)
I0802 00:18:42.939399 12219 sgd_solver.cpp:136] Iteration 215000, lr = 0.0328125, m = 0.9
I0802 00:18:57.002001 12219 solver.cpp:353] Iteration 215100 (7.11124 iter/s, 14.0623s/100 iter), loss = 1.66613
I0802 00:18:57.002104 12219 solver.cpp:375]     Train net output #0: loss = 1.60734 (* 1 = 1.60734 loss)
I0802 00:18:57.002128 12219 sgd_solver.cpp:136] Iteration 215100, lr = 0.0327813, m = 0.9
I0802 00:19:11.144345 12219 solver.cpp:353] Iteration 215200 (7.07115 iter/s, 14.142s/100 iter), loss = 1.71004
I0802 00:19:11.144368 12219 solver.cpp:375]     Train net output #0: loss = 1.91301 (* 1 = 1.91301 loss)
I0802 00:19:11.144372 12219 sgd_solver.cpp:136] Iteration 215200, lr = 0.03275, m = 0.9
I0802 00:19:25.203054 12219 solver.cpp:353] Iteration 215300 (7.11322 iter/s, 14.0583s/100 iter), loss = 1.75502
I0802 00:19:25.203084 12219 solver.cpp:375]     Train net output #0: loss = 1.73971 (* 1 = 1.73971 loss)
I0802 00:19:25.203090 12219 sgd_solver.cpp:136] Iteration 215300, lr = 0.0327187, m = 0.9
I0802 00:19:39.197983 12219 solver.cpp:353] Iteration 215400 (7.14564 iter/s, 13.9945s/100 iter), loss = 2.42782
I0802 00:19:39.198052 12219 solver.cpp:375]     Train net output #0: loss = 2.14553 (* 1 = 2.14553 loss)
I0802 00:19:39.198060 12219 sgd_solver.cpp:136] Iteration 215400, lr = 0.0326875, m = 0.9
I0802 00:19:53.164899 12219 solver.cpp:353] Iteration 215500 (7.15997 iter/s, 13.9665s/100 iter), loss = 1.51538
I0802 00:19:53.164927 12219 solver.cpp:375]     Train net output #0: loss = 1.76079 (* 1 = 1.76079 loss)
I0802 00:19:53.164933 12219 sgd_solver.cpp:136] Iteration 215500, lr = 0.0326563, m = 0.9
I0802 00:20:07.189810 12219 solver.cpp:353] Iteration 215600 (7.13036 iter/s, 14.0245s/100 iter), loss = 1.99542
I0802 00:20:07.189838 12219 solver.cpp:375]     Train net output #0: loss = 2.14027 (* 1 = 2.14027 loss)
I0802 00:20:07.189843 12219 sgd_solver.cpp:136] Iteration 215600, lr = 0.032625, m = 0.9
I0802 00:20:21.166903 12219 solver.cpp:353] Iteration 215700 (7.15476 iter/s, 13.9767s/100 iter), loss = 1.95017
I0802 00:20:21.166983 12219 solver.cpp:375]     Train net output #0: loss = 1.57858 (* 1 = 1.57858 loss)
I0802 00:20:21.166990 12219 sgd_solver.cpp:136] Iteration 215700, lr = 0.0325938, m = 0.9
I0802 00:20:35.229521 12219 solver.cpp:353] Iteration 215800 (7.11124 iter/s, 14.0622s/100 iter), loss = 2.01726
I0802 00:20:35.229549 12219 solver.cpp:375]     Train net output #0: loss = 2.05042 (* 1 = 2.05042 loss)
I0802 00:20:35.229555 12219 sgd_solver.cpp:136] Iteration 215800, lr = 0.0325625, m = 0.9
I0802 00:20:49.314514 12219 solver.cpp:353] Iteration 215900 (7.09995 iter/s, 14.0846s/100 iter), loss = 1.77426
I0802 00:20:49.314584 12219 solver.cpp:375]     Train net output #0: loss = 2.04717 (* 1 = 2.04717 loss)
I0802 00:20:49.314602 12219 sgd_solver.cpp:136] Iteration 215900, lr = 0.0325313, m = 0.9
I0802 00:21:03.140334 12219 solver.cpp:550] Iteration 216000, Testing net (#0)
I0802 00:21:23.254184 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.490941
I0802 00:21:23.254261 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.741587
I0802 00:21:23.254281 12219 solver.cpp:635]     Test net output #2: loss = 2.26657 (* 1 = 2.26657 loss)
I0802 00:21:23.254313 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1134s
I0802 00:21:23.427337 12219 solver.cpp:353] Iteration 216000 (2.93153 iter/s, 34.1119s/100 iter), loss = 1.33044
I0802 00:21:23.427361 12219 solver.cpp:375]     Train net output #0: loss = 1.57461 (* 1 = 1.57461 loss)
I0802 00:21:23.427367 12219 sgd_solver.cpp:136] Iteration 216000, lr = 0.0325, m = 0.9
I0802 00:21:37.483837 12219 solver.cpp:353] Iteration 216100 (7.11434 iter/s, 14.0561s/100 iter), loss = 1.63414
I0802 00:21:37.483896 12219 solver.cpp:375]     Train net output #0: loss = 1.74354 (* 1 = 1.74354 loss)
I0802 00:21:37.483902 12219 sgd_solver.cpp:136] Iteration 216100, lr = 0.0324687, m = 0.9
I0802 00:21:51.471444 12219 solver.cpp:353] Iteration 216200 (7.14938 iter/s, 13.9872s/100 iter), loss = 1.5094
I0802 00:21:51.471480 12219 solver.cpp:375]     Train net output #0: loss = 1.55367 (* 1 = 1.55367 loss)
I0802 00:21:51.471487 12219 sgd_solver.cpp:136] Iteration 216200, lr = 0.0324375, m = 0.9
I0802 00:22:05.438621 12219 solver.cpp:353] Iteration 216300 (7.15984 iter/s, 13.9668s/100 iter), loss = 2.05632
I0802 00:22:05.438648 12219 solver.cpp:375]     Train net output #0: loss = 1.81739 (* 1 = 1.81739 loss)
I0802 00:22:05.438653 12219 sgd_solver.cpp:136] Iteration 216300, lr = 0.0324063, m = 0.9
I0802 00:22:19.408195 12219 solver.cpp:353] Iteration 216400 (7.15861 iter/s, 13.9692s/100 iter), loss = 1.69556
I0802 00:22:19.408272 12219 solver.cpp:375]     Train net output #0: loss = 1.89584 (* 1 = 1.89584 loss)
I0802 00:22:19.408279 12219 sgd_solver.cpp:136] Iteration 216400, lr = 0.032375, m = 0.9
I0802 00:22:33.573614 12219 solver.cpp:353] Iteration 216500 (7.05964 iter/s, 14.165s/100 iter), loss = 1.92711
I0802 00:22:33.573642 12219 solver.cpp:375]     Train net output #0: loss = 1.86666 (* 1 = 1.86666 loss)
I0802 00:22:33.573647 12219 sgd_solver.cpp:136] Iteration 216500, lr = 0.0323438, m = 0.9
I0802 00:22:47.672492 12219 solver.cpp:353] Iteration 216600 (7.09296 iter/s, 14.0985s/100 iter), loss = 2.03095
I0802 00:22:47.672520 12219 solver.cpp:375]     Train net output #0: loss = 2.21187 (* 1 = 2.21187 loss)
I0802 00:22:47.672526 12219 sgd_solver.cpp:136] Iteration 216600, lr = 0.0323125, m = 0.9
I0802 00:23:01.631074 12219 solver.cpp:353] Iteration 216700 (7.16425 iter/s, 13.9582s/100 iter), loss = 1.74153
I0802 00:23:01.631144 12219 solver.cpp:375]     Train net output #0: loss = 2.00878 (* 1 = 2.00878 loss)
I0802 00:23:01.631151 12219 sgd_solver.cpp:136] Iteration 216700, lr = 0.0322812, m = 0.9
I0802 00:23:15.602576 12219 solver.cpp:353] Iteration 216800 (7.15762 iter/s, 13.9711s/100 iter), loss = 1.74037
I0802 00:23:15.602605 12219 solver.cpp:375]     Train net output #0: loss = 1.95479 (* 1 = 1.95479 loss)
I0802 00:23:15.602612 12219 sgd_solver.cpp:136] Iteration 216800, lr = 0.03225, m = 0.9
I0802 00:23:29.583492 12219 solver.cpp:353] Iteration 216900 (7.1528 iter/s, 13.9805s/100 iter), loss = 1.45593
I0802 00:23:29.583516 12219 solver.cpp:375]     Train net output #0: loss = 1.19322 (* 1 = 1.19322 loss)
I0802 00:23:29.583520 12219 sgd_solver.cpp:136] Iteration 216900, lr = 0.0322188, m = 0.9
I0802 00:23:43.595213 12219 solver.cpp:353] Iteration 217000 (7.13707 iter/s, 14.0113s/100 iter), loss = 1.68765
I0802 00:23:43.595266 12219 solver.cpp:375]     Train net output #0: loss = 1.95971 (* 1 = 1.95971 loss)
I0802 00:23:43.595273 12219 sgd_solver.cpp:136] Iteration 217000, lr = 0.0321875, m = 0.9
I0802 00:23:57.624709 12219 solver.cpp:353] Iteration 217100 (7.12804 iter/s, 14.0291s/100 iter), loss = 1.78532
I0802 00:23:57.624802 12219 solver.cpp:375]     Train net output #0: loss = 1.74831 (* 1 = 1.74831 loss)
I0802 00:23:57.624828 12219 sgd_solver.cpp:136] Iteration 217100, lr = 0.0321563, m = 0.9
I0802 00:24:11.584089 12219 solver.cpp:353] Iteration 217200 (7.16384 iter/s, 13.959s/100 iter), loss = 1.58372
I0802 00:24:11.584117 12219 solver.cpp:375]     Train net output #0: loss = 1.65059 (* 1 = 1.65059 loss)
I0802 00:24:11.584123 12219 sgd_solver.cpp:136] Iteration 217200, lr = 0.032125, m = 0.9
I0802 00:24:25.467460 12219 solver.cpp:353] Iteration 217300 (7.20306 iter/s, 13.883s/100 iter), loss = 2.01902
I0802 00:24:25.467530 12219 solver.cpp:375]     Train net output #0: loss = 1.97101 (* 1 = 1.97101 loss)
I0802 00:24:25.467536 12219 sgd_solver.cpp:136] Iteration 217300, lr = 0.0320938, m = 0.9
I0802 00:24:39.375591 12219 solver.cpp:353] Iteration 217400 (7.19023 iter/s, 13.9078s/100 iter), loss = 2.04869
I0802 00:24:39.375618 12219 solver.cpp:375]     Train net output #0: loss = 1.87943 (* 1 = 1.87943 loss)
I0802 00:24:39.375624 12219 sgd_solver.cpp:136] Iteration 217400, lr = 0.0320625, m = 0.9
I0802 00:24:53.401860 12219 solver.cpp:353] Iteration 217500 (7.12967 iter/s, 14.0259s/100 iter), loss = 1.67412
I0802 00:24:53.401888 12219 solver.cpp:375]     Train net output #0: loss = 1.51924 (* 1 = 1.51924 loss)
I0802 00:24:53.401895 12219 sgd_solver.cpp:136] Iteration 217500, lr = 0.0320312, m = 0.9
I0802 00:25:07.346806 12219 solver.cpp:353] Iteration 217600 (7.17125 iter/s, 13.9446s/100 iter), loss = 2.08454
I0802 00:25:07.346873 12219 solver.cpp:375]     Train net output #0: loss = 1.85526 (* 1 = 1.85526 loss)
I0802 00:25:07.346879 12219 sgd_solver.cpp:136] Iteration 217600, lr = 0.032, m = 0.9
I0802 00:25:21.377975 12219 solver.cpp:353] Iteration 217700 (7.12718 iter/s, 14.0308s/100 iter), loss = 1.44855
I0802 00:25:21.378005 12219 solver.cpp:375]     Train net output #0: loss = 1.43001 (* 1 = 1.43001 loss)
I0802 00:25:21.378011 12219 sgd_solver.cpp:136] Iteration 217700, lr = 0.0319688, m = 0.9
I0802 00:25:35.334995 12219 solver.cpp:353] Iteration 217800 (7.16505 iter/s, 13.9566s/100 iter), loss = 1.95014
I0802 00:25:35.335021 12219 solver.cpp:375]     Train net output #0: loss = 2.08535 (* 1 = 2.08535 loss)
I0802 00:25:35.335024 12219 sgd_solver.cpp:136] Iteration 217800, lr = 0.0319375, m = 0.9
I0802 00:25:49.286010 12219 solver.cpp:353] Iteration 217900 (7.16813 iter/s, 13.9506s/100 iter), loss = 1.90035
I0802 00:25:49.286092 12219 solver.cpp:375]     Train net output #0: loss = 1.87553 (* 1 = 1.87553 loss)
I0802 00:25:49.286098 12219 sgd_solver.cpp:136] Iteration 217900, lr = 0.0319062, m = 0.9
I0802 00:26:03.124300 12219 solver.cpp:550] Iteration 218000, Testing net (#0)
I0802 00:26:23.317636 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.470235
I0802 00:26:23.317730 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.72941
I0802 00:26:23.317739 12219 solver.cpp:635]     Test net output #2: loss = 2.37482 (* 1 = 2.37482 loss)
I0802 00:26:23.317757 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1929s
I0802 00:26:23.468917 12219 solver.cpp:353] Iteration 218000 (2.92552 iter/s, 34.182s/100 iter), loss = 2.10725
I0802 00:26:23.468941 12219 solver.cpp:375]     Train net output #0: loss = 1.42356 (* 1 = 1.42356 loss)
I0802 00:26:23.468947 12219 sgd_solver.cpp:136] Iteration 218000, lr = 0.031875, m = 0.9
I0802 00:26:37.339376 12219 solver.cpp:353] Iteration 218100 (7.20976 iter/s, 13.8701s/100 iter), loss = 1.77058
I0802 00:26:37.339401 12219 solver.cpp:375]     Train net output #0: loss = 1.31309 (* 1 = 1.31309 loss)
I0802 00:26:37.339404 12219 sgd_solver.cpp:136] Iteration 218100, lr = 0.0318438, m = 0.9
I0802 00:26:51.400503 12219 solver.cpp:353] Iteration 218200 (7.112 iter/s, 14.0607s/100 iter), loss = 1.88698
I0802 00:26:51.400645 12219 solver.cpp:375]     Train net output #0: loss = 1.83631 (* 1 = 1.83631 loss)
I0802 00:26:51.400712 12219 sgd_solver.cpp:136] Iteration 218200, lr = 0.0318125, m = 0.9
I0802 00:27:05.441740 12219 solver.cpp:353] Iteration 218300 (7.12207 iter/s, 14.0409s/100 iter), loss = 1.80696
I0802 00:27:05.441839 12219 solver.cpp:375]     Train net output #0: loss = 1.69305 (* 1 = 1.69305 loss)
I0802 00:27:05.441848 12219 sgd_solver.cpp:136] Iteration 218300, lr = 0.0317813, m = 0.9
I0802 00:27:19.541967 12219 solver.cpp:353] Iteration 218400 (7.09228 iter/s, 14.0998s/100 iter), loss = 1.63512
I0802 00:27:19.541995 12219 solver.cpp:375]     Train net output #0: loss = 1.8462 (* 1 = 1.8462 loss)
I0802 00:27:19.542001 12219 sgd_solver.cpp:136] Iteration 218400, lr = 0.03175, m = 0.9
I0802 00:27:33.603891 12219 solver.cpp:353] Iteration 218500 (7.1116 iter/s, 14.0615s/100 iter), loss = 1.90758
I0802 00:27:33.603919 12219 solver.cpp:375]     Train net output #0: loss = 1.35343 (* 1 = 1.35343 loss)
I0802 00:27:33.603924 12219 sgd_solver.cpp:136] Iteration 218500, lr = 0.0317187, m = 0.9
I0802 00:27:47.575887 12219 solver.cpp:353] Iteration 218600 (7.15737 iter/s, 13.9716s/100 iter), loss = 1.58538
I0802 00:27:47.576011 12219 solver.cpp:375]     Train net output #0: loss = 1.63328 (* 1 = 1.63328 loss)
I0802 00:27:47.576031 12219 sgd_solver.cpp:136] Iteration 218600, lr = 0.0316875, m = 0.9
I0802 00:28:01.634690 12219 solver.cpp:353] Iteration 218700 (7.11317 iter/s, 14.0584s/100 iter), loss = 1.77386
I0802 00:28:01.634714 12219 solver.cpp:375]     Train net output #0: loss = 1.66746 (* 1 = 1.66746 loss)
I0802 00:28:01.634721 12219 sgd_solver.cpp:136] Iteration 218700, lr = 0.0316562, m = 0.9
I0802 00:28:15.738195 12219 solver.cpp:353] Iteration 218800 (7.09063 iter/s, 14.1031s/100 iter), loss = 1.9838
I0802 00:28:15.738224 12219 solver.cpp:375]     Train net output #0: loss = 2.13568 (* 1 = 2.13568 loss)
I0802 00:28:15.738229 12219 sgd_solver.cpp:136] Iteration 218800, lr = 0.031625, m = 0.9
I0802 00:28:29.918767 12219 solver.cpp:353] Iteration 218900 (7.05209 iter/s, 14.1802s/100 iter), loss = 2.3764
I0802 00:28:29.918895 12219 solver.cpp:375]     Train net output #0: loss = 2.06158 (* 1 = 2.06158 loss)
I0802 00:28:29.918913 12219 sgd_solver.cpp:136] Iteration 218900, lr = 0.0315938, m = 0.9
I0802 00:28:43.921036 12219 solver.cpp:353] Iteration 219000 (7.14189 iter/s, 14.0019s/100 iter), loss = 1.72227
I0802 00:28:43.921059 12219 solver.cpp:375]     Train net output #0: loss = 1.90201 (* 1 = 1.90201 loss)
I0802 00:28:43.921066 12219 sgd_solver.cpp:136] Iteration 219000, lr = 0.0315625, m = 0.9
I0802 00:28:57.782505 12219 solver.cpp:353] Iteration 219100 (7.21444 iter/s, 13.8611s/100 iter), loss = 1.70116
I0802 00:28:57.782531 12219 solver.cpp:375]     Train net output #0: loss = 1.51293 (* 1 = 1.51293 loss)
I0802 00:28:57.782536 12219 sgd_solver.cpp:136] Iteration 219100, lr = 0.0315313, m = 0.9
I0802 00:29:11.843806 12219 solver.cpp:353] Iteration 219200 (7.11191 iter/s, 14.0609s/100 iter), loss = 1.52575
I0802 00:29:11.843891 12219 solver.cpp:375]     Train net output #0: loss = 1.67298 (* 1 = 1.67298 loss)
I0802 00:29:11.843904 12219 sgd_solver.cpp:136] Iteration 219200, lr = 0.0315, m = 0.9
I0802 00:29:26.001891 12219 solver.cpp:353] Iteration 219300 (7.06329 iter/s, 14.1577s/100 iter), loss = 1.67666
I0802 00:29:26.001921 12219 solver.cpp:375]     Train net output #0: loss = 1.49777 (* 1 = 1.49777 loss)
I0802 00:29:26.001929 12219 sgd_solver.cpp:136] Iteration 219300, lr = 0.0314687, m = 0.9
I0802 00:29:40.093688 12219 solver.cpp:353] Iteration 219400 (7.09652 iter/s, 14.0914s/100 iter), loss = 1.88906
I0802 00:29:40.093713 12219 solver.cpp:375]     Train net output #0: loss = 2.08741 (* 1 = 2.08741 loss)
I0802 00:29:40.093716 12219 sgd_solver.cpp:136] Iteration 219400, lr = 0.0314375, m = 0.9
I0802 00:29:54.146466 12219 solver.cpp:353] Iteration 219500 (7.11623 iter/s, 14.0524s/100 iter), loss = 1.74991
I0802 00:29:54.146550 12219 solver.cpp:375]     Train net output #0: loss = 1.95242 (* 1 = 1.95242 loss)
I0802 00:29:54.146558 12219 sgd_solver.cpp:136] Iteration 219500, lr = 0.0314062, m = 0.9
I0802 00:30:08.105756 12219 solver.cpp:353] Iteration 219600 (7.16388 iter/s, 13.9589s/100 iter), loss = 1.56637
I0802 00:30:08.105784 12219 solver.cpp:375]     Train net output #0: loss = 1.60659 (* 1 = 1.60659 loss)
I0802 00:30:08.105790 12219 sgd_solver.cpp:136] Iteration 219600, lr = 0.031375, m = 0.9
I0802 00:30:22.229596 12219 solver.cpp:353] Iteration 219700 (7.08042 iter/s, 14.1235s/100 iter), loss = 1.65849
I0802 00:30:22.229622 12219 solver.cpp:375]     Train net output #0: loss = 1.69531 (* 1 = 1.69531 loss)
I0802 00:30:22.229627 12219 sgd_solver.cpp:136] Iteration 219700, lr = 0.0313438, m = 0.9
I0802 00:30:36.176976 12219 solver.cpp:353] Iteration 219800 (7.17 iter/s, 13.947s/100 iter), loss = 1.87808
I0802 00:30:36.177031 12219 solver.cpp:375]     Train net output #0: loss = 1.83554 (* 1 = 1.83554 loss)
I0802 00:30:36.177037 12219 sgd_solver.cpp:136] Iteration 219800, lr = 0.0313125, m = 0.9
I0802 00:30:50.244715 12219 solver.cpp:353] Iteration 219900 (7.10866 iter/s, 14.0674s/100 iter), loss = 1.9023
I0802 00:30:50.244767 12219 solver.cpp:375]     Train net output #0: loss = 1.83857 (* 1 = 1.83857 loss)
I0802 00:30:50.244781 12219 sgd_solver.cpp:136] Iteration 219900, lr = 0.0312813, m = 0.9
I0802 00:31:04.183177 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_220000.caffemodel
I0802 00:31:04.218199 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_220000.solverstate
I0802 00:31:04.224412 12219 solver.cpp:550] Iteration 220000, Testing net (#0)
I0802 00:31:22.037812 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 00:31:24.117493 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.418764
I0802 00:31:24.117513 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.672646
I0802 00:31:24.117519 12219 solver.cpp:635]     Test net output #2: loss = 2.76517 (* 1 = 2.76517 loss)
I0802 00:31:24.117602 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8927s
I0802 00:31:24.270685 12219 solver.cpp:353] Iteration 220000 (2.93901 iter/s, 34.0251s/100 iter), loss = 1.73235
I0802 00:31:24.270711 12219 solver.cpp:375]     Train net output #0: loss = 1.92398 (* 1 = 1.92398 loss)
I0802 00:31:24.270715 12219 sgd_solver.cpp:136] Iteration 220000, lr = 0.03125, m = 0.9
I0802 00:31:38.212363 12219 solver.cpp:353] Iteration 220100 (7.17294 iter/s, 13.9413s/100 iter), loss = 1.86473
I0802 00:31:38.212390 12219 solver.cpp:375]     Train net output #0: loss = 2.30303 (* 1 = 2.30303 loss)
I0802 00:31:38.212395 12219 sgd_solver.cpp:136] Iteration 220100, lr = 0.0312188, m = 0.9
I0802 00:31:52.268381 12219 solver.cpp:353] Iteration 220200 (7.11458 iter/s, 14.0556s/100 iter), loss = 1.7258
I0802 00:31:52.268450 12219 solver.cpp:375]     Train net output #0: loss = 1.9049 (* 1 = 1.9049 loss)
I0802 00:31:52.268455 12219 sgd_solver.cpp:136] Iteration 220200, lr = 0.0311875, m = 0.9
I0802 00:32:06.315239 12219 solver.cpp:353] Iteration 220300 (7.11922 iter/s, 14.0465s/100 iter), loss = 1.78669
I0802 00:32:06.315268 12219 solver.cpp:375]     Train net output #0: loss = 1.65003 (* 1 = 1.65003 loss)
I0802 00:32:06.315274 12219 sgd_solver.cpp:136] Iteration 220300, lr = 0.0311562, m = 0.9
I0802 00:32:20.343904 12219 solver.cpp:353] Iteration 220400 (7.12846 iter/s, 14.0283s/100 iter), loss = 1.61777
I0802 00:32:20.343930 12219 solver.cpp:375]     Train net output #0: loss = 1.61424 (* 1 = 1.61424 loss)
I0802 00:32:20.343933 12219 sgd_solver.cpp:136] Iteration 220400, lr = 0.031125, m = 0.9
I0802 00:32:34.343986 12219 solver.cpp:353] Iteration 220500 (7.14301 iter/s, 13.9997s/100 iter), loss = 1.65947
I0802 00:32:34.344106 12219 solver.cpp:375]     Train net output #0: loss = 1.72167 (* 1 = 1.72167 loss)
I0802 00:32:34.344125 12219 sgd_solver.cpp:136] Iteration 220500, lr = 0.0310938, m = 0.9
I0802 00:32:48.443662 12219 solver.cpp:353] Iteration 220600 (7.09256 iter/s, 14.0993s/100 iter), loss = 1.57176
I0802 00:32:48.443698 12219 solver.cpp:375]     Train net output #0: loss = 1.45122 (* 1 = 1.45122 loss)
I0802 00:32:48.443703 12219 sgd_solver.cpp:136] Iteration 220600, lr = 0.0310625, m = 0.9
I0802 00:33:02.479267 12219 solver.cpp:353] Iteration 220700 (7.12493 iter/s, 14.0352s/100 iter), loss = 1.861
I0802 00:33:02.479302 12219 solver.cpp:375]     Train net output #0: loss = 2.10753 (* 1 = 2.10753 loss)
I0802 00:33:02.479306 12219 sgd_solver.cpp:136] Iteration 220700, lr = 0.0310313, m = 0.9
I0802 00:33:16.611369 12219 solver.cpp:353] Iteration 220800 (7.07628 iter/s, 14.1317s/100 iter), loss = 1.61249
I0802 00:33:16.611615 12219 solver.cpp:375]     Train net output #0: loss = 1.43789 (* 1 = 1.43789 loss)
I0802 00:33:16.611752 12219 sgd_solver.cpp:136] Iteration 220800, lr = 0.031, m = 0.9
I0802 00:33:30.715728 12219 solver.cpp:353] Iteration 220900 (7.0902 iter/s, 14.104s/100 iter), loss = 1.80812
I0802 00:33:30.715750 12219 solver.cpp:375]     Train net output #0: loss = 2.2898 (* 1 = 2.2898 loss)
I0802 00:33:30.715754 12219 sgd_solver.cpp:136] Iteration 220900, lr = 0.0309687, m = 0.9
I0802 00:33:44.676057 12219 solver.cpp:353] Iteration 221000 (7.16335 iter/s, 13.96s/100 iter), loss = 1.48894
I0802 00:33:44.676151 12219 solver.cpp:375]     Train net output #0: loss = 1.33988 (* 1 = 1.33988 loss)
I0802 00:33:44.676172 12219 sgd_solver.cpp:136] Iteration 221000, lr = 0.0309375, m = 0.9
I0802 00:33:58.700192 12219 solver.cpp:353] Iteration 221100 (7.13077 iter/s, 14.0237s/100 iter), loss = 1.7129
I0802 00:33:58.700273 12219 solver.cpp:375]     Train net output #0: loss = 1.34337 (* 1 = 1.34337 loss)
I0802 00:33:58.700280 12219 sgd_solver.cpp:136] Iteration 221100, lr = 0.0309062, m = 0.9
I0802 00:34:12.774641 12219 solver.cpp:353] Iteration 221200 (7.10527 iter/s, 14.0741s/100 iter), loss = 1.80906
I0802 00:34:12.774669 12219 solver.cpp:375]     Train net output #0: loss = 2.14855 (* 1 = 2.14855 loss)
I0802 00:34:12.774675 12219 sgd_solver.cpp:136] Iteration 221200, lr = 0.030875, m = 0.9
I0802 00:34:26.775372 12219 solver.cpp:353] Iteration 221300 (7.14268 iter/s, 14.0004s/100 iter), loss = 1.41055
I0802 00:34:26.775398 12219 solver.cpp:375]     Train net output #0: loss = 1.37896 (* 1 = 1.37896 loss)
I0802 00:34:26.775403 12219 sgd_solver.cpp:136] Iteration 221300, lr = 0.0308438, m = 0.9
I0802 00:34:40.915864 12219 solver.cpp:353] Iteration 221400 (7.07208 iter/s, 14.1401s/100 iter), loss = 1.52789
I0802 00:34:40.915930 12219 solver.cpp:375]     Train net output #0: loss = 1.83778 (* 1 = 1.83778 loss)
I0802 00:34:40.915937 12219 sgd_solver.cpp:136] Iteration 221400, lr = 0.0308125, m = 0.9
I0802 00:34:54.810220 12219 solver.cpp:353] Iteration 221500 (7.19736 iter/s, 13.894s/100 iter), loss = 1.73862
I0802 00:34:54.810245 12219 solver.cpp:375]     Train net output #0: loss = 2.01805 (* 1 = 2.01805 loss)
I0802 00:34:54.810251 12219 sgd_solver.cpp:136] Iteration 221500, lr = 0.0307813, m = 0.9
I0802 00:35:08.779042 12219 solver.cpp:353] Iteration 221600 (7.15899 iter/s, 13.9684s/100 iter), loss = 1.60783
I0802 00:35:08.779067 12219 solver.cpp:375]     Train net output #0: loss = 1.52613 (* 1 = 1.52613 loss)
I0802 00:35:08.779072 12219 sgd_solver.cpp:136] Iteration 221600, lr = 0.03075, m = 0.9
I0802 00:35:22.888397 12219 solver.cpp:353] Iteration 221700 (7.08769 iter/s, 14.109s/100 iter), loss = 1.65712
I0802 00:35:22.888445 12219 solver.cpp:375]     Train net output #0: loss = 1.51142 (* 1 = 1.51142 loss)
I0802 00:35:22.888451 12219 sgd_solver.cpp:136] Iteration 221700, lr = 0.0307187, m = 0.9
I0802 00:35:36.933557 12219 solver.cpp:353] Iteration 221800 (7.12008 iter/s, 14.0448s/100 iter), loss = 1.55067
I0802 00:35:36.933583 12219 solver.cpp:375]     Train net output #0: loss = 1.71639 (* 1 = 1.71639 loss)
I0802 00:35:36.933586 12219 sgd_solver.cpp:136] Iteration 221800, lr = 0.0306875, m = 0.9
I0802 00:35:50.976222 12219 solver.cpp:353] Iteration 221900 (7.12135 iter/s, 14.0423s/100 iter), loss = 1.54697
I0802 00:35:50.976248 12219 solver.cpp:375]     Train net output #0: loss = 1.62612 (* 1 = 1.62612 loss)
I0802 00:35:50.976253 12219 sgd_solver.cpp:136] Iteration 221900, lr = 0.0306562, m = 0.9
I0802 00:36:04.781817 12219 solver.cpp:550] Iteration 222000, Testing net (#0)
I0802 00:36:24.608530 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.482823
I0802 00:36:24.608552 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.737764
I0802 00:36:24.608557 12219 solver.cpp:635]     Test net output #2: loss = 2.31101 (* 1 = 2.31101 loss)
I0802 00:36:24.608575 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8262s
I0802 00:36:24.752715 12219 solver.cpp:353] Iteration 222000 (2.96072 iter/s, 33.7756s/100 iter), loss = 1.85241
I0802 00:36:24.752830 12219 solver.cpp:375]     Train net output #0: loss = 1.80969 (* 1 = 1.80969 loss)
I0802 00:36:24.752859 12219 sgd_solver.cpp:136] Iteration 222000, lr = 0.030625, m = 0.9
I0802 00:36:38.743389 12219 solver.cpp:353] Iteration 222100 (7.14782 iter/s, 13.9903s/100 iter), loss = 1.61297
I0802 00:36:38.743950 12219 solver.cpp:375]     Train net output #0: loss = 1.39683 (* 1 = 1.39683 loss)
I0802 00:36:38.743959 12219 sgd_solver.cpp:136] Iteration 222100, lr = 0.0305938, m = 0.9
I0802 00:36:52.770097 12219 solver.cpp:353] Iteration 222200 (7.12945 iter/s, 14.0263s/100 iter), loss = 1.4385
I0802 00:36:52.770133 12219 solver.cpp:375]     Train net output #0: loss = 1.08279 (* 1 = 1.08279 loss)
I0802 00:36:52.770138 12219 sgd_solver.cpp:136] Iteration 222200, lr = 0.0305625, m = 0.9
I0802 00:37:06.735080 12219 solver.cpp:353] Iteration 222300 (7.16096 iter/s, 13.9646s/100 iter), loss = 1.62576
I0802 00:37:06.735106 12219 solver.cpp:375]     Train net output #0: loss = 1.60519 (* 1 = 1.60519 loss)
I0802 00:37:06.735111 12219 sgd_solver.cpp:136] Iteration 222300, lr = 0.0305313, m = 0.9
I0802 00:37:20.700034 12219 solver.cpp:353] Iteration 222400 (7.16098 iter/s, 13.9646s/100 iter), loss = 1.71698
I0802 00:37:20.700135 12219 solver.cpp:375]     Train net output #0: loss = 1.79637 (* 1 = 1.79637 loss)
I0802 00:37:20.700143 12219 sgd_solver.cpp:136] Iteration 222400, lr = 0.0305, m = 0.9
I0802 00:37:34.782008 12219 solver.cpp:353] Iteration 222500 (7.10147 iter/s, 14.0816s/100 iter), loss = 1.8235
I0802 00:37:34.782037 12219 solver.cpp:375]     Train net output #0: loss = 2.00646 (* 1 = 2.00646 loss)
I0802 00:37:34.782042 12219 sgd_solver.cpp:136] Iteration 222500, lr = 0.0304688, m = 0.9
I0802 00:37:48.747990 12219 solver.cpp:353] Iteration 222600 (7.16045 iter/s, 13.9656s/100 iter), loss = 2.05431
I0802 00:37:48.748018 12219 solver.cpp:375]     Train net output #0: loss = 1.91154 (* 1 = 1.91154 loss)
I0802 00:37:48.748024 12219 sgd_solver.cpp:136] Iteration 222600, lr = 0.0304375, m = 0.9
I0802 00:38:02.706307 12219 solver.cpp:353] Iteration 222700 (7.16438 iter/s, 13.9579s/100 iter), loss = 1.49897
I0802 00:38:02.706394 12219 solver.cpp:375]     Train net output #0: loss = 1.42651 (* 1 = 1.42651 loss)
I0802 00:38:02.706408 12219 sgd_solver.cpp:136] Iteration 222700, lr = 0.0304062, m = 0.9
I0802 00:38:16.642194 12219 solver.cpp:353] Iteration 222800 (7.17591 iter/s, 13.9355s/100 iter), loss = 1.69034
I0802 00:38:16.642223 12219 solver.cpp:375]     Train net output #0: loss = 1.62439 (* 1 = 1.62439 loss)
I0802 00:38:16.642230 12219 sgd_solver.cpp:136] Iteration 222800, lr = 0.030375, m = 0.9
I0802 00:38:30.646162 12219 solver.cpp:353] Iteration 222900 (7.14103 iter/s, 14.0036s/100 iter), loss = 1.82605
I0802 00:38:30.646186 12219 solver.cpp:375]     Train net output #0: loss = 2.09527 (* 1 = 2.09527 loss)
I0802 00:38:30.646190 12219 sgd_solver.cpp:136] Iteration 222900, lr = 0.0303437, m = 0.9
I0802 00:38:44.621156 12219 solver.cpp:353] Iteration 223000 (7.15583 iter/s, 13.9746s/100 iter), loss = 1.58836
I0802 00:38:44.621239 12219 solver.cpp:375]     Train net output #0: loss = 1.79256 (* 1 = 1.79256 loss)
I0802 00:38:44.621246 12219 sgd_solver.cpp:136] Iteration 223000, lr = 0.0303125, m = 0.9
I0802 00:38:58.594615 12219 solver.cpp:353] Iteration 223100 (7.15662 iter/s, 13.9731s/100 iter), loss = 1.6734
I0802 00:38:58.594640 12219 solver.cpp:375]     Train net output #0: loss = 1.82969 (* 1 = 1.82969 loss)
I0802 00:38:58.594643 12219 sgd_solver.cpp:136] Iteration 223100, lr = 0.0302813, m = 0.9
I0802 00:39:12.657941 12219 solver.cpp:353] Iteration 223200 (7.11089 iter/s, 14.0629s/100 iter), loss = 1.63286
I0802 00:39:12.657965 12219 solver.cpp:375]     Train net output #0: loss = 1.27511 (* 1 = 1.27511 loss)
I0802 00:39:12.657970 12219 sgd_solver.cpp:136] Iteration 223200, lr = 0.03025, m = 0.9
I0802 00:39:26.581401 12219 solver.cpp:353] Iteration 223300 (7.18232 iter/s, 13.9231s/100 iter), loss = 2.07798
I0802 00:39:26.581521 12219 solver.cpp:375]     Train net output #0: loss = 2.40516 (* 1 = 2.40516 loss)
I0802 00:39:26.581542 12219 sgd_solver.cpp:136] Iteration 223300, lr = 0.0302188, m = 0.9
I0802 00:39:40.566953 12219 solver.cpp:353] Iteration 223400 (7.15043 iter/s, 13.9852s/100 iter), loss = 1.89434
I0802 00:39:40.566987 12219 solver.cpp:375]     Train net output #0: loss = 2.08786 (* 1 = 2.08786 loss)
I0802 00:39:40.566992 12219 sgd_solver.cpp:136] Iteration 223400, lr = 0.0301875, m = 0.9
I0802 00:39:54.506505 12219 solver.cpp:353] Iteration 223500 (7.17403 iter/s, 13.9392s/100 iter), loss = 1.85912
I0802 00:39:54.506532 12219 solver.cpp:375]     Train net output #0: loss = 1.76359 (* 1 = 1.76359 loss)
I0802 00:39:54.506537 12219 sgd_solver.cpp:136] Iteration 223500, lr = 0.0301562, m = 0.9
I0802 00:40:08.481719 12219 solver.cpp:353] Iteration 223600 (7.15572 iter/s, 13.9748s/100 iter), loss = 1.89021
I0802 00:40:08.481782 12219 solver.cpp:375]     Train net output #0: loss = 2.40698 (* 1 = 2.40698 loss)
I0802 00:40:08.481789 12219 sgd_solver.cpp:136] Iteration 223600, lr = 0.030125, m = 0.9
I0802 00:40:22.446154 12219 solver.cpp:353] Iteration 223700 (7.16124 iter/s, 13.9641s/100 iter), loss = 1.67197
I0802 00:40:22.446180 12219 solver.cpp:375]     Train net output #0: loss = 1.78891 (* 1 = 1.78891 loss)
I0802 00:40:22.446185 12219 sgd_solver.cpp:136] Iteration 223700, lr = 0.0300937, m = 0.9
I0802 00:40:36.407747 12219 solver.cpp:353] Iteration 223800 (7.1627 iter/s, 13.9612s/100 iter), loss = 2.18534
I0802 00:40:36.407778 12219 solver.cpp:375]     Train net output #0: loss = 2.29539 (* 1 = 2.29539 loss)
I0802 00:40:36.407783 12219 sgd_solver.cpp:136] Iteration 223800, lr = 0.0300625, m = 0.9
I0802 00:40:50.391131 12219 solver.cpp:353] Iteration 223900 (7.15155 iter/s, 13.983s/100 iter), loss = 1.52975
I0802 00:40:50.391234 12219 solver.cpp:375]     Train net output #0: loss = 1.52045 (* 1 = 1.52045 loss)
I0802 00:40:50.391242 12219 sgd_solver.cpp:136] Iteration 223900, lr = 0.0300313, m = 0.9
I0802 00:41:04.199234 12219 solver.cpp:550] Iteration 224000, Testing net (#0)
I0802 00:41:24.103461 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.505059
I0802 00:41:24.103516 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.754351
I0802 00:41:24.103523 12219 solver.cpp:635]     Test net output #2: loss = 2.22613 (* 1 = 2.22613 loss)
I0802 00:41:24.103572 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9038s
I0802 00:41:24.250599 12219 solver.cpp:353] Iteration 224000 (2.95346 iter/s, 33.8586s/100 iter), loss = 1.8531
I0802 00:41:24.250628 12219 solver.cpp:375]     Train net output #0: loss = 1.60859 (* 1 = 1.60859 loss)
I0802 00:41:24.250634 12219 sgd_solver.cpp:136] Iteration 224000, lr = 0.03, m = 0.9
I0802 00:41:38.184299 12219 solver.cpp:353] Iteration 224100 (7.17704 iter/s, 13.9333s/100 iter), loss = 1.54315
I0802 00:41:38.184327 12219 solver.cpp:375]     Train net output #0: loss = 1.38296 (* 1 = 1.38296 loss)
I0802 00:41:38.184334 12219 sgd_solver.cpp:136] Iteration 224100, lr = 0.0299688, m = 0.9
I0802 00:41:52.081491 12219 solver.cpp:353] Iteration 224200 (7.19589 iter/s, 13.8968s/100 iter), loss = 1.67894
I0802 00:41:52.081517 12219 solver.cpp:375]     Train net output #0: loss = 1.78427 (* 1 = 1.78427 loss)
I0802 00:41:52.081523 12219 sgd_solver.cpp:136] Iteration 224200, lr = 0.0299375, m = 0.9
I0802 00:42:06.034644 12219 solver.cpp:353] Iteration 224300 (7.16704 iter/s, 13.9528s/100 iter), loss = 1.81248
I0802 00:42:06.040861 12219 solver.cpp:375]     Train net output #0: loss = 2.09877 (* 1 = 2.09877 loss)
I0802 00:42:06.040877 12219 sgd_solver.cpp:136] Iteration 224300, lr = 0.0299062, m = 0.9
I0802 00:42:20.060547 12219 solver.cpp:353] Iteration 224400 (7.12986 iter/s, 14.0255s/100 iter), loss = 1.72583
I0802 00:42:20.060665 12219 solver.cpp:375]     Train net output #0: loss = 2.15901 (* 1 = 2.15901 loss)
I0802 00:42:20.060695 12219 sgd_solver.cpp:136] Iteration 224400, lr = 0.029875, m = 0.9
I0802 00:42:34.084856 12219 solver.cpp:353] Iteration 224500 (7.13067 iter/s, 14.0239s/100 iter), loss = 1.27129
I0802 00:42:34.084942 12219 solver.cpp:375]     Train net output #0: loss = 1.12028 (* 1 = 1.12028 loss)
I0802 00:42:34.084969 12219 sgd_solver.cpp:136] Iteration 224500, lr = 0.0298437, m = 0.9
I0802 00:42:48.246214 12219 solver.cpp:353] Iteration 224600 (7.06166 iter/s, 14.161s/100 iter), loss = 1.83027
I0802 00:42:48.246340 12219 solver.cpp:375]     Train net output #0: loss = 1.53291 (* 1 = 1.53291 loss)
I0802 00:42:48.246354 12219 sgd_solver.cpp:136] Iteration 224600, lr = 0.0298125, m = 0.9
I0802 00:43:02.373303 12219 solver.cpp:353] Iteration 224700 (7.07879 iter/s, 14.1267s/100 iter), loss = 1.90777
I0802 00:43:02.373368 12219 solver.cpp:375]     Train net output #0: loss = 1.53316 (* 1 = 1.53316 loss)
I0802 00:43:02.373381 12219 sgd_solver.cpp:136] Iteration 224700, lr = 0.0297813, m = 0.9
I0802 00:43:16.462721 12219 solver.cpp:353] Iteration 224800 (7.09772 iter/s, 14.089s/100 iter), loss = 1.7787
I0802 00:43:16.462749 12219 solver.cpp:375]     Train net output #0: loss = 1.81415 (* 1 = 1.81415 loss)
I0802 00:43:16.462755 12219 sgd_solver.cpp:136] Iteration 224800, lr = 0.02975, m = 0.9
I0802 00:43:30.533257 12219 solver.cpp:353] Iteration 224900 (7.10724 iter/s, 14.0702s/100 iter), loss = 1.84438
I0802 00:43:30.533318 12219 solver.cpp:375]     Train net output #0: loss = 1.98176 (* 1 = 1.98176 loss)
I0802 00:43:30.533324 12219 sgd_solver.cpp:136] Iteration 224900, lr = 0.0297188, m = 0.9
I0802 00:43:44.655041 12219 solver.cpp:353] Iteration 225000 (7.08145 iter/s, 14.1214s/100 iter), loss = 1.83109
I0802 00:43:44.655066 12219 solver.cpp:375]     Train net output #0: loss = 1.89396 (* 1 = 1.89396 loss)
I0802 00:43:44.655071 12219 sgd_solver.cpp:136] Iteration 225000, lr = 0.0296875, m = 0.9
I0802 00:43:58.646028 12219 solver.cpp:353] Iteration 225100 (7.14765 iter/s, 13.9906s/100 iter), loss = 1.53939
I0802 00:43:58.646055 12219 solver.cpp:375]     Train net output #0: loss = 1.4185 (* 1 = 1.4185 loss)
I0802 00:43:58.646061 12219 sgd_solver.cpp:136] Iteration 225100, lr = 0.0296563, m = 0.9
I0802 00:44:12.732117 12219 solver.cpp:353] Iteration 225200 (7.09939 iter/s, 14.0857s/100 iter), loss = 1.93182
I0802 00:44:12.732211 12219 solver.cpp:375]     Train net output #0: loss = 2.05242 (* 1 = 2.05242 loss)
I0802 00:44:12.732221 12219 sgd_solver.cpp:136] Iteration 225200, lr = 0.029625, m = 0.9
I0802 00:44:26.726641 12219 solver.cpp:353] Iteration 225300 (7.14585 iter/s, 13.9941s/100 iter), loss = 1.95116
I0802 00:44:26.726668 12219 solver.cpp:375]     Train net output #0: loss = 1.89735 (* 1 = 1.89735 loss)
I0802 00:44:26.726672 12219 sgd_solver.cpp:136] Iteration 225300, lr = 0.0295937, m = 0.9
I0802 00:44:40.802899 12219 solver.cpp:353] Iteration 225400 (7.10435 iter/s, 14.0759s/100 iter), loss = 1.62069
I0802 00:44:40.803061 12219 solver.cpp:375]     Train net output #0: loss = 1.45224 (* 1 = 1.45224 loss)
I0802 00:44:40.803083 12219 sgd_solver.cpp:136] Iteration 225400, lr = 0.0295625, m = 0.9
I0802 00:44:54.836604 12219 solver.cpp:353] Iteration 225500 (7.1259 iter/s, 14.0333s/100 iter), loss = 1.53598
I0802 00:44:54.836668 12219 solver.cpp:375]     Train net output #0: loss = 1.53495 (* 1 = 1.53495 loss)
I0802 00:44:54.836674 12219 sgd_solver.cpp:136] Iteration 225500, lr = 0.0295313, m = 0.9
I0802 00:45:08.885335 12219 solver.cpp:353] Iteration 225600 (7.11827 iter/s, 14.0484s/100 iter), loss = 1.96704
I0802 00:45:08.885366 12219 solver.cpp:375]     Train net output #0: loss = 2.10272 (* 1 = 2.10272 loss)
I0802 00:45:08.885373 12219 sgd_solver.cpp:136] Iteration 225600, lr = 0.0295, m = 0.9
I0802 00:45:23.024003 12219 solver.cpp:353] Iteration 225700 (7.07299 iter/s, 14.1383s/100 iter), loss = 1.52362
I0802 00:45:23.024025 12219 solver.cpp:375]     Train net output #0: loss = 1.70943 (* 1 = 1.70943 loss)
I0802 00:45:23.024030 12219 sgd_solver.cpp:136] Iteration 225700, lr = 0.0294688, m = 0.9
I0802 00:45:37.074259 12219 solver.cpp:353] Iteration 225800 (7.1175 iter/s, 14.0499s/100 iter), loss = 1.76678
I0802 00:45:37.074343 12219 solver.cpp:375]     Train net output #0: loss = 1.61099 (* 1 = 1.61099 loss)
I0802 00:45:37.074350 12219 sgd_solver.cpp:136] Iteration 225800, lr = 0.0294375, m = 0.9
I0802 00:45:51.066772 12219 solver.cpp:353] Iteration 225900 (7.14687 iter/s, 13.9921s/100 iter), loss = 1.58353
I0802 00:45:51.066860 12219 solver.cpp:375]     Train net output #0: loss = 1.88782 (* 1 = 1.88782 loss)
I0802 00:45:51.066882 12219 sgd_solver.cpp:136] Iteration 225900, lr = 0.0294062, m = 0.9
I0802 00:46:05.089159 12219 solver.cpp:550] Iteration 226000, Testing net (#0)
I0802 00:46:25.374955 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.453588
I0802 00:46:25.375015 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.709764
I0802 00:46:25.375025 12219 solver.cpp:635]     Test net output #2: loss = 2.49097 (* 1 = 2.49097 loss)
I0802 00:46:25.375044 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2853s
I0802 00:46:25.514760 12219 solver.cpp:353] Iteration 226000 (2.90301 iter/s, 34.447s/100 iter), loss = 1.80586
I0802 00:46:25.514791 12219 solver.cpp:375]     Train net output #0: loss = 1.92181 (* 1 = 1.92181 loss)
I0802 00:46:25.514798 12219 sgd_solver.cpp:136] Iteration 226000, lr = 0.029375, m = 0.9
I0802 00:46:39.395687 12219 solver.cpp:353] Iteration 226100 (7.20433 iter/s, 13.8805s/100 iter), loss = 1.79767
I0802 00:46:39.395710 12219 solver.cpp:375]     Train net output #0: loss = 1.4361 (* 1 = 1.4361 loss)
I0802 00:46:39.395716 12219 sgd_solver.cpp:136] Iteration 226100, lr = 0.0293437, m = 0.9
I0802 00:46:53.311244 12219 solver.cpp:353] Iteration 226200 (7.1864 iter/s, 13.9152s/100 iter), loss = 1.3227
I0802 00:46:53.311270 12219 solver.cpp:375]     Train net output #0: loss = 1.47059 (* 1 = 1.47059 loss)
I0802 00:46:53.311276 12219 sgd_solver.cpp:136] Iteration 226200, lr = 0.0293125, m = 0.9
I0802 00:47:07.355763 12219 solver.cpp:353] Iteration 226300 (7.12041 iter/s, 14.0441s/100 iter), loss = 1.61006
I0802 00:47:07.355944 12219 solver.cpp:375]     Train net output #0: loss = 1.81599 (* 1 = 1.81599 loss)
I0802 00:47:07.355965 12219 sgd_solver.cpp:136] Iteration 226300, lr = 0.0292813, m = 0.9
I0802 00:47:21.437533 12219 solver.cpp:353] Iteration 226400 (7.10157 iter/s, 14.0814s/100 iter), loss = 1.93951
I0802 00:47:21.437557 12219 solver.cpp:375]     Train net output #0: loss = 2.04411 (* 1 = 2.04411 loss)
I0802 00:47:21.437562 12219 sgd_solver.cpp:136] Iteration 226400, lr = 0.02925, m = 0.9
I0802 00:47:35.489240 12219 solver.cpp:353] Iteration 226500 (7.11677 iter/s, 14.0513s/100 iter), loss = 2.09716
I0802 00:47:35.489269 12219 solver.cpp:375]     Train net output #0: loss = 2.23885 (* 1 = 2.23885 loss)
I0802 00:47:35.489272 12219 sgd_solver.cpp:136] Iteration 226500, lr = 0.0292188, m = 0.9
I0802 00:47:49.492763 12219 solver.cpp:353] Iteration 226600 (7.14125 iter/s, 14.0031s/100 iter), loss = 1.8985
I0802 00:47:49.492825 12219 solver.cpp:375]     Train net output #0: loss = 1.94248 (* 1 = 1.94248 loss)
I0802 00:47:49.492830 12219 sgd_solver.cpp:136] Iteration 226600, lr = 0.0291875, m = 0.9
I0802 00:48:03.532147 12219 solver.cpp:353] Iteration 226700 (7.12301 iter/s, 14.039s/100 iter), loss = 1.92045
I0802 00:48:03.532171 12219 solver.cpp:375]     Train net output #0: loss = 2.10933 (* 1 = 2.10933 loss)
I0802 00:48:03.532176 12219 sgd_solver.cpp:136] Iteration 226700, lr = 0.0291563, m = 0.9
I0802 00:48:17.668895 12219 solver.cpp:353] Iteration 226800 (7.07395 iter/s, 14.1364s/100 iter), loss = 1.75728
I0802 00:48:17.668926 12219 solver.cpp:375]     Train net output #0: loss = 1.74433 (* 1 = 1.74433 loss)
I0802 00:48:17.668932 12219 sgd_solver.cpp:136] Iteration 226800, lr = 0.029125, m = 0.9
I0802 00:48:31.726331 12219 solver.cpp:353] Iteration 226900 (7.11387 iter/s, 14.057s/100 iter), loss = 1.88
I0802 00:48:31.726392 12219 solver.cpp:375]     Train net output #0: loss = 1.81975 (* 1 = 1.81975 loss)
I0802 00:48:31.726399 12219 sgd_solver.cpp:136] Iteration 226900, lr = 0.0290937, m = 0.9
I0802 00:48:45.787137 12219 solver.cpp:353] Iteration 227000 (7.11216 iter/s, 14.0604s/100 iter), loss = 1.76144
I0802 00:48:45.787164 12219 solver.cpp:375]     Train net output #0: loss = 1.74292 (* 1 = 1.74292 loss)
I0802 00:48:45.787168 12219 sgd_solver.cpp:136] Iteration 227000, lr = 0.0290625, m = 0.9
I0802 00:48:59.776465 12219 solver.cpp:353] Iteration 227100 (7.1485 iter/s, 13.9889s/100 iter), loss = 1.94674
I0802 00:48:59.776494 12219 solver.cpp:375]     Train net output #0: loss = 2.00719 (* 1 = 2.00719 loss)
I0802 00:48:59.776500 12219 sgd_solver.cpp:136] Iteration 227100, lr = 0.0290313, m = 0.9
I0802 00:49:13.904474 12219 solver.cpp:353] Iteration 227200 (7.07833 iter/s, 14.1276s/100 iter), loss = 1.59497
I0802 00:49:13.904752 12219 solver.cpp:375]     Train net output #0: loss = 1.60564 (* 1 = 1.60564 loss)
I0802 00:49:13.904757 12219 sgd_solver.cpp:136] Iteration 227200, lr = 0.029, m = 0.9
I0802 00:49:17.626534 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 00:49:28.004508 12219 solver.cpp:353] Iteration 227300 (7.09237 iter/s, 14.0997s/100 iter), loss = 1.8499
I0802 00:49:28.004562 12219 solver.cpp:375]     Train net output #0: loss = 2.00587 (* 1 = 2.00587 loss)
I0802 00:49:28.004575 12219 sgd_solver.cpp:136] Iteration 227300, lr = 0.0289688, m = 0.9
I0802 00:49:42.048388 12219 solver.cpp:353] Iteration 227400 (7.12074 iter/s, 14.0435s/100 iter), loss = 1.88325
I0802 00:49:42.048414 12219 solver.cpp:375]     Train net output #0: loss = 1.84837 (* 1 = 1.84837 loss)
I0802 00:49:42.048419 12219 sgd_solver.cpp:136] Iteration 227400, lr = 0.0289375, m = 0.9
I0802 00:49:56.033264 12219 solver.cpp:353] Iteration 227500 (7.15077 iter/s, 13.9845s/100 iter), loss = 1.81698
I0802 00:49:56.033401 12219 solver.cpp:375]     Train net output #0: loss = 1.77023 (* 1 = 1.77023 loss)
I0802 00:49:56.033421 12219 sgd_solver.cpp:136] Iteration 227500, lr = 0.0289063, m = 0.9
I0802 00:50:09.994899 12219 solver.cpp:353] Iteration 227600 (7.16268 iter/s, 13.9613s/100 iter), loss = 1.47776
I0802 00:50:09.994926 12219 solver.cpp:375]     Train net output #0: loss = 1.59734 (* 1 = 1.59734 loss)
I0802 00:50:09.994932 12219 sgd_solver.cpp:136] Iteration 227600, lr = 0.028875, m = 0.9
I0802 00:50:24.125676 12219 solver.cpp:353] Iteration 227700 (7.07694 iter/s, 14.1304s/100 iter), loss = 1.54386
I0802 00:50:24.125728 12219 solver.cpp:375]     Train net output #0: loss = 1.61275 (* 1 = 1.61275 loss)
I0802 00:50:24.125741 12219 sgd_solver.cpp:136] Iteration 227700, lr = 0.0288437, m = 0.9
I0802 00:50:38.184664 12219 solver.cpp:353] Iteration 227800 (7.11308 iter/s, 14.0586s/100 iter), loss = 1.99267
I0802 00:50:38.184748 12219 solver.cpp:375]     Train net output #0: loss = 1.70331 (* 1 = 1.70331 loss)
I0802 00:50:38.184762 12219 sgd_solver.cpp:136] Iteration 227800, lr = 0.0288125, m = 0.9
I0802 00:50:52.207453 12219 solver.cpp:353] Iteration 227900 (7.13144 iter/s, 14.0224s/100 iter), loss = 1.78766
I0802 00:50:52.207481 12219 solver.cpp:375]     Train net output #0: loss = 1.55 (* 1 = 1.55 loss)
I0802 00:50:52.207487 12219 sgd_solver.cpp:136] Iteration 227900, lr = 0.0287812, m = 0.9
I0802 00:51:06.093895 12219 solver.cpp:550] Iteration 228000, Testing net (#0)
I0802 00:51:19.617997 12207 data_reader.cpp:264] Starting prefetch of epoch 12
I0802 00:51:26.132087 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.482
I0802 00:51:26.132109 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.733468
I0802 00:51:26.132117 12219 solver.cpp:635]     Test net output #2: loss = 2.33837 (* 1 = 2.33837 loss)
I0802 00:51:26.132170 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0377s
I0802 00:51:26.281316 12219 solver.cpp:353] Iteration 228000 (2.93488 iter/s, 34.0729s/100 iter), loss = 1.89262
I0802 00:51:26.281342 12219 solver.cpp:375]     Train net output #0: loss = 2.01544 (* 1 = 2.01544 loss)
I0802 00:51:26.281347 12219 sgd_solver.cpp:136] Iteration 228000, lr = 0.02875, m = 0.9
I0802 00:51:40.316143 12219 solver.cpp:353] Iteration 228100 (7.12533 iter/s, 14.0344s/100 iter), loss = 1.79043
I0802 00:51:40.316172 12219 solver.cpp:375]     Train net output #0: loss = 1.91609 (* 1 = 1.91609 loss)
I0802 00:51:40.316179 12219 sgd_solver.cpp:136] Iteration 228100, lr = 0.0287188, m = 0.9
I0802 00:51:54.342706 12219 solver.cpp:353] Iteration 228200 (7.12953 iter/s, 14.0262s/100 iter), loss = 1.64392
I0802 00:51:54.342789 12219 solver.cpp:375]     Train net output #0: loss = 1.55989 (* 1 = 1.55989 loss)
I0802 00:51:54.342797 12219 sgd_solver.cpp:136] Iteration 228200, lr = 0.0286875, m = 0.9
I0802 00:52:08.446110 12219 solver.cpp:353] Iteration 228300 (7.09068 iter/s, 14.103s/100 iter), loss = 1.80644
I0802 00:52:08.446168 12219 solver.cpp:375]     Train net output #0: loss = 1.83255 (* 1 = 1.83255 loss)
I0802 00:52:08.446182 12219 sgd_solver.cpp:136] Iteration 228300, lr = 0.0286562, m = 0.9
I0802 00:52:22.434311 12219 solver.cpp:353] Iteration 228400 (7.14908 iter/s, 13.9878s/100 iter), loss = 1.66667
I0802 00:52:22.434371 12219 solver.cpp:375]     Train net output #0: loss = 2.02069 (* 1 = 2.02069 loss)
I0802 00:52:22.434386 12219 sgd_solver.cpp:136] Iteration 228400, lr = 0.028625, m = 0.9
I0802 00:52:36.374524 12219 solver.cpp:353] Iteration 228500 (7.17369 iter/s, 13.9398s/100 iter), loss = 1.59769
I0802 00:52:36.374583 12219 solver.cpp:375]     Train net output #0: loss = 1.34078 (* 1 = 1.34078 loss)
I0802 00:52:36.374588 12219 sgd_solver.cpp:136] Iteration 228500, lr = 0.0285937, m = 0.9
I0802 00:52:50.543314 12219 solver.cpp:353] Iteration 228600 (7.05796 iter/s, 14.1684s/100 iter), loss = 1.87281
I0802 00:52:50.543339 12219 solver.cpp:375]     Train net output #0: loss = 1.62299 (* 1 = 1.62299 loss)
I0802 00:52:50.543345 12219 sgd_solver.cpp:136] Iteration 228600, lr = 0.0285625, m = 0.9
I0802 00:53:04.512622 12219 solver.cpp:353] Iteration 228700 (7.15875 iter/s, 13.9689s/100 iter), loss = 1.69752
I0802 00:53:04.512647 12219 solver.cpp:375]     Train net output #0: loss = 1.86872 (* 1 = 1.86872 loss)
I0802 00:53:04.512653 12219 sgd_solver.cpp:136] Iteration 228700, lr = 0.0285312, m = 0.9
I0802 00:53:18.509469 12219 solver.cpp:353] Iteration 228800 (7.14466 iter/s, 13.9965s/100 iter), loss = 1.71002
I0802 00:53:18.509580 12219 solver.cpp:375]     Train net output #0: loss = 1.50965 (* 1 = 1.50965 loss)
I0802 00:53:18.509599 12219 sgd_solver.cpp:136] Iteration 228800, lr = 0.0285, m = 0.9
I0802 00:53:32.522279 12219 solver.cpp:353] Iteration 228900 (7.13652 iter/s, 14.0124s/100 iter), loss = 1.2079
I0802 00:53:32.522300 12219 solver.cpp:375]     Train net output #0: loss = 1.20196 (* 1 = 1.20196 loss)
I0802 00:53:32.522303 12219 sgd_solver.cpp:136] Iteration 228900, lr = 0.0284688, m = 0.9
I0802 00:53:46.538444 12219 solver.cpp:353] Iteration 229000 (7.13481 iter/s, 14.0158s/100 iter), loss = 1.63536
I0802 00:53:46.538472 12219 solver.cpp:375]     Train net output #0: loss = 1.38351 (* 1 = 1.38351 loss)
I0802 00:53:46.538478 12219 sgd_solver.cpp:136] Iteration 229000, lr = 0.0284375, m = 0.9
I0802 00:54:00.538260 12219 solver.cpp:353] Iteration 229100 (7.14315 iter/s, 13.9994s/100 iter), loss = 1.60292
I0802 00:54:00.538345 12219 solver.cpp:375]     Train net output #0: loss = 1.81614 (* 1 = 1.81614 loss)
I0802 00:54:00.538354 12219 sgd_solver.cpp:136] Iteration 229100, lr = 0.0284063, m = 0.9
I0802 00:54:14.495715 12219 solver.cpp:353] Iteration 229200 (7.16482 iter/s, 13.9571s/100 iter), loss = 1.72015
I0802 00:54:14.495741 12219 solver.cpp:375]     Train net output #0: loss = 2.30513 (* 1 = 2.30513 loss)
I0802 00:54:14.495748 12219 sgd_solver.cpp:136] Iteration 229200, lr = 0.028375, m = 0.9
I0802 00:54:28.451530 12219 solver.cpp:353] Iteration 229300 (7.16567 iter/s, 13.9554s/100 iter), loss = 1.77531
I0802 00:54:28.451555 12219 solver.cpp:375]     Train net output #0: loss = 1.89608 (* 1 = 1.89608 loss)
I0802 00:54:28.451560 12219 sgd_solver.cpp:136] Iteration 229300, lr = 0.0283438, m = 0.9
I0802 00:54:42.366392 12219 solver.cpp:353] Iteration 229400 (7.18676 iter/s, 13.9145s/100 iter), loss = 2.25153
I0802 00:54:42.366497 12219 solver.cpp:375]     Train net output #0: loss = 2.59223 (* 1 = 2.59223 loss)
I0802 00:54:42.366503 12219 sgd_solver.cpp:136] Iteration 229400, lr = 0.0283125, m = 0.9
I0802 00:54:56.290783 12219 solver.cpp:353] Iteration 229500 (7.18184 iter/s, 13.924s/100 iter), loss = 1.91549
I0802 00:54:56.290807 12219 solver.cpp:375]     Train net output #0: loss = 1.94458 (* 1 = 1.94458 loss)
I0802 00:54:56.290812 12219 sgd_solver.cpp:136] Iteration 229500, lr = 0.0282812, m = 0.9
I0802 00:55:10.237809 12219 solver.cpp:353] Iteration 229600 (7.17018 iter/s, 13.9466s/100 iter), loss = 1.40171
I0802 00:55:10.237838 12219 solver.cpp:375]     Train net output #0: loss = 1.09799 (* 1 = 1.09799 loss)
I0802 00:55:10.237843 12219 sgd_solver.cpp:136] Iteration 229600, lr = 0.02825, m = 0.9
I0802 00:55:24.246443 12219 solver.cpp:353] Iteration 229700 (7.13865 iter/s, 14.0083s/100 iter), loss = 1.78559
I0802 00:55:24.246526 12219 solver.cpp:375]     Train net output #0: loss = 1.92982 (* 1 = 1.92982 loss)
I0802 00:55:24.246532 12219 sgd_solver.cpp:136] Iteration 229700, lr = 0.0282188, m = 0.9
I0802 00:55:38.209161 12219 solver.cpp:353] Iteration 229800 (7.16213 iter/s, 13.9623s/100 iter), loss = 1.55669
I0802 00:55:38.209189 12219 solver.cpp:375]     Train net output #0: loss = 1.43889 (* 1 = 1.43889 loss)
I0802 00:55:38.209239 12219 sgd_solver.cpp:136] Iteration 229800, lr = 0.0281875, m = 0.9
I0802 00:55:52.191269 12219 solver.cpp:353] Iteration 229900 (7.15219 iter/s, 13.9817s/100 iter), loss = 1.93785
I0802 00:55:52.191298 12219 solver.cpp:375]     Train net output #0: loss = 1.72544 (* 1 = 1.72544 loss)
I0802 00:55:52.191304 12219 sgd_solver.cpp:136] Iteration 229900, lr = 0.0281563, m = 0.9
I0802 00:56:05.964632 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_230000.caffemodel
I0802 00:56:06.015136 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_230000.solverstate
I0802 00:56:06.022002 12219 solver.cpp:550] Iteration 230000, Testing net (#0)
I0802 00:56:26.010488 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.495236
I0802 00:56:26.010519 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.747586
I0802 00:56:26.010527 12219 solver.cpp:635]     Test net output #2: loss = 2.24645 (* 1 = 2.24645 loss)
I0802 00:56:26.010588 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9881s
I0802 00:56:26.154456 12219 solver.cpp:353] Iteration 230000 (2.94444 iter/s, 33.9623s/100 iter), loss = 1.88506
I0802 00:56:26.154486 12219 solver.cpp:375]     Train net output #0: loss = 1.46603 (* 1 = 1.46603 loss)
I0802 00:56:26.154492 12219 sgd_solver.cpp:136] Iteration 230000, lr = 0.028125, m = 0.9
I0802 00:56:40.090957 12219 solver.cpp:353] Iteration 230100 (7.1756 iter/s, 13.9361s/100 iter), loss = 1.71644
I0802 00:56:40.091048 12219 solver.cpp:375]     Train net output #0: loss = 1.35016 (* 1 = 1.35016 loss)
I0802 00:56:40.091056 12219 sgd_solver.cpp:136] Iteration 230100, lr = 0.0280937, m = 0.9
I0802 00:56:53.991035 12219 solver.cpp:353] Iteration 230200 (7.1944 iter/s, 13.8997s/100 iter), loss = 1.967
I0802 00:56:53.991063 12219 solver.cpp:375]     Train net output #0: loss = 2.41837 (* 1 = 2.41837 loss)
I0802 00:56:53.991070 12219 sgd_solver.cpp:136] Iteration 230200, lr = 0.0280625, m = 0.9
I0802 00:57:08.051998 12219 solver.cpp:353] Iteration 230300 (7.11208 iter/s, 14.0606s/100 iter), loss = 1.65436
I0802 00:57:08.052023 12219 solver.cpp:375]     Train net output #0: loss = 2.06367 (* 1 = 2.06367 loss)
I0802 00:57:08.052031 12219 sgd_solver.cpp:136] Iteration 230300, lr = 0.0280312, m = 0.9
I0802 00:57:22.052198 12219 solver.cpp:353] Iteration 230400 (7.14295 iter/s, 13.9998s/100 iter), loss = 1.42776
I0802 00:57:22.052312 12219 solver.cpp:375]     Train net output #0: loss = 1.54418 (* 1 = 1.54418 loss)
I0802 00:57:22.052331 12219 sgd_solver.cpp:136] Iteration 230400, lr = 0.028, m = 0.9
I0802 00:57:36.201723 12219 solver.cpp:353] Iteration 230500 (7.06756 iter/s, 14.1491s/100 iter), loss = 1.74177
I0802 00:57:36.201818 12219 solver.cpp:375]     Train net output #0: loss = 1.51383 (* 1 = 1.51383 loss)
I0802 00:57:36.201838 12219 sgd_solver.cpp:136] Iteration 230500, lr = 0.0279688, m = 0.9
I0802 00:57:50.174753 12219 solver.cpp:353] Iteration 230600 (7.15684 iter/s, 13.9726s/100 iter), loss = 1.32975
I0802 00:57:50.174803 12219 solver.cpp:375]     Train net output #0: loss = 1.40112 (* 1 = 1.40112 loss)
I0802 00:57:50.174827 12219 sgd_solver.cpp:136] Iteration 230600, lr = 0.0279375, m = 0.9
I0802 00:58:04.230871 12219 solver.cpp:353] Iteration 230700 (7.11453 iter/s, 14.0557s/100 iter), loss = 1.4663
I0802 00:58:04.230967 12219 solver.cpp:375]     Train net output #0: loss = 1.56847 (* 1 = 1.56847 loss)
I0802 00:58:04.230979 12219 sgd_solver.cpp:136] Iteration 230700, lr = 0.0279063, m = 0.9
I0802 00:58:18.276383 12219 solver.cpp:353] Iteration 230800 (7.11991 iter/s, 14.0451s/100 iter), loss = 1.40859
I0802 00:58:18.276413 12219 solver.cpp:375]     Train net output #0: loss = 1.6653 (* 1 = 1.6653 loss)
I0802 00:58:18.276420 12219 sgd_solver.cpp:136] Iteration 230800, lr = 0.027875, m = 0.9
I0802 00:58:32.292687 12219 solver.cpp:353] Iteration 230900 (7.13474 iter/s, 14.0159s/100 iter), loss = 1.78181
I0802 00:58:32.292732 12219 solver.cpp:375]     Train net output #0: loss = 1.84603 (* 1 = 1.84603 loss)
I0802 00:58:32.292737 12219 sgd_solver.cpp:136] Iteration 230900, lr = 0.0278437, m = 0.9
I0802 00:58:46.357383 12219 solver.cpp:353] Iteration 231000 (7.11019 iter/s, 14.0643s/100 iter), loss = 2.07459
I0802 00:58:46.357514 12219 solver.cpp:375]     Train net output #0: loss = 2.29224 (* 1 = 2.29224 loss)
I0802 00:58:46.357543 12219 sgd_solver.cpp:136] Iteration 231000, lr = 0.0278125, m = 0.9
I0802 00:59:00.420150 12219 solver.cpp:353] Iteration 231100 (7.11117 iter/s, 14.0624s/100 iter), loss = 2.10082
I0802 00:59:00.420218 12219 solver.cpp:375]     Train net output #0: loss = 2.03315 (* 1 = 2.03315 loss)
I0802 00:59:00.420233 12219 sgd_solver.cpp:136] Iteration 231100, lr = 0.0277812, m = 0.9
I0802 00:59:14.533344 12219 solver.cpp:353] Iteration 231200 (7.08576 iter/s, 14.1128s/100 iter), loss = 2.13924
I0802 00:59:14.533373 12219 solver.cpp:375]     Train net output #0: loss = 2.00263 (* 1 = 2.00263 loss)
I0802 00:59:14.533380 12219 sgd_solver.cpp:136] Iteration 231200, lr = 0.02775, m = 0.9
I0802 00:59:28.497936 12219 solver.cpp:353] Iteration 231300 (7.16116 iter/s, 13.9642s/100 iter), loss = 1.97435
I0802 00:59:28.497997 12219 solver.cpp:375]     Train net output #0: loss = 2.16814 (* 1 = 2.16814 loss)
I0802 00:59:28.498004 12219 sgd_solver.cpp:136] Iteration 231300, lr = 0.0277188, m = 0.9
I0802 00:59:42.457690 12219 solver.cpp:353] Iteration 231400 (7.16364 iter/s, 13.9594s/100 iter), loss = 1.90332
I0802 00:59:42.457718 12219 solver.cpp:375]     Train net output #0: loss = 1.80741 (* 1 = 1.80741 loss)
I0802 00:59:42.457725 12219 sgd_solver.cpp:136] Iteration 231400, lr = 0.0276875, m = 0.9
I0802 00:59:56.600054 12219 solver.cpp:353] Iteration 231500 (7.07115 iter/s, 14.142s/100 iter), loss = 1.48599
I0802 00:59:56.600083 12219 solver.cpp:375]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0802 00:59:56.600090 12219 sgd_solver.cpp:136] Iteration 231500, lr = 0.0276563, m = 0.9
I0802 01:00:10.669991 12219 solver.cpp:353] Iteration 231600 (7.10754 iter/s, 14.0696s/100 iter), loss = 1.69655
I0802 01:00:10.670039 12219 solver.cpp:375]     Train net output #0: loss = 1.73052 (* 1 = 1.73052 loss)
I0802 01:00:10.670044 12219 sgd_solver.cpp:136] Iteration 231600, lr = 0.027625, m = 0.9
I0802 01:00:24.656955 12219 solver.cpp:353] Iteration 231700 (7.14971 iter/s, 13.9866s/100 iter), loss = 1.81785
I0802 01:00:24.657007 12219 solver.cpp:375]     Train net output #0: loss = 2.02136 (* 1 = 2.02136 loss)
I0802 01:00:24.657019 12219 sgd_solver.cpp:136] Iteration 231700, lr = 0.0275938, m = 0.9
I0802 01:00:38.665047 12219 solver.cpp:353] Iteration 231800 (7.13892 iter/s, 14.0077s/100 iter), loss = 1.79964
I0802 01:00:38.665076 12219 solver.cpp:375]     Train net output #0: loss = 1.48737 (* 1 = 1.48737 loss)
I0802 01:00:38.665081 12219 sgd_solver.cpp:136] Iteration 231800, lr = 0.0275625, m = 0.9
I0802 01:00:52.594199 12219 solver.cpp:353] Iteration 231900 (7.17938 iter/s, 13.9288s/100 iter), loss = 1.79232
I0802 01:00:52.594300 12219 solver.cpp:375]     Train net output #0: loss = 1.55524 (* 1 = 1.55524 loss)
I0802 01:00:52.594319 12219 sgd_solver.cpp:136] Iteration 231900, lr = 0.0275312, m = 0.9
I0802 01:01:06.482252 12219 solver.cpp:550] Iteration 232000, Testing net (#0)
I0802 01:01:26.781324 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.494588
I0802 01:01:26.781390 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.744764
I0802 01:01:26.781397 12219 solver.cpp:635]     Test net output #2: loss = 2.27531 (* 1 = 2.27531 loss)
I0802 01:01:26.781416 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2986s
I0802 01:01:26.917732 12219 solver.cpp:353] Iteration 232000 (2.91353 iter/s, 34.3226s/100 iter), loss = 1.59169
I0802 01:01:26.917760 12219 solver.cpp:375]     Train net output #0: loss = 1.19854 (* 1 = 1.19854 loss)
I0802 01:01:26.917767 12219 sgd_solver.cpp:136] Iteration 232000, lr = 0.0275, m = 0.9
I0802 01:01:40.926591 12219 solver.cpp:353] Iteration 232100 (7.13854 iter/s, 14.0085s/100 iter), loss = 1.61547
I0802 01:01:40.926616 12219 solver.cpp:375]     Train net output #0: loss = 1.42851 (* 1 = 1.42851 loss)
I0802 01:01:40.926621 12219 sgd_solver.cpp:136] Iteration 232100, lr = 0.0274688, m = 0.9
I0802 01:01:54.875466 12219 solver.cpp:353] Iteration 232200 (7.16923 iter/s, 13.9485s/100 iter), loss = 1.24218
I0802 01:01:54.875494 12219 solver.cpp:375]     Train net output #0: loss = 1.45443 (* 1 = 1.45443 loss)
I0802 01:01:54.875499 12219 sgd_solver.cpp:136] Iteration 232200, lr = 0.0274375, m = 0.9
I0802 01:02:08.881553 12219 solver.cpp:353] Iteration 232300 (7.13995 iter/s, 14.0057s/100 iter), loss = 1.77867
I0802 01:02:08.881654 12219 solver.cpp:375]     Train net output #0: loss = 1.74701 (* 1 = 1.74701 loss)
I0802 01:02:08.881660 12219 sgd_solver.cpp:136] Iteration 232300, lr = 0.0274063, m = 0.9
I0802 01:02:22.887612 12219 solver.cpp:353] Iteration 232400 (7.13996 iter/s, 14.0057s/100 iter), loss = 1.41135
I0802 01:02:22.887641 12219 solver.cpp:375]     Train net output #0: loss = 1.31154 (* 1 = 1.31154 loss)
I0802 01:02:22.887645 12219 sgd_solver.cpp:136] Iteration 232400, lr = 0.027375, m = 0.9
I0802 01:02:36.942519 12219 solver.cpp:353] Iteration 232500 (7.11515 iter/s, 14.0545s/100 iter), loss = 2.08539
I0802 01:02:36.942749 12219 solver.cpp:375]     Train net output #0: loss = 2.04335 (* 1 = 2.04335 loss)
I0802 01:02:36.942859 12219 sgd_solver.cpp:136] Iteration 232500, lr = 0.0273438, m = 0.9
I0802 01:02:51.040985 12219 solver.cpp:353] Iteration 232600 (7.09316 iter/s, 14.0981s/100 iter), loss = 1.50634
I0802 01:02:51.041069 12219 solver.cpp:375]     Train net output #0: loss = 1.35988 (* 1 = 1.35988 loss)
I0802 01:02:51.041075 12219 sgd_solver.cpp:136] Iteration 232600, lr = 0.0273125, m = 0.9
I0802 01:03:05.067922 12219 solver.cpp:353] Iteration 232700 (7.12933 iter/s, 14.0266s/100 iter), loss = 2.2143
I0802 01:03:05.068025 12219 solver.cpp:375]     Train net output #0: loss = 2.58103 (* 1 = 2.58103 loss)
I0802 01:03:05.068047 12219 sgd_solver.cpp:136] Iteration 232700, lr = 0.0272812, m = 0.9
I0802 01:03:19.176801 12219 solver.cpp:353] Iteration 232800 (7.08793 iter/s, 14.1085s/100 iter), loss = 1.47601
I0802 01:03:19.176838 12219 solver.cpp:375]     Train net output #0: loss = 1.33725 (* 1 = 1.33725 loss)
I0802 01:03:19.176846 12219 sgd_solver.cpp:136] Iteration 232800, lr = 0.02725, m = 0.9
I0802 01:03:33.182417 12219 solver.cpp:353] Iteration 232900 (7.14019 iter/s, 14.0052s/100 iter), loss = 1.53599
I0802 01:03:33.182514 12219 solver.cpp:375]     Train net output #0: loss = 1.65945 (* 1 = 1.65945 loss)
I0802 01:03:33.182526 12219 sgd_solver.cpp:136] Iteration 232900, lr = 0.0272187, m = 0.9
I0802 01:03:47.379093 12219 solver.cpp:353] Iteration 233000 (7.04409 iter/s, 14.1963s/100 iter), loss = 1.92302
I0802 01:03:47.379119 12219 solver.cpp:375]     Train net output #0: loss = 1.7584 (* 1 = 1.7584 loss)
I0802 01:03:47.379125 12219 sgd_solver.cpp:136] Iteration 233000, lr = 0.0271875, m = 0.9
I0802 01:04:01.368324 12219 solver.cpp:353] Iteration 233100 (7.14855 iter/s, 13.9889s/100 iter), loss = 1.81609
I0802 01:04:01.368353 12219 solver.cpp:375]     Train net output #0: loss = 1.77029 (* 1 = 1.77029 loss)
I0802 01:04:01.368360 12219 sgd_solver.cpp:136] Iteration 233100, lr = 0.0271563, m = 0.9
I0802 01:04:15.365157 12219 solver.cpp:353] Iteration 233200 (7.14467 iter/s, 13.9965s/100 iter), loss = 1.76473
I0802 01:04:15.365239 12219 solver.cpp:375]     Train net output #0: loss = 1.90045 (* 1 = 1.90045 loss)
I0802 01:04:15.365247 12219 sgd_solver.cpp:136] Iteration 233200, lr = 0.027125, m = 0.9
I0802 01:04:29.423481 12219 solver.cpp:353] Iteration 233300 (7.11342 iter/s, 14.0579s/100 iter), loss = 1.83326
I0802 01:04:29.423511 12219 solver.cpp:375]     Train net output #0: loss = 1.78816 (* 1 = 1.78816 loss)
I0802 01:04:29.423516 12219 sgd_solver.cpp:136] Iteration 233300, lr = 0.0270938, m = 0.9
I0802 01:04:43.450181 12219 solver.cpp:353] Iteration 233400 (7.12945 iter/s, 14.0263s/100 iter), loss = 1.57547
I0802 01:04:43.450209 12219 solver.cpp:375]     Train net output #0: loss = 1.47861 (* 1 = 1.47861 loss)
I0802 01:04:43.450215 12219 sgd_solver.cpp:136] Iteration 233400, lr = 0.0270625, m = 0.9
I0802 01:04:57.459936 12219 solver.cpp:353] Iteration 233500 (7.13809 iter/s, 14.0094s/100 iter), loss = 1.57024
I0802 01:04:57.460029 12219 solver.cpp:375]     Train net output #0: loss = 1.404 (* 1 = 1.404 loss)
I0802 01:04:57.460037 12219 sgd_solver.cpp:136] Iteration 233500, lr = 0.0270312, m = 0.9
I0802 01:05:11.391587 12219 solver.cpp:353] Iteration 233600 (7.17809 iter/s, 13.9313s/100 iter), loss = 2.14844
I0802 01:05:11.391613 12219 solver.cpp:375]     Train net output #0: loss = 2.11973 (* 1 = 2.11973 loss)
I0802 01:05:11.391618 12219 sgd_solver.cpp:136] Iteration 233600, lr = 0.027, m = 0.9
I0802 01:05:25.355087 12219 solver.cpp:353] Iteration 233700 (7.16172 iter/s, 13.9631s/100 iter), loss = 1.87794
I0802 01:05:25.355113 12219 solver.cpp:375]     Train net output #0: loss = 1.40239 (* 1 = 1.40239 loss)
I0802 01:05:25.355118 12219 sgd_solver.cpp:136] Iteration 233700, lr = 0.0269687, m = 0.9
I0802 01:05:39.499989 12219 solver.cpp:353] Iteration 233800 (7.06988 iter/s, 14.1445s/100 iter), loss = 1.83268
I0802 01:05:39.500089 12219 solver.cpp:375]     Train net output #0: loss = 1.88884 (* 1 = 1.88884 loss)
I0802 01:05:39.500098 12219 sgd_solver.cpp:136] Iteration 233800, lr = 0.0269375, m = 0.9
I0802 01:05:53.574724 12219 solver.cpp:353] Iteration 233900 (7.10512 iter/s, 14.0744s/100 iter), loss = 1.80806
I0802 01:05:53.574748 12219 solver.cpp:375]     Train net output #0: loss = 1.58365 (* 1 = 1.58365 loss)
I0802 01:05:53.574753 12219 sgd_solver.cpp:136] Iteration 233900, lr = 0.0269063, m = 0.9
I0802 01:06:07.452781 12219 solver.cpp:550] Iteration 234000, Testing net (#0)
I0802 01:06:09.415109 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 01:06:27.498320 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.483471
I0802 01:06:27.498430 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.737763
I0802 01:06:27.498438 12219 solver.cpp:635]     Test net output #2: loss = 2.32726 (* 1 = 2.32726 loss)
I0802 01:06:27.498457 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0451s
I0802 01:06:27.637233 12219 solver.cpp:353] Iteration 234000 (2.93586 iter/s, 34.0616s/100 iter), loss = 1.37744
I0802 01:06:27.637264 12219 solver.cpp:375]     Train net output #0: loss = 1.11159 (* 1 = 1.11159 loss)
I0802 01:06:27.637269 12219 sgd_solver.cpp:136] Iteration 234000, lr = 0.026875, m = 0.9
I0802 01:06:41.636865 12219 solver.cpp:353] Iteration 234100 (7.14324 iter/s, 13.9992s/100 iter), loss = 1.61136
I0802 01:06:41.636893 12219 solver.cpp:375]     Train net output #0: loss = 1.51671 (* 1 = 1.51671 loss)
I0802 01:06:41.636899 12219 sgd_solver.cpp:136] Iteration 234100, lr = 0.0268438, m = 0.9
I0802 01:06:55.595242 12219 solver.cpp:353] Iteration 234200 (7.16435 iter/s, 13.958s/100 iter), loss = 1.45463
I0802 01:06:55.595269 12219 solver.cpp:375]     Train net output #0: loss = 1.34408 (* 1 = 1.34408 loss)
I0802 01:06:55.595274 12219 sgd_solver.cpp:136] Iteration 234200, lr = 0.0268125, m = 0.9
I0802 01:07:09.590281 12219 solver.cpp:353] Iteration 234300 (7.14559 iter/s, 13.9947s/100 iter), loss = 1.61339
I0802 01:07:09.590337 12219 solver.cpp:375]     Train net output #0: loss = 1.80368 (* 1 = 1.80368 loss)
I0802 01:07:09.590342 12219 sgd_solver.cpp:136] Iteration 234300, lr = 0.0267812, m = 0.9
I0802 01:07:23.608829 12219 solver.cpp:353] Iteration 234400 (7.1336 iter/s, 14.0182s/100 iter), loss = 1.81338
I0802 01:07:23.608856 12219 solver.cpp:375]     Train net output #0: loss = 1.68674 (* 1 = 1.68674 loss)
I0802 01:07:23.608862 12219 sgd_solver.cpp:136] Iteration 234400, lr = 0.02675, m = 0.9
I0802 01:07:37.638753 12219 solver.cpp:353] Iteration 234500 (7.12782 iter/s, 14.0295s/100 iter), loss = 1.47971
I0802 01:07:37.638782 12219 solver.cpp:375]     Train net output #0: loss = 1.5728 (* 1 = 1.5728 loss)
I0802 01:07:37.638785 12219 sgd_solver.cpp:136] Iteration 234500, lr = 0.0267187, m = 0.9
I0802 01:07:51.610338 12219 solver.cpp:353] Iteration 234600 (7.15758 iter/s, 13.9712s/100 iter), loss = 1.38852
I0802 01:07:51.610441 12219 solver.cpp:375]     Train net output #0: loss = 1.653 (* 1 = 1.653 loss)
I0802 01:07:51.610468 12219 sgd_solver.cpp:136] Iteration 234600, lr = 0.0266875, m = 0.9
I0802 01:08:05.639538 12219 solver.cpp:353] Iteration 234700 (7.12819 iter/s, 14.0288s/100 iter), loss = 1.94423
I0802 01:08:05.639566 12219 solver.cpp:375]     Train net output #0: loss = 1.73476 (* 1 = 1.73476 loss)
I0802 01:08:05.639572 12219 sgd_solver.cpp:136] Iteration 234700, lr = 0.0266563, m = 0.9
I0802 01:08:19.660012 12219 solver.cpp:353] Iteration 234800 (7.13262 iter/s, 14.0201s/100 iter), loss = 1.58753
I0802 01:08:19.660035 12219 solver.cpp:375]     Train net output #0: loss = 1.69086 (* 1 = 1.69086 loss)
I0802 01:08:19.660039 12219 sgd_solver.cpp:136] Iteration 234800, lr = 0.026625, m = 0.9
I0802 01:08:33.662116 12219 solver.cpp:353] Iteration 234900 (7.14198 iter/s, 14.0017s/100 iter), loss = 1.82385
I0802 01:08:33.662191 12219 solver.cpp:375]     Train net output #0: loss = 1.63182 (* 1 = 1.63182 loss)
I0802 01:08:33.662199 12219 sgd_solver.cpp:136] Iteration 234900, lr = 0.0265938, m = 0.9
I0802 01:08:47.609235 12219 solver.cpp:353] Iteration 235000 (7.17014 iter/s, 13.9467s/100 iter), loss = 1.90104
I0802 01:08:47.609259 12219 solver.cpp:375]     Train net output #0: loss = 1.49755 (* 1 = 1.49755 loss)
I0802 01:08:47.609264 12219 sgd_solver.cpp:136] Iteration 235000, lr = 0.0265625, m = 0.9
I0802 01:09:01.523541 12219 solver.cpp:353] Iteration 235100 (7.18704 iter/s, 13.9139s/100 iter), loss = 1.11335
I0802 01:09:01.523566 12219 solver.cpp:375]     Train net output #0: loss = 1.15041 (* 1 = 1.15041 loss)
I0802 01:09:01.523569 12219 sgd_solver.cpp:136] Iteration 235100, lr = 0.0265312, m = 0.9
I0802 01:09:15.525383 12219 solver.cpp:353] Iteration 235200 (7.14211 iter/s, 14.0015s/100 iter), loss = 1.85266
I0802 01:09:15.525496 12219 solver.cpp:375]     Train net output #0: loss = 1.85121 (* 1 = 1.85121 loss)
I0802 01:09:15.525514 12219 sgd_solver.cpp:136] Iteration 235200, lr = 0.0265, m = 0.9
I0802 01:09:29.569602 12219 solver.cpp:353] Iteration 235300 (7.12056 iter/s, 14.0438s/100 iter), loss = 1.58772
I0802 01:09:29.569628 12219 solver.cpp:375]     Train net output #0: loss = 1.74254 (* 1 = 1.74254 loss)
I0802 01:09:29.569633 12219 sgd_solver.cpp:136] Iteration 235300, lr = 0.0264687, m = 0.9
I0802 01:09:43.616338 12219 solver.cpp:353] Iteration 235400 (7.11928 iter/s, 14.0464s/100 iter), loss = 1.71747
I0802 01:09:43.616366 12219 solver.cpp:375]     Train net output #0: loss = 1.39234 (* 1 = 1.39234 loss)
I0802 01:09:43.616372 12219 sgd_solver.cpp:136] Iteration 235400, lr = 0.0264375, m = 0.9
I0802 01:09:57.628281 12219 solver.cpp:353] Iteration 235500 (7.13696 iter/s, 14.0116s/100 iter), loss = 1.67633
I0802 01:09:57.628345 12219 solver.cpp:375]     Train net output #0: loss = 1.66403 (* 1 = 1.66403 loss)
I0802 01:09:57.628350 12219 sgd_solver.cpp:136] Iteration 235500, lr = 0.0264063, m = 0.9
I0802 01:10:11.548476 12219 solver.cpp:353] Iteration 235600 (7.184 iter/s, 13.9198s/100 iter), loss = 1.60771
I0802 01:10:11.548501 12219 solver.cpp:375]     Train net output #0: loss = 1.84282 (* 1 = 1.84282 loss)
I0802 01:10:11.548506 12219 sgd_solver.cpp:136] Iteration 235600, lr = 0.026375, m = 0.9
I0802 01:10:25.472759 12219 solver.cpp:353] Iteration 235700 (7.1819 iter/s, 13.9239s/100 iter), loss = 1.53555
I0802 01:10:25.472784 12219 solver.cpp:375]     Train net output #0: loss = 1.1448 (* 1 = 1.1448 loss)
I0802 01:10:25.472790 12219 sgd_solver.cpp:136] Iteration 235700, lr = 0.0263438, m = 0.9
I0802 01:10:39.427552 12219 solver.cpp:353] Iteration 235800 (7.16619 iter/s, 13.9544s/100 iter), loss = 1.74294
I0802 01:10:39.427657 12219 solver.cpp:375]     Train net output #0: loss = 1.61398 (* 1 = 1.61398 loss)
I0802 01:10:39.427665 12219 sgd_solver.cpp:136] Iteration 235800, lr = 0.0263125, m = 0.9
I0802 01:10:53.407284 12219 solver.cpp:353] Iteration 235900 (7.15341 iter/s, 13.9794s/100 iter), loss = 1.72086
I0802 01:10:53.407310 12219 solver.cpp:375]     Train net output #0: loss = 1.80867 (* 1 = 1.80867 loss)
I0802 01:10:53.407313 12219 sgd_solver.cpp:136] Iteration 235900, lr = 0.0262813, m = 0.9
I0802 01:11:07.195399 12219 solver.cpp:550] Iteration 236000, Testing net (#0)
I0802 01:11:26.989114 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.520706
I0802 01:11:26.989192 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.769234
I0802 01:11:26.989199 12219 solver.cpp:635]     Test net output #2: loss = 2.11405 (* 1 = 2.11405 loss)
I0802 01:11:26.989217 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7933s
I0802 01:11:27.130903 12219 solver.cpp:353] Iteration 236000 (2.96536 iter/s, 33.7227s/100 iter), loss = 1.58608
I0802 01:11:27.130928 12219 solver.cpp:375]     Train net output #0: loss = 1.76975 (* 1 = 1.76975 loss)
I0802 01:11:27.130931 12219 sgd_solver.cpp:136] Iteration 236000, lr = 0.02625, m = 0.9
I0802 01:11:41.103377 12219 solver.cpp:353] Iteration 236100 (7.15712 iter/s, 13.9721s/100 iter), loss = 2.00679
I0802 01:11:41.103405 12219 solver.cpp:375]     Train net output #0: loss = 2.19068 (* 1 = 2.19068 loss)
I0802 01:11:41.103411 12219 sgd_solver.cpp:136] Iteration 236100, lr = 0.0262187, m = 0.9
I0802 01:11:55.068271 12219 solver.cpp:353] Iteration 236200 (7.16101 iter/s, 13.9645s/100 iter), loss = 1.81347
I0802 01:11:55.068305 12219 solver.cpp:375]     Train net output #0: loss = 1.76009 (* 1 = 1.76009 loss)
I0802 01:11:55.068310 12219 sgd_solver.cpp:136] Iteration 236200, lr = 0.0261875, m = 0.9
I0802 01:12:09.148327 12219 solver.cpp:353] Iteration 236300 (7.10244 iter/s, 14.0797s/100 iter), loss = 1.54598
I0802 01:12:09.148393 12219 solver.cpp:375]     Train net output #0: loss = 1.34921 (* 1 = 1.34921 loss)
I0802 01:12:09.148401 12219 sgd_solver.cpp:136] Iteration 236300, lr = 0.0261563, m = 0.9
I0802 01:12:23.075500 12219 solver.cpp:353] Iteration 236400 (7.1804 iter/s, 13.9268s/100 iter), loss = 1.5924
I0802 01:12:23.075525 12219 solver.cpp:375]     Train net output #0: loss = 1.69395 (* 1 = 1.69395 loss)
I0802 01:12:23.075531 12219 sgd_solver.cpp:136] Iteration 236400, lr = 0.026125, m = 0.9
I0802 01:12:37.142668 12219 solver.cpp:353] Iteration 236500 (7.10895 iter/s, 14.0668s/100 iter), loss = 1.83422
I0802 01:12:37.142709 12219 solver.cpp:375]     Train net output #0: loss = 2.21829 (* 1 = 2.21829 loss)
I0802 01:12:37.142717 12219 sgd_solver.cpp:136] Iteration 236500, lr = 0.0260938, m = 0.9
I0802 01:12:51.224304 12219 solver.cpp:353] Iteration 236600 (7.10164 iter/s, 14.0813s/100 iter), loss = 1.79556
I0802 01:12:51.224530 12219 solver.cpp:375]     Train net output #0: loss = 1.7527 (* 1 = 1.7527 loss)
I0802 01:12:51.224544 12219 sgd_solver.cpp:136] Iteration 236600, lr = 0.0260625, m = 0.9
I0802 01:13:05.325016 12219 solver.cpp:353] Iteration 236700 (7.09203 iter/s, 14.1003s/100 iter), loss = 2.15633
I0802 01:13:05.325043 12219 solver.cpp:375]     Train net output #0: loss = 2.23778 (* 1 = 2.23778 loss)
I0802 01:13:05.325049 12219 sgd_solver.cpp:136] Iteration 236700, lr = 0.0260313, m = 0.9
I0802 01:13:19.329464 12219 solver.cpp:353] Iteration 236800 (7.14078 iter/s, 14.0041s/100 iter), loss = 1.96721
I0802 01:13:19.329491 12219 solver.cpp:375]     Train net output #0: loss = 1.94202 (* 1 = 1.94202 loss)
I0802 01:13:19.329495 12219 sgd_solver.cpp:136] Iteration 236800, lr = 0.026, m = 0.9
I0802 01:13:33.245491 12219 solver.cpp:353] Iteration 236900 (7.18616 iter/s, 13.9156s/100 iter), loss = 1.80258
I0802 01:13:33.245556 12219 solver.cpp:375]     Train net output #0: loss = 1.96943 (* 1 = 1.96943 loss)
I0802 01:13:33.245565 12219 sgd_solver.cpp:136] Iteration 236900, lr = 0.0259687, m = 0.9
I0802 01:13:47.276574 12219 solver.cpp:353] Iteration 237000 (7.12723 iter/s, 14.0307s/100 iter), loss = 1.43739
I0802 01:13:47.276617 12219 solver.cpp:375]     Train net output #0: loss = 1.50396 (* 1 = 1.50396 loss)
I0802 01:13:47.276623 12219 sgd_solver.cpp:136] Iteration 237000, lr = 0.0259375, m = 0.9
I0802 01:14:01.380527 12219 solver.cpp:353] Iteration 237100 (7.09041 iter/s, 14.1036s/100 iter), loss = 1.9506
I0802 01:14:01.380561 12219 solver.cpp:375]     Train net output #0: loss = 1.7786 (* 1 = 1.7786 loss)
I0802 01:14:01.380568 12219 sgd_solver.cpp:136] Iteration 237100, lr = 0.0259063, m = 0.9
I0802 01:14:15.530983 12219 solver.cpp:353] Iteration 237200 (7.06711 iter/s, 14.1501s/100 iter), loss = 1.46102
I0802 01:14:15.531075 12219 solver.cpp:375]     Train net output #0: loss = 1.73439 (* 1 = 1.73439 loss)
I0802 01:14:15.531083 12219 sgd_solver.cpp:136] Iteration 237200, lr = 0.025875, m = 0.9
I0802 01:14:29.665004 12219 solver.cpp:353] Iteration 237300 (7.07532 iter/s, 14.1336s/100 iter), loss = 1.93117
I0802 01:14:29.665031 12219 solver.cpp:375]     Train net output #0: loss = 1.71736 (* 1 = 1.71736 loss)
I0802 01:14:29.665035 12219 sgd_solver.cpp:136] Iteration 237300, lr = 0.0258438, m = 0.9
I0802 01:14:43.561902 12219 solver.cpp:353] Iteration 237400 (7.19605 iter/s, 13.8965s/100 iter), loss = 1.61135
I0802 01:14:43.561930 12219 solver.cpp:375]     Train net output #0: loss = 1.60014 (* 1 = 1.60014 loss)
I0802 01:14:43.561935 12219 sgd_solver.cpp:136] Iteration 237400, lr = 0.0258125, m = 0.9
I0802 01:14:57.685950 12219 solver.cpp:353] Iteration 237500 (7.08032 iter/s, 14.1237s/100 iter), loss = 1.67764
I0802 01:14:57.686031 12219 solver.cpp:375]     Train net output #0: loss = 1.80581 (* 1 = 1.80581 loss)
I0802 01:14:57.686039 12219 sgd_solver.cpp:136] Iteration 237500, lr = 0.0257812, m = 0.9
I0802 01:15:11.746853 12219 solver.cpp:353] Iteration 237600 (7.11212 iter/s, 14.0605s/100 iter), loss = 1.78344
I0802 01:15:11.746907 12219 solver.cpp:375]     Train net output #0: loss = 1.46365 (* 1 = 1.46365 loss)
I0802 01:15:11.746920 12219 sgd_solver.cpp:136] Iteration 237600, lr = 0.02575, m = 0.9
I0802 01:15:25.844013 12219 solver.cpp:353] Iteration 237700 (7.09382 iter/s, 14.0968s/100 iter), loss = 1.81202
I0802 01:15:25.844049 12219 solver.cpp:375]     Train net output #0: loss = 1.81919 (* 1 = 1.81919 loss)
I0802 01:15:25.844055 12219 sgd_solver.cpp:136] Iteration 237700, lr = 0.0257187, m = 0.9
I0802 01:15:39.903542 12219 solver.cpp:353] Iteration 237800 (7.1128 iter/s, 14.0592s/100 iter), loss = 2.12005
I0802 01:15:39.903604 12219 solver.cpp:375]     Train net output #0: loss = 1.81053 (* 1 = 1.81053 loss)
I0802 01:15:39.903612 12219 sgd_solver.cpp:136] Iteration 237800, lr = 0.0256875, m = 0.9
I0802 01:15:53.813252 12219 solver.cpp:353] Iteration 237900 (7.18942 iter/s, 13.9093s/100 iter), loss = 1.88591
I0802 01:15:53.813302 12219 solver.cpp:375]     Train net output #0: loss = 1.73164 (* 1 = 1.73164 loss)
I0802 01:15:53.813314 12219 sgd_solver.cpp:136] Iteration 237900, lr = 0.0256562, m = 0.9
I0802 01:16:07.747952 12219 solver.cpp:550] Iteration 238000, Testing net (#0)
I0802 01:16:27.934763 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.477765
I0802 01:16:27.934860 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.731234
I0802 01:16:27.934870 12219 solver.cpp:635]     Test net output #2: loss = 2.34862 (* 1 = 2.34862 loss)
I0802 01:16:27.934888 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1864s
I0802 01:16:28.093727 12219 solver.cpp:353] Iteration 238000 (2.91719 iter/s, 34.2796s/100 iter), loss = 1.53231
I0802 01:16:28.093755 12219 solver.cpp:375]     Train net output #0: loss = 1.7279 (* 1 = 1.7279 loss)
I0802 01:16:28.093760 12219 sgd_solver.cpp:136] Iteration 238000, lr = 0.025625, m = 0.9
I0802 01:16:42.256961 12219 solver.cpp:353] Iteration 238100 (7.06073 iter/s, 14.1628s/100 iter), loss = 1.76073
I0802 01:16:42.256986 12219 solver.cpp:375]     Train net output #0: loss = 1.90711 (* 1 = 1.90711 loss)
I0802 01:16:42.256990 12219 sgd_solver.cpp:136] Iteration 238100, lr = 0.0255938, m = 0.9
I0802 01:16:56.224589 12219 solver.cpp:353] Iteration 238200 (7.15961 iter/s, 13.9672s/100 iter), loss = 1.85545
I0802 01:16:56.224614 12219 solver.cpp:375]     Train net output #0: loss = 2.16501 (* 1 = 2.16501 loss)
I0802 01:16:56.224618 12219 sgd_solver.cpp:136] Iteration 238200, lr = 0.0255625, m = 0.9
I0802 01:17:10.262290 12219 solver.cpp:353] Iteration 238300 (7.12387 iter/s, 14.0373s/100 iter), loss = 1.5695
I0802 01:17:10.262377 12219 solver.cpp:375]     Train net output #0: loss = 1.21763 (* 1 = 1.21763 loss)
I0802 01:17:10.262390 12219 sgd_solver.cpp:136] Iteration 238300, lr = 0.0255313, m = 0.9
I0802 01:17:24.395383 12219 solver.cpp:353] Iteration 238400 (7.07578 iter/s, 14.1327s/100 iter), loss = 1.57966
I0802 01:17:24.395467 12219 solver.cpp:375]     Train net output #0: loss = 1.53303 (* 1 = 1.53303 loss)
I0802 01:17:24.395484 12219 sgd_solver.cpp:136] Iteration 238400, lr = 0.0255, m = 0.9
I0802 01:17:38.446889 12219 solver.cpp:353] Iteration 238500 (7.11687 iter/s, 14.0511s/100 iter), loss = 1.76994
I0802 01:17:38.447010 12219 solver.cpp:375]     Train net output #0: loss = 2.03042 (* 1 = 2.03042 loss)
I0802 01:17:38.447041 12219 sgd_solver.cpp:136] Iteration 238500, lr = 0.0254687, m = 0.9
I0802 01:17:52.496626 12219 solver.cpp:353] Iteration 238600 (7.11776 iter/s, 14.0494s/100 iter), loss = 1.31969
I0802 01:17:52.496718 12219 solver.cpp:375]     Train net output #0: loss = 1.15221 (* 1 = 1.15221 loss)
I0802 01:17:52.496724 12219 sgd_solver.cpp:136] Iteration 238600, lr = 0.0254375, m = 0.9
I0802 01:18:06.540047 12219 solver.cpp:353] Iteration 238700 (7.12097 iter/s, 14.043s/100 iter), loss = 1.66954
I0802 01:18:06.540079 12219 solver.cpp:375]     Train net output #0: loss = 1.75222 (* 1 = 1.75222 loss)
I0802 01:18:06.540086 12219 sgd_solver.cpp:136] Iteration 238700, lr = 0.0254062, m = 0.9
I0802 01:18:20.521405 12219 solver.cpp:353] Iteration 238800 (7.15257 iter/s, 13.981s/100 iter), loss = 2.00739
I0802 01:18:20.521447 12219 solver.cpp:375]     Train net output #0: loss = 2.04718 (* 1 = 2.04718 loss)
I0802 01:18:20.521458 12219 sgd_solver.cpp:136] Iteration 238800, lr = 0.025375, m = 0.9
I0802 01:18:34.623214 12219 solver.cpp:353] Iteration 238900 (7.09148 iter/s, 14.1014s/100 iter), loss = 1.58797
I0802 01:18:34.623953 12219 solver.cpp:375]     Train net output #0: loss = 1.61816 (* 1 = 1.61816 loss)
I0802 01:18:34.623960 12219 sgd_solver.cpp:136] Iteration 238900, lr = 0.0253438, m = 0.9
I0802 01:18:48.790125 12219 solver.cpp:353] Iteration 239000 (7.0589 iter/s, 14.1665s/100 iter), loss = 1.54751
I0802 01:18:48.790174 12219 solver.cpp:375]     Train net output #0: loss = 1.60082 (* 1 = 1.60082 loss)
I0802 01:18:48.790187 12219 sgd_solver.cpp:136] Iteration 239000, lr = 0.0253125, m = 0.9
I0802 01:19:02.782100 12219 solver.cpp:353] Iteration 239100 (7.14714 iter/s, 13.9916s/100 iter), loss = 1.88686
I0802 01:19:02.782130 12219 solver.cpp:375]     Train net output #0: loss = 1.67474 (* 1 = 1.67474 loss)
I0802 01:19:02.782135 12219 sgd_solver.cpp:136] Iteration 239100, lr = 0.0252813, m = 0.9
I0802 01:19:16.743567 12219 solver.cpp:353] Iteration 239200 (7.16277 iter/s, 13.9611s/100 iter), loss = 1.3218
I0802 01:19:16.743634 12219 solver.cpp:375]     Train net output #0: loss = 1.19459 (* 1 = 1.19459 loss)
I0802 01:19:16.743639 12219 sgd_solver.cpp:136] Iteration 239200, lr = 0.02525, m = 0.9
I0802 01:19:30.698586 12219 solver.cpp:353] Iteration 239300 (7.16607 iter/s, 13.9546s/100 iter), loss = 1.66285
I0802 01:19:30.698611 12219 solver.cpp:375]     Train net output #0: loss = 1.49853 (* 1 = 1.49853 loss)
I0802 01:19:30.698617 12219 sgd_solver.cpp:136] Iteration 239300, lr = 0.0252187, m = 0.9
I0802 01:19:44.773650 12219 solver.cpp:353] Iteration 239400 (7.10495 iter/s, 14.0747s/100 iter), loss = 1.75652
I0802 01:19:44.773716 12219 solver.cpp:375]     Train net output #0: loss = 1.83671 (* 1 = 1.83671 loss)
I0802 01:19:44.773738 12219 sgd_solver.cpp:136] Iteration 239400, lr = 0.0251875, m = 0.9
I0802 01:19:58.849817 12219 solver.cpp:353] Iteration 239500 (7.1044 iter/s, 14.0758s/100 iter), loss = 1.40883
I0802 01:19:58.849910 12219 solver.cpp:375]     Train net output #0: loss = 1.4161 (* 1 = 1.4161 loss)
I0802 01:19:58.849917 12219 sgd_solver.cpp:136] Iteration 239500, lr = 0.0251562, m = 0.9
I0802 01:20:12.951148 12219 solver.cpp:353] Iteration 239600 (7.09172 iter/s, 14.101s/100 iter), loss = 1.77754
I0802 01:20:12.951174 12219 solver.cpp:375]     Train net output #0: loss = 1.76898 (* 1 = 1.76898 loss)
I0802 01:20:12.951180 12219 sgd_solver.cpp:136] Iteration 239600, lr = 0.025125, m = 0.9
I0802 01:20:27.051800 12219 solver.cpp:353] Iteration 239700 (7.09206 iter/s, 14.1003s/100 iter), loss = 2.02129
I0802 01:20:27.051825 12219 solver.cpp:375]     Train net output #0: loss = 2.10275 (* 1 = 2.10275 loss)
I0802 01:20:27.051829 12219 sgd_solver.cpp:136] Iteration 239700, lr = 0.0250938, m = 0.9
I0802 01:20:40.992554 12219 solver.cpp:353] Iteration 239800 (7.17341 iter/s, 13.9404s/100 iter), loss = 1.34903
I0802 01:20:40.993275 12219 solver.cpp:375]     Train net output #0: loss = 1.4719 (* 1 = 1.4719 loss)
I0802 01:20:40.993283 12219 sgd_solver.cpp:136] Iteration 239800, lr = 0.0250625, m = 0.9
I0802 01:20:55.051223 12219 solver.cpp:353] Iteration 239900 (7.11324 iter/s, 14.0583s/100 iter), loss = 1.71793
I0802 01:20:55.051247 12219 solver.cpp:375]     Train net output #0: loss = 1.89619 (* 1 = 1.89619 loss)
I0802 01:20:55.051250 12219 sgd_solver.cpp:136] Iteration 239900, lr = 0.0250313, m = 0.9
I0802 01:21:08.952544 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_240000.caffemodel
I0802 01:21:08.980592 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_240000.solverstate
I0802 01:21:08.986515 12219 solver.cpp:550] Iteration 240000, Testing net (#0)
I0802 01:21:13.394052 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 01:21:28.815713 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.483647
I0802 01:21:28.815740 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.738763
I0802 01:21:28.815747 12219 solver.cpp:635]     Test net output #2: loss = 2.31553 (* 1 = 2.31553 loss)
I0802 01:21:28.815773 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8287s
I0802 01:21:28.970082 12219 solver.cpp:353] Iteration 240000 (2.94829 iter/s, 33.918s/100 iter), loss = 1.56616
I0802 01:21:28.970108 12219 solver.cpp:375]     Train net output #0: loss = 1.4085 (* 1 = 1.4085 loss)
I0802 01:21:28.970111 12219 sgd_solver.cpp:136] Iteration 240000, lr = 0.025, m = 0.9
I0802 01:21:42.970798 12219 solver.cpp:353] Iteration 240100 (7.14269 iter/s, 14.0003s/100 iter), loss = 2.02824
I0802 01:21:42.970827 12219 solver.cpp:375]     Train net output #0: loss = 2.21635 (* 1 = 2.21635 loss)
I0802 01:21:42.970834 12219 sgd_solver.cpp:136] Iteration 240100, lr = 0.0249687, m = 0.9
I0802 01:21:56.999188 12219 solver.cpp:353] Iteration 240200 (7.1286 iter/s, 14.028s/100 iter), loss = 1.65624
I0802 01:21:56.999320 12219 solver.cpp:375]     Train net output #0: loss = 1.87189 (* 1 = 1.87189 loss)
I0802 01:21:56.999333 12219 sgd_solver.cpp:136] Iteration 240200, lr = 0.0249375, m = 0.9
I0802 01:22:11.028805 12219 solver.cpp:353] Iteration 240300 (7.12798 iter/s, 14.0292s/100 iter), loss = 1.76112
I0802 01:22:11.028838 12219 solver.cpp:375]     Train net output #0: loss = 2.0127 (* 1 = 2.0127 loss)
I0802 01:22:11.028842 12219 sgd_solver.cpp:136] Iteration 240300, lr = 0.0249062, m = 0.9
I0802 01:22:25.094171 12219 solver.cpp:353] Iteration 240400 (7.10986 iter/s, 14.065s/100 iter), loss = 2.09038
I0802 01:22:25.094198 12219 solver.cpp:375]     Train net output #0: loss = 2.04674 (* 1 = 2.04674 loss)
I0802 01:22:25.094204 12219 sgd_solver.cpp:136] Iteration 240400, lr = 0.024875, m = 0.9
I0802 01:22:39.223367 12219 solver.cpp:353] Iteration 240500 (7.07774 iter/s, 14.1288s/100 iter), loss = 1.56166
I0802 01:22:39.223429 12219 solver.cpp:375]     Train net output #0: loss = 1.65978 (* 1 = 1.65978 loss)
I0802 01:22:39.223436 12219 sgd_solver.cpp:136] Iteration 240500, lr = 0.0248438, m = 0.9
I0802 01:22:53.191561 12219 solver.cpp:353] Iteration 240600 (7.15932 iter/s, 13.9678s/100 iter), loss = 1.64066
I0802 01:22:53.191591 12219 solver.cpp:375]     Train net output #0: loss = 1.58451 (* 1 = 1.58451 loss)
I0802 01:22:53.191596 12219 sgd_solver.cpp:136] Iteration 240600, lr = 0.0248125, m = 0.9
I0802 01:23:07.211271 12219 solver.cpp:353] Iteration 240700 (7.13301 iter/s, 14.0193s/100 iter), loss = 1.81568
I0802 01:23:07.211298 12219 solver.cpp:375]     Train net output #0: loss = 1.47746 (* 1 = 1.47746 loss)
I0802 01:23:07.211303 12219 sgd_solver.cpp:136] Iteration 240700, lr = 0.0247813, m = 0.9
I0802 01:23:21.250481 12219 solver.cpp:353] Iteration 240800 (7.1231 iter/s, 14.0388s/100 iter), loss = 2.24362
I0802 01:23:21.250548 12219 solver.cpp:375]     Train net output #0: loss = 2.35654 (* 1 = 2.35654 loss)
I0802 01:23:21.250555 12219 sgd_solver.cpp:136] Iteration 240800, lr = 0.02475, m = 0.9
I0802 01:23:35.219563 12219 solver.cpp:353] Iteration 240900 (7.15886 iter/s, 13.9687s/100 iter), loss = 1.88133
I0802 01:23:35.219586 12219 solver.cpp:375]     Train net output #0: loss = 1.91266 (* 1 = 1.91266 loss)
I0802 01:23:35.219593 12219 sgd_solver.cpp:136] Iteration 240900, lr = 0.0247188, m = 0.9
I0802 01:23:49.248668 12219 solver.cpp:353] Iteration 241000 (7.12823 iter/s, 14.0287s/100 iter), loss = 1.81621
I0802 01:23:49.248695 12219 solver.cpp:375]     Train net output #0: loss = 1.72 (* 1 = 1.72 loss)
I0802 01:23:49.248702 12219 sgd_solver.cpp:136] Iteration 241000, lr = 0.0246875, m = 0.9
I0802 01:24:03.184686 12219 solver.cpp:353] Iteration 241100 (7.17585 iter/s, 13.9356s/100 iter), loss = 1.77092
I0802 01:24:03.184764 12219 solver.cpp:375]     Train net output #0: loss = 1.47496 (* 1 = 1.47496 loss)
I0802 01:24:03.184773 12219 sgd_solver.cpp:136] Iteration 241100, lr = 0.0246562, m = 0.9
I0802 01:24:17.249097 12219 solver.cpp:353] Iteration 241200 (7.11034 iter/s, 14.064s/100 iter), loss = 1.74236
I0802 01:24:17.249122 12219 solver.cpp:375]     Train net output #0: loss = 1.90311 (* 1 = 1.90311 loss)
I0802 01:24:17.249126 12219 sgd_solver.cpp:136] Iteration 241200, lr = 0.024625, m = 0.9
I0802 01:24:31.271517 12219 solver.cpp:353] Iteration 241300 (7.13163 iter/s, 14.022s/100 iter), loss = 1.80675
I0802 01:24:31.271570 12219 solver.cpp:375]     Train net output #0: loss = 1.66769 (* 1 = 1.66769 loss)
I0802 01:24:31.271586 12219 sgd_solver.cpp:136] Iteration 241300, lr = 0.0245938, m = 0.9
I0802 01:24:45.292567 12219 solver.cpp:353] Iteration 241400 (7.13232 iter/s, 14.0207s/100 iter), loss = 1.72612
I0802 01:24:45.292623 12219 solver.cpp:375]     Train net output #0: loss = 1.55042 (* 1 = 1.55042 loss)
I0802 01:24:45.292629 12219 sgd_solver.cpp:136] Iteration 241400, lr = 0.0245625, m = 0.9
I0802 01:24:59.358736 12219 solver.cpp:353] Iteration 241500 (7.10945 iter/s, 14.0658s/100 iter), loss = 1.50579
I0802 01:24:59.358790 12219 solver.cpp:375]     Train net output #0: loss = 1.73456 (* 1 = 1.73456 loss)
I0802 01:24:59.358803 12219 sgd_solver.cpp:136] Iteration 241500, lr = 0.0245313, m = 0.9
I0802 01:25:13.286491 12219 solver.cpp:353] Iteration 241600 (7.1801 iter/s, 13.9274s/100 iter), loss = 2.02316
I0802 01:25:13.286516 12219 solver.cpp:375]     Train net output #0: loss = 2.00003 (* 1 = 2.00003 loss)
I0802 01:25:13.286522 12219 sgd_solver.cpp:136] Iteration 241600, lr = 0.0245, m = 0.9
I0802 01:25:27.206475 12219 solver.cpp:353] Iteration 241700 (7.18411 iter/s, 13.9196s/100 iter), loss = 1.35973
I0802 01:25:27.206535 12219 solver.cpp:375]     Train net output #0: loss = 1.24409 (* 1 = 1.24409 loss)
I0802 01:25:27.206542 12219 sgd_solver.cpp:136] Iteration 241700, lr = 0.0244687, m = 0.9
I0802 01:25:41.204300 12219 solver.cpp:353] Iteration 241800 (7.14416 iter/s, 13.9974s/100 iter), loss = 1.56155
I0802 01:25:41.204325 12219 solver.cpp:375]     Train net output #0: loss = 1.72365 (* 1 = 1.72365 loss)
I0802 01:25:41.204329 12219 sgd_solver.cpp:136] Iteration 241800, lr = 0.0244375, m = 0.9
I0802 01:25:55.215494 12219 solver.cpp:353] Iteration 241900 (7.13734 iter/s, 14.0108s/100 iter), loss = 1.79189
I0802 01:25:55.215528 12219 solver.cpp:375]     Train net output #0: loss = 1.58258 (* 1 = 1.58258 loss)
I0802 01:25:55.215531 12219 sgd_solver.cpp:136] Iteration 241900, lr = 0.0244062, m = 0.9
I0802 01:26:09.047276 12219 solver.cpp:550] Iteration 242000, Testing net (#0)
I0802 01:26:20.389629 12207 data_reader.cpp:264] Starting prefetch of epoch 13
I0802 01:26:28.685698 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.503529
I0802 01:26:28.685722 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.752175
I0802 01:26:28.685727 12219 solver.cpp:635]     Test net output #2: loss = 2.22326 (* 1 = 2.22326 loss)
I0802 01:26:28.685745 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.6379s
I0802 01:26:28.824254 12219 solver.cpp:353] Iteration 242000 (2.97549 iter/s, 33.6079s/100 iter), loss = 1.80883
I0802 01:26:28.824281 12219 solver.cpp:375]     Train net output #0: loss = 1.48443 (* 1 = 1.48443 loss)
I0802 01:26:28.824287 12219 sgd_solver.cpp:136] Iteration 242000, lr = 0.024375, m = 0.9
I0802 01:26:42.722435 12219 solver.cpp:353] Iteration 242100 (7.19538 iter/s, 13.8978s/100 iter), loss = 1.47078
I0802 01:26:42.722509 12219 solver.cpp:375]     Train net output #0: loss = 1.5366 (* 1 = 1.5366 loss)
I0802 01:26:42.722517 12219 sgd_solver.cpp:136] Iteration 242100, lr = 0.0243438, m = 0.9
I0802 01:26:56.831080 12219 solver.cpp:353] Iteration 242200 (7.08805 iter/s, 14.1082s/100 iter), loss = 1.97224
I0802 01:26:56.831110 12219 solver.cpp:375]     Train net output #0: loss = 1.53838 (* 1 = 1.53838 loss)
I0802 01:26:56.831117 12219 sgd_solver.cpp:136] Iteration 242200, lr = 0.0243125, m = 0.9
I0802 01:27:10.747498 12219 solver.cpp:353] Iteration 242300 (7.18595 iter/s, 13.916s/100 iter), loss = 1.63205
I0802 01:27:10.747524 12219 solver.cpp:375]     Train net output #0: loss = 1.57938 (* 1 = 1.57938 loss)
I0802 01:27:10.747529 12219 sgd_solver.cpp:136] Iteration 242300, lr = 0.0242813, m = 0.9
I0802 01:27:24.641428 12219 solver.cpp:353] Iteration 242400 (7.19759 iter/s, 13.8935s/100 iter), loss = 1.82006
I0802 01:27:24.641556 12219 solver.cpp:375]     Train net output #0: loss = 1.69134 (* 1 = 1.69134 loss)
I0802 01:27:24.641568 12219 sgd_solver.cpp:136] Iteration 242400, lr = 0.02425, m = 0.9
I0802 01:27:38.648257 12219 solver.cpp:353] Iteration 242500 (7.13958 iter/s, 14.0064s/100 iter), loss = 1.9071
I0802 01:27:38.648352 12219 solver.cpp:375]     Train net output #0: loss = 1.79515 (* 1 = 1.79515 loss)
I0802 01:27:38.648371 12219 sgd_solver.cpp:136] Iteration 242500, lr = 0.0242188, m = 0.9
I0802 01:27:52.772547 12219 solver.cpp:353] Iteration 242600 (7.08019 iter/s, 14.1239s/100 iter), loss = 1.76397
I0802 01:27:52.772575 12219 solver.cpp:375]     Train net output #0: loss = 1.8255 (* 1 = 1.8255 loss)
I0802 01:27:52.772581 12219 sgd_solver.cpp:136] Iteration 242600, lr = 0.0241875, m = 0.9
I0802 01:28:06.732842 12219 solver.cpp:353] Iteration 242700 (7.16338 iter/s, 13.9599s/100 iter), loss = 1.47892
I0802 01:28:06.732923 12219 solver.cpp:375]     Train net output #0: loss = 1.59205 (* 1 = 1.59205 loss)
I0802 01:28:06.732929 12219 sgd_solver.cpp:136] Iteration 242700, lr = 0.0241562, m = 0.9
I0802 01:28:20.846231 12219 solver.cpp:353] Iteration 242800 (7.08566 iter/s, 14.113s/100 iter), loss = 1.41822
I0802 01:28:20.846264 12219 solver.cpp:375]     Train net output #0: loss = 1.64972 (* 1 = 1.64972 loss)
I0802 01:28:20.846271 12219 sgd_solver.cpp:136] Iteration 242800, lr = 0.024125, m = 0.9
I0802 01:28:34.865213 12219 solver.cpp:353] Iteration 242900 (7.13338 iter/s, 14.0186s/100 iter), loss = 1.44868
I0802 01:28:34.865242 12219 solver.cpp:375]     Train net output #0: loss = 1.51232 (* 1 = 1.51232 loss)
I0802 01:28:34.865249 12219 sgd_solver.cpp:136] Iteration 242900, lr = 0.0240937, m = 0.9
I0802 01:28:48.836961 12219 solver.cpp:353] Iteration 243000 (7.1575 iter/s, 13.9714s/100 iter), loss = 1.62191
I0802 01:28:48.837034 12219 solver.cpp:375]     Train net output #0: loss = 1.59476 (* 1 = 1.59476 loss)
I0802 01:28:48.837041 12219 sgd_solver.cpp:136] Iteration 243000, lr = 0.0240625, m = 0.9
I0802 01:29:02.835327 12219 solver.cpp:353] Iteration 243100 (7.14388 iter/s, 13.998s/100 iter), loss = 1.82673
I0802 01:29:02.835351 12219 solver.cpp:375]     Train net output #0: loss = 2.06947 (* 1 = 2.06947 loss)
I0802 01:29:02.835355 12219 sgd_solver.cpp:136] Iteration 243100, lr = 0.0240313, m = 0.9
I0802 01:29:16.834013 12219 solver.cpp:353] Iteration 243200 (7.14372 iter/s, 13.9983s/100 iter), loss = 1.97711
I0802 01:29:16.834121 12219 solver.cpp:375]     Train net output #0: loss = 2.08176 (* 1 = 2.08176 loss)
I0802 01:29:16.834146 12219 sgd_solver.cpp:136] Iteration 243200, lr = 0.024, m = 0.9
I0802 01:29:30.887477 12219 solver.cpp:353] Iteration 243300 (7.11588 iter/s, 14.0531s/100 iter), loss = 1.93017
I0802 01:29:30.887547 12219 solver.cpp:375]     Train net output #0: loss = 1.89045 (* 1 = 1.89045 loss)
I0802 01:29:30.887553 12219 sgd_solver.cpp:136] Iteration 243300, lr = 0.0239688, m = 0.9
I0802 01:29:45.019249 12219 solver.cpp:353] Iteration 243400 (7.07644 iter/s, 14.1314s/100 iter), loss = 1.77762
I0802 01:29:45.019275 12219 solver.cpp:375]     Train net output #0: loss = 1.68512 (* 1 = 1.68512 loss)
I0802 01:29:45.019281 12219 sgd_solver.cpp:136] Iteration 243400, lr = 0.0239375, m = 0.9
I0802 01:29:58.965773 12219 solver.cpp:353] Iteration 243500 (7.17044 iter/s, 13.9461s/100 iter), loss = 1.90683
I0802 01:29:58.965798 12219 solver.cpp:375]     Train net output #0: loss = 1.52487 (* 1 = 1.52487 loss)
I0802 01:29:58.965803 12219 sgd_solver.cpp:136] Iteration 243500, lr = 0.0239062, m = 0.9
I0802 01:30:12.963048 12219 solver.cpp:353] Iteration 243600 (7.14444 iter/s, 13.9969s/100 iter), loss = 1.75218
I0802 01:30:12.963176 12219 solver.cpp:375]     Train net output #0: loss = 1.77537 (* 1 = 1.77537 loss)
I0802 01:30:12.963197 12219 sgd_solver.cpp:136] Iteration 243600, lr = 0.023875, m = 0.9
I0802 01:30:26.987892 12219 solver.cpp:353] Iteration 243700 (7.1304 iter/s, 14.0245s/100 iter), loss = 1.42955
I0802 01:30:26.987918 12219 solver.cpp:375]     Train net output #0: loss = 1.74398 (* 1 = 1.74398 loss)
I0802 01:30:26.987921 12219 sgd_solver.cpp:136] Iteration 243700, lr = 0.0238437, m = 0.9
I0802 01:30:41.009935 12219 solver.cpp:353] Iteration 243800 (7.13182 iter/s, 14.0217s/100 iter), loss = 1.57553
I0802 01:30:41.009963 12219 solver.cpp:375]     Train net output #0: loss = 1.44814 (* 1 = 1.44814 loss)
I0802 01:30:41.009968 12219 sgd_solver.cpp:136] Iteration 243800, lr = 0.0238125, m = 0.9
I0802 01:30:54.966897 12219 solver.cpp:353] Iteration 243900 (7.16508 iter/s, 13.9566s/100 iter), loss = 1.65424
I0802 01:30:54.966984 12219 solver.cpp:375]     Train net output #0: loss = 1.31239 (* 1 = 1.31239 loss)
I0802 01:30:54.966990 12219 sgd_solver.cpp:136] Iteration 243900, lr = 0.0237813, m = 0.9
I0802 01:31:08.727679 12219 solver.cpp:550] Iteration 244000, Testing net (#0)
I0802 01:31:29.047899 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.495882
I0802 01:31:29.047999 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.749469
I0802 01:31:29.048008 12219 solver.cpp:635]     Test net output #2: loss = 2.23944 (* 1 = 2.23944 loss)
I0802 01:31:29.048029 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3198s
I0802 01:31:29.196799 12219 solver.cpp:353] Iteration 244000 (2.9215 iter/s, 34.229s/100 iter), loss = 1.63877
I0802 01:31:29.197010 12219 solver.cpp:375]     Train net output #0: loss = 1.52884 (* 1 = 1.52884 loss)
I0802 01:31:29.197100 12219 sgd_solver.cpp:136] Iteration 244000, lr = 0.02375, m = 0.9
I0802 01:31:43.404294 12219 solver.cpp:353] Iteration 244100 (7.03873 iter/s, 14.2071s/100 iter), loss = 1.80449
I0802 01:31:43.404391 12219 solver.cpp:375]     Train net output #0: loss = 1.83409 (* 1 = 1.83409 loss)
I0802 01:31:43.404415 12219 sgd_solver.cpp:136] Iteration 244100, lr = 0.0237188, m = 0.9
I0802 01:31:57.550958 12219 solver.cpp:353] Iteration 244200 (7.069 iter/s, 14.1463s/100 iter), loss = 1.71091
I0802 01:31:57.550987 12219 solver.cpp:375]     Train net output #0: loss = 1.92513 (* 1 = 1.92513 loss)
I0802 01:31:57.550993 12219 sgd_solver.cpp:136] Iteration 244200, lr = 0.0236875, m = 0.9
I0802 01:32:11.580961 12219 solver.cpp:353] Iteration 244300 (7.12778 iter/s, 14.0296s/100 iter), loss = 1.79408
I0802 01:32:11.581013 12219 solver.cpp:375]     Train net output #0: loss = 1.30091 (* 1 = 1.30091 loss)
I0802 01:32:11.581020 12219 sgd_solver.cpp:136] Iteration 244300, lr = 0.0236562, m = 0.9
I0802 01:32:25.584810 12219 solver.cpp:353] Iteration 244400 (7.14109 iter/s, 14.0035s/100 iter), loss = 1.67961
I0802 01:32:25.584844 12219 solver.cpp:375]     Train net output #0: loss = 1.65323 (* 1 = 1.65323 loss)
I0802 01:32:25.584848 12219 sgd_solver.cpp:136] Iteration 244400, lr = 0.023625, m = 0.9
I0802 01:32:39.605032 12219 solver.cpp:353] Iteration 244500 (7.13275 iter/s, 14.0198s/100 iter), loss = 1.81706
I0802 01:32:39.605128 12219 solver.cpp:375]     Train net output #0: loss = 1.56986 (* 1 = 1.56986 loss)
I0802 01:32:39.605146 12219 sgd_solver.cpp:136] Iteration 244500, lr = 0.0235937, m = 0.9
I0802 01:32:53.756224 12219 solver.cpp:353] Iteration 244600 (7.06674 iter/s, 14.1508s/100 iter), loss = 1.76433
I0802 01:32:53.756305 12219 solver.cpp:375]     Train net output #0: loss = 1.67362 (* 1 = 1.67362 loss)
I0802 01:32:53.756314 12219 sgd_solver.cpp:136] Iteration 244600, lr = 0.0235625, m = 0.9
I0802 01:33:07.842900 12219 solver.cpp:353] Iteration 244700 (7.09911 iter/s, 14.0863s/100 iter), loss = 1.77687
I0802 01:33:07.842927 12219 solver.cpp:375]     Train net output #0: loss = 1.71485 (* 1 = 1.71485 loss)
I0802 01:33:07.842931 12219 sgd_solver.cpp:136] Iteration 244700, lr = 0.0235313, m = 0.9
I0802 01:33:21.859606 12219 solver.cpp:353] Iteration 244800 (7.13454 iter/s, 14.0163s/100 iter), loss = 1.68164
I0802 01:33:21.859634 12219 solver.cpp:375]     Train net output #0: loss = 1.58782 (* 1 = 1.58782 loss)
I0802 01:33:21.859642 12219 sgd_solver.cpp:136] Iteration 244800, lr = 0.0235, m = 0.9
I0802 01:33:35.909875 12219 solver.cpp:353] Iteration 244900 (7.11749 iter/s, 14.0499s/100 iter), loss = 1.82288
I0802 01:33:35.909952 12219 solver.cpp:375]     Train net output #0: loss = 1.99781 (* 1 = 1.99781 loss)
I0802 01:33:35.909958 12219 sgd_solver.cpp:136] Iteration 244900, lr = 0.0234688, m = 0.9
I0802 01:33:50.029943 12219 solver.cpp:353] Iteration 245000 (7.08231 iter/s, 14.1197s/100 iter), loss = 1.68307
I0802 01:33:50.029971 12219 solver.cpp:375]     Train net output #0: loss = 1.85176 (* 1 = 1.85176 loss)
I0802 01:33:50.029978 12219 sgd_solver.cpp:136] Iteration 245000, lr = 0.0234375, m = 0.9
I0802 01:34:04.013600 12219 solver.cpp:353] Iteration 245100 (7.1514 iter/s, 13.9833s/100 iter), loss = 1.92763
I0802 01:34:04.013628 12219 solver.cpp:375]     Train net output #0: loss = 2.38712 (* 1 = 2.38712 loss)
I0802 01:34:04.013635 12219 sgd_solver.cpp:136] Iteration 245100, lr = 0.0234063, m = 0.9
I0802 01:34:18.048951 12219 solver.cpp:353] Iteration 245200 (7.12506 iter/s, 14.035s/100 iter), loss = 1.63143
I0802 01:34:18.049021 12219 solver.cpp:375]     Train net output #0: loss = 1.66144 (* 1 = 1.66144 loss)
I0802 01:34:18.049027 12219 sgd_solver.cpp:136] Iteration 245200, lr = 0.023375, m = 0.9
I0802 01:34:32.065300 12219 solver.cpp:353] Iteration 245300 (7.13472 iter/s, 14.016s/100 iter), loss = 1.74728
I0802 01:34:32.065326 12219 solver.cpp:375]     Train net output #0: loss = 1.79082 (* 1 = 1.79082 loss)
I0802 01:34:32.065331 12219 sgd_solver.cpp:136] Iteration 245300, lr = 0.0233437, m = 0.9
I0802 01:34:46.139396 12219 solver.cpp:353] Iteration 245400 (7.10544 iter/s, 14.0737s/100 iter), loss = 1.37125
I0802 01:34:46.139420 12219 solver.cpp:375]     Train net output #0: loss = 1.43435 (* 1 = 1.43435 loss)
I0802 01:34:46.139426 12219 sgd_solver.cpp:136] Iteration 245400, lr = 0.0233125, m = 0.9
I0802 01:35:00.215306 12219 solver.cpp:353] Iteration 245500 (7.10453 iter/s, 14.0755s/100 iter), loss = 1.68592
I0802 01:35:00.215639 12219 solver.cpp:375]     Train net output #0: loss = 2.03397 (* 1 = 2.03397 loss)
I0802 01:35:00.215651 12219 sgd_solver.cpp:136] Iteration 245500, lr = 0.0232813, m = 0.9
I0802 01:35:14.323570 12219 solver.cpp:353] Iteration 245600 (7.08823 iter/s, 14.1079s/100 iter), loss = 1.43565
I0802 01:35:14.323598 12219 solver.cpp:375]     Train net output #0: loss = 1.52686 (* 1 = 1.52686 loss)
I0802 01:35:14.323602 12219 sgd_solver.cpp:136] Iteration 245600, lr = 0.02325, m = 0.9
I0802 01:35:28.371341 12219 solver.cpp:353] Iteration 245700 (7.11876 iter/s, 14.0474s/100 iter), loss = 1.63462
I0802 01:35:28.371445 12219 solver.cpp:375]     Train net output #0: loss = 1.43924 (* 1 = 1.43924 loss)
I0802 01:35:28.371472 12219 sgd_solver.cpp:136] Iteration 245700, lr = 0.0232188, m = 0.9
I0802 01:35:42.420373 12219 solver.cpp:353] Iteration 245800 (7.11812 iter/s, 14.0487s/100 iter), loss = 1.52753
I0802 01:35:42.420481 12219 solver.cpp:375]     Train net output #0: loss = 1.5259 (* 1 = 1.5259 loss)
I0802 01:35:42.420488 12219 sgd_solver.cpp:136] Iteration 245800, lr = 0.0231875, m = 0.9
I0802 01:35:56.463968 12219 solver.cpp:353] Iteration 245900 (7.12088 iter/s, 14.0432s/100 iter), loss = 1.89277
I0802 01:35:56.463991 12219 solver.cpp:375]     Train net output #0: loss = 2.18257 (* 1 = 2.18257 loss)
I0802 01:35:56.463995 12219 sgd_solver.cpp:136] Iteration 245900, lr = 0.0231562, m = 0.9
I0802 01:36:10.437309 12219 solver.cpp:550] Iteration 246000, Testing net (#0)
I0802 01:36:17.611179 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 01:36:30.660981 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.508412
I0802 01:36:30.661008 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.759351
I0802 01:36:30.661015 12219 solver.cpp:635]     Test net output #2: loss = 2.18536 (* 1 = 2.18536 loss)
I0802 01:36:30.661041 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2232s
I0802 01:36:30.808563 12219 solver.cpp:353] Iteration 246000 (2.91174 iter/s, 34.3437s/100 iter), loss = 1.39316
I0802 01:36:30.808655 12219 solver.cpp:375]     Train net output #0: loss = 1.18186 (* 1 = 1.18186 loss)
I0802 01:36:30.808676 12219 sgd_solver.cpp:136] Iteration 246000, lr = 0.023125, m = 0.9
I0802 01:36:44.794795 12219 solver.cpp:353] Iteration 246100 (7.15008 iter/s, 13.9858s/100 iter), loss = 1.60903
I0802 01:36:44.794821 12219 solver.cpp:375]     Train net output #0: loss = 1.81216 (* 1 = 1.81216 loss)
I0802 01:36:44.794826 12219 sgd_solver.cpp:136] Iteration 246100, lr = 0.0230937, m = 0.9
I0802 01:36:58.771379 12219 solver.cpp:353] Iteration 246200 (7.15502 iter/s, 13.9762s/100 iter), loss = 1.68568
I0802 01:36:58.771451 12219 solver.cpp:375]     Train net output #0: loss = 1.91339 (* 1 = 1.91339 loss)
I0802 01:36:58.771458 12219 sgd_solver.cpp:136] Iteration 246200, lr = 0.0230625, m = 0.9
I0802 01:37:12.747555 12219 solver.cpp:353] Iteration 246300 (7.15523 iter/s, 13.9758s/100 iter), loss = 1.54152
I0802 01:37:12.747582 12219 solver.cpp:375]     Train net output #0: loss = 1.88218 (* 1 = 1.88218 loss)
I0802 01:37:12.747589 12219 sgd_solver.cpp:136] Iteration 246300, lr = 0.0230313, m = 0.9
I0802 01:37:26.849040 12219 solver.cpp:353] Iteration 246400 (7.09164 iter/s, 14.1011s/100 iter), loss = 1.37968
I0802 01:37:26.849068 12219 solver.cpp:375]     Train net output #0: loss = 1.38414 (* 1 = 1.38414 loss)
I0802 01:37:26.849073 12219 sgd_solver.cpp:136] Iteration 246400, lr = 0.023, m = 0.9
I0802 01:37:40.897595 12219 solver.cpp:353] Iteration 246500 (7.11836 iter/s, 14.0482s/100 iter), loss = 1.78595
I0802 01:37:40.897806 12219 solver.cpp:375]     Train net output #0: loss = 1.40237 (* 1 = 1.40237 loss)
I0802 01:37:40.897822 12219 sgd_solver.cpp:136] Iteration 246500, lr = 0.0229688, m = 0.9
I0802 01:37:54.830735 12219 solver.cpp:353] Iteration 246600 (7.17733 iter/s, 13.9328s/100 iter), loss = 1.50834
I0802 01:37:54.830765 12219 solver.cpp:375]     Train net output #0: loss = 1.4485 (* 1 = 1.4485 loss)
I0802 01:37:54.830771 12219 sgd_solver.cpp:136] Iteration 246600, lr = 0.0229375, m = 0.9
I0802 01:38:08.698256 12219 solver.cpp:353] Iteration 246700 (7.21129 iter/s, 13.8671s/100 iter), loss = 1.5789
I0802 01:38:08.698282 12219 solver.cpp:375]     Train net output #0: loss = 1.89375 (* 1 = 1.89375 loss)
I0802 01:38:08.698287 12219 sgd_solver.cpp:136] Iteration 246700, lr = 0.0229062, m = 0.9
I0802 01:38:22.704828 12219 solver.cpp:353] Iteration 246800 (7.1397 iter/s, 14.0062s/100 iter), loss = 1.70301
I0802 01:38:22.704903 12219 solver.cpp:375]     Train net output #0: loss = 1.81516 (* 1 = 1.81516 loss)
I0802 01:38:22.704910 12219 sgd_solver.cpp:136] Iteration 246800, lr = 0.022875, m = 0.9
I0802 01:38:36.720160 12219 solver.cpp:353] Iteration 246900 (7.13524 iter/s, 14.015s/100 iter), loss = 1.58681
I0802 01:38:36.720185 12219 solver.cpp:375]     Train net output #0: loss = 1.76739 (* 1 = 1.76739 loss)
I0802 01:38:36.720188 12219 sgd_solver.cpp:136] Iteration 246900, lr = 0.0228437, m = 0.9
I0802 01:38:50.687840 12219 solver.cpp:353] Iteration 247000 (7.15958 iter/s, 13.9673s/100 iter), loss = 1.61914
I0802 01:38:50.687865 12219 solver.cpp:375]     Train net output #0: loss = 1.85203 (* 1 = 1.85203 loss)
I0802 01:38:50.687868 12219 sgd_solver.cpp:136] Iteration 247000, lr = 0.0228125, m = 0.9
I0802 01:39:04.686693 12219 solver.cpp:353] Iteration 247100 (7.14363 iter/s, 13.9985s/100 iter), loss = 1.91004
I0802 01:39:04.686791 12219 solver.cpp:375]     Train net output #0: loss = 1.57842 (* 1 = 1.57842 loss)
I0802 01:39:04.686800 12219 sgd_solver.cpp:136] Iteration 247100, lr = 0.0227813, m = 0.9
I0802 01:39:18.669302 12219 solver.cpp:353] Iteration 247200 (7.15193 iter/s, 13.9822s/100 iter), loss = 1.26145
I0802 01:39:18.669333 12219 solver.cpp:375]     Train net output #0: loss = 1.26926 (* 1 = 1.26926 loss)
I0802 01:39:18.669339 12219 sgd_solver.cpp:136] Iteration 247200, lr = 0.02275, m = 0.9
I0802 01:39:32.672291 12219 solver.cpp:353] Iteration 247300 (7.14153 iter/s, 14.0026s/100 iter), loss = 1.77538
I0802 01:39:32.672319 12219 solver.cpp:375]     Train net output #0: loss = 1.69241 (* 1 = 1.69241 loss)
I0802 01:39:32.672325 12219 sgd_solver.cpp:136] Iteration 247300, lr = 0.0227188, m = 0.9
I0802 01:39:46.687057 12219 solver.cpp:353] Iteration 247400 (7.13552 iter/s, 14.0144s/100 iter), loss = 1.88707
I0802 01:39:46.687119 12219 solver.cpp:375]     Train net output #0: loss = 1.42917 (* 1 = 1.42917 loss)
I0802 01:39:46.687125 12219 sgd_solver.cpp:136] Iteration 247400, lr = 0.0226875, m = 0.9
I0802 01:40:00.746409 12219 solver.cpp:353] Iteration 247500 (7.1129 iter/s, 14.059s/100 iter), loss = 2.01735
I0802 01:40:00.746438 12219 solver.cpp:375]     Train net output #0: loss = 2.14932 (* 1 = 2.14932 loss)
I0802 01:40:00.746443 12219 sgd_solver.cpp:136] Iteration 247500, lr = 0.0226563, m = 0.9
I0802 01:40:14.653151 12219 solver.cpp:353] Iteration 247600 (7.19096 iter/s, 13.9064s/100 iter), loss = 1.74573
I0802 01:40:14.653179 12219 solver.cpp:375]     Train net output #0: loss = 1.69203 (* 1 = 1.69203 loss)
I0802 01:40:14.653187 12219 sgd_solver.cpp:136] Iteration 247600, lr = 0.022625, m = 0.9
I0802 01:40:28.549376 12219 solver.cpp:353] Iteration 247700 (7.19639 iter/s, 13.8959s/100 iter), loss = 1.83136
I0802 01:40:28.549454 12219 solver.cpp:375]     Train net output #0: loss = 2.10463 (* 1 = 2.10463 loss)
I0802 01:40:28.549461 12219 sgd_solver.cpp:136] Iteration 247700, lr = 0.0225937, m = 0.9
I0802 01:40:42.572144 12219 solver.cpp:353] Iteration 247800 (7.13145 iter/s, 14.0224s/100 iter), loss = 1.87543
I0802 01:40:42.572167 12219 solver.cpp:375]     Train net output #0: loss = 2.02499 (* 1 = 2.02499 loss)
I0802 01:40:42.572172 12219 sgd_solver.cpp:136] Iteration 247800, lr = 0.0225625, m = 0.9
I0802 01:40:56.649761 12219 solver.cpp:353] Iteration 247900 (7.10367 iter/s, 14.0772s/100 iter), loss = 2.04738
I0802 01:40:56.649791 12219 solver.cpp:375]     Train net output #0: loss = 2.51847 (* 1 = 2.51847 loss)
I0802 01:40:56.649798 12219 sgd_solver.cpp:136] Iteration 247900, lr = 0.0225312, m = 0.9
I0802 01:41:10.494289 12219 solver.cpp:550] Iteration 248000, Testing net (#0)
I0802 01:41:30.199611 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.518059
I0802 01:41:30.199636 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.768528
I0802 01:41:30.199643 12219 solver.cpp:635]     Test net output #2: loss = 2.13099 (* 1 = 2.13099 loss)
I0802 01:41:30.199668 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7049s
I0802 01:41:30.348055 12219 solver.cpp:353] Iteration 248000 (2.96759 iter/s, 33.6974s/100 iter), loss = 1.51168
I0802 01:41:30.348080 12219 solver.cpp:375]     Train net output #0: loss = 1.48163 (* 1 = 1.48163 loss)
I0802 01:41:30.348085 12219 sgd_solver.cpp:136] Iteration 248000, lr = 0.0225, m = 0.9
I0802 01:41:44.323758 12219 solver.cpp:353] Iteration 248100 (7.15547 iter/s, 13.9753s/100 iter), loss = 1.37954
I0802 01:41:44.323833 12219 solver.cpp:375]     Train net output #0: loss = 1.45482 (* 1 = 1.45482 loss)
I0802 01:41:44.323842 12219 sgd_solver.cpp:136] Iteration 248100, lr = 0.0224688, m = 0.9
I0802 01:41:58.302876 12219 solver.cpp:353] Iteration 248200 (7.15372 iter/s, 13.9787s/100 iter), loss = 1.50692
I0802 01:41:58.303041 12219 solver.cpp:375]     Train net output #0: loss = 1.50735 (* 1 = 1.50735 loss)
I0802 01:41:58.303061 12219 sgd_solver.cpp:136] Iteration 248200, lr = 0.0224375, m = 0.9
I0802 01:42:12.251121 12219 solver.cpp:353] Iteration 248300 (7.16956 iter/s, 13.9479s/100 iter), loss = 2.17263
I0802 01:42:12.251145 12219 solver.cpp:375]     Train net output #0: loss = 2.11331 (* 1 = 2.11331 loss)
I0802 01:42:12.251150 12219 sgd_solver.cpp:136] Iteration 248300, lr = 0.0224063, m = 0.9
I0802 01:42:26.237691 12219 solver.cpp:353] Iteration 248400 (7.14991 iter/s, 13.9862s/100 iter), loss = 1.61761
I0802 01:42:26.237746 12219 solver.cpp:375]     Train net output #0: loss = 1.7516 (* 1 = 1.7516 loss)
I0802 01:42:26.237751 12219 sgd_solver.cpp:136] Iteration 248400, lr = 0.022375, m = 0.9
I0802 01:42:40.103101 12219 solver.cpp:353] Iteration 248500 (7.21239 iter/s, 13.865s/100 iter), loss = 1.62741
I0802 01:42:40.103132 12219 solver.cpp:375]     Train net output #0: loss = 2.0102 (* 1 = 2.0102 loss)
I0802 01:42:40.103138 12219 sgd_solver.cpp:136] Iteration 248500, lr = 0.0223437, m = 0.9
I0802 01:42:54.066381 12219 solver.cpp:353] Iteration 248600 (7.16184 iter/s, 13.9629s/100 iter), loss = 2.11858
I0802 01:42:54.066414 12219 solver.cpp:375]     Train net output #0: loss = 2.40295 (* 1 = 2.40295 loss)
I0802 01:42:54.066418 12219 sgd_solver.cpp:136] Iteration 248600, lr = 0.0223125, m = 0.9
I0802 01:43:08.267626 12219 solver.cpp:353] Iteration 248700 (7.04183 iter/s, 14.2009s/100 iter), loss = 1.29543
I0802 01:43:08.267716 12219 solver.cpp:375]     Train net output #0: loss = 1.03166 (* 1 = 1.03166 loss)
I0802 01:43:08.267726 12219 sgd_solver.cpp:136] Iteration 248700, lr = 0.0222812, m = 0.9
I0802 01:43:22.301736 12219 solver.cpp:353] Iteration 248800 (7.12569 iter/s, 14.0337s/100 iter), loss = 1.43435
I0802 01:43:22.301791 12219 solver.cpp:375]     Train net output #0: loss = 1.4028 (* 1 = 1.4028 loss)
I0802 01:43:22.301805 12219 sgd_solver.cpp:136] Iteration 248800, lr = 0.02225, m = 0.9
I0802 01:43:36.332305 12219 solver.cpp:353] Iteration 248900 (7.12749 iter/s, 14.0302s/100 iter), loss = 2.15051
I0802 01:43:36.332334 12219 solver.cpp:375]     Train net output #0: loss = 1.81128 (* 1 = 1.81128 loss)
I0802 01:43:36.332340 12219 sgd_solver.cpp:136] Iteration 248900, lr = 0.0222188, m = 0.9
I0802 01:43:50.335906 12219 solver.cpp:353] Iteration 249000 (7.14122 iter/s, 14.0032s/100 iter), loss = 1.86128
I0802 01:43:50.336005 12219 solver.cpp:375]     Train net output #0: loss = 1.71474 (* 1 = 1.71474 loss)
I0802 01:43:50.336014 12219 sgd_solver.cpp:136] Iteration 249000, lr = 0.0221875, m = 0.9
I0802 01:44:04.263556 12219 solver.cpp:353] Iteration 249100 (7.18016 iter/s, 13.9273s/100 iter), loss = 1.33937
I0802 01:44:04.263669 12219 solver.cpp:375]     Train net output #0: loss = 1.19245 (* 1 = 1.19245 loss)
I0802 01:44:04.263687 12219 sgd_solver.cpp:136] Iteration 249100, lr = 0.0221563, m = 0.9
I0802 01:44:18.360716 12219 solver.cpp:353] Iteration 249200 (7.09382 iter/s, 14.0968s/100 iter), loss = 1.71817
I0802 01:44:18.360747 12219 solver.cpp:375]     Train net output #0: loss = 1.71321 (* 1 = 1.71321 loss)
I0802 01:44:18.360754 12219 sgd_solver.cpp:136] Iteration 249200, lr = 0.022125, m = 0.9
I0802 01:44:32.406474 12219 solver.cpp:353] Iteration 249300 (7.11978 iter/s, 14.0454s/100 iter), loss = 1.50353
I0802 01:44:32.406522 12219 solver.cpp:375]     Train net output #0: loss = 1.68959 (* 1 = 1.68959 loss)
I0802 01:44:32.406527 12219 sgd_solver.cpp:136] Iteration 249300, lr = 0.0220937, m = 0.9
I0802 01:44:46.455570 12219 solver.cpp:353] Iteration 249400 (7.11809 iter/s, 14.0487s/100 iter), loss = 1.76622
I0802 01:44:46.455600 12219 solver.cpp:375]     Train net output #0: loss = 1.90686 (* 1 = 1.90686 loss)
I0802 01:44:46.455605 12219 sgd_solver.cpp:136] Iteration 249400, lr = 0.0220625, m = 0.9
I0802 01:45:00.454836 12219 solver.cpp:353] Iteration 249500 (7.14343 iter/s, 13.9989s/100 iter), loss = 1.94208
I0802 01:45:00.454864 12219 solver.cpp:375]     Train net output #0: loss = 2.06211 (* 1 = 2.06211 loss)
I0802 01:45:00.454871 12219 sgd_solver.cpp:136] Iteration 249500, lr = 0.0220312, m = 0.9
I0802 01:45:14.435706 12219 solver.cpp:353] Iteration 249600 (7.15282 iter/s, 13.9805s/100 iter), loss = 1.30319
I0802 01:45:14.435829 12219 solver.cpp:375]     Train net output #0: loss = 1.32163 (* 1 = 1.32163 loss)
I0802 01:45:14.435848 12219 sgd_solver.cpp:136] Iteration 249600, lr = 0.022, m = 0.9
I0802 01:45:28.565124 12219 solver.cpp:353] Iteration 249700 (7.07763 iter/s, 14.129s/100 iter), loss = 1.61776
I0802 01:45:28.565238 12219 solver.cpp:375]     Train net output #0: loss = 1.61915 (* 1 = 1.61915 loss)
I0802 01:45:28.565263 12219 sgd_solver.cpp:136] Iteration 249700, lr = 0.0219688, m = 0.9
I0802 01:45:42.650671 12219 solver.cpp:353] Iteration 249800 (7.09967 iter/s, 14.0852s/100 iter), loss = 1.27141
I0802 01:45:42.650696 12219 solver.cpp:375]     Train net output #0: loss = 1.50172 (* 1 = 1.50172 loss)
I0802 01:45:42.650701 12219 sgd_solver.cpp:136] Iteration 249800, lr = 0.0219375, m = 0.9
I0802 01:45:56.644541 12219 solver.cpp:353] Iteration 249900 (7.14618 iter/s, 13.9935s/100 iter), loss = 2.0238
I0802 01:45:56.644626 12219 solver.cpp:375]     Train net output #0: loss = 2.16011 (* 1 = 2.16011 loss)
I0802 01:45:56.644634 12219 sgd_solver.cpp:136] Iteration 249900, lr = 0.0219063, m = 0.9
I0802 01:46:10.528218 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_250000.caffemodel
I0802 01:46:10.640558 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_250000.solverstate
I0802 01:46:10.644969 12219 solver.cpp:550] Iteration 250000, Testing net (#0)
I0802 01:46:30.630676 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.515059
I0802 01:46:30.630770 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.760291
I0802 01:46:30.630782 12219 solver.cpp:635]     Test net output #2: loss = 2.14877 (* 1 = 2.14877 loss)
I0802 01:46:30.630805 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9853s
I0802 01:46:30.769744 12219 solver.cpp:353] Iteration 250000 (2.93046 iter/s, 34.1243s/100 iter), loss = 1.62129
I0802 01:46:30.769770 12219 solver.cpp:375]     Train net output #0: loss = 1.53698 (* 1 = 1.53698 loss)
I0802 01:46:30.769775 12219 sgd_solver.cpp:136] Iteration 250000, lr = 0.021875, m = 0.9
I0802 01:46:44.813977 12219 solver.cpp:353] Iteration 250100 (7.12056 iter/s, 14.0438s/100 iter), loss = 1.88511
I0802 01:46:44.814003 12219 solver.cpp:375]     Train net output #0: loss = 2.18874 (* 1 = 2.18874 loss)
I0802 01:46:44.814008 12219 sgd_solver.cpp:136] Iteration 250100, lr = 0.0218438, m = 0.9
I0802 01:46:58.877022 12219 solver.cpp:353] Iteration 250200 (7.11103 iter/s, 14.0627s/100 iter), loss = 1.71971
I0802 01:46:58.877043 12219 solver.cpp:375]     Train net output #0: loss = 1.73161 (* 1 = 1.73161 loss)
I0802 01:46:58.877048 12219 sgd_solver.cpp:136] Iteration 250200, lr = 0.0218125, m = 0.9
I0802 01:47:12.978794 12219 solver.cpp:353] Iteration 250300 (7.0915 iter/s, 14.1014s/100 iter), loss = 1.75468
I0802 01:47:12.978863 12219 solver.cpp:375]     Train net output #0: loss = 2.02187 (* 1 = 2.02187 loss)
I0802 01:47:12.978870 12219 sgd_solver.cpp:136] Iteration 250300, lr = 0.0217812, m = 0.9
I0802 01:47:27.023329 12219 solver.cpp:353] Iteration 250400 (7.1204 iter/s, 14.0442s/100 iter), loss = 1.4927
I0802 01:47:27.023355 12219 solver.cpp:375]     Train net output #0: loss = 1.49057 (* 1 = 1.49057 loss)
I0802 01:47:27.023360 12219 sgd_solver.cpp:136] Iteration 250400, lr = 0.02175, m = 0.9
I0802 01:47:41.117012 12219 solver.cpp:353] Iteration 250500 (7.09557 iter/s, 14.0933s/100 iter), loss = 1.73579
I0802 01:47:41.117036 12219 solver.cpp:375]     Train net output #0: loss = 1.45879 (* 1 = 1.45879 loss)
I0802 01:47:41.117041 12219 sgd_solver.cpp:136] Iteration 250500, lr = 0.0217188, m = 0.9
I0802 01:47:55.328330 12219 solver.cpp:353] Iteration 250600 (7.03684 iter/s, 14.2109s/100 iter), loss = 1.59359
I0802 01:47:55.328438 12219 solver.cpp:375]     Train net output #0: loss = 1.55534 (* 1 = 1.55534 loss)
I0802 01:47:55.328459 12219 sgd_solver.cpp:136] Iteration 250600, lr = 0.0216875, m = 0.9
I0802 01:48:09.456297 12219 solver.cpp:353] Iteration 250700 (7.07835 iter/s, 14.1276s/100 iter), loss = 1.45241
I0802 01:48:09.456343 12219 solver.cpp:375]     Train net output #0: loss = 1.61935 (* 1 = 1.61935 loss)
I0802 01:48:09.456356 12219 sgd_solver.cpp:136] Iteration 250700, lr = 0.0216563, m = 0.9
I0802 01:48:23.629499 12219 solver.cpp:353] Iteration 250800 (7.05576 iter/s, 14.1728s/100 iter), loss = 1.4902
I0802 01:48:23.629529 12219 solver.cpp:375]     Train net output #0: loss = 1.22242 (* 1 = 1.22242 loss)
I0802 01:48:23.629535 12219 sgd_solver.cpp:136] Iteration 250800, lr = 0.021625, m = 0.9
I0802 01:48:37.596369 12219 solver.cpp:353] Iteration 250900 (7.16 iter/s, 13.9665s/100 iter), loss = 1.79186
I0802 01:48:37.596473 12219 solver.cpp:375]     Train net output #0: loss = 2.10258 (* 1 = 2.10258 loss)
I0802 01:48:37.596485 12219 sgd_solver.cpp:136] Iteration 250900, lr = 0.0215937, m = 0.9
I0802 01:48:51.641448 12219 solver.cpp:353] Iteration 251000 (7.12012 iter/s, 14.0447s/100 iter), loss = 1.20941
I0802 01:48:51.641551 12219 solver.cpp:375]     Train net output #0: loss = 0.922873 (* 1 = 0.922873 loss)
I0802 01:48:51.641577 12219 sgd_solver.cpp:136] Iteration 251000, lr = 0.0215625, m = 0.9
I0802 01:49:05.618098 12219 solver.cpp:353] Iteration 251100 (7.15498 iter/s, 13.9763s/100 iter), loss = 1.46496
I0802 01:49:05.618131 12219 solver.cpp:375]     Train net output #0: loss = 1.40332 (* 1 = 1.40332 loss)
I0802 01:49:05.618137 12219 sgd_solver.cpp:136] Iteration 251100, lr = 0.0215312, m = 0.9
I0802 01:49:19.676980 12219 solver.cpp:353] Iteration 251200 (7.11313 iter/s, 14.0585s/100 iter), loss = 1.62784
I0802 01:49:19.677039 12219 solver.cpp:375]     Train net output #0: loss = 1.45492 (* 1 = 1.45492 loss)
I0802 01:49:19.677047 12219 sgd_solver.cpp:136] Iteration 251200, lr = 0.0215, m = 0.9
I0802 01:49:33.692461 12219 solver.cpp:353] Iteration 251300 (7.13516 iter/s, 14.0151s/100 iter), loss = 1.65925
I0802 01:49:33.692490 12219 solver.cpp:375]     Train net output #0: loss = 1.90265 (* 1 = 1.90265 loss)
I0802 01:49:33.692497 12219 sgd_solver.cpp:136] Iteration 251300, lr = 0.0214688, m = 0.9
I0802 01:49:47.698431 12219 solver.cpp:353] Iteration 251400 (7.14001 iter/s, 14.0056s/100 iter), loss = 2.11593
I0802 01:49:47.698521 12219 solver.cpp:375]     Train net output #0: loss = 2.55251 (* 1 = 2.55251 loss)
I0802 01:49:47.698540 12219 sgd_solver.cpp:136] Iteration 251400, lr = 0.0214375, m = 0.9
I0802 01:50:01.801851 12219 solver.cpp:353] Iteration 251500 (7.09067 iter/s, 14.103s/100 iter), loss = 1.66447
I0802 01:50:01.801903 12219 solver.cpp:375]     Train net output #0: loss = 1.80464 (* 1 = 1.80464 loss)
I0802 01:50:01.801908 12219 sgd_solver.cpp:136] Iteration 251500, lr = 0.0214063, m = 0.9
I0802 01:50:15.787533 12219 solver.cpp:353] Iteration 251600 (7.15036 iter/s, 13.9853s/100 iter), loss = 1.55662
I0802 01:50:15.787562 12219 solver.cpp:375]     Train net output #0: loss = 1.40859 (* 1 = 1.40859 loss)
I0802 01:50:15.787570 12219 sgd_solver.cpp:136] Iteration 251600, lr = 0.021375, m = 0.9
I0802 01:50:29.850144 12219 solver.cpp:353] Iteration 251700 (7.11125 iter/s, 14.0622s/100 iter), loss = 1.53817
I0802 01:50:29.850172 12219 solver.cpp:375]     Train net output #0: loss = 1.36903 (* 1 = 1.36903 loss)
I0802 01:50:29.850178 12219 sgd_solver.cpp:136] Iteration 251700, lr = 0.0213438, m = 0.9
I0802 01:50:43.882870 12219 solver.cpp:353] Iteration 251800 (7.12639 iter/s, 14.0323s/100 iter), loss = 1.42265
I0802 01:50:43.882936 12219 solver.cpp:375]     Train net output #0: loss = 1.45495 (* 1 = 1.45495 loss)
I0802 01:50:43.882942 12219 sgd_solver.cpp:136] Iteration 251800, lr = 0.0213125, m = 0.9
I0802 01:50:57.707168 12219 solver.cpp:353] Iteration 251900 (7.23383 iter/s, 13.8239s/100 iter), loss = 1.96973
I0802 01:50:57.707219 12219 solver.cpp:375]     Train net output #0: loss = 2.01659 (* 1 = 2.01659 loss)
I0802 01:50:57.707232 12219 sgd_solver.cpp:136] Iteration 251900, lr = 0.0212812, m = 0.9
I0802 01:51:11.542268 12219 solver.cpp:550] Iteration 252000, Testing net (#0)
I0802 01:51:21.111387 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 01:51:31.401834 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.526294
I0802 01:51:31.401859 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.770763
I0802 01:51:31.401866 12219 solver.cpp:635]     Test net output #2: loss = 2.10351 (* 1 = 2.10351 loss)
I0802 01:51:31.401887 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8591s
I0802 01:51:31.541889 12219 solver.cpp:353] Iteration 252000 (2.95562 iter/s, 33.8338s/100 iter), loss = 1.54739
I0802 01:51:31.541919 12219 solver.cpp:375]     Train net output #0: loss = 1.89072 (* 1 = 1.89072 loss)
I0802 01:51:31.541925 12219 sgd_solver.cpp:136] Iteration 252000, lr = 0.02125, m = 0.9
I0802 01:51:45.570590 12219 solver.cpp:353] Iteration 252100 (7.12844 iter/s, 14.0283s/100 iter), loss = 1.78255
I0802 01:51:45.570617 12219 solver.cpp:375]     Train net output #0: loss = 2.02651 (* 1 = 2.02651 loss)
I0802 01:51:45.570694 12219 sgd_solver.cpp:136] Iteration 252100, lr = 0.0212188, m = 0.9
I0802 01:51:59.567692 12219 solver.cpp:353] Iteration 252200 (7.14453 iter/s, 13.9967s/100 iter), loss = 2.27986
I0802 01:51:59.567754 12219 solver.cpp:375]     Train net output #0: loss = 2.18308 (* 1 = 2.18308 loss)
I0802 01:51:59.567760 12219 sgd_solver.cpp:136] Iteration 252200, lr = 0.0211875, m = 0.9
I0802 01:52:13.561887 12219 solver.cpp:353] Iteration 252300 (7.14601 iter/s, 13.9938s/100 iter), loss = 1.77891
I0802 01:52:13.561913 12219 solver.cpp:375]     Train net output #0: loss = 1.75376 (* 1 = 1.75376 loss)
I0802 01:52:13.561918 12219 sgd_solver.cpp:136] Iteration 252300, lr = 0.0211563, m = 0.9
I0802 01:52:27.579526 12219 solver.cpp:353] Iteration 252400 (7.13406 iter/s, 14.0173s/100 iter), loss = 1.75049
I0802 01:52:27.579552 12219 solver.cpp:375]     Train net output #0: loss = 1.67633 (* 1 = 1.67633 loss)
I0802 01:52:27.579556 12219 sgd_solver.cpp:136] Iteration 252400, lr = 0.021125, m = 0.9
I0802 01:52:41.637759 12219 solver.cpp:353] Iteration 252500 (7.11346 iter/s, 14.0579s/100 iter), loss = 1.89813
I0802 01:52:41.637883 12219 solver.cpp:375]     Train net output #0: loss = 1.6919 (* 1 = 1.6919 loss)
I0802 01:52:41.637903 12219 sgd_solver.cpp:136] Iteration 252500, lr = 0.0210938, m = 0.9
I0802 01:52:55.639945 12219 solver.cpp:353] Iteration 252600 (7.14194 iter/s, 14.0018s/100 iter), loss = 1.43517
I0802 01:52:55.639981 12219 solver.cpp:375]     Train net output #0: loss = 1.46272 (* 1 = 1.46272 loss)
I0802 01:52:55.639988 12219 sgd_solver.cpp:136] Iteration 252600, lr = 0.0210625, m = 0.9
I0802 01:53:09.665273 12219 solver.cpp:353] Iteration 252700 (7.13015 iter/s, 14.025s/100 iter), loss = 1.47247
I0802 01:53:09.665304 12219 solver.cpp:375]     Train net output #0: loss = 1.41869 (* 1 = 1.41869 loss)
I0802 01:53:09.665310 12219 sgd_solver.cpp:136] Iteration 252700, lr = 0.0210312, m = 0.9
I0802 01:53:23.660430 12219 solver.cpp:353] Iteration 252800 (7.14552 iter/s, 13.9948s/100 iter), loss = 1.57638
I0802 01:53:23.660493 12219 solver.cpp:375]     Train net output #0: loss = 1.9425 (* 1 = 1.9425 loss)
I0802 01:53:23.660500 12219 sgd_solver.cpp:136] Iteration 252800, lr = 0.021, m = 0.9
I0802 01:53:37.683689 12219 solver.cpp:353] Iteration 252900 (7.1312 iter/s, 14.0229s/100 iter), loss = 1.55011
I0802 01:53:37.683719 12219 solver.cpp:375]     Train net output #0: loss = 1.09492 (* 1 = 1.09492 loss)
I0802 01:53:37.683725 12219 sgd_solver.cpp:136] Iteration 252900, lr = 0.0209687, m = 0.9
I0802 01:53:51.728209 12219 solver.cpp:353] Iteration 253000 (7.12041 iter/s, 14.0441s/100 iter), loss = 1.50177
I0802 01:53:51.728262 12219 solver.cpp:375]     Train net output #0: loss = 1.48808 (* 1 = 1.48808 loss)
I0802 01:53:51.728273 12219 sgd_solver.cpp:136] Iteration 253000, lr = 0.0209375, m = 0.9
I0802 01:54:05.792279 12219 solver.cpp:353] Iteration 253100 (7.11051 iter/s, 14.0637s/100 iter), loss = 1.28904
I0802 01:54:05.792562 12219 solver.cpp:375]     Train net output #0: loss = 1.24514 (* 1 = 1.24514 loss)
I0802 01:54:05.792662 12219 sgd_solver.cpp:136] Iteration 253100, lr = 0.0209063, m = 0.9
I0802 01:54:19.734361 12219 solver.cpp:353] Iteration 253200 (7.17272 iter/s, 13.9417s/100 iter), loss = 1.71981
I0802 01:54:19.734391 12219 solver.cpp:375]     Train net output #0: loss = 1.59585 (* 1 = 1.59585 loss)
I0802 01:54:19.734397 12219 sgd_solver.cpp:136] Iteration 253200, lr = 0.020875, m = 0.9
I0802 01:54:33.729524 12219 solver.cpp:353] Iteration 253300 (7.14552 iter/s, 13.9948s/100 iter), loss = 1.7832
I0802 01:54:33.729552 12219 solver.cpp:375]     Train net output #0: loss = 1.78023 (* 1 = 1.78023 loss)
I0802 01:54:33.729558 12219 sgd_solver.cpp:136] Iteration 253300, lr = 0.0208437, m = 0.9
I0802 01:54:47.730075 12219 solver.cpp:353] Iteration 253400 (7.14278 iter/s, 14.0002s/100 iter), loss = 1.88069
I0802 01:54:47.730185 12219 solver.cpp:375]     Train net output #0: loss = 1.80711 (* 1 = 1.80711 loss)
I0802 01:54:47.730195 12219 sgd_solver.cpp:136] Iteration 253400, lr = 0.0208125, m = 0.9
I0802 01:55:01.687876 12219 solver.cpp:353] Iteration 253500 (7.16464 iter/s, 13.9574s/100 iter), loss = 1.86293
I0802 01:55:01.687904 12219 solver.cpp:375]     Train net output #0: loss = 1.43045 (* 1 = 1.43045 loss)
I0802 01:55:01.687911 12219 sgd_solver.cpp:136] Iteration 253500, lr = 0.0207812, m = 0.9
I0802 01:55:15.716255 12219 solver.cpp:353] Iteration 253600 (7.1286 iter/s, 14.028s/100 iter), loss = 1.76811
I0802 01:55:15.716281 12219 solver.cpp:375]     Train net output #0: loss = 1.46296 (* 1 = 1.46296 loss)
I0802 01:55:15.716286 12219 sgd_solver.cpp:136] Iteration 253600, lr = 0.02075, m = 0.9
I0802 01:55:29.636899 12219 solver.cpp:353] Iteration 253700 (7.18377 iter/s, 13.9203s/100 iter), loss = 1.47027
I0802 01:55:29.636991 12219 solver.cpp:375]     Train net output #0: loss = 1.783 (* 1 = 1.783 loss)
I0802 01:55:29.637006 12219 sgd_solver.cpp:136] Iteration 253700, lr = 0.0207187, m = 0.9
I0802 01:55:43.642858 12219 solver.cpp:353] Iteration 253800 (7.14001 iter/s, 14.0056s/100 iter), loss = 1.29602
I0802 01:55:43.642884 12219 solver.cpp:375]     Train net output #0: loss = 1.4059 (* 1 = 1.4059 loss)
I0802 01:55:43.642889 12219 sgd_solver.cpp:136] Iteration 253800, lr = 0.0206875, m = 0.9
I0802 01:55:57.645193 12219 solver.cpp:353] Iteration 253900 (7.14186 iter/s, 14.002s/100 iter), loss = 1.64274
I0802 01:55:57.645218 12219 solver.cpp:375]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I0802 01:55:57.645225 12219 sgd_solver.cpp:136] Iteration 253900, lr = 0.0206563, m = 0.9
I0802 01:56:11.462342 12219 solver.cpp:550] Iteration 254000, Testing net (#0)
I0802 01:56:31.516907 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.525765
I0802 01:56:31.516932 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.770763
I0802 01:56:31.516937 12219 solver.cpp:635]     Test net output #2: loss = 2.12288 (* 1 = 2.12288 loss)
I0802 01:56:31.516990 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0541s
I0802 01:56:31.657672 12219 solver.cpp:353] Iteration 254000 (2.94018 iter/s, 34.0116s/100 iter), loss = 1.69011
I0802 01:56:31.657701 12219 solver.cpp:375]     Train net output #0: loss = 1.6632 (* 1 = 1.6632 loss)
I0802 01:56:31.657707 12219 sgd_solver.cpp:136] Iteration 254000, lr = 0.020625, m = 0.9
I0802 01:56:45.572949 12219 solver.cpp:353] Iteration 254100 (7.18654 iter/s, 13.9149s/100 iter), loss = 1.63868
I0802 01:56:45.573046 12219 solver.cpp:375]     Train net output #0: loss = 1.6325 (* 1 = 1.6325 loss)
I0802 01:56:45.573065 12219 sgd_solver.cpp:136] Iteration 254100, lr = 0.0205938, m = 0.9
I0802 01:56:59.556381 12219 solver.cpp:353] Iteration 254200 (7.15152 iter/s, 13.9831s/100 iter), loss = 1.73682
I0802 01:56:59.556408 12219 solver.cpp:375]     Train net output #0: loss = 1.64672 (* 1 = 1.64672 loss)
I0802 01:56:59.556414 12219 sgd_solver.cpp:136] Iteration 254200, lr = 0.0205625, m = 0.9
I0802 01:57:13.562147 12219 solver.cpp:353] Iteration 254300 (7.14011 iter/s, 14.0054s/100 iter), loss = 1.53135
I0802 01:57:13.562175 12219 solver.cpp:375]     Train net output #0: loss = 1.73058 (* 1 = 1.73058 loss)
I0802 01:57:13.562181 12219 sgd_solver.cpp:136] Iteration 254300, lr = 0.0205313, m = 0.9
I0802 01:57:27.574415 12219 solver.cpp:353] Iteration 254400 (7.1368 iter/s, 14.0119s/100 iter), loss = 2.0804
I0802 01:57:27.574481 12219 solver.cpp:375]     Train net output #0: loss = 2.25621 (* 1 = 2.25621 loss)
I0802 01:57:27.574487 12219 sgd_solver.cpp:136] Iteration 254400, lr = 0.0205, m = 0.9
I0802 01:57:41.475517 12219 solver.cpp:353] Iteration 254500 (7.19387 iter/s, 13.9007s/100 iter), loss = 1.90424
I0802 01:57:41.475546 12219 solver.cpp:375]     Train net output #0: loss = 1.96027 (* 1 = 1.96027 loss)
I0802 01:57:41.475553 12219 sgd_solver.cpp:136] Iteration 254500, lr = 0.0204687, m = 0.9
I0802 01:57:55.376355 12219 solver.cpp:353] Iteration 254600 (7.19401 iter/s, 13.9005s/100 iter), loss = 2.0315
I0802 01:57:55.376380 12219 solver.cpp:375]     Train net output #0: loss = 1.78387 (* 1 = 1.78387 loss)
I0802 01:57:55.376384 12219 sgd_solver.cpp:136] Iteration 254600, lr = 0.0204375, m = 0.9
I0802 01:58:09.339217 12219 solver.cpp:353] Iteration 254700 (7.16205 iter/s, 13.9625s/100 iter), loss = 1.64304
I0802 01:58:09.339272 12219 solver.cpp:375]     Train net output #0: loss = 1.5146 (* 1 = 1.5146 loss)
I0802 01:58:09.339277 12219 sgd_solver.cpp:136] Iteration 254700, lr = 0.0204063, m = 0.9
I0802 01:58:23.326668 12219 solver.cpp:353] Iteration 254800 (7.14946 iter/s, 13.9871s/100 iter), loss = 1.85135
I0802 01:58:23.326697 12219 solver.cpp:375]     Train net output #0: loss = 1.6532 (* 1 = 1.6532 loss)
I0802 01:58:23.326704 12219 sgd_solver.cpp:136] Iteration 254800, lr = 0.020375, m = 0.9
I0802 01:58:37.452844 12219 solver.cpp:353] Iteration 254900 (7.07925 iter/s, 14.1258s/100 iter), loss = 1.48323
I0802 01:58:37.452873 12219 solver.cpp:375]     Train net output #0: loss = 1.61809 (* 1 = 1.61809 loss)
I0802 01:58:37.452879 12219 sgd_solver.cpp:136] Iteration 254900, lr = 0.0203438, m = 0.9
I0802 01:58:51.571877 12219 solver.cpp:353] Iteration 255000 (7.08283 iter/s, 14.1187s/100 iter), loss = 1.71345
I0802 01:58:51.571935 12219 solver.cpp:375]     Train net output #0: loss = 1.88405 (* 1 = 1.88405 loss)
I0802 01:58:51.571940 12219 sgd_solver.cpp:136] Iteration 255000, lr = 0.0203125, m = 0.9
I0802 01:59:05.638144 12219 solver.cpp:353] Iteration 255100 (7.1094 iter/s, 14.0659s/100 iter), loss = 1.60671
I0802 01:59:05.638172 12219 solver.cpp:375]     Train net output #0: loss = 2.03102 (* 1 = 2.03102 loss)
I0802 01:59:05.638180 12219 sgd_solver.cpp:136] Iteration 255100, lr = 0.0202812, m = 0.9
I0802 01:59:19.747567 12219 solver.cpp:353] Iteration 255200 (7.08765 iter/s, 14.109s/100 iter), loss = 1.76267
I0802 01:59:19.747596 12219 solver.cpp:375]     Train net output #0: loss = 1.97464 (* 1 = 1.97464 loss)
I0802 01:59:19.747601 12219 sgd_solver.cpp:136] Iteration 255200, lr = 0.02025, m = 0.9
I0802 01:59:33.764746 12219 solver.cpp:353] Iteration 255300 (7.1343 iter/s, 14.0168s/100 iter), loss = 1.53929
I0802 01:59:33.764809 12219 solver.cpp:375]     Train net output #0: loss = 1.50264 (* 1 = 1.50264 loss)
I0802 01:59:33.764822 12219 sgd_solver.cpp:136] Iteration 255300, lr = 0.0202187, m = 0.9
I0802 01:59:47.849351 12219 solver.cpp:353] Iteration 255400 (7.10014 iter/s, 14.0842s/100 iter), loss = 1.64153
I0802 01:59:47.849380 12219 solver.cpp:375]     Train net output #0: loss = 1.35789 (* 1 = 1.35789 loss)
I0802 01:59:47.849386 12219 sgd_solver.cpp:136] Iteration 255400, lr = 0.0201875, m = 0.9
I0802 02:00:01.830976 12219 solver.cpp:353] Iteration 255500 (7.15244 iter/s, 13.9812s/100 iter), loss = 1.37695
I0802 02:00:01.831006 12219 solver.cpp:375]     Train net output #0: loss = 1.44529 (* 1 = 1.44529 loss)
I0802 02:00:01.831012 12219 sgd_solver.cpp:136] Iteration 255500, lr = 0.0201563, m = 0.9
I0802 02:00:15.819809 12219 solver.cpp:353] Iteration 255600 (7.14876 iter/s, 13.9884s/100 iter), loss = 1.56191
I0802 02:00:15.819910 12219 solver.cpp:375]     Train net output #0: loss = 1.40214 (* 1 = 1.40214 loss)
I0802 02:00:15.819917 12219 sgd_solver.cpp:136] Iteration 255600, lr = 0.020125, m = 0.9
I0802 02:00:29.791880 12219 solver.cpp:353] Iteration 255700 (7.15733 iter/s, 13.9717s/100 iter), loss = 1.66365
I0802 02:00:29.791960 12219 solver.cpp:375]     Train net output #0: loss = 1.3081 (* 1 = 1.3081 loss)
I0802 02:00:29.791975 12219 sgd_solver.cpp:136] Iteration 255700, lr = 0.0200938, m = 0.9
I0802 02:00:43.831863 12219 solver.cpp:353] Iteration 255800 (7.1227 iter/s, 14.0396s/100 iter), loss = 1.94408
I0802 02:00:43.831889 12219 solver.cpp:375]     Train net output #0: loss = 1.69079 (* 1 = 1.69079 loss)
I0802 02:00:43.831894 12219 sgd_solver.cpp:136] Iteration 255800, lr = 0.0200625, m = 0.9
I0802 02:00:57.967661 12219 solver.cpp:353] Iteration 255900 (7.07443 iter/s, 14.1354s/100 iter), loss = 1.73555
I0802 02:00:57.967721 12219 solver.cpp:375]     Train net output #0: loss = 1.62992 (* 1 = 1.62992 loss)
I0802 02:00:57.967728 12219 sgd_solver.cpp:136] Iteration 255900, lr = 0.0200312, m = 0.9
I0802 02:01:11.913043 12219 solver.cpp:550] Iteration 256000, Testing net (#0)
I0802 02:01:20.441294 12207 data_reader.cpp:264] Starting prefetch of epoch 14
I0802 02:01:31.874202 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.516764
I0802 02:01:31.874254 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.764822
I0802 02:01:31.874260 12219 solver.cpp:635]     Test net output #2: loss = 2.1427 (* 1 = 2.1427 loss)
I0802 02:01:31.874279 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9607s
I0802 02:01:32.031857 12219 solver.cpp:353] Iteration 256000 (2.93571 iter/s, 34.0633s/100 iter), loss = 1.84646
I0802 02:01:32.031882 12219 solver.cpp:375]     Train net output #0: loss = 2.24281 (* 1 = 2.24281 loss)
I0802 02:01:32.031885 12219 sgd_solver.cpp:136] Iteration 256000, lr = 0.02, m = 0.9
I0802 02:01:46.207599 12219 solver.cpp:353] Iteration 256100 (7.05449 iter/s, 14.1754s/100 iter), loss = 1.42557
I0802 02:01:46.207628 12219 solver.cpp:375]     Train net output #0: loss = 1.45669 (* 1 = 1.45669 loss)
I0802 02:01:46.207633 12219 sgd_solver.cpp:136] Iteration 256100, lr = 0.0199687, m = 0.9
I0802 02:02:00.350482 12219 solver.cpp:353] Iteration 256200 (7.07089 iter/s, 14.1425s/100 iter), loss = 1.58708
I0802 02:02:00.350553 12219 solver.cpp:375]     Train net output #0: loss = 1.72785 (* 1 = 1.72785 loss)
I0802 02:02:00.350571 12219 sgd_solver.cpp:136] Iteration 256200, lr = 0.0199375, m = 0.9
I0802 02:02:14.473675 12219 solver.cpp:353] Iteration 256300 (7.08074 iter/s, 14.1228s/100 iter), loss = 1.95449
I0802 02:02:14.473768 12219 solver.cpp:375]     Train net output #0: loss = 1.61464 (* 1 = 1.61464 loss)
I0802 02:02:14.473776 12219 sgd_solver.cpp:136] Iteration 256300, lr = 0.0199063, m = 0.9
I0802 02:02:28.550149 12219 solver.cpp:353] Iteration 256400 (7.10424 iter/s, 14.0761s/100 iter), loss = 1.52752
I0802 02:02:28.550179 12219 solver.cpp:375]     Train net output #0: loss = 1.59594 (* 1 = 1.59594 loss)
I0802 02:02:28.550182 12219 sgd_solver.cpp:136] Iteration 256400, lr = 0.019875, m = 0.9
I0802 02:02:42.502424 12219 solver.cpp:353] Iteration 256500 (7.16749 iter/s, 13.9519s/100 iter), loss = 1.56585
I0802 02:02:42.502450 12219 solver.cpp:375]     Train net output #0: loss = 1.5894 (* 1 = 1.5894 loss)
I0802 02:02:42.502456 12219 sgd_solver.cpp:136] Iteration 256500, lr = 0.0198438, m = 0.9
I0802 02:02:56.548166 12219 solver.cpp:353] Iteration 256600 (7.11979 iter/s, 14.0454s/100 iter), loss = 1.39836
I0802 02:02:56.548250 12219 solver.cpp:375]     Train net output #0: loss = 1.40564 (* 1 = 1.40564 loss)
I0802 02:02:56.548257 12219 sgd_solver.cpp:136] Iteration 256600, lr = 0.0198125, m = 0.9
I0802 02:03:10.584280 12219 solver.cpp:353] Iteration 256700 (7.12467 iter/s, 14.0357s/100 iter), loss = 1.48051
I0802 02:03:10.584308 12219 solver.cpp:375]     Train net output #0: loss = 1.41997 (* 1 = 1.41997 loss)
I0802 02:03:10.584313 12219 sgd_solver.cpp:136] Iteration 256700, lr = 0.0197813, m = 0.9
I0802 02:03:24.650509 12219 solver.cpp:353] Iteration 256800 (7.10943 iter/s, 14.0658s/100 iter), loss = 1.24866
I0802 02:03:24.650537 12219 solver.cpp:375]     Train net output #0: loss = 1.52477 (* 1 = 1.52477 loss)
I0802 02:03:24.650544 12219 sgd_solver.cpp:136] Iteration 256800, lr = 0.01975, m = 0.9
I0802 02:03:38.648200 12219 solver.cpp:353] Iteration 256900 (7.14423 iter/s, 13.9973s/100 iter), loss = 1.88141
I0802 02:03:38.648283 12219 solver.cpp:375]     Train net output #0: loss = 1.39002 (* 1 = 1.39002 loss)
I0802 02:03:38.648290 12219 sgd_solver.cpp:136] Iteration 256900, lr = 0.0197187, m = 0.9
I0802 02:03:52.632063 12219 solver.cpp:353] Iteration 257000 (7.15129 iter/s, 13.9835s/100 iter), loss = 1.5242
I0802 02:03:52.632089 12219 solver.cpp:375]     Train net output #0: loss = 1.51709 (* 1 = 1.51709 loss)
I0802 02:03:52.632095 12219 sgd_solver.cpp:136] Iteration 257000, lr = 0.0196875, m = 0.9
I0802 02:04:06.716552 12219 solver.cpp:353] Iteration 257100 (7.1002 iter/s, 14.0841s/100 iter), loss = 1.53492
I0802 02:04:06.716575 12219 solver.cpp:375]     Train net output #0: loss = 1.87929 (* 1 = 1.87929 loss)
I0802 02:04:06.716579 12219 sgd_solver.cpp:136] Iteration 257100, lr = 0.0196563, m = 0.9
I0802 02:04:20.727216 12219 solver.cpp:353] Iteration 257200 (7.13761 iter/s, 14.0103s/100 iter), loss = 1.39883
I0802 02:04:20.727267 12219 solver.cpp:375]     Train net output #0: loss = 1.55984 (* 1 = 1.55984 loss)
I0802 02:04:20.727274 12219 sgd_solver.cpp:136] Iteration 257200, lr = 0.019625, m = 0.9
I0802 02:04:34.765686 12219 solver.cpp:353] Iteration 257300 (7.12349 iter/s, 14.0381s/100 iter), loss = 1.31499
I0802 02:04:34.765713 12219 solver.cpp:375]     Train net output #0: loss = 1.36614 (* 1 = 1.36614 loss)
I0802 02:04:34.765719 12219 sgd_solver.cpp:136] Iteration 257300, lr = 0.0195938, m = 0.9
I0802 02:04:48.749673 12219 solver.cpp:353] Iteration 257400 (7.15123 iter/s, 13.9836s/100 iter), loss = 1.83223
I0802 02:04:48.749702 12219 solver.cpp:375]     Train net output #0: loss = 1.53151 (* 1 = 1.53151 loss)
I0802 02:04:48.749709 12219 sgd_solver.cpp:136] Iteration 257400, lr = 0.0195625, m = 0.9
I0802 02:05:02.735448 12219 solver.cpp:353] Iteration 257500 (7.15032 iter/s, 13.9854s/100 iter), loss = 1.80723
I0802 02:05:02.736366 12219 solver.cpp:375]     Train net output #0: loss = 2.36685 (* 1 = 2.36685 loss)
I0802 02:05:02.736377 12219 sgd_solver.cpp:136] Iteration 257500, lr = 0.0195312, m = 0.9
I0802 02:05:16.788646 12219 solver.cpp:353] Iteration 257600 (7.11601 iter/s, 14.0528s/100 iter), loss = 1.47719
I0802 02:05:16.788672 12219 solver.cpp:375]     Train net output #0: loss = 1.20445 (* 1 = 1.20445 loss)
I0802 02:05:16.788678 12219 sgd_solver.cpp:136] Iteration 257600, lr = 0.0195, m = 0.9
I0802 02:05:30.910604 12219 solver.cpp:353] Iteration 257700 (7.08136 iter/s, 14.1216s/100 iter), loss = 1.69759
I0802 02:05:30.910631 12219 solver.cpp:375]     Train net output #0: loss = 1.79787 (* 1 = 1.79787 loss)
I0802 02:05:30.910635 12219 sgd_solver.cpp:136] Iteration 257700, lr = 0.0194687, m = 0.9
I0802 02:05:44.902163 12219 solver.cpp:353] Iteration 257800 (7.14736 iter/s, 13.9912s/100 iter), loss = 1.53776
I0802 02:05:44.902226 12219 solver.cpp:375]     Train net output #0: loss = 1.61169 (* 1 = 1.61169 loss)
I0802 02:05:44.902232 12219 sgd_solver.cpp:136] Iteration 257800, lr = 0.0194375, m = 0.9
I0802 02:05:58.944491 12219 solver.cpp:353] Iteration 257900 (7.12152 iter/s, 14.0419s/100 iter), loss = 1.83044
I0802 02:05:58.944519 12219 solver.cpp:375]     Train net output #0: loss = 1.65712 (* 1 = 1.65712 loss)
I0802 02:05:58.944525 12219 sgd_solver.cpp:136] Iteration 257900, lr = 0.0194062, m = 0.9
I0802 02:06:12.723014 12219 solver.cpp:550] Iteration 258000, Testing net (#0)
I0802 02:06:25.329188 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 02:06:32.748697 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.512882
I0802 02:06:32.748715 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.761468
I0802 02:06:32.748721 12219 solver.cpp:635]     Test net output #2: loss = 2.15243 (* 1 = 2.15243 loss)
I0802 02:06:32.748742 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0252s
I0802 02:06:32.896056 12219 solver.cpp:353] Iteration 258000 (2.94545 iter/s, 33.9507s/100 iter), loss = 1.43501
I0802 02:06:32.896108 12219 solver.cpp:375]     Train net output #0: loss = 1.2963 (* 1 = 1.2963 loss)
I0802 02:06:32.896121 12219 sgd_solver.cpp:136] Iteration 258000, lr = 0.019375, m = 0.9
I0802 02:06:46.939734 12219 solver.cpp:353] Iteration 258100 (7.12084 iter/s, 14.0433s/100 iter), loss = 1.52389
I0802 02:06:46.939764 12219 solver.cpp:375]     Train net output #0: loss = 1.65604 (* 1 = 1.65604 loss)
I0802 02:06:46.939771 12219 sgd_solver.cpp:136] Iteration 258100, lr = 0.0193438, m = 0.9
I0802 02:07:00.995494 12219 solver.cpp:353] Iteration 258200 (7.11471 iter/s, 14.0554s/100 iter), loss = 1.81176
I0802 02:07:00.995622 12219 solver.cpp:375]     Train net output #0: loss = 1.90674 (* 1 = 1.90674 loss)
I0802 02:07:00.995645 12219 sgd_solver.cpp:136] Iteration 258200, lr = 0.0193125, m = 0.9
I0802 02:07:14.947170 12219 solver.cpp:353] Iteration 258300 (7.16779 iter/s, 13.9513s/100 iter), loss = 1.79946
I0802 02:07:14.947196 12219 solver.cpp:375]     Train net output #0: loss = 1.6632 (* 1 = 1.6632 loss)
I0802 02:07:14.947202 12219 sgd_solver.cpp:136] Iteration 258300, lr = 0.0192813, m = 0.9
I0802 02:07:28.970971 12219 solver.cpp:353] Iteration 258400 (7.13093 iter/s, 14.0234s/100 iter), loss = 1.75018
I0802 02:07:28.970996 12219 solver.cpp:375]     Train net output #0: loss = 2.22994 (* 1 = 2.22994 loss)
I0802 02:07:28.971000 12219 sgd_solver.cpp:136] Iteration 258400, lr = 0.01925, m = 0.9
I0802 02:07:42.969557 12219 solver.cpp:353] Iteration 258500 (7.14377 iter/s, 13.9982s/100 iter), loss = 1.51007
I0802 02:07:42.969627 12219 solver.cpp:375]     Train net output #0: loss = 1.56556 (* 1 = 1.56556 loss)
I0802 02:07:42.969635 12219 sgd_solver.cpp:136] Iteration 258500, lr = 0.0192187, m = 0.9
I0802 02:07:56.977208 12219 solver.cpp:353] Iteration 258600 (7.13915 iter/s, 14.0073s/100 iter), loss = 1.85269
I0802 02:07:56.977241 12219 solver.cpp:375]     Train net output #0: loss = 2.07074 (* 1 = 2.07074 loss)
I0802 02:07:56.977248 12219 sgd_solver.cpp:136] Iteration 258600, lr = 0.0191875, m = 0.9
I0802 02:08:10.998900 12219 solver.cpp:353] Iteration 258700 (7.132 iter/s, 14.0213s/100 iter), loss = 1.40267
I0802 02:08:10.998930 12219 solver.cpp:375]     Train net output #0: loss = 1.80101 (* 1 = 1.80101 loss)
I0802 02:08:10.998936 12219 sgd_solver.cpp:136] Iteration 258700, lr = 0.0191562, m = 0.9
I0802 02:08:24.906865 12219 solver.cpp:353] Iteration 258800 (7.19032 iter/s, 13.9076s/100 iter), loss = 1.98514
I0802 02:08:24.906955 12219 solver.cpp:375]     Train net output #0: loss = 1.84779 (* 1 = 1.84779 loss)
I0802 02:08:24.906976 12219 sgd_solver.cpp:136] Iteration 258800, lr = 0.019125, m = 0.9
I0802 02:08:38.895236 12219 solver.cpp:353] Iteration 258900 (7.14899 iter/s, 13.988s/100 iter), loss = 1.45798
I0802 02:08:38.895301 12219 solver.cpp:375]     Train net output #0: loss = 1.39529 (* 1 = 1.39529 loss)
I0802 02:08:38.895323 12219 sgd_solver.cpp:136] Iteration 258900, lr = 0.0190938, m = 0.9
I0802 02:08:52.901083 12219 solver.cpp:353] Iteration 259000 (7.14007 iter/s, 14.0055s/100 iter), loss = 1.30946
I0802 02:08:52.901110 12219 solver.cpp:375]     Train net output #0: loss = 1.18604 (* 1 = 1.18604 loss)
I0802 02:08:52.901114 12219 sgd_solver.cpp:136] Iteration 259000, lr = 0.0190625, m = 0.9
I0802 02:09:06.919868 12219 solver.cpp:353] Iteration 259100 (7.13348 iter/s, 14.0184s/100 iter), loss = 1.57196
I0802 02:09:06.919953 12219 solver.cpp:375]     Train net output #0: loss = 1.58649 (* 1 = 1.58649 loss)
I0802 02:09:06.919960 12219 sgd_solver.cpp:136] Iteration 259100, lr = 0.0190313, m = 0.9
I0802 02:09:20.971791 12219 solver.cpp:353] Iteration 259200 (7.11666 iter/s, 14.0515s/100 iter), loss = 1.74218
I0802 02:09:20.971828 12219 solver.cpp:375]     Train net output #0: loss = 1.84793 (* 1 = 1.84793 loss)
I0802 02:09:20.971834 12219 sgd_solver.cpp:136] Iteration 259200, lr = 0.019, m = 0.9
I0802 02:09:34.895941 12219 solver.cpp:353] Iteration 259300 (7.18196 iter/s, 13.9238s/100 iter), loss = 1.66157
I0802 02:09:34.895972 12219 solver.cpp:375]     Train net output #0: loss = 1.71292 (* 1 = 1.71292 loss)
I0802 02:09:34.895978 12219 sgd_solver.cpp:136] Iteration 259300, lr = 0.0189687, m = 0.9
I0802 02:09:48.880708 12219 solver.cpp:353] Iteration 259400 (7.15083 iter/s, 13.9844s/100 iter), loss = 1.72894
I0802 02:09:48.880785 12219 solver.cpp:375]     Train net output #0: loss = 1.83959 (* 1 = 1.83959 loss)
I0802 02:09:48.880795 12219 sgd_solver.cpp:136] Iteration 259400, lr = 0.0189375, m = 0.9
I0802 02:10:02.842067 12219 solver.cpp:353] Iteration 259500 (7.16282 iter/s, 13.961s/100 iter), loss = 1.47904
I0802 02:10:02.842159 12219 solver.cpp:375]     Train net output #0: loss = 1.86683 (* 1 = 1.86683 loss)
I0802 02:10:02.842178 12219 sgd_solver.cpp:136] Iteration 259500, lr = 0.0189062, m = 0.9
I0802 02:10:16.811549 12219 solver.cpp:353] Iteration 259600 (7.15866 iter/s, 13.9691s/100 iter), loss = 1.57677
I0802 02:10:16.811579 12219 solver.cpp:375]     Train net output #0: loss = 1.4142 (* 1 = 1.4142 loss)
I0802 02:10:16.811586 12219 sgd_solver.cpp:136] Iteration 259600, lr = 0.018875, m = 0.9
I0802 02:10:30.823462 12219 solver.cpp:353] Iteration 259700 (7.13698 iter/s, 14.0115s/100 iter), loss = 1.48482
I0802 02:10:30.823552 12219 solver.cpp:375]     Train net output #0: loss = 1.65071 (* 1 = 1.65071 loss)
I0802 02:10:30.823565 12219 sgd_solver.cpp:136] Iteration 259700, lr = 0.0188438, m = 0.9
I0802 02:10:44.722452 12219 solver.cpp:353] Iteration 259800 (7.19496 iter/s, 13.8986s/100 iter), loss = 1.66059
I0802 02:10:44.722478 12219 solver.cpp:375]     Train net output #0: loss = 1.66368 (* 1 = 1.66368 loss)
I0802 02:10:44.722483 12219 sgd_solver.cpp:136] Iteration 259800, lr = 0.0188125, m = 0.9
I0802 02:10:58.608717 12219 solver.cpp:353] Iteration 259900 (7.20155 iter/s, 13.8859s/100 iter), loss = 1.45587
I0802 02:10:58.608747 12219 solver.cpp:375]     Train net output #0: loss = 1.35906 (* 1 = 1.35906 loss)
I0802 02:10:58.608750 12219 sgd_solver.cpp:136] Iteration 259900, lr = 0.0187813, m = 0.9
I0802 02:11:12.470734 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_260000.caffemodel
I0802 02:11:12.600301 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_260000.solverstate
I0802 02:11:12.604804 12219 solver.cpp:550] Iteration 260000, Testing net (#0)
I0802 02:11:32.773279 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.508294
I0802 02:11:32.773303 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.753822
I0802 02:11:32.773309 12219 solver.cpp:635]     Test net output #2: loss = 2.18589 (* 1 = 2.18589 loss)
I0802 02:11:32.773329 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.168s
I0802 02:11:32.920155 12219 solver.cpp:353] Iteration 260000 (2.91456 iter/s, 34.3105s/100 iter), loss = 1.35367
I0802 02:11:32.920182 12219 solver.cpp:375]     Train net output #0: loss = 1.32592 (* 1 = 1.32592 loss)
I0802 02:11:32.920187 12219 sgd_solver.cpp:136] Iteration 260000, lr = 0.01875, m = 0.9
I0802 02:11:46.809561 12219 solver.cpp:353] Iteration 260100 (7.19993 iter/s, 13.889s/100 iter), loss = 1.41692
I0802 02:11:46.809609 12219 solver.cpp:375]     Train net output #0: loss = 1.69077 (* 1 = 1.69077 loss)
I0802 02:11:46.809613 12219 sgd_solver.cpp:136] Iteration 260100, lr = 0.0187187, m = 0.9
I0802 02:12:00.765612 12219 solver.cpp:353] Iteration 260200 (7.16554 iter/s, 13.9557s/100 iter), loss = 1.74996
I0802 02:12:00.765637 12219 solver.cpp:375]     Train net output #0: loss = 1.6039 (* 1 = 1.6039 loss)
I0802 02:12:00.765643 12219 sgd_solver.cpp:136] Iteration 260200, lr = 0.0186875, m = 0.9
I0802 02:12:14.776491 12219 solver.cpp:353] Iteration 260300 (7.13751 iter/s, 14.0105s/100 iter), loss = 1.65463
I0802 02:12:14.776546 12219 solver.cpp:375]     Train net output #0: loss = 1.6848 (* 1 = 1.6848 loss)
I0802 02:12:14.776557 12219 sgd_solver.cpp:136] Iteration 260300, lr = 0.0186562, m = 0.9
I0802 02:12:28.738798 12219 solver.cpp:353] Iteration 260400 (7.16233 iter/s, 13.9619s/100 iter), loss = 1.49384
I0802 02:12:28.739042 12219 solver.cpp:375]     Train net output #0: loss = 1.29041 (* 1 = 1.29041 loss)
I0802 02:12:28.739049 12219 sgd_solver.cpp:136] Iteration 260400, lr = 0.018625, m = 0.9
I0802 02:12:42.683172 12219 solver.cpp:353] Iteration 260500 (7.17154 iter/s, 13.944s/100 iter), loss = 1.68807
I0802 02:12:42.683197 12219 solver.cpp:375]     Train net output #0: loss = 1.70678 (* 1 = 1.70678 loss)
I0802 02:12:42.683203 12219 sgd_solver.cpp:136] Iteration 260500, lr = 0.0185938, m = 0.9
I0802 02:12:56.630645 12219 solver.cpp:353] Iteration 260600 (7.16995 iter/s, 13.9471s/100 iter), loss = 1.27821
I0802 02:12:56.630669 12219 solver.cpp:375]     Train net output #0: loss = 1.1623 (* 1 = 1.1623 loss)
I0802 02:12:56.630673 12219 sgd_solver.cpp:136] Iteration 260600, lr = 0.0185625, m = 0.9
I0802 02:13:10.547044 12219 solver.cpp:353] Iteration 260700 (7.18596 iter/s, 13.916s/100 iter), loss = 1.52088
I0802 02:13:10.547097 12219 solver.cpp:375]     Train net output #0: loss = 1.40685 (* 1 = 1.40685 loss)
I0802 02:13:10.547104 12219 sgd_solver.cpp:136] Iteration 260700, lr = 0.0185313, m = 0.9
I0802 02:13:24.622496 12219 solver.cpp:353] Iteration 260800 (7.10476 iter/s, 14.0751s/100 iter), loss = 1.74083
I0802 02:13:24.622521 12219 solver.cpp:375]     Train net output #0: loss = 1.75093 (* 1 = 1.75093 loss)
I0802 02:13:24.622527 12219 sgd_solver.cpp:136] Iteration 260800, lr = 0.0185, m = 0.9
I0802 02:13:38.676990 12219 solver.cpp:353] Iteration 260900 (7.11536 iter/s, 14.0541s/100 iter), loss = 1.52076
I0802 02:13:38.677019 12219 solver.cpp:375]     Train net output #0: loss = 1.64182 (* 1 = 1.64182 loss)
I0802 02:13:38.677026 12219 sgd_solver.cpp:136] Iteration 260900, lr = 0.0184688, m = 0.9
I0802 02:13:52.830457 12219 solver.cpp:353] Iteration 261000 (7.0656 iter/s, 14.1531s/100 iter), loss = 1.89356
I0802 02:13:52.830564 12219 solver.cpp:375]     Train net output #0: loss = 1.40689 (* 1 = 1.40689 loss)
I0802 02:13:52.830570 12219 sgd_solver.cpp:136] Iteration 261000, lr = 0.0184375, m = 0.9
I0802 02:14:06.945111 12219 solver.cpp:353] Iteration 261100 (7.08503 iter/s, 14.1143s/100 iter), loss = 1.68397
I0802 02:14:06.945137 12219 solver.cpp:375]     Train net output #0: loss = 2.08086 (* 1 = 2.08086 loss)
I0802 02:14:06.945142 12219 sgd_solver.cpp:136] Iteration 261100, lr = 0.0184062, m = 0.9
I0802 02:14:20.860970 12219 solver.cpp:353] Iteration 261200 (7.18624 iter/s, 13.9155s/100 iter), loss = 1.65991
I0802 02:14:20.860998 12219 solver.cpp:375]     Train net output #0: loss = 1.42648 (* 1 = 1.42648 loss)
I0802 02:14:20.861006 12219 sgd_solver.cpp:136] Iteration 261200, lr = 0.018375, m = 0.9
I0802 02:14:34.910670 12219 solver.cpp:353] Iteration 261300 (7.11778 iter/s, 14.0493s/100 iter), loss = 1.83371
I0802 02:14:34.910734 12219 solver.cpp:375]     Train net output #0: loss = 1.51499 (* 1 = 1.51499 loss)
I0802 02:14:34.910743 12219 sgd_solver.cpp:136] Iteration 261300, lr = 0.0183438, m = 0.9
I0802 02:14:49.079450 12219 solver.cpp:353] Iteration 261400 (7.05796 iter/s, 14.1684s/100 iter), loss = 1.47392
I0802 02:14:49.079478 12219 solver.cpp:375]     Train net output #0: loss = 1.48294 (* 1 = 1.48294 loss)
I0802 02:14:49.079485 12219 sgd_solver.cpp:136] Iteration 261400, lr = 0.0183125, m = 0.9
I0802 02:15:03.159873 12219 solver.cpp:353] Iteration 261500 (7.10225 iter/s, 14.08s/100 iter), loss = 1.466
I0802 02:15:03.159929 12219 solver.cpp:375]     Train net output #0: loss = 1.48378 (* 1 = 1.48378 loss)
I0802 02:15:03.159941 12219 sgd_solver.cpp:136] Iteration 261500, lr = 0.0182813, m = 0.9
I0802 02:15:17.230696 12219 solver.cpp:353] Iteration 261600 (7.1071 iter/s, 14.0704s/100 iter), loss = 1.59583
I0802 02:15:17.230808 12219 solver.cpp:375]     Train net output #0: loss = 1.9361 (* 1 = 1.9361 loss)
I0802 02:15:17.230815 12219 sgd_solver.cpp:136] Iteration 261600, lr = 0.01825, m = 0.9
I0802 02:15:31.206399 12219 solver.cpp:353] Iteration 261700 (7.15547 iter/s, 13.9753s/100 iter), loss = 1.54565
I0802 02:15:31.206429 12219 solver.cpp:375]     Train net output #0: loss = 1.09792 (* 1 = 1.09792 loss)
I0802 02:15:31.206434 12219 sgd_solver.cpp:136] Iteration 261700, lr = 0.0182188, m = 0.9
I0802 02:15:45.252825 12219 solver.cpp:353] Iteration 261800 (7.11945 iter/s, 14.046s/100 iter), loss = 1.49575
I0802 02:15:45.252863 12219 solver.cpp:375]     Train net output #0: loss = 1.45242 (* 1 = 1.45242 loss)
I0802 02:15:45.252868 12219 sgd_solver.cpp:136] Iteration 261800, lr = 0.0181875, m = 0.9
I0802 02:15:59.179302 12219 solver.cpp:353] Iteration 261900 (7.18076 iter/s, 13.9261s/100 iter), loss = 1.59729
I0802 02:15:59.179383 12219 solver.cpp:375]     Train net output #0: loss = 1.66534 (* 1 = 1.66534 loss)
I0802 02:15:59.179390 12219 sgd_solver.cpp:136] Iteration 261900, lr = 0.0181562, m = 0.9
I0802 02:16:13.049639 12219 solver.cpp:550] Iteration 262000, Testing net (#0)
I0802 02:16:33.187088 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.531236
I0802 02:16:33.187139 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.770998
I0802 02:16:33.187145 12219 solver.cpp:635]     Test net output #2: loss = 2.10071 (* 1 = 2.10071 loss)
I0802 02:16:33.187163 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.137s
I0802 02:16:33.330466 12219 solver.cpp:353] Iteration 262000 (2.92824 iter/s, 34.1502s/100 iter), loss = 1.34747
I0802 02:16:33.330687 12219 solver.cpp:375]     Train net output #0: loss = 1.40838 (* 1 = 1.40838 loss)
I0802 02:16:33.330781 12219 sgd_solver.cpp:136] Iteration 262000, lr = 0.018125, m = 0.9
I0802 02:16:47.258224 12219 solver.cpp:353] Iteration 262100 (7.1801 iter/s, 13.9274s/100 iter), loss = 1.33406
I0802 02:16:47.258249 12219 solver.cpp:375]     Train net output #0: loss = 1.42265 (* 1 = 1.42265 loss)
I0802 02:16:47.258254 12219 sgd_solver.cpp:136] Iteration 262100, lr = 0.0180938, m = 0.9
I0802 02:17:01.419553 12219 solver.cpp:353] Iteration 262200 (7.06168 iter/s, 14.1609s/100 iter), loss = 1.89272
I0802 02:17:01.419581 12219 solver.cpp:375]     Train net output #0: loss = 2.1412 (* 1 = 2.1412 loss)
I0802 02:17:01.419587 12219 sgd_solver.cpp:136] Iteration 262200, lr = 0.0180625, m = 0.9
I0802 02:17:15.629748 12219 solver.cpp:353] Iteration 262300 (7.03739 iter/s, 14.2098s/100 iter), loss = 1.86542
I0802 02:17:15.629802 12219 solver.cpp:375]     Train net output #0: loss = 1.77693 (* 1 = 1.77693 loss)
I0802 02:17:15.629809 12219 sgd_solver.cpp:136] Iteration 262300, lr = 0.0180313, m = 0.9
I0802 02:17:29.825073 12219 solver.cpp:353] Iteration 262400 (7.04476 iter/s, 14.1949s/100 iter), loss = 1.54953
I0802 02:17:29.825098 12219 solver.cpp:375]     Train net output #0: loss = 1.14179 (* 1 = 1.14179 loss)
I0802 02:17:29.825101 12219 sgd_solver.cpp:136] Iteration 262400, lr = 0.018, m = 0.9
I0802 02:17:43.843453 12219 solver.cpp:353] Iteration 262500 (7.13369 iter/s, 14.018s/100 iter), loss = 1.46449
I0802 02:17:43.843550 12219 solver.cpp:375]     Train net output #0: loss = 1.57548 (* 1 = 1.57548 loss)
I0802 02:17:43.843569 12219 sgd_solver.cpp:136] Iteration 262500, lr = 0.0179687, m = 0.9
I0802 02:17:57.831295 12219 solver.cpp:353] Iteration 262600 (7.14926 iter/s, 13.9875s/100 iter), loss = 1.64983
I0802 02:17:57.831393 12219 solver.cpp:375]     Train net output #0: loss = 2.00867 (* 1 = 2.00867 loss)
I0802 02:17:57.831413 12219 sgd_solver.cpp:136] Iteration 262600, lr = 0.0179375, m = 0.9
I0802 02:18:11.872028 12219 solver.cpp:353] Iteration 262700 (7.12233 iter/s, 14.0404s/100 iter), loss = 1.17122
I0802 02:18:11.872054 12219 solver.cpp:375]     Train net output #0: loss = 1.20986 (* 1 = 1.20986 loss)
I0802 02:18:11.872061 12219 sgd_solver.cpp:136] Iteration 262700, lr = 0.0179062, m = 0.9
I0802 02:18:25.940677 12219 solver.cpp:353] Iteration 262800 (7.10819 iter/s, 14.0683s/100 iter), loss = 1.4208
I0802 02:18:25.940702 12219 solver.cpp:375]     Train net output #0: loss = 1.10241 (* 1 = 1.10241 loss)
I0802 02:18:25.940706 12219 sgd_solver.cpp:136] Iteration 262800, lr = 0.017875, m = 0.9
I0802 02:18:39.937266 12219 solver.cpp:353] Iteration 262900 (7.14479 iter/s, 13.9962s/100 iter), loss = 1.55851
I0802 02:18:39.937336 12219 solver.cpp:375]     Train net output #0: loss = 1.62563 (* 1 = 1.62563 loss)
I0802 02:18:39.937343 12219 sgd_solver.cpp:136] Iteration 262900, lr = 0.0178437, m = 0.9
I0802 02:18:54.102540 12219 solver.cpp:353] Iteration 263000 (7.05971 iter/s, 14.1649s/100 iter), loss = 1.60544
I0802 02:18:54.102569 12219 solver.cpp:375]     Train net output #0: loss = 1.64532 (* 1 = 1.64532 loss)
I0802 02:18:54.102576 12219 sgd_solver.cpp:136] Iteration 263000, lr = 0.0178125, m = 0.9
I0802 02:19:08.148102 12219 solver.cpp:353] Iteration 263100 (7.11988 iter/s, 14.0452s/100 iter), loss = 1.83422
I0802 02:19:08.148130 12219 solver.cpp:375]     Train net output #0: loss = 1.62765 (* 1 = 1.62765 loss)
I0802 02:19:08.148138 12219 sgd_solver.cpp:136] Iteration 263100, lr = 0.0177813, m = 0.9
I0802 02:19:22.295295 12219 solver.cpp:353] Iteration 263200 (7.06873 iter/s, 14.1468s/100 iter), loss = 1.48137
I0802 02:19:22.295373 12219 solver.cpp:375]     Train net output #0: loss = 1.44476 (* 1 = 1.44476 loss)
I0802 02:19:22.295378 12219 sgd_solver.cpp:136] Iteration 263200, lr = 0.01775, m = 0.9
I0802 02:19:36.488682 12219 solver.cpp:353] Iteration 263300 (7.04573 iter/s, 14.193s/100 iter), loss = 1.92318
I0802 02:19:36.488713 12219 solver.cpp:375]     Train net output #0: loss = 2.18175 (* 1 = 2.18175 loss)
I0802 02:19:36.488718 12219 sgd_solver.cpp:136] Iteration 263300, lr = 0.0177188, m = 0.9
I0802 02:19:50.529757 12219 solver.cpp:353] Iteration 263400 (7.12216 iter/s, 14.0407s/100 iter), loss = 1.5055
I0802 02:19:50.530005 12219 solver.cpp:375]     Train net output #0: loss = 1.48425 (* 1 = 1.48425 loss)
I0802 02:19:50.530114 12219 sgd_solver.cpp:136] Iteration 263400, lr = 0.0176875, m = 0.9
I0802 02:20:04.514171 12219 solver.cpp:353] Iteration 263500 (7.15101 iter/s, 13.984s/100 iter), loss = 1.73911
I0802 02:20:04.514243 12219 solver.cpp:375]     Train net output #0: loss = 1.94817 (* 1 = 1.94817 loss)
I0802 02:20:04.514250 12219 sgd_solver.cpp:136] Iteration 263500, lr = 0.0176562, m = 0.9
I0802 02:20:18.527365 12219 solver.cpp:353] Iteration 263600 (7.13633 iter/s, 14.0128s/100 iter), loss = 1.66621
I0802 02:20:18.527492 12219 solver.cpp:375]     Train net output #0: loss = 1.83726 (* 1 = 1.83726 loss)
I0802 02:20:18.527516 12219 sgd_solver.cpp:136] Iteration 263600, lr = 0.017625, m = 0.9
I0802 02:20:32.522868 12219 solver.cpp:353] Iteration 263700 (7.14534 iter/s, 13.9951s/100 iter), loss = 1.50254
I0802 02:20:32.522933 12219 solver.cpp:375]     Train net output #0: loss = 1.42347 (* 1 = 1.42347 loss)
I0802 02:20:32.522944 12219 sgd_solver.cpp:136] Iteration 263700, lr = 0.0175937, m = 0.9
I0802 02:20:46.513962 12219 solver.cpp:353] Iteration 263800 (7.1476 iter/s, 13.9907s/100 iter), loss = 1.6147
I0802 02:20:46.514031 12219 solver.cpp:375]     Train net output #0: loss = 1.48804 (* 1 = 1.48804 loss)
I0802 02:20:46.514039 12219 sgd_solver.cpp:136] Iteration 263800, lr = 0.0175625, m = 0.9
I0802 02:21:00.568922 12219 solver.cpp:353] Iteration 263900 (7.11512 iter/s, 14.0546s/100 iter), loss = 1.49759
I0802 02:21:00.569017 12219 solver.cpp:375]     Train net output #0: loss = 1.45273 (* 1 = 1.45273 loss)
I0802 02:21:00.569039 12219 sgd_solver.cpp:136] Iteration 263900, lr = 0.0175313, m = 0.9
I0802 02:21:14.426715 12219 solver.cpp:550] Iteration 264000, Testing net (#0)
I0802 02:21:29.624297 12221 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 02:21:34.702464 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.526706
I0802 02:21:34.702495 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.77488
I0802 02:21:34.702503 12219 solver.cpp:635]     Test net output #2: loss = 2.07843 (* 1 = 2.07843 loss)
I0802 02:21:34.702531 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2753s
I0802 02:21:34.862231 12219 solver.cpp:353] Iteration 264000 (2.9161 iter/s, 34.2924s/100 iter), loss = 1.60189
I0802 02:21:34.862258 12219 solver.cpp:375]     Train net output #0: loss = 1.46104 (* 1 = 1.46104 loss)
I0802 02:21:34.862263 12219 sgd_solver.cpp:136] Iteration 264000, lr = 0.0175, m = 0.9
I0802 02:21:48.888443 12219 solver.cpp:353] Iteration 264100 (7.1297 iter/s, 14.0258s/100 iter), loss = 1.90394
I0802 02:21:48.888542 12219 solver.cpp:375]     Train net output #0: loss = 1.80669 (* 1 = 1.80669 loss)
I0802 02:21:48.888561 12219 sgd_solver.cpp:136] Iteration 264100, lr = 0.0174688, m = 0.9
I0802 02:22:02.909688 12219 solver.cpp:353] Iteration 264200 (7.13223 iter/s, 14.0209s/100 iter), loss = 1.68347
I0802 02:22:02.909790 12219 solver.cpp:375]     Train net output #0: loss = 1.74389 (* 1 = 1.74389 loss)
I0802 02:22:02.909798 12219 sgd_solver.cpp:136] Iteration 264200, lr = 0.0174375, m = 0.9
I0802 02:22:16.887825 12219 solver.cpp:353] Iteration 264300 (7.15423 iter/s, 13.9778s/100 iter), loss = 1.71694
I0802 02:22:16.887864 12219 solver.cpp:375]     Train net output #0: loss = 1.50711 (* 1 = 1.50711 loss)
I0802 02:22:16.887873 12219 sgd_solver.cpp:136] Iteration 264300, lr = 0.0174062, m = 0.9
I0802 02:22:30.806098 12219 solver.cpp:353] Iteration 264400 (7.18499 iter/s, 13.9179s/100 iter), loss = 1.50259
I0802 02:22:30.806123 12219 solver.cpp:375]     Train net output #0: loss = 1.50199 (* 1 = 1.50199 loss)
I0802 02:22:30.806128 12219 sgd_solver.cpp:136] Iteration 264400, lr = 0.017375, m = 0.9
I0802 02:22:44.797255 12219 solver.cpp:353] Iteration 264500 (7.14757 iter/s, 13.9908s/100 iter), loss = 1.37338
I0802 02:22:44.797327 12219 solver.cpp:375]     Train net output #0: loss = 1.3848 (* 1 = 1.3848 loss)
I0802 02:22:44.797335 12219 sgd_solver.cpp:136] Iteration 264500, lr = 0.0173437, m = 0.9
I0802 02:22:58.846596 12219 solver.cpp:353] Iteration 264600 (7.11796 iter/s, 14.049s/100 iter), loss = 1.75577
I0802 02:22:58.846644 12219 solver.cpp:375]     Train net output #0: loss = 1.71472 (* 1 = 1.71472 loss)
I0802 02:22:58.846655 12219 sgd_solver.cpp:136] Iteration 264600, lr = 0.0173125, m = 0.9
I0802 02:23:12.944135 12219 solver.cpp:353] Iteration 264700 (7.09363 iter/s, 14.0972s/100 iter), loss = 1.57589
I0802 02:23:12.944159 12219 solver.cpp:375]     Train net output #0: loss = 1.61538 (* 1 = 1.61538 loss)
I0802 02:23:12.944165 12219 sgd_solver.cpp:136] Iteration 264700, lr = 0.0172813, m = 0.9
I0802 02:23:27.039336 12219 solver.cpp:353] Iteration 264800 (7.09481 iter/s, 14.0948s/100 iter), loss = 1.3415
I0802 02:23:27.039412 12219 solver.cpp:375]     Train net output #0: loss = 1.33891 (* 1 = 1.33891 loss)
I0802 02:23:27.039422 12219 sgd_solver.cpp:136] Iteration 264800, lr = 0.01725, m = 0.9
I0802 02:23:41.032691 12219 solver.cpp:353] Iteration 264900 (7.14644 iter/s, 13.993s/100 iter), loss = 1.75889
I0802 02:23:41.032716 12219 solver.cpp:375]     Train net output #0: loss = 1.48844 (* 1 = 1.48844 loss)
I0802 02:23:41.032722 12219 sgd_solver.cpp:136] Iteration 264900, lr = 0.0172188, m = 0.9
I0802 02:23:55.103178 12219 solver.cpp:353] Iteration 265000 (7.10727 iter/s, 14.0701s/100 iter), loss = 1.84918
I0802 02:23:55.103201 12219 solver.cpp:375]     Train net output #0: loss = 1.78966 (* 1 = 1.78966 loss)
I0802 02:23:55.103206 12219 sgd_solver.cpp:136] Iteration 265000, lr = 0.0171875, m = 0.9
I0802 02:24:09.084838 12219 solver.cpp:353] Iteration 265100 (7.15243 iter/s, 13.9813s/100 iter), loss = 1.32327
I0802 02:24:09.084909 12219 solver.cpp:375]     Train net output #0: loss = 1.30253 (* 1 = 1.30253 loss)
I0802 02:24:09.084916 12219 sgd_solver.cpp:136] Iteration 265100, lr = 0.0171562, m = 0.9
I0802 02:24:23.074169 12219 solver.cpp:353] Iteration 265200 (7.1485 iter/s, 13.9889s/100 iter), loss = 1.46903
I0802 02:24:23.074198 12219 solver.cpp:375]     Train net output #0: loss = 1.07235 (* 1 = 1.07235 loss)
I0802 02:24:23.074204 12219 sgd_solver.cpp:136] Iteration 265200, lr = 0.017125, m = 0.9
I0802 02:24:37.030252 12219 solver.cpp:353] Iteration 265300 (7.16553 iter/s, 13.9557s/100 iter), loss = 1.59572
I0802 02:24:37.030277 12219 solver.cpp:375]     Train net output #0: loss = 1.23767 (* 1 = 1.23767 loss)
I0802 02:24:37.030280 12219 sgd_solver.cpp:136] Iteration 265300, lr = 0.0170937, m = 0.9
I0802 02:24:50.871394 12219 solver.cpp:353] Iteration 265400 (7.22503 iter/s, 13.8408s/100 iter), loss = 1.73812
I0802 02:24:50.871475 12219 solver.cpp:375]     Train net output #0: loss = 2.3143 (* 1 = 2.3143 loss)
I0802 02:24:50.871482 12219 sgd_solver.cpp:136] Iteration 265400, lr = 0.0170625, m = 0.9
I0802 02:25:04.876850 12219 solver.cpp:353] Iteration 265500 (7.14027 iter/s, 14.0051s/100 iter), loss = 1.61991
I0802 02:25:04.876878 12219 solver.cpp:375]     Train net output #0: loss = 1.50173 (* 1 = 1.50173 loss)
I0802 02:25:04.876883 12219 sgd_solver.cpp:136] Iteration 265500, lr = 0.0170313, m = 0.9
I0802 02:25:18.897675 12219 solver.cpp:353] Iteration 265600 (7.13244 iter/s, 14.0204s/100 iter), loss = 1.60303
I0802 02:25:18.897702 12219 solver.cpp:375]     Train net output #0: loss = 1.40818 (* 1 = 1.40818 loss)
I0802 02:25:18.897708 12219 sgd_solver.cpp:136] Iteration 265600, lr = 0.017, m = 0.9
I0802 02:25:32.875351 12219 solver.cpp:353] Iteration 265700 (7.15446 iter/s, 13.9773s/100 iter), loss = 1.59844
I0802 02:25:32.875403 12219 solver.cpp:375]     Train net output #0: loss = 1.73249 (* 1 = 1.73249 loss)
I0802 02:25:32.875409 12219 sgd_solver.cpp:136] Iteration 265700, lr = 0.0169688, m = 0.9
I0802 02:25:46.851528 12219 solver.cpp:353] Iteration 265800 (7.15522 iter/s, 13.9758s/100 iter), loss = 1.62675
I0802 02:25:46.851555 12219 solver.cpp:375]     Train net output #0: loss = 1.53889 (* 1 = 1.53889 loss)
I0802 02:25:46.851560 12219 sgd_solver.cpp:136] Iteration 265800, lr = 0.0169375, m = 0.9
I0802 02:26:00.822248 12219 solver.cpp:353] Iteration 265900 (7.15802 iter/s, 13.9703s/100 iter), loss = 1.42949
I0802 02:26:00.822275 12219 solver.cpp:375]     Train net output #0: loss = 1.36615 (* 1 = 1.36615 loss)
I0802 02:26:00.822279 12219 sgd_solver.cpp:136] Iteration 265900, lr = 0.0169063, m = 0.9
I0802 02:26:14.785634 12219 solver.cpp:550] Iteration 266000, Testing net (#0)
I0802 02:26:35.129657 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.520059
I0802 02:26:35.129680 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.767468
I0802 02:26:35.129686 12219 solver.cpp:635]     Test net output #2: loss = 2.10523 (* 1 = 2.10523 loss)
I0802 02:26:35.129706 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3435s
I0802 02:26:35.277204 12219 solver.cpp:353] Iteration 266000 (2.90242 iter/s, 34.454s/100 iter), loss = 1.30368
I0802 02:26:35.277233 12219 solver.cpp:375]     Train net output #0: loss = 1.25259 (* 1 = 1.25259 loss)
I0802 02:26:35.277237 12219 sgd_solver.cpp:136] Iteration 266000, lr = 0.016875, m = 0.9
I0802 02:26:49.205931 12219 solver.cpp:353] Iteration 266100 (7.1796 iter/s, 13.9284s/100 iter), loss = 1.75075
I0802 02:26:49.205996 12219 solver.cpp:375]     Train net output #0: loss = 1.79021 (* 1 = 1.79021 loss)
I0802 02:26:49.206002 12219 sgd_solver.cpp:136] Iteration 266100, lr = 0.0168437, m = 0.9
I0802 02:27:03.113741 12219 solver.cpp:353] Iteration 266200 (7.1904 iter/s, 13.9074s/100 iter), loss = 1.78579
I0802 02:27:03.113765 12219 solver.cpp:375]     Train net output #0: loss = 1.72394 (* 1 = 1.72394 loss)
I0802 02:27:03.113768 12219 sgd_solver.cpp:136] Iteration 266200, lr = 0.0168125, m = 0.9
I0802 02:27:17.006846 12219 solver.cpp:353] Iteration 266300 (7.19801 iter/s, 13.8927s/100 iter), loss = 1.57984
I0802 02:27:17.006875 12219 solver.cpp:375]     Train net output #0: loss = 1.29051 (* 1 = 1.29051 loss)
I0802 02:27:17.006880 12219 sgd_solver.cpp:136] Iteration 266300, lr = 0.0167813, m = 0.9
I0802 02:27:30.988275 12219 solver.cpp:353] Iteration 266400 (7.15254 iter/s, 13.981s/100 iter), loss = 1.58292
I0802 02:27:30.988335 12219 solver.cpp:375]     Train net output #0: loss = 1.97851 (* 1 = 1.97851 loss)
I0802 02:27:30.988343 12219 sgd_solver.cpp:136] Iteration 266400, lr = 0.01675, m = 0.9
I0802 02:27:44.940042 12219 solver.cpp:353] Iteration 266500 (7.16775 iter/s, 13.9514s/100 iter), loss = 1.73312
I0802 02:27:44.940068 12219 solver.cpp:375]     Train net output #0: loss = 1.5828 (* 1 = 1.5828 loss)
I0802 02:27:44.940073 12219 sgd_solver.cpp:136] Iteration 266500, lr = 0.0167188, m = 0.9
I0802 02:27:58.949193 12219 solver.cpp:353] Iteration 266600 (7.13838 iter/s, 14.0088s/100 iter), loss = 1.55208
I0802 02:27:58.949221 12219 solver.cpp:375]     Train net output #0: loss = 1.38752 (* 1 = 1.38752 loss)
I0802 02:27:58.949228 12219 sgd_solver.cpp:136] Iteration 266600, lr = 0.0166875, m = 0.9
I0802 02:28:12.898299 12219 solver.cpp:353] Iteration 266700 (7.16911 iter/s, 13.9487s/100 iter), loss = 1.53835
I0802 02:28:12.898365 12219 solver.cpp:375]     Train net output #0: loss = 1.61754 (* 1 = 1.61754 loss)
I0802 02:28:12.898370 12219 sgd_solver.cpp:136] Iteration 266700, lr = 0.0166562, m = 0.9
I0802 02:28:26.773573 12219 solver.cpp:353] Iteration 266800 (7.20726 iter/s, 13.8749s/100 iter), loss = 1.87301
I0802 02:28:26.773602 12219 solver.cpp:375]     Train net output #0: loss = 2.03622 (* 1 = 2.03622 loss)
I0802 02:28:26.773609 12219 sgd_solver.cpp:136] Iteration 266800, lr = 0.016625, m = 0.9
I0802 02:28:40.763981 12219 solver.cpp:353] Iteration 266900 (7.14795 iter/s, 13.99s/100 iter), loss = 1.6275
I0802 02:28:40.764008 12219 solver.cpp:375]     Train net output #0: loss = 1.63985 (* 1 = 1.63985 loss)
I0802 02:28:40.764012 12219 sgd_solver.cpp:136] Iteration 266900, lr = 0.0165937, m = 0.9
I0802 02:28:54.837708 12219 solver.cpp:353] Iteration 267000 (7.10563 iter/s, 14.0733s/100 iter), loss = 1.48753
I0802 02:28:54.837775 12219 solver.cpp:375]     Train net output #0: loss = 1.26094 (* 1 = 1.26094 loss)
I0802 02:28:54.837782 12219 sgd_solver.cpp:136] Iteration 267000, lr = 0.0165625, m = 0.9
I0802 02:29:08.938433 12219 solver.cpp:353] Iteration 267100 (7.09203 iter/s, 14.1003s/100 iter), loss = 1.7557
I0802 02:29:08.938462 12219 solver.cpp:375]     Train net output #0: loss = 1.87581 (* 1 = 1.87581 loss)
I0802 02:29:08.938468 12219 sgd_solver.cpp:136] Iteration 267100, lr = 0.0165313, m = 0.9
I0802 02:29:23.003137 12219 solver.cpp:353] Iteration 267200 (7.11019 iter/s, 14.0643s/100 iter), loss = 1.32455
I0802 02:29:23.003233 12219 solver.cpp:375]     Train net output #0: loss = 1.43553 (* 1 = 1.43553 loss)
I0802 02:29:23.003254 12219 sgd_solver.cpp:136] Iteration 267200, lr = 0.0165, m = 0.9
I0802 02:29:36.940886 12219 solver.cpp:353] Iteration 267300 (7.17496 iter/s, 13.9374s/100 iter), loss = 1.34988
I0802 02:29:36.940987 12219 solver.cpp:375]     Train net output #0: loss = 1.23131 (* 1 = 1.23131 loss)
I0802 02:29:36.940996 12219 sgd_solver.cpp:136] Iteration 267300, lr = 0.0164688, m = 0.9
I0802 02:29:51.157639 12219 solver.cpp:353] Iteration 267400 (7.03415 iter/s, 14.2164s/100 iter), loss = 1.47335
I0802 02:29:51.157676 12219 solver.cpp:375]     Train net output #0: loss = 1.54283 (* 1 = 1.54283 loss)
I0802 02:29:51.157683 12219 sgd_solver.cpp:136] Iteration 267400, lr = 0.0164375, m = 0.9
I0802 02:30:05.271592 12219 solver.cpp:353] Iteration 267500 (7.08538 iter/s, 14.1136s/100 iter), loss = 1.72273
I0802 02:30:05.271845 12219 solver.cpp:375]     Train net output #0: loss = 1.78237 (* 1 = 1.78237 loss)
I0802 02:30:05.271940 12219 sgd_solver.cpp:136] Iteration 267500, lr = 0.0164063, m = 0.9
I0802 02:30:19.361717 12219 solver.cpp:353] Iteration 267600 (7.09736 iter/s, 14.0897s/100 iter), loss = 1.70327
I0802 02:30:19.361802 12219 solver.cpp:375]     Train net output #0: loss = 1.51366 (* 1 = 1.51366 loss)
I0802 02:30:19.361809 12219 sgd_solver.cpp:136] Iteration 267600, lr = 0.016375, m = 0.9
I0802 02:30:33.357623 12219 solver.cpp:353] Iteration 267700 (7.14514 iter/s, 13.9955s/100 iter), loss = 1.49008
I0802 02:30:33.357651 12219 solver.cpp:375]     Train net output #0: loss = 1.82518 (* 1 = 1.82518 loss)
I0802 02:30:33.357656 12219 sgd_solver.cpp:136] Iteration 267700, lr = 0.0163437, m = 0.9
I0802 02:30:47.419306 12219 solver.cpp:353] Iteration 267800 (7.11172 iter/s, 14.0613s/100 iter), loss = 1.70341
I0802 02:30:47.419340 12219 solver.cpp:375]     Train net output #0: loss = 1.56547 (* 1 = 1.56547 loss)
I0802 02:30:47.419348 12219 sgd_solver.cpp:136] Iteration 267800, lr = 0.0163125, m = 0.9
I0802 02:31:01.529407 12219 solver.cpp:353] Iteration 267900 (7.08732 iter/s, 14.1097s/100 iter), loss = 1.72662
I0802 02:31:01.529503 12219 solver.cpp:375]     Train net output #0: loss = 1.77807 (* 1 = 1.77807 loss)
I0802 02:31:01.529516 12219 sgd_solver.cpp:136] Iteration 267900, lr = 0.0162812, m = 0.9
I0802 02:31:15.473630 12219 solver.cpp:550] Iteration 268000, Testing net (#0)
I0802 02:31:35.822657 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.533235
I0802 02:31:35.822710 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.778292
I0802 02:31:35.822716 12219 solver.cpp:635]     Test net output #2: loss = 2.04416 (* 1 = 2.04416 loss)
I0802 02:31:35.822734 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3486s
I0802 02:31:35.963090 12219 solver.cpp:353] Iteration 268000 (2.90421 iter/s, 34.4328s/100 iter), loss = 1.59303
I0802 02:31:35.963119 12219 solver.cpp:375]     Train net output #0: loss = 1.54032 (* 1 = 1.54032 loss)
I0802 02:31:35.963122 12219 sgd_solver.cpp:136] Iteration 268000, lr = 0.01625, m = 0.9
I0802 02:31:49.898391 12219 solver.cpp:353] Iteration 268100 (7.17621 iter/s, 13.9349s/100 iter), loss = 1.58305
I0802 02:31:49.898417 12219 solver.cpp:375]     Train net output #0: loss = 1.42031 (* 1 = 1.42031 loss)
I0802 02:31:49.898422 12219 sgd_solver.cpp:136] Iteration 268100, lr = 0.0162188, m = 0.9
I0802 02:32:03.974426 12219 solver.cpp:353] Iteration 268200 (7.10447 iter/s, 14.0757s/100 iter), loss = 1.65152
I0802 02:32:03.974452 12219 solver.cpp:375]     Train net output #0: loss = 1.57311 (* 1 = 1.57311 loss)
I0802 02:32:03.974457 12219 sgd_solver.cpp:136] Iteration 268200, lr = 0.0161875, m = 0.9
I0802 02:32:18.050359 12219 solver.cpp:353] Iteration 268300 (7.10452 iter/s, 14.0756s/100 iter), loss = 1.78478
I0802 02:32:18.050441 12219 solver.cpp:375]     Train net output #0: loss = 2.1475 (* 1 = 2.1475 loss)
I0802 02:32:18.050448 12219 sgd_solver.cpp:136] Iteration 268300, lr = 0.0161563, m = 0.9
I0802 02:32:32.229029 12219 solver.cpp:353] Iteration 268400 (7.05304 iter/s, 14.1783s/100 iter), loss = 1.50871
I0802 02:32:32.229056 12219 solver.cpp:375]     Train net output #0: loss = 1.49995 (* 1 = 1.49995 loss)
I0802 02:32:32.229060 12219 sgd_solver.cpp:136] Iteration 268400, lr = 0.016125, m = 0.9
I0802 02:32:46.240061 12219 solver.cpp:353] Iteration 268500 (7.13743 iter/s, 14.0107s/100 iter), loss = 1.93057
I0802 02:32:46.240089 12219 solver.cpp:375]     Train net output #0: loss = 1.69403 (* 1 = 1.69403 loss)
I0802 02:32:46.240095 12219 sgd_solver.cpp:136] Iteration 268500, lr = 0.0160937, m = 0.9
I0802 02:33:00.242558 12219 solver.cpp:353] Iteration 268600 (7.14178 iter/s, 14.0021s/100 iter), loss = 1.4186
I0802 02:33:00.242635 12219 solver.cpp:375]     Train net output #0: loss = 1.73674 (* 1 = 1.73674 loss)
I0802 02:33:00.242642 12219 sgd_solver.cpp:136] Iteration 268600, lr = 0.0160625, m = 0.9
I0802 02:33:14.267901 12219 solver.cpp:353] Iteration 268700 (7.13014 iter/s, 14.025s/100 iter), loss = 1.67845
I0802 02:33:14.267926 12219 solver.cpp:375]     Train net output #0: loss = 1.68711 (* 1 = 1.68711 loss)
I0802 02:33:14.267932 12219 sgd_solver.cpp:136] Iteration 268700, lr = 0.0160312, m = 0.9
I0802 02:33:28.283812 12219 solver.cpp:353] Iteration 268800 (7.13494 iter/s, 14.0155s/100 iter), loss = 1.62639
I0802 02:33:28.283838 12219 solver.cpp:375]     Train net output #0: loss = 1.69902 (* 1 = 1.69902 loss)
I0802 02:33:28.283844 12219 sgd_solver.cpp:136] Iteration 268800, lr = 0.016, m = 0.9
I0802 02:33:42.371201 12219 solver.cpp:353] Iteration 268900 (7.09874 iter/s, 14.087s/100 iter), loss = 1.857
I0802 02:33:42.371265 12219 solver.cpp:375]     Train net output #0: loss = 1.65089 (* 1 = 1.65089 loss)
I0802 02:33:42.371273 12219 sgd_solver.cpp:136] Iteration 268900, lr = 0.0159688, m = 0.9
I0802 02:33:56.420778 12219 solver.cpp:353] Iteration 269000 (7.11785 iter/s, 14.0492s/100 iter), loss = 1.53714
I0802 02:33:56.420892 12219 solver.cpp:375]     Train net output #0: loss = 1.73932 (* 1 = 1.73932 loss)
I0802 02:33:56.420917 12219 sgd_solver.cpp:136] Iteration 269000, lr = 0.0159375, m = 0.9
I0802 02:34:10.399423 12219 solver.cpp:353] Iteration 269100 (7.15396 iter/s, 13.9783s/100 iter), loss = 1.92431
I0802 02:34:10.399452 12219 solver.cpp:375]     Train net output #0: loss = 2.06318 (* 1 = 2.06318 loss)
I0802 02:34:10.399459 12219 sgd_solver.cpp:136] Iteration 269100, lr = 0.0159063, m = 0.9
I0802 02:34:24.479315 12219 solver.cpp:353] Iteration 269200 (7.10252 iter/s, 14.0795s/100 iter), loss = 1.81212
I0802 02:34:24.485117 12219 solver.cpp:375]     Train net output #0: loss = 1.76423 (* 1 = 1.76423 loss)
I0802 02:34:24.485244 12219 sgd_solver.cpp:136] Iteration 269200, lr = 0.015875, m = 0.9
I0802 02:34:38.555027 12219 solver.cpp:353] Iteration 269300 (7.10463 iter/s, 14.0753s/100 iter), loss = 1.38489
I0802 02:34:38.555057 12219 solver.cpp:375]     Train net output #0: loss = 1.12971 (* 1 = 1.12971 loss)
I0802 02:34:38.555061 12219 sgd_solver.cpp:136] Iteration 269300, lr = 0.0158437, m = 0.9
I0802 02:34:52.603013 12219 solver.cpp:353] Iteration 269400 (7.11865 iter/s, 14.0476s/100 iter), loss = 1.46669
I0802 02:34:52.603039 12219 solver.cpp:375]     Train net output #0: loss = 1.0866 (* 1 = 1.0866 loss)
I0802 02:34:52.603044 12219 sgd_solver.cpp:136] Iteration 269400, lr = 0.0158125, m = 0.9
I0802 02:35:06.739313 12219 solver.cpp:353] Iteration 269500 (7.07418 iter/s, 14.1359s/100 iter), loss = 1.5881
I0802 02:35:06.739379 12219 solver.cpp:375]     Train net output #0: loss = 1.38679 (* 1 = 1.38679 loss)
I0802 02:35:06.739387 12219 sgd_solver.cpp:136] Iteration 269500, lr = 0.0157812, m = 0.9
I0802 02:35:20.732641 12219 solver.cpp:353] Iteration 269600 (7.14645 iter/s, 13.993s/100 iter), loss = 1.20525
I0802 02:35:20.732666 12219 solver.cpp:375]     Train net output #0: loss = 1.25853 (* 1 = 1.25853 loss)
I0802 02:35:20.732671 12219 sgd_solver.cpp:136] Iteration 269600, lr = 0.01575, m = 0.9
I0802 02:35:34.812057 12219 solver.cpp:353] Iteration 269700 (7.10276 iter/s, 14.079s/100 iter), loss = 1.2712
I0802 02:35:34.812086 12219 solver.cpp:375]     Train net output #0: loss = 1.57691 (* 1 = 1.57691 loss)
I0802 02:35:34.812093 12219 sgd_solver.cpp:136] Iteration 269700, lr = 0.0157188, m = 0.9
I0802 02:35:48.857349 12219 solver.cpp:353] Iteration 269800 (7.12001 iter/s, 14.0449s/100 iter), loss = 1.10485
I0802 02:35:48.857405 12219 solver.cpp:375]     Train net output #0: loss = 1.16413 (* 1 = 1.16413 loss)
I0802 02:35:48.857411 12219 sgd_solver.cpp:136] Iteration 269800, lr = 0.0156875, m = 0.9
I0802 02:36:02.905498 12219 solver.cpp:353] Iteration 269900 (7.11857 iter/s, 14.0478s/100 iter), loss = 1.66219
I0802 02:36:02.905524 12219 solver.cpp:375]     Train net output #0: loss = 1.58763 (* 1 = 1.58763 loss)
I0802 02:36:02.905527 12219 sgd_solver.cpp:136] Iteration 269900, lr = 0.0156563, m = 0.9
I0802 02:36:16.852267 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_270000.caffemodel
I0802 02:36:16.983017 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_270000.solverstate
I0802 02:36:16.988950 12219 solver.cpp:550] Iteration 270000, Testing net (#0)
I0802 02:36:22.465617 12207 data_reader.cpp:264] Starting prefetch of epoch 15
I0802 02:36:34.140854 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 02:36:36.727982 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.530294
I0802 02:36:36.728008 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.777233
I0802 02:36:36.728013 12219 solver.cpp:635]     Test net output #2: loss = 2.0565 (* 1 = 2.0565 loss)
I0802 02:36:36.728107 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7386s
I0802 02:36:36.872665 12219 solver.cpp:353] Iteration 270000 (2.9441 iter/s, 33.9663s/100 iter), loss = 1.66854
I0802 02:36:36.872694 12219 solver.cpp:375]     Train net output #0: loss = 1.59954 (* 1 = 1.59954 loss)
I0802 02:36:36.872701 12219 sgd_solver.cpp:136] Iteration 270000, lr = 0.015625, m = 0.9
I0802 02:36:50.888646 12219 solver.cpp:353] Iteration 270100 (7.13491 iter/s, 14.0156s/100 iter), loss = 1.38942
I0802 02:36:50.888741 12219 solver.cpp:375]     Train net output #0: loss = 1.50159 (* 1 = 1.50159 loss)
I0802 02:36:50.888761 12219 sgd_solver.cpp:136] Iteration 270100, lr = 0.0155937, m = 0.9
I0802 02:37:04.841001 12219 solver.cpp:353] Iteration 270200 (7.16744 iter/s, 13.952s/100 iter), loss = 1.42732
I0802 02:37:04.841105 12219 solver.cpp:375]     Train net output #0: loss = 1.313 (* 1 = 1.313 loss)
I0802 02:37:04.841114 12219 sgd_solver.cpp:136] Iteration 270200, lr = 0.0155625, m = 0.9
I0802 02:37:18.862804 12219 solver.cpp:353] Iteration 270300 (7.13195 iter/s, 14.0214s/100 iter), loss = 1.30026
I0802 02:37:18.863060 12219 solver.cpp:375]     Train net output #0: loss = 1.20986 (* 1 = 1.20986 loss)
I0802 02:37:18.863153 12219 sgd_solver.cpp:136] Iteration 270300, lr = 0.0155312, m = 0.9
I0802 02:37:32.867449 12219 solver.cpp:353] Iteration 270400 (7.14068 iter/s, 14.0043s/100 iter), loss = 1.40081
I0802 02:37:32.867480 12219 solver.cpp:375]     Train net output #0: loss = 1.07847 (* 1 = 1.07847 loss)
I0802 02:37:32.867486 12219 sgd_solver.cpp:136] Iteration 270400, lr = 0.0155, m = 0.9
I0802 02:37:46.842829 12219 solver.cpp:353] Iteration 270500 (7.15564 iter/s, 13.975s/100 iter), loss = 1.64619
I0802 02:37:46.842922 12219 solver.cpp:375]     Train net output #0: loss = 1.72925 (* 1 = 1.72925 loss)
I0802 02:37:46.842929 12219 sgd_solver.cpp:136] Iteration 270500, lr = 0.0154688, m = 0.9
I0802 02:38:00.877517 12219 solver.cpp:353] Iteration 270600 (7.1254 iter/s, 14.0343s/100 iter), loss = 1.64268
I0802 02:38:00.877549 12219 solver.cpp:375]     Train net output #0: loss = 1.44991 (* 1 = 1.44991 loss)
I0802 02:38:00.877557 12219 sgd_solver.cpp:136] Iteration 270600, lr = 0.0154375, m = 0.9
I0802 02:38:14.897861 12219 solver.cpp:353] Iteration 270700 (7.13268 iter/s, 14.02s/100 iter), loss = 2.02611
I0802 02:38:14.897883 12219 solver.cpp:375]     Train net output #0: loss = 1.99055 (* 1 = 1.99055 loss)
I0802 02:38:14.897887 12219 sgd_solver.cpp:136] Iteration 270700, lr = 0.0154063, m = 0.9
I0802 02:38:29.008780 12219 solver.cpp:353] Iteration 270800 (7.0869 iter/s, 14.1105s/100 iter), loss = 1.49668
I0802 02:38:29.008890 12219 solver.cpp:375]     Train net output #0: loss = 1.24472 (* 1 = 1.24472 loss)
I0802 02:38:29.008898 12219 sgd_solver.cpp:136] Iteration 270800, lr = 0.015375, m = 0.9
I0802 02:38:42.999894 12219 solver.cpp:353] Iteration 270900 (7.14759 iter/s, 13.9907s/100 iter), loss = 1.46345
I0802 02:38:42.999920 12219 solver.cpp:375]     Train net output #0: loss = 1.67265 (* 1 = 1.67265 loss)
I0802 02:38:42.999927 12219 sgd_solver.cpp:136] Iteration 270900, lr = 0.0153437, m = 0.9
I0802 02:38:56.997627 12219 solver.cpp:353] Iteration 271000 (7.14421 iter/s, 13.9974s/100 iter), loss = 1.38648
I0802 02:38:56.997659 12219 solver.cpp:375]     Train net output #0: loss = 1.30711 (* 1 = 1.30711 loss)
I0802 02:38:56.997666 12219 sgd_solver.cpp:136] Iteration 271000, lr = 0.0153125, m = 0.9
I0802 02:39:11.060521 12219 solver.cpp:353] Iteration 271100 (7.11111 iter/s, 14.0625s/100 iter), loss = 1.60765
I0802 02:39:11.060679 12219 solver.cpp:375]     Train net output #0: loss = 1.5032 (* 1 = 1.5032 loss)
I0802 02:39:11.060703 12219 sgd_solver.cpp:136] Iteration 271100, lr = 0.0152812, m = 0.9
I0802 02:39:25.122509 12219 solver.cpp:353] Iteration 271200 (7.11156 iter/s, 14.0616s/100 iter), loss = 1.70581
I0802 02:39:25.122563 12219 solver.cpp:375]     Train net output #0: loss = 1.80598 (* 1 = 1.80598 loss)
I0802 02:39:25.122576 12219 sgd_solver.cpp:136] Iteration 271200, lr = 0.01525, m = 0.9
I0802 02:39:39.228399 12219 solver.cpp:353] Iteration 271300 (7.08943 iter/s, 14.1055s/100 iter), loss = 2.08776
I0802 02:39:39.228467 12219 solver.cpp:375]     Train net output #0: loss = 1.99362 (* 1 = 1.99362 loss)
I0802 02:39:39.228492 12219 sgd_solver.cpp:136] Iteration 271300, lr = 0.0152188, m = 0.9
I0802 02:39:53.207161 12219 solver.cpp:353] Iteration 271400 (7.1539 iter/s, 13.9784s/100 iter), loss = 1.56631
I0802 02:39:53.207231 12219 solver.cpp:375]     Train net output #0: loss = 1.49388 (* 1 = 1.49388 loss)
I0802 02:39:53.207238 12219 sgd_solver.cpp:136] Iteration 271400, lr = 0.0151875, m = 0.9
I0802 02:40:07.135931 12219 solver.cpp:353] Iteration 271500 (7.17958 iter/s, 13.9284s/100 iter), loss = 1.6008
I0802 02:40:07.135956 12219 solver.cpp:375]     Train net output #0: loss = 1.68085 (* 1 = 1.68085 loss)
I0802 02:40:07.135962 12219 sgd_solver.cpp:136] Iteration 271500, lr = 0.0151563, m = 0.9
I0802 02:40:21.190939 12219 solver.cpp:353] Iteration 271600 (7.11509 iter/s, 14.0546s/100 iter), loss = 1.31926
I0802 02:40:21.191030 12219 solver.cpp:375]     Train net output #0: loss = 1.25119 (* 1 = 1.25119 loss)
I0802 02:40:21.191051 12219 sgd_solver.cpp:136] Iteration 271600, lr = 0.015125, m = 0.9
I0802 02:40:35.129680 12219 solver.cpp:353] Iteration 271700 (7.17444 iter/s, 13.9384s/100 iter), loss = 1.44746
I0802 02:40:35.129739 12219 solver.cpp:375]     Train net output #0: loss = 1.81442 (* 1 = 1.81442 loss)
I0802 02:40:35.129745 12219 sgd_solver.cpp:136] Iteration 271700, lr = 0.0150938, m = 0.9
I0802 02:40:49.080914 12219 solver.cpp:353] Iteration 271800 (7.16802 iter/s, 13.9509s/100 iter), loss = 1.74536
I0802 02:40:49.080938 12219 solver.cpp:375]     Train net output #0: loss = 2.06299 (* 1 = 2.06299 loss)
I0802 02:40:49.080945 12219 sgd_solver.cpp:136] Iteration 271800, lr = 0.0150625, m = 0.9
I0802 02:41:03.021723 12219 solver.cpp:353] Iteration 271900 (7.17338 iter/s, 13.9404s/100 iter), loss = 1.39607
I0802 02:41:03.021752 12219 solver.cpp:375]     Train net output #0: loss = 1.45037 (* 1 = 1.45037 loss)
I0802 02:41:03.021759 12219 sgd_solver.cpp:136] Iteration 271900, lr = 0.0150312, m = 0.9
I0802 02:41:16.839660 12219 solver.cpp:550] Iteration 272000, Testing net (#0)
I0802 02:41:36.821211 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.540235
I0802 02:41:36.821236 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.783587
I0802 02:41:36.821241 12219 solver.cpp:635]     Test net output #2: loss = 2.02317 (* 1 = 2.02317 loss)
I0802 02:41:36.821259 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9811s
I0802 02:41:36.962352 12219 solver.cpp:353] Iteration 272000 (2.9464 iter/s, 33.9397s/100 iter), loss = 1.4443
I0802 02:41:36.962379 12219 solver.cpp:375]     Train net output #0: loss = 1.46604 (* 1 = 1.46604 loss)
I0802 02:41:36.962384 12219 sgd_solver.cpp:136] Iteration 272000, lr = 0.015, m = 0.9
I0802 02:41:50.963737 12219 solver.cpp:353] Iteration 272100 (7.14234 iter/s, 14.001s/100 iter), loss = 1.49001
I0802 02:41:50.963798 12219 solver.cpp:375]     Train net output #0: loss = 1.35385 (* 1 = 1.35385 loss)
I0802 02:41:50.963805 12219 sgd_solver.cpp:136] Iteration 272100, lr = 0.0149688, m = 0.9
I0802 02:42:04.935397 12219 solver.cpp:353] Iteration 272200 (7.15754 iter/s, 13.9713s/100 iter), loss = 1.74737
I0802 02:42:04.935423 12219 solver.cpp:375]     Train net output #0: loss = 1.41524 (* 1 = 1.41524 loss)
I0802 02:42:04.935430 12219 sgd_solver.cpp:136] Iteration 272200, lr = 0.0149375, m = 0.9
I0802 02:42:18.810637 12219 solver.cpp:353] Iteration 272300 (7.20728 iter/s, 13.8749s/100 iter), loss = 1.52053
I0802 02:42:18.810664 12219 solver.cpp:375]     Train net output #0: loss = 1.62982 (* 1 = 1.62982 loss)
I0802 02:42:18.810668 12219 sgd_solver.cpp:136] Iteration 272300, lr = 0.0149063, m = 0.9
I0802 02:42:32.813807 12219 solver.cpp:353] Iteration 272400 (7.14144 iter/s, 14.0028s/100 iter), loss = 1.63504
I0802 02:42:32.813938 12219 solver.cpp:375]     Train net output #0: loss = 1.49973 (* 1 = 1.49973 loss)
I0802 02:42:32.813963 12219 sgd_solver.cpp:136] Iteration 272400, lr = 0.014875, m = 0.9
I0802 02:42:46.904546 12219 solver.cpp:353] Iteration 272500 (7.09705 iter/s, 14.0904s/100 iter), loss = 1.5472
I0802 02:42:46.904578 12219 solver.cpp:375]     Train net output #0: loss = 1.47123 (* 1 = 1.47123 loss)
I0802 02:42:46.904582 12219 sgd_solver.cpp:136] Iteration 272500, lr = 0.0148437, m = 0.9
I0802 02:43:00.915269 12219 solver.cpp:353] Iteration 272600 (7.13758 iter/s, 14.0103s/100 iter), loss = 1.17204
I0802 02:43:00.915295 12219 solver.cpp:375]     Train net output #0: loss = 1.09611 (* 1 = 1.09611 loss)
I0802 02:43:00.915302 12219 sgd_solver.cpp:136] Iteration 272600, lr = 0.0148125, m = 0.9
I0802 02:43:14.889088 12219 solver.cpp:353] Iteration 272700 (7.15643 iter/s, 13.9734s/100 iter), loss = 1.75588
I0802 02:43:14.889411 12219 solver.cpp:375]     Train net output #0: loss = 1.72769 (* 1 = 1.72769 loss)
I0802 02:43:14.889418 12219 sgd_solver.cpp:136] Iteration 272700, lr = 0.0147812, m = 0.9
I0802 02:43:28.899179 12219 solver.cpp:353] Iteration 272800 (7.13791 iter/s, 14.0097s/100 iter), loss = 1.52339
I0802 02:43:28.899206 12219 solver.cpp:375]     Train net output #0: loss = 1.1729 (* 1 = 1.1729 loss)
I0802 02:43:28.899212 12219 sgd_solver.cpp:136] Iteration 272800, lr = 0.01475, m = 0.9
I0802 02:43:42.959578 12219 solver.cpp:353] Iteration 272900 (7.11237 iter/s, 14.06s/100 iter), loss = 1.85977
I0802 02:43:42.959601 12219 solver.cpp:375]     Train net output #0: loss = 1.64713 (* 1 = 1.64713 loss)
I0802 02:43:42.959605 12219 sgd_solver.cpp:136] Iteration 272900, lr = 0.0147187, m = 0.9
I0802 02:43:56.924273 12219 solver.cpp:353] Iteration 273000 (7.16111 iter/s, 13.9643s/100 iter), loss = 1.87647
I0802 02:43:56.924340 12219 solver.cpp:375]     Train net output #0: loss = 1.3371 (* 1 = 1.3371 loss)
I0802 02:43:56.924346 12219 sgd_solver.cpp:136] Iteration 273000, lr = 0.0146875, m = 0.9
I0802 02:44:11.044041 12219 solver.cpp:353] Iteration 273100 (7.08247 iter/s, 14.1194s/100 iter), loss = 1.66637
I0802 02:44:11.044070 12219 solver.cpp:375]     Train net output #0: loss = 1.4946 (* 1 = 1.4946 loss)
I0802 02:44:11.044075 12219 sgd_solver.cpp:136] Iteration 273100, lr = 0.0146563, m = 0.9
I0802 02:44:25.162531 12219 solver.cpp:353] Iteration 273200 (7.0831 iter/s, 14.1181s/100 iter), loss = 1.38209
I0802 02:44:25.162598 12219 solver.cpp:375]     Train net output #0: loss = 1.24125 (* 1 = 1.24125 loss)
I0802 02:44:25.162621 12219 sgd_solver.cpp:136] Iteration 273200, lr = 0.014625, m = 0.9
I0802 02:44:39.081140 12219 solver.cpp:353] Iteration 273300 (7.18482 iter/s, 13.9182s/100 iter), loss = 1.60198
I0802 02:44:39.081244 12219 solver.cpp:375]     Train net output #0: loss = 1.48075 (* 1 = 1.48075 loss)
I0802 02:44:39.081251 12219 sgd_solver.cpp:136] Iteration 273300, lr = 0.0145938, m = 0.9
I0802 02:44:52.941828 12219 solver.cpp:353] Iteration 273400 (7.21484 iter/s, 13.8603s/100 iter), loss = 1.80781
I0802 02:44:52.941926 12219 solver.cpp:375]     Train net output #0: loss = 1.65825 (* 1 = 1.65825 loss)
I0802 02:44:52.941947 12219 sgd_solver.cpp:136] Iteration 273400, lr = 0.0145625, m = 0.9
I0802 02:45:06.906756 12219 solver.cpp:353] Iteration 273500 (7.16099 iter/s, 13.9645s/100 iter), loss = 1.55523
I0802 02:45:06.906783 12219 solver.cpp:375]     Train net output #0: loss = 1.54435 (* 1 = 1.54435 loss)
I0802 02:45:06.906790 12219 sgd_solver.cpp:136] Iteration 273500, lr = 0.0145312, m = 0.9
I0802 02:45:21.010118 12219 solver.cpp:353] Iteration 273600 (7.0907 iter/s, 14.103s/100 iter), loss = 1.41414
I0802 02:45:21.010244 12219 solver.cpp:375]     Train net output #0: loss = 1.35794 (* 1 = 1.35794 loss)
I0802 02:45:21.010264 12219 sgd_solver.cpp:136] Iteration 273600, lr = 0.0145, m = 0.9
I0802 02:45:35.145558 12219 solver.cpp:353] Iteration 273700 (7.07461 iter/s, 14.1351s/100 iter), loss = 1.44408
I0802 02:45:35.145586 12219 solver.cpp:375]     Train net output #0: loss = 1.20288 (* 1 = 1.20288 loss)
I0802 02:45:35.145593 12219 sgd_solver.cpp:136] Iteration 273700, lr = 0.0144687, m = 0.9
I0802 02:45:49.136685 12219 solver.cpp:353] Iteration 273800 (7.14758 iter/s, 13.9908s/100 iter), loss = 1.50305
I0802 02:45:49.136711 12219 solver.cpp:375]     Train net output #0: loss = 1.649 (* 1 = 1.649 loss)
I0802 02:45:49.136718 12219 sgd_solver.cpp:136] Iteration 273800, lr = 0.0144375, m = 0.9
I0802 02:46:03.068768 12219 solver.cpp:353] Iteration 273900 (7.17787 iter/s, 13.9317s/100 iter), loss = 1.66217
I0802 02:46:03.068909 12219 solver.cpp:375]     Train net output #0: loss = 1.8376 (* 1 = 1.8376 loss)
I0802 02:46:03.068933 12219 sgd_solver.cpp:136] Iteration 273900, lr = 0.0144063, m = 0.9
I0802 02:46:16.923552 12219 solver.cpp:550] Iteration 274000, Testing net (#0)
I0802 02:46:37.180696 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.550647
I0802 02:46:37.180810 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.790586
I0802 02:46:37.180830 12219 solver.cpp:635]     Test net output #2: loss = 1.98368 (* 1 = 1.98368 loss)
I0802 02:46:37.180848 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2568s
I0802 02:46:37.336606 12219 solver.cpp:353] Iteration 274000 (2.91827 iter/s, 34.2669s/100 iter), loss = 1.16288
I0802 02:46:37.336727 12219 solver.cpp:375]     Train net output #0: loss = 1.18601 (* 1 = 1.18601 loss)
I0802 02:46:37.336751 12219 sgd_solver.cpp:136] Iteration 274000, lr = 0.014375, m = 0.9
I0802 02:46:51.409795 12219 solver.cpp:353] Iteration 274100 (7.1059 iter/s, 14.0728s/100 iter), loss = 1.69534
I0802 02:46:51.409823 12219 solver.cpp:375]     Train net output #0: loss = 1.94056 (* 1 = 1.94056 loss)
I0802 02:46:51.409831 12219 sgd_solver.cpp:136] Iteration 274100, lr = 0.0143438, m = 0.9
I0802 02:47:05.325223 12219 solver.cpp:353] Iteration 274200 (7.18647 iter/s, 13.915s/100 iter), loss = 1.50376
I0802 02:47:05.325270 12219 solver.cpp:375]     Train net output #0: loss = 1.73219 (* 1 = 1.73219 loss)
I0802 02:47:05.325281 12219 sgd_solver.cpp:136] Iteration 274200, lr = 0.0143125, m = 0.9
I0802 02:47:19.362681 12219 solver.cpp:353] Iteration 274300 (7.12399 iter/s, 14.0371s/100 iter), loss = 1.45058
I0802 02:47:19.362756 12219 solver.cpp:375]     Train net output #0: loss = 1.25511 (* 1 = 1.25511 loss)
I0802 02:47:19.362764 12219 sgd_solver.cpp:136] Iteration 274300, lr = 0.0142812, m = 0.9
I0802 02:47:33.433374 12219 solver.cpp:353] Iteration 274400 (7.10716 iter/s, 14.0703s/100 iter), loss = 1.63871
I0802 02:47:33.433403 12219 solver.cpp:375]     Train net output #0: loss = 1.87646 (* 1 = 1.87646 loss)
I0802 02:47:33.433410 12219 sgd_solver.cpp:136] Iteration 274400, lr = 0.01425, m = 0.9
I0802 02:47:47.479976 12219 solver.cpp:353] Iteration 274500 (7.11935 iter/s, 14.0462s/100 iter), loss = 1.40526
I0802 02:47:47.480010 12219 solver.cpp:375]     Train net output #0: loss = 1.33967 (* 1 = 1.33967 loss)
I0802 02:47:47.480016 12219 sgd_solver.cpp:136] Iteration 274500, lr = 0.0142187, m = 0.9
I0802 02:48:01.498309 12219 solver.cpp:353] Iteration 274600 (7.13371 iter/s, 14.018s/100 iter), loss = 1.62442
I0802 02:48:01.498397 12219 solver.cpp:375]     Train net output #0: loss = 1.94152 (* 1 = 1.94152 loss)
I0802 02:48:01.498404 12219 sgd_solver.cpp:136] Iteration 274600, lr = 0.0141875, m = 0.9
I0802 02:48:15.544126 12219 solver.cpp:353] Iteration 274700 (7.11975 iter/s, 14.0454s/100 iter), loss = 1.5984
I0802 02:48:15.544152 12219 solver.cpp:375]     Train net output #0: loss = 1.50498 (* 1 = 1.50498 loss)
I0802 02:48:15.544157 12219 sgd_solver.cpp:136] Iteration 274700, lr = 0.0141563, m = 0.9
I0802 02:48:29.553694 12219 solver.cpp:353] Iteration 274800 (7.13817 iter/s, 14.0092s/100 iter), loss = 1.79775
I0802 02:48:29.553720 12219 solver.cpp:375]     Train net output #0: loss = 1.88975 (* 1 = 1.88975 loss)
I0802 02:48:29.553726 12219 sgd_solver.cpp:136] Iteration 274800, lr = 0.014125, m = 0.9
I0802 02:48:43.568033 12219 solver.cpp:353] Iteration 274900 (7.13574 iter/s, 14.014s/100 iter), loss = 1.17162
I0802 02:48:43.568102 12219 solver.cpp:375]     Train net output #0: loss = 1.25704 (* 1 = 1.25704 loss)
I0802 02:48:43.568109 12219 sgd_solver.cpp:136] Iteration 274900, lr = 0.0140938, m = 0.9
I0802 02:48:57.649855 12219 solver.cpp:353] Iteration 275000 (7.10154 iter/s, 14.0814s/100 iter), loss = 1.56369
I0802 02:48:57.649880 12219 solver.cpp:375]     Train net output #0: loss = 1.6125 (* 1 = 1.6125 loss)
I0802 02:48:57.649886 12219 sgd_solver.cpp:136] Iteration 275000, lr = 0.0140625, m = 0.9
I0802 02:49:11.742472 12219 solver.cpp:353] Iteration 275100 (7.0961 iter/s, 14.0922s/100 iter), loss = 1.8275
I0802 02:49:11.742497 12219 solver.cpp:375]     Train net output #0: loss = 1.7055 (* 1 = 1.7055 loss)
I0802 02:49:11.742501 12219 sgd_solver.cpp:136] Iteration 275100, lr = 0.0140312, m = 0.9
I0802 02:49:25.736585 12219 solver.cpp:353] Iteration 275200 (7.14606 iter/s, 13.9937s/100 iter), loss = 1.63819
I0802 02:49:25.736659 12219 solver.cpp:375]     Train net output #0: loss = 1.27927 (* 1 = 1.27927 loss)
I0802 02:49:25.736665 12219 sgd_solver.cpp:136] Iteration 275200, lr = 0.014, m = 0.9
I0802 02:49:39.740031 12219 solver.cpp:353] Iteration 275300 (7.14129 iter/s, 14.0031s/100 iter), loss = 1.74885
I0802 02:49:39.740067 12219 solver.cpp:375]     Train net output #0: loss = 1.76686 (* 1 = 1.76686 loss)
I0802 02:49:39.740073 12219 sgd_solver.cpp:136] Iteration 275300, lr = 0.0139687, m = 0.9
I0802 02:49:53.795449 12219 solver.cpp:353] Iteration 275400 (7.11488 iter/s, 14.055s/100 iter), loss = 1.75066
I0802 02:49:53.795482 12219 solver.cpp:375]     Train net output #0: loss = 1.65574 (* 1 = 1.65574 loss)
I0802 02:49:53.795488 12219 sgd_solver.cpp:136] Iteration 275400, lr = 0.0139375, m = 0.9
I0802 02:50:07.865228 12219 solver.cpp:353] Iteration 275500 (7.10762 iter/s, 14.0694s/100 iter), loss = 1.3822
I0802 02:50:07.865288 12219 solver.cpp:375]     Train net output #0: loss = 1.51147 (* 1 = 1.51147 loss)
I0802 02:50:07.865294 12219 sgd_solver.cpp:136] Iteration 275500, lr = 0.0139063, m = 0.9
I0802 02:50:21.965219 12219 solver.cpp:353] Iteration 275600 (7.09239 iter/s, 14.0996s/100 iter), loss = 1.70172
I0802 02:50:21.965248 12219 solver.cpp:375]     Train net output #0: loss = 1.94066 (* 1 = 1.94066 loss)
I0802 02:50:21.965255 12219 sgd_solver.cpp:136] Iteration 275600, lr = 0.013875, m = 0.9
I0802 02:50:35.923403 12219 solver.cpp:353] Iteration 275700 (7.16445 iter/s, 13.9578s/100 iter), loss = 1.61213
I0802 02:50:35.923432 12219 solver.cpp:375]     Train net output #0: loss = 1.43906 (* 1 = 1.43906 loss)
I0802 02:50:35.923437 12219 sgd_solver.cpp:136] Iteration 275700, lr = 0.0138438, m = 0.9
I0802 02:50:49.912557 12219 solver.cpp:353] Iteration 275800 (7.14859 iter/s, 13.9888s/100 iter), loss = 1.13359
I0802 02:50:49.912618 12219 solver.cpp:375]     Train net output #0: loss = 1.21396 (* 1 = 1.21396 loss)
I0802 02:50:49.912626 12219 sgd_solver.cpp:136] Iteration 275800, lr = 0.0138125, m = 0.9
I0802 02:51:03.977427 12219 solver.cpp:353] Iteration 275900 (7.11011 iter/s, 14.0645s/100 iter), loss = 1.67949
I0802 02:51:03.977458 12219 solver.cpp:375]     Train net output #0: loss = 1.88076 (* 1 = 1.88076 loss)
I0802 02:51:03.977463 12219 sgd_solver.cpp:136] Iteration 275900, lr = 0.0137812, m = 0.9
I0802 02:51:17.964355 12219 solver.cpp:550] Iteration 276000, Testing net (#0)
I0802 02:51:38.189932 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.533942
I0802 02:51:38.189988 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.776704
I0802 02:51:38.189996 12219 solver.cpp:635]     Test net output #2: loss = 2.05825 (* 1 = 2.05825 loss)
I0802 02:51:38.190012 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2251s
I0802 02:51:38.329013 12219 solver.cpp:353] Iteration 276000 (2.91115 iter/s, 34.3507s/100 iter), loss = 1.48384
I0802 02:51:38.329041 12219 solver.cpp:375]     Train net output #0: loss = 1.50624 (* 1 = 1.50624 loss)
I0802 02:51:38.329046 12219 sgd_solver.cpp:136] Iteration 276000, lr = 0.01375, m = 0.9
I0802 02:51:52.389801 12219 solver.cpp:353] Iteration 276100 (7.11217 iter/s, 14.0604s/100 iter), loss = 1.38496
I0802 02:51:52.389829 12219 solver.cpp:375]     Train net output #0: loss = 1.16657 (* 1 = 1.16657 loss)
I0802 02:51:52.389833 12219 sgd_solver.cpp:136] Iteration 276100, lr = 0.0137187, m = 0.9
I0802 02:52:06.388774 12219 solver.cpp:353] Iteration 276200 (7.14357 iter/s, 13.9986s/100 iter), loss = 1.59941
I0802 02:52:06.388799 12219 solver.cpp:375]     Train net output #0: loss = 1.03065 (* 1 = 1.03065 loss)
I0802 02:52:06.388803 12219 sgd_solver.cpp:136] Iteration 276200, lr = 0.0136875, m = 0.9
I0802 02:52:20.430819 12219 solver.cpp:353] Iteration 276300 (7.12166 iter/s, 14.0417s/100 iter), loss = 1.36129
I0802 02:52:20.431044 12219 solver.cpp:375]     Train net output #0: loss = 1.42577 (* 1 = 1.42577 loss)
I0802 02:52:20.431052 12219 sgd_solver.cpp:136] Iteration 276300, lr = 0.0136563, m = 0.9
I0802 02:52:34.490864 12219 solver.cpp:353] Iteration 276400 (7.11255 iter/s, 14.0597s/100 iter), loss = 1.98289
I0802 02:52:34.490890 12219 solver.cpp:375]     Train net output #0: loss = 1.94683 (* 1 = 1.94683 loss)
I0802 02:52:34.490895 12219 sgd_solver.cpp:136] Iteration 276400, lr = 0.013625, m = 0.9
I0802 02:52:48.548425 12219 solver.cpp:353] Iteration 276500 (7.1138 iter/s, 14.0572s/100 iter), loss = 1.47481
I0802 02:52:48.548452 12219 solver.cpp:375]     Train net output #0: loss = 1.47746 (* 1 = 1.47746 loss)
I0802 02:52:48.548457 12219 sgd_solver.cpp:136] Iteration 276500, lr = 0.0135938, m = 0.9
I0802 02:53:02.572604 12219 solver.cpp:353] Iteration 276600 (7.13073 iter/s, 14.0238s/100 iter), loss = 1.5477
I0802 02:53:02.572662 12219 solver.cpp:375]     Train net output #0: loss = 1.50787 (* 1 = 1.50787 loss)
I0802 02:53:02.572669 12219 sgd_solver.cpp:136] Iteration 276600, lr = 0.0135625, m = 0.9
I0802 02:53:16.508065 12219 solver.cpp:353] Iteration 276700 (7.17613 iter/s, 13.9351s/100 iter), loss = 1.4953
I0802 02:53:16.508118 12219 solver.cpp:375]     Train net output #0: loss = 1.50861 (* 1 = 1.50861 loss)
I0802 02:53:16.508131 12219 sgd_solver.cpp:136] Iteration 276700, lr = 0.0135312, m = 0.9
I0802 02:53:30.463585 12219 solver.cpp:353] Iteration 276800 (7.16582 iter/s, 13.9551s/100 iter), loss = 1.64302
I0802 02:53:30.463614 12219 solver.cpp:375]     Train net output #0: loss = 1.89112 (* 1 = 1.89112 loss)
I0802 02:53:30.463620 12219 sgd_solver.cpp:136] Iteration 276800, lr = 0.0135, m = 0.9
I0802 02:53:44.475311 12219 solver.cpp:353] Iteration 276900 (7.13707 iter/s, 14.0113s/100 iter), loss = 1.40676
I0802 02:53:44.475395 12219 solver.cpp:375]     Train net output #0: loss = 1.39681 (* 1 = 1.39681 loss)
I0802 02:53:44.475409 12219 sgd_solver.cpp:136] Iteration 276900, lr = 0.0134687, m = 0.9
I0802 02:53:47.906442 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 02:53:58.480204 12219 solver.cpp:353] Iteration 277000 (7.14055 iter/s, 14.0045s/100 iter), loss = 1.88977
I0802 02:53:58.480231 12219 solver.cpp:375]     Train net output #0: loss = 2.15924 (* 1 = 2.15924 loss)
I0802 02:53:58.480237 12219 sgd_solver.cpp:136] Iteration 277000, lr = 0.0134375, m = 0.9
I0802 02:54:12.526628 12219 solver.cpp:353] Iteration 277100 (7.11944 iter/s, 14.046s/100 iter), loss = 1.47812
I0802 02:54:12.526656 12219 solver.cpp:375]     Train net output #0: loss = 1.60721 (* 1 = 1.60721 loss)
I0802 02:54:12.526660 12219 sgd_solver.cpp:136] Iteration 277100, lr = 0.0134063, m = 0.9
I0802 02:54:26.525146 12219 solver.cpp:353] Iteration 277200 (7.14381 iter/s, 13.9981s/100 iter), loss = 1.60412
I0802 02:54:26.525207 12219 solver.cpp:375]     Train net output #0: loss = 1.83348 (* 1 = 1.83348 loss)
I0802 02:54:26.525213 12219 sgd_solver.cpp:136] Iteration 277200, lr = 0.013375, m = 0.9
I0802 02:54:40.584038 12219 solver.cpp:353] Iteration 277300 (7.11313 iter/s, 14.0585s/100 iter), loss = 1.53432
I0802 02:54:40.584062 12219 solver.cpp:375]     Train net output #0: loss = 1.67507 (* 1 = 1.67507 loss)
I0802 02:54:40.584066 12219 sgd_solver.cpp:136] Iteration 277300, lr = 0.0133438, m = 0.9
I0802 02:54:54.474231 12219 solver.cpp:353] Iteration 277400 (7.19952 iter/s, 13.8898s/100 iter), loss = 1.6793
I0802 02:54:54.474256 12219 solver.cpp:375]     Train net output #0: loss = 1.77473 (* 1 = 1.77473 loss)
I0802 02:54:54.474261 12219 sgd_solver.cpp:136] Iteration 277400, lr = 0.0133125, m = 0.9
I0802 02:55:08.567075 12219 solver.cpp:353] Iteration 277500 (7.09599 iter/s, 14.0925s/100 iter), loss = 1.57821
I0802 02:55:08.567142 12219 solver.cpp:375]     Train net output #0: loss = 1.86312 (* 1 = 1.86312 loss)
I0802 02:55:08.567148 12219 sgd_solver.cpp:136] Iteration 277500, lr = 0.0132813, m = 0.9
I0802 02:55:22.473122 12219 solver.cpp:353] Iteration 277600 (7.19131 iter/s, 13.9057s/100 iter), loss = 1.63697
I0802 02:55:22.473147 12219 solver.cpp:375]     Train net output #0: loss = 1.53421 (* 1 = 1.53421 loss)
I0802 02:55:22.473153 12219 sgd_solver.cpp:136] Iteration 277600, lr = 0.01325, m = 0.9
I0802 02:55:36.438715 12219 solver.cpp:353] Iteration 277700 (7.16065 iter/s, 13.9652s/100 iter), loss = 1.18474
I0802 02:55:36.438763 12219 solver.cpp:375]     Train net output #0: loss = 1.05736 (* 1 = 1.05736 loss)
I0802 02:55:36.438773 12219 sgd_solver.cpp:136] Iteration 277700, lr = 0.0132187, m = 0.9
I0802 02:55:50.426751 12219 solver.cpp:353] Iteration 277800 (7.14916 iter/s, 13.9877s/100 iter), loss = 1.41817
I0802 02:55:50.426815 12219 solver.cpp:375]     Train net output #0: loss = 1.54613 (* 1 = 1.54613 loss)
I0802 02:55:50.426822 12219 sgd_solver.cpp:136] Iteration 277800, lr = 0.0131875, m = 0.9
I0802 02:56:04.447046 12219 solver.cpp:353] Iteration 277900 (7.13271 iter/s, 14.0199s/100 iter), loss = 1.77847
I0802 02:56:04.447070 12219 solver.cpp:375]     Train net output #0: loss = 1.79002 (* 1 = 1.79002 loss)
I0802 02:56:04.447074 12219 sgd_solver.cpp:136] Iteration 277900, lr = 0.0131562, m = 0.9
I0802 02:56:18.347877 12219 solver.cpp:550] Iteration 278000, Testing net (#0)
I0802 02:56:37.906579 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.536177
I0802 02:56:37.906684 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.775881
I0802 02:56:37.906697 12219 solver.cpp:635]     Test net output #2: loss = 2.04662 (* 1 = 2.04662 loss)
I0802 02:56:37.906834 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.5584s
I0802 02:56:38.064714 12219 solver.cpp:353] Iteration 278000 (2.97471 iter/s, 33.6168s/100 iter), loss = 1.32006
I0802 02:56:38.064748 12219 solver.cpp:375]     Train net output #0: loss = 1.57285 (* 1 = 1.57285 loss)
I0802 02:56:38.064754 12219 sgd_solver.cpp:136] Iteration 278000, lr = 0.013125, m = 0.9
I0802 02:56:52.007136 12219 solver.cpp:353] Iteration 278100 (7.17255 iter/s, 13.942s/100 iter), loss = 1.26069
I0802 02:56:52.007172 12219 solver.cpp:375]     Train net output #0: loss = 1.04909 (* 1 = 1.04909 loss)
I0802 02:56:52.007177 12219 sgd_solver.cpp:136] Iteration 278100, lr = 0.0130938, m = 0.9
I0802 02:57:05.996125 12219 solver.cpp:353] Iteration 278200 (7.14867 iter/s, 13.9886s/100 iter), loss = 1.59651
I0802 02:57:05.996158 12219 solver.cpp:375]     Train net output #0: loss = 1.5512 (* 1 = 1.5512 loss)
I0802 02:57:05.996165 12219 sgd_solver.cpp:136] Iteration 278200, lr = 0.0130625, m = 0.9
I0802 02:57:19.939532 12219 solver.cpp:353] Iteration 278300 (7.17204 iter/s, 13.943s/100 iter), loss = 2.31747
I0802 02:57:19.941391 12219 solver.cpp:375]     Train net output #0: loss = 2.10684 (* 1 = 2.10684 loss)
I0802 02:57:19.941408 12219 sgd_solver.cpp:136] Iteration 278300, lr = 0.0130313, m = 0.9
I0802 02:57:33.860107 12219 solver.cpp:353] Iteration 278400 (7.18381 iter/s, 13.9202s/100 iter), loss = 1.82929
I0802 02:57:33.860203 12219 solver.cpp:375]     Train net output #0: loss = 1.90629 (* 1 = 1.90629 loss)
I0802 02:57:33.860221 12219 sgd_solver.cpp:136] Iteration 278400, lr = 0.013, m = 0.9
I0802 02:57:47.772543 12219 solver.cpp:353] Iteration 278500 (7.18801 iter/s, 13.9121s/100 iter), loss = 1.43912
I0802 02:57:47.772568 12219 solver.cpp:375]     Train net output #0: loss = 1.21421 (* 1 = 1.21421 loss)
I0802 02:57:47.772572 12219 sgd_solver.cpp:136] Iteration 278500, lr = 0.0129687, m = 0.9
I0802 02:58:01.872881 12219 solver.cpp:353] Iteration 278600 (7.09222 iter/s, 14.1s/100 iter), loss = 1.1494
I0802 02:58:01.873004 12219 solver.cpp:375]     Train net output #0: loss = 1.09342 (* 1 = 1.09342 loss)
I0802 02:58:01.873023 12219 sgd_solver.cpp:136] Iteration 278600, lr = 0.0129375, m = 0.9
I0802 02:58:15.869999 12219 solver.cpp:353] Iteration 278700 (7.14452 iter/s, 13.9967s/100 iter), loss = 1.65356
I0802 02:58:15.870028 12219 solver.cpp:375]     Train net output #0: loss = 1.44799 (* 1 = 1.44799 loss)
I0802 02:58:15.870031 12219 sgd_solver.cpp:136] Iteration 278700, lr = 0.0129062, m = 0.9
I0802 02:58:29.818840 12219 solver.cpp:353] Iteration 278800 (7.16925 iter/s, 13.9485s/100 iter), loss = 1.6615
I0802 02:58:29.818866 12219 solver.cpp:375]     Train net output #0: loss = 1.77079 (* 1 = 1.77079 loss)
I0802 02:58:29.818869 12219 sgd_solver.cpp:136] Iteration 278800, lr = 0.012875, m = 0.9
I0802 02:58:43.931062 12219 solver.cpp:353] Iteration 278900 (7.08625 iter/s, 14.1118s/100 iter), loss = 1.41149
I0802 02:58:43.931129 12219 solver.cpp:375]     Train net output #0: loss = 1.25799 (* 1 = 1.25799 loss)
I0802 02:58:43.931134 12219 sgd_solver.cpp:136] Iteration 278900, lr = 0.0128438, m = 0.9
I0802 02:58:57.827651 12219 solver.cpp:353] Iteration 279000 (7.19621 iter/s, 13.8962s/100 iter), loss = 1.30679
I0802 02:58:57.827679 12219 solver.cpp:375]     Train net output #0: loss = 1.09387 (* 1 = 1.09387 loss)
I0802 02:58:57.827685 12219 sgd_solver.cpp:136] Iteration 279000, lr = 0.0128125, m = 0.9
I0802 02:59:11.940917 12219 solver.cpp:353] Iteration 279100 (7.08572 iter/s, 14.1129s/100 iter), loss = 1.68589
I0802 02:59:11.940946 12219 solver.cpp:375]     Train net output #0: loss = 1.52855 (* 1 = 1.52855 loss)
I0802 02:59:11.940953 12219 sgd_solver.cpp:136] Iteration 279100, lr = 0.0127813, m = 0.9
I0802 02:59:25.965554 12219 solver.cpp:353] Iteration 279200 (7.1305 iter/s, 14.0243s/100 iter), loss = 1.54658
I0802 02:59:25.965638 12219 solver.cpp:375]     Train net output #0: loss = 1.22169 (* 1 = 1.22169 loss)
I0802 02:59:25.965646 12219 sgd_solver.cpp:136] Iteration 279200, lr = 0.01275, m = 0.9
I0802 02:59:40.119431 12219 solver.cpp:353] Iteration 279300 (7.0654 iter/s, 14.1535s/100 iter), loss = 1.58435
I0802 02:59:40.119735 12219 solver.cpp:375]     Train net output #0: loss = 1.26507 (* 1 = 1.26507 loss)
I0802 02:59:40.119848 12219 sgd_solver.cpp:136] Iteration 279300, lr = 0.0127187, m = 0.9
I0802 02:59:54.107431 12219 solver.cpp:353] Iteration 279400 (7.14918 iter/s, 13.9876s/100 iter), loss = 1.58984
I0802 02:59:54.107463 12219 solver.cpp:375]     Train net output #0: loss = 1.4851 (* 1 = 1.4851 loss)
I0802 02:59:54.107471 12219 sgd_solver.cpp:136] Iteration 279400, lr = 0.0126875, m = 0.9
I0802 03:00:08.145467 12219 solver.cpp:353] Iteration 279500 (7.1237 iter/s, 14.0377s/100 iter), loss = 1.6107
I0802 03:00:08.145553 12219 solver.cpp:375]     Train net output #0: loss = 1.62455 (* 1 = 1.62455 loss)
I0802 03:00:08.145567 12219 sgd_solver.cpp:136] Iteration 279500, lr = 0.0126562, m = 0.9
I0802 03:00:22.129492 12219 solver.cpp:353] Iteration 279600 (7.15121 iter/s, 13.9836s/100 iter), loss = 1.66044
I0802 03:00:22.129516 12219 solver.cpp:375]     Train net output #0: loss = 1.67923 (* 1 = 1.67923 loss)
I0802 03:00:22.129523 12219 sgd_solver.cpp:136] Iteration 279600, lr = 0.012625, m = 0.9
I0802 03:00:36.197942 12219 solver.cpp:353] Iteration 279700 (7.1083 iter/s, 14.0681s/100 iter), loss = 1.97927
I0802 03:00:36.198016 12219 solver.cpp:375]     Train net output #0: loss = 1.71892 (* 1 = 1.71892 loss)
I0802 03:00:36.198031 12219 sgd_solver.cpp:136] Iteration 279700, lr = 0.0125938, m = 0.9
I0802 03:00:50.362246 12219 solver.cpp:353] Iteration 279800 (7.06019 iter/s, 14.1639s/100 iter), loss = 1.5127
I0802 03:00:50.362345 12219 solver.cpp:375]     Train net output #0: loss = 1.22566 (* 1 = 1.22566 loss)
I0802 03:00:50.362370 12219 sgd_solver.cpp:136] Iteration 279800, lr = 0.0125625, m = 0.9
I0802 03:01:04.441536 12219 solver.cpp:353] Iteration 279900 (7.10282 iter/s, 14.0789s/100 iter), loss = 1.39602
I0802 03:01:04.441561 12219 solver.cpp:375]     Train net output #0: loss = 1.50697 (* 1 = 1.50697 loss)
I0802 03:01:04.441565 12219 sgd_solver.cpp:136] Iteration 279900, lr = 0.0125313, m = 0.9
I0802 03:01:18.256463 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_280000.caffemodel
I0802 03:01:18.296418 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_280000.solverstate
I0802 03:01:18.301033 12219 solver.cpp:550] Iteration 280000, Testing net (#0)
I0802 03:01:38.733320 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.541471
I0802 03:01:38.733443 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.782351
I0802 03:01:38.733453 12219 solver.cpp:635]     Test net output #2: loss = 2.049 (* 1 = 2.049 loss)
I0802 03:01:38.733503 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.4319s
I0802 03:01:38.890617 12219 solver.cpp:353] Iteration 280000 (2.90291 iter/s, 34.4482s/100 iter), loss = 1.34487
I0802 03:01:38.890643 12219 solver.cpp:375]     Train net output #0: loss = 1.65705 (* 1 = 1.65705 loss)
I0802 03:01:38.890650 12219 sgd_solver.cpp:136] Iteration 280000, lr = 0.0125, m = 0.9
I0802 03:01:53.024399 12219 solver.cpp:353] Iteration 280100 (7.07544 iter/s, 14.1334s/100 iter), loss = 1.44591
I0802 03:01:53.024425 12219 solver.cpp:375]     Train net output #0: loss = 1.30843 (* 1 = 1.30843 loss)
I0802 03:01:53.024430 12219 sgd_solver.cpp:136] Iteration 280100, lr = 0.0124687, m = 0.9
I0802 03:02:07.071642 12219 solver.cpp:353] Iteration 280200 (7.11903 iter/s, 14.0469s/100 iter), loss = 1.75941
I0802 03:02:07.071669 12219 solver.cpp:375]     Train net output #0: loss = 1.83911 (* 1 = 1.83911 loss)
I0802 03:02:07.071676 12219 sgd_solver.cpp:136] Iteration 280200, lr = 0.0124375, m = 0.9
I0802 03:02:21.115329 12219 solver.cpp:353] Iteration 280300 (7.12083 iter/s, 14.0433s/100 iter), loss = 1.41589
I0802 03:02:21.120860 12219 solver.cpp:375]     Train net output #0: loss = 1.86537 (* 1 = 1.86537 loss)
I0802 03:02:21.120870 12219 sgd_solver.cpp:136] Iteration 280300, lr = 0.0124062, m = 0.9
I0802 03:02:35.142563 12219 solver.cpp:353] Iteration 280400 (7.12918 iter/s, 14.0269s/100 iter), loss = 1.24456
I0802 03:02:35.142590 12219 solver.cpp:375]     Train net output #0: loss = 1.37159 (* 1 = 1.37159 loss)
I0802 03:02:35.142632 12219 sgd_solver.cpp:136] Iteration 280400, lr = 0.012375, m = 0.9
I0802 03:02:49.251412 12219 solver.cpp:353] Iteration 280500 (7.08794 iter/s, 14.1085s/100 iter), loss = 1.5134
I0802 03:02:49.251442 12219 solver.cpp:375]     Train net output #0: loss = 1.82541 (* 1 = 1.82541 loss)
I0802 03:02:49.251448 12219 sgd_solver.cpp:136] Iteration 280500, lr = 0.0123438, m = 0.9
I0802 03:03:03.276474 12219 solver.cpp:353] Iteration 280600 (7.13028 iter/s, 14.0247s/100 iter), loss = 1.80528
I0802 03:03:03.276538 12219 solver.cpp:375]     Train net output #0: loss = 1.54799 (* 1 = 1.54799 loss)
I0802 03:03:03.276546 12219 sgd_solver.cpp:136] Iteration 280600, lr = 0.0123125, m = 0.9
I0802 03:03:17.362378 12219 solver.cpp:353] Iteration 280700 (7.09949 iter/s, 14.0855s/100 iter), loss = 1.66481
I0802 03:03:17.362437 12219 solver.cpp:375]     Train net output #0: loss = 1.71648 (* 1 = 1.71648 loss)
I0802 03:03:17.362450 12219 sgd_solver.cpp:136] Iteration 280700, lr = 0.0122813, m = 0.9
I0802 03:03:31.378463 12219 solver.cpp:353] Iteration 280800 (7.13485 iter/s, 14.0157s/100 iter), loss = 1.732
I0802 03:03:31.378527 12219 solver.cpp:375]     Train net output #0: loss = 1.79619 (* 1 = 1.79619 loss)
I0802 03:03:31.378541 12219 sgd_solver.cpp:136] Iteration 280800, lr = 0.01225, m = 0.9
I0802 03:03:45.334584 12219 solver.cpp:353] Iteration 280900 (7.16551 iter/s, 13.9557s/100 iter), loss = 1.38368
I0802 03:03:45.334650 12219 solver.cpp:375]     Train net output #0: loss = 1.22933 (* 1 = 1.22933 loss)
I0802 03:03:45.334657 12219 sgd_solver.cpp:136] Iteration 280900, lr = 0.0122188, m = 0.9
I0802 03:03:59.329807 12219 solver.cpp:353] Iteration 281000 (7.1455 iter/s, 13.9948s/100 iter), loss = 1.42496
I0802 03:03:59.329838 12219 solver.cpp:375]     Train net output #0: loss = 1.6919 (* 1 = 1.6919 loss)
I0802 03:03:59.329844 12219 sgd_solver.cpp:136] Iteration 281000, lr = 0.0121875, m = 0.9
I0802 03:04:13.494115 12219 solver.cpp:353] Iteration 281100 (7.06019 iter/s, 14.1639s/100 iter), loss = 1.45086
I0802 03:04:13.494151 12219 solver.cpp:375]     Train net output #0: loss = 1.49556 (* 1 = 1.49556 loss)
I0802 03:04:13.494158 12219 sgd_solver.cpp:136] Iteration 281100, lr = 0.0121562, m = 0.9
I0802 03:04:27.538969 12219 solver.cpp:353] Iteration 281200 (7.12024 iter/s, 14.0445s/100 iter), loss = 1.42741
I0802 03:04:27.539021 12219 solver.cpp:375]     Train net output #0: loss = 1.4768 (* 1 = 1.4768 loss)
I0802 03:04:27.539028 12219 sgd_solver.cpp:136] Iteration 281200, lr = 0.012125, m = 0.9
I0802 03:04:41.591451 12219 solver.cpp:353] Iteration 281300 (7.11637 iter/s, 14.0521s/100 iter), loss = 1.66092
I0802 03:04:41.591480 12219 solver.cpp:375]     Train net output #0: loss = 1.72658 (* 1 = 1.72658 loss)
I0802 03:04:41.591487 12219 sgd_solver.cpp:136] Iteration 281300, lr = 0.0120938, m = 0.9
I0802 03:04:55.667505 12219 solver.cpp:353] Iteration 281400 (7.10446 iter/s, 14.0757s/100 iter), loss = 1.74048
I0802 03:04:55.667551 12219 solver.cpp:375]     Train net output #0: loss = 1.6053 (* 1 = 1.6053 loss)
I0802 03:04:55.667562 12219 sgd_solver.cpp:136] Iteration 281400, lr = 0.0120625, m = 0.9
I0802 03:05:09.651438 12219 solver.cpp:353] Iteration 281500 (7.15125 iter/s, 13.9836s/100 iter), loss = 1.28576
I0802 03:05:09.651515 12219 solver.cpp:375]     Train net output #0: loss = 1.16717 (* 1 = 1.16717 loss)
I0802 03:05:09.651522 12219 sgd_solver.cpp:136] Iteration 281500, lr = 0.0120313, m = 0.9
I0802 03:05:23.661281 12219 solver.cpp:353] Iteration 281600 (7.13803 iter/s, 14.0095s/100 iter), loss = 1.44961
I0802 03:05:23.661314 12219 solver.cpp:375]     Train net output #0: loss = 1.34678 (* 1 = 1.34678 loss)
I0802 03:05:23.661320 12219 sgd_solver.cpp:136] Iteration 281600, lr = 0.012, m = 0.9
I0802 03:05:37.746794 12219 solver.cpp:353] Iteration 281700 (7.09968 iter/s, 14.0851s/100 iter), loss = 1.34075
I0802 03:05:37.746827 12219 solver.cpp:375]     Train net output #0: loss = 1.63757 (* 1 = 1.63757 loss)
I0802 03:05:37.746834 12219 sgd_solver.cpp:136] Iteration 281700, lr = 0.0119687, m = 0.9
I0802 03:05:51.638675 12219 solver.cpp:353] Iteration 281800 (7.19865 iter/s, 13.8915s/100 iter), loss = 1.2825
I0802 03:05:51.638736 12219 solver.cpp:375]     Train net output #0: loss = 1.39787 (* 1 = 1.39787 loss)
I0802 03:05:51.638741 12219 sgd_solver.cpp:136] Iteration 281800, lr = 0.0119375, m = 0.9
I0802 03:06:05.672479 12219 solver.cpp:353] Iteration 281900 (7.12584 iter/s, 14.0334s/100 iter), loss = 1.45175
I0802 03:06:05.672503 12219 solver.cpp:375]     Train net output #0: loss = 1.12552 (* 1 = 1.12552 loss)
I0802 03:06:05.672508 12219 sgd_solver.cpp:136] Iteration 281900, lr = 0.0119062, m = 0.9
I0802 03:06:19.656708 12219 solver.cpp:550] Iteration 282000, Testing net (#0)
I0802 03:06:39.517441 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.544882
I0802 03:06:39.517560 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786175
I0802 03:06:39.517570 12219 solver.cpp:635]     Test net output #2: loss = 1.99203 (* 1 = 1.99203 loss)
I0802 03:06:39.517588 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8604s
I0802 03:06:39.665148 12219 solver.cpp:353] Iteration 282000 (2.94189 iter/s, 33.9918s/100 iter), loss = 1.49834
I0802 03:06:39.665177 12219 solver.cpp:375]     Train net output #0: loss = 1.41765 (* 1 = 1.41765 loss)
I0802 03:06:39.665184 12219 sgd_solver.cpp:136] Iteration 282000, lr = 0.011875, m = 0.9
I0802 03:06:53.744477 12219 solver.cpp:353] Iteration 282100 (7.10281 iter/s, 14.0789s/100 iter), loss = 1.29843
I0802 03:06:53.744503 12219 solver.cpp:375]     Train net output #0: loss = 1.54826 (* 1 = 1.54826 loss)
I0802 03:06:53.744509 12219 sgd_solver.cpp:136] Iteration 282100, lr = 0.0118438, m = 0.9
I0802 03:07:07.732920 12219 solver.cpp:353] Iteration 282200 (7.14895 iter/s, 13.9881s/100 iter), loss = 1.94514
I0802 03:07:07.733152 12219 solver.cpp:375]     Train net output #0: loss = 1.96595 (* 1 = 1.96595 loss)
I0802 03:07:07.733269 12219 sgd_solver.cpp:136] Iteration 282200, lr = 0.0118125, m = 0.9
I0802 03:07:21.776273 12219 solver.cpp:353] Iteration 282300 (7.121 iter/s, 14.043s/100 iter), loss = 1.78835
I0802 03:07:21.776579 12219 solver.cpp:375]     Train net output #0: loss = 2.08897 (* 1 = 2.08897 loss)
I0802 03:07:21.776700 12219 sgd_solver.cpp:136] Iteration 282300, lr = 0.0117813, m = 0.9
I0802 03:07:35.831694 12219 solver.cpp:353] Iteration 282400 (7.11488 iter/s, 14.055s/100 iter), loss = 1.37034
I0802 03:07:35.831719 12219 solver.cpp:375]     Train net output #0: loss = 1.05562 (* 1 = 1.05562 loss)
I0802 03:07:35.831725 12219 sgd_solver.cpp:136] Iteration 282400, lr = 0.01175, m = 0.9
I0802 03:07:49.930021 12219 solver.cpp:353] Iteration 282500 (7.09323 iter/s, 14.0979s/100 iter), loss = 1.93602
I0802 03:07:49.930044 12219 solver.cpp:375]     Train net output #0: loss = 2.01016 (* 1 = 2.01016 loss)
I0802 03:07:49.930050 12219 sgd_solver.cpp:136] Iteration 282500, lr = 0.0117188, m = 0.9
I0802 03:08:04.115227 12219 solver.cpp:353] Iteration 282600 (7.04979 iter/s, 14.1848s/100 iter), loss = 1.54889
I0802 03:08:04.115306 12219 solver.cpp:375]     Train net output #0: loss = 1.82074 (* 1 = 1.82074 loss)
I0802 03:08:04.115314 12219 sgd_solver.cpp:136] Iteration 282600, lr = 0.0116875, m = 0.9
I0802 03:08:18.029821 12219 solver.cpp:353] Iteration 282700 (7.18689 iter/s, 13.9142s/100 iter), loss = 1.76144
I0802 03:08:18.029847 12219 solver.cpp:375]     Train net output #0: loss = 1.81734 (* 1 = 1.81734 loss)
I0802 03:08:18.029852 12219 sgd_solver.cpp:136] Iteration 282700, lr = 0.0116562, m = 0.9
I0802 03:08:32.065731 12219 solver.cpp:353] Iteration 282800 (7.12478 iter/s, 14.0355s/100 iter), loss = 1.22127
I0802 03:08:32.065757 12219 solver.cpp:375]     Train net output #0: loss = 1.28938 (* 1 = 1.28938 loss)
I0802 03:08:32.065762 12219 sgd_solver.cpp:136] Iteration 282800, lr = 0.011625, m = 0.9
I0802 03:08:46.257081 12219 solver.cpp:353] Iteration 282900 (7.04674 iter/s, 14.191s/100 iter), loss = 1.519
I0802 03:08:46.257146 12219 solver.cpp:375]     Train net output #0: loss = 1.35292 (* 1 = 1.35292 loss)
I0802 03:08:46.257153 12219 sgd_solver.cpp:136] Iteration 282900, lr = 0.0115937, m = 0.9
I0802 03:09:00.331077 12219 solver.cpp:353] Iteration 283000 (7.10549 iter/s, 14.0736s/100 iter), loss = 1.41979
I0802 03:09:00.331105 12219 solver.cpp:375]     Train net output #0: loss = 1.31373 (* 1 = 1.31373 loss)
I0802 03:09:00.331111 12219 sgd_solver.cpp:136] Iteration 283000, lr = 0.0115625, m = 0.9
I0802 03:09:14.390493 12219 solver.cpp:353] Iteration 283100 (7.11287 iter/s, 14.059s/100 iter), loss = 1.19974
I0802 03:09:14.390522 12219 solver.cpp:375]     Train net output #0: loss = 0.982572 (* 1 = 0.982572 loss)
I0802 03:09:14.390528 12219 sgd_solver.cpp:136] Iteration 283100, lr = 0.0115313, m = 0.9
I0802 03:09:28.369141 12219 solver.cpp:353] Iteration 283200 (7.15396 iter/s, 13.9783s/100 iter), loss = 1.31709
I0802 03:09:28.369204 12219 solver.cpp:375]     Train net output #0: loss = 1.51944 (* 1 = 1.51944 loss)
I0802 03:09:28.369211 12219 sgd_solver.cpp:136] Iteration 283200, lr = 0.0115, m = 0.9
I0802 03:09:42.451567 12219 solver.cpp:353] Iteration 283300 (7.10124 iter/s, 14.082s/100 iter), loss = 1.71839
I0802 03:09:42.451597 12219 solver.cpp:375]     Train net output #0: loss = 1.39142 (* 1 = 1.39142 loss)
I0802 03:09:42.451604 12219 sgd_solver.cpp:136] Iteration 283300, lr = 0.0114688, m = 0.9
I0802 03:09:56.502502 12219 solver.cpp:353] Iteration 283400 (7.11716 iter/s, 14.0506s/100 iter), loss = 1.62513
I0802 03:09:56.502527 12219 solver.cpp:375]     Train net output #0: loss = 1.65921 (* 1 = 1.65921 loss)
I0802 03:09:56.502533 12219 sgd_solver.cpp:136] Iteration 283400, lr = 0.0114375, m = 0.9
I0802 03:10:10.456295 12219 solver.cpp:353] Iteration 283500 (7.1667 iter/s, 13.9534s/100 iter), loss = 1.33792
I0802 03:10:10.456356 12219 solver.cpp:375]     Train net output #0: loss = 1.30003 (* 1 = 1.30003 loss)
I0802 03:10:10.456362 12219 sgd_solver.cpp:136] Iteration 283500, lr = 0.0114062, m = 0.9
I0802 03:10:24.503473 12219 solver.cpp:353] Iteration 283600 (7.11906 iter/s, 14.0468s/100 iter), loss = 1.45997
I0802 03:10:24.503500 12219 solver.cpp:375]     Train net output #0: loss = 1.37811 (* 1 = 1.37811 loss)
I0802 03:10:24.503506 12219 sgd_solver.cpp:136] Iteration 283600, lr = 0.011375, m = 0.9
I0802 03:10:38.419323 12219 solver.cpp:353] Iteration 283700 (7.18624 iter/s, 13.9155s/100 iter), loss = 1.33448
I0802 03:10:38.419353 12219 solver.cpp:375]     Train net output #0: loss = 1.07007 (* 1 = 1.07007 loss)
I0802 03:10:38.419358 12219 sgd_solver.cpp:136] Iteration 283700, lr = 0.0113437, m = 0.9
I0802 03:10:52.530704 12219 solver.cpp:353] Iteration 283800 (7.08667 iter/s, 14.111s/100 iter), loss = 1.37501
I0802 03:10:52.530830 12219 solver.cpp:375]     Train net output #0: loss = 1.36492 (* 1 = 1.36492 loss)
I0802 03:10:52.530839 12219 sgd_solver.cpp:136] Iteration 283800, lr = 0.0113125, m = 0.9
I0802 03:11:06.507063 12219 solver.cpp:353] Iteration 283900 (7.15513 iter/s, 13.976s/100 iter), loss = 1.48549
I0802 03:11:06.507089 12219 solver.cpp:375]     Train net output #0: loss = 1.3359 (* 1 = 1.3359 loss)
I0802 03:11:06.507093 12219 sgd_solver.cpp:136] Iteration 283900, lr = 0.0112813, m = 0.9
I0802 03:11:20.379490 12219 solver.cpp:550] Iteration 284000, Testing net (#0)
I0802 03:11:22.057936 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 03:11:23.800390 12207 data_reader.cpp:264] Starting prefetch of epoch 16
I0802 03:11:40.142280 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.548765
I0802 03:11:40.142302 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.789056
I0802 03:11:40.142307 12219 solver.cpp:635]     Test net output #2: loss = 1.96891 (* 1 = 1.96891 loss)
I0802 03:11:40.142326 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7623s
I0802 03:11:40.283349 12219 solver.cpp:353] Iteration 284000 (2.96074 iter/s, 33.7754s/100 iter), loss = 1.50236
I0802 03:11:40.283376 12219 solver.cpp:375]     Train net output #0: loss = 1.21613 (* 1 = 1.21613 loss)
I0802 03:11:40.283380 12219 sgd_solver.cpp:136] Iteration 284000, lr = 0.01125, m = 0.9
I0802 03:11:54.240311 12219 solver.cpp:353] Iteration 284100 (7.16509 iter/s, 13.9566s/100 iter), loss = 1.39415
I0802 03:11:54.240427 12219 solver.cpp:375]     Train net output #0: loss = 1.10815 (* 1 = 1.10815 loss)
I0802 03:11:54.240444 12219 sgd_solver.cpp:136] Iteration 284100, lr = 0.0112188, m = 0.9
I0802 03:12:08.216763 12219 solver.cpp:353] Iteration 284200 (7.15508 iter/s, 13.9761s/100 iter), loss = 1.50928
I0802 03:12:08.216790 12219 solver.cpp:375]     Train net output #0: loss = 1.45153 (* 1 = 1.45153 loss)
I0802 03:12:08.216796 12219 sgd_solver.cpp:136] Iteration 284200, lr = 0.0111875, m = 0.9
I0802 03:12:22.251693 12219 solver.cpp:353] Iteration 284300 (7.12527 iter/s, 14.0345s/100 iter), loss = 1.34428
I0802 03:12:22.251721 12219 solver.cpp:375]     Train net output #0: loss = 1.23433 (* 1 = 1.23433 loss)
I0802 03:12:22.251727 12219 sgd_solver.cpp:136] Iteration 284300, lr = 0.0111562, m = 0.9
I0802 03:12:36.181057 12219 solver.cpp:353] Iteration 284400 (7.17927 iter/s, 13.929s/100 iter), loss = 2.05735
I0802 03:12:36.181188 12219 solver.cpp:375]     Train net output #0: loss = 2.01082 (* 1 = 2.01082 loss)
I0802 03:12:36.181210 12219 sgd_solver.cpp:136] Iteration 284400, lr = 0.011125, m = 0.9
I0802 03:12:50.137224 12219 solver.cpp:353] Iteration 284500 (7.16548 iter/s, 13.9558s/100 iter), loss = 1.52541
I0802 03:12:50.137249 12219 solver.cpp:375]     Train net output #0: loss = 2.24 (* 1 = 2.24 loss)
I0802 03:12:50.137253 12219 sgd_solver.cpp:136] Iteration 284500, lr = 0.0110937, m = 0.9
I0802 03:13:04.037734 12219 solver.cpp:353] Iteration 284600 (7.19417 iter/s, 13.9001s/100 iter), loss = 1.5888
I0802 03:13:04.037762 12219 solver.cpp:375]     Train net output #0: loss = 1.7989 (* 1 = 1.7989 loss)
I0802 03:13:04.037768 12219 sgd_solver.cpp:136] Iteration 284600, lr = 0.0110625, m = 0.9
I0802 03:13:18.012400 12219 solver.cpp:353] Iteration 284700 (7.156 iter/s, 13.9743s/100 iter), loss = 1.17877
I0802 03:13:18.012490 12219 solver.cpp:375]     Train net output #0: loss = 1.16775 (* 1 = 1.16775 loss)
I0802 03:13:18.012497 12219 sgd_solver.cpp:136] Iteration 284700, lr = 0.0110313, m = 0.9
I0802 03:13:32.038980 12219 solver.cpp:353] Iteration 284800 (7.12951 iter/s, 14.0262s/100 iter), loss = 1.29876
I0802 03:13:32.039244 12219 solver.cpp:375]     Train net output #0: loss = 1.48506 (* 1 = 1.48506 loss)
I0802 03:13:32.039363 12219 sgd_solver.cpp:136] Iteration 284800, lr = 0.011, m = 0.9
I0802 03:13:46.231614 12219 solver.cpp:353] Iteration 284900 (7.0461 iter/s, 14.1923s/100 iter), loss = 1.89261
I0802 03:13:46.231639 12219 solver.cpp:375]     Train net output #0: loss = 2.28388 (* 1 = 2.28388 loss)
I0802 03:13:46.231645 12219 sgd_solver.cpp:136] Iteration 284900, lr = 0.0109688, m = 0.9
I0802 03:14:00.224131 12219 solver.cpp:353] Iteration 285000 (7.14687 iter/s, 13.9921s/100 iter), loss = 1.80524
I0802 03:14:00.224258 12219 solver.cpp:375]     Train net output #0: loss = 1.73227 (* 1 = 1.73227 loss)
I0802 03:14:00.224274 12219 sgd_solver.cpp:136] Iteration 285000, lr = 0.0109375, m = 0.9
I0802 03:14:14.247050 12219 solver.cpp:353] Iteration 285100 (7.13137 iter/s, 14.0225s/100 iter), loss = 1.5295
I0802 03:14:14.247292 12219 solver.cpp:375]     Train net output #0: loss = 1.77724 (* 1 = 1.77724 loss)
I0802 03:14:14.247390 12219 sgd_solver.cpp:136] Iteration 285100, lr = 0.0109062, m = 0.9
I0802 03:14:28.322429 12219 solver.cpp:353] Iteration 285200 (7.10479 iter/s, 14.075s/100 iter), loss = 1.59289
I0802 03:14:28.322455 12219 solver.cpp:375]     Train net output #0: loss = 1.3829 (* 1 = 1.3829 loss)
I0802 03:14:28.322460 12219 sgd_solver.cpp:136] Iteration 285200, lr = 0.010875, m = 0.9
I0802 03:14:42.403525 12219 solver.cpp:353] Iteration 285300 (7.10191 iter/s, 14.0807s/100 iter), loss = 1.59569
I0802 03:14:42.403587 12219 solver.cpp:375]     Train net output #0: loss = 1.26705 (* 1 = 1.26705 loss)
I0802 03:14:42.403594 12219 sgd_solver.cpp:136] Iteration 285300, lr = 0.0108437, m = 0.9
I0802 03:14:56.478657 12219 solver.cpp:353] Iteration 285400 (7.10492 iter/s, 14.0748s/100 iter), loss = 1.29764
I0802 03:14:56.478682 12219 solver.cpp:375]     Train net output #0: loss = 1.66919 (* 1 = 1.66919 loss)
I0802 03:14:56.478688 12219 sgd_solver.cpp:136] Iteration 285400, lr = 0.0108125, m = 0.9
I0802 03:15:10.518950 12219 solver.cpp:353] Iteration 285500 (7.12255 iter/s, 14.0399s/100 iter), loss = 1.47183
I0802 03:15:10.518975 12219 solver.cpp:375]     Train net output #0: loss = 1.64613 (* 1 = 1.64613 loss)
I0802 03:15:10.518980 12219 sgd_solver.cpp:136] Iteration 285500, lr = 0.0107813, m = 0.9
I0802 03:15:24.562584 12219 solver.cpp:353] Iteration 285600 (7.12086 iter/s, 14.0433s/100 iter), loss = 1.83648
I0802 03:15:24.562700 12219 solver.cpp:375]     Train net output #0: loss = 1.47379 (* 1 = 1.47379 loss)
I0802 03:15:24.562721 12219 sgd_solver.cpp:136] Iteration 285600, lr = 0.01075, m = 0.9
I0802 03:15:38.775202 12219 solver.cpp:353] Iteration 285700 (7.03619 iter/s, 14.2122s/100 iter), loss = 1.73537
I0802 03:15:38.775230 12219 solver.cpp:375]     Train net output #0: loss = 1.8708 (* 1 = 1.8708 loss)
I0802 03:15:38.775236 12219 sgd_solver.cpp:136] Iteration 285700, lr = 0.0107188, m = 0.9
I0802 03:15:52.803635 12219 solver.cpp:353] Iteration 285800 (7.12857 iter/s, 14.0281s/100 iter), loss = 1.39237
I0802 03:15:52.803660 12219 solver.cpp:375]     Train net output #0: loss = 1.53925 (* 1 = 1.53925 loss)
I0802 03:15:52.803664 12219 sgd_solver.cpp:136] Iteration 285800, lr = 0.0106875, m = 0.9
I0802 03:16:06.868415 12219 solver.cpp:353] Iteration 285900 (7.11015 iter/s, 14.0644s/100 iter), loss = 1.40075
I0802 03:16:06.868863 12219 solver.cpp:375]     Train net output #0: loss = 1.13943 (* 1 = 1.13943 loss)
I0802 03:16:06.868871 12219 sgd_solver.cpp:136] Iteration 285900, lr = 0.0106562, m = 0.9
I0802 03:16:20.668992 12219 solver.cpp:550] Iteration 286000, Testing net (#0)
I0802 03:16:40.459743 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.551294
I0802 03:16:40.459794 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.793233
I0802 03:16:40.459800 12219 solver.cpp:635]     Test net output #2: loss = 1.96198 (* 1 = 1.96198 loss)
I0802 03:16:40.459820 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.7903s
I0802 03:16:40.597043 12219 solver.cpp:353] Iteration 286000 (2.96492 iter/s, 33.7277s/100 iter), loss = 1.2991
I0802 03:16:40.597072 12219 solver.cpp:375]     Train net output #0: loss = 0.878724 (* 1 = 0.878724 loss)
I0802 03:16:40.597079 12219 sgd_solver.cpp:136] Iteration 286000, lr = 0.010625, m = 0.9
I0802 03:16:54.707429 12219 solver.cpp:353] Iteration 286100 (7.08717 iter/s, 14.11s/100 iter), loss = 1.27329
I0802 03:16:54.707458 12219 solver.cpp:375]     Train net output #0: loss = 1.08087 (* 1 = 1.08087 loss)
I0802 03:16:54.707464 12219 sgd_solver.cpp:136] Iteration 286100, lr = 0.0105937, m = 0.9
I0802 03:17:08.795799 12219 solver.cpp:353] Iteration 286200 (7.09825 iter/s, 14.088s/100 iter), loss = 1.30048
I0802 03:17:08.795826 12219 solver.cpp:375]     Train net output #0: loss = 1.48725 (* 1 = 1.48725 loss)
I0802 03:17:08.795830 12219 sgd_solver.cpp:136] Iteration 286200, lr = 0.0105625, m = 0.9
I0802 03:17:22.910419 12219 solver.cpp:353] Iteration 286300 (7.08504 iter/s, 14.1142s/100 iter), loss = 1.25442
I0802 03:17:22.910508 12219 solver.cpp:375]     Train net output #0: loss = 1.43012 (* 1 = 1.43012 loss)
I0802 03:17:22.910521 12219 sgd_solver.cpp:136] Iteration 286300, lr = 0.0105313, m = 0.9
I0802 03:17:36.822530 12219 solver.cpp:353] Iteration 286400 (7.18818 iter/s, 13.9117s/100 iter), loss = 1.33838
I0802 03:17:36.822558 12219 solver.cpp:375]     Train net output #0: loss = 1.17368 (* 1 = 1.17368 loss)
I0802 03:17:36.822566 12219 sgd_solver.cpp:136] Iteration 286400, lr = 0.0105, m = 0.9
I0802 03:17:50.767784 12219 solver.cpp:353] Iteration 286500 (7.17109 iter/s, 13.9449s/100 iter), loss = 1.56387
I0802 03:17:50.767814 12219 solver.cpp:375]     Train net output #0: loss = 1.48098 (* 1 = 1.48098 loss)
I0802 03:17:50.767822 12219 sgd_solver.cpp:136] Iteration 286500, lr = 0.0104688, m = 0.9
I0802 03:18:04.833991 12219 solver.cpp:353] Iteration 286600 (7.10943 iter/s, 14.0658s/100 iter), loss = 1.17793
I0802 03:18:04.834056 12219 solver.cpp:375]     Train net output #0: loss = 1.34598 (* 1 = 1.34598 loss)
I0802 03:18:04.834064 12219 sgd_solver.cpp:136] Iteration 286600, lr = 0.0104375, m = 0.9
I0802 03:18:18.976927 12219 solver.cpp:353] Iteration 286700 (7.07086 iter/s, 14.1426s/100 iter), loss = 1.31011
I0802 03:18:18.976951 12219 solver.cpp:375]     Train net output #0: loss = 1.39824 (* 1 = 1.39824 loss)
I0802 03:18:18.976955 12219 sgd_solver.cpp:136] Iteration 286700, lr = 0.0104063, m = 0.9
I0802 03:18:32.987869 12219 solver.cpp:353] Iteration 286800 (7.13747 iter/s, 14.0106s/100 iter), loss = 1.8306
I0802 03:18:32.987896 12219 solver.cpp:375]     Train net output #0: loss = 1.88274 (* 1 = 1.88274 loss)
I0802 03:18:32.987901 12219 sgd_solver.cpp:136] Iteration 286800, lr = 0.010375, m = 0.9
I0802 03:18:47.024376 12219 solver.cpp:353] Iteration 286900 (7.12447 iter/s, 14.0361s/100 iter), loss = 1.55816
I0802 03:18:47.024437 12219 solver.cpp:375]     Train net output #0: loss = 1.57098 (* 1 = 1.57098 loss)
I0802 03:18:47.024442 12219 sgd_solver.cpp:136] Iteration 286900, lr = 0.0103437, m = 0.9
I0802 03:19:00.997990 12219 solver.cpp:353] Iteration 287000 (7.15654 iter/s, 13.9732s/100 iter), loss = 1.79979
I0802 03:19:00.998014 12219 solver.cpp:375]     Train net output #0: loss = 1.65153 (* 1 = 1.65153 loss)
I0802 03:19:00.998018 12219 sgd_solver.cpp:136] Iteration 287000, lr = 0.0103125, m = 0.9
I0802 03:19:15.199486 12219 solver.cpp:353] Iteration 287100 (7.0417 iter/s, 14.2011s/100 iter), loss = 1.19982
I0802 03:19:15.199511 12219 solver.cpp:375]     Train net output #0: loss = 1.2309 (* 1 = 1.2309 loss)
I0802 03:19:15.199514 12219 sgd_solver.cpp:136] Iteration 287100, lr = 0.0102813, m = 0.9
I0802 03:19:29.305449 12219 solver.cpp:353] Iteration 287200 (7.08939 iter/s, 14.1056s/100 iter), loss = 1.02243
I0802 03:19:29.305544 12219 solver.cpp:375]     Train net output #0: loss = 1.06543 (* 1 = 1.06543 loss)
I0802 03:19:29.305552 12219 sgd_solver.cpp:136] Iteration 287200, lr = 0.01025, m = 0.9
I0802 03:19:43.387658 12219 solver.cpp:353] Iteration 287300 (7.10135 iter/s, 14.0818s/100 iter), loss = 1.54904
I0802 03:19:43.387683 12219 solver.cpp:375]     Train net output #0: loss = 1.58168 (* 1 = 1.58168 loss)
I0802 03:19:43.387687 12219 sgd_solver.cpp:136] Iteration 287300, lr = 0.0102188, m = 0.9
I0802 03:19:57.367511 12219 solver.cpp:353] Iteration 287400 (7.15335 iter/s, 13.9795s/100 iter), loss = 1.85099
I0802 03:19:57.367549 12219 solver.cpp:375]     Train net output #0: loss = 1.86818 (* 1 = 1.86818 loss)
I0802 03:19:57.367555 12219 sgd_solver.cpp:136] Iteration 287400, lr = 0.0101875, m = 0.9
I0802 03:20:11.494122 12219 solver.cpp:353] Iteration 287500 (7.07903 iter/s, 14.1262s/100 iter), loss = 1.90924
I0802 03:20:11.494833 12219 solver.cpp:375]     Train net output #0: loss = 1.82482 (* 1 = 1.82482 loss)
I0802 03:20:11.494841 12219 sgd_solver.cpp:136] Iteration 287500, lr = 0.0101563, m = 0.9
I0802 03:20:25.586599 12219 solver.cpp:353] Iteration 287600 (7.09618 iter/s, 14.0921s/100 iter), loss = 1.77755
I0802 03:20:25.586635 12219 solver.cpp:375]     Train net output #0: loss = 2.3293 (* 1 = 2.3293 loss)
I0802 03:20:25.586639 12219 sgd_solver.cpp:136] Iteration 287600, lr = 0.010125, m = 0.9
I0802 03:20:39.694854 12219 solver.cpp:353] Iteration 287700 (7.08825 iter/s, 14.1079s/100 iter), loss = 1.43957
I0802 03:20:39.694880 12219 solver.cpp:375]     Train net output #0: loss = 1.27435 (* 1 = 1.27435 loss)
I0802 03:20:39.694886 12219 sgd_solver.cpp:136] Iteration 287700, lr = 0.0100937, m = 0.9
I0802 03:20:53.782135 12219 solver.cpp:353] Iteration 287800 (7.09879 iter/s, 14.0869s/100 iter), loss = 1.64339
I0802 03:20:53.782209 12219 solver.cpp:375]     Train net output #0: loss = 1.78328 (* 1 = 1.78328 loss)
I0802 03:20:53.782215 12219 sgd_solver.cpp:136] Iteration 287800, lr = 0.0100625, m = 0.9
I0802 03:21:07.714239 12219 solver.cpp:353] Iteration 287900 (7.17786 iter/s, 13.9317s/100 iter), loss = 1.42536
I0802 03:21:07.714267 12219 solver.cpp:375]     Train net output #0: loss = 1.56439 (* 1 = 1.56439 loss)
I0802 03:21:07.714272 12219 sgd_solver.cpp:136] Iteration 287900, lr = 0.0100312, m = 0.9
I0802 03:21:21.563176 12219 solver.cpp:550] Iteration 288000, Testing net (#0)
I0802 03:21:41.895553 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.556941
I0802 03:21:41.895607 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.792646
I0802 03:21:41.895613 12219 solver.cpp:635]     Test net output #2: loss = 1.9376 (* 1 = 1.9376 loss)
I0802 03:21:41.895632 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3319s
I0802 03:21:42.057154 12219 solver.cpp:353] Iteration 288000 (2.91189 iter/s, 34.342s/100 iter), loss = 1.49755
I0802 03:21:42.057181 12219 solver.cpp:375]     Train net output #0: loss = 1.50822 (* 1 = 1.50822 loss)
I0802 03:21:42.057188 12219 sgd_solver.cpp:136] Iteration 288000, lr = 0.01, m = 0.9
I0802 03:21:56.123746 12219 solver.cpp:353] Iteration 288100 (7.10924 iter/s, 14.0662s/100 iter), loss = 1.67135
I0802 03:21:56.123777 12219 solver.cpp:375]     Train net output #0: loss = 1.83726 (* 1 = 1.83726 loss)
I0802 03:21:56.123785 12219 sgd_solver.cpp:136] Iteration 288100, lr = 0.00996875, m = 0.9
I0802 03:22:10.205421 12219 solver.cpp:353] Iteration 288200 (7.10162 iter/s, 14.0813s/100 iter), loss = 1.35252
I0802 03:22:10.205446 12219 solver.cpp:375]     Train net output #0: loss = 1.18425 (* 1 = 1.18425 loss)
I0802 03:22:10.205451 12219 sgd_solver.cpp:136] Iteration 288200, lr = 0.0099375, m = 0.9
I0802 03:22:24.189076 12219 solver.cpp:353] Iteration 288300 (7.1514 iter/s, 13.9833s/100 iter), loss = 1.80729
I0802 03:22:24.189141 12219 solver.cpp:375]     Train net output #0: loss = 1.44105 (* 1 = 1.44105 loss)
I0802 03:22:24.189148 12219 sgd_solver.cpp:136] Iteration 288300, lr = 0.00990625, m = 0.9
I0802 03:22:38.242862 12219 solver.cpp:353] Iteration 288400 (7.11571 iter/s, 14.0534s/100 iter), loss = 1.93093
I0802 03:22:38.242888 12219 solver.cpp:375]     Train net output #0: loss = 1.94623 (* 1 = 1.94623 loss)
I0802 03:22:38.242894 12219 sgd_solver.cpp:136] Iteration 288400, lr = 0.009875, m = 0.9
I0802 03:22:52.385721 12219 solver.cpp:353] Iteration 288500 (7.0709 iter/s, 14.1425s/100 iter), loss = 1.6287
I0802 03:22:52.385748 12219 solver.cpp:375]     Train net output #0: loss = 1.49199 (* 1 = 1.49199 loss)
I0802 03:22:52.385752 12219 sgd_solver.cpp:136] Iteration 288500, lr = 0.00984375, m = 0.9
I0802 03:23:06.545200 12219 solver.cpp:353] Iteration 288600 (7.0626 iter/s, 14.1591s/100 iter), loss = 1.41753
I0802 03:23:06.545266 12219 solver.cpp:375]     Train net output #0: loss = 1.49192 (* 1 = 1.49192 loss)
I0802 03:23:06.545271 12219 sgd_solver.cpp:136] Iteration 288600, lr = 0.0098125, m = 0.9
I0802 03:23:20.457249 12219 solver.cpp:353] Iteration 288700 (7.18821 iter/s, 13.9117s/100 iter), loss = 1.29788
I0802 03:23:20.457279 12219 solver.cpp:375]     Train net output #0: loss = 1.04468 (* 1 = 1.04468 loss)
I0802 03:23:20.457284 12219 sgd_solver.cpp:136] Iteration 288700, lr = 0.00978125, m = 0.9
I0802 03:23:34.481818 12219 solver.cpp:353] Iteration 288800 (7.13054 iter/s, 14.0242s/100 iter), loss = 1.37613
I0802 03:23:34.481845 12219 solver.cpp:375]     Train net output #0: loss = 1.32739 (* 1 = 1.32739 loss)
I0802 03:23:34.481849 12219 sgd_solver.cpp:136] Iteration 288800, lr = 0.00975, m = 0.9
I0802 03:23:48.620894 12219 solver.cpp:353] Iteration 288900 (7.07279 iter/s, 14.1387s/100 iter), loss = 1.58249
I0802 03:23:48.621013 12219 solver.cpp:375]     Train net output #0: loss = 1.77511 (* 1 = 1.77511 loss)
I0802 03:23:48.621034 12219 sgd_solver.cpp:136] Iteration 288900, lr = 0.00971875, m = 0.9
I0802 03:24:02.620492 12219 solver.cpp:353] Iteration 289000 (7.14326 iter/s, 13.9992s/100 iter), loss = 1.40893
I0802 03:24:02.620517 12219 solver.cpp:375]     Train net output #0: loss = 1.54822 (* 1 = 1.54822 loss)
I0802 03:24:02.620523 12219 sgd_solver.cpp:136] Iteration 289000, lr = 0.0096875, m = 0.9
I0802 03:24:16.620812 12219 solver.cpp:353] Iteration 289100 (7.14289 iter/s, 13.9999s/100 iter), loss = 1.65097
I0802 03:24:16.620842 12219 solver.cpp:375]     Train net output #0: loss = 1.96593 (* 1 = 1.96593 loss)
I0802 03:24:16.620848 12219 sgd_solver.cpp:136] Iteration 289100, lr = 0.00965625, m = 0.9
I0802 03:24:30.569864 12219 solver.cpp:353] Iteration 289200 (7.16914 iter/s, 13.9487s/100 iter), loss = 1.50415
I0802 03:24:30.569996 12219 solver.cpp:375]     Train net output #0: loss = 1.6987 (* 1 = 1.6987 loss)
I0802 03:24:30.570019 12219 sgd_solver.cpp:136] Iteration 289200, lr = 0.009625, m = 0.9
I0802 03:24:44.560904 12219 solver.cpp:353] Iteration 289300 (7.14762 iter/s, 13.9907s/100 iter), loss = 1.1831
I0802 03:24:44.560932 12219 solver.cpp:375]     Train net output #0: loss = 1.18588 (* 1 = 1.18588 loss)
I0802 03:24:44.560938 12219 sgd_solver.cpp:136] Iteration 289300, lr = 0.00959375, m = 0.9
I0802 03:24:58.599628 12219 solver.cpp:353] Iteration 289400 (7.12335 iter/s, 14.0383s/100 iter), loss = 1.72367
I0802 03:24:58.599656 12219 solver.cpp:375]     Train net output #0: loss = 1.61252 (* 1 = 1.61252 loss)
I0802 03:24:58.599663 12219 sgd_solver.cpp:136] Iteration 289400, lr = 0.0095625, m = 0.9
I0802 03:25:12.709870 12219 solver.cpp:353] Iteration 289500 (7.08724 iter/s, 14.1099s/100 iter), loss = 1.72299
I0802 03:25:12.709951 12219 solver.cpp:375]     Train net output #0: loss = 1.56599 (* 1 = 1.56599 loss)
I0802 03:25:12.709959 12219 sgd_solver.cpp:136] Iteration 289500, lr = 0.00953125, m = 0.9
I0802 03:25:26.761737 12219 solver.cpp:353] Iteration 289600 (7.11668 iter/s, 14.0515s/100 iter), loss = 1.45769
I0802 03:25:26.761762 12219 solver.cpp:375]     Train net output #0: loss = 1.27534 (* 1 = 1.27534 loss)
I0802 03:25:26.761766 12219 sgd_solver.cpp:136] Iteration 289600, lr = 0.0095, m = 0.9
I0802 03:25:40.733167 12219 solver.cpp:353] Iteration 289700 (7.15766 iter/s, 13.9711s/100 iter), loss = 1.31719
I0802 03:25:40.733220 12219 solver.cpp:375]     Train net output #0: loss = 1.01039 (* 1 = 1.01039 loss)
I0802 03:25:40.733233 12219 sgd_solver.cpp:136] Iteration 289700, lr = 0.00946875, m = 0.9
I0802 03:25:54.669123 12219 solver.cpp:353] Iteration 289800 (7.17587 iter/s, 13.9356s/100 iter), loss = 1.8007
I0802 03:25:54.669193 12219 solver.cpp:375]     Train net output #0: loss = 2.24034 (* 1 = 2.24034 loss)
I0802 03:25:54.669200 12219 sgd_solver.cpp:136] Iteration 289800, lr = 0.0094375, m = 0.9
I0802 03:26:08.661372 12219 solver.cpp:353] Iteration 289900 (7.14701 iter/s, 13.9919s/100 iter), loss = 1.50269
I0802 03:26:08.661399 12219 solver.cpp:375]     Train net output #0: loss = 1.58929 (* 1 = 1.58929 loss)
I0802 03:26:08.661403 12219 sgd_solver.cpp:136] Iteration 289900, lr = 0.00940625, m = 0.9
I0802 03:26:22.493808 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_290000.caffemodel
I0802 03:26:22.553016 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_290000.solverstate
I0802 03:26:22.558257 12219 solver.cpp:550] Iteration 290000, Testing net (#0)
I0802 03:26:26.412878 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 03:26:42.699187 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.564294
I0802 03:26:42.699218 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.799115
I0802 03:26:42.699224 12219 solver.cpp:635]     Test net output #2: loss = 1.90299 (* 1 = 1.90299 loss)
I0802 03:26:42.699344 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.1406s
I0802 03:26:42.839007 12219 solver.cpp:353] Iteration 290000 (2.92597 iter/s, 34.1767s/100 iter), loss = 1.55831
I0802 03:26:42.839045 12219 solver.cpp:375]     Train net output #0: loss = 1.79684 (* 1 = 1.79684 loss)
I0802 03:26:42.839051 12219 sgd_solver.cpp:136] Iteration 290000, lr = 0.009375, m = 0.9
I0802 03:26:56.807981 12219 solver.cpp:353] Iteration 290100 (7.15892 iter/s, 13.9686s/100 iter), loss = 1.58294
I0802 03:26:56.808239 12219 solver.cpp:375]     Train net output #0: loss = 1.93329 (* 1 = 1.93329 loss)
I0802 03:26:56.808348 12219 sgd_solver.cpp:136] Iteration 290100, lr = 0.00934375, m = 0.9
I0802 03:27:10.725087 12219 solver.cpp:353] Iteration 290200 (7.1856 iter/s, 13.9167s/100 iter), loss = 1.42369
I0802 03:27:10.725116 12219 solver.cpp:375]     Train net output #0: loss = 1.40259 (* 1 = 1.40259 loss)
I0802 03:27:10.725119 12219 sgd_solver.cpp:136] Iteration 290200, lr = 0.0093125, m = 0.9
I0802 03:27:24.698479 12219 solver.cpp:353] Iteration 290300 (7.15665 iter/s, 13.973s/100 iter), loss = 1.51728
I0802 03:27:24.698530 12219 solver.cpp:375]     Train net output #0: loss = 1.53755 (* 1 = 1.53755 loss)
I0802 03:27:24.698544 12219 sgd_solver.cpp:136] Iteration 290300, lr = 0.00928125, m = 0.9
I0802 03:27:38.684526 12219 solver.cpp:353] Iteration 290400 (7.15018 iter/s, 13.9857s/100 iter), loss = 1.48788
I0802 03:27:38.684586 12219 solver.cpp:375]     Train net output #0: loss = 1.6212 (* 1 = 1.6212 loss)
I0802 03:27:38.684590 12219 sgd_solver.cpp:136] Iteration 290400, lr = 0.00925, m = 0.9
I0802 03:27:52.619882 12219 solver.cpp:353] Iteration 290500 (7.17618 iter/s, 13.935s/100 iter), loss = 1.52093
I0802 03:27:52.619909 12219 solver.cpp:375]     Train net output #0: loss = 1.48681 (* 1 = 1.48681 loss)
I0802 03:27:52.619913 12219 sgd_solver.cpp:136] Iteration 290500, lr = 0.00921875, m = 0.9
I0802 03:28:06.449542 12219 solver.cpp:353] Iteration 290600 (7.23103 iter/s, 13.8293s/100 iter), loss = 1.45673
I0802 03:28:06.449573 12219 solver.cpp:375]     Train net output #0: loss = 1.37918 (* 1 = 1.37918 loss)
I0802 03:28:06.449579 12219 sgd_solver.cpp:136] Iteration 290600, lr = 0.0091875, m = 0.9
I0802 03:28:20.465101 12219 solver.cpp:353] Iteration 290700 (7.13512 iter/s, 14.0152s/100 iter), loss = 1.40405
I0802 03:28:20.465152 12219 solver.cpp:375]     Train net output #0: loss = 1.37759 (* 1 = 1.37759 loss)
I0802 03:28:20.465158 12219 sgd_solver.cpp:136] Iteration 290700, lr = 0.00915625, m = 0.9
I0802 03:28:34.545739 12219 solver.cpp:353] Iteration 290800 (7.10214 iter/s, 14.0803s/100 iter), loss = 1.18842
I0802 03:28:34.545764 12219 solver.cpp:375]     Train net output #0: loss = 1.3311 (* 1 = 1.3311 loss)
I0802 03:28:34.545768 12219 sgd_solver.cpp:136] Iteration 290800, lr = 0.009125, m = 0.9
I0802 03:28:48.585330 12219 solver.cpp:353] Iteration 290900 (7.12292 iter/s, 14.0392s/100 iter), loss = 1.31167
I0802 03:28:48.585360 12219 solver.cpp:375]     Train net output #0: loss = 1.48243 (* 1 = 1.48243 loss)
I0802 03:28:48.585366 12219 sgd_solver.cpp:136] Iteration 290900, lr = 0.00909375, m = 0.9
I0802 03:29:02.629029 12219 solver.cpp:353] Iteration 291000 (7.12082 iter/s, 14.0433s/100 iter), loss = 1.2129
I0802 03:29:02.629098 12219 solver.cpp:375]     Train net output #0: loss = 1.22303 (* 1 = 1.22303 loss)
I0802 03:29:02.629106 12219 sgd_solver.cpp:136] Iteration 291000, lr = 0.0090625, m = 0.9
I0802 03:29:16.649339 12219 solver.cpp:353] Iteration 291100 (7.13271 iter/s, 14.0199s/100 iter), loss = 1.6043
I0802 03:29:16.649369 12219 solver.cpp:375]     Train net output #0: loss = 1.6612 (* 1 = 1.6612 loss)
I0802 03:29:16.649375 12219 sgd_solver.cpp:136] Iteration 291100, lr = 0.00903125, m = 0.9
I0802 03:29:30.669028 12219 solver.cpp:353] Iteration 291200 (7.13302 iter/s, 14.0193s/100 iter), loss = 1.50222
I0802 03:29:30.669052 12219 solver.cpp:375]     Train net output #0: loss = 1.33596 (* 1 = 1.33596 loss)
I0802 03:29:30.669057 12219 sgd_solver.cpp:136] Iteration 291200, lr = 0.009, m = 0.9
I0802 03:29:44.748872 12219 solver.cpp:353] Iteration 291300 (7.10254 iter/s, 14.0795s/100 iter), loss = 1.76891
I0802 03:29:44.748955 12219 solver.cpp:375]     Train net output #0: loss = 1.9975 (* 1 = 1.9975 loss)
I0802 03:29:44.748962 12219 sgd_solver.cpp:136] Iteration 291300, lr = 0.00896875, m = 0.9
I0802 03:29:58.825659 12219 solver.cpp:353] Iteration 291400 (7.10408 iter/s, 14.0764s/100 iter), loss = 1.1666
I0802 03:29:58.825752 12219 solver.cpp:375]     Train net output #0: loss = 1.21232 (* 1 = 1.21232 loss)
I0802 03:29:58.825772 12219 sgd_solver.cpp:136] Iteration 291400, lr = 0.0089375, m = 0.9
I0802 03:30:12.860713 12219 solver.cpp:353] Iteration 291500 (7.12521 iter/s, 14.0347s/100 iter), loss = 1.52903
I0802 03:30:12.860743 12219 solver.cpp:375]     Train net output #0: loss = 1.91104 (* 1 = 1.91104 loss)
I0802 03:30:12.860749 12219 sgd_solver.cpp:136] Iteration 291500, lr = 0.00890625, m = 0.9
I0802 03:30:26.840729 12219 solver.cpp:353] Iteration 291600 (7.15326 iter/s, 13.9796s/100 iter), loss = 1.31815
I0802 03:30:26.840803 12219 solver.cpp:375]     Train net output #0: loss = 1.24466 (* 1 = 1.24466 loss)
I0802 03:30:26.840809 12219 sgd_solver.cpp:136] Iteration 291600, lr = 0.008875, m = 0.9
I0802 03:30:40.806557 12219 solver.cpp:353] Iteration 291700 (7.16053 iter/s, 13.9655s/100 iter), loss = 1.14788
I0802 03:30:40.806584 12219 solver.cpp:375]     Train net output #0: loss = 1.30248 (* 1 = 1.30248 loss)
I0802 03:30:40.806591 12219 sgd_solver.cpp:136] Iteration 291700, lr = 0.00884375, m = 0.9
I0802 03:30:54.913951 12219 solver.cpp:353] Iteration 291800 (7.08868 iter/s, 14.107s/100 iter), loss = 1.2798
I0802 03:30:54.913981 12219 solver.cpp:375]     Train net output #0: loss = 1.41039 (* 1 = 1.41039 loss)
I0802 03:30:54.913988 12219 sgd_solver.cpp:136] Iteration 291800, lr = 0.0088125, m = 0.9
I0802 03:31:08.917946 12219 solver.cpp:353] Iteration 291900 (7.14101 iter/s, 14.0036s/100 iter), loss = 1.70641
I0802 03:31:08.918041 12219 solver.cpp:375]     Train net output #0: loss = 1.54816 (* 1 = 1.54816 loss)
I0802 03:31:08.918061 12219 sgd_solver.cpp:136] Iteration 291900, lr = 0.00878125, m = 0.9
I0802 03:31:22.759682 12219 solver.cpp:550] Iteration 292000, Testing net (#0)
I0802 03:31:42.329844 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.552706
I0802 03:31:42.329907 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.790939
I0802 03:31:42.329916 12219 solver.cpp:635]     Test net output #2: loss = 1.9606 (* 1 = 1.9606 loss)
I0802 03:31:42.329936 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.5697s
I0802 03:31:42.470821 12219 solver.cpp:353] Iteration 292000 (2.98045 iter/s, 33.552s/100 iter), loss = 1.34054
I0802 03:31:42.470894 12219 solver.cpp:375]     Train net output #0: loss = 1.62311 (* 1 = 1.62311 loss)
I0802 03:31:42.470923 12219 sgd_solver.cpp:136] Iteration 292000, lr = 0.00875, m = 0.9
I0802 03:31:56.503057 12219 solver.cpp:353] Iteration 292100 (7.12664 iter/s, 14.0319s/100 iter), loss = 1.66983
I0802 03:31:56.503082 12219 solver.cpp:375]     Train net output #0: loss = 1.62191 (* 1 = 1.62191 loss)
I0802 03:31:56.503088 12219 sgd_solver.cpp:136] Iteration 292100, lr = 0.00871875, m = 0.9
I0802 03:32:10.501513 12219 solver.cpp:353] Iteration 292200 (7.14384 iter/s, 13.9981s/100 iter), loss = 1.45631
I0802 03:32:10.501538 12219 solver.cpp:375]     Train net output #0: loss = 1.7909 (* 1 = 1.7909 loss)
I0802 03:32:10.501543 12219 sgd_solver.cpp:136] Iteration 292200, lr = 0.0086875, m = 0.9
I0802 03:32:24.545835 12219 solver.cpp:353] Iteration 292300 (7.12051 iter/s, 14.0439s/100 iter), loss = 1.48862
I0802 03:32:24.545970 12219 solver.cpp:375]     Train net output #0: loss = 1.54017 (* 1 = 1.54017 loss)
I0802 03:32:24.545992 12219 sgd_solver.cpp:136] Iteration 292300, lr = 0.00865625, m = 0.9
I0802 03:32:38.642951 12219 solver.cpp:353] Iteration 292400 (7.09384 iter/s, 14.0967s/100 iter), loss = 0.849196
I0802 03:32:38.642980 12219 solver.cpp:375]     Train net output #0: loss = 0.818507 (* 1 = 0.818507 loss)
I0802 03:32:38.642987 12219 sgd_solver.cpp:136] Iteration 292400, lr = 0.008625, m = 0.9
I0802 03:32:52.578121 12219 solver.cpp:353] Iteration 292500 (7.17628 iter/s, 13.9348s/100 iter), loss = 1.27167
I0802 03:32:52.578145 12219 solver.cpp:375]     Train net output #0: loss = 1.39711 (* 1 = 1.39711 loss)
I0802 03:32:52.578148 12219 sgd_solver.cpp:136] Iteration 292500, lr = 0.00859375, m = 0.9
I0802 03:33:06.691195 12219 solver.cpp:353] Iteration 292600 (7.08582 iter/s, 14.1127s/100 iter), loss = 1.67192
I0802 03:33:06.691251 12219 solver.cpp:375]     Train net output #0: loss = 1.50586 (* 1 = 1.50586 loss)
I0802 03:33:06.691256 12219 sgd_solver.cpp:136] Iteration 292600, lr = 0.0085625, m = 0.9
I0802 03:33:20.730535 12219 solver.cpp:353] Iteration 292700 (7.12303 iter/s, 14.039s/100 iter), loss = 1.2507
I0802 03:33:20.730564 12219 solver.cpp:375]     Train net output #0: loss = 1.31055 (* 1 = 1.31055 loss)
I0802 03:33:20.730569 12219 sgd_solver.cpp:136] Iteration 292700, lr = 0.00853125, m = 0.9
I0802 03:33:34.725107 12219 solver.cpp:353] Iteration 292800 (7.14583 iter/s, 13.9942s/100 iter), loss = 1.40008
I0802 03:33:34.725138 12219 solver.cpp:375]     Train net output #0: loss = 0.922811 (* 1 = 0.922811 loss)
I0802 03:33:34.725144 12219 sgd_solver.cpp:136] Iteration 292800, lr = 0.0085, m = 0.9
I0802 03:33:48.712865 12219 solver.cpp:353] Iteration 292900 (7.1493 iter/s, 13.9874s/100 iter), loss = 1.06406
I0802 03:33:48.712982 12219 solver.cpp:375]     Train net output #0: loss = 1.19192 (* 1 = 1.19192 loss)
I0802 03:33:48.713001 12219 sgd_solver.cpp:136] Iteration 292900, lr = 0.00846875, m = 0.9
I0802 03:34:02.688652 12219 solver.cpp:353] Iteration 293000 (7.15543 iter/s, 13.9754s/100 iter), loss = 1.40899
I0802 03:34:02.688676 12219 solver.cpp:375]     Train net output #0: loss = 1.50546 (* 1 = 1.50546 loss)
I0802 03:34:02.688680 12219 sgd_solver.cpp:136] Iteration 293000, lr = 0.0084375, m = 0.9
I0802 03:34:16.643023 12219 solver.cpp:353] Iteration 293100 (7.16641 iter/s, 13.954s/100 iter), loss = 1.36519
I0802 03:34:16.643051 12219 solver.cpp:375]     Train net output #0: loss = 1.70133 (* 1 = 1.70133 loss)
I0802 03:34:16.643057 12219 sgd_solver.cpp:136] Iteration 293100, lr = 0.00840625, m = 0.9
I0802 03:34:30.748070 12219 solver.cpp:353] Iteration 293200 (7.08985 iter/s, 14.1047s/100 iter), loss = 1.20882
I0802 03:34:30.748155 12219 solver.cpp:375]     Train net output #0: loss = 1.24882 (* 1 = 1.24882 loss)
I0802 03:34:30.748194 12219 sgd_solver.cpp:136] Iteration 293200, lr = 0.008375, m = 0.9
I0802 03:34:44.797422 12219 solver.cpp:353] Iteration 293300 (7.11796 iter/s, 14.049s/100 iter), loss = 1.56328
I0802 03:34:44.797447 12219 solver.cpp:375]     Train net output #0: loss = 1.36269 (* 1 = 1.36269 loss)
I0802 03:34:44.797453 12219 sgd_solver.cpp:136] Iteration 293300, lr = 0.00834375, m = 0.9
I0802 03:34:58.956300 12219 solver.cpp:353] Iteration 293400 (7.0629 iter/s, 14.1585s/100 iter), loss = 1.64275
I0802 03:34:58.956326 12219 solver.cpp:375]     Train net output #0: loss = 1.54692 (* 1 = 1.54692 loss)
I0802 03:34:58.956331 12219 sgd_solver.cpp:136] Iteration 293400, lr = 0.0083125, m = 0.9
I0802 03:35:12.879266 12219 solver.cpp:353] Iteration 293500 (7.18257 iter/s, 13.9226s/100 iter), loss = 1.58508
I0802 03:35:12.879348 12219 solver.cpp:375]     Train net output #0: loss = 1.17073 (* 1 = 1.17073 loss)
I0802 03:35:12.879354 12219 sgd_solver.cpp:136] Iteration 293500, lr = 0.00828125, m = 0.9
I0802 03:35:27.011817 12219 solver.cpp:353] Iteration 293600 (7.07605 iter/s, 14.1322s/100 iter), loss = 1.73411
I0802 03:35:27.011842 12219 solver.cpp:375]     Train net output #0: loss = 1.70256 (* 1 = 1.70256 loss)
I0802 03:35:27.011847 12219 sgd_solver.cpp:136] Iteration 293600, lr = 0.00825, m = 0.9
I0802 03:35:41.095679 12219 solver.cpp:353] Iteration 293700 (7.10052 iter/s, 14.0835s/100 iter), loss = 1.58222
I0802 03:35:41.095765 12219 solver.cpp:375]     Train net output #0: loss = 1.46811 (* 1 = 1.46811 loss)
I0802 03:35:41.095785 12219 sgd_solver.cpp:136] Iteration 293700, lr = 0.00821875, m = 0.9
I0802 03:35:55.232146 12219 solver.cpp:353] Iteration 293800 (7.07409 iter/s, 14.1361s/100 iter), loss = 1.5157
I0802 03:35:55.232283 12219 solver.cpp:375]     Train net output #0: loss = 1.63351 (* 1 = 1.63351 loss)
I0802 03:35:55.232306 12219 sgd_solver.cpp:136] Iteration 293800, lr = 0.0081875, m = 0.9
I0802 03:36:09.317821 12219 solver.cpp:353] Iteration 293900 (7.0996 iter/s, 14.0853s/100 iter), loss = 1.83088
I0802 03:36:09.317850 12219 solver.cpp:375]     Train net output #0: loss = 1.63524 (* 1 = 1.63524 loss)
I0802 03:36:09.317857 12219 sgd_solver.cpp:136] Iteration 293900, lr = 0.00815625, m = 0.9
I0802 03:36:23.149448 12219 solver.cpp:550] Iteration 294000, Testing net (#0)
I0802 03:36:43.525660 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.572882
I0802 03:36:43.525797 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.803821
I0802 03:36:43.525816 12219 solver.cpp:635]     Test net output #2: loss = 1.8632 (* 1 = 1.8632 loss)
I0802 03:36:43.525878 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3759s
I0802 03:36:43.701918 12219 solver.cpp:353] Iteration 294000 (2.9084 iter/s, 34.3832s/100 iter), loss = 1.43883
I0802 03:36:43.701949 12219 solver.cpp:375]     Train net output #0: loss = 1.46585 (* 1 = 1.46585 loss)
I0802 03:36:43.701956 12219 sgd_solver.cpp:136] Iteration 294000, lr = 0.008125, m = 0.9
I0802 03:36:57.698192 12219 solver.cpp:353] Iteration 294100 (7.14495 iter/s, 13.9959s/100 iter), loss = 1.23101
I0802 03:36:57.698410 12219 solver.cpp:375]     Train net output #0: loss = 1.29567 (* 1 = 1.29567 loss)
I0802 03:36:57.698501 12219 sgd_solver.cpp:136] Iteration 294100, lr = 0.00809375, m = 0.9
I0802 03:37:11.798195 12219 solver.cpp:353] Iteration 294200 (7.09239 iter/s, 14.0996s/100 iter), loss = 1.11492
I0802 03:37:11.798315 12219 solver.cpp:375]     Train net output #0: loss = 1.04724 (* 1 = 1.04724 loss)
I0802 03:37:11.798339 12219 sgd_solver.cpp:136] Iteration 294200, lr = 0.0080625, m = 0.9
I0802 03:37:25.783525 12219 solver.cpp:353] Iteration 294300 (7.15054 iter/s, 13.985s/100 iter), loss = 1.42103
I0802 03:37:25.783673 12219 solver.cpp:375]     Train net output #0: loss = 1.67556 (* 1 = 1.67556 loss)
I0802 03:37:25.783694 12219 sgd_solver.cpp:136] Iteration 294300, lr = 0.00803125, m = 0.9
I0802 03:37:39.729924 12219 solver.cpp:353] Iteration 294400 (7.1705 iter/s, 13.946s/100 iter), loss = 1.23577
I0802 03:37:39.729959 12219 solver.cpp:375]     Train net output #0: loss = 1.06893 (* 1 = 1.06893 loss)
I0802 03:37:39.729964 12219 sgd_solver.cpp:136] Iteration 294400, lr = 0.008, m = 0.9
I0802 03:37:53.724469 12219 solver.cpp:353] Iteration 294500 (7.14583 iter/s, 13.9942s/100 iter), loss = 1.20671
I0802 03:37:53.724494 12219 solver.cpp:375]     Train net output #0: loss = 1.21102 (* 1 = 1.21102 loss)
I0802 03:37:53.724527 12219 sgd_solver.cpp:136] Iteration 294500, lr = 0.00796875, m = 0.9
I0802 03:38:07.798352 12219 solver.cpp:353] Iteration 294600 (7.10555 iter/s, 14.0735s/100 iter), loss = 1.12
I0802 03:38:07.798470 12219 solver.cpp:375]     Train net output #0: loss = 1.22011 (* 1 = 1.22011 loss)
I0802 03:38:07.798483 12219 sgd_solver.cpp:136] Iteration 294600, lr = 0.0079375, m = 0.9
I0802 03:38:21.821331 12219 solver.cpp:353] Iteration 294700 (7.13135 iter/s, 14.0226s/100 iter), loss = 1.38919
I0802 03:38:21.821413 12219 solver.cpp:375]     Train net output #0: loss = 1.61681 (* 1 = 1.61681 loss)
I0802 03:38:21.821435 12219 sgd_solver.cpp:136] Iteration 294700, lr = 0.00790625, m = 0.9
I0802 03:38:35.812932 12219 solver.cpp:353] Iteration 294800 (7.14734 iter/s, 13.9912s/100 iter), loss = 1.30354
I0802 03:38:35.812958 12219 solver.cpp:375]     Train net output #0: loss = 1.50669 (* 1 = 1.50669 loss)
I0802 03:38:35.812964 12219 sgd_solver.cpp:136] Iteration 294800, lr = 0.007875, m = 0.9
I0802 03:38:49.794594 12219 solver.cpp:353] Iteration 294900 (7.15242 iter/s, 13.9813s/100 iter), loss = 1.38275
I0802 03:38:49.794673 12219 solver.cpp:375]     Train net output #0: loss = 1.2792 (* 1 = 1.2792 loss)
I0802 03:38:49.794684 12219 sgd_solver.cpp:136] Iteration 294900, lr = 0.00784375, m = 0.9
I0802 03:39:03.829671 12219 solver.cpp:353] Iteration 295000 (7.1252 iter/s, 14.0347s/100 iter), loss = 1.21087
I0802 03:39:03.829730 12219 solver.cpp:375]     Train net output #0: loss = 1.24701 (* 1 = 1.24701 loss)
I0802 03:39:03.829742 12219 sgd_solver.cpp:136] Iteration 295000, lr = 0.0078125, m = 0.9
I0802 03:39:17.770776 12219 solver.cpp:353] Iteration 295100 (7.17323 iter/s, 13.9407s/100 iter), loss = 1.31748
I0802 03:39:17.770848 12219 solver.cpp:375]     Train net output #0: loss = 1.5999 (* 1 = 1.5999 loss)
I0802 03:39:17.770866 12219 sgd_solver.cpp:136] Iteration 295100, lr = 0.00778125, m = 0.9
I0802 03:39:31.839974 12219 solver.cpp:353] Iteration 295200 (7.10792 iter/s, 14.0688s/100 iter), loss = 1.13616
I0802 03:39:31.840061 12219 solver.cpp:375]     Train net output #0: loss = 1.46973 (* 1 = 1.46973 loss)
I0802 03:39:31.840068 12219 sgd_solver.cpp:136] Iteration 295200, lr = 0.00775, m = 0.9
I0802 03:39:45.773104 12219 solver.cpp:353] Iteration 295300 (7.17734 iter/s, 13.9327s/100 iter), loss = 1.94806
I0802 03:39:45.773133 12219 solver.cpp:375]     Train net output #0: loss = 1.67913 (* 1 = 1.67913 loss)
I0802 03:39:45.773140 12219 sgd_solver.cpp:136] Iteration 295300, lr = 0.00771875, m = 0.9
I0802 03:39:59.693454 12219 solver.cpp:353] Iteration 295400 (7.18393 iter/s, 13.92s/100 iter), loss = 1.55031
I0802 03:39:59.693508 12219 solver.cpp:375]     Train net output #0: loss = 1.52371 (* 1 = 1.52371 loss)
I0802 03:39:59.693521 12219 sgd_solver.cpp:136] Iteration 295400, lr = 0.0076875, m = 0.9
I0802 03:40:13.743000 12219 solver.cpp:353] Iteration 295500 (7.11786 iter/s, 14.0492s/100 iter), loss = 1.31146
I0802 03:40:13.743054 12219 solver.cpp:375]     Train net output #0: loss = 1.17314 (* 1 = 1.17314 loss)
I0802 03:40:13.743062 12219 sgd_solver.cpp:136] Iteration 295500, lr = 0.00765625, m = 0.9
I0802 03:40:27.676203 12219 solver.cpp:353] Iteration 295600 (7.1773 iter/s, 13.9328s/100 iter), loss = 1.24877
I0802 03:40:27.676232 12219 solver.cpp:375]     Train net output #0: loss = 1.38991 (* 1 = 1.38991 loss)
I0802 03:40:27.676239 12219 sgd_solver.cpp:136] Iteration 295600, lr = 0.007625, m = 0.9
I0802 03:40:41.750049 12219 solver.cpp:353] Iteration 295700 (7.10557 iter/s, 14.0735s/100 iter), loss = 1.50716
I0802 03:40:41.750118 12219 solver.cpp:375]     Train net output #0: loss = 1.34184 (* 1 = 1.34184 loss)
I0802 03:40:41.750135 12219 sgd_solver.cpp:136] Iteration 295700, lr = 0.00759375, m = 0.9
I0802 03:40:55.731648 12219 solver.cpp:353] Iteration 295800 (7.15245 iter/s, 13.9812s/100 iter), loss = 1.20634
I0802 03:40:55.731717 12219 solver.cpp:375]     Train net output #0: loss = 1.21026 (* 1 = 1.21026 loss)
I0802 03:40:55.731724 12219 sgd_solver.cpp:136] Iteration 295800, lr = 0.0075625, m = 0.9
I0802 03:41:09.654268 12219 solver.cpp:353] Iteration 295900 (7.18275 iter/s, 13.9222s/100 iter), loss = 1.33547
I0802 03:41:09.654299 12219 solver.cpp:375]     Train net output #0: loss = 1.35992 (* 1 = 1.35992 loss)
I0802 03:41:09.654305 12219 sgd_solver.cpp:136] Iteration 295900, lr = 0.00753125, m = 0.9
I0802 03:41:23.596262 12219 solver.cpp:550] Iteration 296000, Testing net (#0)
I0802 03:41:30.040024 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 03:41:43.805977 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.562529
I0802 03:41:43.806000 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.801821
I0802 03:41:43.806006 12219 solver.cpp:635]     Test net output #2: loss = 1.89613 (* 1 = 1.89613 loss)
I0802 03:41:43.806028 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.2092s
I0802 03:41:43.945705 12219 solver.cpp:353] Iteration 296000 (2.91626 iter/s, 34.2905s/100 iter), loss = 1.40143
I0802 03:41:43.945735 12219 solver.cpp:375]     Train net output #0: loss = 1.36623 (* 1 = 1.36623 loss)
I0802 03:41:43.945741 12219 sgd_solver.cpp:136] Iteration 296000, lr = 0.0075, m = 0.9
I0802 03:41:58.063062 12219 solver.cpp:353] Iteration 296100 (7.08367 iter/s, 14.117s/100 iter), loss = 1.2242
I0802 03:41:58.063088 12219 solver.cpp:375]     Train net output #0: loss = 0.82765 (* 1 = 0.82765 loss)
I0802 03:41:58.063093 12219 sgd_solver.cpp:136] Iteration 296100, lr = 0.00746875, m = 0.9
I0802 03:42:12.013628 12219 solver.cpp:353] Iteration 296200 (7.16836 iter/s, 13.9502s/100 iter), loss = 1.81679
I0802 03:42:12.013738 12219 solver.cpp:375]     Train net output #0: loss = 2.09972 (* 1 = 2.09972 loss)
I0802 03:42:12.013746 12219 sgd_solver.cpp:136] Iteration 296200, lr = 0.0074375, m = 0.9
I0802 03:42:26.054407 12219 solver.cpp:353] Iteration 296300 (7.1223 iter/s, 14.0404s/100 iter), loss = 1.26325
I0802 03:42:26.054431 12219 solver.cpp:375]     Train net output #0: loss = 1.27692 (* 1 = 1.27692 loss)
I0802 03:42:26.054435 12219 sgd_solver.cpp:136] Iteration 296300, lr = 0.00740625, m = 0.9
I0802 03:42:40.146790 12219 solver.cpp:353] Iteration 296400 (7.09622 iter/s, 14.092s/100 iter), loss = 1.5164
I0802 03:42:40.146818 12219 solver.cpp:375]     Train net output #0: loss = 1.56057 (* 1 = 1.56057 loss)
I0802 03:42:40.146824 12219 sgd_solver.cpp:136] Iteration 296400, lr = 0.007375, m = 0.9
I0802 03:42:54.167392 12219 solver.cpp:353] Iteration 296500 (7.13256 iter/s, 14.0202s/100 iter), loss = 1.40603
I0802 03:42:54.167934 12219 solver.cpp:375]     Train net output #0: loss = 1.04093 (* 1 = 1.04093 loss)
I0802 03:42:54.167943 12219 sgd_solver.cpp:136] Iteration 296500, lr = 0.00734375, m = 0.9
I0802 03:43:08.181114 12219 solver.cpp:353] Iteration 296600 (7.13605 iter/s, 14.0133s/100 iter), loss = 1.53865
I0802 03:43:08.181139 12219 solver.cpp:375]     Train net output #0: loss = 1.67026 (* 1 = 1.67026 loss)
I0802 03:43:08.181143 12219 sgd_solver.cpp:136] Iteration 296600, lr = 0.0073125, m = 0.9
I0802 03:43:22.130338 12219 solver.cpp:353] Iteration 296700 (7.16905 iter/s, 13.9488s/100 iter), loss = 1.25075
I0802 03:43:22.130362 12219 solver.cpp:375]     Train net output #0: loss = 0.940687 (* 1 = 0.940687 loss)
I0802 03:43:22.130368 12219 sgd_solver.cpp:136] Iteration 296700, lr = 0.00728125, m = 0.9
I0802 03:43:36.087304 12219 solver.cpp:353] Iteration 296800 (7.16508 iter/s, 13.9566s/100 iter), loss = 1.56045
I0802 03:43:36.087397 12219 solver.cpp:375]     Train net output #0: loss = 1.85404 (* 1 = 1.85404 loss)
I0802 03:43:36.087404 12219 sgd_solver.cpp:136] Iteration 296800, lr = 0.00725, m = 0.9
I0802 03:43:50.158376 12219 solver.cpp:353] Iteration 296900 (7.10697 iter/s, 14.0707s/100 iter), loss = 1.78214
I0802 03:43:50.158484 12219 solver.cpp:375]     Train net output #0: loss = 1.73764 (* 1 = 1.73764 loss)
I0802 03:43:50.158506 12219 sgd_solver.cpp:136] Iteration 296900, lr = 0.00721875, m = 0.9
I0802 03:44:04.252516 12219 solver.cpp:353] Iteration 297000 (7.09534 iter/s, 14.0938s/100 iter), loss = 1.87989
I0802 03:44:04.252542 12219 solver.cpp:375]     Train net output #0: loss = 1.59821 (* 1 = 1.59821 loss)
I0802 03:44:04.252548 12219 sgd_solver.cpp:136] Iteration 297000, lr = 0.0071875, m = 0.9
I0802 03:44:18.411442 12219 solver.cpp:353] Iteration 297100 (7.06287 iter/s, 14.1585s/100 iter), loss = 1.76437
I0802 03:44:18.411538 12219 solver.cpp:375]     Train net output #0: loss = 2.10278 (* 1 = 2.10278 loss)
I0802 03:44:18.411543 12219 sgd_solver.cpp:136] Iteration 297100, lr = 0.00715625, m = 0.9
I0802 03:44:32.402555 12219 solver.cpp:353] Iteration 297200 (7.14758 iter/s, 13.9907s/100 iter), loss = 1.15875
I0802 03:44:32.402609 12219 solver.cpp:375]     Train net output #0: loss = 1.29258 (* 1 = 1.29258 loss)
I0802 03:44:32.402623 12219 sgd_solver.cpp:136] Iteration 297200, lr = 0.007125, m = 0.9
I0802 03:44:46.374332 12219 solver.cpp:353] Iteration 297300 (7.15748 iter/s, 13.9714s/100 iter), loss = 1.26138
I0802 03:44:46.374529 12219 solver.cpp:375]     Train net output #0: loss = 1.15152 (* 1 = 1.15152 loss)
I0802 03:44:46.374619 12219 sgd_solver.cpp:136] Iteration 297300, lr = 0.00709375, m = 0.9
I0802 03:45:00.497545 12219 solver.cpp:353] Iteration 297400 (7.08073 iter/s, 14.1228s/100 iter), loss = 1.53552
I0802 03:45:00.497604 12219 solver.cpp:375]     Train net output #0: loss = 1.61823 (* 1 = 1.61823 loss)
I0802 03:45:00.497611 12219 sgd_solver.cpp:136] Iteration 297400, lr = 0.0070625, m = 0.9
I0802 03:45:14.551632 12219 solver.cpp:353] Iteration 297500 (7.11556 iter/s, 14.0537s/100 iter), loss = 1.51419
I0802 03:45:14.551661 12219 solver.cpp:375]     Train net output #0: loss = 1.68096 (* 1 = 1.68096 loss)
I0802 03:45:14.551666 12219 sgd_solver.cpp:136] Iteration 297500, lr = 0.00703125, m = 0.9
I0802 03:45:28.631644 12219 solver.cpp:353] Iteration 297600 (7.10246 iter/s, 14.0796s/100 iter), loss = 1.37004
I0802 03:45:28.631671 12219 solver.cpp:375]     Train net output #0: loss = 1.06766 (* 1 = 1.06766 loss)
I0802 03:45:28.631677 12219 sgd_solver.cpp:136] Iteration 297600, lr = 0.007, m = 0.9
I0802 03:45:42.639945 12219 solver.cpp:353] Iteration 297700 (7.13882 iter/s, 14.0079s/100 iter), loss = 1.49118
I0802 03:45:42.640002 12219 solver.cpp:375]     Train net output #0: loss = 1.23952 (* 1 = 1.23952 loss)
I0802 03:45:42.640007 12219 sgd_solver.cpp:136] Iteration 297700, lr = 0.00696875, m = 0.9
I0802 03:45:56.708433 12219 solver.cpp:353] Iteration 297800 (7.10827 iter/s, 14.0681s/100 iter), loss = 1.04524
I0802 03:45:56.708458 12219 solver.cpp:375]     Train net output #0: loss = 0.720367 (* 1 = 0.720367 loss)
I0802 03:45:56.708462 12219 sgd_solver.cpp:136] Iteration 297800, lr = 0.0069375, m = 0.9
I0802 03:46:10.809178 12219 solver.cpp:353] Iteration 297900 (7.09202 iter/s, 14.1004s/100 iter), loss = 1.27888
I0802 03:46:10.809207 12219 solver.cpp:375]     Train net output #0: loss = 1.09624 (* 1 = 1.09624 loss)
I0802 03:46:10.809213 12219 sgd_solver.cpp:136] Iteration 297900, lr = 0.00690625, m = 0.9
I0802 03:46:24.705428 12219 solver.cpp:550] Iteration 298000, Testing net (#0)
I0802 03:46:25.446709 12207 data_reader.cpp:264] Starting prefetch of epoch 17
I0802 03:46:44.753834 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.57
I0802 03:46:44.753860 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805115
I0802 03:46:44.753865 12219 solver.cpp:635]     Test net output #2: loss = 1.86635 (* 1 = 1.86635 loss)
I0802 03:46:44.763481 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.048s
I0802 03:46:44.893340 12219 solver.cpp:353] Iteration 298000 (2.93399 iter/s, 34.0833s/100 iter), loss = 1.22984
I0802 03:46:44.893370 12219 solver.cpp:375]     Train net output #0: loss = 1.0685 (* 1 = 1.0685 loss)
I0802 03:46:44.893537 12219 sgd_solver.cpp:136] Iteration 298000, lr = 0.006875, m = 0.9
I0802 03:46:58.846364 12219 solver.cpp:353] Iteration 298100 (7.1671 iter/s, 13.9526s/100 iter), loss = 1.53011
I0802 03:46:58.846420 12219 solver.cpp:375]     Train net output #0: loss = 1.24093 (* 1 = 1.24093 loss)
I0802 03:46:58.846426 12219 sgd_solver.cpp:136] Iteration 298100, lr = 0.00684375, m = 0.9
I0802 03:47:12.928370 12219 solver.cpp:353] Iteration 298200 (7.10146 iter/s, 14.0816s/100 iter), loss = 1.5943
I0802 03:47:12.928498 12219 solver.cpp:375]     Train net output #0: loss = 1.72567 (* 1 = 1.72567 loss)
I0802 03:47:12.928524 12219 sgd_solver.cpp:136] Iteration 298200, lr = 0.0068125, m = 0.9
I0802 03:47:27.025858 12219 solver.cpp:353] Iteration 298300 (7.09365 iter/s, 14.0971s/100 iter), loss = 1.62848
I0802 03:47:27.025887 12219 solver.cpp:375]     Train net output #0: loss = 1.54287 (* 1 = 1.54287 loss)
I0802 03:47:27.025892 12219 sgd_solver.cpp:136] Iteration 298300, lr = 0.00678125, m = 0.9
I0802 03:47:41.021788 12219 solver.cpp:353] Iteration 298400 (7.14513 iter/s, 13.9956s/100 iter), loss = 1.65592
I0802 03:47:41.021879 12219 solver.cpp:375]     Train net output #0: loss = 1.7036 (* 1 = 1.7036 loss)
I0802 03:47:41.021886 12219 sgd_solver.cpp:136] Iteration 298400, lr = 0.00675, m = 0.9
I0802 03:47:55.042992 12219 solver.cpp:353] Iteration 298500 (7.13225 iter/s, 14.0208s/100 iter), loss = 1.58714
I0802 03:47:55.043017 12219 solver.cpp:375]     Train net output #0: loss = 1.83648 (* 1 = 1.83648 loss)
I0802 03:47:55.043023 12219 sgd_solver.cpp:136] Iteration 298500, lr = 0.00671875, m = 0.9
I0802 03:48:08.980509 12219 solver.cpp:353] Iteration 298600 (7.17508 iter/s, 13.9371s/100 iter), loss = 1.62347
I0802 03:48:08.980537 12219 solver.cpp:375]     Train net output #0: loss = 1.77913 (* 1 = 1.77913 loss)
I0802 03:48:08.980545 12219 sgd_solver.cpp:136] Iteration 298600, lr = 0.0066875, m = 0.9
I0802 03:48:23.007314 12219 solver.cpp:353] Iteration 298700 (7.1294 iter/s, 14.0264s/100 iter), loss = 1.24576
I0802 03:48:23.007396 12219 solver.cpp:375]     Train net output #0: loss = 1.12304 (* 1 = 1.12304 loss)
I0802 03:48:23.007405 12219 sgd_solver.cpp:136] Iteration 298700, lr = 0.00665625, m = 0.9
I0802 03:48:37.010123 12219 solver.cpp:353] Iteration 298800 (7.14162 iter/s, 14.0024s/100 iter), loss = 1.2155
I0802 03:48:37.010149 12219 solver.cpp:375]     Train net output #0: loss = 1.23192 (* 1 = 1.23192 loss)
I0802 03:48:37.010156 12219 sgd_solver.cpp:136] Iteration 298800, lr = 0.006625, m = 0.9
I0802 03:48:50.963896 12219 solver.cpp:353] Iteration 298900 (7.16671 iter/s, 13.9534s/100 iter), loss = 1.37169
I0802 03:48:50.963922 12219 solver.cpp:375]     Train net output #0: loss = 0.900744 (* 1 = 0.900744 loss)
I0802 03:48:50.963925 12219 sgd_solver.cpp:136] Iteration 298900, lr = 0.00659375, m = 0.9
I0802 03:49:04.980727 12219 solver.cpp:353] Iteration 299000 (7.13447 iter/s, 14.0165s/100 iter), loss = 1.62574
I0802 03:49:04.980851 12219 solver.cpp:375]     Train net output #0: loss = 1.26767 (* 1 = 1.26767 loss)
I0802 03:49:04.980872 12219 sgd_solver.cpp:136] Iteration 299000, lr = 0.0065625, m = 0.9
I0802 03:49:18.908511 12219 solver.cpp:353] Iteration 299100 (7.18009 iter/s, 13.9274s/100 iter), loss = 1.44451
I0802 03:49:18.908581 12219 solver.cpp:375]     Train net output #0: loss = 1.50503 (* 1 = 1.50503 loss)
I0802 03:49:18.908599 12219 sgd_solver.cpp:136] Iteration 299100, lr = 0.00653125, m = 0.9
I0802 03:49:33.060792 12219 solver.cpp:353] Iteration 299200 (7.06619 iter/s, 14.1519s/100 iter), loss = 1.47162
I0802 03:49:33.060822 12219 solver.cpp:375]     Train net output #0: loss = 1.32932 (* 1 = 1.32932 loss)
I0802 03:49:33.060828 12219 sgd_solver.cpp:136] Iteration 299200, lr = 0.0065, m = 0.9
I0802 03:49:47.135934 12219 solver.cpp:353] Iteration 299300 (7.10491 iter/s, 14.0748s/100 iter), loss = 1.48182
I0802 03:49:47.136029 12219 solver.cpp:375]     Train net output #0: loss = 1.22665 (* 1 = 1.22665 loss)
I0802 03:49:47.136044 12219 sgd_solver.cpp:136] Iteration 299300, lr = 0.00646875, m = 0.9
I0802 03:50:01.215214 12219 solver.cpp:353] Iteration 299400 (7.10283 iter/s, 14.0789s/100 iter), loss = 1.35112
I0802 03:50:01.215241 12219 solver.cpp:375]     Train net output #0: loss = 1.48351 (* 1 = 1.48351 loss)
I0802 03:50:01.215246 12219 sgd_solver.cpp:136] Iteration 299400, lr = 0.0064375, m = 0.9
I0802 03:50:15.248704 12219 solver.cpp:353] Iteration 299500 (7.12601 iter/s, 14.0331s/100 iter), loss = 1.32988
I0802 03:50:15.248776 12219 solver.cpp:375]     Train net output #0: loss = 1.40631 (* 1 = 1.40631 loss)
I0802 03:50:15.248803 12219 sgd_solver.cpp:136] Iteration 299500, lr = 0.00640625, m = 0.9
I0802 03:50:29.373841 12219 solver.cpp:353] Iteration 299600 (7.07977 iter/s, 14.1248s/100 iter), loss = 1.21201
I0802 03:50:29.373909 12219 solver.cpp:375]     Train net output #0: loss = 1.24033 (* 1 = 1.24033 loss)
I0802 03:50:29.373916 12219 sgd_solver.cpp:136] Iteration 299600, lr = 0.006375, m = 0.9
I0802 03:50:43.475643 12219 solver.cpp:353] Iteration 299700 (7.09148 iter/s, 14.1014s/100 iter), loss = 1.33117
I0802 03:50:43.475670 12219 solver.cpp:375]     Train net output #0: loss = 1.6722 (* 1 = 1.6722 loss)
I0802 03:50:43.475674 12219 sgd_solver.cpp:136] Iteration 299700, lr = 0.00634375, m = 0.9
I0802 03:50:57.495591 12219 solver.cpp:353] Iteration 299800 (7.13289 iter/s, 14.0196s/100 iter), loss = 1.02479
I0802 03:50:57.495649 12219 solver.cpp:375]     Train net output #0: loss = 1.12964 (* 1 = 1.12964 loss)
I0802 03:50:57.495666 12219 sgd_solver.cpp:136] Iteration 299800, lr = 0.0063125, m = 0.9
I0802 03:51:11.614655 12219 solver.cpp:353] Iteration 299900 (7.08281 iter/s, 14.1187s/100 iter), loss = 1.12666
I0802 03:51:11.614753 12219 solver.cpp:375]     Train net output #0: loss = 1.1654 (* 1 = 1.1654 loss)
I0802 03:51:11.614765 12219 sgd_solver.cpp:136] Iteration 299900, lr = 0.00628125, m = 0.9
I0802 03:51:25.437857 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_300000.caffemodel
I0802 03:51:25.563333 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_300000.solverstate
I0802 03:51:25.571650 12219 solver.cpp:550] Iteration 300000, Testing net (#0)
I0802 03:51:45.519393 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.576706
I0802 03:51:45.519484 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.806468
I0802 03:51:45.519493 12219 solver.cpp:635]     Test net output #2: loss = 1.85113 (* 1 = 1.85113 loss)
I0802 03:51:45.519546 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9474s
I0802 03:51:45.661372 12219 solver.cpp:353] Iteration 300000 (2.93722 iter/s, 34.0458s/100 iter), loss = 1.12414
I0802 03:51:45.661397 12219 solver.cpp:375]     Train net output #0: loss = 1.03816 (* 1 = 1.03816 loss)
I0802 03:51:45.661402 12219 sgd_solver.cpp:136] Iteration 300000, lr = 0.00625, m = 0.9
I0802 03:51:59.731922 12219 solver.cpp:353] Iteration 300100 (7.10724 iter/s, 14.0702s/100 iter), loss = 1.20388
I0802 03:51:59.731953 12219 solver.cpp:375]     Train net output #0: loss = 1.34134 (* 1 = 1.34134 loss)
I0802 03:51:59.731959 12219 sgd_solver.cpp:136] Iteration 300100, lr = 0.00621875, m = 0.9
I0802 03:52:13.756022 12219 solver.cpp:353] Iteration 300200 (7.13078 iter/s, 14.0237s/100 iter), loss = 1.56864
I0802 03:52:13.756108 12219 solver.cpp:375]     Train net output #0: loss = 1.65633 (* 1 = 1.65633 loss)
I0802 03:52:13.756145 12219 sgd_solver.cpp:136] Iteration 300200, lr = 0.0061875, m = 0.9
I0802 03:52:27.952754 12219 solver.cpp:353] Iteration 300300 (7.04406 iter/s, 14.1964s/100 iter), loss = 1.28362
I0802 03:52:27.952807 12219 solver.cpp:375]     Train net output #0: loss = 1.3598 (* 1 = 1.3598 loss)
I0802 03:52:27.952813 12219 sgd_solver.cpp:136] Iteration 300300, lr = 0.00615625, m = 0.9
I0802 03:52:41.833911 12219 solver.cpp:353] Iteration 300400 (7.20421 iter/s, 13.8808s/100 iter), loss = 1.37045
I0802 03:52:41.833940 12219 solver.cpp:375]     Train net output #0: loss = 1.23602 (* 1 = 1.23602 loss)
I0802 03:52:41.833946 12219 sgd_solver.cpp:136] Iteration 300400, lr = 0.006125, m = 0.9
I0802 03:52:55.805876 12219 solver.cpp:353] Iteration 300500 (7.15738 iter/s, 13.9716s/100 iter), loss = 1.29805
I0802 03:52:55.805903 12219 solver.cpp:375]     Train net output #0: loss = 1.29379 (* 1 = 1.29379 loss)
I0802 03:52:55.805909 12219 sgd_solver.cpp:136] Iteration 300500, lr = 0.00609375, m = 0.9
I0802 03:53:09.783756 12219 solver.cpp:353] Iteration 300600 (7.15435 iter/s, 13.9775s/100 iter), loss = 1.19108
I0802 03:53:09.783943 12219 solver.cpp:375]     Train net output #0: loss = 1.06465 (* 1 = 1.06465 loss)
I0802 03:53:09.783951 12219 sgd_solver.cpp:136] Iteration 300600, lr = 0.0060625, m = 0.9
I0802 03:53:23.755702 12219 solver.cpp:353] Iteration 300700 (7.15739 iter/s, 13.9716s/100 iter), loss = 1.53517
I0802 03:53:23.755733 12219 solver.cpp:375]     Train net output #0: loss = 1.28901 (* 1 = 1.28901 loss)
I0802 03:53:23.755738 12219 sgd_solver.cpp:136] Iteration 300700, lr = 0.00603125, m = 0.9
I0802 03:53:37.842955 12219 solver.cpp:353] Iteration 300800 (7.09881 iter/s, 14.0869s/100 iter), loss = 1.46202
I0802 03:53:37.842979 12219 solver.cpp:375]     Train net output #0: loss = 1.40484 (* 1 = 1.40484 loss)
I0802 03:53:37.842983 12219 sgd_solver.cpp:136] Iteration 300800, lr = 0.006, m = 0.9
I0802 03:53:51.792919 12219 solver.cpp:353] Iteration 300900 (7.16867 iter/s, 13.9496s/100 iter), loss = 1.47455
I0802 03:53:51.792979 12219 solver.cpp:375]     Train net output #0: loss = 1.55244 (* 1 = 1.55244 loss)
I0802 03:53:51.792986 12219 sgd_solver.cpp:136] Iteration 300900, lr = 0.00596875, m = 0.9
I0802 03:54:05.772814 12219 solver.cpp:353] Iteration 301000 (7.15332 iter/s, 13.9795s/100 iter), loss = 1.5671
I0802 03:54:05.772860 12219 solver.cpp:375]     Train net output #0: loss = 1.79961 (* 1 = 1.79961 loss)
I0802 03:54:05.772866 12219 sgd_solver.cpp:136] Iteration 301000, lr = 0.0059375, m = 0.9
I0802 03:54:19.759263 12219 solver.cpp:353] Iteration 301100 (7.14997 iter/s, 13.9861s/100 iter), loss = 1.31904
I0802 03:54:19.759299 12219 solver.cpp:375]     Train net output #0: loss = 1.4209 (* 1 = 1.4209 loss)
I0802 03:54:19.759306 12219 sgd_solver.cpp:136] Iteration 301100, lr = 0.00590625, m = 0.9
I0802 03:54:33.814481 12219 solver.cpp:353] Iteration 301200 (7.11499 iter/s, 14.0548s/100 iter), loss = 1.18775
I0802 03:54:33.814538 12219 solver.cpp:375]     Train net output #0: loss = 0.972175 (* 1 = 0.972175 loss)
I0802 03:54:33.814544 12219 sgd_solver.cpp:136] Iteration 301200, lr = 0.005875, m = 0.9
I0802 03:54:47.914044 12219 solver.cpp:353] Iteration 301300 (7.09261 iter/s, 14.0992s/100 iter), loss = 1.35206
I0802 03:54:47.914072 12219 solver.cpp:375]     Train net output #0: loss = 1.43366 (* 1 = 1.43366 loss)
I0802 03:54:47.914077 12219 sgd_solver.cpp:136] Iteration 301300, lr = 0.00584375, m = 0.9
I0802 03:55:01.883144 12219 solver.cpp:353] Iteration 301400 (7.15885 iter/s, 13.9687s/100 iter), loss = 1.57504
I0802 03:55:01.883172 12219 solver.cpp:375]     Train net output #0: loss = 1.48164 (* 1 = 1.48164 loss)
I0802 03:55:01.883178 12219 sgd_solver.cpp:136] Iteration 301400, lr = 0.0058125, m = 0.9
I0802 03:55:15.905112 12219 solver.cpp:353] Iteration 301500 (7.13186 iter/s, 14.0216s/100 iter), loss = 1.45585
I0802 03:55:15.905187 12219 solver.cpp:375]     Train net output #0: loss = 1.30192 (* 1 = 1.30192 loss)
I0802 03:55:15.905195 12219 sgd_solver.cpp:136] Iteration 301500, lr = 0.00578125, m = 0.9
I0802 03:55:29.935199 12219 solver.cpp:353] Iteration 301600 (7.12773 iter/s, 14.0297s/100 iter), loss = 1.53837
I0802 03:55:29.935227 12219 solver.cpp:375]     Train net output #0: loss = 1.388 (* 1 = 1.388 loss)
I0802 03:55:29.935231 12219 sgd_solver.cpp:136] Iteration 301600, lr = 0.00575, m = 0.9
I0802 03:55:43.868650 12219 solver.cpp:353] Iteration 301700 (7.17716 iter/s, 13.9331s/100 iter), loss = 1.37653
I0802 03:55:43.868680 12219 solver.cpp:375]     Train net output #0: loss = 0.965245 (* 1 = 0.965245 loss)
I0802 03:55:43.868686 12219 sgd_solver.cpp:136] Iteration 301700, lr = 0.00571875, m = 0.9
I0802 03:55:57.861856 12219 solver.cpp:353] Iteration 301800 (7.14652 iter/s, 13.9928s/100 iter), loss = 1.33524
I0802 03:55:57.861915 12219 solver.cpp:375]     Train net output #0: loss = 1.34611 (* 1 = 1.34611 loss)
I0802 03:55:57.861922 12219 sgd_solver.cpp:136] Iteration 301800, lr = 0.0056875, m = 0.9
I0802 03:56:11.839648 12219 solver.cpp:353] Iteration 301900 (7.15441 iter/s, 13.9774s/100 iter), loss = 1.43561
I0802 03:56:11.839678 12219 solver.cpp:375]     Train net output #0: loss = 1.71717 (* 1 = 1.71717 loss)
I0802 03:56:11.839682 12219 sgd_solver.cpp:136] Iteration 301900, lr = 0.00565625, m = 0.9
I0802 03:56:25.661049 12219 solver.cpp:550] Iteration 302000, Testing net (#0)
I0802 03:56:34.233494 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 03:56:45.733048 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.570941
I0802 03:56:45.733072 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.80841
I0802 03:56:45.733078 12219 solver.cpp:635]     Test net output #2: loss = 1.8398 (* 1 = 1.8398 loss)
I0802 03:56:45.733098 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0715s
I0802 03:56:45.882867 12219 solver.cpp:353] Iteration 302000 (2.93752 iter/s, 34.0423s/100 iter), loss = 1.26858
I0802 03:56:45.882892 12219 solver.cpp:375]     Train net output #0: loss = 1.24606 (* 1 = 1.24606 loss)
I0802 03:56:45.882896 12219 sgd_solver.cpp:136] Iteration 302000, lr = 0.005625, m = 0.9
I0802 03:56:59.894971 12219 solver.cpp:353] Iteration 302100 (7.13688 iter/s, 14.0117s/100 iter), loss = 1.06993
I0802 03:56:59.894997 12219 solver.cpp:375]     Train net output #0: loss = 1.11102 (* 1 = 1.11102 loss)
I0802 03:56:59.895002 12219 sgd_solver.cpp:136] Iteration 302100, lr = 0.00559375, m = 0.9
I0802 03:57:13.876235 12219 solver.cpp:353] Iteration 302200 (7.15262 iter/s, 13.9809s/100 iter), loss = 1.25695
I0802 03:57:13.876318 12219 solver.cpp:375]     Train net output #0: loss = 1.43751 (* 1 = 1.43751 loss)
I0802 03:57:13.876325 12219 sgd_solver.cpp:136] Iteration 302200, lr = 0.0055625, m = 0.9
I0802 03:57:27.853454 12219 solver.cpp:353] Iteration 302300 (7.15469 iter/s, 13.9768s/100 iter), loss = 1.25395
I0802 03:57:27.853482 12219 solver.cpp:375]     Train net output #0: loss = 1.08281 (* 1 = 1.08281 loss)
I0802 03:57:27.853487 12219 sgd_solver.cpp:136] Iteration 302300, lr = 0.00553125, m = 0.9
I0802 03:57:41.835204 12219 solver.cpp:353] Iteration 302400 (7.15237 iter/s, 13.9814s/100 iter), loss = 1.13537
I0802 03:57:41.835230 12219 solver.cpp:375]     Train net output #0: loss = 1.36593 (* 1 = 1.36593 loss)
I0802 03:57:41.835234 12219 sgd_solver.cpp:136] Iteration 302400, lr = 0.0055, m = 0.9
I0802 03:57:55.745530 12219 solver.cpp:353] Iteration 302500 (7.1891 iter/s, 13.9099s/100 iter), loss = 1.42721
I0802 03:57:55.745595 12219 solver.cpp:375]     Train net output #0: loss = 1.63676 (* 1 = 1.63676 loss)
I0802 03:57:55.745602 12219 sgd_solver.cpp:136] Iteration 302500, lr = 0.00546875, m = 0.9
I0802 03:58:09.646594 12219 solver.cpp:353] Iteration 302600 (7.19389 iter/s, 13.9007s/100 iter), loss = 1.20142
I0802 03:58:09.646670 12219 solver.cpp:375]     Train net output #0: loss = 1.62819 (* 1 = 1.62819 loss)
I0802 03:58:09.646692 12219 sgd_solver.cpp:136] Iteration 302600, lr = 0.0054375, m = 0.9
I0802 03:58:23.576267 12219 solver.cpp:353] Iteration 302700 (7.17912 iter/s, 13.9293s/100 iter), loss = 1.39142
I0802 03:58:23.576297 12219 solver.cpp:375]     Train net output #0: loss = 1.50246 (* 1 = 1.50246 loss)
I0802 03:58:23.576303 12219 sgd_solver.cpp:136] Iteration 302700, lr = 0.00540625, m = 0.9
I0802 03:58:37.450826 12219 solver.cpp:353] Iteration 302800 (7.20763 iter/s, 13.8742s/100 iter), loss = 1.01999
I0802 03:58:37.450907 12219 solver.cpp:375]     Train net output #0: loss = 1.02427 (* 1 = 1.02427 loss)
I0802 03:58:37.450917 12219 sgd_solver.cpp:136] Iteration 302800, lr = 0.005375, m = 0.9
I0802 03:58:51.519809 12219 solver.cpp:353] Iteration 302900 (7.10802 iter/s, 14.0686s/100 iter), loss = 1.41031
I0802 03:58:51.519842 12219 solver.cpp:375]     Train net output #0: loss = 1.84641 (* 1 = 1.84641 loss)
I0802 03:58:51.519848 12219 sgd_solver.cpp:136] Iteration 302900, lr = 0.00534375, m = 0.9
I0802 03:59:05.653453 12219 solver.cpp:353] Iteration 303000 (7.07552 iter/s, 14.1332s/100 iter), loss = 1.14165
I0802 03:59:05.653544 12219 solver.cpp:375]     Train net output #0: loss = 1.06951 (* 1 = 1.06951 loss)
I0802 03:59:05.653570 12219 sgd_solver.cpp:136] Iteration 303000, lr = 0.0053125, m = 0.9
I0802 03:59:19.619120 12219 solver.cpp:353] Iteration 303100 (7.16061 iter/s, 13.9653s/100 iter), loss = 1.17484
I0802 03:59:19.619230 12219 solver.cpp:375]     Train net output #0: loss = 0.942386 (* 1 = 0.942386 loss)
I0802 03:59:19.619244 12219 sgd_solver.cpp:136] Iteration 303100, lr = 0.00528125, m = 0.9
I0802 03:59:33.658143 12219 solver.cpp:353] Iteration 303200 (7.1232 iter/s, 14.0386s/100 iter), loss = 1.33014
I0802 03:59:33.658171 12219 solver.cpp:375]     Train net output #0: loss = 1.28476 (* 1 = 1.28476 loss)
I0802 03:59:33.658177 12219 sgd_solver.cpp:136] Iteration 303200, lr = 0.00525, m = 0.9
I0802 03:59:47.640527 12219 solver.cpp:353] Iteration 303300 (7.15205 iter/s, 13.982s/100 iter), loss = 2.00074
I0802 03:59:47.640557 12219 solver.cpp:375]     Train net output #0: loss = 2.1155 (* 1 = 2.1155 loss)
I0802 03:59:47.640563 12219 sgd_solver.cpp:136] Iteration 303300, lr = 0.00521875, m = 0.9
I0802 04:00:01.621927 12219 solver.cpp:353] Iteration 303400 (7.15255 iter/s, 13.981s/100 iter), loss = 1.40404
I0802 04:00:01.621997 12219 solver.cpp:375]     Train net output #0: loss = 1.46775 (* 1 = 1.46775 loss)
I0802 04:00:01.622004 12219 sgd_solver.cpp:136] Iteration 303400, lr = 0.0051875, m = 0.9
I0802 04:00:15.768494 12219 solver.cpp:353] Iteration 303500 (7.06905 iter/s, 14.1462s/100 iter), loss = 1.6905
I0802 04:00:15.768524 12219 solver.cpp:375]     Train net output #0: loss = 1.62623 (* 1 = 1.62623 loss)
I0802 04:00:15.768530 12219 sgd_solver.cpp:136] Iteration 303500, lr = 0.00515625, m = 0.9
I0802 04:00:29.764477 12219 solver.cpp:353] Iteration 303600 (7.1451 iter/s, 13.9956s/100 iter), loss = 1.56416
I0802 04:00:29.764505 12219 solver.cpp:375]     Train net output #0: loss = 1.48604 (* 1 = 1.48604 loss)
I0802 04:00:29.764510 12219 sgd_solver.cpp:136] Iteration 303600, lr = 0.005125, m = 0.9
I0802 04:00:43.724061 12219 solver.cpp:353] Iteration 303700 (7.16373 iter/s, 13.9592s/100 iter), loss = 1.23007
I0802 04:00:43.724119 12219 solver.cpp:375]     Train net output #0: loss = 0.998628 (* 1 = 0.998628 loss)
I0802 04:00:43.724126 12219 sgd_solver.cpp:136] Iteration 303700, lr = 0.00509375, m = 0.9
I0802 04:00:57.748801 12219 solver.cpp:353] Iteration 303800 (7.13045 iter/s, 14.0244s/100 iter), loss = 1.40567
I0802 04:00:57.748829 12219 solver.cpp:375]     Train net output #0: loss = 1.52533 (* 1 = 1.52533 loss)
I0802 04:00:57.748869 12219 sgd_solver.cpp:136] Iteration 303800, lr = 0.0050625, m = 0.9
I0802 04:01:11.705454 12219 solver.cpp:353] Iteration 303900 (7.16524 iter/s, 13.9563s/100 iter), loss = 1.22443
I0802 04:01:11.705482 12219 solver.cpp:375]     Train net output #0: loss = 0.720992 (* 1 = 0.720992 loss)
I0802 04:01:11.705487 12219 sgd_solver.cpp:136] Iteration 303900, lr = 0.00503125, m = 0.9
I0802 04:01:25.672847 12219 solver.cpp:550] Iteration 304000, Testing net (#0)
I0802 04:01:45.682121 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.582471
I0802 04:01:45.682142 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.814056
I0802 04:01:45.682147 12219 solver.cpp:635]     Test net output #2: loss = 1.79229 (* 1 = 1.79229 loss)
I0802 04:01:45.682201 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.0088s
I0802 04:01:45.819797 12219 solver.cpp:353] Iteration 304000 (2.9314 iter/s, 34.1134s/100 iter), loss = 0.99058
I0802 04:01:45.819826 12219 solver.cpp:375]     Train net output #0: loss = 0.803757 (* 1 = 0.803757 loss)
I0802 04:01:45.819833 12219 sgd_solver.cpp:136] Iteration 304000, lr = 0.005, m = 0.9
I0802 04:01:59.877089 12219 solver.cpp:353] Iteration 304100 (7.11394 iter/s, 14.0569s/100 iter), loss = 1.55547
I0802 04:01:59.877156 12219 solver.cpp:375]     Train net output #0: loss = 1.67643 (* 1 = 1.67643 loss)
I0802 04:01:59.877162 12219 sgd_solver.cpp:136] Iteration 304100, lr = 0.00496875, m = 0.9
I0802 04:02:13.870429 12219 solver.cpp:353] Iteration 304200 (7.14645 iter/s, 13.993s/100 iter), loss = 1.24148
I0802 04:02:13.870457 12219 solver.cpp:375]     Train net output #0: loss = 1.15065 (* 1 = 1.15065 loss)
I0802 04:02:13.870463 12219 sgd_solver.cpp:136] Iteration 304200, lr = 0.0049375, m = 0.9
I0802 04:02:27.904896 12219 solver.cpp:353] Iteration 304300 (7.12551 iter/s, 14.0341s/100 iter), loss = 1.62266
I0802 04:02:27.904923 12219 solver.cpp:375]     Train net output #0: loss = 1.76121 (* 1 = 1.76121 loss)
I0802 04:02:27.904927 12219 sgd_solver.cpp:136] Iteration 304300, lr = 0.00490625, m = 0.9
I0802 04:02:42.015859 12219 solver.cpp:353] Iteration 304400 (7.08688 iter/s, 14.1106s/100 iter), loss = 1.33884
I0802 04:02:42.015936 12219 solver.cpp:375]     Train net output #0: loss = 1.33999 (* 1 = 1.33999 loss)
I0802 04:02:42.015944 12219 sgd_solver.cpp:136] Iteration 304400, lr = 0.004875, m = 0.9
I0802 04:02:56.204340 12219 solver.cpp:353] Iteration 304500 (7.04816 iter/s, 14.1881s/100 iter), loss = 1.42332
I0802 04:02:56.204368 12219 solver.cpp:375]     Train net output #0: loss = 1.14258 (* 1 = 1.14258 loss)
I0802 04:02:56.204375 12219 sgd_solver.cpp:136] Iteration 304500, lr = 0.00484375, m = 0.9
I0802 04:03:10.205441 12219 solver.cpp:353] Iteration 304600 (7.14249 iter/s, 14.0007s/100 iter), loss = 1.10069
I0802 04:03:10.205466 12219 solver.cpp:375]     Train net output #0: loss = 1.23334 (* 1 = 1.23334 loss)
I0802 04:03:10.205469 12219 sgd_solver.cpp:136] Iteration 304600, lr = 0.0048125, m = 0.9
I0802 04:03:24.144390 12219 solver.cpp:353] Iteration 304700 (7.17434 iter/s, 13.9386s/100 iter), loss = 1.41524
I0802 04:03:24.144448 12219 solver.cpp:375]     Train net output #0: loss = 1.52625 (* 1 = 1.52625 loss)
I0802 04:03:24.144454 12219 sgd_solver.cpp:136] Iteration 304700, lr = 0.00478125, m = 0.9
I0802 04:03:38.183676 12219 solver.cpp:353] Iteration 304800 (7.12306 iter/s, 14.0389s/100 iter), loss = 1.34082
I0802 04:03:38.183765 12219 solver.cpp:375]     Train net output #0: loss = 1.3895 (* 1 = 1.3895 loss)
I0802 04:03:38.183785 12219 sgd_solver.cpp:136] Iteration 304800, lr = 0.00475, m = 0.9
I0802 04:03:52.365298 12219 solver.cpp:353] Iteration 304900 (7.05157 iter/s, 14.1812s/100 iter), loss = 1.07488
I0802 04:03:52.365330 12219 solver.cpp:375]     Train net output #0: loss = 0.861437 (* 1 = 0.861437 loss)
I0802 04:03:52.365336 12219 sgd_solver.cpp:136] Iteration 304900, lr = 0.00471875, m = 0.9
I0802 04:04:06.390754 12219 solver.cpp:353] Iteration 305000 (7.13009 iter/s, 14.0251s/100 iter), loss = 0.94177
I0802 04:04:06.390854 12219 solver.cpp:375]     Train net output #0: loss = 0.899406 (* 1 = 0.899406 loss)
I0802 04:04:06.390867 12219 sgd_solver.cpp:136] Iteration 305000, lr = 0.0046875, m = 0.9
I0802 04:04:20.418933 12219 solver.cpp:353] Iteration 305100 (7.12872 iter/s, 14.0278s/100 iter), loss = 1.25693
I0802 04:04:20.419021 12219 solver.cpp:375]     Train net output #0: loss = 1.42933 (* 1 = 1.42933 loss)
I0802 04:04:20.419042 12219 sgd_solver.cpp:136] Iteration 305100, lr = 0.00465625, m = 0.9
I0802 04:04:34.471966 12219 solver.cpp:353] Iteration 305200 (7.11609 iter/s, 14.0527s/100 iter), loss = 1.07363
I0802 04:04:34.472014 12219 solver.cpp:375]     Train net output #0: loss = 0.887444 (* 1 = 0.887444 loss)
I0802 04:04:34.472024 12219 sgd_solver.cpp:136] Iteration 305200, lr = 0.004625, m = 0.9
I0802 04:04:48.607455 12219 solver.cpp:353] Iteration 305300 (7.07458 iter/s, 14.1351s/100 iter), loss = 1.1884
I0802 04:04:48.607553 12219 solver.cpp:375]     Train net output #0: loss = 1.29491 (* 1 = 1.29491 loss)
I0802 04:04:48.607573 12219 sgd_solver.cpp:136] Iteration 305300, lr = 0.00459375, m = 0.9
I0802 04:05:02.627179 12219 solver.cpp:353] Iteration 305400 (7.133 iter/s, 14.0193s/100 iter), loss = 1.34337
I0802 04:05:02.627210 12219 solver.cpp:375]     Train net output #0: loss = 1.26305 (* 1 = 1.26305 loss)
I0802 04:05:02.627218 12219 sgd_solver.cpp:136] Iteration 305400, lr = 0.0045625, m = 0.9
I0802 04:05:16.735381 12219 solver.cpp:353] Iteration 305500 (7.08827 iter/s, 14.1078s/100 iter), loss = 1.48866
I0802 04:05:16.735404 12219 solver.cpp:375]     Train net output #0: loss = 1.02663 (* 1 = 1.02663 loss)
I0802 04:05:16.735409 12219 sgd_solver.cpp:136] Iteration 305500, lr = 0.00453125, m = 0.9
I0802 04:05:30.746727 12219 solver.cpp:353] Iteration 305600 (7.13727 iter/s, 14.011s/100 iter), loss = 1.60545
I0802 04:05:30.746795 12219 solver.cpp:375]     Train net output #0: loss = 1.75199 (* 1 = 1.75199 loss)
I0802 04:05:30.746800 12219 sgd_solver.cpp:136] Iteration 305600, lr = 0.0045, m = 0.9
I0802 04:05:44.715579 12219 solver.cpp:353] Iteration 305700 (7.15898 iter/s, 13.9685s/100 iter), loss = 1.13266
I0802 04:05:44.715603 12219 solver.cpp:375]     Train net output #0: loss = 1.19414 (* 1 = 1.19414 loss)
I0802 04:05:44.715610 12219 sgd_solver.cpp:136] Iteration 305700, lr = 0.00446875, m = 0.9
I0802 04:05:58.845824 12219 solver.cpp:353] Iteration 305800 (7.07721 iter/s, 14.1299s/100 iter), loss = 1.344
I0802 04:05:58.845850 12219 solver.cpp:375]     Train net output #0: loss = 1.65114 (* 1 = 1.65114 loss)
I0802 04:05:58.845856 12219 sgd_solver.cpp:136] Iteration 305800, lr = 0.0044375, m = 0.9
I0802 04:06:12.899727 12219 solver.cpp:353] Iteration 305900 (7.11565 iter/s, 14.0535s/100 iter), loss = 1.50669
I0802 04:06:12.899847 12219 solver.cpp:375]     Train net output #0: loss = 1.29232 (* 1 = 1.29232 loss)
I0802 04:06:12.899866 12219 sgd_solver.cpp:136] Iteration 305900, lr = 0.00440625, m = 0.9
I0802 04:06:26.855100 12219 solver.cpp:550] Iteration 306000, Testing net (#0)
I0802 04:06:46.859511 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587117
I0802 04:06:46.859599 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.815467
I0802 04:06:46.859608 12219 solver.cpp:635]     Test net output #2: loss = 1.78881 (* 1 = 1.78881 loss)
I0802 04:06:46.859628 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.004s
I0802 04:06:47.003379 12219 solver.cpp:353] Iteration 306000 (2.93232 iter/s, 34.1027s/100 iter), loss = 1.42859
I0802 04:06:47.003409 12219 solver.cpp:375]     Train net output #0: loss = 1.55108 (* 1 = 1.55108 loss)
I0802 04:06:47.003415 12219 sgd_solver.cpp:136] Iteration 306000, lr = 0.004375, m = 0.9
I0802 04:07:01.063757 12219 solver.cpp:353] Iteration 306100 (7.11238 iter/s, 14.06s/100 iter), loss = 1.31409
I0802 04:07:01.063807 12219 solver.cpp:375]     Train net output #0: loss = 1.27106 (* 1 = 1.27106 loss)
I0802 04:07:01.063819 12219 sgd_solver.cpp:136] Iteration 306100, lr = 0.00434375, m = 0.9
I0802 04:07:15.065811 12219 solver.cpp:353] Iteration 306200 (7.142 iter/s, 14.0017s/100 iter), loss = 1.27764
I0802 04:07:15.065838 12219 solver.cpp:375]     Train net output #0: loss = 1.333 (* 1 = 1.333 loss)
I0802 04:07:15.065845 12219 sgd_solver.cpp:136] Iteration 306200, lr = 0.0043125, m = 0.9
I0802 04:07:29.135278 12219 solver.cpp:353] Iteration 306300 (7.10778 iter/s, 14.0691s/100 iter), loss = 1.34278
I0802 04:07:29.135344 12219 solver.cpp:375]     Train net output #0: loss = 1.53377 (* 1 = 1.53377 loss)
I0802 04:07:29.135354 12219 sgd_solver.cpp:136] Iteration 306300, lr = 0.00428125, m = 0.9
I0802 04:07:43.150862 12219 solver.cpp:353] Iteration 306400 (7.13511 iter/s, 14.0152s/100 iter), loss = 1.24354
I0802 04:07:43.150889 12219 solver.cpp:375]     Train net output #0: loss = 1.44285 (* 1 = 1.44285 loss)
I0802 04:07:43.150893 12219 sgd_solver.cpp:136] Iteration 306400, lr = 0.00425, m = 0.9
I0802 04:07:57.167825 12219 solver.cpp:353] Iteration 306500 (7.1344 iter/s, 14.0166s/100 iter), loss = 1.03089
I0802 04:07:57.167853 12219 solver.cpp:375]     Train net output #0: loss = 0.871922 (* 1 = 0.871922 loss)
I0802 04:07:57.167860 12219 sgd_solver.cpp:136] Iteration 306500, lr = 0.00421875, m = 0.9
I0802 04:08:11.172879 12219 solver.cpp:353] Iteration 306600 (7.14047 iter/s, 14.0047s/100 iter), loss = 1.66083
I0802 04:08:11.172935 12219 solver.cpp:375]     Train net output #0: loss = 1.7034 (* 1 = 1.7034 loss)
I0802 04:08:11.172941 12219 sgd_solver.cpp:136] Iteration 306600, lr = 0.0041875, m = 0.9
I0802 04:08:25.261476 12219 solver.cpp:353] Iteration 306700 (7.09813 iter/s, 14.0882s/100 iter), loss = 1.25231
I0802 04:08:25.261504 12219 solver.cpp:375]     Train net output #0: loss = 1.48942 (* 1 = 1.48942 loss)
I0802 04:08:25.261508 12219 sgd_solver.cpp:136] Iteration 306700, lr = 0.00415625, m = 0.9
I0802 04:08:39.334460 12219 solver.cpp:353] Iteration 306800 (7.10601 iter/s, 14.0726s/100 iter), loss = 1.52422
I0802 04:08:39.334583 12219 solver.cpp:375]     Train net output #0: loss = 1.43587 (* 1 = 1.43587 loss)
I0802 04:08:39.334604 12219 sgd_solver.cpp:136] Iteration 306800, lr = 0.004125, m = 0.9
I0802 04:08:53.424182 12219 solver.cpp:353] Iteration 306900 (7.09756 iter/s, 14.0893s/100 iter), loss = 1.2569
I0802 04:08:53.424278 12219 solver.cpp:375]     Train net output #0: loss = 1.33834 (* 1 = 1.33834 loss)
I0802 04:08:53.424285 12219 sgd_solver.cpp:136] Iteration 306900, lr = 0.00409375, m = 0.9
I0802 04:09:07.376503 12219 solver.cpp:353] Iteration 307000 (7.16746 iter/s, 13.9519s/100 iter), loss = 1.3171
I0802 04:09:07.376529 12219 solver.cpp:375]     Train net output #0: loss = 0.963978 (* 1 = 0.963978 loss)
I0802 04:09:07.376535 12219 sgd_solver.cpp:136] Iteration 307000, lr = 0.0040625, m = 0.9
I0802 04:09:21.452833 12219 solver.cpp:353] Iteration 307100 (7.10432 iter/s, 14.0759s/100 iter), loss = 1.80315
I0802 04:09:21.452867 12219 solver.cpp:375]     Train net output #0: loss = 1.46685 (* 1 = 1.46685 loss)
I0802 04:09:21.452875 12219 sgd_solver.cpp:136] Iteration 307100, lr = 0.00403125, m = 0.9
I0802 04:09:35.487375 12219 solver.cpp:353] Iteration 307200 (7.12547 iter/s, 14.0342s/100 iter), loss = 1.50327
I0802 04:09:35.487709 12219 solver.cpp:375]     Train net output #0: loss = 1.76103 (* 1 = 1.76103 loss)
I0802 04:09:35.487715 12219 sgd_solver.cpp:136] Iteration 307200, lr = 0.004, m = 0.9
I0802 04:09:49.566577 12219 solver.cpp:353] Iteration 307300 (7.10287 iter/s, 14.0788s/100 iter), loss = 1.21925
I0802 04:09:49.566604 12219 solver.cpp:375]     Train net output #0: loss = 0.981725 (* 1 = 0.981725 loss)
I0802 04:09:49.566609 12219 sgd_solver.cpp:136] Iteration 307300, lr = 0.00396875, m = 0.9
I0802 04:10:03.662842 12219 solver.cpp:353] Iteration 307400 (7.09427 iter/s, 14.0959s/100 iter), loss = 1.18695
I0802 04:10:03.662870 12219 solver.cpp:375]     Train net output #0: loss = 1.51737 (* 1 = 1.51737 loss)
I0802 04:10:03.662875 12219 sgd_solver.cpp:136] Iteration 307400, lr = 0.0039375, m = 0.9
I0802 04:10:17.679201 12219 solver.cpp:353] Iteration 307500 (7.13471 iter/s, 14.016s/100 iter), loss = 1.08709
I0802 04:10:17.679314 12219 solver.cpp:375]     Train net output #0: loss = 1.30691 (* 1 = 1.30691 loss)
I0802 04:10:17.679333 12219 sgd_solver.cpp:136] Iteration 307500, lr = 0.00390625, m = 0.9
I0802 04:10:31.638178 12219 solver.cpp:353] Iteration 307600 (7.16404 iter/s, 13.9586s/100 iter), loss = 1.27614
I0802 04:10:31.638206 12219 solver.cpp:375]     Train net output #0: loss = 1.16824 (* 1 = 1.16824 loss)
I0802 04:10:31.638211 12219 sgd_solver.cpp:136] Iteration 307600, lr = 0.003875, m = 0.9
I0802 04:10:45.547186 12219 solver.cpp:353] Iteration 307700 (7.18978 iter/s, 13.9086s/100 iter), loss = 1.29497
I0802 04:10:45.547210 12219 solver.cpp:375]     Train net output #0: loss = 0.940898 (* 1 = 0.940898 loss)
I0802 04:10:45.547214 12219 sgd_solver.cpp:136] Iteration 307700, lr = 0.00384375, m = 0.9
I0802 04:10:59.614871 12219 solver.cpp:353] Iteration 307800 (7.10869 iter/s, 14.0673s/100 iter), loss = 1.11956
I0802 04:10:59.614954 12219 solver.cpp:375]     Train net output #0: loss = 0.979071 (* 1 = 0.979071 loss)
I0802 04:10:59.614962 12219 sgd_solver.cpp:136] Iteration 307800, lr = 0.0038125, m = 0.9
I0802 04:11:13.547343 12219 solver.cpp:353] Iteration 307900 (7.17767 iter/s, 13.9321s/100 iter), loss = 1.50232
I0802 04:11:13.547369 12219 solver.cpp:375]     Train net output #0: loss = 1.45562 (* 1 = 1.45562 loss)
I0802 04:11:13.547374 12219 sgd_solver.cpp:136] Iteration 307900, lr = 0.00378125, m = 0.9
I0802 04:11:27.334830 12219 solver.cpp:550] Iteration 308000, Testing net (#0)
I0802 04:11:38.542771 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 04:11:47.156509 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587647
I0802 04:11:47.156536 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816938
I0802 04:11:47.156543 12219 solver.cpp:635]     Test net output #2: loss = 1.78002 (* 1 = 1.78002 loss)
I0802 04:11:47.156563 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8212s
I0802 04:11:47.301831 12219 solver.cpp:353] Iteration 308000 (2.96265 iter/s, 33.7536s/100 iter), loss = 1.10023
I0802 04:11:47.301873 12219 solver.cpp:375]     Train net output #0: loss = 1.15367 (* 1 = 1.15367 loss)
I0802 04:11:47.301880 12219 sgd_solver.cpp:136] Iteration 308000, lr = 0.00375, m = 0.9
I0802 04:12:01.241659 12219 solver.cpp:353] Iteration 308100 (7.17388 iter/s, 13.9395s/100 iter), loss = 1.0729
I0802 04:12:01.241693 12219 solver.cpp:375]     Train net output #0: loss = 1.22654 (* 1 = 1.22654 loss)
I0802 04:12:01.241698 12219 sgd_solver.cpp:136] Iteration 308100, lr = 0.00371875, m = 0.9
I0802 04:12:15.241957 12219 solver.cpp:353] Iteration 308200 (7.1429 iter/s, 13.9999s/100 iter), loss = 1.34227
I0802 04:12:15.242074 12219 solver.cpp:375]     Train net output #0: loss = 1.11552 (* 1 = 1.11552 loss)
I0802 04:12:15.242081 12219 sgd_solver.cpp:136] Iteration 308200, lr = 0.0036875, m = 0.9
I0802 04:12:29.130990 12219 solver.cpp:353] Iteration 308300 (7.20012 iter/s, 13.8887s/100 iter), loss = 1.14285
I0802 04:12:29.131014 12219 solver.cpp:375]     Train net output #0: loss = 1.07486 (* 1 = 1.07486 loss)
I0802 04:12:29.131018 12219 sgd_solver.cpp:136] Iteration 308300, lr = 0.00365625, m = 0.9
I0802 04:12:43.097837 12219 solver.cpp:353] Iteration 308400 (7.16001 iter/s, 13.9665s/100 iter), loss = 0.890444
I0802 04:12:43.097862 12219 solver.cpp:375]     Train net output #0: loss = 0.7635 (* 1 = 0.7635 loss)
I0802 04:12:43.097868 12219 sgd_solver.cpp:136] Iteration 308400, lr = 0.003625, m = 0.9
I0802 04:12:57.054386 12219 solver.cpp:353] Iteration 308500 (7.16529 iter/s, 13.9562s/100 iter), loss = 1.4696
I0802 04:12:57.054450 12219 solver.cpp:375]     Train net output #0: loss = 1.14242 (* 1 = 1.14242 loss)
I0802 04:12:57.054456 12219 sgd_solver.cpp:136] Iteration 308500, lr = 0.00359375, m = 0.9
I0802 04:13:11.022471 12219 solver.cpp:353] Iteration 308600 (7.15937 iter/s, 13.9677s/100 iter), loss = 1.48539
I0802 04:13:11.022506 12219 solver.cpp:375]     Train net output #0: loss = 1.66568 (* 1 = 1.66568 loss)
I0802 04:13:11.022512 12219 sgd_solver.cpp:136] Iteration 308600, lr = 0.0035625, m = 0.9
I0802 04:13:24.958107 12219 solver.cpp:353] Iteration 308700 (7.17604 iter/s, 13.9353s/100 iter), loss = 1.19365
I0802 04:13:24.958137 12219 solver.cpp:375]     Train net output #0: loss = 1.2805 (* 1 = 1.2805 loss)
I0802 04:13:24.958142 12219 sgd_solver.cpp:136] Iteration 308700, lr = 0.00353125, m = 0.9
I0802 04:13:38.916518 12219 solver.cpp:353] Iteration 308800 (7.16433 iter/s, 13.958s/100 iter), loss = 1.79239
I0802 04:13:38.916589 12219 solver.cpp:375]     Train net output #0: loss = 2.07546 (* 1 = 2.07546 loss)
I0802 04:13:38.916597 12219 sgd_solver.cpp:136] Iteration 308800, lr = 0.0035, m = 0.9
I0802 04:13:52.840567 12219 solver.cpp:353] Iteration 308900 (7.18201 iter/s, 13.9237s/100 iter), loss = 1.51477
I0802 04:13:52.840592 12219 solver.cpp:375]     Train net output #0: loss = 1.58291 (* 1 = 1.58291 loss)
I0802 04:13:52.840598 12219 sgd_solver.cpp:136] Iteration 308900, lr = 0.00346875, m = 0.9
I0802 04:14:06.932302 12219 solver.cpp:353] Iteration 309000 (7.09655 iter/s, 14.0914s/100 iter), loss = 1.24678
I0802 04:14:06.932327 12219 solver.cpp:375]     Train net output #0: loss = 1.11724 (* 1 = 1.11724 loss)
I0802 04:14:06.932333 12219 sgd_solver.cpp:136] Iteration 309000, lr = 0.0034375, m = 0.9
I0802 04:14:20.976747 12219 solver.cpp:353] Iteration 309100 (7.12044 iter/s, 14.0441s/100 iter), loss = 1.41873
I0802 04:14:20.976807 12219 solver.cpp:375]     Train net output #0: loss = 1.61154 (* 1 = 1.61154 loss)
I0802 04:14:20.976817 12219 sgd_solver.cpp:136] Iteration 309100, lr = 0.00340625, m = 0.9
I0802 04:14:35.036178 12219 solver.cpp:353] Iteration 309200 (7.11286 iter/s, 14.0591s/100 iter), loss = 1.75649
I0802 04:14:35.036206 12219 solver.cpp:375]     Train net output #0: loss = 1.90455 (* 1 = 1.90455 loss)
I0802 04:14:35.036213 12219 sgd_solver.cpp:136] Iteration 309200, lr = 0.003375, m = 0.9
I0802 04:14:49.080826 12219 solver.cpp:353] Iteration 309300 (7.12035 iter/s, 14.0443s/100 iter), loss = 1.39879
I0802 04:14:49.080914 12219 solver.cpp:375]     Train net output #0: loss = 1.67781 (* 1 = 1.67781 loss)
I0802 04:14:49.080936 12219 sgd_solver.cpp:136] Iteration 309300, lr = 0.00334375, m = 0.9
I0802 04:15:03.104302 12219 solver.cpp:353] Iteration 309400 (7.13108 iter/s, 14.0231s/100 iter), loss = 1.34354
I0802 04:15:03.108883 12219 solver.cpp:375]     Train net output #0: loss = 1.2892 (* 1 = 1.2892 loss)
I0802 04:15:03.108906 12219 sgd_solver.cpp:136] Iteration 309400, lr = 0.0033125, m = 0.9
I0802 04:15:17.140053 12219 solver.cpp:353] Iteration 309500 (7.12486 iter/s, 14.0354s/100 iter), loss = 1.27961
I0802 04:15:17.140082 12219 solver.cpp:375]     Train net output #0: loss = 1.17943 (* 1 = 1.17943 loss)
I0802 04:15:17.140089 12219 sgd_solver.cpp:136] Iteration 309500, lr = 0.00328125, m = 0.9
I0802 04:15:31.155855 12219 solver.cpp:353] Iteration 309600 (7.135 iter/s, 14.0154s/100 iter), loss = 1.36566
I0802 04:15:31.155901 12219 solver.cpp:375]     Train net output #0: loss = 1.3893 (* 1 = 1.3893 loss)
I0802 04:15:31.155925 12219 sgd_solver.cpp:136] Iteration 309600, lr = 0.00325, m = 0.9
I0802 04:15:45.242745 12219 solver.cpp:353] Iteration 309700 (7.09899 iter/s, 14.0865s/100 iter), loss = 1.33332
I0802 04:15:45.242808 12219 solver.cpp:375]     Train net output #0: loss = 1.64921 (* 1 = 1.64921 loss)
I0802 04:15:45.242815 12219 sgd_solver.cpp:136] Iteration 309700, lr = 0.00321875, m = 0.9
I0802 04:15:59.340806 12219 solver.cpp:353] Iteration 309800 (7.09337 iter/s, 14.0977s/100 iter), loss = 1.48691
I0802 04:15:59.340855 12219 solver.cpp:375]     Train net output #0: loss = 1.43361 (* 1 = 1.43361 loss)
I0802 04:15:59.340865 12219 sgd_solver.cpp:136] Iteration 309800, lr = 0.0031875, m = 0.9
I0802 04:16:13.319591 12219 solver.cpp:353] Iteration 309900 (7.15389 iter/s, 13.9784s/100 iter), loss = 1.30381
I0802 04:16:13.319871 12219 solver.cpp:375]     Train net output #0: loss = 1.02992 (* 1 = 1.02992 loss)
I0802 04:16:13.319986 12219 sgd_solver.cpp:136] Iteration 309900, lr = 0.00315625, m = 0.9
I0802 04:16:27.191330 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_310000.caffemodel
I0802 04:16:27.231128 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_310000.solverstate
I0802 04:16:27.237206 12219 solver.cpp:550] Iteration 310000, Testing net (#0)
I0802 04:16:47.550019 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.59847
I0802 04:16:47.550037 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.82035
I0802 04:16:47.550042 12219 solver.cpp:635]     Test net output #2: loss = 1.74437 (* 1 = 1.74437 loss)
I0802 04:16:47.550063 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3123s
I0802 04:16:47.701019 12219 solver.cpp:353] Iteration 310000 (2.90862 iter/s, 34.3805s/100 iter), loss = 1.32957
I0802 04:16:47.701189 12219 solver.cpp:375]     Train net output #0: loss = 1.75731 (* 1 = 1.75731 loss)
I0802 04:16:47.701206 12219 sgd_solver.cpp:136] Iteration 310000, lr = 0.003125, m = 0.9
I0802 04:17:01.765197 12219 solver.cpp:353] Iteration 310100 (7.11046 iter/s, 14.0638s/100 iter), loss = 1.87656
I0802 04:17:01.765257 12219 solver.cpp:375]     Train net output #0: loss = 2.01544 (* 1 = 2.01544 loss)
I0802 04:17:01.765264 12219 sgd_solver.cpp:136] Iteration 310100, lr = 0.00309375, m = 0.9
I0802 04:17:15.776365 12219 solver.cpp:353] Iteration 310200 (7.13736 iter/s, 14.0108s/100 iter), loss = 1.40985
I0802 04:17:15.776391 12219 solver.cpp:375]     Train net output #0: loss = 1.53104 (* 1 = 1.53104 loss)
I0802 04:17:15.776396 12219 sgd_solver.cpp:136] Iteration 310200, lr = 0.0030625, m = 0.9
I0802 04:17:29.792943 12219 solver.cpp:353] Iteration 310300 (7.13461 iter/s, 14.0162s/100 iter), loss = 1.3028
I0802 04:17:29.792973 12219 solver.cpp:375]     Train net output #0: loss = 1.11664 (* 1 = 1.11664 loss)
I0802 04:17:29.792979 12219 sgd_solver.cpp:136] Iteration 310300, lr = 0.00303125, m = 0.9
I0802 04:17:43.848812 12219 solver.cpp:353] Iteration 310400 (7.11466 iter/s, 14.0555s/100 iter), loss = 1.14491
I0802 04:17:43.848959 12219 solver.cpp:375]     Train net output #0: loss = 1.1804 (* 1 = 1.1804 loss)
I0802 04:17:43.848980 12219 sgd_solver.cpp:136] Iteration 310400, lr = 0.003, m = 0.9
I0802 04:17:57.973839 12219 solver.cpp:353] Iteration 310500 (7.07982 iter/s, 14.1246s/100 iter), loss = 1.49834
I0802 04:17:57.973863 12219 solver.cpp:375]     Train net output #0: loss = 1.08717 (* 1 = 1.08717 loss)
I0802 04:17:57.973867 12219 sgd_solver.cpp:136] Iteration 310500, lr = 0.00296875, m = 0.9
I0802 04:18:12.112713 12219 solver.cpp:353] Iteration 310600 (7.07289 iter/s, 14.1385s/100 iter), loss = 1.48328
I0802 04:18:12.112802 12219 solver.cpp:375]     Train net output #0: loss = 1.75682 (* 1 = 1.75682 loss)
I0802 04:18:12.112828 12219 sgd_solver.cpp:136] Iteration 310600, lr = 0.0029375, m = 0.9
I0802 04:18:26.124387 12219 solver.cpp:353] Iteration 310700 (7.1371 iter/s, 14.0113s/100 iter), loss = 1.29394
I0802 04:18:26.124461 12219 solver.cpp:375]     Train net output #0: loss = 0.985022 (* 1 = 0.985022 loss)
I0802 04:18:26.124500 12219 sgd_solver.cpp:136] Iteration 310700, lr = 0.00290625, m = 0.9
I0802 04:18:40.175746 12219 solver.cpp:353] Iteration 310800 (7.11694 iter/s, 14.051s/100 iter), loss = 1.43932
I0802 04:18:40.175894 12219 solver.cpp:375]     Train net output #0: loss = 1.38992 (* 1 = 1.38992 loss)
I0802 04:18:40.175909 12219 sgd_solver.cpp:136] Iteration 310800, lr = 0.002875, m = 0.9
I0802 04:18:54.112486 12219 solver.cpp:353] Iteration 310900 (7.17547 iter/s, 13.9364s/100 iter), loss = 1.26503
I0802 04:18:54.112514 12219 solver.cpp:375]     Train net output #0: loss = 1.38596 (* 1 = 1.38596 loss)
I0802 04:18:54.112520 12219 sgd_solver.cpp:136] Iteration 310900, lr = 0.00284375, m = 0.9
I0802 04:19:08.185185 12219 solver.cpp:353] Iteration 311000 (7.10615 iter/s, 14.0723s/100 iter), loss = 1.14969
I0802 04:19:08.185236 12219 solver.cpp:375]     Train net output #0: loss = 0.988528 (* 1 = 0.988528 loss)
I0802 04:19:08.185241 12219 sgd_solver.cpp:136] Iteration 311000, lr = 0.0028125, m = 0.9
I0802 04:19:22.283031 12219 solver.cpp:353] Iteration 311100 (7.09347 iter/s, 14.0975s/100 iter), loss = 1.32106
I0802 04:19:22.283059 12219 solver.cpp:375]     Train net output #0: loss = 1.44926 (* 1 = 1.44926 loss)
I0802 04:19:22.283063 12219 sgd_solver.cpp:136] Iteration 311100, lr = 0.00278125, m = 0.9
I0802 04:19:36.329460 12219 solver.cpp:353] Iteration 311200 (7.11944 iter/s, 14.0461s/100 iter), loss = 1.43035
I0802 04:19:36.329488 12219 solver.cpp:375]     Train net output #0: loss = 1.12361 (* 1 = 1.12361 loss)
I0802 04:19:36.329494 12219 sgd_solver.cpp:136] Iteration 311200, lr = 0.00275, m = 0.9
I0802 04:19:50.342808 12219 solver.cpp:353] Iteration 311300 (7.13625 iter/s, 14.013s/100 iter), loss = 1.30747
I0802 04:19:50.342919 12219 solver.cpp:375]     Train net output #0: loss = 1.4409 (* 1 = 1.4409 loss)
I0802 04:19:50.342933 12219 sgd_solver.cpp:136] Iteration 311300, lr = 0.00271875, m = 0.9
I0802 04:20:04.453151 12219 solver.cpp:353] Iteration 311400 (7.08719 iter/s, 14.11s/100 iter), loss = 1.25598
I0802 04:20:04.453181 12219 solver.cpp:375]     Train net output #0: loss = 1.38008 (* 1 = 1.38008 loss)
I0802 04:20:04.453188 12219 sgd_solver.cpp:136] Iteration 311400, lr = 0.0026875, m = 0.9
I0802 04:20:18.553124 12219 solver.cpp:353] Iteration 311500 (7.0924 iter/s, 14.0996s/100 iter), loss = 1.43443
I0802 04:20:18.553156 12219 solver.cpp:375]     Train net output #0: loss = 1.25998 (* 1 = 1.25998 loss)
I0802 04:20:18.553162 12219 sgd_solver.cpp:136] Iteration 311500, lr = 0.00265625, m = 0.9
I0802 04:20:32.559186 12219 solver.cpp:353] Iteration 311600 (7.13996 iter/s, 14.0057s/100 iter), loss = 1.21357
I0802 04:20:32.559250 12219 solver.cpp:375]     Train net output #0: loss = 1.23741 (* 1 = 1.23741 loss)
I0802 04:20:32.559257 12219 sgd_solver.cpp:136] Iteration 311600, lr = 0.002625, m = 0.9
I0802 04:20:46.597352 12219 solver.cpp:353] Iteration 311700 (7.12363 iter/s, 14.0378s/100 iter), loss = 1.71664
I0802 04:20:46.597443 12219 solver.cpp:375]     Train net output #0: loss = 2.13168 (* 1 = 2.13168 loss)
I0802 04:20:46.597465 12219 sgd_solver.cpp:136] Iteration 311700, lr = 0.00259375, m = 0.9
I0802 04:21:00.625653 12219 solver.cpp:353] Iteration 311800 (7.12864 iter/s, 14.0279s/100 iter), loss = 0.91841
I0802 04:21:00.625679 12219 solver.cpp:375]     Train net output #0: loss = 0.906455 (* 1 = 0.906455 loss)
I0802 04:21:00.625684 12219 sgd_solver.cpp:136] Iteration 311800, lr = 0.0025625, m = 0.9
I0802 04:21:14.686084 12219 solver.cpp:353] Iteration 311900 (7.11235 iter/s, 14.06s/100 iter), loss = 1.41568
I0802 04:21:14.686195 12219 solver.cpp:375]     Train net output #0: loss = 1.53391 (* 1 = 1.53391 loss)
I0802 04:21:14.686218 12219 sgd_solver.cpp:136] Iteration 311900, lr = 0.00253125, m = 0.9
I0802 04:21:28.635424 12219 solver.cpp:550] Iteration 312000, Testing net (#0)
I0802 04:21:45.303902 12207 data_reader.cpp:264] Starting prefetch of epoch 18
I0802 04:21:48.463346 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.594176
I0802 04:21:48.463369 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821233
I0802 04:21:48.463376 12219 solver.cpp:635]     Test net output #2: loss = 1.74599 (* 1 = 1.74599 loss)
I0802 04:21:48.463466 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.8275s
I0802 04:21:48.601303 12219 solver.cpp:353] Iteration 312000 (2.94861 iter/s, 33.9143s/100 iter), loss = 1.75509
I0802 04:21:48.601327 12219 solver.cpp:375]     Train net output #0: loss = 1.67241 (* 1 = 1.67241 loss)
I0802 04:21:48.601333 12219 sgd_solver.cpp:136] Iteration 312000, lr = 0.0025, m = 0.9
I0802 04:22:02.602509 12219 solver.cpp:353] Iteration 312100 (7.14244 iter/s, 14.0008s/100 iter), loss = 1.14925
I0802 04:22:02.602543 12219 solver.cpp:375]     Train net output #0: loss = 0.928282 (* 1 = 0.928282 loss)
I0802 04:22:02.602550 12219 sgd_solver.cpp:136] Iteration 312100, lr = 0.00246875, m = 0.9
I0802 04:22:16.805032 12219 solver.cpp:353] Iteration 312200 (7.04119 iter/s, 14.2021s/100 iter), loss = 1.39269
I0802 04:22:16.805090 12219 solver.cpp:375]     Train net output #0: loss = 1.64951 (* 1 = 1.64951 loss)
I0802 04:22:16.805099 12219 sgd_solver.cpp:136] Iteration 312200, lr = 0.0024375, m = 0.9
I0802 04:22:30.837721 12219 solver.cpp:353] Iteration 312300 (7.12641 iter/s, 14.0323s/100 iter), loss = 1.37278
I0802 04:22:30.837750 12219 solver.cpp:375]     Train net output #0: loss = 1.24313 (* 1 = 1.24313 loss)
I0802 04:22:30.837757 12219 sgd_solver.cpp:136] Iteration 312300, lr = 0.00240625, m = 0.9
I0802 04:22:44.929159 12219 solver.cpp:353] Iteration 312400 (7.09671 iter/s, 14.091s/100 iter), loss = 1.16973
I0802 04:22:44.929214 12219 solver.cpp:375]     Train net output #0: loss = 1.24999 (* 1 = 1.24999 loss)
I0802 04:22:44.929225 12219 sgd_solver.cpp:136] Iteration 312400, lr = 0.002375, m = 0.9
I0802 04:22:58.903040 12219 solver.cpp:353] Iteration 312500 (7.1564 iter/s, 13.9735s/100 iter), loss = 1.16228
I0802 04:22:58.903112 12219 solver.cpp:375]     Train net output #0: loss = 1.02586 (* 1 = 1.02586 loss)
I0802 04:22:58.903120 12219 sgd_solver.cpp:136] Iteration 312500, lr = 0.00234375, m = 0.9
I0802 04:23:12.972769 12219 solver.cpp:353] Iteration 312600 (7.10765 iter/s, 14.0693s/100 iter), loss = 0.880809
I0802 04:23:12.972831 12219 solver.cpp:375]     Train net output #0: loss = 0.852398 (* 1 = 0.852398 loss)
I0802 04:23:12.972844 12219 sgd_solver.cpp:136] Iteration 312600, lr = 0.0023125, m = 0.9
I0802 04:23:26.991541 12219 solver.cpp:353] Iteration 312700 (7.13348 iter/s, 14.0184s/100 iter), loss = 1.18897
I0802 04:23:26.991567 12219 solver.cpp:375]     Train net output #0: loss = 0.820719 (* 1 = 0.820719 loss)
I0802 04:23:26.991572 12219 sgd_solver.cpp:136] Iteration 312700, lr = 0.00228125, m = 0.9
I0802 04:23:40.976698 12219 solver.cpp:353] Iteration 312800 (7.15063 iter/s, 13.9848s/100 iter), loss = 1.24518
I0802 04:23:40.976768 12219 solver.cpp:375]     Train net output #0: loss = 1.25664 (* 1 = 1.25664 loss)
I0802 04:23:40.976775 12219 sgd_solver.cpp:136] Iteration 312800, lr = 0.00225, m = 0.9
I0802 04:23:55.069161 12219 solver.cpp:353] Iteration 312900 (7.09618 iter/s, 14.0921s/100 iter), loss = 1.05184
I0802 04:23:55.069188 12219 solver.cpp:375]     Train net output #0: loss = 0.865127 (* 1 = 0.865127 loss)
I0802 04:23:55.069193 12219 sgd_solver.cpp:136] Iteration 312900, lr = 0.00221875, m = 0.9
I0802 04:24:09.050488 12219 solver.cpp:353] Iteration 313000 (7.15259 iter/s, 13.9809s/100 iter), loss = 1.20265
I0802 04:24:09.050513 12219 solver.cpp:375]     Train net output #0: loss = 0.997083 (* 1 = 0.997083 loss)
I0802 04:24:09.050519 12219 sgd_solver.cpp:136] Iteration 313000, lr = 0.0021875, m = 0.9
I0802 04:24:23.110216 12219 solver.cpp:353] Iteration 313100 (7.1127 iter/s, 14.0593s/100 iter), loss = 1.12
I0802 04:24:23.110276 12219 solver.cpp:375]     Train net output #0: loss = 1.29452 (* 1 = 1.29452 loss)
I0802 04:24:23.110283 12219 sgd_solver.cpp:136] Iteration 313100, lr = 0.00215625, m = 0.9
I0802 04:24:37.153858 12219 solver.cpp:353] Iteration 313200 (7.12085 iter/s, 14.0433s/100 iter), loss = 1.20707
I0802 04:24:37.153910 12219 solver.cpp:375]     Train net output #0: loss = 1.17769 (* 1 = 1.17769 loss)
I0802 04:24:37.153926 12219 sgd_solver.cpp:136] Iteration 313200, lr = 0.002125, m = 0.9
I0802 04:24:51.172724 12219 solver.cpp:353] Iteration 313300 (7.13344 iter/s, 14.0185s/100 iter), loss = 1.30088
I0802 04:24:51.172930 12219 solver.cpp:375]     Train net output #0: loss = 1.20752 (* 1 = 1.20752 loss)
I0802 04:24:51.173010 12219 sgd_solver.cpp:136] Iteration 313300, lr = 0.00209375, m = 0.9
I0802 04:25:05.300181 12219 solver.cpp:353] Iteration 313400 (7.07861 iter/s, 14.1271s/100 iter), loss = 1.55629
I0802 04:25:05.300261 12219 solver.cpp:375]     Train net output #0: loss = 1.67965 (* 1 = 1.67965 loss)
I0802 04:25:05.300273 12219 sgd_solver.cpp:136] Iteration 313400, lr = 0.0020625, m = 0.9
I0802 04:25:19.275833 12219 solver.cpp:353] Iteration 313500 (7.15549 iter/s, 13.9753s/100 iter), loss = 1.16984
I0802 04:25:19.275857 12219 solver.cpp:375]     Train net output #0: loss = 1.08799 (* 1 = 1.08799 loss)
I0802 04:25:19.275861 12219 sgd_solver.cpp:136] Iteration 313500, lr = 0.00203125, m = 0.9
I0802 04:25:33.345962 12219 solver.cpp:353] Iteration 313600 (7.10745 iter/s, 14.0697s/100 iter), loss = 1.06167
I0802 04:25:33.345989 12219 solver.cpp:375]     Train net output #0: loss = 0.958226 (* 1 = 0.958226 loss)
I0802 04:25:33.345995 12219 sgd_solver.cpp:136] Iteration 313600, lr = 0.002, m = 0.9
I0802 04:25:47.411914 12219 solver.cpp:353] Iteration 313700 (7.10956 iter/s, 14.0656s/100 iter), loss = 1.30528
I0802 04:25:47.411974 12219 solver.cpp:375]     Train net output #0: loss = 1.05245 (* 1 = 1.05245 loss)
I0802 04:25:47.411981 12219 sgd_solver.cpp:136] Iteration 313700, lr = 0.00196875, m = 0.9
I0802 04:26:01.492254 12219 solver.cpp:353] Iteration 313800 (7.10229 iter/s, 14.08s/100 iter), loss = 1.28516
I0802 04:26:01.492283 12219 solver.cpp:375]     Train net output #0: loss = 0.921925 (* 1 = 0.921925 loss)
I0802 04:26:01.492290 12219 sgd_solver.cpp:136] Iteration 313800, lr = 0.0019375, m = 0.9
I0802 04:26:15.518215 12219 solver.cpp:353] Iteration 313900 (7.12983 iter/s, 14.0256s/100 iter), loss = 1.56909
I0802 04:26:15.518242 12219 solver.cpp:375]     Train net output #0: loss = 1.63544 (* 1 = 1.63544 loss)
I0802 04:26:15.518246 12219 sgd_solver.cpp:136] Iteration 313900, lr = 0.00190625, m = 0.9
I0802 04:26:29.357597 12219 solver.cpp:550] Iteration 314000, Testing net (#0)
I0802 04:26:43.062166 12220 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 04:26:48.955374 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.595529
I0802 04:26:48.955399 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.824468
I0802 04:26:48.955407 12219 solver.cpp:635]     Test net output #2: loss = 1.72502 (* 1 = 1.72502 loss)
I0802 04:26:48.955428 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.5973s
I0802 04:26:49.104522 12219 solver.cpp:353] Iteration 314000 (2.97748 iter/s, 33.5854s/100 iter), loss = 1.32648
I0802 04:26:49.104550 12219 solver.cpp:375]     Train net output #0: loss = 1.21847 (* 1 = 1.21847 loss)
I0802 04:26:49.104557 12219 sgd_solver.cpp:136] Iteration 314000, lr = 0.001875, m = 0.9
I0802 04:27:03.074460 12219 solver.cpp:353] Iteration 314100 (7.15842 iter/s, 13.9696s/100 iter), loss = 1.33769
I0802 04:27:03.074535 12219 solver.cpp:375]     Train net output #0: loss = 1.24844 (* 1 = 1.24844 loss)
I0802 04:27:03.074542 12219 sgd_solver.cpp:136] Iteration 314100, lr = 0.00184375, m = 0.9
I0802 04:27:17.126127 12219 solver.cpp:353] Iteration 314200 (7.11679 iter/s, 14.0513s/100 iter), loss = 1.41065
I0802 04:27:17.126153 12219 solver.cpp:375]     Train net output #0: loss = 1.4735 (* 1 = 1.4735 loss)
I0802 04:27:17.126158 12219 sgd_solver.cpp:136] Iteration 314200, lr = 0.0018125, m = 0.9
I0802 04:27:31.106427 12219 solver.cpp:353] Iteration 314300 (7.15312 iter/s, 13.9799s/100 iter), loss = 1.42894
I0802 04:27:31.106453 12219 solver.cpp:375]     Train net output #0: loss = 1.3245 (* 1 = 1.3245 loss)
I0802 04:27:31.106458 12219 sgd_solver.cpp:136] Iteration 314300, lr = 0.00178125, m = 0.9
I0802 04:27:45.087630 12219 solver.cpp:353] Iteration 314400 (7.15265 iter/s, 13.9808s/100 iter), loss = 1.15023
I0802 04:27:45.087689 12219 solver.cpp:375]     Train net output #0: loss = 1.17026 (* 1 = 1.17026 loss)
I0802 04:27:45.087697 12219 sgd_solver.cpp:136] Iteration 314400, lr = 0.00175, m = 0.9
I0802 04:27:59.054790 12219 solver.cpp:353] Iteration 314500 (7.15985 iter/s, 13.9668s/100 iter), loss = 1.6035
I0802 04:27:59.054816 12219 solver.cpp:375]     Train net output #0: loss = 1.65906 (* 1 = 1.65906 loss)
I0802 04:27:59.054819 12219 sgd_solver.cpp:136] Iteration 314500, lr = 0.00171875, m = 0.9
I0802 04:28:13.046584 12219 solver.cpp:353] Iteration 314600 (7.14724 iter/s, 13.9914s/100 iter), loss = 1.29092
I0802 04:28:13.046615 12219 solver.cpp:375]     Train net output #0: loss = 1.13896 (* 1 = 1.13896 loss)
I0802 04:28:13.046623 12219 sgd_solver.cpp:136] Iteration 314600, lr = 0.0016875, m = 0.9
I0802 04:28:26.968961 12219 solver.cpp:353] Iteration 314700 (7.18288 iter/s, 13.922s/100 iter), loss = 1.67914
I0802 04:28:26.969048 12219 solver.cpp:375]     Train net output #0: loss = 1.63387 (* 1 = 1.63387 loss)
I0802 04:28:26.969061 12219 sgd_solver.cpp:136] Iteration 314700, lr = 0.00165625, m = 0.9
I0802 04:28:40.944530 12219 solver.cpp:353] Iteration 314800 (7.15554 iter/s, 13.9752s/100 iter), loss = 1.42957
I0802 04:28:40.944555 12219 solver.cpp:375]     Train net output #0: loss = 1.45992 (* 1 = 1.45992 loss)
I0802 04:28:40.944558 12219 sgd_solver.cpp:136] Iteration 314800, lr = 0.001625, m = 0.9
I0802 04:28:54.812255 12219 solver.cpp:353] Iteration 314900 (7.21118 iter/s, 13.8674s/100 iter), loss = 1.16001
I0802 04:28:54.812279 12219 solver.cpp:375]     Train net output #0: loss = 1.20702 (* 1 = 1.20702 loss)
I0802 04:28:54.812283 12219 sgd_solver.cpp:136] Iteration 314900, lr = 0.00159375, m = 0.9
I0802 04:29:08.713062 12219 solver.cpp:353] Iteration 315000 (7.19402 iter/s, 13.9004s/100 iter), loss = 1.202
I0802 04:29:08.713117 12219 solver.cpp:375]     Train net output #0: loss = 1.30041 (* 1 = 1.30041 loss)
I0802 04:29:08.713124 12219 sgd_solver.cpp:136] Iteration 315000, lr = 0.0015625, m = 0.9
I0802 04:29:22.713757 12219 solver.cpp:353] Iteration 315100 (7.1427 iter/s, 14.0003s/100 iter), loss = 1.35006
I0802 04:29:22.713785 12219 solver.cpp:375]     Train net output #0: loss = 1.44016 (* 1 = 1.44016 loss)
I0802 04:29:22.713793 12219 sgd_solver.cpp:136] Iteration 315100, lr = 0.00153125, m = 0.9
I0802 04:29:36.860452 12219 solver.cpp:353] Iteration 315200 (7.06898 iter/s, 14.1463s/100 iter), loss = 1.42861
I0802 04:29:36.860481 12219 solver.cpp:375]     Train net output #0: loss = 1.3564 (* 1 = 1.3564 loss)
I0802 04:29:36.860484 12219 sgd_solver.cpp:136] Iteration 315200, lr = 0.0015, m = 0.9
I0802 04:29:50.830649 12219 solver.cpp:353] Iteration 315300 (7.15829 iter/s, 13.9698s/100 iter), loss = 1.48852
I0802 04:29:50.830765 12219 solver.cpp:375]     Train net output #0: loss = 1.53419 (* 1 = 1.53419 loss)
I0802 04:29:50.830777 12219 sgd_solver.cpp:136] Iteration 315300, lr = 0.00146875, m = 0.9
I0802 04:30:04.866709 12219 solver.cpp:353] Iteration 315400 (7.1247 iter/s, 14.0357s/100 iter), loss = 1.00012
I0802 04:30:04.866739 12219 solver.cpp:375]     Train net output #0: loss = 1.01978 (* 1 = 1.01978 loss)
I0802 04:30:04.866744 12219 sgd_solver.cpp:136] Iteration 315400, lr = 0.0014375, m = 0.9
I0802 04:30:18.842458 12219 solver.cpp:353] Iteration 315500 (7.15545 iter/s, 13.9754s/100 iter), loss = 1.1453
I0802 04:30:18.842484 12219 solver.cpp:375]     Train net output #0: loss = 0.952886 (* 1 = 0.952886 loss)
I0802 04:30:18.842490 12219 sgd_solver.cpp:136] Iteration 315500, lr = 0.00140625, m = 0.9
I0802 04:30:32.924365 12219 solver.cpp:353] Iteration 315600 (7.1015 iter/s, 14.0815s/100 iter), loss = 0.779151
I0802 04:30:32.924450 12219 solver.cpp:375]     Train net output #0: loss = 0.616775 (* 1 = 0.616775 loss)
I0802 04:30:32.924458 12219 sgd_solver.cpp:136] Iteration 315600, lr = 0.001375, m = 0.9
I0802 04:30:46.956986 12219 solver.cpp:353] Iteration 315700 (7.12644 iter/s, 14.0322s/100 iter), loss = 1.37173
I0802 04:30:46.957016 12219 solver.cpp:375]     Train net output #0: loss = 1.09665 (* 1 = 1.09665 loss)
I0802 04:30:46.957022 12219 sgd_solver.cpp:136] Iteration 315700, lr = 0.00134375, m = 0.9
I0802 04:31:01.042366 12219 solver.cpp:353] Iteration 315800 (7.09975 iter/s, 14.085s/100 iter), loss = 1.4153
I0802 04:31:01.042392 12219 solver.cpp:375]     Train net output #0: loss = 1.555 (* 1 = 1.555 loss)
I0802 04:31:01.042398 12219 sgd_solver.cpp:136] Iteration 315800, lr = 0.0013125, m = 0.9
I0802 04:31:15.072190 12219 solver.cpp:353] Iteration 315900 (7.12786 iter/s, 14.0294s/100 iter), loss = 1.40783
I0802 04:31:15.072247 12219 solver.cpp:375]     Train net output #0: loss = 1.53659 (* 1 = 1.53659 loss)
I0802 04:31:15.072254 12219 sgd_solver.cpp:136] Iteration 315900, lr = 0.00128125, m = 0.9
I0802 04:31:29.015499 12219 solver.cpp:550] Iteration 316000, Testing net (#0)
I0802 04:31:49.382326 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.607235
I0802 04:31:49.382382 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.833173
I0802 04:31:49.382390 12219 solver.cpp:635]     Test net output #2: loss = 1.68439 (* 1 = 1.68439 loss)
I0802 04:31:49.382414 12219 solver.cpp:305] [MultiGPU] Tests completed in 20.3664s
I0802 04:31:49.533538 12219 solver.cpp:353] Iteration 316000 (2.90188 iter/s, 34.4604s/100 iter), loss = 1.0251
I0802 04:31:49.533596 12219 solver.cpp:375]     Train net output #0: loss = 1.17858 (* 1 = 1.17858 loss)
I0802 04:31:49.533608 12219 sgd_solver.cpp:136] Iteration 316000, lr = 0.00125, m = 0.9
I0802 04:32:03.583626 12219 solver.cpp:353] Iteration 316100 (7.11759 iter/s, 14.0497s/100 iter), loss = 1.32359
I0802 04:32:03.583773 12219 solver.cpp:375]     Train net output #0: loss = 1.10554 (* 1 = 1.10554 loss)
I0802 04:32:03.583789 12219 sgd_solver.cpp:136] Iteration 316100, lr = 0.00121875, m = 0.9
I0802 04:32:17.665031 12219 solver.cpp:353] Iteration 316200 (7.10176 iter/s, 14.081s/100 iter), loss = 1.32225
I0802 04:32:17.665060 12219 solver.cpp:375]     Train net output #0: loss = 1.32192 (* 1 = 1.32192 loss)
I0802 04:32:17.665066 12219 sgd_solver.cpp:136] Iteration 316200, lr = 0.0011875, m = 0.9
I0802 04:32:31.602607 12219 solver.cpp:353] Iteration 316300 (7.17505 iter/s, 13.9372s/100 iter), loss = 1.38119
I0802 04:32:31.602761 12219 solver.cpp:375]     Train net output #0: loss = 1.35332 (* 1 = 1.35332 loss)
I0802 04:32:31.602784 12219 sgd_solver.cpp:136] Iteration 316300, lr = 0.00115625, m = 0.9
I0802 04:32:45.711653 12219 solver.cpp:353] Iteration 316400 (7.08784 iter/s, 14.1087s/100 iter), loss = 1.19695
I0802 04:32:45.711709 12219 solver.cpp:375]     Train net output #0: loss = 1.12768 (* 1 = 1.12768 loss)
I0802 04:32:45.711721 12219 sgd_solver.cpp:136] Iteration 316400, lr = 0.001125, m = 0.9
I0802 04:32:59.888363 12219 solver.cpp:353] Iteration 316500 (7.05401 iter/s, 14.1763s/100 iter), loss = 0.948498
I0802 04:32:59.888388 12219 solver.cpp:375]     Train net output #0: loss = 0.946411 (* 1 = 0.946411 loss)
I0802 04:32:59.888394 12219 sgd_solver.cpp:136] Iteration 316500, lr = 0.00109375, m = 0.9
I0802 04:33:14.004443 12219 solver.cpp:353] Iteration 316600 (7.08431 iter/s, 14.1157s/100 iter), loss = 1.36571
I0802 04:33:14.004554 12219 solver.cpp:375]     Train net output #0: loss = 1.29204 (* 1 = 1.29204 loss)
I0802 04:33:14.004572 12219 sgd_solver.cpp:136] Iteration 316600, lr = 0.0010625, m = 0.9
I0802 04:33:28.126339 12219 solver.cpp:353] Iteration 316700 (7.08139 iter/s, 14.1215s/100 iter), loss = 1.05797
I0802 04:33:28.126364 12219 solver.cpp:375]     Train net output #0: loss = 1.18409 (* 1 = 1.18409 loss)
I0802 04:33:28.126368 12219 sgd_solver.cpp:136] Iteration 316700, lr = 0.00103125, m = 0.9
I0802 04:33:42.067281 12219 solver.cpp:353] Iteration 316800 (7.17331 iter/s, 13.9406s/100 iter), loss = 0.950366
I0802 04:33:42.067306 12219 solver.cpp:375]     Train net output #0: loss = 1.14385 (* 1 = 1.14385 loss)
I0802 04:33:42.067312 12219 sgd_solver.cpp:136] Iteration 316800, lr = 0.000999999, m = 0.9
I0802 04:33:56.080749 12219 solver.cpp:353] Iteration 316900 (7.13618 iter/s, 14.0131s/100 iter), loss = 1.23848
I0802 04:33:56.080827 12219 solver.cpp:375]     Train net output #0: loss = 0.898681 (* 1 = 0.898681 loss)
I0802 04:33:56.080835 12219 sgd_solver.cpp:136] Iteration 316900, lr = 0.000968748, m = 0.9
I0802 04:34:10.212323 12219 solver.cpp:353] Iteration 317000 (7.07654 iter/s, 14.1312s/100 iter), loss = 1.08006
I0802 04:34:10.212348 12219 solver.cpp:375]     Train net output #0: loss = 1.19451 (* 1 = 1.19451 loss)
I0802 04:34:10.212354 12219 sgd_solver.cpp:136] Iteration 317000, lr = 0.000937498, m = 0.9
I0802 04:34:24.460584 12219 solver.cpp:353] Iteration 317100 (7.01859 iter/s, 14.2479s/100 iter), loss = 1.33217
I0802 04:34:24.460620 12219 solver.cpp:375]     Train net output #0: loss = 1.31381 (* 1 = 1.31381 loss)
I0802 04:34:24.460628 12219 sgd_solver.cpp:136] Iteration 317100, lr = 0.000906253, m = 0.9
I0802 04:34:38.424865 12219 solver.cpp:353] Iteration 317200 (7.16132 iter/s, 13.9639s/100 iter), loss = 1.31988
I0802 04:34:38.424943 12219 solver.cpp:375]     Train net output #0: loss = 1.28399 (* 1 = 1.28399 loss)
I0802 04:34:38.424950 12219 sgd_solver.cpp:136] Iteration 317200, lr = 0.000875002, m = 0.9
I0802 04:34:52.362493 12219 solver.cpp:353] Iteration 317300 (7.17502 iter/s, 13.9373s/100 iter), loss = 1.65001
I0802 04:34:52.362517 12219 solver.cpp:375]     Train net output #0: loss = 1.7563 (* 1 = 1.7563 loss)
I0802 04:34:52.362524 12219 sgd_solver.cpp:136] Iteration 317300, lr = 0.000843751, m = 0.9
I0802 04:35:06.425206 12219 solver.cpp:353] Iteration 317400 (7.1112 iter/s, 14.0623s/100 iter), loss = 1.14387
I0802 04:35:06.425235 12219 solver.cpp:375]     Train net output #0: loss = 0.878663 (* 1 = 0.878663 loss)
I0802 04:35:06.425240 12219 sgd_solver.cpp:136] Iteration 317400, lr = 0.000812501, m = 0.9
I0802 04:35:20.418957 12219 solver.cpp:353] Iteration 317500 (7.14624 iter/s, 13.9934s/100 iter), loss = 1.25492
I0802 04:35:20.424873 12219 solver.cpp:375]     Train net output #0: loss = 1.35492 (* 1 = 1.35492 loss)
I0802 04:35:20.424895 12219 sgd_solver.cpp:136] Iteration 317500, lr = 0.00078125, m = 0.9
I0802 04:35:34.471026 12219 solver.cpp:353] Iteration 317600 (7.11658 iter/s, 14.0517s/100 iter), loss = 1.55092
I0802 04:35:34.471089 12219 solver.cpp:375]     Train net output #0: loss = 1.25306 (* 1 = 1.25306 loss)
I0802 04:35:34.471104 12219 sgd_solver.cpp:136] Iteration 317600, lr = 0.000749999, m = 0.9
I0802 04:35:48.492264 12219 solver.cpp:353] Iteration 317700 (7.13223 iter/s, 14.0209s/100 iter), loss = 1.10257
I0802 04:35:48.492316 12219 solver.cpp:375]     Train net output #0: loss = 1.36251 (* 1 = 1.36251 loss)
I0802 04:35:48.492329 12219 sgd_solver.cpp:136] Iteration 317700, lr = 0.000718749, m = 0.9
I0802 04:36:02.498381 12219 solver.cpp:353] Iteration 317800 (7.13993 iter/s, 14.0057s/100 iter), loss = 1.31026
I0802 04:36:02.498693 12219 solver.cpp:375]     Train net output #0: loss = 1.30772 (* 1 = 1.30772 loss)
I0802 04:36:02.498790 12219 sgd_solver.cpp:136] Iteration 317800, lr = 0.000687498, m = 0.9
I0802 04:36:16.566200 12219 solver.cpp:353] Iteration 317900 (7.10861 iter/s, 14.0674s/100 iter), loss = 1.28684
I0802 04:36:16.566229 12219 solver.cpp:375]     Train net output #0: loss = 1.31707 (* 1 = 1.31707 loss)
I0802 04:36:16.566236 12219 sgd_solver.cpp:136] Iteration 317900, lr = 0.000656247, m = 0.9
I0802 04:36:30.666610 12219 solver.cpp:550] Iteration 318000, Testing net (#0)
I0802 04:36:50.630074 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.604294
I0802 04:36:50.630167 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.830114
I0802 04:36:50.630177 12219 solver.cpp:635]     Test net output #2: loss = 1.69332 (* 1 = 1.69332 loss)
I0802 04:36:50.630203 12219 solver.cpp:305] [MultiGPU] Tests completed in 19.9631s
I0802 04:36:50.771078 12219 solver.cpp:353] Iteration 318000 (2.92364 iter/s, 34.204s/100 iter), loss = 1.48247
I0802 04:36:50.771106 12219 solver.cpp:375]     Train net output #0: loss = 1.47776 (* 1 = 1.47776 loss)
I0802 04:36:50.771112 12219 sgd_solver.cpp:136] Iteration 318000, lr = 0.000625002, m = 0.9
I0802 04:37:04.794497 12219 solver.cpp:353] Iteration 318100 (7.13112 iter/s, 14.023s/100 iter), loss = 1.33513
I0802 04:37:04.794736 12219 solver.cpp:375]     Train net output #0: loss = 1.58785 (* 1 = 1.58785 loss)
I0802 04:37:04.794831 12219 sgd_solver.cpp:136] Iteration 318100, lr = 0.000593752, m = 0.9
I0802 04:37:18.788357 12219 solver.cpp:353] Iteration 318200 (7.14619 iter/s, 13.9935s/100 iter), loss = 1.43608
I0802 04:37:18.788381 12219 solver.cpp:375]     Train net output #0: loss = 1.34997 (* 1 = 1.34997 loss)
I0802 04:37:18.788385 12219 sgd_solver.cpp:136] Iteration 318200, lr = 0.000562501, m = 0.9
I0802 04:37:32.790971 12219 solver.cpp:353] Iteration 318300 (7.14172 iter/s, 14.0022s/100 iter), loss = 1.55585
I0802 04:37:32.791065 12219 solver.cpp:375]     Train net output #0: loss = 1.44777 (* 1 = 1.44777 loss)
I0802 04:37:32.791079 12219 sgd_solver.cpp:136] Iteration 318300, lr = 0.00053125, m = 0.9
I0802 04:37:46.860713 12219 solver.cpp:353] Iteration 318400 (7.10764 iter/s, 14.0694s/100 iter), loss = 1.29525
I0802 04:37:46.860831 12219 solver.cpp:375]     Train net output #0: loss = 1.59577 (* 1 = 1.59577 loss)
I0802 04:37:46.860853 12219 sgd_solver.cpp:136] Iteration 318400, lr = 0.0005, m = 0.9
I0802 04:38:01.053072 12219 solver.cpp:353] Iteration 318500 (7.04624 iter/s, 14.192s/100 iter), loss = 1.38924
I0802 04:38:01.053143 12219 solver.cpp:375]     Train net output #0: loss = 1.19204 (* 1 = 1.19204 loss)
I0802 04:38:01.053164 12219 sgd_solver.cpp:136] Iteration 318500, lr = 0.000468749, m = 0.9
I0802 04:38:15.113956 12219 solver.cpp:353] Iteration 318600 (7.11212 iter/s, 14.0605s/100 iter), loss = 1.29982
I0802 04:38:15.114043 12219 solver.cpp:375]     Train net output #0: loss = 1.38919 (* 1 = 1.38919 loss)
I0802 04:38:15.114050 12219 sgd_solver.cpp:136] Iteration 318600, lr = 0.000437498, m = 0.9
I0802 04:38:29.058506 12219 solver.cpp:353] Iteration 318700 (7.17145 iter/s, 13.9442s/100 iter), loss = 1.42705
I0802 04:38:29.058531 12219 solver.cpp:375]     Train net output #0: loss = 1.10176 (* 1 = 1.10176 loss)
I0802 04:38:29.058535 12219 sgd_solver.cpp:136] Iteration 318700, lr = 0.000406247, m = 0.9
I0802 04:38:43.005287 12219 solver.cpp:353] Iteration 318800 (7.17031 iter/s, 13.9464s/100 iter), loss = 1.38141
I0802 04:38:43.005321 12219 solver.cpp:375]     Train net output #0: loss = 1.74363 (* 1 = 1.74363 loss)
I0802 04:38:43.005327 12219 sgd_solver.cpp:136] Iteration 318800, lr = 0.000375003, m = 0.9
I0802 04:38:57.061393 12219 solver.cpp:353] Iteration 318900 (7.11454 iter/s, 14.0557s/100 iter), loss = 1.31853
I0802 04:38:57.061468 12219 solver.cpp:375]     Train net output #0: loss = 1.26542 (* 1 = 1.26542 loss)
I0802 04:38:57.061475 12219 sgd_solver.cpp:136] Iteration 318900, lr = 0.000343752, m = 0.9
I0802 04:39:11.025130 12219 solver.cpp:353] Iteration 319000 (7.1616 iter/s, 13.9634s/100 iter), loss = 1.29791
I0802 04:39:11.025158 12219 solver.cpp:375]     Train net output #0: loss = 1.15146 (* 1 = 1.15146 loss)
I0802 04:39:11.025164 12219 sgd_solver.cpp:136] Iteration 319000, lr = 0.000312501, m = 0.9
I0802 04:39:24.947214 12219 solver.cpp:353] Iteration 319100 (7.18303 iter/s, 13.9217s/100 iter), loss = 1.38771
I0802 04:39:24.947240 12219 solver.cpp:375]     Train net output #0: loss = 1.22123 (* 1 = 1.22123 loss)
I0802 04:39:24.947247 12219 sgd_solver.cpp:136] Iteration 319100, lr = 0.00028125, m = 0.9
I0802 04:39:39.056404 12219 solver.cpp:353] Iteration 319200 (7.08777 iter/s, 14.1088s/100 iter), loss = 1.28185
I0802 04:39:39.056474 12219 solver.cpp:375]     Train net output #0: loss = 1.31651 (* 1 = 1.31651 loss)
I0802 04:39:39.056483 12219 sgd_solver.cpp:136] Iteration 319200, lr = 0.00025, m = 0.9
I0802 04:39:53.180333 12219 solver.cpp:353] Iteration 319300 (7.08038 iter/s, 14.1235s/100 iter), loss = 1.13024
I0802 04:39:53.180397 12219 solver.cpp:375]     Train net output #0: loss = 1.02583 (* 1 = 1.02583 loss)
I0802 04:39:53.180416 12219 sgd_solver.cpp:136] Iteration 319300, lr = 0.000218749, m = 0.9
I0802 04:40:07.276895 12219 solver.cpp:353] Iteration 319400 (7.09412 iter/s, 14.0962s/100 iter), loss = 1.5129
I0802 04:40:07.276922 12219 solver.cpp:375]     Train net output #0: loss = 1.35891 (* 1 = 1.35891 loss)
I0802 04:40:07.276928 12219 sgd_solver.cpp:136] Iteration 319400, lr = 0.000187498, m = 0.9
I0802 04:40:21.423220 12219 solver.cpp:353] Iteration 319500 (7.06916 iter/s, 14.1459s/100 iter), loss = 1.06428
I0802 04:40:21.423344 12219 solver.cpp:375]     Train net output #0: loss = 1.10095 (* 1 = 1.10095 loss)
I0802 04:40:21.423363 12219 sgd_solver.cpp:136] Iteration 319500, lr = 0.000156248, m = 0.9
I0802 04:40:35.328630 12219 solver.cpp:353] Iteration 319600 (7.19164 iter/s, 13.905s/100 iter), loss = 1.12589
I0802 04:40:35.328652 12219 solver.cpp:375]     Train net output #0: loss = 0.956696 (* 1 = 0.956696 loss)
I0802 04:40:35.328656 12219 sgd_solver.cpp:136] Iteration 319600, lr = 0.000125003, m = 0.9
I0802 04:40:49.279855 12219 solver.cpp:353] Iteration 319700 (7.16802 iter/s, 13.9508s/100 iter), loss = 1.41023
I0802 04:40:49.279881 12219 solver.cpp:375]     Train net output #0: loss = 1.3154 (* 1 = 1.3154 loss)
I0802 04:40:49.279886 12219 sgd_solver.cpp:136] Iteration 319700, lr = 9.37521e-05, m = 0.9
I0802 04:41:03.392446 12219 solver.cpp:353] Iteration 319800 (7.08606 iter/s, 14.1122s/100 iter), loss = 1.04542
I0802 04:41:03.392532 12219 solver.cpp:375]     Train net output #0: loss = 0.779871 (* 1 = 0.779871 loss)
I0802 04:41:03.392539 12219 sgd_solver.cpp:136] Iteration 319800, lr = 6.25014e-05, m = 0.9
I0802 04:41:17.394804 12219 solver.cpp:353] Iteration 319900 (7.14185 iter/s, 14.002s/100 iter), loss = 1.10027
I0802 04:41:17.394834 12219 solver.cpp:375]     Train net output #0: loss = 1.20771 (* 1 = 1.20771 loss)
I0802 04:41:17.394840 12219 sgd_solver.cpp:136] Iteration 319900, lr = 3.12507e-05, m = 0.9
I0802 04:41:31.302140 12219 solver.cpp:353] Iteration 319999 (7.11874 iter/s, 13.9069s/99 iter), loss = 1.28914
I0802 04:41:31.302170 12219 solver.cpp:375]     Train net output #0: loss = 1.12294 (* 1 = 1.12294 loss)
I0802 04:41:31.302176 12219 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_320000.caffemodel
I0802 04:41:31.358417 12219 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_320000.solverstate
I0802 04:41:31.387876 12219 solver.cpp:527] Iteration 320000, loss = 1.34285
I0802 04:41:31.387913 12219 solver.cpp:550] Iteration 320000, Testing net (#0)
I0802 04:41:47.005221 12219 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 04:41:50.823999 12219 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.613058
I0802 04:41:50.824024 12219 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.834938
I0802 04:41:50.824031 12219 solver.cpp:635]     Test net output #2: loss = 1.65648 (* 1 = 1.65648 loss)
I0802 04:41:50.838723 12170 parallel.cpp:73] Root Solver performance on device 0: 6.668 * 43 = 286.7 img/sec (320000 itr in 4.799e+04 sec)
I0802 04:41:50.838740 12170 parallel.cpp:78]      Solver performance on device 1: 6.668 * 43 = 286.7 img/sec (320000 itr in 4.799e+04 sec)
I0802 04:41:50.838745 12170 parallel.cpp:78]      Solver performance on device 2: 6.667 * 43 = 286.7 img/sec (320000 itr in 4.799e+04 sec)
I0802 04:41:50.838747 12170 parallel.cpp:81] Overall multi-GPU performance: 860.114 img/sec
I0802 04:41:51.694269 12170 caffe.cpp:247] Optimization Done in 13h 20m 18s
I0802 04:41:54.744052 18523 caffe.cpp:608] This is NVCaffe 0.16.3 started at Wed Aug  2 04:41:53 2017
I0802 04:41:54.746682 18523 caffe.cpp:611] CuDNN version: 6021
I0802 04:41:54.746700 18523 caffe.cpp:612] CuBLAS version: 8000
I0802 04:41:54.746706 18523 caffe.cpp:613] CUDA version: 8000
I0802 04:41:54.746712 18523 caffe.cpp:614] CUDA driver version: 8000
I0802 04:41:55.035533 18523 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0802 04:41:55.036105 18523 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0802 04:41:55.036630 18523 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0802 04:41:55.037153 18523 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0802 04:41:55.037161 18523 caffe.cpp:208] Using GPUs 0, 1, 2
I0802 04:41:55.037487 18523 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0802 04:41:55.037814 18523 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0802 04:41:55.038141 18523 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0802 04:41:55.059761 18523 solver.cpp:42] Solver data type: FLOAT
I0802 04:41:55.059816 18523 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt"
test_iter: 1000
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 160000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
iter_size: 2
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.01
sparsity_step_iter: 1000
sparsity_start_iter: 20000
sparsity_start_factor: 0
I0802 04:41:55.081804 18523 solver.cpp:77] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/train.prototxt
I0802 04:41:55.096571 18523 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0802 04:41:55.096627 18523 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0802 04:41:55.096788 18523 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:55.097769 18523 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 43
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0802 04:41:55.098340 18523 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:55.098373 18523 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:55.098393 18523 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0802 04:41:55.098412 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.099833 18523 net.cpp:184] Created Layer data (0)
I0802 04:41:55.099934 18523 net.cpp:530] data -> data
I0802 04:41:55.100013 18523 net.cpp:530] data -> label
I0802 04:41:55.100126 18523 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:55.100205 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:55.118032 18597 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:55.126688 18523 data_layer.cpp:184] [0] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:55.127013 18523 data_layer.cpp:208] [0] Output data size: 43, 3, 224, 224
I0802 04:41:55.127043 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:55.127130 18523 net.cpp:245] Setting up data
I0802 04:41:55.127171 18523 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 3 224 224 (6472704)
I0802 04:41:55.127203 18523 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 (43)
I0802 04:41:55.127239 18523 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0802 04:41:55.127264 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.127348 18523 net.cpp:184] Created Layer data/bias (1)
I0802 04:41:55.127373 18523 net.cpp:561] data/bias <- data
I0802 04:41:55.127410 18523 net.cpp:530] data/bias -> data/bias
I0802 04:41:55.134845 18523 net.cpp:245] Setting up data/bias
I0802 04:41:55.134898 18523 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 43 3 224 224 (6472704)
I0802 04:41:55.134945 18523 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0802 04:41:55.134970 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.135027 18523 net.cpp:184] Created Layer conv1a (2)
I0802 04:41:55.135048 18523 net.cpp:561] conv1a <- data/bias
I0802 04:41:55.135069 18523 net.cpp:530] conv1a -> conv1a
I0802 04:41:55.951262 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 7.97G, req 0G)
I0802 04:41:55.951337 18523 net.cpp:245] Setting up conv1a
I0802 04:41:55.951364 18523 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 43 32 112 112 (17260544)
I0802 04:41:55.951407 18523 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0802 04:41:55.951439 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.951493 18523 net.cpp:184] Created Layer conv1a/bn (3)
I0802 04:41:55.951516 18523 net.cpp:561] conv1a/bn <- conv1a
I0802 04:41:55.951532 18523 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0802 04:41:55.954481 18523 net.cpp:245] Setting up conv1a/bn
I0802 04:41:55.954524 18523 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 43 32 112 112 (17260544)
I0802 04:41:55.954560 18523 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0802 04:41:55.954576 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.954607 18523 net.cpp:184] Created Layer conv1a/relu (4)
I0802 04:41:55.954632 18523 net.cpp:561] conv1a/relu <- conv1a
I0802 04:41:55.954653 18523 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0802 04:41:55.954716 18523 net.cpp:245] Setting up conv1a/relu
I0802 04:41:55.954748 18523 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 43 32 112 112 (17260544)
I0802 04:41:55.954766 18523 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0802 04:41:55.954779 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.954815 18523 net.cpp:184] Created Layer conv1b (5)
I0802 04:41:55.954840 18523 net.cpp:561] conv1b <- conv1a
I0802 04:41:55.954862 18523 net.cpp:530] conv1b -> conv1b
I0802 04:41:55.991631 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0G)
I0802 04:41:55.991649 18523 net.cpp:245] Setting up conv1b
I0802 04:41:55.991654 18523 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 43 32 112 112 (17260544)
I0802 04:41:55.991662 18523 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0802 04:41:55.991680 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.991693 18523 net.cpp:184] Created Layer conv1b/bn (6)
I0802 04:41:55.991699 18523 net.cpp:561] conv1b/bn <- conv1b
I0802 04:41:55.991704 18523 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0802 04:41:55.992389 18523 net.cpp:245] Setting up conv1b/bn
I0802 04:41:55.992398 18523 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 43 32 112 112 (17260544)
I0802 04:41:55.992403 18523 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0802 04:41:55.992406 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992410 18523 net.cpp:184] Created Layer conv1b/relu (7)
I0802 04:41:55.992413 18523 net.cpp:561] conv1b/relu <- conv1b
I0802 04:41:55.992414 18523 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0802 04:41:55.992419 18523 net.cpp:245] Setting up conv1b/relu
I0802 04:41:55.992421 18523 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 43 32 112 112 (17260544)
I0802 04:41:55.992424 18523 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0802 04:41:55.992425 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992434 18523 net.cpp:184] Created Layer pool1 (8)
I0802 04:41:55.992439 18523 net.cpp:561] pool1 <- conv1b
I0802 04:41:55.992444 18523 net.cpp:530] pool1 -> pool1
I0802 04:41:55.992521 18523 net.cpp:245] Setting up pool1
I0802 04:41:55.992525 18523 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 43 32 56 56 (4315136)
I0802 04:41:55.992528 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0802 04:41:55.992532 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992540 18523 net.cpp:184] Created Layer res2a_branch2a (9)
I0802 04:41:55.992543 18523 net.cpp:561] res2a_branch2a <- pool1
I0802 04:41:55.992545 18523 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0802 04:41:56.017033 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.71G, req 0G)
I0802 04:41:56.017055 18523 net.cpp:245] Setting up res2a_branch2a
I0802 04:41:56.017060 18523 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 43 64 56 56 (8630272)
I0802 04:41:56.017071 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.017073 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017082 18523 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0802 04:41:56.017086 18523 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0802 04:41:56.017091 18523 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0802 04:41:56.017776 18523 net.cpp:245] Setting up res2a_branch2a/bn
I0802 04:41:56.017784 18523 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 43 64 56 56 (8630272)
I0802 04:41:56.017791 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.017793 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017797 18523 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0802 04:41:56.017801 18523 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0802 04:41:56.017802 18523 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0802 04:41:56.017807 18523 net.cpp:245] Setting up res2a_branch2a/relu
I0802 04:41:56.017808 18523 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 43 64 56 56 (8630272)
I0802 04:41:56.017810 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0802 04:41:56.017813 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017823 18523 net.cpp:184] Created Layer res2a_branch2b (12)
I0802 04:41:56.017828 18523 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0802 04:41:56.017832 18523 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0802 04:41:56.030603 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.64G, req 0G)
I0802 04:41:56.030617 18523 net.cpp:245] Setting up res2a_branch2b
I0802 04:41:56.030622 18523 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 43 64 56 56 (8630272)
I0802 04:41:56.030627 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.030629 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.030635 18523 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0802 04:41:56.030638 18523 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0802 04:41:56.030640 18523 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0802 04:41:56.031788 18523 net.cpp:245] Setting up res2a_branch2b/bn
I0802 04:41:56.031796 18523 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 43 64 56 56 (8630272)
I0802 04:41:56.031803 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.031806 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031810 18523 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0802 04:41:56.031811 18523 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0802 04:41:56.031814 18523 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0802 04:41:56.031818 18523 net.cpp:245] Setting up res2a_branch2b/relu
I0802 04:41:56.031821 18523 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 43 64 56 56 (8630272)
I0802 04:41:56.031822 18523 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0802 04:41:56.031826 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031831 18523 net.cpp:184] Created Layer pool2 (15)
I0802 04:41:56.031834 18523 net.cpp:561] pool2 <- res2a_branch2b
I0802 04:41:56.031838 18523 net.cpp:530] pool2 -> pool2
I0802 04:41:56.031901 18523 net.cpp:245] Setting up pool2
I0802 04:41:56.031906 18523 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 43 64 28 28 (2157568)
I0802 04:41:56.031909 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0802 04:41:56.031911 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031980 18523 net.cpp:184] Created Layer res3a_branch2a (16)
I0802 04:41:56.031985 18523 net.cpp:561] res3a_branch2a <- pool2
I0802 04:41:56.031987 18523 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0802 04:41:56.054648 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.58G, req 0G)
I0802 04:41:56.054661 18523 net.cpp:245] Setting up res3a_branch2a
I0802 04:41:56.054666 18523 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 43 128 28 28 (4315136)
I0802 04:41:56.054672 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.054674 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.054679 18523 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0802 04:41:56.054682 18523 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0802 04:41:56.054685 18523 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0802 04:41:56.055346 18523 net.cpp:245] Setting up res3a_branch2a/bn
I0802 04:41:56.055353 18523 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 43 128 28 28 (4315136)
I0802 04:41:56.055361 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.055364 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.055367 18523 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0802 04:41:56.055369 18523 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0802 04:41:56.055372 18523 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0802 04:41:56.055385 18523 net.cpp:245] Setting up res3a_branch2a/relu
I0802 04:41:56.055390 18523 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 43 128 28 28 (4315136)
I0802 04:41:56.055394 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0802 04:41:56.055399 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.055408 18523 net.cpp:184] Created Layer res3a_branch2b (19)
I0802 04:41:56.055413 18523 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0802 04:41:56.055414 18523 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0802 04:41:56.063125 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.54G, req 0G)
I0802 04:41:56.063136 18523 net.cpp:245] Setting up res3a_branch2b
I0802 04:41:56.063140 18523 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 43 128 28 28 (4315136)
I0802 04:41:56.063145 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.063148 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063153 18523 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0802 04:41:56.063154 18523 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0802 04:41:56.063158 18523 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0802 04:41:56.063789 18523 net.cpp:245] Setting up res3a_branch2b/bn
I0802 04:41:56.063797 18523 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 43 128 28 28 (4315136)
I0802 04:41:56.063803 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.063805 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063809 18523 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0802 04:41:56.063812 18523 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0802 04:41:56.063813 18523 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0802 04:41:56.063817 18523 net.cpp:245] Setting up res3a_branch2b/relu
I0802 04:41:56.063819 18523 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 43 128 28 28 (4315136)
I0802 04:41:56.063822 18523 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0802 04:41:56.063824 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063829 18523 net.cpp:184] Created Layer pool3 (22)
I0802 04:41:56.063834 18523 net.cpp:561] pool3 <- res3a_branch2b
I0802 04:41:56.063838 18523 net.cpp:530] pool3 -> pool3
I0802 04:41:56.063910 18523 net.cpp:245] Setting up pool3
I0802 04:41:56.063915 18523 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 43 128 14 14 (1078784)
I0802 04:41:56.063917 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0802 04:41:56.063920 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063925 18523 net.cpp:184] Created Layer res4a_branch2a (23)
I0802 04:41:56.063927 18523 net.cpp:561] res4a_branch2a <- pool3
I0802 04:41:56.063930 18523 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0802 04:41:56.089606 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.51G, req 0G)
I0802 04:41:56.089617 18523 net.cpp:245] Setting up res4a_branch2a
I0802 04:41:56.089622 18523 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 43 256 14 14 (2157568)
I0802 04:41:56.089627 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.089629 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.089638 18523 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0802 04:41:56.089642 18523 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0802 04:41:56.089644 18523 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0802 04:41:56.090286 18523 net.cpp:245] Setting up res4a_branch2a/bn
I0802 04:41:56.090301 18523 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 43 256 14 14 (2157568)
I0802 04:41:56.090308 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.090311 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.090313 18523 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0802 04:41:56.090317 18523 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0802 04:41:56.090318 18523 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0802 04:41:56.090322 18523 net.cpp:245] Setting up res4a_branch2a/relu
I0802 04:41:56.090324 18523 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 43 256 14 14 (2157568)
I0802 04:41:56.090327 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0802 04:41:56.090328 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.090334 18523 net.cpp:184] Created Layer res4a_branch2b (26)
I0802 04:41:56.090338 18523 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0802 04:41:56.090342 18523 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0802 04:41:56.099535 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0G)
I0802 04:41:56.099546 18523 net.cpp:245] Setting up res4a_branch2b
I0802 04:41:56.099550 18523 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 43 256 14 14 (2157568)
I0802 04:41:56.099555 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.099557 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.099561 18523 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0802 04:41:56.099565 18523 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0802 04:41:56.099566 18523 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0802 04:41:56.100215 18523 net.cpp:245] Setting up res4a_branch2b/bn
I0802 04:41:56.100224 18523 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 43 256 14 14 (2157568)
I0802 04:41:56.100229 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.100232 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100235 18523 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0802 04:41:56.100239 18523 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0802 04:41:56.100240 18523 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0802 04:41:56.100244 18523 net.cpp:245] Setting up res4a_branch2b/relu
I0802 04:41:56.100246 18523 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 43 256 14 14 (2157568)
I0802 04:41:56.100248 18523 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0802 04:41:56.100250 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100255 18523 net.cpp:184] Created Layer pool4 (29)
I0802 04:41:56.100257 18523 net.cpp:561] pool4 <- res4a_branch2b
I0802 04:41:56.100261 18523 net.cpp:530] pool4 -> pool4
I0802 04:41:56.100327 18523 net.cpp:245] Setting up pool4
I0802 04:41:56.100332 18523 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 43 256 7 7 (539392)
I0802 04:41:56.100334 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0802 04:41:56.100337 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100348 18523 net.cpp:184] Created Layer res5a_branch2a (30)
I0802 04:41:56.100350 18523 net.cpp:561] res5a_branch2a <- pool4
I0802 04:41:56.100353 18523 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0802 04:41:56.154194 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.45G, req 0G)
I0802 04:41:56.154266 18523 net.cpp:245] Setting up res5a_branch2a
I0802 04:41:56.154291 18523 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 43 512 7 7 (1078784)
I0802 04:41:56.154379 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.154412 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.154455 18523 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0802 04:41:56.154481 18523 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0802 04:41:56.154497 18523 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0802 04:41:56.157847 18523 net.cpp:245] Setting up res5a_branch2a/bn
I0802 04:41:56.157892 18523 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 43 512 7 7 (1078784)
I0802 04:41:56.157922 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.157937 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.157960 18523 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0802 04:41:56.157986 18523 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0802 04:41:56.158011 18523 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0802 04:41:56.158046 18523 net.cpp:245] Setting up res5a_branch2a/relu
I0802 04:41:56.158071 18523 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 43 512 7 7 (1078784)
I0802 04:41:56.158092 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0802 04:41:56.158112 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.158140 18523 net.cpp:184] Created Layer res5a_branch2b (33)
I0802 04:41:56.158156 18523 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0802 04:41:56.158182 18523 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0802 04:41:56.197304 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 7.44G, req 0G)
I0802 04:41:56.197321 18523 net.cpp:245] Setting up res5a_branch2b
I0802 04:41:56.197329 18523 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 43 512 7 7 (1078784)
I0802 04:41:56.197352 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.197358 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.197373 18523 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0802 04:41:56.197378 18523 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0802 04:41:56.197382 18523 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0802 04:41:56.198104 18523 net.cpp:245] Setting up res5a_branch2b/bn
I0802 04:41:56.198112 18523 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 43 512 7 7 (1078784)
I0802 04:41:56.198120 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.198127 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198132 18523 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0802 04:41:56.198137 18523 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0802 04:41:56.198140 18523 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0802 04:41:56.198148 18523 net.cpp:245] Setting up res5a_branch2b/relu
I0802 04:41:56.198153 18523 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 43 512 7 7 (1078784)
I0802 04:41:56.198158 18523 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0802 04:41:56.198163 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198169 18523 net.cpp:184] Created Layer pool5 (36)
I0802 04:41:56.198173 18523 net.cpp:561] pool5 <- res5a_branch2b
I0802 04:41:56.198176 18523 net.cpp:530] pool5 -> pool5
I0802 04:41:56.198207 18523 net.cpp:245] Setting up pool5
I0802 04:41:56.198213 18523 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 43 512 1 1 (22016)
I0802 04:41:56.198216 18523 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0802 04:41:56.198228 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198238 18523 net.cpp:184] Created Layer fc1000 (37)
I0802 04:41:56.198242 18523 net.cpp:561] fc1000 <- pool5
I0802 04:41:56.198246 18523 net.cpp:530] fc1000 -> fc1000
I0802 04:41:56.209369 18523 net.cpp:245] Setting up fc1000
I0802 04:41:56.209381 18523 net.cpp:252] TRAIN Top shape for layer 37 'fc1000' 43 1000 (43000)
I0802 04:41:56.209389 18523 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0802 04:41:56.209394 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.209408 18523 net.cpp:184] Created Layer loss (38)
I0802 04:41:56.209412 18523 net.cpp:561] loss <- fc1000
I0802 04:41:56.209416 18523 net.cpp:561] loss <- label
I0802 04:41:56.209424 18523 net.cpp:530] loss -> loss
I0802 04:41:56.224781 18523 net.cpp:245] Setting up loss
I0802 04:41:56.224810 18523 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0802 04:41:56.224827 18523 net.cpp:256]     with loss weight 1
I0802 04:41:56.224839 18523 net.cpp:323] loss needs backward computation.
I0802 04:41:56.224848 18523 net.cpp:323] fc1000 needs backward computation.
I0802 04:41:56.224853 18523 net.cpp:323] pool5 needs backward computation.
I0802 04:41:56.224858 18523 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0802 04:41:56.224861 18523 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0802 04:41:56.224865 18523 net.cpp:323] res5a_branch2b needs backward computation.
I0802 04:41:56.224870 18523 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0802 04:41:56.224874 18523 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0802 04:41:56.224887 18523 net.cpp:323] res5a_branch2a needs backward computation.
I0802 04:41:56.224894 18523 net.cpp:323] pool4 needs backward computation.
I0802 04:41:56.224897 18523 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0802 04:41:56.224902 18523 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0802 04:41:56.224905 18523 net.cpp:323] res4a_branch2b needs backward computation.
I0802 04:41:56.224910 18523 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0802 04:41:56.224915 18523 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0802 04:41:56.224920 18523 net.cpp:323] res4a_branch2a needs backward computation.
I0802 04:41:56.224922 18523 net.cpp:323] pool3 needs backward computation.
I0802 04:41:56.224928 18523 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0802 04:41:56.224932 18523 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0802 04:41:56.224936 18523 net.cpp:323] res3a_branch2b needs backward computation.
I0802 04:41:56.224938 18523 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0802 04:41:56.224942 18523 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0802 04:41:56.224946 18523 net.cpp:323] res3a_branch2a needs backward computation.
I0802 04:41:56.224951 18523 net.cpp:323] pool2 needs backward computation.
I0802 04:41:56.224954 18523 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0802 04:41:56.224958 18523 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0802 04:41:56.224962 18523 net.cpp:323] res2a_branch2b needs backward computation.
I0802 04:41:56.224967 18523 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0802 04:41:56.224970 18523 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0802 04:41:56.224974 18523 net.cpp:323] res2a_branch2a needs backward computation.
I0802 04:41:56.224979 18523 net.cpp:323] pool1 needs backward computation.
I0802 04:41:56.224983 18523 net.cpp:323] conv1b/relu needs backward computation.
I0802 04:41:56.224987 18523 net.cpp:323] conv1b/bn needs backward computation.
I0802 04:41:56.224992 18523 net.cpp:323] conv1b needs backward computation.
I0802 04:41:56.224997 18523 net.cpp:323] conv1a/relu needs backward computation.
I0802 04:41:56.225000 18523 net.cpp:323] conv1a/bn needs backward computation.
I0802 04:41:56.225013 18523 net.cpp:323] conv1a needs backward computation.
I0802 04:41:56.225018 18523 net.cpp:325] data/bias does not need backward computation.
I0802 04:41:56.225023 18523 net.cpp:325] data does not need backward computation.
I0802 04:41:56.225028 18523 net.cpp:367] This network produces output loss
I0802 04:41:56.225066 18523 net.cpp:389] Top memory (TRAIN) required for data: 802615296 diff: 802615304
I0802 04:41:56.225070 18523 net.cpp:392] Bottom memory (TRAIN) required for data: 802615296 diff: 802615296
I0802 04:41:56.225073 18523 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 535076864 diff: 535076864
I0802 04:41:56.225077 18523 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0802 04:41:56.225081 18523 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0802 04:41:56.225085 18523 net.cpp:407] Network initialization done.
I0802 04:41:56.225637 18523 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:56.225692 18523 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:56.225821 18523 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0802 04:41:56.225949 18523 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.225955 18523 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.225960 18523 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0802 04:41:56.225965 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.225980 18523 net.cpp:184] Created Layer data (0)
I0802 04:41:56.225985 18523 net.cpp:530] data -> data
I0802 04:41:56.225989 18523 net.cpp:530] data -> label
I0802 04:41:56.225998 18523 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:56.226012 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.229346 18619 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:56.230068 18523 data_layer.cpp:184] (0) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:56.230159 18523 data_layer.cpp:208] (0) Output data size: 17, 3, 224, 224
I0802 04:41:56.230165 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.230185 18523 net.cpp:245] Setting up data
I0802 04:41:56.230191 18523 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 224 224 (2558976)
I0802 04:41:56.230195 18523 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0802 04:41:56.230199 18523 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0802 04:41:56.230214 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230226 18523 net.cpp:184] Created Layer label_data_1_split (1)
I0802 04:41:56.230231 18523 net.cpp:561] label_data_1_split <- label
I0802 04:41:56.230237 18523 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0802 04:41:56.230243 18523 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0802 04:41:56.230248 18523 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0802 04:41:56.230316 18523 net.cpp:245] Setting up label_data_1_split
I0802 04:41:56.230322 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230326 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230331 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230335 18523 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0802 04:41:56.230340 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230347 18523 net.cpp:184] Created Layer data/bias (2)
I0802 04:41:56.230350 18523 net.cpp:561] data/bias <- data
I0802 04:41:56.230355 18523 net.cpp:530] data/bias -> data/bias
I0802 04:41:56.230547 18523 net.cpp:245] Setting up data/bias
I0802 04:41:56.230556 18523 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 224 224 (2558976)
I0802 04:41:56.230563 18523 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0802 04:41:56.230567 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230579 18523 net.cpp:184] Created Layer conv1a (3)
I0802 04:41:56.230583 18523 net.cpp:561] conv1a <- data/bias
I0802 04:41:56.230587 18523 net.cpp:530] conv1a -> conv1a
I0802 04:41:56.230909 18620 data_layer.cpp:97] (0) Parser threads: 1
I0802 04:41:56.230918 18620 data_layer.cpp:99] (0) Transformer threads: 1
I0802 04:41:56.237251 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.4G, req 0G)
I0802 04:41:56.237270 18523 net.cpp:245] Setting up conv1a
I0802 04:41:56.237277 18523 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 112 112 (6823936)
I0802 04:41:56.237289 18523 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0802 04:41:56.237304 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.237321 18523 net.cpp:184] Created Layer conv1a/bn (4)
I0802 04:41:56.237326 18523 net.cpp:561] conv1a/bn <- conv1a
I0802 04:41:56.237332 18523 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0802 04:41:56.238095 18523 net.cpp:245] Setting up conv1a/bn
I0802 04:41:56.238103 18523 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 112 112 (6823936)
I0802 04:41:56.238113 18523 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0802 04:41:56.238117 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.238123 18523 net.cpp:184] Created Layer conv1a/relu (5)
I0802 04:41:56.238127 18523 net.cpp:561] conv1a/relu <- conv1a
I0802 04:41:56.238132 18523 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0802 04:41:56.238138 18523 net.cpp:245] Setting up conv1a/relu
I0802 04:41:56.238143 18523 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 112 112 (6823936)
I0802 04:41:56.238147 18523 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0802 04:41:56.238152 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.238162 18523 net.cpp:184] Created Layer conv1b (6)
I0802 04:41:56.238165 18523 net.cpp:561] conv1b <- conv1a
I0802 04:41:56.238169 18523 net.cpp:530] conv1b -> conv1b
I0802 04:41:56.243749 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:56.243764 18523 net.cpp:245] Setting up conv1b
I0802 04:41:56.243772 18523 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 112 112 (6823936)
I0802 04:41:56.243790 18523 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0802 04:41:56.243795 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.243805 18523 net.cpp:184] Created Layer conv1b/bn (7)
I0802 04:41:56.243809 18523 net.cpp:561] conv1b/bn <- conv1b
I0802 04:41:56.243814 18523 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0802 04:41:56.244539 18523 net.cpp:245] Setting up conv1b/bn
I0802 04:41:56.244547 18523 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 112 112 (6823936)
I0802 04:41:56.244556 18523 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0802 04:41:56.244560 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244565 18523 net.cpp:184] Created Layer conv1b/relu (8)
I0802 04:41:56.244570 18523 net.cpp:561] conv1b/relu <- conv1b
I0802 04:41:56.244575 18523 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0802 04:41:56.244580 18523 net.cpp:245] Setting up conv1b/relu
I0802 04:41:56.244585 18523 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 112 112 (6823936)
I0802 04:41:56.244590 18523 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0802 04:41:56.244593 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244601 18523 net.cpp:184] Created Layer pool1 (9)
I0802 04:41:56.244604 18523 net.cpp:561] pool1 <- conv1b
I0802 04:41:56.244609 18523 net.cpp:530] pool1 -> pool1
I0802 04:41:56.244684 18523 net.cpp:245] Setting up pool1
I0802 04:41:56.244690 18523 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 56 56 (1705984)
I0802 04:41:56.244695 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0802 04:41:56.244700 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244709 18523 net.cpp:184] Created Layer res2a_branch2a (10)
I0802 04:41:56.244712 18523 net.cpp:561] res2a_branch2a <- pool1
I0802 04:41:56.244716 18523 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0802 04:41:56.250139 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.34G, req 0G)
I0802 04:41:56.250156 18523 net.cpp:245] Setting up res2a_branch2a
I0802 04:41:56.250164 18523 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 56 56 (3411968)
I0802 04:41:56.250175 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.250190 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.250201 18523 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0802 04:41:56.250206 18523 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0802 04:41:56.250211 18523 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0802 04:41:56.252259 18523 net.cpp:245] Setting up res2a_branch2a/bn
I0802 04:41:56.252272 18523 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 56 56 (3411968)
I0802 04:41:56.252284 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.252288 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.252295 18523 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0802 04:41:56.252298 18523 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0802 04:41:56.252303 18523 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0802 04:41:56.252312 18523 net.cpp:245] Setting up res2a_branch2a/relu
I0802 04:41:56.252317 18523 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 56 56 (3411968)
I0802 04:41:56.252322 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0802 04:41:56.252326 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.252338 18523 net.cpp:184] Created Layer res2a_branch2b (13)
I0802 04:41:56.252351 18523 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0802 04:41:56.252355 18523 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0802 04:41:56.256112 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.32G, req 0G)
I0802 04:41:56.256129 18523 net.cpp:245] Setting up res2a_branch2b
I0802 04:41:56.256137 18523 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 56 56 (3411968)
I0802 04:41:56.256146 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.256151 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.256160 18523 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0802 04:41:56.256165 18523 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0802 04:41:56.256168 18523 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0802 04:41:56.256968 18523 net.cpp:245] Setting up res2a_branch2b/bn
I0802 04:41:56.256978 18523 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 56 56 (3411968)
I0802 04:41:56.256989 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.256994 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.256999 18523 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0802 04:41:56.257004 18523 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0802 04:41:56.257007 18523 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0802 04:41:56.257014 18523 net.cpp:245] Setting up res2a_branch2b/relu
I0802 04:41:56.257019 18523 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 56 56 (3411968)
I0802 04:41:56.257025 18523 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0802 04:41:56.257028 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.257036 18523 net.cpp:184] Created Layer pool2 (16)
I0802 04:41:56.257040 18523 net.cpp:561] pool2 <- res2a_branch2b
I0802 04:41:56.257043 18523 net.cpp:530] pool2 -> pool2
I0802 04:41:56.257115 18523 net.cpp:245] Setting up pool2
I0802 04:41:56.257122 18523 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 28 28 (852992)
I0802 04:41:56.257127 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0802 04:41:56.257131 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.257141 18523 net.cpp:184] Created Layer res3a_branch2a (17)
I0802 04:41:56.257145 18523 net.cpp:561] res3a_branch2a <- pool2
I0802 04:41:56.257149 18523 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0802 04:41:56.264302 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.31G, req 0G)
I0802 04:41:56.264324 18523 net.cpp:245] Setting up res3a_branch2a
I0802 04:41:56.264333 18523 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 28 28 (1705984)
I0802 04:41:56.264343 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.264349 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.264360 18523 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0802 04:41:56.264366 18523 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0802 04:41:56.264371 18523 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0802 04:41:56.265467 18523 net.cpp:245] Setting up res3a_branch2a/bn
I0802 04:41:56.265480 18523 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 28 28 (1705984)
I0802 04:41:56.265493 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.265498 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.265504 18523 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0802 04:41:56.265509 18523 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0802 04:41:56.265513 18523 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0802 04:41:56.265533 18523 net.cpp:245] Setting up res3a_branch2a/relu
I0802 04:41:56.265540 18523 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 28 28 (1705984)
I0802 04:41:56.265544 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0802 04:41:56.265548 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.265560 18523 net.cpp:184] Created Layer res3a_branch2b (20)
I0802 04:41:56.265564 18523 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0802 04:41:56.265569 18523 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0802 04:41:56.269692 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.3G, req 0G)
I0802 04:41:56.269707 18523 net.cpp:245] Setting up res3a_branch2b
I0802 04:41:56.269714 18523 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 28 28 (1705984)
I0802 04:41:56.269721 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.269726 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.269743 18523 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0802 04:41:56.269749 18523 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0802 04:41:56.269754 18523 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0802 04:41:56.270772 18523 net.cpp:245] Setting up res3a_branch2b/bn
I0802 04:41:56.270784 18523 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 28 28 (1705984)
I0802 04:41:56.270794 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.270799 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270805 18523 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0802 04:41:56.270809 18523 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0802 04:41:56.270813 18523 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0802 04:41:56.270822 18523 net.cpp:245] Setting up res3a_branch2b/relu
I0802 04:41:56.270826 18523 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 28 28 (1705984)
I0802 04:41:56.270831 18523 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0802 04:41:56.270835 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270843 18523 net.cpp:184] Created Layer pool3 (23)
I0802 04:41:56.270848 18523 net.cpp:561] pool3 <- res3a_branch2b
I0802 04:41:56.270853 18523 net.cpp:530] pool3 -> pool3
I0802 04:41:56.270957 18523 net.cpp:245] Setting up pool3
I0802 04:41:56.270967 18523 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 14 14 (426496)
I0802 04:41:56.270972 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0802 04:41:56.270975 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270992 18523 net.cpp:184] Created Layer res4a_branch2a (24)
I0802 04:41:56.270997 18523 net.cpp:561] res4a_branch2a <- pool3
I0802 04:41:56.271003 18523 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0802 04:41:56.283207 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.29G, req 0G)
I0802 04:41:56.283224 18523 net.cpp:245] Setting up res4a_branch2a
I0802 04:41:56.283229 18523 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 14 14 (852992)
I0802 04:41:56.283236 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.283239 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.283247 18523 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0802 04:41:56.283251 18523 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0802 04:41:56.283253 18523 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0802 04:41:56.283978 18523 net.cpp:245] Setting up res4a_branch2a/bn
I0802 04:41:56.283996 18523 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 14 14 (852992)
I0802 04:41:56.284003 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.284004 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.284008 18523 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0802 04:41:56.284010 18523 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0802 04:41:56.284013 18523 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0802 04:41:56.284018 18523 net.cpp:245] Setting up res4a_branch2a/relu
I0802 04:41:56.284020 18523 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 14 14 (852992)
I0802 04:41:56.284023 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0802 04:41:56.284025 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.284031 18523 net.cpp:184] Created Layer res4a_branch2b (27)
I0802 04:41:56.284034 18523 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0802 04:41:56.284036 18523 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0802 04:41:56.290033 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.28G, req 0G)
I0802 04:41:56.290050 18523 net.cpp:245] Setting up res4a_branch2b
I0802 04:41:56.290056 18523 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 14 14 (852992)
I0802 04:41:56.290065 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.290068 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.290077 18523 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0802 04:41:56.290081 18523 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0802 04:41:56.290086 18523 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0802 04:41:56.290952 18523 net.cpp:245] Setting up res4a_branch2b/bn
I0802 04:41:56.290962 18523 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 14 14 (852992)
I0802 04:41:56.290968 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.290973 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.290977 18523 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0802 04:41:56.290980 18523 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0802 04:41:56.290983 18523 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0802 04:41:56.290988 18523 net.cpp:245] Setting up res4a_branch2b/relu
I0802 04:41:56.290992 18523 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 14 14 (852992)
I0802 04:41:56.290994 18523 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0802 04:41:56.290997 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.291002 18523 net.cpp:184] Created Layer pool4 (30)
I0802 04:41:56.291004 18523 net.cpp:561] pool4 <- res4a_branch2b
I0802 04:41:56.291007 18523 net.cpp:530] pool4 -> pool4
I0802 04:41:56.291079 18523 net.cpp:245] Setting up pool4
I0802 04:41:56.291082 18523 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 7 7 (213248)
I0802 04:41:56.291085 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0802 04:41:56.291087 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.291095 18523 net.cpp:184] Created Layer res5a_branch2a (31)
I0802 04:41:56.291098 18523 net.cpp:561] res5a_branch2a <- pool4
I0802 04:41:56.291100 18523 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0802 04:41:56.321835 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.28G, req 0G)
I0802 04:41:56.321854 18523 net.cpp:245] Setting up res5a_branch2a
I0802 04:41:56.321861 18523 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 7 7 (426496)
I0802 04:41:56.321878 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.321883 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.321893 18523 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0802 04:41:56.321897 18523 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0802 04:41:56.321900 18523 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0802 04:41:56.322690 18523 net.cpp:245] Setting up res5a_branch2a/bn
I0802 04:41:56.322698 18523 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 7 7 (426496)
I0802 04:41:56.322705 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.322710 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.322713 18523 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0802 04:41:56.322716 18523 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0802 04:41:56.322718 18523 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0802 04:41:56.322723 18523 net.cpp:245] Setting up res5a_branch2a/relu
I0802 04:41:56.322726 18523 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 7 7 (426496)
I0802 04:41:56.322728 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0802 04:41:56.322731 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.322741 18523 net.cpp:184] Created Layer res5a_branch2b (34)
I0802 04:41:56.322744 18523 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0802 04:41:56.322747 18523 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0802 04:41:56.339610 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.27G, req 0G)
I0802 04:41:56.339627 18523 net.cpp:245] Setting up res5a_branch2b
I0802 04:41:56.339632 18523 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 7 7 (426496)
I0802 04:41:56.339642 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.339645 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.339653 18523 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0802 04:41:56.339656 18523 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0802 04:41:56.339660 18523 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0802 04:41:56.340412 18523 net.cpp:245] Setting up res5a_branch2b/bn
I0802 04:41:56.340420 18523 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 7 7 (426496)
I0802 04:41:56.340426 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.340430 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340438 18523 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0802 04:41:56.340441 18523 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0802 04:41:56.340443 18523 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0802 04:41:56.340447 18523 net.cpp:245] Setting up res5a_branch2b/relu
I0802 04:41:56.340451 18523 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 7 7 (426496)
I0802 04:41:56.340452 18523 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0802 04:41:56.340454 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340458 18523 net.cpp:184] Created Layer pool5 (37)
I0802 04:41:56.340461 18523 net.cpp:561] pool5 <- res5a_branch2b
I0802 04:41:56.340463 18523 net.cpp:530] pool5 -> pool5
I0802 04:41:56.340494 18523 net.cpp:245] Setting up pool5
I0802 04:41:56.340499 18523 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0802 04:41:56.340502 18523 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0802 04:41:56.340504 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340519 18523 net.cpp:184] Created Layer fc1000 (38)
I0802 04:41:56.340522 18523 net.cpp:561] fc1000 <- pool5
I0802 04:41:56.340524 18523 net.cpp:530] fc1000 -> fc1000
I0802 04:41:56.351748 18523 net.cpp:245] Setting up fc1000
I0802 04:41:56.351769 18523 net.cpp:252] TEST Top shape for layer 38 'fc1000' 17 1000 (17000)
I0802 04:41:56.351778 18523 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0802 04:41:56.351780 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.351785 18523 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0802 04:41:56.351788 18523 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0802 04:41:56.351793 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0802 04:41:56.351795 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0802 04:41:56.351799 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0802 04:41:56.351877 18523 net.cpp:245] Setting up fc1000_fc1000_0_split
I0802 04:41:56.351882 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351886 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351888 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351891 18523 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0802 04:41:56.351893 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.351900 18523 net.cpp:184] Created Layer loss (40)
I0802 04:41:56.351903 18523 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0802 04:41:56.351905 18523 net.cpp:561] loss <- label_data_1_split_0
I0802 04:41:56.351909 18523 net.cpp:530] loss -> loss
I0802 04:41:56.352123 18523 net.cpp:245] Setting up loss
I0802 04:41:56.352131 18523 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0802 04:41:56.352133 18523 net.cpp:256]     with loss weight 1
I0802 04:41:56.352139 18523 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0802 04:41:56.352143 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.352156 18523 net.cpp:184] Created Layer accuracy/top1 (41)
I0802 04:41:56.352160 18523 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0802 04:41:56.352165 18523 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0802 04:41:56.352169 18523 net.cpp:530] accuracy/top1 -> accuracy/top1
I0802 04:41:56.352174 18523 net.cpp:245] Setting up accuracy/top1
I0802 04:41:56.352176 18523 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0802 04:41:56.352180 18523 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0802 04:41:56.352181 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.352187 18523 net.cpp:184] Created Layer accuracy/top5 (42)
I0802 04:41:56.352190 18523 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0802 04:41:56.352192 18523 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0802 04:41:56.352195 18523 net.cpp:530] accuracy/top5 -> accuracy/top5
I0802 04:41:56.352198 18523 net.cpp:245] Setting up accuracy/top5
I0802 04:41:56.352201 18523 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0802 04:41:56.352203 18523 net.cpp:325] accuracy/top5 does not need backward computation.
I0802 04:41:56.352206 18523 net.cpp:325] accuracy/top1 does not need backward computation.
I0802 04:41:56.352210 18523 net.cpp:323] loss needs backward computation.
I0802 04:41:56.352211 18523 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0802 04:41:56.352214 18523 net.cpp:323] fc1000 needs backward computation.
I0802 04:41:56.352216 18523 net.cpp:323] pool5 needs backward computation.
I0802 04:41:56.352219 18523 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0802 04:41:56.352234 18523 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0802 04:41:56.352237 18523 net.cpp:323] res5a_branch2b needs backward computation.
I0802 04:41:56.352241 18523 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0802 04:41:56.352242 18523 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0802 04:41:56.352246 18523 net.cpp:323] res5a_branch2a needs backward computation.
I0802 04:41:56.352247 18523 net.cpp:323] pool4 needs backward computation.
I0802 04:41:56.352250 18523 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0802 04:41:56.352252 18523 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0802 04:41:56.352253 18523 net.cpp:323] res4a_branch2b needs backward computation.
I0802 04:41:56.352257 18523 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0802 04:41:56.352258 18523 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0802 04:41:56.352260 18523 net.cpp:323] res4a_branch2a needs backward computation.
I0802 04:41:56.352263 18523 net.cpp:323] pool3 needs backward computation.
I0802 04:41:56.352265 18523 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0802 04:41:56.352268 18523 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0802 04:41:56.352270 18523 net.cpp:323] res3a_branch2b needs backward computation.
I0802 04:41:56.352272 18523 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0802 04:41:56.352275 18523 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0802 04:41:56.352278 18523 net.cpp:323] res3a_branch2a needs backward computation.
I0802 04:41:56.352280 18523 net.cpp:323] pool2 needs backward computation.
I0802 04:41:56.352283 18523 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0802 04:41:56.352285 18523 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0802 04:41:56.352288 18523 net.cpp:323] res2a_branch2b needs backward computation.
I0802 04:41:56.352290 18523 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0802 04:41:56.352293 18523 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0802 04:41:56.352295 18523 net.cpp:323] res2a_branch2a needs backward computation.
I0802 04:41:56.352298 18523 net.cpp:323] pool1 needs backward computation.
I0802 04:41:56.352300 18523 net.cpp:323] conv1b/relu needs backward computation.
I0802 04:41:56.352303 18523 net.cpp:323] conv1b/bn needs backward computation.
I0802 04:41:56.352304 18523 net.cpp:323] conv1b needs backward computation.
I0802 04:41:56.352308 18523 net.cpp:323] conv1a/relu needs backward computation.
I0802 04:41:56.352309 18523 net.cpp:323] conv1a/bn needs backward computation.
I0802 04:41:56.352313 18523 net.cpp:323] conv1a needs backward computation.
I0802 04:41:56.352314 18523 net.cpp:325] data/bias does not need backward computation.
I0802 04:41:56.352319 18523 net.cpp:325] label_data_1_split does not need backward computation.
I0802 04:41:56.352321 18523 net.cpp:325] data does not need backward computation.
I0802 04:41:56.352322 18523 net.cpp:367] This network produces output accuracy/top1
I0802 04:41:56.352325 18523 net.cpp:367] This network produces output accuracy/top5
I0802 04:41:56.352327 18523 net.cpp:367] This network produces output loss
I0802 04:41:56.352365 18523 net.cpp:389] Top memory (TEST) required for data: 317313024 diff: 8
I0802 04:41:56.352368 18523 net.cpp:392] Bottom memory (TEST) required for data: 317313024 diff: 317313024
I0802 04:41:56.352370 18523 net.cpp:395] Shared (in-place) memory (TEST) by data: 211542016 diff: 211542016
I0802 04:41:56.352372 18523 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0802 04:41:56.352375 18523 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0802 04:41:56.352376 18523 net.cpp:407] Network initialization done.
I0802 04:41:56.352443 18523 solver.cpp:56] Solver scaffolding done.
I0802 04:41:56.356739 18523 caffe.cpp:137] Finetuning from training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_320000.caffemodel
I0802 04:41:56.362118 18523 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0802 04:41:56.362149 18523 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0802 04:41:56.362196 18523 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0802 04:41:56.362211 18523 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362540 18523 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0802 04:41:56.362545 18523 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0802 04:41:56.362553 18523 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362705 18523 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0802 04:41:56.362710 18523 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0802 04:41:56.362712 18523 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.362727 18523 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362885 18523 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.362890 18523 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.362901 18523 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363047 18523 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363051 18523 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0802 04:41:56.363054 18523 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.363090 18523 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363229 18523 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.363234 18523 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.363255 18523 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363373 18523 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363376 18523 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0802 04:41:56.363379 18523 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.363488 18523 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363612 18523 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.363616 18523 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.363672 18523 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363793 18523 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363797 18523 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0802 04:41:56.363801 18523 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.364166 18523 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.364302 18523 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.364306 18523 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.364487 18523 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.364608 18523 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.364611 18523 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0802 04:41:56.364614 18523 net.cpp:1089] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0802 04:41:56.364732 18523 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0802 04:41:56.367926 18523 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0802 04:41:56.367944 18523 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0802 04:41:56.367967 18523 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0802 04:41:56.367993 18523 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368239 18523 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0802 04:41:56.368243 18523 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0802 04:41:56.368252 18523 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368402 18523 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0802 04:41:56.368407 18523 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0802 04:41:56.368408 18523 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.368424 18523 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368576 18523 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.368579 18523 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.368592 18523 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368734 18523 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.368738 18523 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0802 04:41:56.368741 18523 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.368777 18523 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368927 18523 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.368932 18523 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.368953 18523 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369074 18523 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.369078 18523 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0802 04:41:56.369081 18523 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.369191 18523 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369312 18523 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.369316 18523 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.369371 18523 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369493 18523 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.369496 18523 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0802 04:41:56.369498 18523 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.369860 18523 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369983 18523 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.369987 18523 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.370151 18523 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.370267 18523 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.370272 18523 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0802 04:41:56.370275 18523 net.cpp:1089] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0802 04:41:56.370419 18523 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0802 04:41:56.370479 18523 parallel.cpp:108] [0 - 0] P2pSync adding callback
I0802 04:41:56.370484 18523 parallel.cpp:108] [1 - 1] P2pSync adding callback
I0802 04:41:56.370487 18523 parallel.cpp:108] [2 - 2] P2pSync adding callback
I0802 04:41:56.370488 18523 parallel.cpp:61] Starting Optimization
I0802 04:41:56.370491 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.370517 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.370543 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.371220 18636 device_alternate.hpp:116] NVML initialized on thread 139687390533376
I0802 04:41:56.399471 18636 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0802 04:41:56.399533 18637 device_alternate.hpp:116] NVML initialized on thread 139687382140672
I0802 04:41:56.400754 18637 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0802 04:41:56.400799 18638 device_alternate.hpp:116] NVML initialized on thread 139687373747968
I0802 04:41:56.401738 18638 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0802 04:41:56.405870 18637 solver.cpp:42] Solver data type: FLOAT
W0802 04:41:56.406304 18637 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:56.406393 18637 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.406399 18637 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.406435 18637 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:56.406450 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.410317 18638 solver.cpp:42] Solver data type: FLOAT
W0802 04:41:56.410688 18638 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:56.410758 18638 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.410761 18638 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.410786 18638 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:56.410797 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.411038 18639 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:56.411900 18640 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:56.413580 18637 data_layer.cpp:184] [1] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:56.413950 18638 data_layer.cpp:184] [2] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:56.414046 18637 data_layer.cpp:208] [1] Output data size: 43, 3, 224, 224
I0802 04:41:56.414052 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.414108 18638 data_layer.cpp:208] [2] Output data size: 43, 3, 224, 224
I0802 04:41:56.414117 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.871357 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0802 04:41:56.899570 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0802 04:41:56.900894 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0802 04:41:56.928280 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0802 04:41:56.929008 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0802 04:41:56.945242 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0802 04:41:56.957072 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0802 04:41:56.970396 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0802 04:41:56.972242 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0802 04:41:56.980752 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.64G, req 0G)
I0802 04:41:56.998411 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0802 04:41:57.013320 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.64G, req 0G)
I0802 04:41:57.013525 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.6G, req 0G)
I0802 04:41:57.024993 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0802 04:41:57.043541 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.6G, req 0G)
I0802 04:41:57.054344 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0802 04:41:57.080781 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.55G, req 0G)
I0802 04:41:57.102641 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 1 1 3  (limit 7.53G, req 0G)
I0802 04:41:57.108036 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.55G, req 0G)
I0802 04:41:57.115304 18637 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:57.115365 18637 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:57.115460 18637 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:57.115468 18637 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:57.115489 18637 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:57.115504 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:57.116323 18657 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:57.116919 18637 data_layer.cpp:184] (1) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:57.117030 18637 data_layer.cpp:208] (1) Output data size: 17, 3, 224, 224
I0802 04:41:57.117035 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:57.117722 18658 data_layer.cpp:97] (1) Parser threads: 1
I0802 04:41:57.117729 18658 data_layer.cpp:99] (1) Transformer threads: 1
I0802 04:41:57.124271 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0802 04:41:57.129130 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 7.53G, req 0G)
I0802 04:41:57.131852 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0802 04:41:57.138068 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.44G, req 0G)
I0802 04:41:57.142299 18638 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:57.142350 18638 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:57.142467 18638 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:57.142474 18638 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:57.142498 18638 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:57.142505 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:57.144170 18659 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:57.144332 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0802 04:41:57.144973 18638 data_layer.cpp:184] (2) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:57.145124 18638 data_layer.cpp:208] (2) Output data size: 17, 3, 224, 224
I0802 04:41:57.145133 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:57.145910 18660 data_layer.cpp:97] (2) Parser threads: 1
I0802 04:41:57.145925 18660 data_layer.cpp:99] (2) Transformer threads: 1
I0802 04:41:57.154600 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0802 04:41:57.156186 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0802 04:41:57.161520 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0802 04:41:57.161972 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0802 04:41:57.169631 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.43G, req 0G)
I0802 04:41:57.174918 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0802 04:41:57.175720 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0802 04:41:57.182627 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0802 04:41:57.185529 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0802 04:41:57.191018 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0802 04:41:57.206315 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0802 04:41:57.215036 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0802 04:41:57.223242 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0802 04:41:57.246142 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:57.256129 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0802 04:41:57.261837 18637 solver.cpp:56] Solver scaffolding done.
I0802 04:41:57.277657 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:57.290199 18638 solver.cpp:56] Solver scaffolding done.
I0802 04:41:57.334172 18637 parallel.cpp:164] [1 - 1] P2pSync adding callback
I0802 04:41:57.334193 18638 parallel.cpp:164] [2 - 2] P2pSync adding callback
I0802 04:41:57.334194 18636 parallel.cpp:164] [0 - 0] P2pSync adding callback
I0802 04:41:57.542634 18636 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 04:41:57.548943 18637 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.548959 18637 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.549031 18638 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.549038 18638 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.557137 18636 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.557152 18636 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.566503 18637 solver.cpp:268] Starting Optimization on GPU 1
I0802 04:41:57.566504 18636 solver.cpp:268] Starting Optimization on GPU 0
I0802 04:41:57.566504 18638 solver.cpp:268] Starting Optimization on GPU 2
I0802 04:41:57.566668 18636 solver.cpp:550] Iteration 0, Testing net (#0)
I0802 04:41:57.566720 18663 device_alternate.hpp:116] NVML initialized on thread 139545555494656
I0802 04:41:57.566741 18663 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0802 04:41:57.566751 18661 device_alternate.hpp:116] NVML initialized on thread 139545547101952
I0802 04:41:57.566766 18661 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0802 04:41:57.566776 18662 device_alternate.hpp:116] NVML initialized on thread 139545538709248
I0802 04:41:57.566784 18662 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0802 04:41:57.576212 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.3G, req 0G)
I0802 04:41:57.578899 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.3G, req 0G)
I0802 04:41:57.585031 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.24G, req 0G)
I0802 04:41:57.587999 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.24G, req 0G)
I0802 04:41:57.598659 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.24G, req 0G)
I0802 04:41:57.600513 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.17G, req 0G)
I0802 04:41:57.601436 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.17G, req 0G)
I0802 04:41:57.607422 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.14G, req 0G)
I0802 04:41:57.608446 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.14G, req 0G)
I0802 04:41:57.610725 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.17G, req 0G)
I0802 04:41:57.615265 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.11G, req 0G)
I0802 04:41:57.615890 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.11G, req 0G)
I0802 04:41:57.620972 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0802 04:41:57.622221 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0802 04:41:57.622462 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 1  (limit 7.1G, req 0G)
I0802 04:41:57.628850 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.629439 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.07G, req 0G)
I0802 04:41:57.631719 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.07G, req 0G)
I0802 04:41:57.634940 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.636811 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.637799 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.04G, req 0G)
I0802 04:41:57.642558 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.02G, req 0G)
I0802 04:41:57.643242 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.06G, req 0G)
I0802 04:41:57.645154 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.06G, req 0G)
I0802 04:41:57.649615 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.06G, req 0G)
I0802 04:41:57.650171 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.06G, req 0G)
I0802 04:41:57.652117 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.01G, req 0G)
I0802 04:41:57.655248 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7G, req 0G)
I0802 04:41:57.661854 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 6.99G, req 0G)
I0802 04:41:57.666119 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 6.99G, req 0G)
I0802 04:41:57.670177 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.411765
I0802 04:41:57.670189 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.529412
I0802 04:41:57.670194 18636 solver.cpp:635]     Test net output #2: loss = 2.68052 (* 1 = 2.68052 loss)
I0802 04:41:57.670212 18636 solver.cpp:295] [MultiGPU] Initial Test completed
I0802 04:41:57.670230 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 04:41:57.764883 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7G, req 0G)
I0802 04:41:57.766609 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7G, req 0G)
I0802 04:41:57.767659 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 6.93G, req 0G)
I0802 04:41:57.797825 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.86G, req 0G)
I0802 04:41:57.800348 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.86G, req 0G)
I0802 04:41:57.803140 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.79G, req 0G)
I0802 04:41:57.830986 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 6.7G, req 0G)
I0802 04:41:57.836990 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.7G, req 0G)
I0802 04:41:57.837196 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.63G, req 0G)
I0802 04:41:57.849103 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.63G, req 0G)
I0802 04:41:57.854073 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.63G, req 0G)
I0802 04:41:57.854231 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.56G, req 0G)
I0802 04:41:57.874125 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.55G, req 0G)
I0802 04:41:57.883646 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 6.48G, req 0G)
I0802 04:41:57.884027 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.51G, req 0G)
I0802 04:41:57.884508 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.55G, req 0G)
I0802 04:41:57.893481 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.44G, req 0G)
I0802 04:41:57.895653 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.51G, req 0G)
I0802 04:41:57.908303 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.47G, req 0G)
I0802 04:41:57.914922 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.39G, req 0G)
I0802 04:41:57.916596 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.45G, req 0G)
I0802 04:41:57.917002 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.47G, req 0G)
I0802 04:41:57.923189 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.37G, req 0G)
I0802 04:41:57.925855 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.45G, req 0G)
I0802 04:41:57.944221 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 3  (limit 6.42G, req 0G)
I0802 04:41:57.948272 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.34G, req 0G)
I0802 04:41:57.950654 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.42G, req 0G)
I0802 04:41:57.953498 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 6.41G, req 0G)
I0802 04:41:57.956415 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 6.33G, req 0G)
I0802 04:41:57.959470 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 6.41G, req 0G)
I0802 04:41:58.009326 18641 data_layer.cpp:97] [1] Parser threads: 1
I0802 04:41:58.009343 18641 data_layer.cpp:99] [1] Transformer threads: 1
I0802 04:41:58.012058 18598 data_layer.cpp:97] [0] Parser threads: 1
I0802 04:41:58.012068 18598 data_layer.cpp:99] [0] Transformer threads: 1
I0802 04:41:58.016244 18642 data_layer.cpp:97] [2] Parser threads: 1
I0802 04:41:58.016253 18642 data_layer.cpp:99] [2] Transformer threads: 1
I0802 04:41:58.161202 18636 solver.cpp:358] Iteration 0 (0.490953 s), loss = 1.14066
I0802 04:41:58.161224 18636 solver.cpp:375]     Train net output #0: loss = 1.13888 (* 1 = 1.13888 loss)
I0802 04:41:58.161229 18636 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0802 04:41:58.188468 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.4G, req 0G)
I0802 04:41:58.189609 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.31G, req 0G)
I0802 04:41:58.190129 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.4G, req 0G)
I0802 04:41:58.258949 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.259146 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.259600 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.6G, req 0G)
I0802 04:41:58.307332 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 3  (limit 4.6G, req 0G)
I0802 04:41:58.308959 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 1  (limit 4.69G, req 0G)
I0802 04:41:58.309664 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.326849 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.6G, req 0G)
I0802 04:41:58.330370 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.69G, req 0G)
I0802 04:41:58.332389 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.69G, req 0G)
I0802 04:41:58.358510 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.365193 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.366474 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.376209 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 1 4 3  (limit 4.6G, req 0.06G)
I0802 04:41:58.379575 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.386618 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 1 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.412219 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.418045 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.422755 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.428756 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.6G, req 0.06G)
I0802 04:41:58.435308 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.439368 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.478915 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.491147 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.493398 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 6 1 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.494364 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.504158 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 7 1 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.506006 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 7 1 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.535116 18636 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.547755 18638 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.549535 18637 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.632644 18636 solver.cpp:358] Iteration 1 (0.471423 s), loss = 1.05683
I0802 04:41:58.632673 18636 solver.cpp:375]     Train net output #0: loss = 1.29804 (* 1 = 1.29804 loss)
I0802 04:41:58.780123 18636 solver.cpp:358] Iteration 2 (0.147465 s), loss = 1.33586
I0802 04:41:58.780151 18636 solver.cpp:375]     Train net output #0: loss = 1.42587 (* 1 = 1.42587 loss)
I0802 04:42:12.300084 18636 solver.cpp:353] Iteration 100 (7.24874 iter/s, 13.5196s/98 iter), loss = 1.40792
I0802 04:42:12.300109 18636 solver.cpp:375]     Train net output #0: loss = 1.27096 (* 1 = 1.27096 loss)
I0802 04:42:12.300113 18636 sgd_solver.cpp:136] Iteration 100, lr = 0.00999375, m = 0.9
I0802 04:42:26.194919 18636 solver.cpp:353] Iteration 200 (7.19712 iter/s, 13.8945s/100 iter), loss = 1.4507
I0802 04:42:26.194984 18636 solver.cpp:375]     Train net output #0: loss = 1.43852 (* 1 = 1.43852 loss)
I0802 04:42:26.194991 18636 sgd_solver.cpp:136] Iteration 200, lr = 0.0099875, m = 0.9
I0802 04:42:40.100770 18636 solver.cpp:353] Iteration 300 (7.19142 iter/s, 13.9055s/100 iter), loss = 1.76461
I0802 04:42:40.100800 18636 solver.cpp:375]     Train net output #0: loss = 1.63631 (* 1 = 1.63631 loss)
I0802 04:42:40.100806 18636 sgd_solver.cpp:136] Iteration 300, lr = 0.00998125, m = 0.9
I0802 04:42:53.953501 18636 solver.cpp:353] Iteration 400 (7.21899 iter/s, 13.8524s/100 iter), loss = 1.49658
I0802 04:42:53.953527 18636 solver.cpp:375]     Train net output #0: loss = 1.63474 (* 1 = 1.63474 loss)
I0802 04:42:53.953532 18636 sgd_solver.cpp:136] Iteration 400, lr = 0.009975, m = 0.9
I0802 04:43:07.782989 18636 solver.cpp:353] Iteration 500 (7.23112 iter/s, 13.8291s/100 iter), loss = 1.39605
I0802 04:43:07.783044 18636 solver.cpp:375]     Train net output #0: loss = 1.23662 (* 1 = 1.23662 loss)
I0802 04:43:07.783049 18636 sgd_solver.cpp:136] Iteration 500, lr = 0.00996875, m = 0.9
I0802 04:43:21.711097 18636 solver.cpp:353] Iteration 600 (7.17992 iter/s, 13.9277s/100 iter), loss = 1.2038
I0802 04:43:21.711123 18636 solver.cpp:375]     Train net output #0: loss = 1.3082 (* 1 = 1.3082 loss)
I0802 04:43:21.711129 18636 sgd_solver.cpp:136] Iteration 600, lr = 0.0099625, m = 0.9
I0802 04:43:35.592906 18636 solver.cpp:353] Iteration 700 (7.20387 iter/s, 13.8814s/100 iter), loss = 1.25342
I0802 04:43:35.592932 18636 solver.cpp:375]     Train net output #0: loss = 1.41266 (* 1 = 1.41266 loss)
I0802 04:43:35.592937 18636 sgd_solver.cpp:136] Iteration 700, lr = 0.00995625, m = 0.9
I0802 04:43:49.510676 18636 solver.cpp:353] Iteration 800 (7.18525 iter/s, 13.9174s/100 iter), loss = 1.32427
I0802 04:43:49.510783 18636 solver.cpp:375]     Train net output #0: loss = 1.43607 (* 1 = 1.43607 loss)
I0802 04:43:49.510792 18636 sgd_solver.cpp:136] Iteration 800, lr = 0.00995, m = 0.9
I0802 04:44:03.318053 18636 solver.cpp:353] Iteration 900 (7.2427 iter/s, 13.807s/100 iter), loss = 1.33455
I0802 04:44:03.318084 18636 solver.cpp:375]     Train net output #0: loss = 1.57395 (* 1 = 1.57395 loss)
I0802 04:44:03.318089 18636 sgd_solver.cpp:136] Iteration 900, lr = 0.00994375, m = 0.9
I0802 04:44:17.025671 18636 solver.cpp:404] Sparsity after update:
I0802 04:44:17.036933 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:44:17.036975 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:44:17.036996 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:44:17.037008 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:44:17.037016 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:44:17.037025 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:44:17.037034 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:44:17.037045 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:44:17.037055 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:44:17.037062 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:44:17.037071 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:44:17.037080 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:44:17.037088 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:44:17.178385 18636 solver.cpp:353] Iteration 1000 (7.21503 iter/s, 13.86s/100 iter), loss = 1.47177
I0802 04:44:17.178416 18636 solver.cpp:375]     Train net output #0: loss = 1.28685 (* 1 = 1.28685 loss)
I0802 04:44:17.178422 18636 sgd_solver.cpp:136] Iteration 1000, lr = 0.0099375, m = 0.9
I0802 04:44:31.085815 18636 solver.cpp:353] Iteration 1100 (7.1906 iter/s, 13.9071s/100 iter), loss = 1.53807
I0802 04:44:31.086923 18636 solver.cpp:375]     Train net output #0: loss = 1.63114 (* 1 = 1.63114 loss)
I0802 04:44:31.086933 18636 sgd_solver.cpp:136] Iteration 1100, lr = 0.00993125, m = 0.9
I0802 04:44:44.993254 18636 solver.cpp:353] Iteration 1200 (7.19059 iter/s, 13.9071s/100 iter), loss = 1.5934
I0802 04:44:44.993284 18636 solver.cpp:375]     Train net output #0: loss = 1.63936 (* 1 = 1.63936 loss)
I0802 04:44:44.993290 18636 sgd_solver.cpp:136] Iteration 1200, lr = 0.009925, m = 0.9
I0802 04:44:58.837923 18636 solver.cpp:353] Iteration 1300 (7.22319 iter/s, 13.8443s/100 iter), loss = 1.30213
I0802 04:44:58.837947 18636 solver.cpp:375]     Train net output #0: loss = 1.04995 (* 1 = 1.04995 loss)
I0802 04:44:58.837951 18636 sgd_solver.cpp:136] Iteration 1300, lr = 0.00991875, m = 0.9
I0802 04:45:12.710419 18636 solver.cpp:353] Iteration 1400 (7.2087 iter/s, 13.8721s/100 iter), loss = 1.20778
I0802 04:45:12.710502 18636 solver.cpp:375]     Train net output #0: loss = 1.30892 (* 1 = 1.30892 loss)
I0802 04:45:12.710510 18636 sgd_solver.cpp:136] Iteration 1400, lr = 0.0099125, m = 0.9
I0802 04:45:26.571426 18636 solver.cpp:353] Iteration 1500 (7.21468 iter/s, 13.8606s/100 iter), loss = 1.49515
I0802 04:45:26.571455 18636 solver.cpp:375]     Train net output #0: loss = 1.64644 (* 1 = 1.64644 loss)
I0802 04:45:26.571461 18636 sgd_solver.cpp:136] Iteration 1500, lr = 0.00990625, m = 0.9
I0802 04:45:40.444102 18636 solver.cpp:353] Iteration 1600 (7.20861 iter/s, 13.8723s/100 iter), loss = 1.79271
I0802 04:45:40.444130 18636 solver.cpp:375]     Train net output #0: loss = 1.996 (* 1 = 1.996 loss)
I0802 04:45:40.444139 18636 sgd_solver.cpp:136] Iteration 1600, lr = 0.0099, m = 0.9
I0802 04:45:54.343536 18636 solver.cpp:353] Iteration 1700 (7.19473 iter/s, 13.8991s/100 iter), loss = 1.32072
I0802 04:45:54.343616 18636 solver.cpp:375]     Train net output #0: loss = 1.47131 (* 1 = 1.47131 loss)
I0802 04:45:54.343622 18636 sgd_solver.cpp:136] Iteration 1700, lr = 0.00989375, m = 0.9
I0802 04:46:08.220157 18636 solver.cpp:353] Iteration 1800 (7.20656 iter/s, 13.8762s/100 iter), loss = 1.50691
I0802 04:46:08.220247 18636 solver.cpp:375]     Train net output #0: loss = 1.57113 (* 1 = 1.57113 loss)
I0802 04:46:08.220265 18636 sgd_solver.cpp:136] Iteration 1800, lr = 0.0098875, m = 0.9
I0802 04:46:22.067145 18636 solver.cpp:353] Iteration 1900 (7.22198 iter/s, 13.8466s/100 iter), loss = 1.41145
I0802 04:46:22.067217 18636 solver.cpp:375]     Train net output #0: loss = 1.5441 (* 1 = 1.5441 loss)
I0802 04:46:22.067236 18636 sgd_solver.cpp:136] Iteration 1900, lr = 0.00988125, m = 0.9
I0802 04:46:35.831696 18636 solver.cpp:404] Sparsity after update:
I0802 04:46:35.844086 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:46:35.844106 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:46:35.844115 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:46:35.844117 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:46:35.844120 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:46:35.844123 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:46:35.844126 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:46:35.844137 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:46:35.844146 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:46:35.844154 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:46:35.844162 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:46:35.844172 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:46:35.844179 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:46:35.844202 18636 solver.cpp:550] Iteration 2000, Testing net (#0)
I0802 04:46:53.897833 18619 data_reader.cpp:264] Starting prefetch of epoch 1
I0802 04:46:55.213395 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.541824
I0802 04:46:55.213418 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.782175
I0802 04:46:55.213426 18636 solver.cpp:635]     Test net output #2: loss = 2.0454 (* 1 = 2.0454 loss)
I0802 04:46:55.213449 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3687s
I0802 04:46:55.365571 18636 solver.cpp:353] Iteration 2000 (3.00322 iter/s, 33.2975s/100 iter), loss = 1.5267
I0802 04:46:55.365595 18636 solver.cpp:375]     Train net output #0: loss = 1.77623 (* 1 = 1.77623 loss)
I0802 04:46:55.365599 18636 sgd_solver.cpp:136] Iteration 2000, lr = 0.009875, m = 0.9
I0802 04:47:09.262711 18636 solver.cpp:353] Iteration 2100 (7.19592 iter/s, 13.8968s/100 iter), loss = 1.31399
I0802 04:47:09.262951 18636 solver.cpp:375]     Train net output #0: loss = 1.44549 (* 1 = 1.44549 loss)
I0802 04:47:09.262959 18636 sgd_solver.cpp:136] Iteration 2100, lr = 0.00986875, m = 0.9
I0802 04:47:23.096982 18636 solver.cpp:353] Iteration 2200 (7.22862 iter/s, 13.8339s/100 iter), loss = 1.62425
I0802 04:47:23.097007 18636 solver.cpp:375]     Train net output #0: loss = 1.81043 (* 1 = 1.81043 loss)
I0802 04:47:23.097010 18636 sgd_solver.cpp:136] Iteration 2200, lr = 0.0098625, m = 0.9
I0802 04:47:36.935868 18636 solver.cpp:353] Iteration 2300 (7.22621 iter/s, 13.8385s/100 iter), loss = 1.37867
I0802 04:47:36.935897 18636 solver.cpp:375]     Train net output #0: loss = 1.36032 (* 1 = 1.36032 loss)
I0802 04:47:36.935904 18636 sgd_solver.cpp:136] Iteration 2300, lr = 0.00985625, m = 0.9
I0802 04:47:50.846935 18636 solver.cpp:353] Iteration 2400 (7.18872 iter/s, 13.9107s/100 iter), loss = 1.60656
I0802 04:47:50.846998 18636 solver.cpp:375]     Train net output #0: loss = 1.64311 (* 1 = 1.64311 loss)
I0802 04:47:50.847005 18636 sgd_solver.cpp:136] Iteration 2400, lr = 0.00985, m = 0.9
I0802 04:48:04.728579 18636 solver.cpp:353] Iteration 2500 (7.20395 iter/s, 13.8813s/100 iter), loss = 1.1758
I0802 04:48:04.728603 18636 solver.cpp:375]     Train net output #0: loss = 1.12295 (* 1 = 1.12295 loss)
I0802 04:48:04.728610 18636 sgd_solver.cpp:136] Iteration 2500, lr = 0.00984375, m = 0.9
I0802 04:48:18.610437 18636 solver.cpp:353] Iteration 2600 (7.20384 iter/s, 13.8815s/100 iter), loss = 1.74137
I0802 04:48:18.610463 18636 solver.cpp:375]     Train net output #0: loss = 1.81678 (* 1 = 1.81678 loss)
I0802 04:48:18.610469 18636 sgd_solver.cpp:136] Iteration 2600, lr = 0.0098375, m = 0.9
I0802 04:48:32.503883 18636 solver.cpp:353] Iteration 2700 (7.19783 iter/s, 13.8931s/100 iter), loss = 1.40645
I0802 04:48:32.504009 18636 solver.cpp:375]     Train net output #0: loss = 1.50965 (* 1 = 1.50965 loss)
I0802 04:48:32.504016 18636 sgd_solver.cpp:136] Iteration 2700, lr = 0.00983125, m = 0.9
I0802 04:48:46.338052 18636 solver.cpp:353] Iteration 2800 (7.22867 iter/s, 13.8338s/100 iter), loss = 1.46026
I0802 04:48:46.338083 18636 solver.cpp:375]     Train net output #0: loss = 1.59502 (* 1 = 1.59502 loss)
I0802 04:48:46.338088 18636 sgd_solver.cpp:136] Iteration 2800, lr = 0.009825, m = 0.9
I0802 04:49:00.181720 18636 solver.cpp:353] Iteration 2900 (7.22371 iter/s, 13.8433s/100 iter), loss = 1.42592
I0802 04:49:00.181746 18636 solver.cpp:375]     Train net output #0: loss = 1.30748 (* 1 = 1.30748 loss)
I0802 04:49:00.181751 18636 sgd_solver.cpp:136] Iteration 2900, lr = 0.00981875, m = 0.9
I0802 04:49:13.945041 18636 solver.cpp:404] Sparsity after update:
I0802 04:49:13.979758 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:49:13.979779 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:49:13.979786 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:49:13.979789 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:49:13.979792 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:49:13.979795 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:49:13.979799 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:49:13.979804 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:49:13.979806 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:49:13.979809 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:49:13.980067 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:49:13.980080 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:49:13.980166 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:49:14.109004 18636 solver.cpp:353] Iteration 3000 (7.18034 iter/s, 13.9269s/100 iter), loss = 1.66629
I0802 04:49:14.109028 18636 solver.cpp:375]     Train net output #0: loss = 1.92017 (* 1 = 1.92017 loss)
I0802 04:49:14.109035 18636 sgd_solver.cpp:136] Iteration 3000, lr = 0.0098125, m = 0.9
I0802 04:49:28.056218 18636 solver.cpp:353] Iteration 3100 (7.17009 iter/s, 13.9468s/100 iter), loss = 1.65539
I0802 04:49:28.056249 18636 solver.cpp:375]     Train net output #0: loss = 1.46319 (* 1 = 1.46319 loss)
I0802 04:49:28.056255 18636 sgd_solver.cpp:136] Iteration 3100, lr = 0.00980625, m = 0.9
I0802 04:49:41.921808 18636 solver.cpp:353] Iteration 3200 (7.21229 iter/s, 13.8652s/100 iter), loss = 1.57357
I0802 04:49:41.921834 18636 solver.cpp:375]     Train net output #0: loss = 1.8228 (* 1 = 1.8228 loss)
I0802 04:49:41.921838 18636 sgd_solver.cpp:136] Iteration 3200, lr = 0.0098, m = 0.9
I0802 04:49:55.893332 18636 solver.cpp:353] Iteration 3300 (7.15761 iter/s, 13.9712s/100 iter), loss = 1.44518
I0802 04:49:55.893416 18636 solver.cpp:375]     Train net output #0: loss = 1.50991 (* 1 = 1.50991 loss)
I0802 04:49:55.893424 18636 sgd_solver.cpp:136] Iteration 3300, lr = 0.00979375, m = 0.9
I0802 04:50:09.781358 18636 solver.cpp:353] Iteration 3400 (7.20064 iter/s, 13.8877s/100 iter), loss = 1.34996
I0802 04:50:09.781381 18636 solver.cpp:375]     Train net output #0: loss = 1.42667 (* 1 = 1.42667 loss)
I0802 04:50:09.781388 18636 sgd_solver.cpp:136] Iteration 3400, lr = 0.0097875, m = 0.9
I0802 04:50:23.670627 18636 solver.cpp:353] Iteration 3500 (7.2 iter/s, 13.8889s/100 iter), loss = 1.75447
I0802 04:50:23.670652 18636 solver.cpp:375]     Train net output #0: loss = 1.28846 (* 1 = 1.28846 loss)
I0802 04:50:23.670656 18636 sgd_solver.cpp:136] Iteration 3500, lr = 0.00978125, m = 0.9
I0802 04:50:37.614274 18636 solver.cpp:353] Iteration 3600 (7.17192 iter/s, 13.9433s/100 iter), loss = 1.41468
I0802 04:50:37.614353 18636 solver.cpp:375]     Train net output #0: loss = 1.50341 (* 1 = 1.50341 loss)
I0802 04:50:37.614361 18636 sgd_solver.cpp:136] Iteration 3600, lr = 0.009775, m = 0.9
I0802 04:50:51.499898 18636 solver.cpp:353] Iteration 3700 (7.20189 iter/s, 13.8852s/100 iter), loss = 1.63415
I0802 04:50:51.499925 18636 solver.cpp:375]     Train net output #0: loss = 2.341 (* 1 = 2.341 loss)
I0802 04:50:51.499933 18636 sgd_solver.cpp:136] Iteration 3700, lr = 0.00976875, m = 0.9
I0802 04:51:05.373553 18636 solver.cpp:353] Iteration 3800 (7.2081 iter/s, 13.8733s/100 iter), loss = 1.85738
I0802 04:51:05.373581 18636 solver.cpp:375]     Train net output #0: loss = 1.82473 (* 1 = 1.82473 loss)
I0802 04:51:05.373589 18636 sgd_solver.cpp:136] Iteration 3800, lr = 0.0097625, m = 0.9
I0802 04:51:19.194438 18636 solver.cpp:353] Iteration 3900 (7.23562 iter/s, 13.8205s/100 iter), loss = 1.5445
I0802 04:51:19.194538 18636 solver.cpp:375]     Train net output #0: loss = 1.46924 (* 1 = 1.46924 loss)
I0802 04:51:19.194546 18636 sgd_solver.cpp:136] Iteration 3900, lr = 0.00975625, m = 0.9
I0802 04:51:32.979055 18636 solver.cpp:404] Sparsity after update:
I0802 04:51:32.982990 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:51:32.983003 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:51:32.983011 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:51:32.983016 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:51:32.983031 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:51:32.983042 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:51:32.983052 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:51:32.983059 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:51:32.983068 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:51:32.983078 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:51:32.983085 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:51:32.983094 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:51:32.983103 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:51:32.983122 18636 solver.cpp:550] Iteration 4000, Testing net (#0)
I0802 04:51:52.276240 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.541118
I0802 04:51:52.276363 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.780409
I0802 04:51:52.276374 18636 solver.cpp:635]     Test net output #2: loss = 2.06271 (* 1 = 2.06271 loss)
I0802 04:51:52.276393 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2928s
I0802 04:51:52.418325 18636 solver.cpp:353] Iteration 4000 (3.00996 iter/s, 33.223s/100 iter), loss = 1.47225
I0802 04:51:52.418352 18636 solver.cpp:375]     Train net output #0: loss = 1.49732 (* 1 = 1.49732 loss)
I0802 04:51:52.418357 18636 sgd_solver.cpp:136] Iteration 4000, lr = 0.00975, m = 0.9
I0802 04:52:06.320499 18636 solver.cpp:353] Iteration 4100 (7.19331 iter/s, 13.9018s/100 iter), loss = 1.40722
I0802 04:52:06.320529 18636 solver.cpp:375]     Train net output #0: loss = 1.42812 (* 1 = 1.42812 loss)
I0802 04:52:06.320535 18636 sgd_solver.cpp:136] Iteration 4100, lr = 0.00974375, m = 0.9
I0802 04:52:20.297951 18636 solver.cpp:353] Iteration 4200 (7.15458 iter/s, 13.9771s/100 iter), loss = 1.27217
I0802 04:52:20.298018 18636 solver.cpp:375]     Train net output #0: loss = 1.32106 (* 1 = 1.32106 loss)
I0802 04:52:20.298032 18636 sgd_solver.cpp:136] Iteration 4200, lr = 0.0097375, m = 0.9
I0802 04:52:34.153208 18636 solver.cpp:353] Iteration 4300 (7.21767 iter/s, 13.8549s/100 iter), loss = 1.78682
I0802 04:52:34.153280 18636 solver.cpp:375]     Train net output #0: loss = 1.87984 (* 1 = 1.87984 loss)
I0802 04:52:34.153287 18636 sgd_solver.cpp:136] Iteration 4300, lr = 0.00973125, m = 0.9
I0802 04:52:48.078076 18636 solver.cpp:353] Iteration 4400 (7.18159 iter/s, 13.9245s/100 iter), loss = 1.65482
I0802 04:52:48.078105 18636 solver.cpp:375]     Train net output #0: loss = 1.87672 (* 1 = 1.87672 loss)
I0802 04:52:48.078111 18636 sgd_solver.cpp:136] Iteration 4400, lr = 0.009725, m = 0.9
I0802 04:53:01.875010 18636 solver.cpp:353] Iteration 4500 (7.24818 iter/s, 13.7966s/100 iter), loss = 1.5807
I0802 04:53:01.875039 18636 solver.cpp:375]     Train net output #0: loss = 1.69783 (* 1 = 1.69783 loss)
I0802 04:53:01.875046 18636 sgd_solver.cpp:136] Iteration 4500, lr = 0.00971875, m = 0.9
I0802 04:53:15.741317 18636 solver.cpp:353] Iteration 4600 (7.21192 iter/s, 13.8659s/100 iter), loss = 1.60366
I0802 04:53:15.741477 18636 solver.cpp:375]     Train net output #0: loss = 1.69297 (* 1 = 1.69297 loss)
I0802 04:53:15.741498 18636 sgd_solver.cpp:136] Iteration 4600, lr = 0.0097125, m = 0.9
I0802 04:53:29.565253 18636 solver.cpp:353] Iteration 4700 (7.23402 iter/s, 13.8236s/100 iter), loss = 1.98118
I0802 04:53:29.565281 18636 solver.cpp:375]     Train net output #0: loss = 1.79589 (* 1 = 1.79589 loss)
I0802 04:53:29.565287 18636 sgd_solver.cpp:136] Iteration 4700, lr = 0.00970625, m = 0.9
I0802 04:53:43.420809 18636 solver.cpp:353] Iteration 4800 (7.21752 iter/s, 13.8552s/100 iter), loss = 1.44386
I0802 04:53:43.420843 18636 solver.cpp:375]     Train net output #0: loss = 1.97463 (* 1 = 1.97463 loss)
I0802 04:53:43.420850 18636 sgd_solver.cpp:136] Iteration 4800, lr = 0.0097, m = 0.9
I0802 04:53:57.320909 18636 solver.cpp:353] Iteration 4900 (7.19439 iter/s, 13.8997s/100 iter), loss = 1.51961
I0802 04:53:57.320992 18636 solver.cpp:375]     Train net output #0: loss = 1.54783 (* 1 = 1.54783 loss)
I0802 04:53:57.321004 18636 sgd_solver.cpp:136] Iteration 4900, lr = 0.00969375, m = 0.9
I0802 04:54:11.059767 18636 solver.cpp:404] Sparsity after update:
I0802 04:54:11.070971 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:54:11.070986 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:54:11.070994 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:54:11.070997 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:54:11.071000 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:54:11.071003 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:54:11.071007 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:54:11.071009 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:54:11.071012 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:54:11.071015 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:54:11.071018 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:54:11.071022 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:54:11.071024 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:54:11.210940 18636 solver.cpp:353] Iteration 5000 (7.1996 iter/s, 13.8897s/100 iter), loss = 1.5357
I0802 04:54:11.210966 18636 solver.cpp:375]     Train net output #0: loss = 2.02582 (* 1 = 2.02582 loss)
I0802 04:54:11.210973 18636 sgd_solver.cpp:136] Iteration 5000, lr = 0.0096875, m = 0.9
I0802 04:54:25.051344 18636 solver.cpp:353] Iteration 5100 (7.22542 iter/s, 13.84s/100 iter), loss = 1.27904
I0802 04:54:25.051369 18636 solver.cpp:375]     Train net output #0: loss = 1.11084 (* 1 = 1.11084 loss)
I0802 04:54:25.051375 18636 sgd_solver.cpp:136] Iteration 5100, lr = 0.00968125, m = 0.9
I0802 04:54:38.944774 18636 solver.cpp:353] Iteration 5200 (7.19784 iter/s, 13.8931s/100 iter), loss = 1.32342
I0802 04:54:38.944840 18636 solver.cpp:375]     Train net output #0: loss = 1.34547 (* 1 = 1.34547 loss)
I0802 04:54:38.944847 18636 sgd_solver.cpp:136] Iteration 5200, lr = 0.009675, m = 0.9
I0802 04:54:52.763200 18636 solver.cpp:353] Iteration 5300 (7.23691 iter/s, 13.8181s/100 iter), loss = 1.48829
I0802 04:54:52.763227 18636 solver.cpp:375]     Train net output #0: loss = 1.49274 (* 1 = 1.49274 loss)
I0802 04:54:52.763234 18636 sgd_solver.cpp:136] Iteration 5300, lr = 0.00966875, m = 0.9
I0802 04:55:06.671777 18636 solver.cpp:353] Iteration 5400 (7.19 iter/s, 13.9082s/100 iter), loss = 1.49806
I0802 04:55:06.671829 18636 solver.cpp:375]     Train net output #0: loss = 1.83859 (* 1 = 1.83859 loss)
I0802 04:55:06.671841 18636 sgd_solver.cpp:136] Iteration 5400, lr = 0.0096625, m = 0.9
I0802 04:55:20.519006 18636 solver.cpp:353] Iteration 5500 (7.22186 iter/s, 13.8469s/100 iter), loss = 1.26795
I0802 04:55:20.519109 18636 solver.cpp:375]     Train net output #0: loss = 1.24585 (* 1 = 1.24585 loss)
I0802 04:55:20.519120 18636 sgd_solver.cpp:136] Iteration 5500, lr = 0.00965625, m = 0.9
I0802 04:55:34.392174 18636 solver.cpp:353] Iteration 5600 (7.20835 iter/s, 13.8728s/100 iter), loss = 1.65233
I0802 04:55:34.392202 18636 solver.cpp:375]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I0802 04:55:34.392208 18636 sgd_solver.cpp:136] Iteration 5600, lr = 0.00965, m = 0.9
I0802 04:55:48.339846 18636 solver.cpp:353] Iteration 5700 (7.16985 iter/s, 13.9473s/100 iter), loss = 1.83073
I0802 04:55:48.339875 18636 solver.cpp:375]     Train net output #0: loss = 1.81682 (* 1 = 1.81682 loss)
I0802 04:55:48.339881 18636 sgd_solver.cpp:136] Iteration 5700, lr = 0.00964375, m = 0.9
I0802 04:56:02.207470 18636 solver.cpp:353] Iteration 5800 (7.21123 iter/s, 13.8673s/100 iter), loss = 1.44008
I0802 04:56:02.207540 18636 solver.cpp:375]     Train net output #0: loss = 1.51265 (* 1 = 1.51265 loss)
I0802 04:56:02.207548 18636 sgd_solver.cpp:136] Iteration 5800, lr = 0.0096375, m = 0.9
I0802 04:56:16.144201 18636 solver.cpp:353] Iteration 5900 (7.17548 iter/s, 13.9364s/100 iter), loss = 1.26119
I0802 04:56:16.144228 18636 solver.cpp:375]     Train net output #0: loss = 1.20156 (* 1 = 1.20156 loss)
I0802 04:56:16.144232 18636 sgd_solver.cpp:136] Iteration 5900, lr = 0.00963125, m = 0.9
I0802 04:56:29.858077 18636 solver.cpp:404] Sparsity after update:
I0802 04:56:29.862864 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:56:29.862880 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:56:29.862888 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:56:29.862891 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:56:29.862895 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:56:29.862897 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:56:29.862900 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:56:29.862917 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:56:29.862931 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:56:29.862941 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:56:29.862949 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:56:29.862958 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:56:29.862967 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:56:29.862985 18636 solver.cpp:550] Iteration 6000, Testing net (#0)
I0802 04:56:49.047332 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.543
I0802 04:56:49.047427 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.785292
I0802 04:56:49.047436 18636 solver.cpp:635]     Test net output #2: loss = 2.02456 (* 1 = 2.02456 loss)
I0802 04:56:49.047456 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.184s
I0802 04:56:49.185627 18636 solver.cpp:353] Iteration 6000 (3.02658 iter/s, 33.0405s/100 iter), loss = 1.51495
I0802 04:56:49.185653 18636 solver.cpp:375]     Train net output #0: loss = 1.57783 (* 1 = 1.57783 loss)
I0802 04:56:49.185657 18636 sgd_solver.cpp:136] Iteration 6000, lr = 0.009625, m = 0.9
I0802 04:57:03.031970 18636 solver.cpp:353] Iteration 6100 (7.22232 iter/s, 13.846s/100 iter), loss = 1.48361
I0802 04:57:03.031998 18636 solver.cpp:375]     Train net output #0: loss = 1.42167 (* 1 = 1.42167 loss)
I0802 04:57:03.032004 18636 sgd_solver.cpp:136] Iteration 6100, lr = 0.00961875, m = 0.9
I0802 04:57:16.944602 18636 solver.cpp:353] Iteration 6200 (7.18791 iter/s, 13.9123s/100 iter), loss = 2.01327
I0802 04:57:16.944661 18636 solver.cpp:375]     Train net output #0: loss = 1.75674 (* 1 = 1.75674 loss)
I0802 04:57:16.944677 18636 sgd_solver.cpp:136] Iteration 6200, lr = 0.0096125, m = 0.9
I0802 04:57:30.874598 18636 solver.cpp:353] Iteration 6300 (7.17895 iter/s, 13.9296s/100 iter), loss = 1.34817
I0802 04:57:30.874694 18636 solver.cpp:375]     Train net output #0: loss = 1.42854 (* 1 = 1.42854 loss)
I0802 04:57:30.874701 18636 sgd_solver.cpp:136] Iteration 6300, lr = 0.00960625, m = 0.9
I0802 04:57:44.823580 18636 solver.cpp:353] Iteration 6400 (7.16918 iter/s, 13.9486s/100 iter), loss = 1.37892
I0802 04:57:44.823609 18636 solver.cpp:375]     Train net output #0: loss = 1.6996 (* 1 = 1.6996 loss)
I0802 04:57:44.823614 18636 sgd_solver.cpp:136] Iteration 6400, lr = 0.0096, m = 0.9
I0802 04:57:58.783347 18636 solver.cpp:353] Iteration 6500 (7.16364 iter/s, 13.9594s/100 iter), loss = 1.60807
I0802 04:57:58.783375 18636 solver.cpp:375]     Train net output #0: loss = 1.41555 (* 1 = 1.41555 loss)
I0802 04:57:58.783378 18636 sgd_solver.cpp:136] Iteration 6500, lr = 0.00959375, m = 0.9
I0802 04:58:12.718683 18636 solver.cpp:353] Iteration 6600 (7.17619 iter/s, 13.935s/100 iter), loss = 1.20525
I0802 04:58:12.718767 18636 solver.cpp:375]     Train net output #0: loss = 0.978498 (* 1 = 0.978498 loss)
I0802 04:58:12.718775 18636 sgd_solver.cpp:136] Iteration 6600, lr = 0.0095875, m = 0.9
I0802 04:58:26.586509 18636 solver.cpp:353] Iteration 6700 (7.21113 iter/s, 13.8675s/100 iter), loss = 1.47858
I0802 04:58:26.586536 18636 solver.cpp:375]     Train net output #0: loss = 1.37219 (* 1 = 1.37219 loss)
I0802 04:58:26.586542 18636 sgd_solver.cpp:136] Iteration 6700, lr = 0.00958125, m = 0.9
I0802 04:58:40.606501 18636 solver.cpp:353] Iteration 6800 (7.13286 iter/s, 14.0196s/100 iter), loss = 1.3588
I0802 04:58:40.606526 18636 solver.cpp:375]     Train net output #0: loss = 1.53007 (* 1 = 1.53007 loss)
I0802 04:58:40.606530 18636 sgd_solver.cpp:136] Iteration 6800, lr = 0.009575, m = 0.9
I0802 04:58:54.601866 18636 solver.cpp:353] Iteration 6900 (7.14542 iter/s, 13.995s/100 iter), loss = 1.37586
I0802 04:58:54.601939 18636 solver.cpp:375]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I0802 04:58:54.601948 18636 sgd_solver.cpp:136] Iteration 6900, lr = 0.00956875, m = 0.9
I0802 04:59:08.353750 18636 solver.cpp:404] Sparsity after update:
I0802 04:59:08.368100 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:59:08.368115 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:59:08.368124 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:59:08.368127 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:59:08.368130 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:59:08.368142 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:59:08.368151 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:59:08.368160 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:59:08.368168 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:59:08.368176 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:59:08.368185 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:59:08.368193 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:59:08.368201 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:59:08.499538 18636 solver.cpp:353] Iteration 7000 (7.19564 iter/s, 13.8973s/100 iter), loss = 1.53921
I0802 04:59:08.499567 18636 solver.cpp:375]     Train net output #0: loss = 1.38604 (* 1 = 1.38604 loss)
I0802 04:59:08.499574 18636 sgd_solver.cpp:136] Iteration 7000, lr = 0.0095625, m = 0.9
I0802 04:59:22.366319 18636 solver.cpp:353] Iteration 7100 (7.21167 iter/s, 13.8664s/100 iter), loss = 1.82688
I0802 04:59:22.366343 18636 solver.cpp:375]     Train net output #0: loss = 2.00839 (* 1 = 2.00839 loss)
I0802 04:59:22.366349 18636 sgd_solver.cpp:136] Iteration 7100, lr = 0.00955625, m = 0.9
I0802 04:59:36.192361 18636 solver.cpp:353] Iteration 7200 (7.23292 iter/s, 13.8257s/100 iter), loss = 1.91382
I0802 04:59:36.192446 18636 solver.cpp:375]     Train net output #0: loss = 1.89274 (* 1 = 1.89274 loss)
I0802 04:59:36.192453 18636 sgd_solver.cpp:136] Iteration 7200, lr = 0.00955, m = 0.9
I0802 04:59:50.109035 18636 solver.cpp:353] Iteration 7300 (7.18582 iter/s, 13.9163s/100 iter), loss = 1.17835
I0802 04:59:50.109063 18636 solver.cpp:375]     Train net output #0: loss = 0.990199 (* 1 = 0.990199 loss)
I0802 04:59:50.109069 18636 sgd_solver.cpp:136] Iteration 7300, lr = 0.00954375, m = 0.9
I0802 05:00:03.990999 18636 solver.cpp:353] Iteration 7400 (7.20378 iter/s, 13.8816s/100 iter), loss = 1.72353
I0802 05:00:03.991029 18636 solver.cpp:375]     Train net output #0: loss = 1.57782 (* 1 = 1.57782 loss)
I0802 05:00:03.991036 18636 sgd_solver.cpp:136] Iteration 7400, lr = 0.0095375, m = 0.9
I0802 05:00:17.855082 18636 solver.cpp:353] Iteration 7500 (7.21308 iter/s, 13.8637s/100 iter), loss = 1.7722
I0802 05:00:17.855155 18636 solver.cpp:375]     Train net output #0: loss = 2.17071 (* 1 = 2.17071 loss)
I0802 05:00:17.855162 18636 sgd_solver.cpp:136] Iteration 7500, lr = 0.00953125, m = 0.9
I0802 05:00:31.691184 18636 solver.cpp:353] Iteration 7600 (7.22766 iter/s, 13.8357s/100 iter), loss = 1.27205
I0802 05:00:31.691385 18636 solver.cpp:375]     Train net output #0: loss = 1.12413 (* 1 = 1.12413 loss)
I0802 05:00:31.691476 18636 sgd_solver.cpp:136] Iteration 7600, lr = 0.009525, m = 0.9
I0802 05:00:45.606993 18636 solver.cpp:353] Iteration 7700 (7.18626 iter/s, 13.9154s/100 iter), loss = 1.10668
I0802 05:00:45.607084 18636 solver.cpp:375]     Train net output #0: loss = 0.999282 (* 1 = 0.999282 loss)
I0802 05:00:45.607103 18636 sgd_solver.cpp:136] Iteration 7700, lr = 0.00951875, m = 0.9
I0802 05:00:59.428810 18636 solver.cpp:353] Iteration 7800 (7.23513 iter/s, 13.8214s/100 iter), loss = 1.4092
I0802 05:00:59.428995 18636 solver.cpp:375]     Train net output #0: loss = 1.54673 (* 1 = 1.54673 loss)
I0802 05:00:59.429013 18636 sgd_solver.cpp:136] Iteration 7800, lr = 0.0095125, m = 0.9
I0802 05:01:13.284245 18636 solver.cpp:353] Iteration 7900 (7.21758 iter/s, 13.8551s/100 iter), loss = 1.18931
I0802 05:01:13.284272 18636 solver.cpp:375]     Train net output #0: loss = 1.28331 (* 1 = 1.28331 loss)
I0802 05:01:13.284349 18636 sgd_solver.cpp:136] Iteration 7900, lr = 0.00950625, m = 0.9
I0802 05:01:27.037045 18636 solver.cpp:404] Sparsity after update:
I0802 05:01:27.041007 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:01:27.041033 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:01:27.041046 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:01:27.041055 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:01:27.041064 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:01:27.041071 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:01:27.041079 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:01:27.041087 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:01:27.041095 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:01:27.041102 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:01:27.041110 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:01:27.041118 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:01:27.041126 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:01:27.041141 18636 solver.cpp:550] Iteration 8000, Testing net (#0)
I0802 05:01:32.740919 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:01:46.241772 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.538059
I0802 05:01:46.241798 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.778174
I0802 05:01:46.241806 18636 solver.cpp:635]     Test net output #2: loss = 2.04737 (* 1 = 2.04737 loss)
I0802 05:01:46.241855 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2002s
I0802 05:01:46.379637 18636 solver.cpp:353] Iteration 8000 (3.02165 iter/s, 33.0945s/100 iter), loss = 1.46263
I0802 05:01:46.379667 18636 solver.cpp:375]     Train net output #0: loss = 1.29611 (* 1 = 1.29611 loss)
I0802 05:01:46.379673 18636 sgd_solver.cpp:136] Iteration 8000, lr = 0.0095, m = 0.9
I0802 05:02:00.218849 18636 solver.cpp:353] Iteration 8100 (7.22604 iter/s, 13.8388s/100 iter), loss = 1.59933
I0802 05:02:00.218880 18636 solver.cpp:375]     Train net output #0: loss = 1.64596 (* 1 = 1.64596 loss)
I0802 05:02:00.218886 18636 sgd_solver.cpp:136] Iteration 8100, lr = 0.00949375, m = 0.9
I0802 05:02:14.094224 18636 solver.cpp:353] Iteration 8200 (7.20721 iter/s, 13.875s/100 iter), loss = 1.54464
I0802 05:02:14.094290 18636 solver.cpp:375]     Train net output #0: loss = 1.54173 (* 1 = 1.54173 loss)
I0802 05:02:14.094295 18636 sgd_solver.cpp:136] Iteration 8200, lr = 0.0094875, m = 0.9
I0802 05:02:27.997720 18636 solver.cpp:353] Iteration 8300 (7.19263 iter/s, 13.9031s/100 iter), loss = 1.07007
I0802 05:02:27.997747 18636 solver.cpp:375]     Train net output #0: loss = 1.29533 (* 1 = 1.29533 loss)
I0802 05:02:27.997753 18636 sgd_solver.cpp:136] Iteration 8300, lr = 0.00948125, m = 0.9
I0802 05:02:41.856050 18636 solver.cpp:353] Iteration 8400 (7.21607 iter/s, 13.858s/100 iter), loss = 1.41191
I0802 05:02:41.856078 18636 solver.cpp:375]     Train net output #0: loss = 1.66202 (* 1 = 1.66202 loss)
I0802 05:02:41.856083 18636 sgd_solver.cpp:136] Iteration 8400, lr = 0.009475, m = 0.9
I0802 05:02:55.762964 18636 solver.cpp:353] Iteration 8500 (7.19086 iter/s, 13.9065s/100 iter), loss = 1.63513
I0802 05:02:55.763027 18636 solver.cpp:375]     Train net output #0: loss = 1.8706 (* 1 = 1.8706 loss)
I0802 05:02:55.763034 18636 sgd_solver.cpp:136] Iteration 8500, lr = 0.00946875, m = 0.9
I0802 05:03:09.755496 18636 solver.cpp:353] Iteration 8600 (7.14686 iter/s, 13.9922s/100 iter), loss = 1.66202
I0802 05:03:09.755594 18636 solver.cpp:375]     Train net output #0: loss = 1.79235 (* 1 = 1.79235 loss)
I0802 05:03:09.755612 18636 sgd_solver.cpp:136] Iteration 8600, lr = 0.0094625, m = 0.9
I0802 05:03:23.740362 18636 solver.cpp:353] Iteration 8700 (7.15078 iter/s, 13.9845s/100 iter), loss = 1.07931
I0802 05:03:23.740387 18636 solver.cpp:375]     Train net output #0: loss = 1.11741 (* 1 = 1.11741 loss)
I0802 05:03:23.740521 18636 sgd_solver.cpp:136] Iteration 8700, lr = 0.00945625, m = 0.9
I0802 05:03:37.691612 18636 solver.cpp:353] Iteration 8800 (7.16801 iter/s, 13.9509s/100 iter), loss = 1.35378
I0802 05:03:37.691671 18636 solver.cpp:375]     Train net output #0: loss = 1.63088 (* 1 = 1.63088 loss)
I0802 05:03:37.691678 18636 sgd_solver.cpp:136] Iteration 8800, lr = 0.00945, m = 0.9
I0802 05:03:51.675288 18636 solver.cpp:353] Iteration 8900 (7.15139 iter/s, 13.9833s/100 iter), loss = 1.612
I0802 05:03:51.675318 18636 solver.cpp:375]     Train net output #0: loss = 1.77736 (* 1 = 1.77736 loss)
I0802 05:03:51.675323 18636 sgd_solver.cpp:136] Iteration 8900, lr = 0.00944375, m = 0.9
I0802 05:04:05.455504 18636 solver.cpp:404] Sparsity after update:
I0802 05:04:05.468346 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:04:05.468366 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:04:05.468374 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:04:05.468377 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:04:05.468380 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:04:05.468384 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:04:05.468396 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:04:05.468405 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:04:05.468415 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:04:05.468422 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:04:05.468430 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:04:05.468438 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:04:05.468447 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:04:05.598258 18636 solver.cpp:353] Iteration 9000 (7.18257 iter/s, 13.9226s/100 iter), loss = 1.41228
I0802 05:04:05.598284 18636 solver.cpp:375]     Train net output #0: loss = 1.316 (* 1 = 1.316 loss)
I0802 05:04:05.598289 18636 sgd_solver.cpp:136] Iteration 9000, lr = 0.0094375, m = 0.9
I0802 05:04:19.507028 18636 solver.cpp:353] Iteration 9100 (7.1899 iter/s, 13.9084s/100 iter), loss = 1.38701
I0802 05:04:19.507084 18636 solver.cpp:375]     Train net output #0: loss = 1.01615 (* 1 = 1.01615 loss)
I0802 05:04:19.507091 18636 sgd_solver.cpp:136] Iteration 9100, lr = 0.00943125, m = 0.9
I0802 05:04:33.481158 18636 solver.cpp:353] Iteration 9200 (7.15627 iter/s, 13.9738s/100 iter), loss = 1.57483
I0802 05:04:33.481202 18636 solver.cpp:375]     Train net output #0: loss = 1.78519 (* 1 = 1.78519 loss)
I0802 05:04:33.481210 18636 sgd_solver.cpp:136] Iteration 9200, lr = 0.009425, m = 0.9
I0802 05:04:47.369740 18636 solver.cpp:353] Iteration 9300 (7.20035 iter/s, 13.8882s/100 iter), loss = 2.04938
I0802 05:04:47.369767 18636 solver.cpp:375]     Train net output #0: loss = 2.46906 (* 1 = 2.46906 loss)
I0802 05:04:47.369774 18636 sgd_solver.cpp:136] Iteration 9300, lr = 0.00941875, m = 0.9
I0802 05:05:01.274790 18636 solver.cpp:353] Iteration 9400 (7.19183 iter/s, 13.9047s/100 iter), loss = 1.33343
I0802 05:05:01.274926 18636 solver.cpp:375]     Train net output #0: loss = 1.10483 (* 1 = 1.10483 loss)
I0802 05:05:01.274945 18636 sgd_solver.cpp:136] Iteration 9400, lr = 0.0094125, m = 0.9
I0802 05:05:15.201956 18636 solver.cpp:353] Iteration 9500 (7.1804 iter/s, 13.9268s/100 iter), loss = 1.69231
I0802 05:05:15.201989 18636 solver.cpp:375]     Train net output #0: loss = 1.7673 (* 1 = 1.7673 loss)
I0802 05:05:15.201995 18636 sgd_solver.cpp:136] Iteration 9500, lr = 0.00940625, m = 0.9
I0802 05:05:29.111989 18636 solver.cpp:353] Iteration 9600 (7.18925 iter/s, 13.9097s/100 iter), loss = 1.74886
I0802 05:05:29.112013 18636 solver.cpp:375]     Train net output #0: loss = 1.96588 (* 1 = 1.96588 loss)
I0802 05:05:29.112017 18636 sgd_solver.cpp:136] Iteration 9600, lr = 0.0094, m = 0.9
I0802 05:05:43.043020 18636 solver.cpp:353] Iteration 9700 (7.17841 iter/s, 13.9307s/100 iter), loss = 1.45507
I0802 05:05:43.043102 18636 solver.cpp:375]     Train net output #0: loss = 1.66859 (* 1 = 1.66859 loss)
I0802 05:05:43.043109 18636 sgd_solver.cpp:136] Iteration 9700, lr = 0.00939375, m = 0.9
I0802 05:05:56.872213 18636 solver.cpp:353] Iteration 9800 (7.23127 iter/s, 13.8288s/100 iter), loss = 1.16169
I0802 05:05:56.872242 18636 solver.cpp:375]     Train net output #0: loss = 1.24524 (* 1 = 1.24524 loss)
I0802 05:05:56.872248 18636 sgd_solver.cpp:136] Iteration 9800, lr = 0.0093875, m = 0.9
I0802 05:06:10.794850 18636 solver.cpp:353] Iteration 9900 (7.18274 iter/s, 13.9223s/100 iter), loss = 1.06741
I0802 05:06:10.794876 18636 solver.cpp:375]     Train net output #0: loss = 1.09565 (* 1 = 1.09565 loss)
I0802 05:06:10.794880 18636 sgd_solver.cpp:136] Iteration 9900, lr = 0.00938125, m = 0.9
I0802 05:06:24.550987 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_10000.caffemodel
I0802 05:06:24.640632 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_10000.solverstate
I0802 05:06:24.646739 18636 solver.cpp:404] Sparsity after update:
I0802 05:06:24.648044 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:06:24.648053 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:06:24.648062 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:06:24.648066 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:06:24.648068 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:06:24.648072 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:06:24.648074 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:06:24.648077 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:06:24.648080 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:06:24.648083 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:06:24.648087 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:06:24.648092 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:06:24.648095 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:06:24.648105 18636 solver.cpp:550] Iteration 10000, Testing net (#0)
I0802 05:06:43.966737 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545176
I0802 05:06:43.966764 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786057
I0802 05:06:43.966769 18636 solver.cpp:635]     Test net output #2: loss = 2.0029 (* 1 = 2.0029 loss)
I0802 05:06:43.966817 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3182s
I0802 05:06:44.106503 18636 solver.cpp:353] Iteration 10000 (3.00203 iter/s, 33.3108s/100 iter), loss = 1.41626
I0802 05:06:44.106526 18636 solver.cpp:375]     Train net output #0: loss = 1.13567 (* 1 = 1.13567 loss)
I0802 05:06:44.106530 18636 sgd_solver.cpp:136] Iteration 10000, lr = 0.009375, m = 0.9
I0802 05:06:57.985812 18636 solver.cpp:353] Iteration 10100 (7.20516 iter/s, 13.8789s/100 iter), loss = 1.16987
I0802 05:06:57.985880 18636 solver.cpp:375]     Train net output #0: loss = 1.3719 (* 1 = 1.3719 loss)
I0802 05:06:57.985885 18636 sgd_solver.cpp:136] Iteration 10100, lr = 0.00936875, m = 0.9
I0802 05:07:11.778300 18636 solver.cpp:353] Iteration 10200 (7.25052 iter/s, 13.7921s/100 iter), loss = 1.40301
I0802 05:07:11.778326 18636 solver.cpp:375]     Train net output #0: loss = 1.35546 (* 1 = 1.35546 loss)
I0802 05:07:11.778331 18636 sgd_solver.cpp:136] Iteration 10200, lr = 0.0093625, m = 0.9
I0802 05:07:25.630964 18636 solver.cpp:353] Iteration 10300 (7.21902 iter/s, 13.8523s/100 iter), loss = 1.51182
I0802 05:07:25.630991 18636 solver.cpp:375]     Train net output #0: loss = 1.87202 (* 1 = 1.87202 loss)
I0802 05:07:25.630997 18636 sgd_solver.cpp:136] Iteration 10300, lr = 0.00935625, m = 0.9
I0802 05:07:39.563318 18636 solver.cpp:353] Iteration 10400 (7.17773 iter/s, 13.932s/100 iter), loss = 1.30222
I0802 05:07:39.568851 18636 solver.cpp:375]     Train net output #0: loss = 1.04902 (* 1 = 1.04902 loss)
I0802 05:07:39.568863 18636 sgd_solver.cpp:136] Iteration 10400, lr = 0.00935, m = 0.9
I0802 05:07:53.458145 18636 solver.cpp:353] Iteration 10500 (7.19712 iter/s, 13.8945s/100 iter), loss = 1.12604
I0802 05:07:53.458232 18636 solver.cpp:375]     Train net output #0: loss = 0.862887 (* 1 = 0.862887 loss)
I0802 05:07:53.458251 18636 sgd_solver.cpp:136] Iteration 10500, lr = 0.00934375, m = 0.9
I0802 05:08:07.426353 18636 solver.cpp:353] Iteration 10600 (7.15931 iter/s, 13.9678s/100 iter), loss = 1.68947
I0802 05:08:07.426378 18636 solver.cpp:375]     Train net output #0: loss = 1.88788 (* 1 = 1.88788 loss)
I0802 05:08:07.426384 18636 sgd_solver.cpp:136] Iteration 10600, lr = 0.0093375, m = 0.9
I0802 05:08:21.357084 18636 solver.cpp:353] Iteration 10700 (7.17857 iter/s, 13.9304s/100 iter), loss = 1.51223
I0802 05:08:21.357156 18636 solver.cpp:375]     Train net output #0: loss = 1.22732 (* 1 = 1.22732 loss)
I0802 05:08:21.357163 18636 sgd_solver.cpp:136] Iteration 10700, lr = 0.00933125, m = 0.9
I0802 05:08:35.277541 18636 solver.cpp:353] Iteration 10800 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.30428
I0802 05:08:35.277570 18636 solver.cpp:375]     Train net output #0: loss = 1.08756 (* 1 = 1.08756 loss)
I0802 05:08:35.277576 18636 sgd_solver.cpp:136] Iteration 10800, lr = 0.009325, m = 0.9
I0802 05:08:49.181172 18636 solver.cpp:353] Iteration 10900 (7.19256 iter/s, 13.9033s/100 iter), loss = 1.55089
I0802 05:08:49.181198 18636 solver.cpp:375]     Train net output #0: loss = 1.58958 (* 1 = 1.58958 loss)
I0802 05:08:49.181205 18636 sgd_solver.cpp:136] Iteration 10900, lr = 0.00931875, m = 0.9
I0802 05:09:02.917752 18636 solver.cpp:404] Sparsity after update:
I0802 05:09:02.932209 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:09:02.932262 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:09:02.932291 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:09:02.932304 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:09:02.932317 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:09:02.932329 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:09:02.932341 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:09:02.932354 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:09:02.932366 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:09:02.932379 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:09:02.932390 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:09:02.932402 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:09:02.932415 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:09:03.063855 18636 solver.cpp:353] Iteration 11000 (7.20341 iter/s, 13.8823s/100 iter), loss = 1.07035
I0802 05:09:03.063926 18636 solver.cpp:375]     Train net output #0: loss = 0.931263 (* 1 = 0.931263 loss)
I0802 05:09:03.063944 18636 sgd_solver.cpp:136] Iteration 11000, lr = 0.0093125, m = 0.9
I0802 05:09:16.951753 18636 solver.cpp:353] Iteration 11100 (7.20071 iter/s, 13.8875s/100 iter), loss = 1.65756
I0802 05:09:16.951779 18636 solver.cpp:375]     Train net output #0: loss = 1.47072 (* 1 = 1.47072 loss)
I0802 05:09:16.951786 18636 sgd_solver.cpp:136] Iteration 11100, lr = 0.00930625, m = 0.9
I0802 05:09:30.782676 18636 solver.cpp:353] Iteration 11200 (7.23037 iter/s, 13.8305s/100 iter), loss = 1.16568
I0802 05:09:30.782752 18636 solver.cpp:375]     Train net output #0: loss = 1.09341 (* 1 = 1.09341 loss)
I0802 05:09:30.782771 18636 sgd_solver.cpp:136] Iteration 11200, lr = 0.0093, m = 0.9
I0802 05:09:44.684280 18636 solver.cpp:353] Iteration 11300 (7.19361 iter/s, 13.9012s/100 iter), loss = 1.46043
I0802 05:09:44.684350 18636 solver.cpp:375]     Train net output #0: loss = 1.29646 (* 1 = 1.29646 loss)
I0802 05:09:44.684356 18636 sgd_solver.cpp:136] Iteration 11300, lr = 0.00929375, m = 0.9
I0802 05:09:58.617301 18636 solver.cpp:353] Iteration 11400 (7.17739 iter/s, 13.9326s/100 iter), loss = 1.7512
I0802 05:09:58.617326 18636 solver.cpp:375]     Train net output #0: loss = 1.82513 (* 1 = 1.82513 loss)
I0802 05:09:58.617331 18636 sgd_solver.cpp:136] Iteration 11400, lr = 0.0092875, m = 0.9
I0802 05:10:12.534874 18636 solver.cpp:353] Iteration 11500 (7.18535 iter/s, 13.9172s/100 iter), loss = 1.96538
I0802 05:10:12.534903 18636 solver.cpp:375]     Train net output #0: loss = 1.45159 (* 1 = 1.45159 loss)
I0802 05:10:12.534909 18636 sgd_solver.cpp:136] Iteration 11500, lr = 0.00928125, m = 0.9
I0802 05:10:26.456550 18636 solver.cpp:353] Iteration 11600 (7.18324 iter/s, 13.9213s/100 iter), loss = 1.10327
I0802 05:10:26.456692 18636 solver.cpp:375]     Train net output #0: loss = 1.00122 (* 1 = 1.00122 loss)
I0802 05:10:26.456712 18636 sgd_solver.cpp:136] Iteration 11600, lr = 0.009275, m = 0.9
I0802 05:10:40.368288 18636 solver.cpp:353] Iteration 11700 (7.18837 iter/s, 13.9114s/100 iter), loss = 1.24648
I0802 05:10:40.368381 18636 solver.cpp:375]     Train net output #0: loss = 1.36835 (* 1 = 1.36835 loss)
I0802 05:10:40.368399 18636 sgd_solver.cpp:136] Iteration 11700, lr = 0.00926875, m = 0.9
I0802 05:10:54.272001 18636 solver.cpp:353] Iteration 11800 (7.19252 iter/s, 13.9033s/100 iter), loss = 1.47204
I0802 05:10:54.272032 18636 solver.cpp:375]     Train net output #0: loss = 0.948505 (* 1 = 0.948505 loss)
I0802 05:10:54.272038 18636 sgd_solver.cpp:136] Iteration 11800, lr = 0.0092625, m = 0.9
I0802 05:11:08.282202 18636 solver.cpp:353] Iteration 11900 (7.13785 iter/s, 14.0098s/100 iter), loss = 1.8833
I0802 05:11:08.282285 18636 solver.cpp:375]     Train net output #0: loss = 2.25845 (* 1 = 2.25845 loss)
I0802 05:11:08.282294 18636 sgd_solver.cpp:136] Iteration 11900, lr = 0.00925625, m = 0.9
I0802 05:11:22.002900 18636 solver.cpp:404] Sparsity after update:
I0802 05:11:22.006853 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:11:22.006865 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:11:22.006873 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:11:22.006876 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:11:22.006882 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:11:22.006886 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:11:22.006889 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:11:22.006891 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:11:22.006894 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:11:22.006898 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:11:22.006901 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:11:22.006904 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:11:22.006908 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:11:22.006920 18636 solver.cpp:550] Iteration 12000, Testing net (#0)
I0802 05:11:41.183079 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.532176
I0802 05:11:41.183190 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.77441
I0802 05:11:41.183202 18636 solver.cpp:635]     Test net output #2: loss = 2.0914 (* 1 = 2.0914 loss)
I0802 05:11:41.183223 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1758s
I0802 05:11:41.324180 18636 solver.cpp:353] Iteration 12000 (3.02653 iter/s, 33.0411s/100 iter), loss = 1.46126
I0802 05:11:41.324257 18636 solver.cpp:375]     Train net output #0: loss = 1.36349 (* 1 = 1.36349 loss)
I0802 05:11:41.324278 18636 sgd_solver.cpp:136] Iteration 12000, lr = 0.00925, m = 0.9
I0802 05:11:55.258982 18636 solver.cpp:353] Iteration 12100 (7.17647 iter/s, 13.9344s/100 iter), loss = 1.66599
I0802 05:11:55.259007 18636 solver.cpp:375]     Train net output #0: loss = 1.67516 (* 1 = 1.67516 loss)
I0802 05:11:55.259012 18636 sgd_solver.cpp:136] Iteration 12100, lr = 0.00924375, m = 0.9
I0802 05:12:09.130162 18636 solver.cpp:353] Iteration 12200 (7.20939 iter/s, 13.8708s/100 iter), loss = 1.18156
I0802 05:12:09.130192 18636 solver.cpp:375]     Train net output #0: loss = 1.07089 (* 1 = 1.07089 loss)
I0802 05:12:09.130198 18636 sgd_solver.cpp:136] Iteration 12200, lr = 0.0092375, m = 0.9
I0802 05:12:23.062439 18636 solver.cpp:353] Iteration 12300 (7.17777 iter/s, 13.9319s/100 iter), loss = 0.940485
I0802 05:12:23.062511 18636 solver.cpp:375]     Train net output #0: loss = 1.1388 (* 1 = 1.1388 loss)
I0802 05:12:23.062518 18636 sgd_solver.cpp:136] Iteration 12300, lr = 0.00923125, m = 0.9
I0802 05:12:36.922199 18636 solver.cpp:353] Iteration 12400 (7.21533 iter/s, 13.8594s/100 iter), loss = 1.23913
I0802 05:12:36.922225 18636 solver.cpp:375]     Train net output #0: loss = 1.06177 (* 1 = 1.06177 loss)
I0802 05:12:36.922231 18636 sgd_solver.cpp:136] Iteration 12400, lr = 0.009225, m = 0.9
I0802 05:12:50.873733 18636 solver.cpp:353] Iteration 12500 (7.16786 iter/s, 13.9512s/100 iter), loss = 1.37424
I0802 05:12:50.873760 18636 solver.cpp:375]     Train net output #0: loss = 1.38143 (* 1 = 1.38143 loss)
I0802 05:12:50.873765 18636 sgd_solver.cpp:136] Iteration 12500, lr = 0.00921875, m = 0.9
I0802 05:13:04.864334 18636 solver.cpp:353] Iteration 12600 (7.14785 iter/s, 13.9902s/100 iter), loss = 1.94755
I0802 05:13:04.864398 18636 solver.cpp:375]     Train net output #0: loss = 1.61048 (* 1 = 1.61048 loss)
I0802 05:13:04.864403 18636 sgd_solver.cpp:136] Iteration 12600, lr = 0.0092125, m = 0.9
I0802 05:13:18.839527 18636 solver.cpp:353] Iteration 12700 (7.15573 iter/s, 13.9748s/100 iter), loss = 1.25097
I0802 05:13:18.839601 18636 solver.cpp:375]     Train net output #0: loss = 1.22904 (* 1 = 1.22904 loss)
I0802 05:13:18.839622 18636 sgd_solver.cpp:136] Iteration 12700, lr = 0.00920625, m = 0.9
I0802 05:13:32.800871 18636 solver.cpp:353] Iteration 12800 (7.16283 iter/s, 13.961s/100 iter), loss = 1.62802
I0802 05:13:32.800894 18636 solver.cpp:375]     Train net output #0: loss = 1.71379 (* 1 = 1.71379 loss)
I0802 05:13:32.800899 18636 sgd_solver.cpp:136] Iteration 12800, lr = 0.0092, m = 0.9
I0802 05:13:46.734324 18636 solver.cpp:353] Iteration 12900 (7.17716 iter/s, 13.9331s/100 iter), loss = 1.14665
I0802 05:13:46.734381 18636 solver.cpp:375]     Train net output #0: loss = 1.29307 (* 1 = 1.29307 loss)
I0802 05:13:46.734386 18636 sgd_solver.cpp:136] Iteration 12900, lr = 0.00919375, m = 0.9
I0802 05:14:00.555871 18636 solver.cpp:404] Sparsity after update:
I0802 05:14:00.566409 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:14:00.566428 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:14:00.566438 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:14:00.566442 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:14:00.566445 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:14:00.566449 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:14:00.566453 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:14:00.566457 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:14:00.566462 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:14:00.566465 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:14:00.566469 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:14:00.566473 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:14:00.566475 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:14:00.696218 18636 solver.cpp:353] Iteration 13000 (7.16254 iter/s, 13.9615s/100 iter), loss = 1.42068
I0802 05:14:00.696249 18636 solver.cpp:375]     Train net output #0: loss = 1.52428 (* 1 = 1.52428 loss)
I0802 05:14:00.696254 18636 sgd_solver.cpp:136] Iteration 13000, lr = 0.0091875, m = 0.9
I0802 05:14:14.671617 18636 solver.cpp:353] Iteration 13100 (7.15562 iter/s, 13.975s/100 iter), loss = 1.62978
I0802 05:14:14.671645 18636 solver.cpp:375]     Train net output #0: loss = 1.45921 (* 1 = 1.45921 loss)
I0802 05:14:14.671651 18636 sgd_solver.cpp:136] Iteration 13100, lr = 0.00918125, m = 0.9
I0802 05:14:28.610309 18636 solver.cpp:353] Iteration 13200 (7.17447 iter/s, 13.9383s/100 iter), loss = 1.71688
I0802 05:14:28.610536 18636 solver.cpp:375]     Train net output #0: loss = 1.55691 (* 1 = 1.55691 loss)
I0802 05:14:28.610543 18636 sgd_solver.cpp:136] Iteration 13200, lr = 0.009175, m = 0.9
I0802 05:14:42.569718 18636 solver.cpp:353] Iteration 13300 (7.16382 iter/s, 13.959s/100 iter), loss = 1.13932
I0802 05:14:42.569748 18636 solver.cpp:375]     Train net output #0: loss = 1.00764 (* 1 = 1.00764 loss)
I0802 05:14:42.569754 18636 sgd_solver.cpp:136] Iteration 13300, lr = 0.00916875, m = 0.9
I0802 05:14:56.490088 18636 solver.cpp:353] Iteration 13400 (7.18391 iter/s, 13.92s/100 iter), loss = 1.44258
I0802 05:14:56.490113 18636 solver.cpp:375]     Train net output #0: loss = 1.37717 (* 1 = 1.37717 loss)
I0802 05:14:56.490116 18636 sgd_solver.cpp:136] Iteration 13400, lr = 0.0091625, m = 0.9
I0802 05:15:10.515723 18636 solver.cpp:353] Iteration 13500 (7.12999 iter/s, 14.0253s/100 iter), loss = 1.18715
I0802 05:15:10.515806 18636 solver.cpp:375]     Train net output #0: loss = 1.2583 (* 1 = 1.2583 loss)
I0802 05:15:10.515813 18636 sgd_solver.cpp:136] Iteration 13500, lr = 0.00915625, m = 0.9
I0802 05:15:24.555548 18636 solver.cpp:353] Iteration 13600 (7.12279 iter/s, 14.0394s/100 iter), loss = 1.23433
I0802 05:15:24.555573 18636 solver.cpp:375]     Train net output #0: loss = 1.2649 (* 1 = 1.2649 loss)
I0802 05:15:24.555577 18636 sgd_solver.cpp:136] Iteration 13600, lr = 0.00915, m = 0.9
I0802 05:15:38.555088 18636 solver.cpp:353] Iteration 13700 (7.14328 iter/s, 13.9992s/100 iter), loss = 1.35563
I0802 05:15:38.555115 18636 solver.cpp:375]     Train net output #0: loss = 1.26144 (* 1 = 1.26144 loss)
I0802 05:15:38.555119 18636 sgd_solver.cpp:136] Iteration 13700, lr = 0.00914375, m = 0.9
I0802 05:15:52.474756 18636 solver.cpp:353] Iteration 13800 (7.18427 iter/s, 13.9193s/100 iter), loss = 1.32597
I0802 05:15:52.474840 18636 solver.cpp:375]     Train net output #0: loss = 1.14365 (* 1 = 1.14365 loss)
I0802 05:15:52.474848 18636 sgd_solver.cpp:136] Iteration 13800, lr = 0.0091375, m = 0.9
I0802 05:16:06.481912 18636 solver.cpp:353] Iteration 13900 (7.1394 iter/s, 14.0068s/100 iter), loss = 1.3844
I0802 05:16:06.481940 18636 solver.cpp:375]     Train net output #0: loss = 1.57618 (* 1 = 1.57618 loss)
I0802 05:16:06.481946 18636 sgd_solver.cpp:136] Iteration 13900, lr = 0.00913125, m = 0.9
I0802 05:16:20.316606 18636 solver.cpp:404] Sparsity after update:
I0802 05:16:20.321094 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:16:20.322137 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:16:20.322155 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:16:20.322264 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:16:20.322325 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:16:20.322391 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:16:20.322455 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:16:20.322470 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:16:20.322480 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:16:20.322489 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:16:20.322499 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:16:20.322515 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:16:20.322525 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:16:20.322544 18636 solver.cpp:550] Iteration 14000, Testing net (#0)
I0802 05:16:32.223212 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:16:40.104125 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.547941
I0802 05:16:40.104152 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786645
I0802 05:16:40.104159 18636 solver.cpp:635]     Test net output #2: loss = 2.02799 (* 1 = 2.02799 loss)
I0802 05:16:40.104177 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7811s
I0802 05:16:40.256855 18636 solver.cpp:353] Iteration 14000 (2.96085 iter/s, 33.774s/100 iter), loss = 1.47719
I0802 05:16:40.256886 18636 solver.cpp:375]     Train net output #0: loss = 1.68967 (* 1 = 1.68967 loss)
I0802 05:16:40.256893 18636 sgd_solver.cpp:136] Iteration 14000, lr = 0.009125, m = 0.9
I0802 05:16:54.166344 18636 solver.cpp:353] Iteration 14100 (7.18953 iter/s, 13.9091s/100 iter), loss = 1.7227
I0802 05:16:54.166373 18636 solver.cpp:375]     Train net output #0: loss = 2.12618 (* 1 = 2.12618 loss)
I0802 05:16:54.166378 18636 sgd_solver.cpp:136] Iteration 14100, lr = 0.00911875, m = 0.9
I0802 05:17:08.028828 18636 solver.cpp:353] Iteration 14200 (7.21391 iter/s, 13.8621s/100 iter), loss = 1.5752
I0802 05:17:08.028894 18636 solver.cpp:375]     Train net output #0: loss = 1.7972 (* 1 = 1.7972 loss)
I0802 05:17:08.028901 18636 sgd_solver.cpp:136] Iteration 14200, lr = 0.0091125, m = 0.9
I0802 05:17:21.887006 18636 solver.cpp:353] Iteration 14300 (7.21615 iter/s, 13.8578s/100 iter), loss = 1.41944
I0802 05:17:21.887030 18636 solver.cpp:375]     Train net output #0: loss = 1.46848 (* 1 = 1.46848 loss)
I0802 05:17:21.887035 18636 sgd_solver.cpp:136] Iteration 14300, lr = 0.00910625, m = 0.9
I0802 05:17:35.721982 18636 solver.cpp:353] Iteration 14400 (7.22825 iter/s, 13.8346s/100 iter), loss = 1.44828
I0802 05:17:35.722036 18636 solver.cpp:375]     Train net output #0: loss = 1.68453 (* 1 = 1.68453 loss)
I0802 05:17:35.722048 18636 sgd_solver.cpp:136] Iteration 14400, lr = 0.0091, m = 0.9
I0802 05:17:49.579622 18636 solver.cpp:353] Iteration 14500 (7.21643 iter/s, 13.8573s/100 iter), loss = 1.45777
I0802 05:17:49.579710 18636 solver.cpp:375]     Train net output #0: loss = 1.51019 (* 1 = 1.51019 loss)
I0802 05:17:49.579716 18636 sgd_solver.cpp:136] Iteration 14500, lr = 0.00909375, m = 0.9
I0802 05:18:03.532361 18636 solver.cpp:353] Iteration 14600 (7.16725 iter/s, 13.9524s/100 iter), loss = 1.42475
I0802 05:18:03.532410 18636 solver.cpp:375]     Train net output #0: loss = 1.02638 (* 1 = 1.02638 loss)
I0802 05:18:03.532519 18636 sgd_solver.cpp:136] Iteration 14600, lr = 0.0090875, m = 0.9
I0802 05:18:17.435036 18636 solver.cpp:353] Iteration 14700 (7.19305 iter/s, 13.9023s/100 iter), loss = 1.4453
I0802 05:18:17.435101 18636 solver.cpp:375]     Train net output #0: loss = 1.48259 (* 1 = 1.48259 loss)
I0802 05:18:17.435123 18636 sgd_solver.cpp:136] Iteration 14700, lr = 0.00908125, m = 0.9
I0802 05:18:31.393128 18636 solver.cpp:353] Iteration 14800 (7.1645 iter/s, 13.9577s/100 iter), loss = 1.27523
I0802 05:18:31.393191 18636 solver.cpp:375]     Train net output #0: loss = 1.34106 (* 1 = 1.34106 loss)
I0802 05:18:31.393200 18636 sgd_solver.cpp:136] Iteration 14800, lr = 0.009075, m = 0.9
I0802 05:18:45.321465 18636 solver.cpp:353] Iteration 14900 (7.1798 iter/s, 13.928s/100 iter), loss = 1.29844
I0802 05:18:45.321490 18636 solver.cpp:375]     Train net output #0: loss = 1.41953 (* 1 = 1.41953 loss)
I0802 05:18:45.321494 18636 sgd_solver.cpp:136] Iteration 14900, lr = 0.00906875, m = 0.9
I0802 05:18:59.043818 18636 solver.cpp:404] Sparsity after update:
I0802 05:18:59.058166 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:18:59.058182 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:18:59.058190 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:18:59.058193 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:18:59.058197 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:18:59.058200 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:18:59.058203 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:18:59.058207 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:18:59.058209 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:18:59.058212 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:18:59.058215 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:18:59.058218 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:18:59.058221 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:18:59.189627 18636 solver.cpp:353] Iteration 15000 (7.21095 iter/s, 13.8678s/100 iter), loss = 1.51539
I0802 05:18:59.189679 18636 solver.cpp:375]     Train net output #0: loss = 1.44726 (* 1 = 1.44726 loss)
I0802 05:18:59.189692 18636 sgd_solver.cpp:136] Iteration 15000, lr = 0.0090625, m = 0.9
I0802 05:19:13.094259 18636 solver.cpp:353] Iteration 15100 (7.19204 iter/s, 13.9043s/100 iter), loss = 1.27794
I0802 05:19:13.094334 18636 solver.cpp:375]     Train net output #0: loss = 1.15503 (* 1 = 1.15503 loss)
I0802 05:19:13.094341 18636 sgd_solver.cpp:136] Iteration 15100, lr = 0.00905625, m = 0.9
I0802 05:19:27.049186 18636 solver.cpp:353] Iteration 15200 (7.16612 iter/s, 13.9546s/100 iter), loss = 1.80617
I0802 05:19:27.049214 18636 solver.cpp:375]     Train net output #0: loss = 1.9514 (* 1 = 1.9514 loss)
I0802 05:19:27.049221 18636 sgd_solver.cpp:136] Iteration 15200, lr = 0.00905, m = 0.9
I0802 05:19:40.978282 18636 solver.cpp:353] Iteration 15300 (7.17941 iter/s, 13.9287s/100 iter), loss = 1.31917
I0802 05:19:40.978312 18636 solver.cpp:375]     Train net output #0: loss = 1.35257 (* 1 = 1.35257 loss)
I0802 05:19:40.978317 18636 sgd_solver.cpp:136] Iteration 15300, lr = 0.00904375, m = 0.9
I0802 05:19:54.872757 18636 solver.cpp:353] Iteration 15400 (7.1973 iter/s, 13.8941s/100 iter), loss = 1.35222
I0802 05:19:54.872864 18636 solver.cpp:375]     Train net output #0: loss = 1.56204 (* 1 = 1.56204 loss)
I0802 05:19:54.872884 18636 sgd_solver.cpp:136] Iteration 15400, lr = 0.0090375, m = 0.9
I0802 05:20:08.768571 18636 solver.cpp:353] Iteration 15500 (7.19661 iter/s, 13.8954s/100 iter), loss = 1.82378
I0802 05:20:08.768656 18636 solver.cpp:375]     Train net output #0: loss = 1.82336 (* 1 = 1.82336 loss)
I0802 05:20:08.768677 18636 sgd_solver.cpp:136] Iteration 15500, lr = 0.00903125, m = 0.9
I0802 05:20:22.630192 18636 solver.cpp:353] Iteration 15600 (7.21436 iter/s, 13.8612s/100 iter), loss = 1.52658
I0802 05:20:22.630218 18636 solver.cpp:375]     Train net output #0: loss = 1.53204 (* 1 = 1.53204 loss)
I0802 05:20:22.630223 18636 sgd_solver.cpp:136] Iteration 15600, lr = 0.009025, m = 0.9
I0802 05:20:36.547076 18636 solver.cpp:353] Iteration 15700 (7.18571 iter/s, 13.9165s/100 iter), loss = 1.7171
I0802 05:20:36.547139 18636 solver.cpp:375]     Train net output #0: loss = 1.62115 (* 1 = 1.62115 loss)
I0802 05:20:36.547145 18636 sgd_solver.cpp:136] Iteration 15700, lr = 0.00901875, m = 0.9
I0802 05:20:50.411113 18636 solver.cpp:353] Iteration 15800 (7.2131 iter/s, 13.8637s/100 iter), loss = 1.37406
I0802 05:20:50.411167 18636 solver.cpp:375]     Train net output #0: loss = 1.4155 (* 1 = 1.4155 loss)
I0802 05:20:50.411180 18636 sgd_solver.cpp:136] Iteration 15800, lr = 0.0090125, m = 0.9
I0802 05:21:04.226763 18636 solver.cpp:353] Iteration 15900 (7.23836 iter/s, 13.8153s/100 iter), loss = 1.49226
I0802 05:21:04.226855 18636 solver.cpp:375]     Train net output #0: loss = 1.47413 (* 1 = 1.47413 loss)
I0802 05:21:04.226874 18636 sgd_solver.cpp:136] Iteration 15900, lr = 0.00900625, m = 0.9
I0802 05:21:17.958263 18636 solver.cpp:404] Sparsity after update:
I0802 05:21:17.962703 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:21:17.962714 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:21:17.962723 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:21:17.962726 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:21:17.962918 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:21:17.962937 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:21:17.962949 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:21:17.962959 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:21:17.962968 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:21:17.962978 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:21:17.962988 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:21:17.963001 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:21:17.963011 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:21:17.963029 18636 solver.cpp:550] Iteration 16000, Testing net (#0)
I0802 05:21:33.436034 18619 data_reader.cpp:264] Starting prefetch of epoch 2
I0802 05:21:37.125027 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545118
I0802 05:21:37.125051 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.78835
I0802 05:21:37.125056 18636 solver.cpp:635]     Test net output #2: loss = 1.9818 (* 1 = 1.9818 loss)
I0802 05:21:37.125082 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1615s
I0802 05:21:37.273218 18636 solver.cpp:353] Iteration 16000 (3.02612 iter/s, 33.0456s/100 iter), loss = 1.10273
I0802 05:21:37.273247 18636 solver.cpp:375]     Train net output #0: loss = 1.12065 (* 1 = 1.12065 loss)
I0802 05:21:37.273252 18636 sgd_solver.cpp:136] Iteration 16000, lr = 0.009, m = 0.9
I0802 05:21:51.206502 18636 solver.cpp:353] Iteration 16100 (7.17725 iter/s, 13.9329s/100 iter), loss = 1.4361
I0802 05:21:51.206571 18636 solver.cpp:375]     Train net output #0: loss = 1.28775 (* 1 = 1.28775 loss)
I0802 05:21:51.206578 18636 sgd_solver.cpp:136] Iteration 16100, lr = 0.00899375, m = 0.9
I0802 05:22:05.070497 18636 solver.cpp:353] Iteration 16200 (7.21313 iter/s, 13.8636s/100 iter), loss = 1.25098
I0802 05:22:05.070524 18636 solver.cpp:375]     Train net output #0: loss = 1.44754 (* 1 = 1.44754 loss)
I0802 05:22:05.070529 18636 sgd_solver.cpp:136] Iteration 16200, lr = 0.0089875, m = 0.9
I0802 05:22:18.969538 18636 solver.cpp:353] Iteration 16300 (7.19494 iter/s, 13.8987s/100 iter), loss = 1.15624
I0802 05:22:18.969599 18636 solver.cpp:375]     Train net output #0: loss = 1.00725 (* 1 = 1.00725 loss)
I0802 05:22:18.969611 18636 sgd_solver.cpp:136] Iteration 16300, lr = 0.00898125, m = 0.9
I0802 05:22:32.839517 18636 solver.cpp:353] Iteration 16400 (7.21001 iter/s, 13.8696s/100 iter), loss = 1.36407
I0802 05:22:32.839642 18636 solver.cpp:375]     Train net output #0: loss = 1.1093 (* 1 = 1.1093 loss)
I0802 05:22:32.839661 18636 sgd_solver.cpp:136] Iteration 16400, lr = 0.008975, m = 0.9
I0802 05:22:46.722980 18636 solver.cpp:353] Iteration 16500 (7.20301 iter/s, 13.8831s/100 iter), loss = 1.5395
I0802 05:22:46.723057 18636 solver.cpp:375]     Train net output #0: loss = 1.88018 (* 1 = 1.88018 loss)
I0802 05:22:46.723079 18636 sgd_solver.cpp:136] Iteration 16500, lr = 0.00896875, m = 0.9
I0802 05:23:00.584707 18636 solver.cpp:353] Iteration 16600 (7.2143 iter/s, 13.8614s/100 iter), loss = 1.71827
I0802 05:23:00.584729 18636 solver.cpp:375]     Train net output #0: loss = 1.80719 (* 1 = 1.80719 loss)
I0802 05:23:00.584734 18636 sgd_solver.cpp:136] Iteration 16600, lr = 0.0089625, m = 0.9
I0802 05:23:14.442056 18636 solver.cpp:353] Iteration 16700 (7.21658 iter/s, 13.857s/100 iter), loss = 1.32967
I0802 05:23:14.442162 18636 solver.cpp:375]     Train net output #0: loss = 1.26811 (* 1 = 1.26811 loss)
I0802 05:23:14.442169 18636 sgd_solver.cpp:136] Iteration 16700, lr = 0.00895625, m = 0.9
I0802 05:23:28.317584 18636 solver.cpp:353] Iteration 16800 (7.20713 iter/s, 13.8752s/100 iter), loss = 1.22493
I0802 05:23:28.317606 18636 solver.cpp:375]     Train net output #0: loss = 1.2825 (* 1 = 1.2825 loss)
I0802 05:23:28.317611 18636 sgd_solver.cpp:136] Iteration 16800, lr = 0.00895, m = 0.9
I0802 05:23:42.258579 18636 solver.cpp:353] Iteration 16900 (7.17328 iter/s, 13.9406s/100 iter), loss = 1.30223
I0802 05:23:42.258604 18636 solver.cpp:375]     Train net output #0: loss = 1.3247 (* 1 = 1.3247 loss)
I0802 05:23:42.258607 18636 sgd_solver.cpp:136] Iteration 16900, lr = 0.00894375, m = 0.9
I0802 05:23:55.963856 18636 solver.cpp:404] Sparsity after update:
I0802 05:23:55.974319 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:23:55.974331 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:23:55.974339 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:23:55.974340 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:23:55.974342 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:23:55.974344 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:23:55.974346 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:23:55.974347 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:23:55.974349 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:23:55.974351 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:23:55.974356 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:23:55.974359 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:23:55.974360 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:23:56.103974 18636 solver.cpp:353] Iteration 17000 (7.22281 iter/s, 13.845s/100 iter), loss = 1.65736
I0802 05:23:56.104002 18636 solver.cpp:375]     Train net output #0: loss = 1.57223 (* 1 = 1.57223 loss)
I0802 05:23:56.104008 18636 sgd_solver.cpp:136] Iteration 17000, lr = 0.0089375, m = 0.9
I0802 05:24:09.986588 18636 solver.cpp:353] Iteration 17100 (7.20345 iter/s, 13.8822s/100 iter), loss = 1.40896
I0802 05:24:09.986611 18636 solver.cpp:375]     Train net output #0: loss = 1.29463 (* 1 = 1.29463 loss)
I0802 05:24:09.986615 18636 sgd_solver.cpp:136] Iteration 17100, lr = 0.00893125, m = 0.9
I0802 05:24:23.868880 18636 solver.cpp:353] Iteration 17200 (7.20362 iter/s, 13.8819s/100 iter), loss = 1.97233
I0802 05:24:23.868903 18636 solver.cpp:375]     Train net output #0: loss = 1.94361 (* 1 = 1.94361 loss)
I0802 05:24:23.868907 18636 sgd_solver.cpp:136] Iteration 17200, lr = 0.008925, m = 0.9
I0802 05:24:37.687897 18636 solver.cpp:353] Iteration 17300 (7.2366 iter/s, 13.8186s/100 iter), loss = 1.02718
I0802 05:24:37.687958 18636 solver.cpp:375]     Train net output #0: loss = 0.702612 (* 1 = 0.702612 loss)
I0802 05:24:37.687964 18636 sgd_solver.cpp:136] Iteration 17300, lr = 0.00891875, m = 0.9
I0802 05:24:51.606356 18636 solver.cpp:353] Iteration 17400 (7.1849 iter/s, 13.9181s/100 iter), loss = 1.46742
I0802 05:24:51.606386 18636 solver.cpp:375]     Train net output #0: loss = 1.74005 (* 1 = 1.74005 loss)
I0802 05:24:51.606393 18636 sgd_solver.cpp:136] Iteration 17400, lr = 0.0089125, m = 0.9
I0802 05:25:05.479851 18636 solver.cpp:353] Iteration 17500 (7.20818 iter/s, 13.8731s/100 iter), loss = 1.43945
I0802 05:25:05.479881 18636 solver.cpp:375]     Train net output #0: loss = 1.31185 (* 1 = 1.31185 loss)
I0802 05:25:05.479887 18636 sgd_solver.cpp:136] Iteration 17500, lr = 0.00890625, m = 0.9
I0802 05:25:19.436414 18636 solver.cpp:353] Iteration 17600 (7.16528 iter/s, 13.9562s/100 iter), loss = 1.35501
I0802 05:25:19.436532 18636 solver.cpp:375]     Train net output #0: loss = 1.54581 (* 1 = 1.54581 loss)
I0802 05:25:19.436553 18636 sgd_solver.cpp:136] Iteration 17600, lr = 0.0089, m = 0.9
I0802 05:25:33.349280 18636 solver.cpp:353] Iteration 17700 (7.18778 iter/s, 13.9125s/100 iter), loss = 1.5272
I0802 05:25:33.349306 18636 solver.cpp:375]     Train net output #0: loss = 1.83314 (* 1 = 1.83314 loss)
I0802 05:25:33.349313 18636 sgd_solver.cpp:136] Iteration 17700, lr = 0.00889375, m = 0.9
I0802 05:25:47.336400 18636 solver.cpp:353] Iteration 17800 (7.14963 iter/s, 13.9867s/100 iter), loss = 1.50605
I0802 05:25:47.336427 18636 solver.cpp:375]     Train net output #0: loss = 1.55337 (* 1 = 1.55337 loss)
I0802 05:25:47.336433 18636 sgd_solver.cpp:136] Iteration 17800, lr = 0.0088875, m = 0.9
I0802 05:26:01.240406 18636 solver.cpp:353] Iteration 17900 (7.19237 iter/s, 13.9036s/100 iter), loss = 1.09764
I0802 05:26:01.240574 18636 solver.cpp:375]     Train net output #0: loss = 0.732286 (* 1 = 0.732286 loss)
I0802 05:26:01.240597 18636 sgd_solver.cpp:136] Iteration 17900, lr = 0.00888125, m = 0.9
I0802 05:26:15.032248 18636 solver.cpp:404] Sparsity after update:
I0802 05:26:15.036761 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:26:15.036803 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:26:15.036834 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:26:15.036847 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:26:15.036860 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:26:15.036873 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:26:15.036885 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:26:15.036893 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:26:15.036901 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:26:15.036909 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:26:15.036918 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:26:15.036926 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:26:15.036936 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:26:15.036953 18636 solver.cpp:550] Iteration 18000, Testing net (#0)
I0802 05:26:34.076294 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.543764
I0802 05:26:34.076339 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.784057
I0802 05:26:34.076345 18636 solver.cpp:635]     Test net output #2: loss = 2.02545 (* 1 = 2.02545 loss)
I0802 05:26:34.076366 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.0389s
I0802 05:26:34.230080 18636 solver.cpp:353] Iteration 18000 (3.03133 iter/s, 32.9888s/100 iter), loss = 1.63438
I0802 05:26:34.230113 18636 solver.cpp:375]     Train net output #0: loss = 1.30954 (* 1 = 1.30954 loss)
I0802 05:26:34.230120 18636 sgd_solver.cpp:136] Iteration 18000, lr = 0.008875, m = 0.9
I0802 05:26:48.150887 18636 solver.cpp:353] Iteration 18100 (7.18369 iter/s, 13.9204s/100 iter), loss = 1.77469
I0802 05:26:48.150913 18636 solver.cpp:375]     Train net output #0: loss = 1.78332 (* 1 = 1.78332 loss)
I0802 05:26:48.150918 18636 sgd_solver.cpp:136] Iteration 18100, lr = 0.00886875, m = 0.9
I0802 05:27:02.079476 18636 solver.cpp:353] Iteration 18200 (7.17967 iter/s, 13.9282s/100 iter), loss = 1.61092
I0802 05:27:02.079502 18636 solver.cpp:375]     Train net output #0: loss = 1.32539 (* 1 = 1.32539 loss)
I0802 05:27:02.079507 18636 sgd_solver.cpp:136] Iteration 18200, lr = 0.0088625, m = 0.9
I0802 05:27:16.025403 18636 solver.cpp:353] Iteration 18300 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.56431
I0802 05:27:16.026970 18636 solver.cpp:375]     Train net output #0: loss = 1.54777 (* 1 = 1.54777 loss)
I0802 05:27:16.026978 18636 sgd_solver.cpp:136] Iteration 18300, lr = 0.00885625, m = 0.9
I0802 05:27:29.950011 18636 solver.cpp:353] Iteration 18400 (7.18173 iter/s, 13.9242s/100 iter), loss = 1.32837
I0802 05:27:29.950037 18636 solver.cpp:375]     Train net output #0: loss = 1.56175 (* 1 = 1.56175 loss)
I0802 05:27:29.950042 18636 sgd_solver.cpp:136] Iteration 18400, lr = 0.00885, m = 0.9
I0802 05:27:43.850275 18636 solver.cpp:353] Iteration 18500 (7.1943 iter/s, 13.8999s/100 iter), loss = 1.2
I0802 05:27:43.850301 18636 solver.cpp:375]     Train net output #0: loss = 1.47531 (* 1 = 1.47531 loss)
I0802 05:27:43.850306 18636 sgd_solver.cpp:136] Iteration 18500, lr = 0.00884375, m = 0.9
I0802 05:27:57.712074 18636 solver.cpp:353] Iteration 18600 (7.21427 iter/s, 13.8614s/100 iter), loss = 1.46373
I0802 05:27:57.712143 18636 solver.cpp:375]     Train net output #0: loss = 1.31826 (* 1 = 1.31826 loss)
I0802 05:27:57.712151 18636 sgd_solver.cpp:136] Iteration 18600, lr = 0.0088375, m = 0.9
I0802 05:28:11.706173 18636 solver.cpp:353] Iteration 18700 (7.14606 iter/s, 13.9937s/100 iter), loss = 1.51733
I0802 05:28:11.706198 18636 solver.cpp:375]     Train net output #0: loss = 1.68964 (* 1 = 1.68964 loss)
I0802 05:28:11.706203 18636 sgd_solver.cpp:136] Iteration 18700, lr = 0.00883125, m = 0.9
I0802 05:28:25.645344 18636 solver.cpp:353] Iteration 18800 (7.17422 iter/s, 13.9388s/100 iter), loss = 1.21066
I0802 05:28:25.645370 18636 solver.cpp:375]     Train net output #0: loss = 1.40112 (* 1 = 1.40112 loss)
I0802 05:28:25.645375 18636 sgd_solver.cpp:136] Iteration 18800, lr = 0.008825, m = 0.9
I0802 05:28:39.606240 18636 solver.cpp:353] Iteration 18900 (7.16306 iter/s, 13.9605s/100 iter), loss = 1.90997
I0802 05:28:39.606308 18636 solver.cpp:375]     Train net output #0: loss = 1.89836 (* 1 = 1.89836 loss)
I0802 05:28:39.606313 18636 sgd_solver.cpp:136] Iteration 18900, lr = 0.00881875, m = 0.9
I0802 05:28:53.388239 18636 solver.cpp:404] Sparsity after update:
I0802 05:28:53.401017 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:28:53.401028 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:28:53.401036 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:28:53.401041 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:28:53.401047 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:28:53.401053 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:28:53.401057 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:28:53.401062 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:28:53.401067 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:28:53.401072 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:28:53.401075 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:28:53.401078 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:28:53.401082 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:28:53.530748 18636 solver.cpp:353] Iteration 19000 (7.18178 iter/s, 13.9241s/100 iter), loss = 1.86526
I0802 05:28:53.530776 18636 solver.cpp:375]     Train net output #0: loss = 2.00912 (* 1 = 2.00912 loss)
I0802 05:28:53.530781 18636 sgd_solver.cpp:136] Iteration 19000, lr = 0.0088125, m = 0.9
I0802 05:29:07.538439 18636 solver.cpp:353] Iteration 19100 (7.13913 iter/s, 14.0073s/100 iter), loss = 1.29437
I0802 05:29:07.538466 18636 solver.cpp:375]     Train net output #0: loss = 1.05448 (* 1 = 1.05448 loss)
I0802 05:29:07.538473 18636 sgd_solver.cpp:136] Iteration 19100, lr = 0.00880625, m = 0.9
I0802 05:29:21.525013 18636 solver.cpp:353] Iteration 19200 (7.14991 iter/s, 13.9862s/100 iter), loss = 1.32729
I0802 05:29:21.525084 18636 solver.cpp:375]     Train net output #0: loss = 1.72308 (* 1 = 1.72308 loss)
I0802 05:29:21.525092 18636 sgd_solver.cpp:136] Iteration 19200, lr = 0.0088, m = 0.9
I0802 05:29:35.511768 18636 solver.cpp:353] Iteration 19300 (7.14981 iter/s, 13.9864s/100 iter), loss = 1.73863
I0802 05:29:35.511823 18636 solver.cpp:375]     Train net output #0: loss = 1.84331 (* 1 = 1.84331 loss)
I0802 05:29:35.511840 18636 sgd_solver.cpp:136] Iteration 19300, lr = 0.00879375, m = 0.9
I0802 05:29:49.495375 18636 solver.cpp:353] Iteration 19400 (7.15142 iter/s, 13.9832s/100 iter), loss = 1.44273
I0802 05:29:49.495401 18636 solver.cpp:375]     Train net output #0: loss = 1.18283 (* 1 = 1.18283 loss)
I0802 05:29:49.495406 18636 sgd_solver.cpp:136] Iteration 19400, lr = 0.0087875, m = 0.9
I0802 05:30:03.363842 18636 solver.cpp:353] Iteration 19500 (7.2108 iter/s, 13.8681s/100 iter), loss = 1.55155
I0802 05:30:03.363915 18636 solver.cpp:375]     Train net output #0: loss = 1.52163 (* 1 = 1.52163 loss)
I0802 05:30:03.363926 18636 sgd_solver.cpp:136] Iteration 19500, lr = 0.00878125, m = 0.9
I0802 05:30:17.429108 18636 solver.cpp:353] Iteration 19600 (7.1099 iter/s, 14.0649s/100 iter), loss = 1.16038
I0802 05:30:17.429162 18636 solver.cpp:375]     Train net output #0: loss = 1.10747 (* 1 = 1.10747 loss)
I0802 05:30:17.429173 18636 sgd_solver.cpp:136] Iteration 19600, lr = 0.008775, m = 0.9
I0802 05:30:31.384658 18636 solver.cpp:353] Iteration 19700 (7.1658 iter/s, 13.9552s/100 iter), loss = 1.33003
I0802 05:30:31.384692 18636 solver.cpp:375]     Train net output #0: loss = 1.29553 (* 1 = 1.29553 loss)
I0802 05:30:31.384697 18636 sgd_solver.cpp:136] Iteration 19700, lr = 0.00876875, m = 0.9
I0802 05:30:45.389739 18636 solver.cpp:353] Iteration 19800 (7.14046 iter/s, 14.0047s/100 iter), loss = 1.98333
I0802 05:30:45.389840 18636 solver.cpp:375]     Train net output #0: loss = 1.57004 (* 1 = 1.57004 loss)
I0802 05:30:45.389847 18636 sgd_solver.cpp:136] Iteration 19800, lr = 0.0087625, m = 0.9
I0802 05:30:59.528532 18636 solver.cpp:353] Iteration 19900 (7.07293 iter/s, 14.1384s/100 iter), loss = 1.59281
I0802 05:30:59.528555 18636 solver.cpp:375]     Train net output #0: loss = 1.43256 (* 1 = 1.43256 loss)
I0802 05:30:59.528559 18636 sgd_solver.cpp:136] Iteration 19900, lr = 0.00875625, m = 0.9
I0802 05:31:14.520417 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_20000.caffemodel
I0802 05:31:14.531327 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_20000.solverstate
I0802 05:31:14.535600 18636 solver.cpp:404] Sparsity after update:
I0802 05:31:14.536706 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:31:14.536715 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:31:14.536721 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:31:14.536723 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:31:14.536726 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:31:14.536728 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:31:14.536731 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:31:14.536732 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:31:14.536734 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:31:14.536736 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:31:14.536739 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:31:14.536741 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:31:14.536743 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:31:14.536752 18636 solver.cpp:550] Iteration 20000, Testing net (#0)
I0802 05:31:32.045634 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:31:34.086845 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.558176
I0802 05:31:34.086870 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.791939
I0802 05:31:34.086876 18636 solver.cpp:635]     Test net output #2: loss = 1.94261 (* 1 = 1.94261 loss)
I0802 05:31:34.086894 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5496s
I0802 05:31:34.233956 18661 solver.cpp:450] Finding and applying sparsity: 0.01
I0802 05:31:53.233930 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:31:53.235826 18636 solver.cpp:353] Iteration 20000 (1.86199 iter/s, 53.7059s/100 iter), loss = 1.77072
I0802 05:31:53.235843 18636 solver.cpp:375]     Train net output #0: loss = 1.64473 (* 1 = 1.64473 loss)
I0802 05:31:53.235849 18636 sgd_solver.cpp:136] Iteration 20000, lr = 0.00875, m = 0.9
I0802 05:32:07.502239 18636 solver.cpp:353] Iteration 20100 (7.00966 iter/s, 14.266s/100 iter), loss = 1.30029
I0802 05:32:07.502324 18636 solver.cpp:375]     Train net output #0: loss = 1.37026 (* 1 = 1.37026 loss)
I0802 05:32:07.502337 18636 sgd_solver.cpp:136] Iteration 20100, lr = 0.00874375, m = 0.9
I0802 05:32:21.441437 18636 solver.cpp:353] Iteration 20200 (7.17421 iter/s, 13.9388s/100 iter), loss = 1.44786
I0802 05:32:21.441465 18636 solver.cpp:375]     Train net output #0: loss = 1.27863 (* 1 = 1.27863 loss)
I0802 05:32:21.441473 18636 sgd_solver.cpp:136] Iteration 20200, lr = 0.0087375, m = 0.9
I0802 05:32:35.303284 18636 solver.cpp:353] Iteration 20300 (7.21424 iter/s, 13.8615s/100 iter), loss = 1.73769
I0802 05:32:35.303310 18636 solver.cpp:375]     Train net output #0: loss = 2.13868 (* 1 = 2.13868 loss)
I0802 05:32:35.303314 18636 sgd_solver.cpp:136] Iteration 20300, lr = 0.00873125, m = 0.9
I0802 05:32:49.187461 18636 solver.cpp:353] Iteration 20400 (7.20264 iter/s, 13.8838s/100 iter), loss = 1.44267
I0802 05:32:49.187517 18636 solver.cpp:375]     Train net output #0: loss = 1.30583 (* 1 = 1.30583 loss)
I0802 05:32:49.187522 18636 sgd_solver.cpp:136] Iteration 20400, lr = 0.008725, m = 0.9
I0802 05:33:03.052575 18636 solver.cpp:353] Iteration 20500 (7.21254 iter/s, 13.8647s/100 iter), loss = 1.57031
I0802 05:33:03.052600 18636 solver.cpp:375]     Train net output #0: loss = 1.36288 (* 1 = 1.36288 loss)
I0802 05:33:03.052606 18636 sgd_solver.cpp:136] Iteration 20500, lr = 0.00871875, m = 0.9
I0802 05:33:16.929404 18636 solver.cpp:353] Iteration 20600 (7.20645 iter/s, 13.8765s/100 iter), loss = 1.42995
I0802 05:33:16.929430 18636 solver.cpp:375]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0802 05:33:16.929433 18636 sgd_solver.cpp:136] Iteration 20600, lr = 0.0087125, m = 0.9
I0802 05:33:30.788378 18636 solver.cpp:353] Iteration 20700 (7.21574 iter/s, 13.8586s/100 iter), loss = 1.68946
I0802 05:33:30.788456 18636 solver.cpp:375]     Train net output #0: loss = 1.33902 (* 1 = 1.33902 loss)
I0802 05:33:30.788463 18636 sgd_solver.cpp:136] Iteration 20700, lr = 0.00870625, m = 0.9
I0802 05:33:44.710747 18636 solver.cpp:353] Iteration 20800 (7.18288 iter/s, 13.922s/100 iter), loss = 1.30892
I0802 05:33:44.710777 18636 solver.cpp:375]     Train net output #0: loss = 1.53976 (* 1 = 1.53976 loss)
I0802 05:33:44.710783 18636 sgd_solver.cpp:136] Iteration 20800, lr = 0.0087, m = 0.9
I0802 05:33:58.547086 18636 solver.cpp:353] Iteration 20900 (7.22754 iter/s, 13.836s/100 iter), loss = 1.43676
I0802 05:33:58.547113 18636 solver.cpp:375]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I0802 05:33:58.547119 18636 sgd_solver.cpp:136] Iteration 20900, lr = 0.00869375, m = 0.9
I0802 05:34:12.294008 18636 solver.cpp:404] Sparsity after update:
I0802 05:34:12.304450 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:34:12.304484 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:34:12.304498 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:34:12.304507 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:34:12.304514 18636 net.cpp:2270] res2a_branch2a_param_0(0.00694) 
I0802 05:34:12.304523 18636 net.cpp:2270] res2a_branch2b_param_0(0.00694) 
I0802 05:34:12.304532 18636 net.cpp:2270] res3a_branch2a_param_0(0.00868) 
I0802 05:34:12.304539 18636 net.cpp:2270] res3a_branch2b_param_0(0.00694) 
I0802 05:34:12.304548 18636 net.cpp:2270] res4a_branch2a_param_0(0.00955) 
I0802 05:34:12.304555 18636 net.cpp:2270] res4a_branch2b_param_0(0.00868) 
I0802 05:34:12.304563 18636 net.cpp:2270] res5a_branch2a_param_0(0.00998) 
I0802 05:34:12.304571 18636 net.cpp:2270] res5a_branch2b_param_0(0.00952) 
I0802 05:34:12.304579 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (22565/2.86678e+06) 0.00787
I0802 05:34:12.435575 18661 solver.cpp:450] Finding and applying sparsity: 0.02
I0802 05:34:31.476828 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:34:31.478734 18636 solver.cpp:353] Iteration 21000 (3.03667 iter/s, 32.9308s/100 iter), loss = 1.84803
I0802 05:34:31.478751 18636 solver.cpp:375]     Train net output #0: loss = 1.66258 (* 1 = 1.66258 loss)
I0802 05:34:31.478757 18636 sgd_solver.cpp:136] Iteration 21000, lr = 0.0086875, m = 0.9
I0802 05:34:45.866204 18636 solver.cpp:353] Iteration 21100 (6.95068 iter/s, 14.3871s/100 iter), loss = 1.78053
I0802 05:34:45.866266 18636 solver.cpp:375]     Train net output #0: loss = 1.20908 (* 1 = 1.20908 loss)
I0802 05:34:45.866272 18636 sgd_solver.cpp:136] Iteration 21100, lr = 0.00868125, m = 0.9
I0802 05:34:59.812415 18636 solver.cpp:353] Iteration 21200 (7.1706 iter/s, 13.9458s/100 iter), loss = 1.6
I0802 05:34:59.812443 18636 solver.cpp:375]     Train net output #0: loss = 1.84059 (* 1 = 1.84059 loss)
I0802 05:34:59.812448 18636 sgd_solver.cpp:136] Iteration 21200, lr = 0.008675, m = 0.9
I0802 05:35:13.676756 18636 solver.cpp:353] Iteration 21300 (7.21294 iter/s, 13.864s/100 iter), loss = 1.4402
I0802 05:35:13.676779 18636 solver.cpp:375]     Train net output #0: loss = 1.82637 (* 1 = 1.82637 loss)
I0802 05:35:13.676784 18636 sgd_solver.cpp:136] Iteration 21300, lr = 0.00866875, m = 0.9
I0802 05:35:27.512042 18636 solver.cpp:353] Iteration 21400 (7.22809 iter/s, 13.8349s/100 iter), loss = 1.5097
I0802 05:35:27.512140 18636 solver.cpp:375]     Train net output #0: loss = 1.25008 (* 1 = 1.25008 loss)
I0802 05:35:27.512146 18636 sgd_solver.cpp:136] Iteration 21400, lr = 0.0086625, m = 0.9
I0802 05:35:41.406788 18636 solver.cpp:353] Iteration 21500 (7.19716 iter/s, 13.8944s/100 iter), loss = 1.49853
I0802 05:35:41.406816 18636 solver.cpp:375]     Train net output #0: loss = 1.51946 (* 1 = 1.51946 loss)
I0802 05:35:41.406821 18636 sgd_solver.cpp:136] Iteration 21500, lr = 0.00865625, m = 0.9
I0802 05:35:55.255885 18636 solver.cpp:353] Iteration 21600 (7.22088 iter/s, 13.8487s/100 iter), loss = 1.65517
I0802 05:35:55.255981 18636 solver.cpp:375]     Train net output #0: loss = 1.47423 (* 1 = 1.47423 loss)
I0802 05:35:55.256003 18636 sgd_solver.cpp:136] Iteration 21600, lr = 0.00865, m = 0.9
I0802 05:36:09.270805 18636 solver.cpp:353] Iteration 21700 (7.13545 iter/s, 14.0145s/100 iter), loss = 1.58966
I0802 05:36:09.270908 18636 solver.cpp:375]     Train net output #0: loss = 1.60244 (* 1 = 1.60244 loss)
I0802 05:36:09.270915 18636 sgd_solver.cpp:136] Iteration 21700, lr = 0.00864375, m = 0.9
I0802 05:36:23.249799 18636 solver.cpp:353] Iteration 21800 (7.15378 iter/s, 13.9786s/100 iter), loss = 1.28478
I0802 05:36:23.249830 18636 solver.cpp:375]     Train net output #0: loss = 1.33883 (* 1 = 1.33883 loss)
I0802 05:36:23.249835 18636 sgd_solver.cpp:136] Iteration 21800, lr = 0.0086375, m = 0.9
I0802 05:36:37.201951 18636 solver.cpp:353] Iteration 21900 (7.16755 iter/s, 13.9518s/100 iter), loss = 1.37625
I0802 05:36:37.202050 18636 solver.cpp:375]     Train net output #0: loss = 1.80413 (* 1 = 1.80413 loss)
I0802 05:36:37.202071 18636 sgd_solver.cpp:136] Iteration 21900, lr = 0.00863125, m = 0.9
I0802 05:36:51.029222 18636 solver.cpp:404] Sparsity after update:
I0802 05:36:51.033460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:36:51.033471 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:36:51.033480 18636 net.cpp:2270] conv1b_param_0(0.00694) 
I0802 05:36:51.033484 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:36:51.033488 18636 net.cpp:2270] res2a_branch2a_param_0(0.0174) 
I0802 05:36:51.033490 18636 net.cpp:2270] res2a_branch2b_param_0(0.0139) 
I0802 05:36:51.033493 18636 net.cpp:2270] res3a_branch2a_param_0(0.0191) 
I0802 05:36:51.033498 18636 net.cpp:2270] res3a_branch2b_param_0(0.0173) 
I0802 05:36:51.033500 18636 net.cpp:2270] res4a_branch2a_param_0(0.02) 
I0802 05:36:51.033504 18636 net.cpp:2270] res4a_branch2b_param_0(0.0191) 
I0802 05:36:51.033506 18636 net.cpp:2270] res5a_branch2a_param_0(0.02) 
I0802 05:36:51.033510 18636 net.cpp:2270] res5a_branch2b_param_0(0.0199) 
I0802 05:36:51.033514 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (46508/2.86678e+06) 0.0162
I0802 05:36:51.033526 18636 solver.cpp:550] Iteration 22000, Testing net (#0)
I0802 05:37:10.451876 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545529
I0802 05:37:10.451902 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787174
I0802 05:37:10.451907 18636 solver.cpp:635]     Test net output #2: loss = 2.02181 (* 1 = 2.02181 loss)
I0802 05:37:10.451958 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4179s
I0802 05:37:10.599603 18661 solver.cpp:450] Finding and applying sparsity: 0.03
I0802 05:37:30.326567 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:37:30.328475 18636 solver.cpp:353] Iteration 22000 (1.88235 iter/s, 53.1251s/100 iter), loss = 1.8609
I0802 05:37:30.328493 18636 solver.cpp:375]     Train net output #0: loss = 1.55529 (* 1 = 1.55529 loss)
I0802 05:37:30.328500 18636 sgd_solver.cpp:136] Iteration 22000, lr = 0.008625, m = 0.9
I0802 05:37:44.710464 18636 solver.cpp:353] Iteration 22100 (6.95334 iter/s, 14.3816s/100 iter), loss = 1.64592
I0802 05:37:44.710536 18636 solver.cpp:375]     Train net output #0: loss = 1.55267 (* 1 = 1.55267 loss)
I0802 05:37:44.710548 18636 sgd_solver.cpp:136] Iteration 22100, lr = 0.00861875, m = 0.9
I0802 05:37:58.712465 18636 solver.cpp:353] Iteration 22200 (7.14203 iter/s, 14.0016s/100 iter), loss = 1.32659
I0802 05:37:58.712491 18636 solver.cpp:375]     Train net output #0: loss = 1.12278 (* 1 = 1.12278 loss)
I0802 05:37:58.712494 18636 sgd_solver.cpp:136] Iteration 22200, lr = 0.0086125, m = 0.9
I0802 05:38:12.669386 18636 solver.cpp:353] Iteration 22300 (7.1651 iter/s, 13.9565s/100 iter), loss = 1.36619
I0802 05:38:12.669463 18636 solver.cpp:375]     Train net output #0: loss = 1.31978 (* 1 = 1.31978 loss)
I0802 05:38:12.669468 18636 sgd_solver.cpp:136] Iteration 22300, lr = 0.00860625, m = 0.9
I0802 05:38:26.628396 18636 solver.cpp:353] Iteration 22400 (7.16403 iter/s, 13.9586s/100 iter), loss = 1.73878
I0802 05:38:26.628485 18636 solver.cpp:375]     Train net output #0: loss = 1.75981 (* 1 = 1.75981 loss)
I0802 05:38:26.628504 18636 sgd_solver.cpp:136] Iteration 22400, lr = 0.0086, m = 0.9
I0802 05:38:40.513186 18636 solver.cpp:353] Iteration 22500 (7.20232 iter/s, 13.8844s/100 iter), loss = 1.45458
I0802 05:38:40.513216 18636 solver.cpp:375]     Train net output #0: loss = 1.5517 (* 1 = 1.5517 loss)
I0802 05:38:40.513221 18636 sgd_solver.cpp:136] Iteration 22500, lr = 0.00859375, m = 0.9
I0802 05:38:54.448285 18636 solver.cpp:353] Iteration 22600 (7.17632 iter/s, 13.9347s/100 iter), loss = 1.46736
I0802 05:38:54.448354 18636 solver.cpp:375]     Train net output #0: loss = 0.847797 (* 1 = 0.847797 loss)
I0802 05:38:54.448360 18636 sgd_solver.cpp:136] Iteration 22600, lr = 0.0085875, m = 0.9
I0802 05:39:08.452394 18636 solver.cpp:353] Iteration 22700 (7.14095 iter/s, 14.0037s/100 iter), loss = 1.36274
I0802 05:39:08.452422 18636 solver.cpp:375]     Train net output #0: loss = 1.57267 (* 1 = 1.57267 loss)
I0802 05:39:08.452427 18636 sgd_solver.cpp:136] Iteration 22700, lr = 0.00858125, m = 0.9
I0802 05:39:22.309039 18636 solver.cpp:353] Iteration 22800 (7.21695 iter/s, 13.8563s/100 iter), loss = 1.47466
I0802 05:39:22.309070 18636 solver.cpp:375]     Train net output #0: loss = 1.54463 (* 1 = 1.54463 loss)
I0802 05:39:22.309077 18636 sgd_solver.cpp:136] Iteration 22800, lr = 0.008575, m = 0.9
I0802 05:39:36.221313 18636 solver.cpp:353] Iteration 22900 (7.18809 iter/s, 13.9119s/100 iter), loss = 1.52271
I0802 05:39:36.221393 18636 solver.cpp:375]     Train net output #0: loss = 1.36345 (* 1 = 1.36345 loss)
I0802 05:39:36.221400 18636 sgd_solver.cpp:136] Iteration 22900, lr = 0.00856875, m = 0.9
I0802 05:39:50.008510 18636 solver.cpp:404] Sparsity after update:
I0802 05:39:50.019078 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:39:50.019093 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:39:50.019103 18636 net.cpp:2270] conv1b_param_0(0.0139) 
I0802 05:39:50.019105 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:39:50.019109 18636 net.cpp:2270] res2a_branch2a_param_0(0.0277) 
I0802 05:39:50.019121 18636 net.cpp:2270] res2a_branch2b_param_0(0.0277) 
I0802 05:39:50.019130 18636 net.cpp:2270] res3a_branch2a_param_0(0.0295) 
I0802 05:39:50.019140 18636 net.cpp:2270] res3a_branch2b_param_0(0.0278) 
I0802 05:39:50.019155 18636 net.cpp:2270] res4a_branch2a_param_0(0.0295) 
I0802 05:39:50.019161 18636 net.cpp:2270] res4a_branch2b_param_0(0.0295) 
I0802 05:39:50.019165 18636 net.cpp:2270] res5a_branch2a_param_0(0.0299) 
I0802 05:39:50.019173 18636 net.cpp:2270] res5a_branch2b_param_0(0.0295) 
I0802 05:39:50.019178 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (69779/2.86678e+06) 0.0243
I0802 05:39:50.151249 18661 solver.cpp:450] Finding and applying sparsity: 0.04
I0802 05:40:09.475435 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:40:09.477368 18636 solver.cpp:353] Iteration 23000 (3.00705 iter/s, 33.2552s/100 iter), loss = 1.46279
I0802 05:40:09.477387 18636 solver.cpp:375]     Train net output #0: loss = 1.52898 (* 1 = 1.52898 loss)
I0802 05:40:09.477393 18636 sgd_solver.cpp:136] Iteration 23000, lr = 0.0085625, m = 0.9
I0802 05:40:23.920900 18636 solver.cpp:353] Iteration 23100 (6.92371 iter/s, 14.4431s/100 iter), loss = 1.76185
I0802 05:40:23.920974 18636 solver.cpp:375]     Train net output #0: loss = 1.82227 (* 1 = 1.82227 loss)
I0802 05:40:23.920990 18636 sgd_solver.cpp:136] Iteration 23100, lr = 0.00855625, m = 0.9
I0802 05:40:37.840987 18636 solver.cpp:353] Iteration 23200 (7.18406 iter/s, 13.9197s/100 iter), loss = 1.43151
I0802 05:40:37.841017 18636 solver.cpp:375]     Train net output #0: loss = 1.30827 (* 1 = 1.30827 loss)
I0802 05:40:37.841022 18636 sgd_solver.cpp:136] Iteration 23200, lr = 0.00855, m = 0.9
I0802 05:40:51.792546 18636 solver.cpp:353] Iteration 23300 (7.16785 iter/s, 13.9512s/100 iter), loss = 1.35608
I0802 05:40:51.792683 18636 solver.cpp:375]     Train net output #0: loss = 1.22174 (* 1 = 1.22174 loss)
I0802 05:40:51.792702 18636 sgd_solver.cpp:136] Iteration 23300, lr = 0.00854375, m = 0.9
I0802 05:41:05.734192 18636 solver.cpp:353] Iteration 23400 (7.17295 iter/s, 13.9413s/100 iter), loss = 1.49833
I0802 05:41:05.734221 18636 solver.cpp:375]     Train net output #0: loss = 1.50744 (* 1 = 1.50744 loss)
I0802 05:41:05.734266 18636 sgd_solver.cpp:136] Iteration 23400, lr = 0.0085375, m = 0.9
I0802 05:41:19.747889 18636 solver.cpp:353] Iteration 23500 (7.13607 iter/s, 14.0133s/100 iter), loss = 1.46401
I0802 05:41:19.747920 18636 solver.cpp:375]     Train net output #0: loss = 1.19949 (* 1 = 1.19949 loss)
I0802 05:41:19.747926 18636 sgd_solver.cpp:136] Iteration 23500, lr = 0.00853125, m = 0.9
I0802 05:41:33.629787 18636 solver.cpp:353] Iteration 23600 (7.20382 iter/s, 13.8815s/100 iter), loss = 1.50098
I0802 05:41:33.629858 18636 solver.cpp:375]     Train net output #0: loss = 1.70676 (* 1 = 1.70676 loss)
I0802 05:41:33.629868 18636 sgd_solver.cpp:136] Iteration 23600, lr = 0.008525, m = 0.9
I0802 05:41:47.520200 18636 solver.cpp:353] Iteration 23700 (7.1994 iter/s, 13.89s/100 iter), loss = 1.47679
I0802 05:41:47.520231 18636 solver.cpp:375]     Train net output #0: loss = 1.25338 (* 1 = 1.25338 loss)
I0802 05:41:47.520237 18636 sgd_solver.cpp:136] Iteration 23700, lr = 0.00851875, m = 0.9
I0802 05:42:01.480682 18636 solver.cpp:353] Iteration 23800 (7.16327 iter/s, 13.9601s/100 iter), loss = 1.55269
I0802 05:42:01.480711 18636 solver.cpp:375]     Train net output #0: loss = 1.70255 (* 1 = 1.70255 loss)
I0802 05:42:01.480717 18636 sgd_solver.cpp:136] Iteration 23800, lr = 0.0085125, m = 0.9
I0802 05:42:15.425860 18636 solver.cpp:353] Iteration 23900 (7.17113 iter/s, 13.9448s/100 iter), loss = 1.51883
I0802 05:42:15.425933 18636 solver.cpp:375]     Train net output #0: loss = 1.3618 (* 1 = 1.3618 loss)
I0802 05:42:15.425938 18636 sgd_solver.cpp:136] Iteration 23900, lr = 0.00850625, m = 0.9
I0802 05:42:29.300487 18636 solver.cpp:404] Sparsity after update:
I0802 05:42:29.304849 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:42:29.304862 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:42:29.304870 18636 net.cpp:2270] conv1b_param_0(0.0139) 
I0802 05:42:29.304874 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:42:29.304878 18636 net.cpp:2270] res2a_branch2a_param_0(0.0381) 
I0802 05:42:29.304883 18636 net.cpp:2270] res2a_branch2b_param_0(0.0347) 
I0802 05:42:29.304886 18636 net.cpp:2270] res3a_branch2a_param_0(0.0399) 
I0802 05:42:29.304890 18636 net.cpp:2270] res3a_branch2b_param_0(0.0382) 
I0802 05:42:29.304893 18636 net.cpp:2270] res4a_branch2a_param_0(0.0399) 
I0802 05:42:29.304896 18636 net.cpp:2270] res4a_branch2b_param_0(0.0399) 
I0802 05:42:29.304900 18636 net.cpp:2270] res5a_branch2a_param_0(0.0399) 
I0802 05:42:29.304903 18636 net.cpp:2270] res5a_branch2b_param_0(0.0399) 
I0802 05:42:29.304906 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (93725/2.86678e+06) 0.0327
I0802 05:42:29.304918 18636 solver.cpp:550] Iteration 24000, Testing net (#0)
I0802 05:42:48.555557 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.547529
I0802 05:42:48.555637 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787351
I0802 05:42:48.555647 18636 solver.cpp:635]     Test net output #2: loss = 2.00144 (* 1 = 2.00144 loss)
I0802 05:42:48.555667 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2502s
I0802 05:42:48.705113 18661 solver.cpp:450] Finding and applying sparsity: 0.05
I0802 05:43:07.848326 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:43:07.850229 18636 solver.cpp:353] Iteration 24000 (1.90756 iter/s, 52.423s/100 iter), loss = 1.35446
I0802 05:43:07.850253 18636 solver.cpp:375]     Train net output #0: loss = 1.30837 (* 1 = 1.30837 loss)
I0802 05:43:07.850262 18636 sgd_solver.cpp:136] Iteration 24000, lr = 0.0085, m = 0.9
I0802 05:43:22.167886 18636 solver.cpp:353] Iteration 24100 (6.98458 iter/s, 14.3173s/100 iter), loss = 1.49808
I0802 05:43:22.167974 18636 solver.cpp:375]     Train net output #0: loss = 1.36545 (* 1 = 1.36545 loss)
I0802 05:43:22.167981 18636 sgd_solver.cpp:136] Iteration 24100, lr = 0.00849375, m = 0.9
I0802 05:43:35.974591 18636 solver.cpp:353] Iteration 24200 (7.24306 iter/s, 13.8063s/100 iter), loss = 1.58167
I0802 05:43:35.974619 18636 solver.cpp:375]     Train net output #0: loss = 1.22837 (* 1 = 1.22837 loss)
I0802 05:43:35.974625 18636 sgd_solver.cpp:136] Iteration 24200, lr = 0.0084875, m = 0.9
I0802 05:43:49.875634 18636 solver.cpp:353] Iteration 24300 (7.1939 iter/s, 13.9007s/100 iter), loss = 1.07276
I0802 05:43:49.875710 18636 solver.cpp:375]     Train net output #0: loss = 1.21721 (* 1 = 1.21721 loss)
I0802 05:43:49.875722 18636 sgd_solver.cpp:136] Iteration 24300, lr = 0.00848125, m = 0.9
I0802 05:44:03.785732 18636 solver.cpp:353] Iteration 24400 (7.18922 iter/s, 13.9097s/100 iter), loss = 1.42349
I0802 05:44:03.785833 18636 solver.cpp:375]     Train net output #0: loss = 1.37992 (* 1 = 1.37992 loss)
I0802 05:44:03.785853 18636 sgd_solver.cpp:136] Iteration 24400, lr = 0.008475, m = 0.9
I0802 05:44:17.683492 18636 solver.cpp:353] Iteration 24500 (7.1956 iter/s, 13.8974s/100 iter), loss = 1.49714
I0802 05:44:17.683519 18636 solver.cpp:375]     Train net output #0: loss = 1.87334 (* 1 = 1.87334 loss)
I0802 05:44:17.683524 18636 sgd_solver.cpp:136] Iteration 24500, lr = 0.00846875, m = 0.9
I0802 05:44:31.504407 18636 solver.cpp:353] Iteration 24600 (7.23561 iter/s, 13.8205s/100 iter), loss = 1.58734
I0802 05:44:31.504436 18636 solver.cpp:375]     Train net output #0: loss = 1.29047 (* 1 = 1.29047 loss)
I0802 05:44:31.504443 18636 sgd_solver.cpp:136] Iteration 24600, lr = 0.0084625, m = 0.9
I0802 05:44:45.370369 18636 solver.cpp:353] Iteration 24700 (7.2121 iter/s, 13.8656s/100 iter), loss = 1.28708
I0802 05:44:45.370437 18636 solver.cpp:375]     Train net output #0: loss = 1.678 (* 1 = 1.678 loss)
I0802 05:44:45.370445 18636 sgd_solver.cpp:136] Iteration 24700, lr = 0.00845625, m = 0.9
I0802 05:44:59.292448 18636 solver.cpp:353] Iteration 24800 (7.18303 iter/s, 13.9217s/100 iter), loss = 1.20666
I0802 05:44:59.292516 18636 solver.cpp:375]     Train net output #0: loss = 1.29825 (* 1 = 1.29825 loss)
I0802 05:44:59.292536 18636 sgd_solver.cpp:136] Iteration 24800, lr = 0.00845, m = 0.9
I0802 05:45:13.152274 18636 solver.cpp:353] Iteration 24900 (7.21529 iter/s, 13.8595s/100 iter), loss = 1.3001
I0802 05:45:13.152299 18636 solver.cpp:375]     Train net output #0: loss = 1.30287 (* 1 = 1.30287 loss)
I0802 05:45:13.152304 18636 sgd_solver.cpp:136] Iteration 24900, lr = 0.00844375, m = 0.9
I0802 05:45:26.871785 18636 solver.cpp:404] Sparsity after update:
I0802 05:45:26.882943 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:45:26.882956 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:45:26.882966 18636 net.cpp:2270] conv1b_param_0(0.0208) 
I0802 05:45:26.882969 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:45:26.882973 18636 net.cpp:2270] res2a_branch2a_param_0(0.0486) 
I0802 05:45:26.882992 18636 net.cpp:2270] res2a_branch2b_param_0(0.0486) 
I0802 05:45:26.883002 18636 net.cpp:2270] res3a_branch2a_param_0(0.0486) 
I0802 05:45:26.883015 18636 net.cpp:2270] res3a_branch2b_param_0(0.0486) 
I0802 05:45:26.883024 18636 net.cpp:2270] res4a_branch2a_param_0(0.0495) 
I0802 05:45:26.883033 18636 net.cpp:2270] res4a_branch2b_param_0(0.0486) 
I0802 05:45:26.883043 18636 net.cpp:2270] res5a_branch2a_param_0(0.0499) 
I0802 05:45:26.883050 18636 net.cpp:2270] res5a_branch2b_param_0(0.0494) 
I0802 05:45:26.883059 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (116580/2.86678e+06) 0.0407
I0802 05:45:27.014031 18661 solver.cpp:450] Finding and applying sparsity: 0.06
I0802 05:45:46.455001 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:45:46.457041 18636 solver.cpp:353] Iteration 25000 (3.00265 iter/s, 33.3039s/100 iter), loss = 1.73484
I0802 05:45:46.457058 18636 solver.cpp:375]     Train net output #0: loss = 1.46269 (* 1 = 1.46269 loss)
I0802 05:45:46.457064 18636 sgd_solver.cpp:136] Iteration 25000, lr = 0.0084375, m = 0.9
I0802 05:46:00.759029 18636 solver.cpp:353] Iteration 25100 (6.99223 iter/s, 14.3016s/100 iter), loss = 1.72729
I0802 05:46:00.759104 18636 solver.cpp:375]     Train net output #0: loss = 1.93451 (* 1 = 1.93451 loss)
I0802 05:46:00.759109 18636 sgd_solver.cpp:136] Iteration 25100, lr = 0.00843125, m = 0.9
I0802 05:46:14.629340 18636 solver.cpp:353] Iteration 25200 (7.20984 iter/s, 13.8699s/100 iter), loss = 1.3077
I0802 05:46:14.629366 18636 solver.cpp:375]     Train net output #0: loss = 1.26359 (* 1 = 1.26359 loss)
I0802 05:46:14.629370 18636 sgd_solver.cpp:136] Iteration 25200, lr = 0.008425, m = 0.9
I0802 05:46:28.514237 18636 solver.cpp:353] Iteration 25300 (7.20227 iter/s, 13.8845s/100 iter), loss = 1.96846
I0802 05:46:28.514263 18636 solver.cpp:375]     Train net output #0: loss = 1.89946 (* 1 = 1.89946 loss)
I0802 05:46:28.514267 18636 sgd_solver.cpp:136] Iteration 25300, lr = 0.00841875, m = 0.9
I0802 05:46:42.354074 18636 solver.cpp:353] Iteration 25400 (7.22571 iter/s, 13.8395s/100 iter), loss = 1.4288
I0802 05:46:42.361017 18636 solver.cpp:375]     Train net output #0: loss = 1.10299 (* 1 = 1.10299 loss)
I0802 05:46:42.361032 18636 sgd_solver.cpp:136] Iteration 25400, lr = 0.0084125, m = 0.9
I0802 05:46:56.257583 18636 solver.cpp:353] Iteration 25500 (7.19262 iter/s, 13.9031s/100 iter), loss = 1.83777
I0802 05:46:56.257613 18636 solver.cpp:375]     Train net output #0: loss = 1.74782 (* 1 = 1.74782 loss)
I0802 05:46:56.257619 18636 sgd_solver.cpp:136] Iteration 25500, lr = 0.00840625, m = 0.9
I0802 05:47:10.093750 18636 solver.cpp:353] Iteration 25600 (7.22763 iter/s, 13.8358s/100 iter), loss = 1.6852
I0802 05:47:10.093776 18636 solver.cpp:375]     Train net output #0: loss = 1.55889 (* 1 = 1.55889 loss)
I0802 05:47:10.093783 18636 sgd_solver.cpp:136] Iteration 25600, lr = 0.0084, m = 0.9
I0802 05:47:23.930405 18636 solver.cpp:353] Iteration 25700 (7.22738 iter/s, 13.8363s/100 iter), loss = 1.44803
I0802 05:47:23.930495 18636 solver.cpp:375]     Train net output #0: loss = 1.24387 (* 1 = 1.24387 loss)
I0802 05:47:23.930502 18636 sgd_solver.cpp:136] Iteration 25700, lr = 0.00839375, m = 0.9
I0802 05:47:37.890206 18636 solver.cpp:353] Iteration 25800 (7.16362 iter/s, 13.9594s/100 iter), loss = 1.53797
I0802 05:47:37.890233 18636 solver.cpp:375]     Train net output #0: loss = 1.42731 (* 1 = 1.42731 loss)
I0802 05:47:37.890239 18636 sgd_solver.cpp:136] Iteration 25800, lr = 0.0083875, m = 0.9
I0802 05:47:51.944435 18636 solver.cpp:353] Iteration 25900 (7.11549 iter/s, 14.0539s/100 iter), loss = 1.48832
I0802 05:47:51.944465 18636 solver.cpp:375]     Train net output #0: loss = 1.76716 (* 1 = 1.76716 loss)
I0802 05:47:51.944471 18636 sgd_solver.cpp:136] Iteration 25900, lr = 0.00838125, m = 0.9
I0802 05:48:05.725561 18636 solver.cpp:404] Sparsity after update:
I0802 05:48:05.731585 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:48:05.731602 18636 net.cpp:2270] conv1a_param_0(0.0267) 
I0802 05:48:05.731611 18636 net.cpp:2270] conv1b_param_0(0.0278) 
I0802 05:48:05.731616 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:48:05.731618 18636 net.cpp:2270] res2a_branch2a_param_0(0.059) 
I0802 05:48:05.731621 18636 net.cpp:2270] res2a_branch2b_param_0(0.0556) 
I0802 05:48:05.731624 18636 net.cpp:2270] res3a_branch2a_param_0(0.059) 
I0802 05:48:05.731628 18636 net.cpp:2270] res3a_branch2b_param_0(0.059) 
I0802 05:48:05.731631 18636 net.cpp:2270] res4a_branch2a_param_0(0.0599) 
I0802 05:48:05.731634 18636 net.cpp:2270] res4a_branch2b_param_0(0.059) 
I0802 05:48:05.731637 18636 net.cpp:2270] res5a_branch2a_param_0(0.0599) 
I0802 05:48:05.731640 18636 net.cpp:2270] res5a_branch2b_param_0(0.0599) 
I0802 05:48:05.731644 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (140569/2.86678e+06) 0.049
I0802 05:48:05.731655 18636 solver.cpp:550] Iteration 26000, Testing net (#0)
I0802 05:48:25.378115 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.54547
I0802 05:48:25.378137 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786527
I0802 05:48:25.378142 18636 solver.cpp:635]     Test net output #2: loss = 2.02239 (* 1 = 2.02239 loss)
I0802 05:48:25.378207 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.646s
I0802 05:48:25.527134 18661 solver.cpp:450] Finding and applying sparsity: 0.07
I0802 05:48:45.052001 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:48:45.053951 18636 solver.cpp:353] Iteration 26000 (1.88295 iter/s, 53.1081s/100 iter), loss = 1.15137
I0802 05:48:45.053970 18636 solver.cpp:375]     Train net output #0: loss = 1.26326 (* 1 = 1.26326 loss)
I0802 05:48:45.053977 18636 sgd_solver.cpp:136] Iteration 26000, lr = 0.008375, m = 0.9
I0802 05:48:59.539932 18636 solver.cpp:353] Iteration 26100 (6.90342 iter/s, 14.4856s/100 iter), loss = 1.65253
I0802 05:48:59.539968 18636 solver.cpp:375]     Train net output #0: loss = 1.65329 (* 1 = 1.65329 loss)
I0802 05:48:59.539974 18636 sgd_solver.cpp:136] Iteration 26100, lr = 0.00836875, m = 0.9
I0802 05:49:13.509402 18636 solver.cpp:353] Iteration 26200 (7.15866 iter/s, 13.9691s/100 iter), loss = 1.4452
I0802 05:49:13.509515 18636 solver.cpp:375]     Train net output #0: loss = 1.48456 (* 1 = 1.48456 loss)
I0802 05:49:13.509536 18636 sgd_solver.cpp:136] Iteration 26200, lr = 0.0083625, m = 0.9
I0802 05:49:27.490145 18636 solver.cpp:353] Iteration 26300 (7.15289 iter/s, 13.9804s/100 iter), loss = 1.64355
I0802 05:49:27.490244 18636 solver.cpp:375]     Train net output #0: loss = 2.07935 (* 1 = 2.07935 loss)
I0802 05:49:27.490263 18636 sgd_solver.cpp:136] Iteration 26300, lr = 0.00835625, m = 0.9
I0802 05:49:41.438264 18636 solver.cpp:353] Iteration 26400 (7.16962 iter/s, 13.9477s/100 iter), loss = 1.48892
I0802 05:49:41.438292 18636 solver.cpp:375]     Train net output #0: loss = 1.15364 (* 1 = 1.15364 loss)
I0802 05:49:41.438298 18636 sgd_solver.cpp:136] Iteration 26400, lr = 0.00835, m = 0.9
I0802 05:49:55.308226 18636 solver.cpp:353] Iteration 26500 (7.21002 iter/s, 13.8696s/100 iter), loss = 1.63855
I0802 05:49:55.308253 18636 solver.cpp:375]     Train net output #0: loss = 1.9412 (* 1 = 1.9412 loss)
I0802 05:49:55.308259 18636 sgd_solver.cpp:136] Iteration 26500, lr = 0.00834375, m = 0.9
I0802 05:50:09.280038 18636 solver.cpp:353] Iteration 26600 (7.15746 iter/s, 13.9714s/100 iter), loss = 1.47421
I0802 05:50:09.280107 18636 solver.cpp:375]     Train net output #0: loss = 1.54585 (* 1 = 1.54585 loss)
I0802 05:50:09.280113 18636 sgd_solver.cpp:136] Iteration 26600, lr = 0.0083375, m = 0.9
I0802 05:50:23.243505 18636 solver.cpp:353] Iteration 26700 (7.16174 iter/s, 13.9631s/100 iter), loss = 1.22211
I0802 05:50:23.243532 18636 solver.cpp:375]     Train net output #0: loss = 1.25101 (* 1 = 1.25101 loss)
I0802 05:50:23.243536 18636 sgd_solver.cpp:136] Iteration 26700, lr = 0.00833125, m = 0.9
I0802 05:50:37.131322 18636 solver.cpp:353] Iteration 26800 (7.20075 iter/s, 13.8874s/100 iter), loss = 1.28483
I0802 05:50:37.131376 18636 solver.cpp:375]     Train net output #0: loss = 1.08323 (* 1 = 1.08323 loss)
I0802 05:50:37.131388 18636 sgd_solver.cpp:136] Iteration 26800, lr = 0.008325, m = 0.9
I0802 05:50:51.073673 18636 solver.cpp:353] Iteration 26900 (7.17258 iter/s, 13.942s/100 iter), loss = 1.36901
I0802 05:50:51.073781 18636 solver.cpp:375]     Train net output #0: loss = 1.5163 (* 1 = 1.5163 loss)
I0802 05:50:51.073791 18636 sgd_solver.cpp:136] Iteration 26900, lr = 0.00831875, m = 0.9
I0802 05:51:04.790513 18636 solver.cpp:404] Sparsity after update:
I0802 05:51:04.803939 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:51:04.803953 18636 net.cpp:2270] conv1a_param_0(0.0267) 
I0802 05:51:04.803962 18636 net.cpp:2270] conv1b_param_0(0.0347) 
I0802 05:51:04.803966 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:51:04.803969 18636 net.cpp:2270] res2a_branch2a_param_0(0.0694) 
I0802 05:51:04.803973 18636 net.cpp:2270] res2a_branch2b_param_0(0.0694) 
I0802 05:51:04.803977 18636 net.cpp:2270] res3a_branch2a_param_0(0.0694) 
I0802 05:51:04.803979 18636 net.cpp:2270] res3a_branch2b_param_0(0.0694) 
I0802 05:51:04.803989 18636 net.cpp:2270] res4a_branch2a_param_0(0.0694) 
I0802 05:51:04.803994 18636 net.cpp:2270] res4a_branch2b_param_0(0.0694) 
I0802 05:51:04.803999 18636 net.cpp:2270] res5a_branch2a_param_0(0.0699) 
I0802 05:51:04.804003 18636 net.cpp:2270] res5a_branch2b_param_0(0.0694) 
I0802 05:51:04.804008 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (163814/2.86678e+06) 0.0571
I0802 05:51:04.932961 18661 solver.cpp:450] Finding and applying sparsity: 0.08
I0802 05:51:24.970907 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:51:24.972904 18636 solver.cpp:353] Iteration 27000 (2.95 iter/s, 33.8983s/100 iter), loss = 1.25808
I0802 05:51:24.972925 18636 solver.cpp:375]     Train net output #0: loss = 1.14989 (* 1 = 1.14989 loss)
I0802 05:51:24.972934 18636 sgd_solver.cpp:136] Iteration 27000, lr = 0.0083125, m = 0.9
I0802 05:51:39.426556 18636 solver.cpp:353] Iteration 27100 (6.91886 iter/s, 14.4533s/100 iter), loss = 1.52276
I0802 05:51:39.426584 18636 solver.cpp:375]     Train net output #0: loss = 1.66015 (* 1 = 1.66015 loss)
I0802 05:51:39.426591 18636 sgd_solver.cpp:136] Iteration 27100, lr = 0.00830625, m = 0.9
I0802 05:51:53.388947 18636 solver.cpp:353] Iteration 27200 (7.1623 iter/s, 13.962s/100 iter), loss = 1.53717
I0802 05:51:53.389037 18636 solver.cpp:375]     Train net output #0: loss = 1.47797 (* 1 = 1.47797 loss)
I0802 05:51:53.389063 18636 sgd_solver.cpp:136] Iteration 27200, lr = 0.0083, m = 0.9
I0802 05:52:07.359203 18636 solver.cpp:353] Iteration 27300 (7.15826 iter/s, 13.9699s/100 iter), loss = 1.61222
I0802 05:52:07.359269 18636 solver.cpp:375]     Train net output #0: loss = 1.58989 (* 1 = 1.58989 loss)
I0802 05:52:07.359274 18636 sgd_solver.cpp:136] Iteration 27300, lr = 0.00829375, m = 0.9
I0802 05:52:21.335191 18636 solver.cpp:353] Iteration 27400 (7.15532 iter/s, 13.9756s/100 iter), loss = 1.07942
I0802 05:52:21.335222 18636 solver.cpp:375]     Train net output #0: loss = 0.921983 (* 1 = 0.921983 loss)
I0802 05:52:21.335228 18636 sgd_solver.cpp:136] Iteration 27400, lr = 0.0082875, m = 0.9
I0802 05:52:35.370445 18636 solver.cpp:353] Iteration 27500 (7.12511 iter/s, 14.0349s/100 iter), loss = 1.27896
I0802 05:52:35.370473 18636 solver.cpp:375]     Train net output #0: loss = 1.30543 (* 1 = 1.30543 loss)
I0802 05:52:35.370479 18636 sgd_solver.cpp:136] Iteration 27500, lr = 0.00828125, m = 0.9
I0802 05:52:49.342378 18636 solver.cpp:353] Iteration 27600 (7.1574 iter/s, 13.9716s/100 iter), loss = 1.52811
I0802 05:52:49.342440 18636 solver.cpp:375]     Train net output #0: loss = 1.59892 (* 1 = 1.59892 loss)
I0802 05:52:49.342447 18636 sgd_solver.cpp:136] Iteration 27600, lr = 0.008275, m = 0.9
I0802 05:53:03.323745 18636 solver.cpp:353] Iteration 27700 (7.15257 iter/s, 13.981s/100 iter), loss = 1.44105
I0802 05:53:03.323770 18636 solver.cpp:375]     Train net output #0: loss = 1.39796 (* 1 = 1.39796 loss)
I0802 05:53:03.323774 18636 sgd_solver.cpp:136] Iteration 27700, lr = 0.00826875, m = 0.9
I0802 05:53:17.241407 18636 solver.cpp:353] Iteration 27800 (7.18531 iter/s, 13.9173s/100 iter), loss = 1.30981
I0802 05:53:17.241436 18636 solver.cpp:375]     Train net output #0: loss = 1.33884 (* 1 = 1.33884 loss)
I0802 05:53:17.241441 18636 sgd_solver.cpp:136] Iteration 27800, lr = 0.0082625, m = 0.9
I0802 05:53:31.153429 18636 solver.cpp:353] Iteration 27900 (7.18822 iter/s, 13.9116s/100 iter), loss = 1.06217
I0802 05:53:31.153514 18636 solver.cpp:375]     Train net output #0: loss = 1.06779 (* 1 = 1.06779 loss)
I0802 05:53:31.153522 18636 sgd_solver.cpp:136] Iteration 27900, lr = 0.00825625, m = 0.9
I0802 05:53:44.930532 18636 solver.cpp:404] Sparsity after update:
I0802 05:53:44.934460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:53:44.934471 18636 net.cpp:2270] conv1a_param_0(0.0262) 
I0802 05:53:44.934479 18636 net.cpp:2270] conv1b_param_0(0.0347) 
I0802 05:53:44.934484 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:53:44.934496 18636 net.cpp:2270] res2a_branch2a_param_0(0.0799) 
I0802 05:53:44.934505 18636 net.cpp:2270] res2a_branch2b_param_0(0.0764) 
I0802 05:53:44.934514 18636 net.cpp:2270] res3a_branch2a_param_0(0.0798) 
I0802 05:53:44.934522 18636 net.cpp:2270] res3a_branch2b_param_0(0.0799) 
I0802 05:53:44.934530 18636 net.cpp:2270] res4a_branch2a_param_0(0.0799) 
I0802 05:53:44.934538 18636 net.cpp:2270] res4a_branch2b_param_0(0.0799) 
I0802 05:53:44.934546 18636 net.cpp:2270] res5a_branch2a_param_0(0.0799) 
I0802 05:53:44.934556 18636 net.cpp:2270] res5a_branch2b_param_0(0.0798) 
I0802 05:53:44.934566 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (187754/2.86678e+06) 0.0655
I0802 05:53:44.934584 18636 solver.cpp:550] Iteration 28000, Testing net (#0)
I0802 05:53:48.686712 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:54:04.789305 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.554353
I0802 05:54:04.789420 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.790821
I0802 05:54:04.789429 18636 solver.cpp:635]     Test net output #2: loss = 1.98504 (* 1 = 1.98504 loss)
I0802 05:54:04.789448 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8543s
I0802 05:54:04.945808 18661 solver.cpp:450] Finding and applying sparsity: 0.09
I0802 05:54:24.515985 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:54:24.517915 18636 solver.cpp:353] Iteration 28000 (1.87396 iter/s, 53.3631s/100 iter), loss = 1.44075
I0802 05:54:24.517940 18636 solver.cpp:375]     Train net output #0: loss = 1.39853 (* 1 = 1.39853 loss)
I0802 05:54:24.517949 18636 sgd_solver.cpp:136] Iteration 28000, lr = 0.00825, m = 0.9
I0802 05:54:38.884678 18636 solver.cpp:353] Iteration 28100 (6.9607 iter/s, 14.3664s/100 iter), loss = 1.56361
I0802 05:54:38.884759 18636 solver.cpp:375]     Train net output #0: loss = 1.38216 (* 1 = 1.38216 loss)
I0802 05:54:38.884771 18636 sgd_solver.cpp:136] Iteration 28100, lr = 0.00824375, m = 0.9
I0802 05:54:52.827004 18636 solver.cpp:353] Iteration 28200 (7.1726 iter/s, 13.9419s/100 iter), loss = 1.50082
I0802 05:54:52.827054 18636 solver.cpp:375]     Train net output #0: loss = 1.92704 (* 1 = 1.92704 loss)
I0802 05:54:52.827066 18636 sgd_solver.cpp:136] Iteration 28200, lr = 0.0082375, m = 0.9
I0802 05:55:06.724313 18636 solver.cpp:353] Iteration 28300 (7.19583 iter/s, 13.8969s/100 iter), loss = 1.14405
I0802 05:55:06.724339 18636 solver.cpp:375]     Train net output #0: loss = 0.965398 (* 1 = 0.965398 loss)
I0802 05:55:06.724344 18636 sgd_solver.cpp:136] Iteration 28300, lr = 0.00823125, m = 0.9
I0802 05:55:20.617398 18636 solver.cpp:353] Iteration 28400 (7.19802 iter/s, 13.8927s/100 iter), loss = 1.33969
I0802 05:55:20.617461 18636 solver.cpp:375]     Train net output #0: loss = 1.24811 (* 1 = 1.24811 loss)
I0802 05:55:20.617511 18636 sgd_solver.cpp:136] Iteration 28400, lr = 0.008225, m = 0.9
I0802 05:55:34.476828 18636 solver.cpp:353] Iteration 28500 (7.2155 iter/s, 13.8591s/100 iter), loss = 1.48448
I0802 05:55:34.476853 18636 solver.cpp:375]     Train net output #0: loss = 1.35362 (* 1 = 1.35362 loss)
I0802 05:55:34.476857 18636 sgd_solver.cpp:136] Iteration 28500, lr = 0.00821875, m = 0.9
I0802 05:55:48.346257 18636 solver.cpp:353] Iteration 28600 (7.2103 iter/s, 13.8691s/100 iter), loss = 1.43251
I0802 05:55:48.346287 18636 solver.cpp:375]     Train net output #0: loss = 1.23167 (* 1 = 1.23167 loss)
I0802 05:55:48.346292 18636 sgd_solver.cpp:136] Iteration 28600, lr = 0.0082125, m = 0.9
I0802 05:56:02.275045 18636 solver.cpp:353] Iteration 28700 (7.17957 iter/s, 13.9284s/100 iter), loss = 1.44467
I0802 05:56:02.275142 18636 solver.cpp:375]     Train net output #0: loss = 1.49335 (* 1 = 1.49335 loss)
I0802 05:56:02.275151 18636 sgd_solver.cpp:136] Iteration 28700, lr = 0.00820625, m = 0.9
I0802 05:56:16.309741 18636 solver.cpp:353] Iteration 28800 (7.12539 iter/s, 14.0343s/100 iter), loss = 1.72062
I0802 05:56:16.309769 18636 solver.cpp:375]     Train net output #0: loss = 1.96237 (* 1 = 1.96237 loss)
I0802 05:56:16.309777 18636 sgd_solver.cpp:136] Iteration 28800, lr = 0.0082, m = 0.9
I0802 05:56:30.224898 18636 solver.cpp:353] Iteration 28900 (7.1866 iter/s, 13.9148s/100 iter), loss = 1.06731
I0802 05:56:30.224930 18636 solver.cpp:375]     Train net output #0: loss = 0.991142 (* 1 = 0.991142 loss)
I0802 05:56:30.224936 18636 sgd_solver.cpp:136] Iteration 28900, lr = 0.00819375, m = 0.9
I0802 05:56:43.965917 18636 solver.cpp:404] Sparsity after update:
I0802 05:56:43.977092 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:56:43.977107 18636 net.cpp:2270] conv1a_param_0(0.04) 
I0802 05:56:43.977114 18636 net.cpp:2270] conv1b_param_0(0.0417) 
I0802 05:56:43.977118 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:56:43.977129 18636 net.cpp:2270] res2a_branch2a_param_0(0.0868) 
I0802 05:56:43.977139 18636 net.cpp:2270] res2a_branch2b_param_0(0.0833) 
I0802 05:56:43.977149 18636 net.cpp:2270] res3a_branch2a_param_0(0.0885) 
I0802 05:56:43.977156 18636 net.cpp:2270] res3a_branch2b_param_0(0.0868) 
I0802 05:56:43.977165 18636 net.cpp:2270] res4a_branch2a_param_0(0.0894) 
I0802 05:56:43.977174 18636 net.cpp:2270] res4a_branch2b_param_0(0.0885) 
I0802 05:56:43.977182 18636 net.cpp:2270] res5a_branch2a_param_0(0.0898) 
I0802 05:56:43.977191 18636 net.cpp:2270] res5a_branch2b_param_0(0.0894) 
I0802 05:56:43.977201 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (210392/2.86678e+06) 0.0734
I0802 05:56:44.106552 18661 solver.cpp:450] Finding and applying sparsity: 0.1
I0802 05:57:04.043655 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:57:04.045635 18636 solver.cpp:353] Iteration 29000 (2.95685 iter/s, 33.8198s/100 iter), loss = 1.18944
I0802 05:57:04.045672 18636 solver.cpp:375]     Train net output #0: loss = 0.998471 (* 1 = 0.998471 loss)
I0802 05:57:04.045681 18636 sgd_solver.cpp:136] Iteration 29000, lr = 0.0081875, m = 0.9
I0802 05:57:18.509735 18636 solver.cpp:353] Iteration 29100 (6.91386 iter/s, 14.4637s/100 iter), loss = 1.42564
I0802 05:57:18.509838 18636 solver.cpp:375]     Train net output #0: loss = 1.19782 (* 1 = 1.19782 loss)
I0802 05:57:18.509860 18636 sgd_solver.cpp:136] Iteration 29100, lr = 0.00818125, m = 0.9
I0802 05:57:32.500514 18636 solver.cpp:353] Iteration 29200 (7.14776 iter/s, 13.9904s/100 iter), loss = 1.47032
I0802 05:57:32.500542 18636 solver.cpp:375]     Train net output #0: loss = 1.21898 (* 1 = 1.21898 loss)
I0802 05:57:32.500548 18636 sgd_solver.cpp:136] Iteration 29200, lr = 0.008175, m = 0.9
I0802 05:57:46.439697 18636 solver.cpp:353] Iteration 29300 (7.17422 iter/s, 13.9388s/100 iter), loss = 1.66436
I0802 05:57:46.439728 18636 solver.cpp:375]     Train net output #0: loss = 1.42395 (* 1 = 1.42395 loss)
I0802 05:57:46.439734 18636 sgd_solver.cpp:136] Iteration 29300, lr = 0.00816875, m = 0.9
I0802 05:58:00.393677 18636 solver.cpp:353] Iteration 29400 (7.16661 iter/s, 13.9536s/100 iter), loss = 1.53845
I0802 05:58:00.393759 18636 solver.cpp:375]     Train net output #0: loss = 1.38139 (* 1 = 1.38139 loss)
I0802 05:58:00.393766 18636 sgd_solver.cpp:136] Iteration 29400, lr = 0.0081625, m = 0.9
I0802 05:58:14.452641 18636 solver.cpp:353] Iteration 29500 (7.11309 iter/s, 14.0586s/100 iter), loss = 1.03383
I0802 05:58:14.452674 18636 solver.cpp:375]     Train net output #0: loss = 0.914532 (* 1 = 0.914532 loss)
I0802 05:58:14.452683 18636 sgd_solver.cpp:136] Iteration 29500, lr = 0.00815625, m = 0.9
I0802 05:58:28.427186 18636 solver.cpp:353] Iteration 29600 (7.15606 iter/s, 13.9742s/100 iter), loss = 1.31844
I0802 05:58:28.427227 18636 solver.cpp:375]     Train net output #0: loss = 1.50894 (* 1 = 1.50894 loss)
I0802 05:58:28.427235 18636 sgd_solver.cpp:136] Iteration 29600, lr = 0.00815, m = 0.9
I0802 05:58:42.444792 18636 solver.cpp:353] Iteration 29700 (7.13408 iter/s, 14.0172s/100 iter), loss = 1.38425
I0802 05:58:42.444916 18636 solver.cpp:375]     Train net output #0: loss = 0.928484 (* 1 = 0.928484 loss)
I0802 05:58:42.444922 18636 sgd_solver.cpp:136] Iteration 29700, lr = 0.00814375, m = 0.9
I0802 05:58:56.391649 18636 solver.cpp:353] Iteration 29800 (7.17027 iter/s, 13.9465s/100 iter), loss = 1.07253
I0802 05:58:56.391674 18636 solver.cpp:375]     Train net output #0: loss = 1.08238 (* 1 = 1.08238 loss)
I0802 05:58:56.391680 18636 sgd_solver.cpp:136] Iteration 29800, lr = 0.0081375, m = 0.9
I0802 05:59:10.329859 18636 solver.cpp:353] Iteration 29900 (7.17472 iter/s, 13.9378s/100 iter), loss = 1.21531
I0802 05:59:10.329883 18636 solver.cpp:375]     Train net output #0: loss = 1.20152 (* 1 = 1.20152 loss)
I0802 05:59:10.329888 18636 sgd_solver.cpp:136] Iteration 29900, lr = 0.00813125, m = 0.9
I0802 05:59:24.033574 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_30000.caffemodel
I0802 05:59:24.126144 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_30000.solverstate
I0802 05:59:24.130535 18636 solver.cpp:404] Sparsity after update:
I0802 05:59:24.132350 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:59:24.132361 18636 net.cpp:2270] conv1a_param_0(0.04) 
I0802 05:59:24.132370 18636 net.cpp:2270] conv1b_param_0(0.0486) 
I0802 05:59:24.132375 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:59:24.132385 18636 net.cpp:2270] res2a_branch2a_param_0(0.0972) 
I0802 05:59:24.132395 18636 net.cpp:2270] res2a_branch2b_param_0(0.0972) 
I0802 05:59:24.132405 18636 net.cpp:2270] res3a_branch2a_param_0(0.099) 
I0802 05:59:24.132412 18636 net.cpp:2270] res3a_branch2b_param_0(0.0972) 
I0802 05:59:24.132421 18636 net.cpp:2270] res4a_branch2a_param_0(0.0998) 
I0802 05:59:24.132429 18636 net.cpp:2270] res4a_branch2b_param_0(0.099) 
I0802 05:59:24.132438 18636 net.cpp:2270] res5a_branch2a_param_0(0.0998) 
I0802 05:59:24.132448 18636 net.cpp:2270] res5a_branch2b_param_0(0.0998) 
I0802 05:59:24.132458 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (234400/2.86678e+06) 0.0818
I0802 05:59:24.132483 18636 solver.cpp:550] Iteration 30000, Testing net (#0)
I0802 05:59:37.595752 18619 data_reader.cpp:264] Starting prefetch of epoch 3
I0802 05:59:44.095373 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.559235
I0802 05:59:44.095394 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.793174
I0802 05:59:44.095399 18636 solver.cpp:635]     Test net output #2: loss = 1.94894 (* 1 = 1.94894 loss)
I0802 05:59:44.095417 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9624s
I0802 05:59:44.233949 18661 solver.cpp:450] Finding and applying sparsity: 0.11
I0802 06:00:04.353149 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:00:04.355175 18636 solver.cpp:353] Iteration 30000 (1.85103 iter/s, 54.0239s/100 iter), loss = 1.55084
I0802 06:00:04.355196 18636 solver.cpp:375]     Train net output #0: loss = 1.76583 (* 1 = 1.76583 loss)
I0802 06:00:04.355204 18636 sgd_solver.cpp:136] Iteration 30000, lr = 0.008125, m = 0.9
I0802 06:00:18.704565 18636 solver.cpp:353] Iteration 30100 (6.96913 iter/s, 14.349s/100 iter), loss = 1.32596
I0802 06:00:18.704620 18636 solver.cpp:375]     Train net output #0: loss = 1.75135 (* 1 = 1.75135 loss)
I0802 06:00:18.704633 18636 sgd_solver.cpp:136] Iteration 30100, lr = 0.00811875, m = 0.9
I0802 06:00:32.593791 18636 solver.cpp:353] Iteration 30200 (7.20002 iter/s, 13.8888s/100 iter), loss = 1.54684
I0802 06:00:32.593843 18636 solver.cpp:375]     Train net output #0: loss = 1.27261 (* 1 = 1.27261 loss)
I0802 06:00:32.593855 18636 sgd_solver.cpp:136] Iteration 30200, lr = 0.0081125, m = 0.9
I0802 06:00:46.584283 18636 solver.cpp:353] Iteration 30300 (7.14791 iter/s, 13.9901s/100 iter), loss = 1.39891
I0802 06:00:46.584355 18636 solver.cpp:375]     Train net output #0: loss = 1.52353 (* 1 = 1.52353 loss)
I0802 06:00:46.584362 18636 sgd_solver.cpp:136] Iteration 30300, lr = 0.00810625, m = 0.9
I0802 06:01:00.582442 18636 solver.cpp:353] Iteration 30400 (7.14399 iter/s, 13.9978s/100 iter), loss = 1.61956
I0802 06:01:00.582473 18636 solver.cpp:375]     Train net output #0: loss = 1.50366 (* 1 = 1.50366 loss)
I0802 06:01:00.582479 18636 sgd_solver.cpp:136] Iteration 30400, lr = 0.0081, m = 0.9
I0802 06:01:14.577157 18636 solver.cpp:353] Iteration 30500 (7.14575 iter/s, 13.9943s/100 iter), loss = 1.28949
I0802 06:01:14.577262 18636 solver.cpp:375]     Train net output #0: loss = 1.10569 (* 1 = 1.10569 loss)
I0802 06:01:14.577283 18636 sgd_solver.cpp:136] Iteration 30500, lr = 0.00809375, m = 0.9
I0802 06:01:28.466857 18636 solver.cpp:353] Iteration 30600 (7.19978 iter/s, 13.8893s/100 iter), loss = 1.71852
I0802 06:01:28.467118 18636 solver.cpp:375]     Train net output #0: loss = 1.61279 (* 1 = 1.61279 loss)
I0802 06:01:28.467241 18636 sgd_solver.cpp:136] Iteration 30600, lr = 0.0080875, m = 0.9
I0802 06:01:42.438578 18636 solver.cpp:353] Iteration 30700 (7.15751 iter/s, 13.9713s/100 iter), loss = 1.45255
I0802 06:01:42.438616 18636 solver.cpp:375]     Train net output #0: loss = 1.45898 (* 1 = 1.45898 loss)
I0802 06:01:42.438623 18636 sgd_solver.cpp:136] Iteration 30700, lr = 0.00808125, m = 0.9
I0802 06:01:56.410507 18636 solver.cpp:353] Iteration 30800 (7.1574 iter/s, 13.9716s/100 iter), loss = 1.66551
I0802 06:01:56.410536 18636 solver.cpp:375]     Train net output #0: loss = 1.8377 (* 1 = 1.8377 loss)
I0802 06:01:56.410542 18636 sgd_solver.cpp:136] Iteration 30800, lr = 0.008075, m = 0.9
I0802 06:02:10.450546 18636 solver.cpp:353] Iteration 30900 (7.12268 iter/s, 14.0397s/100 iter), loss = 1.37373
I0802 06:02:10.450628 18636 solver.cpp:375]     Train net output #0: loss = 1.3678 (* 1 = 1.3678 loss)
I0802 06:02:10.450634 18636 sgd_solver.cpp:136] Iteration 30900, lr = 0.00806875, m = 0.9
I0802 06:02:24.294728 18636 solver.cpp:404] Sparsity after update:
I0802 06:02:24.305922 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:02:24.305934 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:02:24.305943 18636 net.cpp:2270] conv1b_param_0(0.0486) 
I0802 06:02:24.305948 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:02:24.305953 18636 net.cpp:2270] res2a_branch2a_param_0(0.108) 
I0802 06:02:24.305958 18636 net.cpp:2270] res2a_branch2b_param_0(0.104) 
I0802 06:02:24.305960 18636 net.cpp:2270] res3a_branch2a_param_0(0.109) 
I0802 06:02:24.305965 18636 net.cpp:2270] res3a_branch2b_param_0(0.108) 
I0802 06:02:24.305968 18636 net.cpp:2270] res4a_branch2a_param_0(0.109) 
I0802 06:02:24.305974 18636 net.cpp:2270] res4a_branch2b_param_0(0.109) 
I0802 06:02:24.305977 18636 net.cpp:2270] res5a_branch2a_param_0(0.11) 
I0802 06:02:24.305982 18636 net.cpp:2270] res5a_branch2b_param_0(0.109) 
I0802 06:02:24.305986 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (257606/2.86678e+06) 0.0899
I0802 06:02:24.450870 18661 solver.cpp:450] Finding and applying sparsity: 0.12
I0802 06:02:44.700291 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:02:44.702239 18636 solver.cpp:353] Iteration 31000 (2.91964 iter/s, 34.2508s/100 iter), loss = 1.54528
I0802 06:02:44.702256 18636 solver.cpp:375]     Train net output #0: loss = 1.26986 (* 1 = 1.26986 loss)
I0802 06:02:44.702262 18636 sgd_solver.cpp:136] Iteration 31000, lr = 0.0080625, m = 0.9
I0802 06:02:59.029135 18636 solver.cpp:353] Iteration 31100 (6.98007 iter/s, 14.3265s/100 iter), loss = 1.3692
I0802 06:02:59.029161 18636 solver.cpp:375]     Train net output #0: loss = 1.43204 (* 1 = 1.43204 loss)
I0802 06:02:59.029167 18636 sgd_solver.cpp:136] Iteration 31100, lr = 0.00805625, m = 0.9
I0802 06:03:12.971092 18636 solver.cpp:353] Iteration 31200 (7.17279 iter/s, 13.9416s/100 iter), loss = 1.51153
I0802 06:03:12.971119 18636 solver.cpp:375]     Train net output #0: loss = 1.30409 (* 1 = 1.30409 loss)
I0802 06:03:12.971125 18636 sgd_solver.cpp:136] Iteration 31200, lr = 0.00805, m = 0.9
I0802 06:03:26.903607 18636 solver.cpp:353] Iteration 31300 (7.17765 iter/s, 13.9321s/100 iter), loss = 1.53376
I0802 06:03:26.903708 18636 solver.cpp:375]     Train net output #0: loss = 1.68108 (* 1 = 1.68108 loss)
I0802 06:03:26.903717 18636 sgd_solver.cpp:136] Iteration 31300, lr = 0.00804375, m = 0.9
I0802 06:03:40.943881 18636 solver.cpp:353] Iteration 31400 (7.12256 iter/s, 14.0399s/100 iter), loss = 1.29764
I0802 06:03:40.943938 18636 solver.cpp:375]     Train net output #0: loss = 0.925732 (* 1 = 0.925732 loss)
I0802 06:03:40.943953 18636 sgd_solver.cpp:136] Iteration 31400, lr = 0.0080375, m = 0.9
I0802 06:03:54.825460 18636 solver.cpp:353] Iteration 31500 (7.20399 iter/s, 13.8812s/100 iter), loss = 1.62597
I0802 06:03:54.825489 18636 solver.cpp:375]     Train net output #0: loss = 1.41889 (* 1 = 1.41889 loss)
I0802 06:03:54.825492 18636 sgd_solver.cpp:136] Iteration 31500, lr = 0.00803125, m = 0.9
I0802 06:04:08.749730 18636 solver.cpp:353] Iteration 31600 (7.1819 iter/s, 13.9239s/100 iter), loss = 1.01587
I0802 06:04:08.749794 18636 solver.cpp:375]     Train net output #0: loss = 1.06167 (* 1 = 1.06167 loss)
I0802 06:04:08.749801 18636 sgd_solver.cpp:136] Iteration 31600, lr = 0.008025, m = 0.9
I0802 06:04:22.789878 18636 solver.cpp:353] Iteration 31700 (7.12262 iter/s, 14.0398s/100 iter), loss = 1.64736
I0802 06:04:22.789901 18636 solver.cpp:375]     Train net output #0: loss = 1.54187 (* 1 = 1.54187 loss)
I0802 06:04:22.789906 18636 sgd_solver.cpp:136] Iteration 31700, lr = 0.00801875, m = 0.9
I0802 06:04:36.716022 18636 solver.cpp:353] Iteration 31800 (7.18093 iter/s, 13.9258s/100 iter), loss = 1.391
I0802 06:04:36.716049 18636 solver.cpp:375]     Train net output #0: loss = 1.52721 (* 1 = 1.52721 loss)
I0802 06:04:36.716056 18636 sgd_solver.cpp:136] Iteration 31800, lr = 0.0080125, m = 0.9
I0802 06:04:50.609114 18636 solver.cpp:353] Iteration 31900 (7.19802 iter/s, 13.8927s/100 iter), loss = 1.54249
I0802 06:04:50.609360 18636 solver.cpp:375]     Train net output #0: loss = 1.55528 (* 1 = 1.55528 loss)
I0802 06:04:50.609378 18636 sgd_solver.cpp:136] Iteration 31900, lr = 0.00800625, m = 0.9
I0802 06:05:04.447976 18636 solver.cpp:404] Sparsity after update:
I0802 06:05:04.453987 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:05:04.454004 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:05:04.454010 18636 net.cpp:2270] conv1b_param_0(0.0556) 
I0802 06:05:04.454015 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:05:04.454017 18636 net.cpp:2270] res2a_branch2a_param_0(0.118) 
I0802 06:05:04.454021 18636 net.cpp:2270] res2a_branch2b_param_0(0.118) 
I0802 06:05:04.454026 18636 net.cpp:2270] res3a_branch2a_param_0(0.12) 
I0802 06:05:04.454030 18636 net.cpp:2270] res3a_branch2b_param_0(0.118) 
I0802 06:05:04.454033 18636 net.cpp:2270] res4a_branch2a_param_0(0.12) 
I0802 06:05:04.454036 18636 net.cpp:2270] res4a_branch2b_param_0(0.12) 
I0802 06:05:04.454040 18636 net.cpp:2270] res5a_branch2a_param_0(0.12) 
I0802 06:05:04.454042 18636 net.cpp:2270] res5a_branch2b_param_0(0.12) 
I0802 06:05:04.454046 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (281620/2.86678e+06) 0.0982
I0802 06:05:04.454067 18636 solver.cpp:550] Iteration 32000, Testing net (#0)
I0802 06:05:24.197046 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.553588
I0802 06:05:24.197094 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.792939
I0802 06:05:24.197103 18636 solver.cpp:635]     Test net output #2: loss = 1.98824 (* 1 = 1.98824 loss)
I0802 06:05:24.197170 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7426s
I0802 06:05:24.349567 18661 solver.cpp:450] Finding and applying sparsity: 0.13
I0802 06:05:44.432041 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:05:44.433919 18636 solver.cpp:353] Iteration 32000 (1.85793 iter/s, 53.8234s/100 iter), loss = 1.31415
I0802 06:05:44.433938 18636 solver.cpp:375]     Train net output #0: loss = 1.01202 (* 1 = 1.01202 loss)
I0802 06:05:44.433944 18636 sgd_solver.cpp:136] Iteration 32000, lr = 0.008, m = 0.9
I0802 06:05:58.895612 18636 solver.cpp:353] Iteration 32100 (6.91501 iter/s, 14.4613s/100 iter), loss = 1.21099
I0802 06:05:58.895697 18636 solver.cpp:375]     Train net output #0: loss = 1.15348 (* 1 = 1.15348 loss)
I0802 06:05:58.895704 18636 sgd_solver.cpp:136] Iteration 32100, lr = 0.00799375, m = 0.9
I0802 06:06:12.789685 18636 solver.cpp:353] Iteration 32200 (7.19751 iter/s, 13.8937s/100 iter), loss = 1.73192
I0802 06:06:12.789717 18636 solver.cpp:375]     Train net output #0: loss = 2.14005 (* 1 = 2.14005 loss)
I0802 06:06:12.789724 18636 sgd_solver.cpp:136] Iteration 32200, lr = 0.0079875, m = 0.9
I0802 06:06:26.737817 18636 solver.cpp:353] Iteration 32300 (7.16961 iter/s, 13.9478s/100 iter), loss = 1.58302
I0802 06:06:26.737839 18636 solver.cpp:375]     Train net output #0: loss = 1.36198 (* 1 = 1.36198 loss)
I0802 06:06:26.737843 18636 sgd_solver.cpp:136] Iteration 32300, lr = 0.00798125, m = 0.9
I0802 06:06:40.744541 18636 solver.cpp:353] Iteration 32400 (7.13962 iter/s, 14.0063s/100 iter), loss = 1.27726
I0802 06:06:40.744622 18636 solver.cpp:375]     Train net output #0: loss = 1.23522 (* 1 = 1.23522 loss)
I0802 06:06:40.744630 18636 sgd_solver.cpp:136] Iteration 32400, lr = 0.007975, m = 0.9
I0802 06:06:54.807512 18636 solver.cpp:353] Iteration 32500 (7.11106 iter/s, 14.0626s/100 iter), loss = 1.39991
I0802 06:06:54.807543 18636 solver.cpp:375]     Train net output #0: loss = 1.44973 (* 1 = 1.44973 loss)
I0802 06:06:54.807548 18636 sgd_solver.cpp:136] Iteration 32500, lr = 0.00796875, m = 0.9
I0802 06:07:08.808859 18636 solver.cpp:353] Iteration 32600 (7.14237 iter/s, 14.001s/100 iter), loss = 1.75013
I0802 06:07:08.808895 18636 solver.cpp:375]     Train net output #0: loss = 2.22344 (* 1 = 2.22344 loss)
I0802 06:07:08.808902 18636 sgd_solver.cpp:136] Iteration 32600, lr = 0.0079625, m = 0.9
I0802 06:07:22.758975 18636 solver.cpp:353] Iteration 32700 (7.16859 iter/s, 13.9497s/100 iter), loss = 1.17581
I0802 06:07:22.759032 18636 solver.cpp:375]     Train net output #0: loss = 1.31548 (* 1 = 1.31548 loss)
I0802 06:07:22.759038 18636 sgd_solver.cpp:136] Iteration 32700, lr = 0.00795625, m = 0.9
I0802 06:07:36.652197 18636 solver.cpp:353] Iteration 32800 (7.19795 iter/s, 13.8928s/100 iter), loss = 1.25648
I0802 06:07:36.652220 18636 solver.cpp:375]     Train net output #0: loss = 1.28467 (* 1 = 1.28467 loss)
I0802 06:07:36.652225 18636 sgd_solver.cpp:136] Iteration 32800, lr = 0.00795, m = 0.9
I0802 06:07:50.659379 18636 solver.cpp:353] Iteration 32900 (7.13939 iter/s, 14.0068s/100 iter), loss = 1.94627
I0802 06:07:50.659409 18636 solver.cpp:375]     Train net output #0: loss = 2.0849 (* 1 = 2.0849 loss)
I0802 06:07:50.659415 18636 sgd_solver.cpp:136] Iteration 32900, lr = 0.00794375, m = 0.9
I0802 06:08:04.500062 18636 solver.cpp:404] Sparsity after update:
I0802 06:08:04.511224 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:08:04.511237 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:08:04.511246 18636 net.cpp:2270] conv1b_param_0(0.0625) 
I0802 06:08:04.511250 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:08:04.511262 18636 net.cpp:2270] res2a_branch2a_param_0(0.128) 
I0802 06:08:04.511272 18636 net.cpp:2270] res2a_branch2b_param_0(0.125) 
I0802 06:08:04.511281 18636 net.cpp:2270] res3a_branch2a_param_0(0.128) 
I0802 06:08:04.511291 18636 net.cpp:2270] res3a_branch2b_param_0(0.128) 
I0802 06:08:04.511296 18636 net.cpp:2270] res4a_branch2a_param_0(0.129) 
I0802 06:08:04.511299 18636 net.cpp:2270] res4a_branch2b_param_0(0.128) 
I0802 06:08:04.511307 18636 net.cpp:2270] res5a_branch2a_param_0(0.13) 
I0802 06:08:04.511312 18636 net.cpp:2270] res5a_branch2b_param_0(0.129) 
I0802 06:08:04.511317 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (304422/2.86678e+06) 0.106
I0802 06:08:04.640012 18661 solver.cpp:450] Finding and applying sparsity: 0.14
I0802 06:08:24.951288 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:08:24.953225 18636 solver.cpp:353] Iteration 33000 (2.91606 iter/s, 34.2929s/100 iter), loss = 1.3684
I0802 06:08:24.953243 18636 solver.cpp:375]     Train net output #0: loss = 1.39817 (* 1 = 1.39817 loss)
I0802 06:08:24.953249 18636 sgd_solver.cpp:136] Iteration 33000, lr = 0.0079375, m = 0.9
I0802 06:08:39.351909 18636 solver.cpp:353] Iteration 33100 (6.94527 iter/s, 14.3983s/100 iter), loss = 1.43742
I0802 06:08:39.351992 18636 solver.cpp:375]     Train net output #0: loss = 1.53362 (* 1 = 1.53362 loss)
I0802 06:08:39.352001 18636 sgd_solver.cpp:136] Iteration 33100, lr = 0.00793125, m = 0.9
I0802 06:08:53.253420 18636 solver.cpp:353] Iteration 33200 (7.19366 iter/s, 13.9011s/100 iter), loss = 1.2981
I0802 06:08:53.253449 18636 solver.cpp:375]     Train net output #0: loss = 1.10609 (* 1 = 1.10609 loss)
I0802 06:08:53.253455 18636 sgd_solver.cpp:136] Iteration 33200, lr = 0.007925, m = 0.9
I0802 06:09:07.130131 18636 solver.cpp:353] Iteration 33300 (7.20651 iter/s, 13.8763s/100 iter), loss = 1.52726
I0802 06:09:07.130156 18636 solver.cpp:375]     Train net output #0: loss = 1.32184 (* 1 = 1.32184 loss)
I0802 06:09:07.130162 18636 sgd_solver.cpp:136] Iteration 33300, lr = 0.00791875, m = 0.9
I0802 06:09:20.979233 18636 solver.cpp:353] Iteration 33400 (7.22088 iter/s, 13.8487s/100 iter), loss = 1.5708
I0802 06:09:20.979318 18636 solver.cpp:375]     Train net output #0: loss = 1.31809 (* 1 = 1.31809 loss)
I0802 06:09:20.979326 18636 sgd_solver.cpp:136] Iteration 33400, lr = 0.0079125, m = 0.9
I0802 06:09:34.832259 18636 solver.cpp:353] Iteration 33500 (7.21884 iter/s, 13.8526s/100 iter), loss = 1.69316
I0802 06:09:34.832288 18636 solver.cpp:375]     Train net output #0: loss = 1.53227 (* 1 = 1.53227 loss)
I0802 06:09:34.832293 18636 sgd_solver.cpp:136] Iteration 33500, lr = 0.00790625, m = 0.9
I0802 06:09:48.706733 18636 solver.cpp:353] Iteration 33600 (7.20767 iter/s, 13.8741s/100 iter), loss = 1.39298
I0802 06:09:48.706763 18636 solver.cpp:375]     Train net output #0: loss = 1.55378 (* 1 = 1.55378 loss)
I0802 06:09:48.706769 18636 sgd_solver.cpp:136] Iteration 33600, lr = 0.0079, m = 0.9
I0802 06:10:02.608650 18636 solver.cpp:353] Iteration 33700 (7.19345 iter/s, 13.9015s/100 iter), loss = 1.55934
I0802 06:10:02.608757 18636 solver.cpp:375]     Train net output #0: loss = 1.90295 (* 1 = 1.90295 loss)
I0802 06:10:02.608765 18636 sgd_solver.cpp:136] Iteration 33700, lr = 0.00789375, m = 0.9
I0802 06:10:16.490907 18636 solver.cpp:353] Iteration 33800 (7.20363 iter/s, 13.8819s/100 iter), loss = 1.4353
I0802 06:10:16.490938 18636 solver.cpp:375]     Train net output #0: loss = 1.84529 (* 1 = 1.84529 loss)
I0802 06:10:16.490944 18636 sgd_solver.cpp:136] Iteration 33800, lr = 0.0078875, m = 0.9
I0802 06:10:30.520153 18636 solver.cpp:353] Iteration 33900 (7.12816 iter/s, 14.0289s/100 iter), loss = 1.21506
I0802 06:10:30.520223 18636 solver.cpp:375]     Train net output #0: loss = 1.20371 (* 1 = 1.20371 loss)
I0802 06:10:30.520243 18636 sgd_solver.cpp:136] Iteration 33900, lr = 0.00788125, m = 0.9
I0802 06:10:44.253865 18636 solver.cpp:404] Sparsity after update:
I0802 06:10:44.259771 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:10:44.259781 18636 net.cpp:2270] conv1a_param_0(0.0667) 
I0802 06:10:44.259789 18636 net.cpp:2270] conv1b_param_0(0.0694) 
I0802 06:10:44.259791 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:10:44.259793 18636 net.cpp:2270] res2a_branch2a_param_0(0.139) 
I0802 06:10:44.259795 18636 net.cpp:2270] res2a_branch2b_param_0(0.139) 
I0802 06:10:44.259798 18636 net.cpp:2270] res3a_branch2a_param_0(0.139) 
I0802 06:10:44.259799 18636 net.cpp:2270] res3a_branch2b_param_0(0.139) 
I0802 06:10:44.259801 18636 net.cpp:2270] res4a_branch2a_param_0(0.14) 
I0802 06:10:44.259802 18636 net.cpp:2270] res4a_branch2b_param_0(0.139) 
I0802 06:10:44.259804 18636 net.cpp:2270] res5a_branch2a_param_0(0.14) 
I0802 06:10:44.259806 18636 net.cpp:2270] res5a_branch2b_param_0(0.14) 
I0802 06:10:44.259809 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (328454/2.86678e+06) 0.115
I0802 06:10:44.259817 18636 solver.cpp:550] Iteration 34000, Testing net (#0)
I0802 06:10:53.497588 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:11:03.796056 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.549588
I0802 06:11:03.796079 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787291
I0802 06:11:03.796085 18636 solver.cpp:635]     Test net output #2: loss = 2.00174 (* 1 = 2.00174 loss)
I0802 06:11:03.796108 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5358s
I0802 06:11:03.952508 18661 solver.cpp:450] Finding and applying sparsity: 0.15
I0802 06:11:24.097986 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:11:24.099927 18636 solver.cpp:353] Iteration 34000 (1.86643 iter/s, 53.5783s/100 iter), loss = 1.93675
I0802 06:11:24.099951 18636 solver.cpp:375]     Train net output #0: loss = 1.56001 (* 1 = 1.56001 loss)
I0802 06:11:24.099961 18636 sgd_solver.cpp:136] Iteration 34000, lr = 0.007875, m = 0.9
I0802 06:11:38.466827 18636 solver.cpp:353] Iteration 34100 (6.96064 iter/s, 14.3665s/100 iter), loss = 1.61132
I0802 06:11:38.466856 18636 solver.cpp:375]     Train net output #0: loss = 2.14462 (* 1 = 2.14462 loss)
I0802 06:11:38.466861 18636 sgd_solver.cpp:136] Iteration 34100, lr = 0.00786875, m = 0.9
I0802 06:11:52.376768 18636 solver.cpp:353] Iteration 34200 (7.1893 iter/s, 13.9096s/100 iter), loss = 1.47794
I0802 06:11:52.376798 18636 solver.cpp:375]     Train net output #0: loss = 0.957443 (* 1 = 0.957443 loss)
I0802 06:11:52.376806 18636 sgd_solver.cpp:136] Iteration 34200, lr = 0.0078625, m = 0.9
I0802 06:12:06.240746 18636 solver.cpp:353] Iteration 34300 (7.21313 iter/s, 13.8636s/100 iter), loss = 1.60245
I0802 06:12:06.240804 18636 solver.cpp:375]     Train net output #0: loss = 1.42783 (* 1 = 1.42783 loss)
I0802 06:12:06.240810 18636 sgd_solver.cpp:136] Iteration 34300, lr = 0.00785625, m = 0.9
I0802 06:12:20.134119 18636 solver.cpp:353] Iteration 34400 (7.19787 iter/s, 13.893s/100 iter), loss = 1.35297
I0802 06:12:20.134187 18636 solver.cpp:375]     Train net output #0: loss = 1.25616 (* 1 = 1.25616 loss)
I0802 06:12:20.134201 18636 sgd_solver.cpp:136] Iteration 34400, lr = 0.00785, m = 0.9
I0802 06:12:34.038715 18636 solver.cpp:353] Iteration 34500 (7.19206 iter/s, 13.9042s/100 iter), loss = 1.12554
I0802 06:12:34.038743 18636 solver.cpp:375]     Train net output #0: loss = 1.15932 (* 1 = 1.15932 loss)
I0802 06:12:34.038750 18636 sgd_solver.cpp:136] Iteration 34500, lr = 0.00784375, m = 0.9
I0802 06:12:47.964478 18636 solver.cpp:353] Iteration 34600 (7.18113 iter/s, 13.9254s/100 iter), loss = 1.33582
I0802 06:12:47.964535 18636 solver.cpp:375]     Train net output #0: loss = 1.322 (* 1 = 1.322 loss)
I0802 06:12:47.964540 18636 sgd_solver.cpp:136] Iteration 34600, lr = 0.0078375, m = 0.9
I0802 06:13:01.897832 18636 solver.cpp:353] Iteration 34700 (7.17722 iter/s, 13.933s/100 iter), loss = 1.23736
I0802 06:13:01.897884 18636 solver.cpp:375]     Train net output #0: loss = 1.24658 (* 1 = 1.24658 loss)
I0802 06:13:01.897897 18636 sgd_solver.cpp:136] Iteration 34700, lr = 0.00783125, m = 0.9
I0802 06:13:15.799737 18636 solver.cpp:353] Iteration 34800 (7.19345 iter/s, 13.9015s/100 iter), loss = 1.65103
I0802 06:13:15.799791 18636 solver.cpp:375]     Train net output #0: loss = 2.00466 (* 1 = 2.00466 loss)
I0802 06:13:15.799803 18636 sgd_solver.cpp:136] Iteration 34800, lr = 0.007825, m = 0.9
I0802 06:13:29.772428 18636 solver.cpp:353] Iteration 34900 (7.15701 iter/s, 13.9723s/100 iter), loss = 1.3906
I0802 06:13:29.772493 18636 solver.cpp:375]     Train net output #0: loss = 1.35142 (* 1 = 1.35142 loss)
I0802 06:13:29.772501 18636 sgd_solver.cpp:136] Iteration 34900, lr = 0.00781875, m = 0.9
I0802 06:13:43.697849 18636 solver.cpp:404] Sparsity after update:
I0802 06:13:43.709441 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:13:43.709455 18636 net.cpp:2270] conv1a_param_0(0.0667) 
I0802 06:13:43.709463 18636 net.cpp:2270] conv1b_param_0(0.0694) 
I0802 06:13:43.709467 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:13:43.709471 18636 net.cpp:2270] res2a_branch2a_param_0(0.149) 
I0802 06:13:43.709475 18636 net.cpp:2270] res2a_branch2b_param_0(0.146) 
I0802 06:13:43.709480 18636 net.cpp:2270] res3a_branch2a_param_0(0.149) 
I0802 06:13:43.709482 18636 net.cpp:2270] res3a_branch2b_param_0(0.149) 
I0802 06:13:43.709486 18636 net.cpp:2270] res4a_branch2a_param_0(0.149) 
I0802 06:13:43.709489 18636 net.cpp:2270] res4a_branch2b_param_0(0.149) 
I0802 06:13:43.709492 18636 net.cpp:2270] res5a_branch2a_param_0(0.15) 
I0802 06:13:43.709496 18636 net.cpp:2270] res5a_branch2b_param_0(0.149) 
I0802 06:13:43.709512 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (351632/2.86678e+06) 0.123
I0802 06:13:43.847515 18661 solver.cpp:450] Finding and applying sparsity: 0.16
I0802 06:14:04.641059 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:14:04.643103 18636 solver.cpp:353] Iteration 35000 (2.86782 iter/s, 34.8697s/100 iter), loss = 1.43152
I0802 06:14:04.643139 18636 solver.cpp:375]     Train net output #0: loss = 1.01164 (* 1 = 1.01164 loss)
I0802 06:14:04.643148 18636 sgd_solver.cpp:136] Iteration 35000, lr = 0.0078125, m = 0.9
I0802 06:14:18.947489 18636 solver.cpp:353] Iteration 35100 (6.99105 iter/s, 14.304s/100 iter), loss = 1.42457
I0802 06:14:18.947513 18636 solver.cpp:375]     Train net output #0: loss = 1.97777 (* 1 = 1.97777 loss)
I0802 06:14:18.947520 18636 sgd_solver.cpp:136] Iteration 35100, lr = 0.00780625, m = 0.9
I0802 06:14:32.969018 18636 solver.cpp:353] Iteration 35200 (7.13209 iter/s, 14.0211s/100 iter), loss = 1.42045
I0802 06:14:32.969049 18636 solver.cpp:375]     Train net output #0: loss = 1.4208 (* 1 = 1.4208 loss)
I0802 06:14:32.969055 18636 sgd_solver.cpp:136] Iteration 35200, lr = 0.0078, m = 0.9
I0802 06:14:46.913822 18636 solver.cpp:353] Iteration 35300 (7.17133 iter/s, 13.9444s/100 iter), loss = 1.41107
I0802 06:14:46.913913 18636 solver.cpp:375]     Train net output #0: loss = 0.936475 (* 1 = 0.936475 loss)
I0802 06:14:46.913920 18636 sgd_solver.cpp:136] Iteration 35300, lr = 0.00779375, m = 0.9
I0802 06:15:00.840399 18636 solver.cpp:353] Iteration 35400 (7.18071 iter/s, 13.9262s/100 iter), loss = 1.51751
I0802 06:15:00.840426 18636 solver.cpp:375]     Train net output #0: loss = 1.38669 (* 1 = 1.38669 loss)
I0802 06:15:00.840432 18636 sgd_solver.cpp:136] Iteration 35400, lr = 0.0077875, m = 0.9
I0802 06:15:14.787082 18636 solver.cpp:353] Iteration 35500 (7.17036 iter/s, 13.9463s/100 iter), loss = 1.56842
I0802 06:15:14.787112 18636 solver.cpp:375]     Train net output #0: loss = 1.52226 (* 1 = 1.52226 loss)
I0802 06:15:14.787118 18636 sgd_solver.cpp:136] Iteration 35500, lr = 0.00778125, m = 0.9
I0802 06:15:28.679105 18636 solver.cpp:353] Iteration 35600 (7.19857 iter/s, 13.8916s/100 iter), loss = 1.7313
I0802 06:15:28.679175 18636 solver.cpp:375]     Train net output #0: loss = 1.96809 (* 1 = 1.96809 loss)
I0802 06:15:28.679183 18636 sgd_solver.cpp:136] Iteration 35600, lr = 0.007775, m = 0.9
I0802 06:15:42.644631 18636 solver.cpp:353] Iteration 35700 (7.16068 iter/s, 13.9651s/100 iter), loss = 1.48752
I0802 06:15:42.644659 18636 solver.cpp:375]     Train net output #0: loss = 1.07982 (* 1 = 1.07982 loss)
I0802 06:15:42.644665 18636 sgd_solver.cpp:136] Iteration 35700, lr = 0.00776875, m = 0.9
I0802 06:15:56.663738 18636 solver.cpp:353] Iteration 35800 (7.13331 iter/s, 14.0187s/100 iter), loss = 1.3464
I0802 06:15:56.663767 18636 solver.cpp:375]     Train net output #0: loss = 1.33096 (* 1 = 1.33096 loss)
I0802 06:15:56.663774 18636 sgd_solver.cpp:136] Iteration 35800, lr = 0.0077625, m = 0.9
I0802 06:16:10.717176 18636 solver.cpp:353] Iteration 35900 (7.11589 iter/s, 14.0531s/100 iter), loss = 1.68913
I0802 06:16:10.717329 18636 solver.cpp:375]     Train net output #0: loss = 1.56663 (* 1 = 1.56663 loss)
I0802 06:16:10.717352 18636 sgd_solver.cpp:136] Iteration 35900, lr = 0.00775625, m = 0.9
I0802 06:16:24.580972 18636 solver.cpp:404] Sparsity after update:
I0802 06:16:24.586894 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:16:24.586905 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:16:24.586911 18636 net.cpp:2270] conv1b_param_0(0.0764) 
I0802 06:16:24.586913 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:16:24.586915 18636 net.cpp:2270] res2a_branch2a_param_0(0.16) 
I0802 06:16:24.586917 18636 net.cpp:2270] res2a_branch2b_param_0(0.16) 
I0802 06:16:24.586920 18636 net.cpp:2270] res3a_branch2a_param_0(0.16) 
I0802 06:16:24.586921 18636 net.cpp:2270] res3a_branch2b_param_0(0.16) 
I0802 06:16:24.586923 18636 net.cpp:2270] res4a_branch2a_param_0(0.16) 
I0802 06:16:24.586925 18636 net.cpp:2270] res4a_branch2b_param_0(0.16) 
I0802 06:16:24.586926 18636 net.cpp:2270] res5a_branch2a_param_0(0.16) 
I0802 06:16:24.586928 18636 net.cpp:2270] res5a_branch2b_param_0(0.16) 
I0802 06:16:24.586930 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (375680/2.86678e+06) 0.131
I0802 06:16:24.586938 18636 solver.cpp:550] Iteration 36000, Testing net (#0)
I0802 06:16:44.273229 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.555117
I0802 06:16:44.273355 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.794233
I0802 06:16:44.273365 18636 solver.cpp:635]     Test net output #2: loss = 1.92847 (* 1 = 1.92847 loss)
I0802 06:16:44.273385 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6859s
I0802 06:16:44.420588 18661 solver.cpp:450] Finding and applying sparsity: 0.17
I0802 06:17:04.913697 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:17:04.915570 18636 solver.cpp:353] Iteration 36000 (1.84512 iter/s, 54.1969s/100 iter), loss = 1.51753
I0802 06:17:04.915586 18636 solver.cpp:375]     Train net output #0: loss = 1.57273 (* 1 = 1.57273 loss)
I0802 06:17:04.915591 18636 sgd_solver.cpp:136] Iteration 36000, lr = 0.00775, m = 0.9
I0802 06:17:19.329577 18636 solver.cpp:353] Iteration 36100 (6.93789 iter/s, 14.4136s/100 iter), loss = 1.50182
I0802 06:17:19.329650 18636 solver.cpp:375]     Train net output #0: loss = 1.53348 (* 1 = 1.53348 loss)
I0802 06:17:19.329658 18636 sgd_solver.cpp:136] Iteration 36100, lr = 0.00774375, m = 0.9
I0802 06:17:33.286272 18636 solver.cpp:353] Iteration 36200 (7.16522 iter/s, 13.9563s/100 iter), loss = 1.76154
I0802 06:17:33.286296 18636 solver.cpp:375]     Train net output #0: loss = 1.67475 (* 1 = 1.67475 loss)
I0802 06:17:33.286301 18636 sgd_solver.cpp:136] Iteration 36200, lr = 0.0077375, m = 0.9
I0802 06:17:47.245664 18636 solver.cpp:353] Iteration 36300 (7.16383 iter/s, 13.959s/100 iter), loss = 1.09926
I0802 06:17:47.245688 18636 solver.cpp:375]     Train net output #0: loss = 1.27584 (* 1 = 1.27584 loss)
I0802 06:17:47.245693 18636 sgd_solver.cpp:136] Iteration 36300, lr = 0.00773125, m = 0.9
I0802 06:18:01.193382 18636 solver.cpp:353] Iteration 36400 (7.16983 iter/s, 13.9473s/100 iter), loss = 1.26449
I0802 06:18:01.193449 18636 solver.cpp:375]     Train net output #0: loss = 1.66912 (* 1 = 1.66912 loss)
I0802 06:18:01.193456 18636 sgd_solver.cpp:136] Iteration 36400, lr = 0.007725, m = 0.9
I0802 06:18:15.328508 18636 solver.cpp:353] Iteration 36500 (7.07477 iter/s, 14.1347s/100 iter), loss = 1.61662
I0802 06:18:15.328578 18636 solver.cpp:375]     Train net output #0: loss = 1.53164 (* 1 = 1.53164 loss)
I0802 06:18:15.328598 18636 sgd_solver.cpp:136] Iteration 36500, lr = 0.00771875, m = 0.9
I0802 06:18:29.340258 18636 solver.cpp:353] Iteration 36600 (7.13706 iter/s, 14.0114s/100 iter), loss = 1.60855
I0802 06:18:29.340286 18636 solver.cpp:375]     Train net output #0: loss = 1.48098 (* 1 = 1.48098 loss)
I0802 06:18:29.340291 18636 sgd_solver.cpp:136] Iteration 36600, lr = 0.0077125, m = 0.9
I0802 06:18:43.297201 18636 solver.cpp:353] Iteration 36700 (7.16508 iter/s, 13.9566s/100 iter), loss = 1.49479
I0802 06:18:43.297263 18636 solver.cpp:375]     Train net output #0: loss = 1.31479 (* 1 = 1.31479 loss)
I0802 06:18:43.297268 18636 sgd_solver.cpp:136] Iteration 36700, lr = 0.00770625, m = 0.9
I0802 06:18:57.193707 18636 solver.cpp:353] Iteration 36800 (7.19625 iter/s, 13.8961s/100 iter), loss = 1.4898
I0802 06:18:57.193732 18636 solver.cpp:375]     Train net output #0: loss = 1.62973 (* 1 = 1.62973 loss)
I0802 06:18:57.193737 18636 sgd_solver.cpp:136] Iteration 36800, lr = 0.0077, m = 0.9
I0802 06:19:11.067134 18636 solver.cpp:353] Iteration 36900 (7.20822 iter/s, 13.8731s/100 iter), loss = 1.21016
I0802 06:19:11.067162 18636 solver.cpp:375]     Train net output #0: loss = 1.23126 (* 1 = 1.23126 loss)
I0802 06:19:11.067167 18636 sgd_solver.cpp:136] Iteration 36900, lr = 0.00769375, m = 0.9
I0802 06:19:24.965551 18636 solver.cpp:404] Sparsity after update:
I0802 06:19:24.977135 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:19:24.977183 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:19:24.977205 18636 net.cpp:2270] conv1b_param_0(0.0833) 
I0802 06:19:24.977218 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:19:24.977231 18636 net.cpp:2270] res2a_branch2a_param_0(0.167) 
I0802 06:19:24.977246 18636 net.cpp:2270] res2a_branch2b_param_0(0.167) 
I0802 06:19:24.977258 18636 net.cpp:2270] res3a_branch2a_param_0(0.168) 
I0802 06:19:24.977270 18636 net.cpp:2270] res3a_branch2b_param_0(0.167) 
I0802 06:19:24.977283 18636 net.cpp:2270] res4a_branch2a_param_0(0.169) 
I0802 06:19:24.977298 18636 net.cpp:2270] res4a_branch2b_param_0(0.168) 
I0802 06:19:24.977311 18636 net.cpp:2270] res5a_branch2a_param_0(0.17) 
I0802 06:19:24.977324 18636 net.cpp:2270] res5a_branch2b_param_0(0.169) 
I0802 06:19:24.977336 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (398286/2.86678e+06) 0.139
I0802 06:19:25.106381 18661 solver.cpp:450] Finding and applying sparsity: 0.18
I0802 06:19:45.968976 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:19:45.971139 18636 solver.cpp:353] Iteration 37000 (2.86508 iter/s, 34.9031s/100 iter), loss = 1.26192
I0802 06:19:45.971158 18636 solver.cpp:375]     Train net output #0: loss = 1.16363 (* 1 = 1.16363 loss)
I0802 06:19:45.971163 18636 sgd_solver.cpp:136] Iteration 37000, lr = 0.0076875, m = 0.9
I0802 06:20:00.393435 18636 solver.cpp:353] Iteration 37100 (6.9339 iter/s, 14.4219s/100 iter), loss = 1.05397
I0802 06:20:00.393489 18636 solver.cpp:375]     Train net output #0: loss = 0.835889 (* 1 = 0.835889 loss)
I0802 06:20:00.393496 18636 sgd_solver.cpp:136] Iteration 37100, lr = 0.00768125, m = 0.9
I0802 06:20:14.286320 18636 solver.cpp:353] Iteration 37200 (7.19813 iter/s, 13.8925s/100 iter), loss = 1.8707
I0802 06:20:14.286346 18636 solver.cpp:375]     Train net output #0: loss = 1.66551 (* 1 = 1.66551 loss)
I0802 06:20:14.286350 18636 sgd_solver.cpp:136] Iteration 37200, lr = 0.007675, m = 0.9
I0802 06:20:28.226047 18636 solver.cpp:353] Iteration 37300 (7.17394 iter/s, 13.9393s/100 iter), loss = 1.72135
I0802 06:20:28.226070 18636 solver.cpp:375]     Train net output #0: loss = 1.74327 (* 1 = 1.74327 loss)
I0802 06:20:28.226074 18636 sgd_solver.cpp:136] Iteration 37300, lr = 0.00766875, m = 0.9
I0802 06:20:42.150656 18636 solver.cpp:353] Iteration 37400 (7.18173 iter/s, 13.9242s/100 iter), loss = 1.71549
I0802 06:20:42.150756 18636 solver.cpp:375]     Train net output #0: loss = 1.71501 (* 1 = 1.71501 loss)
I0802 06:20:42.150763 18636 sgd_solver.cpp:136] Iteration 37400, lr = 0.0076625, m = 0.9
I0802 06:20:56.064934 18636 solver.cpp:353] Iteration 37500 (7.18706 iter/s, 13.9139s/100 iter), loss = 1.6
I0802 06:20:56.064959 18636 solver.cpp:375]     Train net output #0: loss = 1.995 (* 1 = 1.995 loss)
I0802 06:20:56.064962 18636 sgd_solver.cpp:136] Iteration 37500, lr = 0.00765625, m = 0.9
I0802 06:21:10.059826 18636 solver.cpp:353] Iteration 37600 (7.14566 iter/s, 13.9945s/100 iter), loss = 1.39218
I0802 06:21:10.059876 18636 solver.cpp:375]     Train net output #0: loss = 1.61101 (* 1 = 1.61101 loss)
I0802 06:21:10.059888 18636 sgd_solver.cpp:136] Iteration 37600, lr = 0.00765, m = 0.9
I0802 06:21:23.919587 18636 solver.cpp:353] Iteration 37700 (7.21533 iter/s, 13.8594s/100 iter), loss = 1.57623
I0802 06:21:23.919646 18636 solver.cpp:375]     Train net output #0: loss = 1.2753 (* 1 = 1.2753 loss)
I0802 06:21:23.919651 18636 sgd_solver.cpp:136] Iteration 37700, lr = 0.00764375, m = 0.9
I0802 06:21:37.846767 18636 solver.cpp:353] Iteration 37800 (7.1804 iter/s, 13.9268s/100 iter), loss = 1.60018
I0802 06:21:37.846797 18636 solver.cpp:375]     Train net output #0: loss = 1.40636 (* 1 = 1.40636 loss)
I0802 06:21:37.846803 18636 sgd_solver.cpp:136] Iteration 37800, lr = 0.0076375, m = 0.9
I0802 06:21:51.780758 18636 solver.cpp:353] Iteration 37900 (7.17689 iter/s, 13.9336s/100 iter), loss = 1.53046
I0802 06:21:51.780783 18636 solver.cpp:375]     Train net output #0: loss = 2.12822 (* 1 = 2.12822 loss)
I0802 06:21:51.780787 18636 sgd_solver.cpp:136] Iteration 37900, lr = 0.00763125, m = 0.9
I0802 06:22:05.612592 18636 solver.cpp:404] Sparsity after update:
I0802 06:22:05.616559 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:22:05.616585 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:22:05.616601 18636 net.cpp:2270] conv1b_param_0(0.0833) 
I0802 06:22:05.616611 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:22:05.616619 18636 net.cpp:2270] res2a_branch2a_param_0(0.177) 
I0802 06:22:05.616628 18636 net.cpp:2270] res2a_branch2b_param_0(0.174) 
I0802 06:22:05.616637 18636 net.cpp:2270] res3a_branch2a_param_0(0.179) 
I0802 06:22:05.616647 18636 net.cpp:2270] res3a_branch2b_param_0(0.177) 
I0802 06:22:05.616654 18636 net.cpp:2270] res4a_branch2a_param_0(0.18) 
I0802 06:22:05.616663 18636 net.cpp:2270] res4a_branch2b_param_0(0.179) 
I0802 06:22:05.616672 18636 net.cpp:2270] res5a_branch2a_param_0(0.18) 
I0802 06:22:05.616683 18636 net.cpp:2270] res5a_branch2b_param_0(0.18) 
I0802 06:22:05.616691 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (422239/2.86678e+06) 0.147
I0802 06:22:05.616708 18636 solver.cpp:550] Iteration 38000, Testing net (#0)
I0802 06:22:25.381539 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.552588
I0802 06:22:25.381563 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.791351
I0802 06:22:25.381570 18636 solver.cpp:635]     Test net output #2: loss = 1.98253 (* 1 = 1.98253 loss)
I0802 06:22:25.381592 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7644s
I0802 06:22:25.518003 18661 solver.cpp:450] Finding and applying sparsity: 0.19
I0802 06:22:46.400144 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:22:46.402097 18636 solver.cpp:353] Iteration 38000 (1.83084 iter/s, 54.6199s/100 iter), loss = 1.69205
I0802 06:22:46.402117 18636 solver.cpp:375]     Train net output #0: loss = 1.79909 (* 1 = 1.79909 loss)
I0802 06:22:46.402122 18636 sgd_solver.cpp:136] Iteration 38000, lr = 0.007625, m = 0.9
I0802 06:23:00.731480 18636 solver.cpp:353] Iteration 38100 (6.97886 iter/s, 14.329s/100 iter), loss = 1.80046
I0802 06:23:00.731506 18636 solver.cpp:375]     Train net output #0: loss = 2.05708 (* 1 = 2.05708 loss)
I0802 06:23:00.731510 18636 sgd_solver.cpp:136] Iteration 38100, lr = 0.00761875, m = 0.9
I0802 06:23:14.658001 18636 solver.cpp:353] Iteration 38200 (7.18074 iter/s, 13.9261s/100 iter), loss = 1.21661
I0802 06:23:14.658028 18636 solver.cpp:375]     Train net output #0: loss = 1.42619 (* 1 = 1.42619 loss)
I0802 06:23:14.658035 18636 sgd_solver.cpp:136] Iteration 38200, lr = 0.0076125, m = 0.9
I0802 06:23:28.583777 18636 solver.cpp:353] Iteration 38300 (7.18112 iter/s, 13.9254s/100 iter), loss = 1.25251
I0802 06:23:28.583835 18636 solver.cpp:375]     Train net output #0: loss = 1.37285 (* 1 = 1.37285 loss)
I0802 06:23:28.583842 18636 sgd_solver.cpp:136] Iteration 38300, lr = 0.00760625, m = 0.9
I0802 06:23:42.530740 18636 solver.cpp:353] Iteration 38400 (7.17022 iter/s, 13.9466s/100 iter), loss = 1.25288
I0802 06:23:42.530771 18636 solver.cpp:375]     Train net output #0: loss = 1.24914 (* 1 = 1.24914 loss)
I0802 06:23:42.530776 18636 sgd_solver.cpp:136] Iteration 38400, lr = 0.0076, m = 0.9
I0802 06:23:56.428102 18636 solver.cpp:353] Iteration 38500 (7.19581 iter/s, 13.897s/100 iter), loss = 1.42903
I0802 06:23:56.428128 18636 solver.cpp:375]     Train net output #0: loss = 1.47603 (* 1 = 1.47603 loss)
I0802 06:23:56.428131 18636 sgd_solver.cpp:136] Iteration 38500, lr = 0.00759375, m = 0.9
I0802 06:24:10.403116 18636 solver.cpp:353] Iteration 38600 (7.15582 iter/s, 13.9746s/100 iter), loss = 1.2294
I0802 06:24:10.403229 18636 solver.cpp:375]     Train net output #0: loss = 1.0918 (* 1 = 1.0918 loss)
I0802 06:24:10.403244 18636 sgd_solver.cpp:136] Iteration 38600, lr = 0.0075875, m = 0.9
I0802 06:24:24.326005 18636 solver.cpp:353] Iteration 38700 (7.18261 iter/s, 13.9225s/100 iter), loss = 1.25299
I0802 06:24:24.326031 18636 solver.cpp:375]     Train net output #0: loss = 1.15782 (* 1 = 1.15782 loss)
I0802 06:24:24.326037 18636 sgd_solver.cpp:136] Iteration 38700, lr = 0.00758125, m = 0.9
I0802 06:24:38.258417 18636 solver.cpp:353] Iteration 38800 (7.1777 iter/s, 13.932s/100 iter), loss = 1.20266
I0802 06:24:38.258519 18636 solver.cpp:375]     Train net output #0: loss = 1.23225 (* 1 = 1.23225 loss)
I0802 06:24:38.258541 18636 sgd_solver.cpp:136] Iteration 38800, lr = 0.007575, m = 0.9
I0802 06:24:52.170344 18636 solver.cpp:353] Iteration 38900 (7.18827 iter/s, 13.9115s/100 iter), loss = 1.60019
I0802 06:24:52.170416 18636 solver.cpp:375]     Train net output #0: loss = 1.53797 (* 1 = 1.53797 loss)
I0802 06:24:52.170423 18636 sgd_solver.cpp:136] Iteration 38900, lr = 0.00756875, m = 0.9
I0802 06:25:05.944622 18636 solver.cpp:404] Sparsity after update:
I0802 06:25:05.955860 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:25:05.955878 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:25:05.955888 18636 net.cpp:2270] conv1b_param_0(0.0903) 
I0802 06:25:05.955891 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:25:05.955894 18636 net.cpp:2270] res2a_branch2a_param_0(0.188) 
I0802 06:25:05.955899 18636 net.cpp:2270] res2a_branch2b_param_0(0.188) 
I0802 06:25:05.955904 18636 net.cpp:2270] res3a_branch2a_param_0(0.189) 
I0802 06:25:05.955907 18636 net.cpp:2270] res3a_branch2b_param_0(0.188) 
I0802 06:25:05.955912 18636 net.cpp:2270] res4a_branch2a_param_0(0.189) 
I0802 06:25:05.955915 18636 net.cpp:2270] res4a_branch2b_param_0(0.189) 
I0802 06:25:05.955920 18636 net.cpp:2270] res5a_branch2a_param_0(0.19) 
I0802 06:25:05.955924 18636 net.cpp:2270] res5a_branch2b_param_0(0.189) 
I0802 06:25:05.955927 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (445521/2.86678e+06) 0.155
I0802 06:25:06.100692 18661 solver.cpp:450] Finding and applying sparsity: 0.2
I0802 06:25:27.137229 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:25:27.139153 18636 solver.cpp:353] Iteration 39000 (2.85977 iter/s, 34.9679s/100 iter), loss = 1.27791
I0802 06:25:27.139178 18636 solver.cpp:375]     Train net output #0: loss = 1.22092 (* 1 = 1.22092 loss)
I0802 06:25:27.139188 18636 sgd_solver.cpp:136] Iteration 39000, lr = 0.0075625, m = 0.9
I0802 06:25:41.602329 18636 solver.cpp:353] Iteration 39100 (6.9143 iter/s, 14.4628s/100 iter), loss = 1.598
I0802 06:25:41.602355 18636 solver.cpp:375]     Train net output #0: loss = 1.65378 (* 1 = 1.65378 loss)
I0802 06:25:41.602360 18636 sgd_solver.cpp:136] Iteration 39100, lr = 0.00755625, m = 0.9
I0802 06:25:55.517410 18636 solver.cpp:353] Iteration 39200 (7.18665 iter/s, 13.9147s/100 iter), loss = 1.31253
I0802 06:25:55.517449 18636 solver.cpp:375]     Train net output #0: loss = 1.27237 (* 1 = 1.27237 loss)
I0802 06:25:55.517457 18636 sgd_solver.cpp:136] Iteration 39200, lr = 0.00755, m = 0.9
I0802 06:26:09.456235 18636 solver.cpp:353] Iteration 39300 (7.1744 iter/s, 13.9385s/100 iter), loss = 1.72936
I0802 06:26:09.456323 18636 solver.cpp:375]     Train net output #0: loss = 1.60916 (* 1 = 1.60916 loss)
I0802 06:26:09.456333 18636 sgd_solver.cpp:136] Iteration 39300, lr = 0.00754375, m = 0.9
I0802 06:26:23.416247 18636 solver.cpp:353] Iteration 39400 (7.16351 iter/s, 13.9596s/100 iter), loss = 1.26201
I0802 06:26:23.416275 18636 solver.cpp:375]     Train net output #0: loss = 1.18686 (* 1 = 1.18686 loss)
I0802 06:26:23.416280 18636 sgd_solver.cpp:136] Iteration 39400, lr = 0.0075375, m = 0.9
I0802 06:26:37.319764 18636 solver.cpp:353] Iteration 39500 (7.19262 iter/s, 13.9031s/100 iter), loss = 1.46721
I0802 06:26:37.319803 18636 solver.cpp:375]     Train net output #0: loss = 1.33026 (* 1 = 1.33026 loss)
I0802 06:26:37.319855 18636 sgd_solver.cpp:136] Iteration 39500, lr = 0.00753125, m = 0.9
I0802 06:26:51.252980 18636 solver.cpp:353] Iteration 39600 (7.17729 iter/s, 13.9328s/100 iter), loss = 1.27651
I0802 06:26:51.253078 18636 solver.cpp:375]     Train net output #0: loss = 1.35573 (* 1 = 1.35573 loss)
I0802 06:26:51.253087 18636 sgd_solver.cpp:136] Iteration 39600, lr = 0.007525, m = 0.9
I0802 06:27:05.245072 18636 solver.cpp:353] Iteration 39700 (7.14709 iter/s, 13.9917s/100 iter), loss = 1.70815
I0802 06:27:05.245102 18636 solver.cpp:375]     Train net output #0: loss = 1.46875 (* 1 = 1.46875 loss)
I0802 06:27:05.245108 18636 sgd_solver.cpp:136] Iteration 39700, lr = 0.00751875, m = 0.9
I0802 06:27:19.091055 18636 solver.cpp:353] Iteration 39800 (7.22251 iter/s, 13.8456s/100 iter), loss = 1.44988
I0802 06:27:19.091116 18636 solver.cpp:375]     Train net output #0: loss = 1.33867 (* 1 = 1.33867 loss)
I0802 06:27:19.091131 18636 sgd_solver.cpp:136] Iteration 39800, lr = 0.0075125, m = 0.9
I0802 06:27:33.081580 18636 solver.cpp:353] Iteration 39900 (7.14789 iter/s, 13.9901s/100 iter), loss = 1.47849
I0802 06:27:33.081645 18636 solver.cpp:375]     Train net output #0: loss = 1.57575 (* 1 = 1.57575 loss)
I0802 06:27:33.081652 18636 sgd_solver.cpp:136] Iteration 39900, lr = 0.00750625, m = 0.9
I0802 06:27:46.918226 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_40000.caffemodel
I0802 06:27:47.127272 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_40000.solverstate
I0802 06:27:47.133810 18636 solver.cpp:404] Sparsity after update:
I0802 06:27:47.135515 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:27:47.135679 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:27:47.135779 18636 net.cpp:2270] conv1b_param_0(0.0972) 
I0802 06:27:47.135867 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:27:47.135954 18636 net.cpp:2270] res2a_branch2a_param_0(0.198) 
I0802 06:27:47.136047 18636 net.cpp:2270] res2a_branch2b_param_0(0.194) 
I0802 06:27:47.136137 18636 net.cpp:2270] res3a_branch2a_param_0(0.2) 
I0802 06:27:47.136236 18636 net.cpp:2270] res3a_branch2b_param_0(0.198) 
I0802 06:27:47.136330 18636 net.cpp:2270] res4a_branch2a_param_0(0.2) 
I0802 06:27:47.136423 18636 net.cpp:2270] res4a_branch2b_param_0(0.2) 
I0802 06:27:47.138080 18636 net.cpp:2270] res5a_branch2a_param_0(0.2) 
I0802 06:27:47.138100 18636 net.cpp:2270] res5a_branch2b_param_0(0.2) 
I0802 06:27:47.138105 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (469468/2.86678e+06) 0.164
I0802 06:27:47.138140 18636 solver.cpp:550] Iteration 40000, Testing net (#0)
I0802 06:28:01.935674 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:28:06.800062 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.560177
I0802 06:28:06.800124 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.796115
I0802 06:28:06.800132 18636 solver.cpp:635]     Test net output #2: loss = 1.9378 (* 1 = 1.9378 loss)
I0802 06:28:06.800149 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6615s
I0802 06:28:06.946436 18661 solver.cpp:450] Finding and applying sparsity: 0.21
I0802 06:28:27.992902 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:28:27.994789 18636 solver.cpp:353] Iteration 40000 (1.8211 iter/s, 54.9117s/100 iter), loss = 1.63003
I0802 06:28:27.994812 18636 solver.cpp:375]     Train net output #0: loss = 1.55091 (* 1 = 1.55091 loss)
I0802 06:28:27.994820 18636 sgd_solver.cpp:136] Iteration 40000, lr = 0.0075, m = 0.9
I0802 06:28:42.409591 18636 solver.cpp:353] Iteration 40100 (6.9375 iter/s, 14.4144s/100 iter), loss = 1.71002
I0802 06:28:42.409649 18636 solver.cpp:375]     Train net output #0: loss = 1.50388 (* 1 = 1.50388 loss)
I0802 06:28:42.409656 18636 sgd_solver.cpp:136] Iteration 40100, lr = 0.00749375, m = 0.9
I0802 06:28:56.414604 18636 solver.cpp:353] Iteration 40200 (7.1405 iter/s, 14.0046s/100 iter), loss = 1.20617
I0802 06:28:56.414630 18636 solver.cpp:375]     Train net output #0: loss = 1.23194 (* 1 = 1.23194 loss)
I0802 06:28:56.414636 18636 sgd_solver.cpp:136] Iteration 40200, lr = 0.0074875, m = 0.9
I0802 06:29:10.462944 18636 solver.cpp:353] Iteration 40300 (7.11847 iter/s, 14.048s/100 iter), loss = 1.54082
I0802 06:29:10.462975 18636 solver.cpp:375]     Train net output #0: loss = 1.53425 (* 1 = 1.53425 loss)
I0802 06:29:10.462980 18636 sgd_solver.cpp:136] Iteration 40300, lr = 0.00748125, m = 0.9
I0802 06:29:24.406249 18636 solver.cpp:353] Iteration 40400 (7.1721 iter/s, 13.9429s/100 iter), loss = 1.21038
I0802 06:29:24.406561 18636 solver.cpp:375]     Train net output #0: loss = 1.28717 (* 1 = 1.28717 loss)
I0802 06:29:24.406568 18636 sgd_solver.cpp:136] Iteration 40400, lr = 0.007475, m = 0.9
I0802 06:29:38.334887 18636 solver.cpp:353] Iteration 40500 (7.17965 iter/s, 13.9283s/100 iter), loss = 1.48942
I0802 06:29:38.334914 18636 solver.cpp:375]     Train net output #0: loss = 1.36205 (* 1 = 1.36205 loss)
I0802 06:29:38.334921 18636 sgd_solver.cpp:136] Iteration 40500, lr = 0.00746875, m = 0.9
I0802 06:29:52.353590 18636 solver.cpp:353] Iteration 40600 (7.13352 iter/s, 14.0183s/100 iter), loss = 1.59644
I0802 06:29:52.353689 18636 solver.cpp:375]     Train net output #0: loss = 1.60522 (* 1 = 1.60522 loss)
I0802 06:29:52.353710 18636 sgd_solver.cpp:136] Iteration 40600, lr = 0.0074625, m = 0.9
I0802 06:30:06.332756 18636 solver.cpp:353] Iteration 40700 (7.1537 iter/s, 13.9788s/100 iter), loss = 0.950537
I0802 06:30:06.332834 18636 solver.cpp:375]     Train net output #0: loss = 0.931537 (* 1 = 0.931537 loss)
I0802 06:30:06.332852 18636 sgd_solver.cpp:136] Iteration 40700, lr = 0.00745625, m = 0.9
I0802 06:30:20.253262 18636 solver.cpp:353] Iteration 40800 (7.18384 iter/s, 13.9201s/100 iter), loss = 1.60472
I0802 06:30:20.253288 18636 solver.cpp:375]     Train net output #0: loss = 1.59545 (* 1 = 1.59545 loss)
I0802 06:30:20.253293 18636 sgd_solver.cpp:136] Iteration 40800, lr = 0.00745, m = 0.9
I0802 06:30:34.194393 18636 solver.cpp:353] Iteration 40900 (7.17321 iter/s, 13.9408s/100 iter), loss = 1.31298
I0802 06:30:34.194422 18636 solver.cpp:375]     Train net output #0: loss = 1.23913 (* 1 = 1.23913 loss)
I0802 06:30:34.194425 18636 sgd_solver.cpp:136] Iteration 40900, lr = 0.00744375, m = 0.9
I0802 06:30:47.880269 18636 solver.cpp:404] Sparsity after update:
I0802 06:30:47.890738 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:30:47.890750 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:30:47.890758 18636 net.cpp:2270] conv1b_param_0(0.104) 
I0802 06:30:47.890759 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:30:47.890761 18636 net.cpp:2270] res2a_branch2a_param_0(0.208) 
I0802 06:30:47.890763 18636 net.cpp:2270] res2a_branch2b_param_0(0.208) 
I0802 06:30:47.890765 18636 net.cpp:2270] res3a_branch2a_param_0(0.208) 
I0802 06:30:47.890768 18636 net.cpp:2270] res3a_branch2b_param_0(0.208) 
I0802 06:30:47.890769 18636 net.cpp:2270] res4a_branch2a_param_0(0.209) 
I0802 06:30:47.890771 18636 net.cpp:2270] res4a_branch2b_param_0(0.208) 
I0802 06:30:47.890774 18636 net.cpp:2270] res5a_branch2a_param_0(0.21) 
I0802 06:30:47.890777 18636 net.cpp:2270] res5a_branch2b_param_0(0.209) 
I0802 06:30:47.890781 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (492322/2.86678e+06) 0.172
I0802 06:30:48.029168 18661 solver.cpp:450] Finding and applying sparsity: 0.22
I0802 06:31:09.523921 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:31:09.525807 18636 solver.cpp:353] Iteration 41000 (2.83042 iter/s, 35.3305s/100 iter), loss = 0.992093
I0802 06:31:09.525825 18636 solver.cpp:375]     Train net output #0: loss = 1.14669 (* 1 = 1.14669 loss)
I0802 06:31:09.525830 18636 sgd_solver.cpp:136] Iteration 41000, lr = 0.0074375, m = 0.9
I0802 06:31:23.853233 18636 solver.cpp:353] Iteration 41100 (6.97981 iter/s, 14.327s/100 iter), loss = 1.90873
I0802 06:31:23.853332 18636 solver.cpp:375]     Train net output #0: loss = 1.75004 (* 1 = 1.75004 loss)
I0802 06:31:23.853348 18636 sgd_solver.cpp:136] Iteration 41100, lr = 0.00743125, m = 0.9
I0802 06:31:37.727987 18636 solver.cpp:353] Iteration 41200 (7.20753 iter/s, 13.8744s/100 iter), loss = 1.67371
I0802 06:31:37.728016 18636 solver.cpp:375]     Train net output #0: loss = 1.46641 (* 1 = 1.46641 loss)
I0802 06:31:37.728022 18636 sgd_solver.cpp:136] Iteration 41200, lr = 0.007425, m = 0.9
I0802 06:31:51.609165 18636 solver.cpp:353] Iteration 41300 (7.2042 iter/s, 13.8808s/100 iter), loss = 1.23522
I0802 06:31:51.609192 18636 solver.cpp:375]     Train net output #0: loss = 1.421 (* 1 = 1.421 loss)
I0802 06:31:51.609196 18636 sgd_solver.cpp:136] Iteration 41300, lr = 0.00741875, m = 0.9
I0802 06:32:05.446794 18636 solver.cpp:353] Iteration 41400 (7.22687 iter/s, 13.8373s/100 iter), loss = 1.44284
I0802 06:32:05.446856 18636 solver.cpp:375]     Train net output #0: loss = 1.37251 (* 1 = 1.37251 loss)
I0802 06:32:05.446863 18636 sgd_solver.cpp:136] Iteration 41400, lr = 0.0074125, m = 0.9
I0802 06:32:19.324635 18636 solver.cpp:353] Iteration 41500 (7.20593 iter/s, 13.8775s/100 iter), loss = 1.39509
I0802 06:32:19.324662 18636 solver.cpp:375]     Train net output #0: loss = 1.34528 (* 1 = 1.34528 loss)
I0802 06:32:19.324707 18636 sgd_solver.cpp:136] Iteration 41500, lr = 0.00740625, m = 0.9
I0802 06:32:33.161878 18636 solver.cpp:353] Iteration 41600 (7.22707 iter/s, 13.8369s/100 iter), loss = 1.61164
I0802 06:32:33.161908 18636 solver.cpp:375]     Train net output #0: loss = 1.16941 (* 1 = 1.16941 loss)
I0802 06:32:33.161914 18636 sgd_solver.cpp:136] Iteration 41600, lr = 0.0074, m = 0.9
I0802 06:32:47.023342 18636 solver.cpp:353] Iteration 41700 (7.21444 iter/s, 13.8611s/100 iter), loss = 1.30632
I0802 06:32:47.023402 18636 solver.cpp:375]     Train net output #0: loss = 1.3031 (* 1 = 1.3031 loss)
I0802 06:32:47.023408 18636 sgd_solver.cpp:136] Iteration 41700, lr = 0.00739375, m = 0.9
I0802 06:33:00.822670 18636 solver.cpp:353] Iteration 41800 (7.24693 iter/s, 13.799s/100 iter), loss = 1.58325
I0802 06:33:00.822700 18636 solver.cpp:375]     Train net output #0: loss = 1.396 (* 1 = 1.396 loss)
I0802 06:33:00.822705 18636 sgd_solver.cpp:136] Iteration 41800, lr = 0.0073875, m = 0.9
I0802 06:33:14.724967 18636 solver.cpp:353] Iteration 41900 (7.19325 iter/s, 13.9019s/100 iter), loss = 1.78261
I0802 06:33:14.724993 18636 solver.cpp:375]     Train net output #0: loss = 2.19002 (* 1 = 2.19002 loss)
I0802 06:33:14.724999 18636 sgd_solver.cpp:136] Iteration 41900, lr = 0.00738125, m = 0.9
I0802 06:33:28.467797 18636 solver.cpp:404] Sparsity after update:
I0802 06:33:28.473062 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:33:28.473076 18636 net.cpp:2270] conv1a_param_0(0.106) 
I0802 06:33:28.473085 18636 net.cpp:2270] conv1b_param_0(0.104) 
I0802 06:33:28.473088 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:33:28.473093 18636 net.cpp:2270] res2a_branch2a_param_0(0.219) 
I0802 06:33:28.473101 18636 net.cpp:2270] res2a_branch2b_param_0(0.215) 
I0802 06:33:28.473104 18636 net.cpp:2270] res3a_branch2a_param_0(0.219) 
I0802 06:33:28.473109 18636 net.cpp:2270] res3a_branch2b_param_0(0.219) 
I0802 06:33:28.473112 18636 net.cpp:2270] res4a_branch2a_param_0(0.22) 
I0802 06:33:28.473116 18636 net.cpp:2270] res4a_branch2b_param_0(0.219) 
I0802 06:33:28.473120 18636 net.cpp:2270] res5a_branch2a_param_0(0.22) 
I0802 06:33:28.473124 18636 net.cpp:2270] res5a_branch2b_param_0(0.22) 
I0802 06:33:28.473129 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (516297/2.86678e+06) 0.18
I0802 06:33:28.473140 18636 solver.cpp:550] Iteration 42000, Testing net (#0)
I0802 06:33:47.721364 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.565941
I0802 06:33:47.721385 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.796527
I0802 06:33:47.721390 18636 solver.cpp:635]     Test net output #2: loss = 1.9225 (* 1 = 1.9225 loss)
I0802 06:33:47.721451 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2478s
I0802 06:33:47.859217 18661 solver.cpp:450] Finding and applying sparsity: 0.23
I0802 06:34:09.007230 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:34:09.009160 18636 solver.cpp:353] Iteration 42000 (1.84221 iter/s, 54.2827s/100 iter), loss = 1.28439
I0802 06:34:09.009179 18636 solver.cpp:375]     Train net output #0: loss = 1.18323 (* 1 = 1.18323 loss)
I0802 06:34:09.009186 18636 sgd_solver.cpp:136] Iteration 42000, lr = 0.007375, m = 0.9
I0802 06:34:23.432950 18636 solver.cpp:353] Iteration 42100 (6.93318 iter/s, 14.4234s/100 iter), loss = 1.25685
I0802 06:34:23.432982 18636 solver.cpp:375]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0802 06:34:23.432988 18636 sgd_solver.cpp:136] Iteration 42100, lr = 0.00736875, m = 0.9
I0802 06:34:37.325703 18636 solver.cpp:353] Iteration 42200 (7.19819 iter/s, 13.8924s/100 iter), loss = 1.86303
I0802 06:34:37.325757 18636 solver.cpp:375]     Train net output #0: loss = 1.73459 (* 1 = 1.73459 loss)
I0802 06:34:37.325770 18636 sgd_solver.cpp:136] Iteration 42200, lr = 0.0073625, m = 0.9
I0802 06:34:51.245548 18636 solver.cpp:353] Iteration 42300 (7.18418 iter/s, 13.9195s/100 iter), loss = 1.18419
I0802 06:34:51.245607 18636 solver.cpp:375]     Train net output #0: loss = 1.33185 (* 1 = 1.33185 loss)
I0802 06:34:51.245611 18636 sgd_solver.cpp:136] Iteration 42300, lr = 0.00735625, m = 0.9
I0802 06:35:05.206889 18636 solver.cpp:353] Iteration 42400 (7.16283 iter/s, 13.961s/100 iter), loss = 1.68184
I0802 06:35:05.206918 18636 solver.cpp:375]     Train net output #0: loss = 1.59306 (* 1 = 1.59306 loss)
I0802 06:35:05.206923 18636 sgd_solver.cpp:136] Iteration 42400, lr = 0.00735, m = 0.9
I0802 06:35:19.135705 18636 solver.cpp:353] Iteration 42500 (7.17956 iter/s, 13.9284s/100 iter), loss = 1.17915
I0802 06:35:19.135735 18636 solver.cpp:375]     Train net output #0: loss = 0.95866 (* 1 = 0.95866 loss)
I0802 06:35:19.135740 18636 sgd_solver.cpp:136] Iteration 42500, lr = 0.00734375, m = 0.9
I0802 06:35:33.048720 18636 solver.cpp:353] Iteration 42600 (7.18771 iter/s, 13.9126s/100 iter), loss = 1.30587
I0802 06:35:33.048775 18636 solver.cpp:375]     Train net output #0: loss = 1.0482 (* 1 = 1.0482 loss)
I0802 06:35:33.048779 18636 sgd_solver.cpp:136] Iteration 42600, lr = 0.0073375, m = 0.9
I0802 06:35:47.022706 18636 solver.cpp:353] Iteration 42700 (7.15635 iter/s, 13.9736s/100 iter), loss = 1.58489
I0802 06:35:47.022732 18636 solver.cpp:375]     Train net output #0: loss = 1.62362 (* 1 = 1.62362 loss)
I0802 06:35:47.022737 18636 sgd_solver.cpp:136] Iteration 42700, lr = 0.00733125, m = 0.9
I0802 06:36:00.987190 18636 solver.cpp:353] Iteration 42800 (7.16122 iter/s, 13.9641s/100 iter), loss = 1.27826
I0802 06:36:00.987224 18636 solver.cpp:375]     Train net output #0: loss = 0.845746 (* 1 = 0.845746 loss)
I0802 06:36:00.987232 18636 sgd_solver.cpp:136] Iteration 42800, lr = 0.007325, m = 0.9
I0802 06:36:14.955454 18636 solver.cpp:353] Iteration 42900 (7.15928 iter/s, 13.9679s/100 iter), loss = 1.25878
I0802 06:36:14.955525 18636 solver.cpp:375]     Train net output #0: loss = 1.3283 (* 1 = 1.3283 loss)
I0802 06:36:14.955531 18636 sgd_solver.cpp:136] Iteration 42900, lr = 0.00731875, m = 0.9
I0802 06:36:28.790963 18636 solver.cpp:404] Sparsity after update:
I0802 06:36:28.802691 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:36:28.802703 18636 net.cpp:2270] conv1a_param_0(0.107) 
I0802 06:36:28.802711 18636 net.cpp:2270] conv1b_param_0(0.111) 
I0802 06:36:28.802713 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:36:28.802716 18636 net.cpp:2270] res2a_branch2a_param_0(0.229) 
I0802 06:36:28.802717 18636 net.cpp:2270] res2a_branch2b_param_0(0.229) 
I0802 06:36:28.802721 18636 net.cpp:2270] res3a_branch2a_param_0(0.229) 
I0802 06:36:28.802723 18636 net.cpp:2270] res3a_branch2b_param_0(0.229) 
I0802 06:36:28.802726 18636 net.cpp:2270] res4a_branch2a_param_0(0.229) 
I0802 06:36:28.802727 18636 net.cpp:2270] res4a_branch2b_param_0(0.229) 
I0802 06:36:28.802729 18636 net.cpp:2270] res5a_branch2a_param_0(0.23) 
I0802 06:36:28.802731 18636 net.cpp:2270] res5a_branch2b_param_0(0.229) 
I0802 06:36:28.802732 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (539552/2.86678e+06) 0.188
I0802 06:36:28.934412 18661 solver.cpp:450] Finding and applying sparsity: 0.24
I0802 06:36:50.518585 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:36:50.520534 18636 solver.cpp:353] Iteration 43000 (2.81182 iter/s, 35.5641s/100 iter), loss = 1.27689
I0802 06:36:50.520552 18636 solver.cpp:375]     Train net output #0: loss = 1.21047 (* 1 = 1.21047 loss)
I0802 06:36:50.520558 18636 sgd_solver.cpp:136] Iteration 43000, lr = 0.0073125, m = 0.9
I0802 06:37:04.926537 18636 solver.cpp:353] Iteration 43100 (6.94174 iter/s, 14.4056s/100 iter), loss = 1.03635
I0802 06:37:04.926636 18636 solver.cpp:375]     Train net output #0: loss = 1.204 (* 1 = 1.204 loss)
I0802 06:37:04.926661 18636 sgd_solver.cpp:136] Iteration 43100, lr = 0.00730625, m = 0.9
I0802 06:37:18.842052 18636 solver.cpp:353] Iteration 43200 (7.18642 iter/s, 13.9151s/100 iter), loss = 1.30922
I0802 06:37:18.842082 18636 solver.cpp:375]     Train net output #0: loss = 1.61254 (* 1 = 1.61254 loss)
I0802 06:37:18.842089 18636 sgd_solver.cpp:136] Iteration 43200, lr = 0.0073, m = 0.9
I0802 06:37:32.891185 18636 solver.cpp:353] Iteration 43300 (7.11807 iter/s, 14.0487s/100 iter), loss = 1.26509
I0802 06:37:32.891279 18636 solver.cpp:375]     Train net output #0: loss = 1.55621 (* 1 = 1.55621 loss)
I0802 06:37:32.891289 18636 sgd_solver.cpp:136] Iteration 43300, lr = 0.00729375, m = 0.9
I0802 06:37:46.772514 18636 solver.cpp:353] Iteration 43400 (7.20412 iter/s, 13.881s/100 iter), loss = 1.48852
I0802 06:37:46.772541 18636 solver.cpp:375]     Train net output #0: loss = 1.80188 (* 1 = 1.80188 loss)
I0802 06:37:46.772545 18636 sgd_solver.cpp:136] Iteration 43400, lr = 0.0072875, m = 0.9
I0802 06:38:00.719149 18636 solver.cpp:353] Iteration 43500 (7.17038 iter/s, 13.9463s/100 iter), loss = 1.30827
I0802 06:38:00.719179 18636 solver.cpp:375]     Train net output #0: loss = 1.36527 (* 1 = 1.36527 loss)
I0802 06:38:00.719185 18636 sgd_solver.cpp:136] Iteration 43500, lr = 0.00728125, m = 0.9
I0802 06:38:14.709920 18636 solver.cpp:353] Iteration 43600 (7.14776 iter/s, 13.9904s/100 iter), loss = 1.39245
I0802 06:38:14.712865 18636 solver.cpp:375]     Train net output #0: loss = 1.04971 (* 1 = 1.04971 loss)
I0802 06:38:14.712872 18636 sgd_solver.cpp:136] Iteration 43600, lr = 0.007275, m = 0.9
I0802 06:38:28.583206 18636 solver.cpp:353] Iteration 43700 (7.20829 iter/s, 13.8729s/100 iter), loss = 1.76581
I0802 06:38:28.583313 18636 solver.cpp:375]     Train net output #0: loss = 1.33426 (* 1 = 1.33426 loss)
I0802 06:38:28.583336 18636 sgd_solver.cpp:136] Iteration 43700, lr = 0.00726875, m = 0.9
I0802 06:38:42.498215 18636 solver.cpp:353] Iteration 43800 (7.18668 iter/s, 13.9146s/100 iter), loss = 1.59617
I0802 06:38:42.498288 18636 solver.cpp:375]     Train net output #0: loss = 1.95819 (* 1 = 1.95819 loss)
I0802 06:38:42.498308 18636 sgd_solver.cpp:136] Iteration 43800, lr = 0.0072625, m = 0.9
I0802 06:38:56.374387 18636 solver.cpp:353] Iteration 43900 (7.20679 iter/s, 13.8758s/100 iter), loss = 1.79397
I0802 06:38:56.374526 18636 solver.cpp:375]     Train net output #0: loss = 2.18008 (* 1 = 2.18008 loss)
I0802 06:38:56.374550 18636 sgd_solver.cpp:136] Iteration 43900, lr = 0.00725625, m = 0.9
I0802 06:39:10.116588 18636 solver.cpp:404] Sparsity after update:
I0802 06:39:10.121076 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:39:10.121088 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:39:10.121096 18636 net.cpp:2270] conv1b_param_0(0.118) 
I0802 06:39:10.121100 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:39:10.121105 18636 net.cpp:2270] res2a_branch2a_param_0(0.24) 
I0802 06:39:10.121109 18636 net.cpp:2270] res2a_branch2b_param_0(0.236) 
I0802 06:39:10.121112 18636 net.cpp:2270] res3a_branch2a_param_0(0.24) 
I0802 06:39:10.121115 18636 net.cpp:2270] res3a_branch2b_param_0(0.24) 
I0802 06:39:10.121117 18636 net.cpp:2270] res4a_branch2a_param_0(0.24) 
I0802 06:39:10.121120 18636 net.cpp:2270] res4a_branch2b_param_0(0.24) 
I0802 06:39:10.121124 18636 net.cpp:2270] res5a_branch2a_param_0(0.24) 
I0802 06:39:10.121126 18636 net.cpp:2270] res5a_branch2b_param_0(0.24) 
I0802 06:39:10.121130 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (563527/2.86678e+06) 0.197
I0802 06:39:10.121142 18636 solver.cpp:550] Iteration 44000, Testing net (#0)
I0802 06:39:29.524693 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.562294
I0802 06:39:29.524827 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.79788
I0802 06:39:29.524837 18636 solver.cpp:635]     Test net output #2: loss = 1.94508 (* 1 = 1.94508 loss)
I0802 06:39:29.524859 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4032s
I0802 06:39:29.682147 18661 solver.cpp:450] Finding and applying sparsity: 0.25
I0802 06:39:51.588835 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:39:51.590732 18636 solver.cpp:353] Iteration 44000 (1.81111 iter/s, 55.2149s/100 iter), loss = 1.46358
I0802 06:39:51.590750 18636 solver.cpp:375]     Train net output #0: loss = 1.61415 (* 1 = 1.61415 loss)
I0802 06:39:51.590755 18636 sgd_solver.cpp:136] Iteration 44000, lr = 0.00725, m = 0.9
I0802 06:40:05.990845 18636 solver.cpp:353] Iteration 44100 (6.94458 iter/s, 14.3997s/100 iter), loss = 1.216
I0802 06:40:05.990943 18636 solver.cpp:375]     Train net output #0: loss = 1.39276 (* 1 = 1.39276 loss)
I0802 06:40:05.990963 18636 sgd_solver.cpp:136] Iteration 44100, lr = 0.00724375, m = 0.9
I0802 06:40:19.838136 18636 solver.cpp:353] Iteration 44200 (7.22183 iter/s, 13.8469s/100 iter), loss = 1.01748
I0802 06:40:19.838167 18636 solver.cpp:375]     Train net output #0: loss = 1.11225 (* 1 = 1.11225 loss)
I0802 06:40:19.838173 18636 sgd_solver.cpp:136] Iteration 44200, lr = 0.0072375, m = 0.9
I0802 06:40:33.803078 18636 solver.cpp:353] Iteration 44300 (7.16098 iter/s, 13.9646s/100 iter), loss = 1.66549
I0802 06:40:33.803133 18636 solver.cpp:375]     Train net output #0: loss = 1.2116 (* 1 = 1.2116 loss)
I0802 06:40:33.803145 18636 sgd_solver.cpp:136] Iteration 44300, lr = 0.00723125, m = 0.9
I0802 06:40:47.661633 18636 solver.cpp:353] Iteration 44400 (7.21596 iter/s, 13.8582s/100 iter), loss = 1.56242
I0802 06:40:47.661742 18636 solver.cpp:375]     Train net output #0: loss = 1.87705 (* 1 = 1.87705 loss)
I0802 06:40:47.661749 18636 sgd_solver.cpp:136] Iteration 44400, lr = 0.007225, m = 0.9
I0802 06:41:01.575479 18636 solver.cpp:353] Iteration 44500 (7.18728 iter/s, 13.9135s/100 iter), loss = 1.39829
I0802 06:41:01.575574 18636 solver.cpp:375]     Train net output #0: loss = 1.17315 (* 1 = 1.17315 loss)
I0802 06:41:01.575587 18636 sgd_solver.cpp:136] Iteration 44500, lr = 0.00721875, m = 0.9
I0802 06:41:15.508016 18636 solver.cpp:353] Iteration 44600 (7.17764 iter/s, 13.9322s/100 iter), loss = 1.68973
I0802 06:41:15.508070 18636 solver.cpp:375]     Train net output #0: loss = 1.40314 (* 1 = 1.40314 loss)
I0802 06:41:15.508085 18636 sgd_solver.cpp:136] Iteration 44600, lr = 0.0072125, m = 0.9
I0802 06:41:27.982205 18597 data_reader.cpp:264] Starting prefetch of epoch 1
I0802 06:41:29.393496 18636 solver.cpp:353] Iteration 44700 (7.20196 iter/s, 13.8851s/100 iter), loss = 1.36495
I0802 06:41:29.393543 18636 solver.cpp:375]     Train net output #0: loss = 1.57697 (* 1 = 1.57697 loss)
I0802 06:41:29.393554 18636 sgd_solver.cpp:136] Iteration 44700, lr = 0.00720625, m = 0.9
I0802 06:41:43.324690 18636 solver.cpp:353] Iteration 44800 (7.17833 iter/s, 13.9308s/100 iter), loss = 1.53605
I0802 06:41:43.324717 18636 solver.cpp:375]     Train net output #0: loss = 1.87628 (* 1 = 1.87628 loss)
I0802 06:41:43.324723 18636 sgd_solver.cpp:136] Iteration 44800, lr = 0.0072, m = 0.9
I0802 06:41:57.215554 18636 solver.cpp:353] Iteration 44900 (7.19917 iter/s, 13.8905s/100 iter), loss = 1.27778
I0802 06:41:57.215580 18636 solver.cpp:375]     Train net output #0: loss = 1.67304 (* 1 = 1.67304 loss)
I0802 06:41:57.215584 18636 sgd_solver.cpp:136] Iteration 44900, lr = 0.00719375, m = 0.9
I0802 06:42:11.048933 18636 solver.cpp:404] Sparsity after update:
I0802 06:42:11.061384 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:42:11.061400 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:42:11.061410 18636 net.cpp:2270] conv1b_param_0(0.25) 
I0802 06:42:11.061414 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:42:11.061431 18636 net.cpp:2270] res2a_branch2a_param_0(0.25) 
I0802 06:42:11.061440 18636 net.cpp:2270] res2a_branch2b_param_0(0.25) 
I0802 06:42:11.061449 18636 net.cpp:2270] res3a_branch2a_param_0(0.25) 
I0802 06:42:11.061461 18636 net.cpp:2270] res3a_branch2b_param_0(0.25) 
I0802 06:42:11.061470 18636 net.cpp:2270] res4a_branch2a_param_0(0.25) 
I0802 06:42:11.061488 18636 net.cpp:2270] res4a_branch2b_param_0(0.25) 
I0802 06:42:11.061501 18636 net.cpp:2270] res5a_branch2a_param_0(0.25) 
I0802 06:42:11.061514 18636 net.cpp:2270] res5a_branch2b_param_0(0.25) 
I0802 06:42:11.061527 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (588349/2.86678e+06) 0.205
I0802 06:42:11.202025 18661 solver.cpp:450] Finding and applying sparsity: 0.26
I0802 06:42:32.753993 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:42:32.755877 18636 solver.cpp:353] Iteration 45000 (2.81378 iter/s, 35.5394s/100 iter), loss = 1.62799
I0802 06:42:32.755893 18636 solver.cpp:375]     Train net output #0: loss = 1.92437 (* 1 = 1.92437 loss)
I0802 06:42:32.755899 18636 sgd_solver.cpp:136] Iteration 45000, lr = 0.0071875, m = 0.9
I0802 06:42:47.250612 18636 solver.cpp:353] Iteration 45100 (6.89925 iter/s, 14.4943s/100 iter), loss = 1.63918
I0802 06:42:47.250674 18636 solver.cpp:375]     Train net output #0: loss = 1.90115 (* 1 = 1.90115 loss)
I0802 06:42:47.250680 18636 sgd_solver.cpp:136] Iteration 45100, lr = 0.00718125, m = 0.9
I0802 06:43:01.227965 18636 solver.cpp:353] Iteration 45200 (7.15463 iter/s, 13.977s/100 iter), loss = 1.42448
I0802 06:43:01.227993 18636 solver.cpp:375]     Train net output #0: loss = 1.12796 (* 1 = 1.12796 loss)
I0802 06:43:01.227999 18636 sgd_solver.cpp:136] Iteration 45200, lr = 0.007175, m = 0.9
I0802 06:43:15.182236 18636 solver.cpp:353] Iteration 45300 (7.16646 iter/s, 13.9539s/100 iter), loss = 1.50197
I0802 06:43:15.182265 18636 solver.cpp:375]     Train net output #0: loss = 1.30693 (* 1 = 1.30693 loss)
I0802 06:43:15.182270 18636 sgd_solver.cpp:136] Iteration 45300, lr = 0.00716875, m = 0.9
I0802 06:43:29.112654 18636 solver.cpp:353] Iteration 45400 (7.17873 iter/s, 13.93s/100 iter), loss = 1.307
I0802 06:43:29.112725 18636 solver.cpp:375]     Train net output #0: loss = 1.18026 (* 1 = 1.18026 loss)
I0802 06:43:29.112731 18636 sgd_solver.cpp:136] Iteration 45400, lr = 0.0071625, m = 0.9
I0802 06:43:42.985051 18636 solver.cpp:353] Iteration 45500 (7.20875 iter/s, 13.872s/100 iter), loss = 1.59157
I0802 06:43:42.985077 18636 solver.cpp:375]     Train net output #0: loss = 1.86329 (* 1 = 1.86329 loss)
I0802 06:43:42.985083 18636 sgd_solver.cpp:136] Iteration 45500, lr = 0.00715625, m = 0.9
I0802 06:43:57.002856 18636 solver.cpp:353] Iteration 45600 (7.13398 iter/s, 14.0174s/100 iter), loss = 1.24251
I0802 06:43:57.002882 18636 solver.cpp:375]     Train net output #0: loss = 1.19333 (* 1 = 1.19333 loss)
I0802 06:43:57.002885 18636 sgd_solver.cpp:136] Iteration 45600, lr = 0.00715, m = 0.9
I0802 06:44:10.969877 18636 solver.cpp:353] Iteration 45700 (7.15992 iter/s, 13.9666s/100 iter), loss = 1.3431
I0802 06:44:10.969983 18636 solver.cpp:375]     Train net output #0: loss = 1.52618 (* 1 = 1.52618 loss)
I0802 06:44:10.969990 18636 sgd_solver.cpp:136] Iteration 45700, lr = 0.00714375, m = 0.9
I0802 06:44:24.932498 18636 solver.cpp:353] Iteration 45800 (7.16217 iter/s, 13.9622s/100 iter), loss = 1.56623
I0802 06:44:24.932523 18636 solver.cpp:375]     Train net output #0: loss = 1.69944 (* 1 = 1.69944 loss)
I0802 06:44:24.932526 18636 sgd_solver.cpp:136] Iteration 45800, lr = 0.0071375, m = 0.9
I0802 06:44:38.879467 18636 solver.cpp:353] Iteration 45900 (7.17021 iter/s, 13.9466s/100 iter), loss = 1.10833
I0802 06:44:38.879492 18636 solver.cpp:375]     Train net output #0: loss = 1.12398 (* 1 = 1.12398 loss)
I0802 06:44:38.879497 18636 sgd_solver.cpp:136] Iteration 45900, lr = 0.00713125, m = 0.9
I0802 06:44:52.707373 18636 solver.cpp:404] Sparsity after update:
I0802 06:44:52.711374 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:44:52.711385 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:44:52.711393 18636 net.cpp:2270] conv1b_param_0(0.25) 
I0802 06:44:52.711397 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:44:52.711402 18636 net.cpp:2270] res2a_branch2a_param_0(0.257) 
I0802 06:44:52.711405 18636 net.cpp:2270] res2a_branch2b_param_0(0.257) 
I0802 06:44:52.711408 18636 net.cpp:2270] res3a_branch2a_param_0(0.259) 
I0802 06:44:52.711411 18636 net.cpp:2270] res3a_branch2b_param_0(0.257) 
I0802 06:44:52.711414 18636 net.cpp:2270] res4a_branch2a_param_0(0.26) 
I0802 06:44:52.711418 18636 net.cpp:2270] res4a_branch2b_param_0(0.259) 
I0802 06:44:52.711422 18636 net.cpp:2270] res5a_branch2a_param_0(0.26) 
I0802 06:44:52.711426 18636 net.cpp:2270] res5a_branch2b_param_0(0.26) 
I0802 06:44:52.711431 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (610947/2.86678e+06) 0.213
I0802 06:44:52.711444 18636 solver.cpp:550] Iteration 46000, Testing net (#0)
I0802 06:45:12.764072 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.563647
I0802 06:45:12.764096 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.799057
I0802 06:45:12.764103 18636 solver.cpp:635]     Test net output #2: loss = 1.96481 (* 1 = 1.96481 loss)
I0802 06:45:12.764127 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0521s
I0802 06:45:12.912250 18661 solver.cpp:450] Finding and applying sparsity: 0.27
I0802 06:45:35.201942 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:45:35.203936 18636 solver.cpp:353] Iteration 46000 (1.77548 iter/s, 56.323s/100 iter), loss = 1.85064
I0802 06:45:35.203955 18636 solver.cpp:375]     Train net output #0: loss = 1.80574 (* 1 = 1.80574 loss)
I0802 06:45:35.203960 18636 sgd_solver.cpp:136] Iteration 46000, lr = 0.007125, m = 0.9
I0802 06:45:49.589026 18636 solver.cpp:353] Iteration 46100 (6.95184 iter/s, 14.3847s/100 iter), loss = 1.48732
I0802 06:45:49.589056 18636 solver.cpp:375]     Train net output #0: loss = 1.59209 (* 1 = 1.59209 loss)
I0802 06:45:49.589064 18636 sgd_solver.cpp:136] Iteration 46100, lr = 0.00711875, m = 0.9
I0802 06:46:03.439882 18636 solver.cpp:353] Iteration 46200 (7.21997 iter/s, 13.8505s/100 iter), loss = 1.02752
I0802 06:46:03.439913 18636 solver.cpp:375]     Train net output #0: loss = 0.630138 (* 1 = 0.630138 loss)
I0802 06:46:03.439918 18636 sgd_solver.cpp:136] Iteration 46200, lr = 0.0071125, m = 0.9
I0802 06:46:17.480677 18636 solver.cpp:353] Iteration 46300 (7.1223 iter/s, 14.0404s/100 iter), loss = 1.34733
I0802 06:46:17.480756 18636 solver.cpp:375]     Train net output #0: loss = 1.45305 (* 1 = 1.45305 loss)
I0802 06:46:17.480792 18636 sgd_solver.cpp:136] Iteration 46300, lr = 0.00710625, m = 0.9
I0802 06:46:31.429672 18636 solver.cpp:353] Iteration 46400 (7.16917 iter/s, 13.9486s/100 iter), loss = 1.44085
I0802 06:46:31.429733 18636 solver.cpp:375]     Train net output #0: loss = 1.21708 (* 1 = 1.21708 loss)
I0802 06:46:31.429749 18636 sgd_solver.cpp:136] Iteration 46400, lr = 0.0071, m = 0.9
I0802 06:46:45.427994 18636 solver.cpp:353] Iteration 46500 (7.14391 iter/s, 13.9979s/100 iter), loss = 1.55319
I0802 06:46:45.428270 18636 solver.cpp:375]     Train net output #0: loss = 1.64202 (* 1 = 1.64202 loss)
I0802 06:46:45.428378 18636 sgd_solver.cpp:136] Iteration 46500, lr = 0.00709375, m = 0.9
I0802 06:46:59.380161 18636 solver.cpp:353] Iteration 46600 (7.16754 iter/s, 13.9518s/100 iter), loss = 1.26816
I0802 06:46:59.380551 18636 solver.cpp:375]     Train net output #0: loss = 0.986781 (* 1 = 0.986781 loss)
I0802 06:46:59.380564 18636 sgd_solver.cpp:136] Iteration 46600, lr = 0.0070875, m = 0.9
I0802 06:47:13.300606 18636 solver.cpp:353] Iteration 46700 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.82209
I0802 06:47:13.300659 18636 solver.cpp:375]     Train net output #0: loss = 1.57574 (* 1 = 1.57574 loss)
I0802 06:47:13.300678 18636 sgd_solver.cpp:136] Iteration 46700, lr = 0.00708125, m = 0.9
I0802 06:47:27.272965 18636 solver.cpp:353] Iteration 46800 (7.15718 iter/s, 13.972s/100 iter), loss = 1.45986
I0802 06:47:27.272990 18636 solver.cpp:375]     Train net output #0: loss = 1.67214 (* 1 = 1.67214 loss)
I0802 06:47:27.272994 18636 sgd_solver.cpp:136] Iteration 46800, lr = 0.007075, m = 0.9
I0802 06:47:41.217309 18636 solver.cpp:353] Iteration 46900 (7.17156 iter/s, 13.944s/100 iter), loss = 1.67315
I0802 06:47:41.217409 18636 solver.cpp:375]     Train net output #0: loss = 1.9193 (* 1 = 1.9193 loss)
I0802 06:47:41.217417 18636 sgd_solver.cpp:136] Iteration 46900, lr = 0.00706875, m = 0.9
I0802 06:47:55.051767 18636 solver.cpp:404] Sparsity after update:
I0802 06:47:55.065769 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:47:55.065834 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:47:55.065860 18636 net.cpp:2270] conv1b_param_0(0.264) 
I0802 06:47:55.065872 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:47:55.065884 18636 net.cpp:2270] res2a_branch2a_param_0(0.267) 
I0802 06:47:55.065897 18636 net.cpp:2270] res2a_branch2b_param_0(0.264) 
I0802 06:47:55.065909 18636 net.cpp:2270] res3a_branch2a_param_0(0.269) 
I0802 06:47:55.065922 18636 net.cpp:2270] res3a_branch2b_param_0(0.267) 
I0802 06:47:55.065934 18636 net.cpp:2270] res4a_branch2a_param_0(0.27) 
I0802 06:47:55.065946 18636 net.cpp:2270] res4a_branch2b_param_0(0.269) 
I0802 06:47:55.065958 18636 net.cpp:2270] res5a_branch2a_param_0(0.27) 
I0802 06:47:55.065971 18636 net.cpp:2270] res5a_branch2b_param_0(0.27) 
I0802 06:47:55.065984 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (634946/2.86678e+06) 0.221
I0802 06:47:55.195879 18661 solver.cpp:450] Finding and applying sparsity: 0.28
I0802 06:48:17.474906 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:48:17.476811 18636 solver.cpp:353] Iteration 47000 (2.75797 iter/s, 36.2585s/100 iter), loss = 1.43364
I0802 06:48:17.476836 18636 solver.cpp:375]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0802 06:48:17.476841 18636 sgd_solver.cpp:136] Iteration 47000, lr = 0.0070625, m = 0.9
I0802 06:48:31.929507 18636 solver.cpp:353] Iteration 47100 (6.91931 iter/s, 14.4523s/100 iter), loss = 1.7444
I0802 06:48:31.929533 18636 solver.cpp:375]     Train net output #0: loss = 1.90673 (* 1 = 1.90673 loss)
I0802 06:48:31.929538 18636 sgd_solver.cpp:136] Iteration 47100, lr = 0.00705625, m = 0.9
I0802 06:48:45.907543 18636 solver.cpp:353] Iteration 47200 (7.15428 iter/s, 13.9777s/100 iter), loss = 1.40348
I0802 06:48:45.907568 18636 solver.cpp:375]     Train net output #0: loss = 1.12277 (* 1 = 1.12277 loss)
I0802 06:48:45.907574 18636 sgd_solver.cpp:136] Iteration 47200, lr = 0.00705, m = 0.9
I0802 06:48:59.868453 18636 solver.cpp:353] Iteration 47300 (7.16305 iter/s, 13.9605s/100 iter), loss = 1.0933
I0802 06:48:59.868542 18636 solver.cpp:375]     Train net output #0: loss = 1.21015 (* 1 = 1.21015 loss)
I0802 06:48:59.868549 18636 sgd_solver.cpp:136] Iteration 47300, lr = 0.00704375, m = 0.9
I0802 06:49:13.825317 18636 solver.cpp:353] Iteration 47400 (7.16513 iter/s, 13.9565s/100 iter), loss = 1.40051
I0802 06:49:13.825526 18636 solver.cpp:375]     Train net output #0: loss = 1.22915 (* 1 = 1.22915 loss)
I0802 06:49:13.825645 18636 sgd_solver.cpp:136] Iteration 47400, lr = 0.0070375, m = 0.9
I0802 06:49:27.719486 18636 solver.cpp:353] Iteration 47500 (7.19746 iter/s, 13.8938s/100 iter), loss = 1.26055
I0802 06:49:27.719513 18636 solver.cpp:375]     Train net output #0: loss = 1.3017 (* 1 = 1.3017 loss)
I0802 06:49:27.719517 18636 sgd_solver.cpp:136] Iteration 47500, lr = 0.00703125, m = 0.9
I0802 06:49:41.755682 18636 solver.cpp:353] Iteration 47600 (7.12463 iter/s, 14.0358s/100 iter), loss = 2.0023
I0802 06:49:41.760870 18636 solver.cpp:375]     Train net output #0: loss = 2.03366 (* 1 = 2.03366 loss)
I0802 06:49:41.760882 18636 sgd_solver.cpp:136] Iteration 47600, lr = 0.007025, m = 0.9
I0802 06:49:55.637300 18636 solver.cpp:353] Iteration 47700 (7.20397 iter/s, 13.8812s/100 iter), loss = 1.45381
I0802 06:49:55.637363 18636 solver.cpp:375]     Train net output #0: loss = 1.37967 (* 1 = 1.37967 loss)
I0802 06:49:55.637374 18636 sgd_solver.cpp:136] Iteration 47700, lr = 0.00701875, m = 0.9
I0802 06:50:09.616214 18636 solver.cpp:353] Iteration 47800 (7.15382 iter/s, 13.9785s/100 iter), loss = 1.29604
I0802 06:50:09.616245 18636 solver.cpp:375]     Train net output #0: loss = 1.12856 (* 1 = 1.12856 loss)
I0802 06:50:09.616250 18636 sgd_solver.cpp:136] Iteration 47800, lr = 0.0070125, m = 0.9
I0802 06:50:23.606892 18636 solver.cpp:353] Iteration 47900 (7.14781 iter/s, 13.9903s/100 iter), loss = 1.39784
I0802 06:50:23.606962 18636 solver.cpp:375]     Train net output #0: loss = 1.9935 (* 1 = 1.9935 loss)
I0802 06:50:23.606969 18636 sgd_solver.cpp:136] Iteration 47900, lr = 0.00700625, m = 0.9
I0802 06:50:37.389869 18636 solver.cpp:404] Sparsity after update:
I0802 06:50:37.412127 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:50:37.412143 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:50:37.412151 18636 net.cpp:2270] conv1b_param_0(0.278) 
I0802 06:50:37.412155 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:50:37.412158 18636 net.cpp:2270] res2a_branch2a_param_0(0.278) 
I0802 06:50:37.412161 18636 net.cpp:2270] res2a_branch2b_param_0(0.278) 
I0802 06:50:37.412168 18636 net.cpp:2270] res3a_branch2a_param_0(0.28) 
I0802 06:50:37.412173 18636 net.cpp:2270] res3a_branch2b_param_0(0.278) 
I0802 06:50:37.412175 18636 net.cpp:2270] res4a_branch2a_param_0(0.28) 
I0802 06:50:37.412178 18636 net.cpp:2270] res4a_branch2b_param_0(0.28) 
I0802 06:50:37.412181 18636 net.cpp:2270] res5a_branch2a_param_0(0.28) 
I0802 06:50:37.412184 18636 net.cpp:2270] res5a_branch2b_param_0(0.279) 
I0802 06:50:37.412189 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (658213/2.86678e+06) 0.23
I0802 06:50:37.412201 18636 solver.cpp:550] Iteration 48000, Testing net (#0)
I0802 06:50:38.225237 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:50:56.960484 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.566647
I0802 06:50:56.960579 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.799821
I0802 06:50:56.960587 18636 solver.cpp:635]     Test net output #2: loss = 1.91587 (* 1 = 1.91587 loss)
I0802 06:50:56.960606 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5479s
I0802 06:50:57.113481 18661 solver.cpp:450] Finding and applying sparsity: 0.29
I0802 06:51:19.837556 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:51:19.839766 18636 solver.cpp:353] Iteration 48000 (1.77837 iter/s, 56.2314s/100 iter), loss = 1.46168
I0802 06:51:19.839797 18636 solver.cpp:375]     Train net output #0: loss = 1.67141 (* 1 = 1.67141 loss)
I0802 06:51:19.839807 18636 sgd_solver.cpp:136] Iteration 48000, lr = 0.007, m = 0.9
I0802 06:51:34.164759 18636 solver.cpp:353] Iteration 48100 (6.981 iter/s, 14.3246s/100 iter), loss = 1.41451
I0802 06:51:34.164826 18636 solver.cpp:375]     Train net output #0: loss = 1.61945 (* 1 = 1.61945 loss)
I0802 06:51:34.164834 18636 sgd_solver.cpp:136] Iteration 48100, lr = 0.00699375, m = 0.9
I0802 06:51:48.059079 18636 solver.cpp:353] Iteration 48200 (7.19738 iter/s, 13.8939s/100 iter), loss = 1.70287
I0802 06:51:48.059129 18636 solver.cpp:375]     Train net output #0: loss = 1.90336 (* 1 = 1.90336 loss)
I0802 06:51:48.059141 18636 sgd_solver.cpp:136] Iteration 48200, lr = 0.0069875, m = 0.9
I0802 06:52:01.952579 18636 solver.cpp:353] Iteration 48300 (7.19781 iter/s, 13.8931s/100 iter), loss = 1.27285
I0802 06:52:01.952606 18636 solver.cpp:375]     Train net output #0: loss = 1.40388 (* 1 = 1.40388 loss)
I0802 06:52:01.952610 18636 sgd_solver.cpp:136] Iteration 48300, lr = 0.00698125, m = 0.9
I0802 06:52:15.848634 18636 solver.cpp:353] Iteration 48400 (7.19648 iter/s, 13.8957s/100 iter), loss = 1.47127
I0802 06:52:15.848747 18636 solver.cpp:375]     Train net output #0: loss = 1.09558 (* 1 = 1.09558 loss)
I0802 06:52:15.848757 18636 sgd_solver.cpp:136] Iteration 48400, lr = 0.006975, m = 0.9
I0802 06:52:29.761567 18636 solver.cpp:353] Iteration 48500 (7.18775 iter/s, 13.9126s/100 iter), loss = 1.35573
I0802 06:52:29.761595 18636 solver.cpp:375]     Train net output #0: loss = 1.24959 (* 1 = 1.24959 loss)
I0802 06:52:29.761601 18636 sgd_solver.cpp:136] Iteration 48500, lr = 0.00696875, m = 0.9
I0802 06:52:43.773345 18636 solver.cpp:353] Iteration 48600 (7.13705 iter/s, 14.0114s/100 iter), loss = 1.23291
I0802 06:52:43.773377 18636 solver.cpp:375]     Train net output #0: loss = 1.32274 (* 1 = 1.32274 loss)
I0802 06:52:43.773382 18636 sgd_solver.cpp:136] Iteration 48600, lr = 0.0069625, m = 0.9
I0802 06:52:57.674425 18636 solver.cpp:353] Iteration 48700 (7.19388 iter/s, 13.9007s/100 iter), loss = 1.4489
I0802 06:52:57.674484 18636 solver.cpp:375]     Train net output #0: loss = 1.47148 (* 1 = 1.47148 loss)
I0802 06:52:57.674491 18636 sgd_solver.cpp:136] Iteration 48700, lr = 0.00695625, m = 0.9
I0802 06:53:11.597658 18636 solver.cpp:353] Iteration 48800 (7.18243 iter/s, 13.9229s/100 iter), loss = 1.5043
I0802 06:53:11.597684 18636 solver.cpp:375]     Train net output #0: loss = 1.66918 (* 1 = 1.66918 loss)
I0802 06:53:11.597746 18636 sgd_solver.cpp:136] Iteration 48800, lr = 0.00695, m = 0.9
I0802 06:53:25.499907 18636 solver.cpp:353] Iteration 48900 (7.19327 iter/s, 13.9019s/100 iter), loss = 1.67643
I0802 06:53:25.499960 18636 solver.cpp:375]     Train net output #0: loss = 1.6099 (* 1 = 1.6099 loss)
I0802 06:53:25.499972 18636 sgd_solver.cpp:136] Iteration 48900, lr = 0.00694375, m = 0.9
I0802 06:53:39.304018 18636 solver.cpp:404] Sparsity after update:
I0802 06:53:39.314502 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:53:39.314517 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:53:39.314525 18636 net.cpp:2270] conv1b_param_0(0.278) 
I0802 06:53:39.314528 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:53:39.314532 18636 net.cpp:2270] res2a_branch2a_param_0(0.288) 
I0802 06:53:39.314535 18636 net.cpp:2270] res2a_branch2b_param_0(0.285) 
I0802 06:53:39.314538 18636 net.cpp:2270] res3a_branch2a_param_0(0.29) 
I0802 06:53:39.314541 18636 net.cpp:2270] res3a_branch2b_param_0(0.288) 
I0802 06:53:39.314544 18636 net.cpp:2270] res4a_branch2a_param_0(0.29) 
I0802 06:53:39.314546 18636 net.cpp:2270] res4a_branch2b_param_0(0.29) 
I0802 06:53:39.314549 18636 net.cpp:2270] res5a_branch2a_param_0(0.29) 
I0802 06:53:39.314553 18636 net.cpp:2270] res5a_branch2b_param_0(0.29) 
I0802 06:53:39.314555 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (682156/2.86678e+06) 0.238
I0802 06:53:39.443033 18661 solver.cpp:450] Finding and applying sparsity: 0.3
I0802 06:54:02.264540 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:54:02.266433 18636 solver.cpp:353] Iteration 49000 (2.71994 iter/s, 36.7655s/100 iter), loss = 1.58539
I0802 06:54:02.266453 18636 solver.cpp:375]     Train net output #0: loss = 1.48071 (* 1 = 1.48071 loss)
I0802 06:54:02.266458 18636 sgd_solver.cpp:136] Iteration 49000, lr = 0.0069375, m = 0.9
I0802 06:54:16.650591 18636 solver.cpp:353] Iteration 49100 (6.95228 iter/s, 14.3838s/100 iter), loss = 1.62198
I0802 06:54:16.650651 18636 solver.cpp:375]     Train net output #0: loss = 1.80605 (* 1 = 1.80605 loss)
I0802 06:54:16.650658 18636 sgd_solver.cpp:136] Iteration 49100, lr = 0.00693125, m = 0.9
I0802 06:54:30.567860 18636 solver.cpp:353] Iteration 49200 (7.18551 iter/s, 13.9169s/100 iter), loss = 1.57636
I0802 06:54:30.567952 18636 solver.cpp:375]     Train net output #0: loss = 1.80384 (* 1 = 1.80384 loss)
I0802 06:54:30.567972 18636 sgd_solver.cpp:136] Iteration 49200, lr = 0.006925, m = 0.9
I0802 06:54:44.438364 18636 solver.cpp:353] Iteration 49300 (7.20974 iter/s, 13.8701s/100 iter), loss = 1.37102
I0802 06:54:44.438400 18636 solver.cpp:375]     Train net output #0: loss = 1.35321 (* 1 = 1.35321 loss)
I0802 06:54:44.438405 18636 sgd_solver.cpp:136] Iteration 49300, lr = 0.00691875, m = 0.9
I0802 06:54:58.346591 18636 solver.cpp:353] Iteration 49400 (7.19018 iter/s, 13.9079s/100 iter), loss = 1.30816
I0802 06:54:58.346665 18636 solver.cpp:375]     Train net output #0: loss = 1.01246 (* 1 = 1.01246 loss)
I0802 06:54:58.346673 18636 sgd_solver.cpp:136] Iteration 49400, lr = 0.0069125, m = 0.9
I0802 06:55:12.272529 18636 solver.cpp:353] Iteration 49500 (7.18104 iter/s, 13.9256s/100 iter), loss = 1.30787
I0802 06:55:12.272554 18636 solver.cpp:375]     Train net output #0: loss = 1.08105 (* 1 = 1.08105 loss)
I0802 06:55:12.272559 18636 sgd_solver.cpp:136] Iteration 49500, lr = 0.00690625, m = 0.9
I0802 06:55:26.163686 18636 solver.cpp:353] Iteration 49600 (7.19902 iter/s, 13.8908s/100 iter), loss = 1.48203
I0802 06:55:26.163799 18636 solver.cpp:375]     Train net output #0: loss = 1.61794 (* 1 = 1.61794 loss)
I0802 06:55:26.163820 18636 sgd_solver.cpp:136] Iteration 49600, lr = 0.0069, m = 0.9
I0802 06:55:40.105550 18636 solver.cpp:353] Iteration 49700 (7.17283 iter/s, 13.9415s/100 iter), loss = 1.69063
I0802 06:55:40.105645 18636 solver.cpp:375]     Train net output #0: loss = 1.51562 (* 1 = 1.51562 loss)
I0802 06:55:40.105662 18636 sgd_solver.cpp:136] Iteration 49700, lr = 0.00689375, m = 0.9
I0802 06:55:54.042373 18636 solver.cpp:353] Iteration 49800 (7.17543 iter/s, 13.9364s/100 iter), loss = 1.54997
I0802 06:55:54.042409 18636 solver.cpp:375]     Train net output #0: loss = 1.95499 (* 1 = 1.95499 loss)
I0802 06:55:54.042417 18636 sgd_solver.cpp:136] Iteration 49800, lr = 0.0068875, m = 0.9
I0802 06:56:08.002913 18636 solver.cpp:353] Iteration 49900 (7.16324 iter/s, 13.9602s/100 iter), loss = 1.24592
I0802 06:56:08.002944 18636 solver.cpp:375]     Train net output #0: loss = 1.1966 (* 1 = 1.1966 loss)
I0802 06:56:08.002951 18636 sgd_solver.cpp:136] Iteration 49900, lr = 0.00688125, m = 0.9
I0802 06:56:21.870254 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_50000.caffemodel
I0802 06:56:21.965221 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_50000.solverstate
I0802 06:56:21.971206 18636 solver.cpp:404] Sparsity after update:
I0802 06:56:21.973189 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:56:21.973201 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 06:56:21.973209 18636 net.cpp:2270] conv1b_param_0(0.292) 
I0802 06:56:21.973212 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:56:21.973217 18636 net.cpp:2270] res2a_branch2a_param_0(0.299) 
I0802 06:56:21.973219 18636 net.cpp:2270] res2a_branch2b_param_0(0.299) 
I0802 06:56:21.973223 18636 net.cpp:2270] res3a_branch2a_param_0(0.299) 
I0802 06:56:21.973227 18636 net.cpp:2270] res3a_branch2b_param_0(0.299) 
I0802 06:56:21.973229 18636 net.cpp:2270] res4a_branch2a_param_0(0.299) 
I0802 06:56:21.973232 18636 net.cpp:2270] res4a_branch2b_param_0(0.299) 
I0802 06:56:21.973237 18636 net.cpp:2270] res5a_branch2a_param_0(0.3) 
I0802 06:56:21.973239 18636 net.cpp:2270] res5a_branch2b_param_0(0.299) 
I0802 06:56:21.973243 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (705071/2.86678e+06) 0.246
I0802 06:56:21.973256 18636 solver.cpp:550] Iteration 50000, Testing net (#0)
I0802 06:56:41.616878 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.561411
I0802 06:56:41.616904 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.803821
I0802 06:56:41.616910 18636 solver.cpp:635]     Test net output #2: loss = 1.9167 (* 1 = 1.9167 loss)
I0802 06:56:41.616932 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6431s
I0802 06:56:41.756669 18661 solver.cpp:450] Finding and applying sparsity: 0.31
I0802 06:57:04.953845 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:57:04.955755 18636 solver.cpp:353] Iteration 50000 (1.75589 iter/s, 56.9513s/100 iter), loss = 1.42634
I0802 06:57:04.955772 18636 solver.cpp:375]     Train net output #0: loss = 1.31368 (* 1 = 1.31368 loss)
I0802 06:57:04.955778 18636 sgd_solver.cpp:136] Iteration 50000, lr = 0.006875, m = 0.9
I0802 06:57:19.352954 18636 solver.cpp:353] Iteration 50100 (6.94599 iter/s, 14.3968s/100 iter), loss = 1.49455
I0802 06:57:19.352982 18636 solver.cpp:375]     Train net output #0: loss = 1.33442 (* 1 = 1.33442 loss)
I0802 06:57:19.352988 18636 sgd_solver.cpp:136] Iteration 50100, lr = 0.00686875, m = 0.9
I0802 06:57:33.430371 18636 solver.cpp:353] Iteration 50200 (7.10377 iter/s, 14.077s/100 iter), loss = 1.31277
I0802 06:57:33.430402 18636 solver.cpp:375]     Train net output #0: loss = 1.11821 (* 1 = 1.11821 loss)
I0802 06:57:33.430454 18636 sgd_solver.cpp:136] Iteration 50200, lr = 0.0068625, m = 0.9
I0802 06:57:47.387488 18636 solver.cpp:353] Iteration 50300 (7.165 iter/s, 13.9567s/100 iter), loss = 1.42128
I0802 06:57:47.387569 18636 solver.cpp:375]     Train net output #0: loss = 1.32181 (* 1 = 1.32181 loss)
I0802 06:57:47.387575 18636 sgd_solver.cpp:136] Iteration 50300, lr = 0.00685625, m = 0.9
I0802 06:58:01.375219 18636 solver.cpp:353] Iteration 50400 (7.14932 iter/s, 13.9873s/100 iter), loss = 1.62011
I0802 06:58:01.375247 18636 solver.cpp:375]     Train net output #0: loss = 2.09463 (* 1 = 2.09463 loss)
I0802 06:58:01.375253 18636 sgd_solver.cpp:136] Iteration 50400, lr = 0.00685, m = 0.9
I0802 06:58:15.326139 18636 solver.cpp:353] Iteration 50500 (7.16818 iter/s, 13.9505s/100 iter), loss = 1.40214
I0802 06:58:15.326167 18636 solver.cpp:375]     Train net output #0: loss = 1.21161 (* 1 = 1.21161 loss)
I0802 06:58:15.326174 18636 sgd_solver.cpp:136] Iteration 50500, lr = 0.00684375, m = 0.9
I0802 06:58:29.311125 18636 solver.cpp:353] Iteration 50600 (7.15072 iter/s, 13.9846s/100 iter), loss = 1.29509
I0802 06:58:29.312919 18636 solver.cpp:375]     Train net output #0: loss = 1.39533 (* 1 = 1.39533 loss)
I0802 06:58:29.312942 18636 sgd_solver.cpp:136] Iteration 50600, lr = 0.0068375, m = 0.9
I0802 06:58:43.294925 18636 solver.cpp:353] Iteration 50700 (7.15133 iter/s, 13.9834s/100 iter), loss = 1.42442
I0802 06:58:43.294955 18636 solver.cpp:375]     Train net output #0: loss = 1.81988 (* 1 = 1.81988 loss)
I0802 06:58:43.294960 18636 sgd_solver.cpp:136] Iteration 50700, lr = 0.00683125, m = 0.9
I0802 06:58:57.313169 18636 solver.cpp:353] Iteration 50800 (7.13375 iter/s, 14.0179s/100 iter), loss = 1.65342
I0802 06:58:57.313194 18636 solver.cpp:375]     Train net output #0: loss = 1.66311 (* 1 = 1.66311 loss)
I0802 06:58:57.313199 18636 sgd_solver.cpp:136] Iteration 50800, lr = 0.006825, m = 0.9
I0802 06:59:11.291710 18636 solver.cpp:353] Iteration 50900 (7.15402 iter/s, 13.9782s/100 iter), loss = 1.24462
I0802 06:59:11.291844 18636 solver.cpp:375]     Train net output #0: loss = 1.28791 (* 1 = 1.28791 loss)
I0802 06:59:11.291867 18636 sgd_solver.cpp:136] Iteration 50900, lr = 0.00681875, m = 0.9
I0802 06:59:25.146364 18636 solver.cpp:404] Sparsity after update:
I0802 06:59:25.160383 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:59:25.160434 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 06:59:25.160459 18636 net.cpp:2270] conv1b_param_0(0.306) 
I0802 06:59:25.160472 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:59:25.160485 18636 net.cpp:2270] res2a_branch2a_param_0(0.309) 
I0802 06:59:25.160498 18636 net.cpp:2270] res2a_branch2b_param_0(0.306) 
I0802 06:59:25.160517 18636 net.cpp:2270] res3a_branch2a_param_0(0.309) 
I0802 06:59:25.160531 18636 net.cpp:2270] res3a_branch2b_param_0(0.309) 
I0802 06:59:25.160544 18636 net.cpp:2270] res4a_branch2a_param_0(0.31) 
I0802 06:59:25.160557 18636 net.cpp:2270] res4a_branch2b_param_0(0.309) 
I0802 06:59:25.160569 18636 net.cpp:2270] res5a_branch2a_param_0(0.31) 
I0802 06:59:25.160583 18636 net.cpp:2270] res5a_branch2b_param_0(0.31) 
I0802 06:59:25.160595 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (729022/2.86678e+06) 0.254
I0802 06:59:25.309448 18661 solver.cpp:450] Finding and applying sparsity: 0.32
I0802 06:59:48.668054 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:59:48.669999 18636 solver.cpp:353] Iteration 51000 (2.67542 iter/s, 37.3773s/100 iter), loss = 1.28452
I0802 06:59:48.670018 18636 solver.cpp:375]     Train net output #0: loss = 1.35639 (* 1 = 1.35639 loss)
I0802 06:59:48.670025 18636 sgd_solver.cpp:136] Iteration 51000, lr = 0.0068125, m = 0.9
I0802 07:00:02.994339 18636 solver.cpp:353] Iteration 51100 (6.98132 iter/s, 14.3239s/100 iter), loss = 1.63698
I0802 07:00:02.994391 18636 solver.cpp:375]     Train net output #0: loss = 1.47396 (* 1 = 1.47396 loss)
I0802 07:00:02.994405 18636 sgd_solver.cpp:136] Iteration 51100, lr = 0.00680625, m = 0.9
I0802 07:00:16.960281 18636 solver.cpp:353] Iteration 51200 (7.16047 iter/s, 13.9656s/100 iter), loss = 1.50861
I0802 07:00:16.960309 18636 solver.cpp:375]     Train net output #0: loss = 1.48856 (* 1 = 1.48856 loss)
I0802 07:00:16.960312 18636 sgd_solver.cpp:136] Iteration 51200, lr = 0.0068, m = 0.9
I0802 07:00:30.944360 18636 solver.cpp:353] Iteration 51300 (7.15118 iter/s, 13.9837s/100 iter), loss = 1.43701
I0802 07:00:30.944428 18636 solver.cpp:375]     Train net output #0: loss = 1.61454 (* 1 = 1.61454 loss)
I0802 07:00:30.944434 18636 sgd_solver.cpp:136] Iteration 51300, lr = 0.00679375, m = 0.9
I0802 07:00:44.883304 18636 solver.cpp:353] Iteration 51400 (7.17434 iter/s, 13.9386s/100 iter), loss = 1.76298
I0802 07:00:44.883330 18636 solver.cpp:375]     Train net output #0: loss = 1.62156 (* 1 = 1.62156 loss)
I0802 07:00:44.883337 18636 sgd_solver.cpp:136] Iteration 51400, lr = 0.0067875, m = 0.9
I0802 07:00:58.770870 18636 solver.cpp:353] Iteration 51500 (7.20088 iter/s, 13.8872s/100 iter), loss = 1.58322
I0802 07:00:58.770961 18636 solver.cpp:375]     Train net output #0: loss = 1.49675 (* 1 = 1.49675 loss)
I0802 07:00:58.770982 18636 sgd_solver.cpp:136] Iteration 51500, lr = 0.00678125, m = 0.9
I0802 07:01:12.664788 18636 solver.cpp:353] Iteration 51600 (7.19759 iter/s, 13.8935s/100 iter), loss = 1.38689
I0802 07:01:12.664846 18636 solver.cpp:375]     Train net output #0: loss = 1.24145 (* 1 = 1.24145 loss)
I0802 07:01:12.664851 18636 sgd_solver.cpp:136] Iteration 51600, lr = 0.006775, m = 0.9
I0802 07:01:26.669744 18636 solver.cpp:353] Iteration 51700 (7.14052 iter/s, 14.0046s/100 iter), loss = 1.40688
I0802 07:01:26.669767 18636 solver.cpp:375]     Train net output #0: loss = 1.59067 (* 1 = 1.59067 loss)
I0802 07:01:26.669771 18636 sgd_solver.cpp:136] Iteration 51700, lr = 0.00676875, m = 0.9
I0802 07:01:40.595296 18636 solver.cpp:353] Iteration 51800 (7.18124 iter/s, 13.9252s/100 iter), loss = 1.14221
I0802 07:01:40.595324 18636 solver.cpp:375]     Train net output #0: loss = 0.87731 (* 1 = 0.87731 loss)
I0802 07:01:40.595327 18636 sgd_solver.cpp:136] Iteration 51800, lr = 0.0067625, m = 0.9
I0802 07:01:54.571805 18636 solver.cpp:353] Iteration 51900 (7.15506 iter/s, 13.9761s/100 iter), loss = 1.59654
I0802 07:01:54.571871 18636 solver.cpp:375]     Train net output #0: loss = 1.30264 (* 1 = 1.30264 loss)
I0802 07:01:54.571877 18636 sgd_solver.cpp:136] Iteration 51900, lr = 0.00675625, m = 0.9
I0802 07:02:08.471431 18636 solver.cpp:404] Sparsity after update:
I0802 07:02:08.477458 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:02:08.477469 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 07:02:08.477478 18636 net.cpp:2270] conv1b_param_0(0.319) 
I0802 07:02:08.477483 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:02:08.477485 18636 net.cpp:2270] res2a_branch2a_param_0(0.319) 
I0802 07:02:08.477494 18636 net.cpp:2270] res2a_branch2b_param_0(0.319) 
I0802 07:02:08.477499 18636 net.cpp:2270] res3a_branch2a_param_0(0.319) 
I0802 07:02:08.477504 18636 net.cpp:2270] res3a_branch2b_param_0(0.319) 
I0802 07:02:08.477509 18636 net.cpp:2270] res4a_branch2a_param_0(0.319) 
I0802 07:02:08.477514 18636 net.cpp:2270] res4a_branch2b_param_0(0.319) 
I0802 07:02:08.477516 18636 net.cpp:2270] res5a_branch2a_param_0(0.32) 
I0802 07:02:08.477521 18636 net.cpp:2270] res5a_branch2b_param_0(0.319) 
I0802 07:02:08.477526 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (752286/2.86678e+06) 0.262
I0802 07:02:08.477538 18636 solver.cpp:550] Iteration 52000, Testing net (#0)
I0802 07:02:27.808290 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.571647
I0802 07:02:27.808419 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805997
I0802 07:02:27.808429 18636 solver.cpp:635]     Test net output #2: loss = 1.88316 (* 1 = 1.88316 loss)
I0802 07:02:27.808447 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3304s
I0802 07:02:27.947489 18661 solver.cpp:450] Finding and applying sparsity: 0.33
I0802 07:02:51.755393 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:02:51.757508 18636 solver.cpp:353] Iteration 52000 (1.74874 iter/s, 57.1842s/100 iter), loss = 1.33747
I0802 07:02:51.757534 18636 solver.cpp:375]     Train net output #0: loss = 0.915729 (* 1 = 0.915729 loss)
I0802 07:02:51.757544 18636 sgd_solver.cpp:136] Iteration 52000, lr = 0.00675, m = 0.9
I0802 07:03:06.099489 18636 solver.cpp:353] Iteration 52100 (6.97273 iter/s, 14.3416s/100 iter), loss = 1.14879
I0802 07:03:06.099555 18636 solver.cpp:375]     Train net output #0: loss = 1.09354 (* 1 = 1.09354 loss)
I0802 07:03:06.099561 18636 sgd_solver.cpp:136] Iteration 52100, lr = 0.00674375, m = 0.9
I0802 07:03:20.012018 18636 solver.cpp:353] Iteration 52200 (7.18796 iter/s, 13.9121s/100 iter), loss = 1.15975
I0802 07:03:20.012042 18636 solver.cpp:375]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0802 07:03:20.012046 18636 sgd_solver.cpp:136] Iteration 52200, lr = 0.0067375, m = 0.9
I0802 07:03:33.993377 18636 solver.cpp:353] Iteration 52300 (7.15258 iter/s, 13.981s/100 iter), loss = 1.56232
I0802 07:03:33.993407 18636 solver.cpp:375]     Train net output #0: loss = 1.73745 (* 1 = 1.73745 loss)
I0802 07:03:33.993412 18636 sgd_solver.cpp:136] Iteration 52300, lr = 0.00673125, m = 0.9
I0802 07:03:47.896731 18636 solver.cpp:353] Iteration 52400 (7.19271 iter/s, 13.903s/100 iter), loss = 1.19491
I0802 07:03:47.896808 18636 solver.cpp:375]     Train net output #0: loss = 1.24251 (* 1 = 1.24251 loss)
I0802 07:03:47.896821 18636 sgd_solver.cpp:136] Iteration 52400, lr = 0.006725, m = 0.9
I0802 07:04:01.850445 18636 solver.cpp:353] Iteration 52500 (7.16675 iter/s, 13.9533s/100 iter), loss = 1.34499
I0802 07:04:01.850540 18636 solver.cpp:375]     Train net output #0: loss = 1.02749 (* 1 = 1.02749 loss)
I0802 07:04:01.850560 18636 sgd_solver.cpp:136] Iteration 52500, lr = 0.00671875, m = 0.9
I0802 07:04:15.795472 18636 solver.cpp:353] Iteration 52600 (7.17121 iter/s, 13.9446s/100 iter), loss = 1.14722
I0802 07:04:15.795542 18636 solver.cpp:375]     Train net output #0: loss = 1.29363 (* 1 = 1.29363 loss)
I0802 07:04:15.795554 18636 sgd_solver.cpp:136] Iteration 52600, lr = 0.0067125, m = 0.9
I0802 07:04:29.791151 18636 solver.cpp:353] Iteration 52700 (7.14525 iter/s, 13.9953s/100 iter), loss = 1.05876
I0802 07:04:29.791239 18636 solver.cpp:375]     Train net output #0: loss = 0.923927 (* 1 = 0.923927 loss)
I0802 07:04:29.791245 18636 sgd_solver.cpp:136] Iteration 52700, lr = 0.00670625, m = 0.9
I0802 07:04:43.743845 18636 solver.cpp:353] Iteration 52800 (7.16727 iter/s, 13.9523s/100 iter), loss = 1.73719
I0802 07:04:43.743870 18636 solver.cpp:375]     Train net output #0: loss = 1.32157 (* 1 = 1.32157 loss)
I0802 07:04:43.743875 18636 sgd_solver.cpp:136] Iteration 52800, lr = 0.0067, m = 0.9
I0802 07:04:57.645217 18636 solver.cpp:353] Iteration 52900 (7.19373 iter/s, 13.901s/100 iter), loss = 1.38644
I0802 07:04:57.645248 18636 solver.cpp:375]     Train net output #0: loss = 1.38102 (* 1 = 1.38102 loss)
I0802 07:04:57.645254 18636 sgd_solver.cpp:136] Iteration 52900, lr = 0.00669375, m = 0.9
I0802 07:05:11.505561 18636 solver.cpp:404] Sparsity after update:
I0802 07:05:11.516348 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:05:11.516369 18636 net.cpp:2270] conv1a_param_0(0.159) 
I0802 07:05:11.516378 18636 net.cpp:2270] conv1b_param_0(0.319) 
I0802 07:05:11.516381 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:05:11.516384 18636 net.cpp:2270] res2a_branch2a_param_0(0.33) 
I0802 07:05:11.516394 18636 net.cpp:2270] res2a_branch2b_param_0(0.326) 
I0802 07:05:11.516400 18636 net.cpp:2270] res3a_branch2a_param_0(0.33) 
I0802 07:05:11.516405 18636 net.cpp:2270] res3a_branch2b_param_0(0.33) 
I0802 07:05:11.516408 18636 net.cpp:2270] res4a_branch2a_param_0(0.33) 
I0802 07:05:11.516412 18636 net.cpp:2270] res4a_branch2b_param_0(0.33) 
I0802 07:05:11.516415 18636 net.cpp:2270] res5a_branch2a_param_0(0.33) 
I0802 07:05:11.516419 18636 net.cpp:2270] res5a_branch2b_param_0(0.33) 
I0802 07:05:11.516424 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (776264/2.86678e+06) 0.271
I0802 07:05:11.647892 18661 solver.cpp:450] Finding and applying sparsity: 0.34
I0802 07:05:35.421032 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:05:35.422912 18636 solver.cpp:353] Iteration 53000 (2.64714 iter/s, 37.7767s/100 iter), loss = 1.3688
I0802 07:05:35.422931 18636 solver.cpp:375]     Train net output #0: loss = 1.2552 (* 1 = 1.2552 loss)
I0802 07:05:35.422937 18636 sgd_solver.cpp:136] Iteration 53000, lr = 0.0066875, m = 0.9
I0802 07:05:49.760010 18636 solver.cpp:353] Iteration 53100 (6.9751 iter/s, 14.3367s/100 iter), loss = 1.37704
I0802 07:05:49.760112 18636 solver.cpp:375]     Train net output #0: loss = 1.38668 (* 1 = 1.38668 loss)
I0802 07:05:49.760119 18636 sgd_solver.cpp:136] Iteration 53100, lr = 0.00668125, m = 0.9
I0802 07:06:03.750648 18636 solver.cpp:353] Iteration 53200 (7.14783 iter/s, 13.9903s/100 iter), loss = 1.31814
I0802 07:06:03.750895 18636 solver.cpp:375]     Train net output #0: loss = 1.35946 (* 1 = 1.35946 loss)
I0802 07:06:03.751005 18636 sgd_solver.cpp:136] Iteration 53200, lr = 0.006675, m = 0.9
I0802 07:06:17.688721 18636 solver.cpp:353] Iteration 53300 (7.17479 iter/s, 13.9377s/100 iter), loss = 1.26445
I0802 07:06:17.688747 18636 solver.cpp:375]     Train net output #0: loss = 1.13752 (* 1 = 1.13752 loss)
I0802 07:06:17.688752 18636 sgd_solver.cpp:136] Iteration 53300, lr = 0.00666875, m = 0.9
I0802 07:06:31.538981 18636 solver.cpp:353] Iteration 53400 (7.22028 iter/s, 13.8499s/100 iter), loss = 1.6693
I0802 07:06:31.539044 18636 solver.cpp:375]     Train net output #0: loss = 1.75626 (* 1 = 1.75626 loss)
I0802 07:06:31.539052 18636 sgd_solver.cpp:136] Iteration 53400, lr = 0.0066625, m = 0.9
I0802 07:06:45.611104 18636 solver.cpp:353] Iteration 53500 (7.10644 iter/s, 14.0717s/100 iter), loss = 1.26637
I0802 07:06:45.611130 18636 solver.cpp:375]     Train net output #0: loss = 1.47593 (* 1 = 1.47593 loss)
I0802 07:06:45.611135 18636 sgd_solver.cpp:136] Iteration 53500, lr = 0.00665625, m = 0.9
I0802 07:06:59.581105 18636 solver.cpp:353] Iteration 53600 (7.15839 iter/s, 13.9696s/100 iter), loss = 1.68158
I0802 07:06:59.581130 18636 solver.cpp:375]     Train net output #0: loss = 1.72183 (* 1 = 1.72183 loss)
I0802 07:06:59.581135 18636 sgd_solver.cpp:136] Iteration 53600, lr = 0.00665, m = 0.9
I0802 07:07:13.554539 18636 solver.cpp:353] Iteration 53700 (7.15663 iter/s, 13.9731s/100 iter), loss = 1.29332
I0802 07:07:13.554605 18636 solver.cpp:375]     Train net output #0: loss = 1.2885 (* 1 = 1.2885 loss)
I0802 07:07:13.554611 18636 sgd_solver.cpp:136] Iteration 53700, lr = 0.00664375, m = 0.9
I0802 07:07:27.582221 18636 solver.cpp:353] Iteration 53800 (7.12896 iter/s, 14.0273s/100 iter), loss = 1.42862
I0802 07:07:27.582247 18636 solver.cpp:375]     Train net output #0: loss = 1.82077 (* 1 = 1.82077 loss)
I0802 07:07:27.582252 18636 sgd_solver.cpp:136] Iteration 53800, lr = 0.0066375, m = 0.9
I0802 07:07:41.559911 18636 solver.cpp:353] Iteration 53900 (7.15445 iter/s, 13.9773s/100 iter), loss = 1.26151
I0802 07:07:41.560009 18636 solver.cpp:375]     Train net output #0: loss = 1.17131 (* 1 = 1.17131 loss)
I0802 07:07:41.560030 18636 sgd_solver.cpp:136] Iteration 53900, lr = 0.00663125, m = 0.9
I0802 07:07:55.302817 18636 solver.cpp:404] Sparsity after update:
I0802 07:07:55.308001 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:07:55.308013 18636 net.cpp:2270] conv1a_param_0(0.159) 
I0802 07:07:55.308022 18636 net.cpp:2270] conv1b_param_0(0.333) 
I0802 07:07:55.308024 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:07:55.308028 18636 net.cpp:2270] res2a_branch2a_param_0(0.337) 
I0802 07:07:55.308032 18636 net.cpp:2270] res2a_branch2b_param_0(0.333) 
I0802 07:07:55.308034 18636 net.cpp:2270] res3a_branch2a_param_0(0.339) 
I0802 07:07:55.308037 18636 net.cpp:2270] res3a_branch2b_param_0(0.337) 
I0802 07:07:55.308040 18636 net.cpp:2270] res4a_branch2a_param_0(0.339) 
I0802 07:07:55.308043 18636 net.cpp:2270] res4a_branch2b_param_0(0.339) 
I0802 07:07:55.308046 18636 net.cpp:2270] res5a_branch2a_param_0(0.34) 
I0802 07:07:55.308049 18636 net.cpp:2270] res5a_branch2b_param_0(0.339) 
I0802 07:07:55.308053 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (798889/2.86678e+06) 0.279
I0802 07:07:55.308063 18636 solver.cpp:550] Iteration 54000, Testing net (#0)
I0802 07:08:01.456009 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:08:14.873641 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.563353
I0802 07:08:14.873693 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.801762
I0802 07:08:14.873702 18636 solver.cpp:635]     Test net output #2: loss = 1.91771 (* 1 = 1.91771 loss)
I0802 07:08:14.873730 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5651s
I0802 07:08:15.025360 18661 solver.cpp:450] Finding and applying sparsity: 0.35
I0802 07:08:39.018271 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:08:39.020277 18636 solver.cpp:353] Iteration 54000 (1.74038 iter/s, 57.4588s/100 iter), loss = 1.41918
I0802 07:08:39.020298 18636 solver.cpp:375]     Train net output #0: loss = 1.563 (* 1 = 1.563 loss)
I0802 07:08:39.020303 18636 sgd_solver.cpp:136] Iteration 54000, lr = 0.006625, m = 0.9
I0802 07:08:53.371479 18636 solver.cpp:353] Iteration 54100 (6.96825 iter/s, 14.3508s/100 iter), loss = 1.46314
I0802 07:08:53.371506 18636 solver.cpp:375]     Train net output #0: loss = 1.79181 (* 1 = 1.79181 loss)
I0802 07:08:53.371512 18636 sgd_solver.cpp:136] Iteration 54100, lr = 0.00661875, m = 0.9
I0802 07:09:07.245044 18636 solver.cpp:353] Iteration 54200 (7.20815 iter/s, 13.8732s/100 iter), loss = 1.64423
I0802 07:09:07.245074 18636 solver.cpp:375]     Train net output #0: loss = 1.28533 (* 1 = 1.28533 loss)
I0802 07:09:07.245080 18636 sgd_solver.cpp:136] Iteration 54200, lr = 0.0066125, m = 0.9
I0802 07:09:21.184610 18636 solver.cpp:353] Iteration 54300 (7.17402 iter/s, 13.9392s/100 iter), loss = 1.3993
I0802 07:09:21.184743 18636 solver.cpp:375]     Train net output #0: loss = 1.31292 (* 1 = 1.31292 loss)
I0802 07:09:21.184765 18636 sgd_solver.cpp:136] Iteration 54300, lr = 0.00660625, m = 0.9
I0802 07:09:35.067245 18636 solver.cpp:353] Iteration 54400 (7.20344 iter/s, 13.8823s/100 iter), loss = 1.57866
I0802 07:09:35.067358 18636 solver.cpp:375]     Train net output #0: loss = 1.49391 (* 1 = 1.49391 loss)
I0802 07:09:35.067378 18636 sgd_solver.cpp:136] Iteration 54400, lr = 0.0066, m = 0.9
I0802 07:09:48.981613 18636 solver.cpp:353] Iteration 54500 (7.18701 iter/s, 13.914s/100 iter), loss = 1.55979
I0802 07:09:48.981643 18636 solver.cpp:375]     Train net output #0: loss = 1.88824 (* 1 = 1.88824 loss)
I0802 07:09:48.981647 18636 sgd_solver.cpp:136] Iteration 54500, lr = 0.00659375, m = 0.9
I0802 07:10:02.885670 18636 solver.cpp:353] Iteration 54600 (7.19234 iter/s, 13.9037s/100 iter), loss = 1.16714
I0802 07:10:02.885929 18636 solver.cpp:375]     Train net output #0: loss = 1.23169 (* 1 = 1.23169 loss)
I0802 07:10:02.886037 18636 sgd_solver.cpp:136] Iteration 54600, lr = 0.0065875, m = 0.9
I0802 07:10:16.838683 18636 solver.cpp:353] Iteration 54700 (7.16711 iter/s, 13.9526s/100 iter), loss = 1.50748
I0802 07:10:16.838714 18636 solver.cpp:375]     Train net output #0: loss = 1.6616 (* 1 = 1.6616 loss)
I0802 07:10:16.838721 18636 sgd_solver.cpp:136] Iteration 54700, lr = 0.00658125, m = 0.9
I0802 07:10:30.678393 18636 solver.cpp:353] Iteration 54800 (7.22578 iter/s, 13.8393s/100 iter), loss = 1.27701
I0802 07:10:30.678426 18636 solver.cpp:375]     Train net output #0: loss = 1.37952 (* 1 = 1.37952 loss)
I0802 07:10:30.678432 18636 sgd_solver.cpp:136] Iteration 54800, lr = 0.006575, m = 0.9
I0802 07:10:44.541751 18636 solver.cpp:353] Iteration 54900 (7.21345 iter/s, 13.863s/100 iter), loss = 1.81978
I0802 07:10:44.541862 18636 solver.cpp:375]     Train net output #0: loss = 1.86716 (* 1 = 1.86716 loss)
I0802 07:10:44.541882 18636 sgd_solver.cpp:136] Iteration 54900, lr = 0.00656875, m = 0.9
I0802 07:10:58.307562 18636 solver.cpp:404] Sparsity after update:
I0802 07:10:58.318047 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:10:58.318061 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:10:58.318069 18636 net.cpp:2270] conv1b_param_0(0.347) 
I0802 07:10:58.318073 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:10:58.318079 18636 net.cpp:2270] res2a_branch2a_param_0(0.347) 
I0802 07:10:58.318084 18636 net.cpp:2270] res2a_branch2b_param_0(0.347) 
I0802 07:10:58.318086 18636 net.cpp:2270] res3a_branch2a_param_0(0.349) 
I0802 07:10:58.318089 18636 net.cpp:2270] res3a_branch2b_param_0(0.347) 
I0802 07:10:58.318092 18636 net.cpp:2270] res4a_branch2a_param_0(0.35) 
I0802 07:10:58.318096 18636 net.cpp:2270] res4a_branch2b_param_0(0.349) 
I0802 07:10:58.318100 18636 net.cpp:2270] res5a_branch2a_param_0(0.35) 
I0802 07:10:58.318104 18636 net.cpp:2270] res5a_branch2b_param_0(0.35) 
I0802 07:10:58.318109 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (822947/2.86678e+06) 0.287
I0802 07:10:58.446967 18661 solver.cpp:450] Finding and applying sparsity: 0.36
I0802 07:11:22.830132 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:11:22.832044 18636 solver.cpp:353] Iteration 55000 (2.6117 iter/s, 38.2893s/100 iter), loss = 1.21977
I0802 07:11:22.832063 18636 solver.cpp:375]     Train net output #0: loss = 1.47755 (* 1 = 1.47755 loss)
I0802 07:11:22.832072 18636 sgd_solver.cpp:136] Iteration 55000, lr = 0.0065625, m = 0.9
I0802 07:11:37.284111 18636 solver.cpp:353] Iteration 55100 (6.91962 iter/s, 14.4517s/100 iter), loss = 1.47629
I0802 07:11:37.284142 18636 solver.cpp:375]     Train net output #0: loss = 1.16382 (* 1 = 1.16382 loss)
I0802 07:11:37.284147 18636 sgd_solver.cpp:136] Iteration 55100, lr = 0.00655625, m = 0.9
I0802 07:11:51.161692 18636 solver.cpp:353] Iteration 55200 (7.20607 iter/s, 13.8772s/100 iter), loss = 1.16159
I0802 07:11:51.161720 18636 solver.cpp:375]     Train net output #0: loss = 1.43692 (* 1 = 1.43692 loss)
I0802 07:11:51.161723 18636 sgd_solver.cpp:136] Iteration 55200, lr = 0.00655, m = 0.9
I0802 07:12:05.081414 18636 solver.cpp:353] Iteration 55300 (7.18425 iter/s, 13.9193s/100 iter), loss = 1.27465
I0802 07:12:05.081482 18636 solver.cpp:375]     Train net output #0: loss = 1.34837 (* 1 = 1.34837 loss)
I0802 07:12:05.081488 18636 sgd_solver.cpp:136] Iteration 55300, lr = 0.00654375, m = 0.9
I0802 07:12:18.982712 18636 solver.cpp:353] Iteration 55400 (7.19377 iter/s, 13.9009s/100 iter), loss = 1.64487
I0802 07:12:18.982738 18636 solver.cpp:375]     Train net output #0: loss = 1.67845 (* 1 = 1.67845 loss)
I0802 07:12:18.982743 18636 sgd_solver.cpp:136] Iteration 55400, lr = 0.0065375, m = 0.9
I0802 07:12:33.156852 18636 solver.cpp:353] Iteration 55500 (7.05529 iter/s, 14.1738s/100 iter), loss = 1.33269
I0802 07:12:33.156914 18636 solver.cpp:375]     Train net output #0: loss = 1.19603 (* 1 = 1.19603 loss)
I0802 07:12:33.156930 18636 sgd_solver.cpp:136] Iteration 55500, lr = 0.00653125, m = 0.9
I0802 07:12:47.185145 18636 solver.cpp:353] Iteration 55600 (7.12864 iter/s, 14.0279s/100 iter), loss = 1.65497
I0802 07:12:47.186980 18636 solver.cpp:375]     Train net output #0: loss = 1.69117 (* 1 = 1.69117 loss)
I0802 07:12:47.186990 18636 sgd_solver.cpp:136] Iteration 55600, lr = 0.006525, m = 0.9
I0802 07:13:01.106055 18636 solver.cpp:353] Iteration 55700 (7.18363 iter/s, 13.9205s/100 iter), loss = 1.56877
I0802 07:13:01.106081 18636 solver.cpp:375]     Train net output #0: loss = 1.77582 (* 1 = 1.77582 loss)
I0802 07:13:01.106086 18636 sgd_solver.cpp:136] Iteration 55700, lr = 0.00651875, m = 0.9
I0802 07:13:15.008054 18636 solver.cpp:353] Iteration 55800 (7.19341 iter/s, 13.9016s/100 iter), loss = 1.47388
I0802 07:13:15.008081 18636 solver.cpp:375]     Train net output #0: loss = 1.91846 (* 1 = 1.91846 loss)
I0802 07:13:15.008085 18636 sgd_solver.cpp:136] Iteration 55800, lr = 0.0065125, m = 0.9
I0802 07:13:28.984356 18636 solver.cpp:353] Iteration 55900 (7.15516 iter/s, 13.9759s/100 iter), loss = 1.3096
I0802 07:13:28.984428 18636 solver.cpp:375]     Train net output #0: loss = 1.29841 (* 1 = 1.29841 loss)
I0802 07:13:28.984433 18636 sgd_solver.cpp:136] Iteration 55900, lr = 0.00650625, m = 0.9
I0802 07:13:42.822312 18636 solver.cpp:404] Sparsity after update:
I0802 07:13:42.826253 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:13:42.826263 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:13:42.826272 18636 net.cpp:2270] conv1b_param_0(0.347) 
I0802 07:13:42.826275 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:13:42.826285 18636 net.cpp:2270] res2a_branch2a_param_0(0.358) 
I0802 07:13:42.826292 18636 net.cpp:2270] res2a_branch2b_param_0(0.354) 
I0802 07:13:42.826297 18636 net.cpp:2270] res3a_branch2a_param_0(0.359) 
I0802 07:13:42.826301 18636 net.cpp:2270] res3a_branch2b_param_0(0.358) 
I0802 07:13:42.826305 18636 net.cpp:2270] res4a_branch2a_param_0(0.359) 
I0802 07:13:42.826309 18636 net.cpp:2270] res4a_branch2b_param_0(0.359) 
I0802 07:13:42.826313 18636 net.cpp:2270] res5a_branch2a_param_0(0.36) 
I0802 07:13:42.826318 18636 net.cpp:2270] res5a_branch2b_param_0(0.359) 
I0802 07:13:42.826321 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (846122/2.86678e+06) 0.295
I0802 07:13:42.826333 18636 solver.cpp:550] Iteration 56000, Testing net (#0)
I0802 07:14:02.465950 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.570411
I0802 07:14:02.465999 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.804703
I0802 07:14:02.466008 18636 solver.cpp:635]     Test net output #2: loss = 1.88501 (* 1 = 1.88501 loss)
I0802 07:14:02.466029 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6392s
I0802 07:14:02.602612 18661 solver.cpp:450] Finding and applying sparsity: 0.37
I0802 07:14:27.401006 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:14:27.402935 18636 solver.cpp:353] Iteration 56000 (1.71183 iter/s, 58.417s/100 iter), loss = 1.27009
I0802 07:14:27.402964 18636 solver.cpp:375]     Train net output #0: loss = 1.18265 (* 1 = 1.18265 loss)
I0802 07:14:27.402971 18636 sgd_solver.cpp:136] Iteration 56000, lr = 0.0065, m = 0.9
I0802 07:14:41.788522 18636 solver.cpp:353] Iteration 56100 (6.95159 iter/s, 14.3852s/100 iter), loss = 1.44743
I0802 07:14:41.788604 18636 solver.cpp:375]     Train net output #0: loss = 1.75094 (* 1 = 1.75094 loss)
I0802 07:14:41.788612 18636 sgd_solver.cpp:136] Iteration 56100, lr = 0.00649375, m = 0.9
I0802 07:14:55.691238 18636 solver.cpp:353] Iteration 56200 (7.19304 iter/s, 13.9023s/100 iter), loss = 1.35106
I0802 07:14:55.691268 18636 solver.cpp:375]     Train net output #0: loss = 1.58864 (* 1 = 1.58864 loss)
I0802 07:14:55.691272 18636 sgd_solver.cpp:136] Iteration 56200, lr = 0.0064875, m = 0.9
I0802 07:15:09.641079 18636 solver.cpp:353] Iteration 56300 (7.16874 iter/s, 13.9495s/100 iter), loss = 1.53019
I0802 07:15:09.641105 18636 solver.cpp:375]     Train net output #0: loss = 1.4709 (* 1 = 1.4709 loss)
I0802 07:15:09.641110 18636 sgd_solver.cpp:136] Iteration 56300, lr = 0.00648125, m = 0.9
I0802 07:15:23.571559 18636 solver.cpp:353] Iteration 56400 (7.1787 iter/s, 13.9301s/100 iter), loss = 1.43427
I0802 07:15:23.571631 18636 solver.cpp:375]     Train net output #0: loss = 1.12767 (* 1 = 1.12767 loss)
I0802 07:15:23.571638 18636 sgd_solver.cpp:136] Iteration 56400, lr = 0.006475, m = 0.9
I0802 07:15:37.484747 18636 solver.cpp:353] Iteration 56500 (7.18762 iter/s, 13.9128s/100 iter), loss = 1.19695
I0802 07:15:37.484776 18636 solver.cpp:375]     Train net output #0: loss = 1.23702 (* 1 = 1.23702 loss)
I0802 07:15:37.484783 18636 sgd_solver.cpp:136] Iteration 56500, lr = 0.00646875, m = 0.9
I0802 07:15:51.387397 18636 solver.cpp:353] Iteration 56600 (7.19307 iter/s, 13.9023s/100 iter), loss = 1.17161
I0802 07:15:51.387428 18636 solver.cpp:375]     Train net output #0: loss = 1.15145 (* 1 = 1.15145 loss)
I0802 07:15:51.387435 18636 sgd_solver.cpp:136] Iteration 56600, lr = 0.0064625, m = 0.9
I0802 07:16:05.368883 18636 solver.cpp:353] Iteration 56700 (7.15251 iter/s, 13.9811s/100 iter), loss = 1.56862
I0802 07:16:05.369055 18636 solver.cpp:375]     Train net output #0: loss = 2.0181 (* 1 = 2.0181 loss)
I0802 07:16:05.369088 18636 sgd_solver.cpp:136] Iteration 56700, lr = 0.00645625, m = 0.9
I0802 07:16:19.451378 18636 solver.cpp:353] Iteration 56800 (7.10121 iter/s, 14.0821s/100 iter), loss = 1.52177
I0802 07:16:19.451406 18636 solver.cpp:375]     Train net output #0: loss = 1.73733 (* 1 = 1.73733 loss)
I0802 07:16:19.451411 18636 sgd_solver.cpp:136] Iteration 56800, lr = 0.00645, m = 0.9
I0802 07:16:33.338721 18636 solver.cpp:353] Iteration 56900 (7.201 iter/s, 13.887s/100 iter), loss = 1.29799
I0802 07:16:33.338747 18636 solver.cpp:375]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0802 07:16:33.338750 18636 sgd_solver.cpp:136] Iteration 56900, lr = 0.00644375, m = 0.9
I0802 07:16:47.146754 18636 solver.cpp:404] Sparsity after update:
I0802 07:16:47.157187 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:16:47.157202 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:16:47.157212 18636 net.cpp:2270] conv1b_param_0(0.361) 
I0802 07:16:47.157214 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:16:47.157218 18636 net.cpp:2270] res2a_branch2a_param_0(0.368) 
I0802 07:16:47.157222 18636 net.cpp:2270] res2a_branch2b_param_0(0.368) 
I0802 07:16:47.157224 18636 net.cpp:2270] res3a_branch2a_param_0(0.37) 
I0802 07:16:47.157227 18636 net.cpp:2270] res3a_branch2b_param_0(0.368) 
I0802 07:16:47.157230 18636 net.cpp:2270] res4a_branch2a_param_0(0.37) 
I0802 07:16:47.157234 18636 net.cpp:2270] res4a_branch2b_param_0(0.37) 
I0802 07:16:47.157236 18636 net.cpp:2270] res5a_branch2a_param_0(0.37) 
I0802 07:16:47.157240 18636 net.cpp:2270] res5a_branch2b_param_0(0.37) 
I0802 07:16:47.157243 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (870155/2.86678e+06) 0.304
I0802 07:16:47.290729 18661 solver.cpp:450] Finding and applying sparsity: 0.38
I0802 07:17:12.588165 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:17:12.590158 18636 solver.cpp:353] Iteration 57000 (2.54775 iter/s, 39.2504s/100 iter), loss = 1.28647
I0802 07:17:12.590198 18636 solver.cpp:375]     Train net output #0: loss = 1.34178 (* 1 = 1.34178 loss)
I0802 07:17:12.590207 18636 sgd_solver.cpp:136] Iteration 57000, lr = 0.0064375, m = 0.9
I0802 07:17:27.065862 18636 solver.cpp:353] Iteration 57100 (6.90832 iter/s, 14.4753s/100 iter), loss = 1.49189
I0802 07:17:27.065965 18636 solver.cpp:375]     Train net output #0: loss = 1.29164 (* 1 = 1.29164 loss)
I0802 07:17:27.065984 18636 sgd_solver.cpp:136] Iteration 57100, lr = 0.00643125, m = 0.9
I0802 07:17:40.976732 18636 solver.cpp:353] Iteration 57200 (7.18882 iter/s, 13.9105s/100 iter), loss = 1.33051
I0802 07:17:40.976758 18636 solver.cpp:375]     Train net output #0: loss = 1.22851 (* 1 = 1.22851 loss)
I0802 07:17:40.976763 18636 sgd_solver.cpp:136] Iteration 57200, lr = 0.006425, m = 0.9
I0802 07:17:54.974357 18636 solver.cpp:353] Iteration 57300 (7.14427 iter/s, 13.9972s/100 iter), loss = 1.32794
I0802 07:17:54.974412 18636 solver.cpp:375]     Train net output #0: loss = 1.37752 (* 1 = 1.37752 loss)
I0802 07:17:54.974424 18636 sgd_solver.cpp:136] Iteration 57300, lr = 0.00641875, m = 0.9
I0802 07:18:08.856353 18636 solver.cpp:353] Iteration 57400 (7.20377 iter/s, 13.8816s/100 iter), loss = 1.43544
I0802 07:18:08.857069 18636 solver.cpp:375]     Train net output #0: loss = 1.32185 (* 1 = 1.32185 loss)
I0802 07:18:08.857082 18636 sgd_solver.cpp:136] Iteration 57400, lr = 0.0064125, m = 0.9
I0802 07:18:22.826472 18636 solver.cpp:353] Iteration 57500 (7.15833 iter/s, 13.9697s/100 iter), loss = 1.01827
I0802 07:18:22.826527 18636 solver.cpp:375]     Train net output #0: loss = 0.701854 (* 1 = 0.701854 loss)
I0802 07:18:22.826539 18636 sgd_solver.cpp:136] Iteration 57500, lr = 0.00640625, m = 0.9
I0802 07:18:36.797045 18636 solver.cpp:353] Iteration 57600 (7.1581 iter/s, 13.9702s/100 iter), loss = 1.30358
I0802 07:18:36.797072 18636 solver.cpp:375]     Train net output #0: loss = 1.48649 (* 1 = 1.48649 loss)
I0802 07:18:36.797078 18636 sgd_solver.cpp:136] Iteration 57600, lr = 0.0064, m = 0.9
I0802 07:18:50.727118 18636 solver.cpp:353] Iteration 57700 (7.17891 iter/s, 13.9297s/100 iter), loss = 1.34477
I0802 07:18:50.727237 18636 solver.cpp:375]     Train net output #0: loss = 1.43541 (* 1 = 1.43541 loss)
I0802 07:18:50.727244 18636 sgd_solver.cpp:136] Iteration 57700, lr = 0.00639375, m = 0.9
I0802 07:19:04.665344 18636 solver.cpp:353] Iteration 57800 (7.17471 iter/s, 13.9378s/100 iter), loss = 1.6367
I0802 07:19:04.665372 18636 solver.cpp:375]     Train net output #0: loss = 1.57905 (* 1 = 1.57905 loss)
I0802 07:19:04.665376 18636 sgd_solver.cpp:136] Iteration 57800, lr = 0.0063875, m = 0.9
I0802 07:19:18.631595 18636 solver.cpp:353] Iteration 57900 (7.16031 iter/s, 13.9659s/100 iter), loss = 1.56533
I0802 07:19:18.631664 18636 solver.cpp:375]     Train net output #0: loss = 1.47951 (* 1 = 1.47951 loss)
I0802 07:19:18.631676 18636 sgd_solver.cpp:136] Iteration 57900, lr = 0.00638125, m = 0.9
I0802 07:19:32.496054 18636 solver.cpp:404] Sparsity after update:
I0802 07:19:32.502087 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:19:32.502100 18636 net.cpp:2270] conv1a_param_0(0.185) 
I0802 07:19:32.502110 18636 net.cpp:2270] conv1b_param_0(0.375) 
I0802 07:19:32.502113 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:19:32.502116 18636 net.cpp:2270] res2a_branch2a_param_0(0.378) 
I0802 07:19:32.502120 18636 net.cpp:2270] res2a_branch2b_param_0(0.375) 
I0802 07:19:32.502123 18636 net.cpp:2270] res3a_branch2a_param_0(0.378) 
I0802 07:19:32.502127 18636 net.cpp:2270] res3a_branch2b_param_0(0.378) 
I0802 07:19:32.502130 18636 net.cpp:2270] res4a_branch2a_param_0(0.379) 
I0802 07:19:32.502133 18636 net.cpp:2270] res4a_branch2b_param_0(0.378) 
I0802 07:19:32.502136 18636 net.cpp:2270] res5a_branch2a_param_0(0.38) 
I0802 07:19:32.502140 18636 net.cpp:2270] res5a_branch2b_param_0(0.379) 
I0802 07:19:32.502144 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (892998/2.86678e+06) 0.311
I0802 07:19:32.502156 18636 solver.cpp:550] Iteration 58000, Testing net (#0)
I0802 07:19:52.364909 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.571883
I0802 07:19:52.364931 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.80288
I0802 07:19:52.364936 18636 solver.cpp:635]     Test net output #2: loss = 1.89267 (* 1 = 1.89267 loss)
I0802 07:19:52.364965 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8623s
I0802 07:19:52.510557 18661 solver.cpp:450] Finding and applying sparsity: 0.39
I0802 07:20:17.867076 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:20:17.869050 18636 solver.cpp:353] Iteration 58000 (1.68817 iter/s, 59.2359s/100 iter), loss = 1.9683
I0802 07:20:17.869071 18636 solver.cpp:375]     Train net output #0: loss = 1.64893 (* 1 = 1.64893 loss)
I0802 07:20:17.869076 18636 sgd_solver.cpp:136] Iteration 58000, lr = 0.006375, m = 0.9
I0802 07:20:32.372722 18636 solver.cpp:353] Iteration 58100 (6.895 iter/s, 14.5033s/100 iter), loss = 1.11556
I0802 07:20:32.372751 18636 solver.cpp:375]     Train net output #0: loss = 1.34231 (* 1 = 1.34231 loss)
I0802 07:20:32.372756 18636 sgd_solver.cpp:136] Iteration 58100, lr = 0.00636875, m = 0.9
I0802 07:20:46.368193 18636 solver.cpp:353] Iteration 58200 (7.14536 iter/s, 13.9951s/100 iter), loss = 1.48174
I0802 07:20:46.368221 18636 solver.cpp:375]     Train net output #0: loss = 1.41853 (* 1 = 1.41853 loss)
I0802 07:20:46.368227 18636 sgd_solver.cpp:136] Iteration 58200, lr = 0.0063625, m = 0.9
I0802 07:21:00.261178 18636 solver.cpp:353] Iteration 58300 (7.19807 iter/s, 13.8926s/100 iter), loss = 2.0441
I0802 07:21:00.261286 18636 solver.cpp:375]     Train net output #0: loss = 1.95299 (* 1 = 1.95299 loss)
I0802 07:21:00.261301 18636 sgd_solver.cpp:136] Iteration 58300, lr = 0.00635625, m = 0.9
I0802 07:21:14.171640 18636 solver.cpp:353] Iteration 58400 (7.18903 iter/s, 13.9101s/100 iter), loss = 1.54882
I0802 07:21:14.171674 18636 solver.cpp:375]     Train net output #0: loss = 1.74634 (* 1 = 1.74634 loss)
I0802 07:21:14.171679 18636 sgd_solver.cpp:136] Iteration 58400, lr = 0.00635, m = 0.9
I0802 07:21:28.137908 18636 solver.cpp:353] Iteration 58500 (7.16031 iter/s, 13.9659s/100 iter), loss = 1.73519
I0802 07:21:28.137935 18636 solver.cpp:375]     Train net output #0: loss = 1.39208 (* 1 = 1.39208 loss)
I0802 07:21:28.137940 18636 sgd_solver.cpp:136] Iteration 58500, lr = 0.00634375, m = 0.9
I0802 07:21:42.054123 18636 solver.cpp:353] Iteration 58600 (7.18606 iter/s, 13.9158s/100 iter), loss = 1.45902
I0802 07:21:42.054409 18636 solver.cpp:375]     Train net output #0: loss = 1.50557 (* 1 = 1.50557 loss)
I0802 07:21:42.054414 18636 sgd_solver.cpp:136] Iteration 58600, lr = 0.0063375, m = 0.9
I0802 07:21:56.000000 18636 solver.cpp:353] Iteration 58700 (7.17077 iter/s, 13.9455s/100 iter), loss = 1.35255
I0802 07:21:56.000032 18636 solver.cpp:375]     Train net output #0: loss = 1.13265 (* 1 = 1.13265 loss)
I0802 07:21:56.000038 18636 sgd_solver.cpp:136] Iteration 58700, lr = 0.00633125, m = 0.9
I0802 07:22:09.907995 18636 solver.cpp:353] Iteration 58800 (7.19031 iter/s, 13.9076s/100 iter), loss = 1.7962
I0802 07:22:09.908023 18636 solver.cpp:375]     Train net output #0: loss = 1.59622 (* 1 = 1.59622 loss)
I0802 07:22:09.908027 18636 sgd_solver.cpp:136] Iteration 58800, lr = 0.006325, m = 0.9
I0802 07:22:23.843312 18636 solver.cpp:353] Iteration 58900 (7.17621 iter/s, 13.9349s/100 iter), loss = 1.18926
I0802 07:22:23.843391 18636 solver.cpp:375]     Train net output #0: loss = 1.10351 (* 1 = 1.10351 loss)
I0802 07:22:23.843400 18636 sgd_solver.cpp:136] Iteration 58900, lr = 0.00631875, m = 0.9
I0802 07:22:37.648619 18636 solver.cpp:404] Sparsity after update:
I0802 07:22:37.659072 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:22:37.659088 18636 net.cpp:2270] conv1a_param_0(0.186) 
I0802 07:22:37.659097 18636 net.cpp:2270] conv1b_param_0(0.389) 
I0802 07:22:37.659101 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:22:37.659103 18636 net.cpp:2270] res2a_branch2a_param_0(0.389) 
I0802 07:22:37.659106 18636 net.cpp:2270] res2a_branch2b_param_0(0.389) 
I0802 07:22:37.659109 18636 net.cpp:2270] res3a_branch2a_param_0(0.389) 
I0802 07:22:37.659112 18636 net.cpp:2270] res3a_branch2b_param_0(0.389) 
I0802 07:22:37.659116 18636 net.cpp:2270] res4a_branch2a_param_0(0.39) 
I0802 07:22:37.659119 18636 net.cpp:2270] res4a_branch2b_param_0(0.389) 
I0802 07:22:37.659122 18636 net.cpp:2270] res5a_branch2a_param_0(0.39) 
I0802 07:22:37.659126 18636 net.cpp:2270] res5a_branch2b_param_0(0.39) 
I0802 07:22:37.659128 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (917033/2.86678e+06) 0.32
I0802 07:22:37.788271 18661 solver.cpp:450] Finding and applying sparsity: 0.4
I0802 07:23:03.504350 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:23:03.506274 18636 solver.cpp:353] Iteration 59000 (2.52131 iter/s, 39.6619s/100 iter), loss = 1.58673
I0802 07:23:03.506295 18636 solver.cpp:375]     Train net output #0: loss = 2.01155 (* 1 = 2.01155 loss)
I0802 07:23:03.506304 18636 sgd_solver.cpp:136] Iteration 59000, lr = 0.0063125, m = 0.9
I0802 07:23:17.818212 18636 solver.cpp:353] Iteration 59100 (6.98737 iter/s, 14.3115s/100 iter), loss = 1.82313
I0802 07:23:17.818236 18636 solver.cpp:375]     Train net output #0: loss = 1.41825 (* 1 = 1.41825 loss)
I0802 07:23:17.818240 18636 sgd_solver.cpp:136] Iteration 59100, lr = 0.00630625, m = 0.9
I0802 07:23:31.777236 18636 solver.cpp:353] Iteration 59200 (7.16402 iter/s, 13.9586s/100 iter), loss = 1.67298
I0802 07:23:31.777261 18636 solver.cpp:375]     Train net output #0: loss = 1.68318 (* 1 = 1.68318 loss)
I0802 07:23:31.777266 18636 sgd_solver.cpp:136] Iteration 59200, lr = 0.0063, m = 0.9
I0802 07:23:45.659060 18636 solver.cpp:353] Iteration 59300 (7.20386 iter/s, 13.8814s/100 iter), loss = 1.60126
I0802 07:23:45.659137 18636 solver.cpp:375]     Train net output #0: loss = 1.20719 (* 1 = 1.20719 loss)
I0802 07:23:45.659143 18636 sgd_solver.cpp:136] Iteration 59300, lr = 0.00629375, m = 0.9
I0802 07:23:59.618278 18636 solver.cpp:353] Iteration 59400 (7.16392 iter/s, 13.9588s/100 iter), loss = 1.79199
I0802 07:23:59.618304 18636 solver.cpp:375]     Train net output #0: loss = 1.7811 (* 1 = 1.7811 loss)
I0802 07:23:59.618309 18636 sgd_solver.cpp:136] Iteration 59400, lr = 0.0062875, m = 0.9
I0802 07:24:13.583524 18636 solver.cpp:353] Iteration 59500 (7.16083 iter/s, 13.9649s/100 iter), loss = 1.39625
I0802 07:24:13.583559 18636 solver.cpp:375]     Train net output #0: loss = 1.13655 (* 1 = 1.13655 loss)
I0802 07:24:13.583565 18636 sgd_solver.cpp:136] Iteration 59500, lr = 0.00628125, m = 0.9
I0802 07:24:25.753217 18597 data_reader.cpp:264] Starting prefetch of epoch 2
I0802 07:24:27.505362 18636 solver.cpp:353] Iteration 59600 (7.18316 iter/s, 13.9215s/100 iter), loss = 1.55658
I0802 07:24:27.505391 18636 solver.cpp:375]     Train net output #0: loss = 1.56884 (* 1 = 1.56884 loss)
I0802 07:24:27.505396 18636 sgd_solver.cpp:136] Iteration 59600, lr = 0.006275, m = 0.9
I0802 07:24:41.399225 18636 solver.cpp:353] Iteration 59700 (7.19762 iter/s, 13.8935s/100 iter), loss = 1.61404
I0802 07:24:41.399253 18636 solver.cpp:375]     Train net output #0: loss = 1.73803 (* 1 = 1.73803 loss)
I0802 07:24:41.399260 18636 sgd_solver.cpp:136] Iteration 59700, lr = 0.00626875, m = 0.9
I0802 07:24:55.377158 18636 solver.cpp:353] Iteration 59800 (7.15433 iter/s, 13.9776s/100 iter), loss = 1.42022
I0802 07:24:55.377187 18636 solver.cpp:375]     Train net output #0: loss = 1.41593 (* 1 = 1.41593 loss)
I0802 07:24:55.377192 18636 sgd_solver.cpp:136] Iteration 59800, lr = 0.0062625, m = 0.9
I0802 07:25:09.266149 18636 solver.cpp:353] Iteration 59900 (7.20014 iter/s, 13.8886s/100 iter), loss = 1.37849
I0802 07:25:09.266212 18636 solver.cpp:375]     Train net output #0: loss = 1.33551 (* 1 = 1.33551 loss)
I0802 07:25:09.266219 18636 sgd_solver.cpp:136] Iteration 59900, lr = 0.00625625, m = 0.9
I0802 07:25:23.095371 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_60000.caffemodel
I0802 07:25:23.188323 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_60000.solverstate
I0802 07:25:23.194314 18636 solver.cpp:404] Sparsity after update:
I0802 07:25:23.196532 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:25:23.196568 18636 net.cpp:2270] conv1a_param_0(0.186) 
I0802 07:25:23.196589 18636 net.cpp:2270] conv1b_param_0(0.389) 
I0802 07:25:23.196604 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:25:23.196616 18636 net.cpp:2270] res2a_branch2a_param_0(0.399) 
I0802 07:25:23.196630 18636 net.cpp:2270] res2a_branch2b_param_0(0.396) 
I0802 07:25:23.196642 18636 net.cpp:2270] res3a_branch2a_param_0(0.399) 
I0802 07:25:23.196655 18636 net.cpp:2270] res3a_branch2b_param_0(0.399) 
I0802 07:25:23.196667 18636 net.cpp:2270] res4a_branch2a_param_0(0.399) 
I0802 07:25:23.196686 18636 net.cpp:2270] res4a_branch2b_param_0(0.399) 
I0802 07:25:23.196699 18636 net.cpp:2270] res5a_branch2a_param_0(0.4) 
I0802 07:25:23.196713 18636 net.cpp:2270] res5a_branch2b_param_0(0.399) 
I0802 07:25:23.196725 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (940203/2.86678e+06) 0.328
I0802 07:25:23.196748 18636 solver.cpp:550] Iteration 60000, Testing net (#0)
I0802 07:25:34.694542 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:25:42.138268 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.573647
I0802 07:25:42.138358 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808585
I0802 07:25:42.138366 18636 solver.cpp:635]     Test net output #2: loss = 1.86643 (* 1 = 1.86643 loss)
I0802 07:25:42.138386 18636 solver.cpp:305] [MultiGPU] Tests completed in 18.9411s
I0802 07:25:42.275270 18661 solver.cpp:450] Finding and applying sparsity: 0.41
I0802 07:26:08.244931 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:26:08.246879 18636 solver.cpp:353] Iteration 60000 (1.69551 iter/s, 58.9791s/100 iter), loss = 1.6524
I0802 07:26:08.246898 18636 solver.cpp:375]     Train net output #0: loss = 2.182 (* 1 = 2.182 loss)
I0802 07:26:08.246904 18636 sgd_solver.cpp:136] Iteration 60000, lr = 0.00625, m = 0.9
I0802 07:26:22.635092 18636 solver.cpp:353] Iteration 60100 (6.95033 iter/s, 14.3878s/100 iter), loss = 1.60534
I0802 07:26:22.635159 18636 solver.cpp:375]     Train net output #0: loss = 1.46723 (* 1 = 1.46723 loss)
I0802 07:26:22.635166 18636 sgd_solver.cpp:136] Iteration 60100, lr = 0.00624375, m = 0.9
I0802 07:26:36.538588 18636 solver.cpp:353] Iteration 60200 (7.19263 iter/s, 13.9031s/100 iter), loss = 1.4236
I0802 07:26:36.538617 18636 solver.cpp:375]     Train net output #0: loss = 1.2661 (* 1 = 1.2661 loss)
I0802 07:26:36.538624 18636 sgd_solver.cpp:136] Iteration 60200, lr = 0.0062375, m = 0.9
I0802 07:26:50.515405 18636 solver.cpp:353] Iteration 60300 (7.1549 iter/s, 13.9764s/100 iter), loss = 1.30889
I0802 07:26:50.515434 18636 solver.cpp:375]     Train net output #0: loss = 1.24364 (* 1 = 1.24364 loss)
I0802 07:26:50.515439 18636 sgd_solver.cpp:136] Iteration 60300, lr = 0.00623125, m = 0.9
I0802 07:27:04.416568 18636 solver.cpp:353] Iteration 60400 (7.19384 iter/s, 13.9008s/100 iter), loss = 1.58455
I0802 07:27:04.416641 18636 solver.cpp:375]     Train net output #0: loss = 1.67805 (* 1 = 1.67805 loss)
I0802 07:27:04.416651 18636 sgd_solver.cpp:136] Iteration 60400, lr = 0.006225, m = 0.9
I0802 07:27:18.438828 18636 solver.cpp:353] Iteration 60500 (7.13171 iter/s, 14.0219s/100 iter), loss = 1.2347
I0802 07:27:18.438859 18636 solver.cpp:375]     Train net output #0: loss = 0.939074 (* 1 = 0.939074 loss)
I0802 07:27:18.438865 18636 sgd_solver.cpp:136] Iteration 60500, lr = 0.00621875, m = 0.9
I0802 07:27:32.487241 18636 solver.cpp:353] Iteration 60600 (7.11844 iter/s, 14.048s/100 iter), loss = 1.44834
I0802 07:27:32.487269 18636 solver.cpp:375]     Train net output #0: loss = 1.62215 (* 1 = 1.62215 loss)
I0802 07:27:32.487274 18636 sgd_solver.cpp:136] Iteration 60600, lr = 0.0062125, m = 0.9
I0802 07:27:46.488085 18636 solver.cpp:353] Iteration 60700 (7.14262 iter/s, 14.0005s/100 iter), loss = 1.45303
I0802 07:27:46.488144 18636 solver.cpp:375]     Train net output #0: loss = 1.37341 (* 1 = 1.37341 loss)
I0802 07:27:46.488204 18636 sgd_solver.cpp:136] Iteration 60700, lr = 0.00620625, m = 0.9
I0802 07:28:00.472434 18636 solver.cpp:353] Iteration 60800 (7.15104 iter/s, 13.984s/100 iter), loss = 1.43882
I0802 07:28:00.472465 18636 solver.cpp:375]     Train net output #0: loss = 1.62144 (* 1 = 1.62144 loss)
I0802 07:28:00.472471 18636 sgd_solver.cpp:136] Iteration 60800, lr = 0.0062, m = 0.9
I0802 07:28:14.364140 18636 solver.cpp:353] Iteration 60900 (7.19874 iter/s, 13.8913s/100 iter), loss = 1.70264
I0802 07:28:14.364166 18636 solver.cpp:375]     Train net output #0: loss = 1.58483 (* 1 = 1.58483 loss)
I0802 07:28:14.364171 18636 sgd_solver.cpp:136] Iteration 60900, lr = 0.00619375, m = 0.9
I0802 07:28:28.217761 18636 solver.cpp:404] Sparsity after update:
I0802 07:28:28.229600 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:28:28.229795 18636 net.cpp:2270] conv1a_param_0(0.199) 
I0802 07:28:28.229904 18636 net.cpp:2270] conv1b_param_0(0.403) 
I0802 07:28:28.230002 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:28:28.230093 18636 net.cpp:2270] res2a_branch2a_param_0(0.41) 
I0802 07:28:28.230185 18636 net.cpp:2270] res2a_branch2b_param_0(0.41) 
I0802 07:28:28.230279 18636 net.cpp:2270] res3a_branch2a_param_0(0.41) 
I0802 07:28:28.230376 18636 net.cpp:2270] res3a_branch2b_param_0(0.41) 
I0802 07:28:28.230469 18636 net.cpp:2270] res4a_branch2a_param_0(0.41) 
I0802 07:28:28.230554 18636 net.cpp:2270] res4a_branch2b_param_0(0.41) 
I0802 07:28:28.230638 18636 net.cpp:2270] res5a_branch2a_param_0(0.41) 
I0802 07:28:28.230721 18636 net.cpp:2270] res5a_branch2b_param_0(0.41) 
I0802 07:28:28.230811 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (964266/2.86678e+06) 0.336
I0802 07:28:28.369887 18661 solver.cpp:450] Finding and applying sparsity: 0.42
I0802 07:28:54.771836 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:28:54.773711 18636 solver.cpp:353] Iteration 61000 (2.47473 iter/s, 40.4085s/100 iter), loss = 1.51899
I0802 07:28:54.773730 18636 solver.cpp:375]     Train net output #0: loss = 1.56803 (* 1 = 1.56803 loss)
I0802 07:28:54.773736 18636 sgd_solver.cpp:136] Iteration 61000, lr = 0.0061875, m = 0.9
I0802 07:29:09.331300 18636 solver.cpp:353] Iteration 61100 (6.86946 iter/s, 14.5572s/100 iter), loss = 1.2902
I0802 07:29:09.331394 18636 solver.cpp:375]     Train net output #0: loss = 1.00981 (* 1 = 1.00981 loss)
I0802 07:29:09.331583 18636 sgd_solver.cpp:136] Iteration 61100, lr = 0.00618125, m = 0.9
I0802 07:29:23.309799 18636 solver.cpp:353] Iteration 61200 (7.15404 iter/s, 13.9781s/100 iter), loss = 1.32224
I0802 07:29:23.309828 18636 solver.cpp:375]     Train net output #0: loss = 1.70577 (* 1 = 1.70577 loss)
I0802 07:29:23.309834 18636 sgd_solver.cpp:136] Iteration 61200, lr = 0.006175, m = 0.9
I0802 07:29:37.291540 18636 solver.cpp:353] Iteration 61300 (7.15238 iter/s, 13.9814s/100 iter), loss = 1.81624
I0802 07:29:37.291570 18636 solver.cpp:375]     Train net output #0: loss = 1.75867 (* 1 = 1.75867 loss)
I0802 07:29:37.291574 18636 sgd_solver.cpp:136] Iteration 61300, lr = 0.00616875, m = 0.9
I0802 07:29:51.237061 18636 solver.cpp:353] Iteration 61400 (7.17096 iter/s, 13.9451s/100 iter), loss = 1.32494
I0802 07:29:51.237149 18636 solver.cpp:375]     Train net output #0: loss = 1.58517 (* 1 = 1.58517 loss)
I0802 07:29:51.237156 18636 sgd_solver.cpp:136] Iteration 61400, lr = 0.0061625, m = 0.9
I0802 07:30:05.254897 18636 solver.cpp:353] Iteration 61500 (7.13396 iter/s, 14.0175s/100 iter), loss = 1.35415
I0802 07:30:05.254922 18636 solver.cpp:375]     Train net output #0: loss = 1.24216 (* 1 = 1.24216 loss)
I0802 07:30:05.254926 18636 sgd_solver.cpp:136] Iteration 61500, lr = 0.00615625, m = 0.9
I0802 07:30:19.212620 18636 solver.cpp:353] Iteration 61600 (7.16469 iter/s, 13.9573s/100 iter), loss = 1.22835
I0802 07:30:19.212646 18636 solver.cpp:375]     Train net output #0: loss = 1.12502 (* 1 = 1.12502 loss)
I0802 07:30:19.212652 18636 sgd_solver.cpp:136] Iteration 61600, lr = 0.00615, m = 0.9
I0802 07:30:33.032500 18636 solver.cpp:353] Iteration 61700 (7.23615 iter/s, 13.8195s/100 iter), loss = 1.51404
I0802 07:30:33.032586 18636 solver.cpp:375]     Train net output #0: loss = 1.42565 (* 1 = 1.42565 loss)
I0802 07:30:33.032593 18636 sgd_solver.cpp:136] Iteration 61700, lr = 0.00614375, m = 0.9
I0802 07:30:47.092478 18636 solver.cpp:353] Iteration 61800 (7.11258 iter/s, 14.0596s/100 iter), loss = 1.20981
I0802 07:30:47.092502 18636 solver.cpp:375]     Train net output #0: loss = 1.22027 (* 1 = 1.22027 loss)
I0802 07:30:47.092509 18636 sgd_solver.cpp:136] Iteration 61800, lr = 0.0061375, m = 0.9
I0802 07:31:01.112046 18636 solver.cpp:353] Iteration 61900 (7.13308 iter/s, 14.0192s/100 iter), loss = 1.63269
I0802 07:31:01.112072 18636 solver.cpp:375]     Train net output #0: loss = 1.35717 (* 1 = 1.35717 loss)
I0802 07:31:01.112077 18636 sgd_solver.cpp:136] Iteration 61900, lr = 0.00613125, m = 0.9
I0802 07:31:14.922338 18636 solver.cpp:404] Sparsity after update:
I0802 07:31:14.928143 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:31:14.928153 18636 net.cpp:2270] conv1a_param_0(0.199) 
I0802 07:31:14.928161 18636 net.cpp:2270] conv1b_param_0(0.417) 
I0802 07:31:14.928165 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:31:14.928170 18636 net.cpp:2270] res2a_branch2a_param_0(0.417) 
I0802 07:31:14.928174 18636 net.cpp:2270] res2a_branch2b_param_0(0.417) 
I0802 07:31:14.928177 18636 net.cpp:2270] res3a_branch2a_param_0(0.418) 
I0802 07:31:14.928180 18636 net.cpp:2270] res3a_branch2b_param_0(0.417) 
I0802 07:31:14.928184 18636 net.cpp:2270] res4a_branch2a_param_0(0.419) 
I0802 07:31:14.928186 18636 net.cpp:2270] res4a_branch2b_param_0(0.418) 
I0802 07:31:14.928189 18636 net.cpp:2270] res5a_branch2a_param_0(0.42) 
I0802 07:31:14.928192 18636 net.cpp:2270] res5a_branch2b_param_0(0.419) 
I0802 07:31:14.928194 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (986896/2.86678e+06) 0.344
I0802 07:31:14.928206 18636 solver.cpp:550] Iteration 62000, Testing net (#0)
I0802 07:31:34.498687 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.573588
I0802 07:31:34.498759 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.806173
I0802 07:31:34.498778 18636 solver.cpp:635]     Test net output #2: loss = 1.86024 (* 1 = 1.86024 loss)
I0802 07:31:34.498811 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5701s
I0802 07:31:34.657292 18661 solver.cpp:450] Finding and applying sparsity: 0.43
I0802 07:32:01.193218 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:32:01.195147 18636 solver.cpp:353] Iteration 62000 (1.66441 iter/s, 60.0815s/100 iter), loss = 1.55012
I0802 07:32:01.195163 18636 solver.cpp:375]     Train net output #0: loss = 1.60266 (* 1 = 1.60266 loss)
I0802 07:32:01.195168 18636 sgd_solver.cpp:136] Iteration 62000, lr = 0.006125, m = 0.9
I0802 07:32:15.532398 18636 solver.cpp:353] Iteration 62100 (6.97503 iter/s, 14.3369s/100 iter), loss = 1.54202
I0802 07:32:15.532425 18636 solver.cpp:375]     Train net output #0: loss = 1.62652 (* 1 = 1.62652 loss)
I0802 07:32:15.532433 18636 sgd_solver.cpp:136] Iteration 62100, lr = 0.00611875, m = 0.9
I0802 07:32:29.390271 18636 solver.cpp:353] Iteration 62200 (7.21631 iter/s, 13.8575s/100 iter), loss = 1.36603
I0802 07:32:29.390298 18636 solver.cpp:375]     Train net output #0: loss = 1.47057 (* 1 = 1.47057 loss)
I0802 07:32:29.390303 18636 sgd_solver.cpp:136] Iteration 62200, lr = 0.0061125, m = 0.9
I0802 07:32:43.244763 18636 solver.cpp:353] Iteration 62300 (7.21807 iter/s, 13.8541s/100 iter), loss = 1.68403
I0802 07:32:43.244841 18636 solver.cpp:375]     Train net output #0: loss = 2.08293 (* 1 = 2.08293 loss)
I0802 07:32:43.244848 18636 sgd_solver.cpp:136] Iteration 62300, lr = 0.00610625, m = 0.9
I0802 07:32:57.196967 18636 solver.cpp:353] Iteration 62400 (7.16752 iter/s, 13.9518s/100 iter), loss = 1.46694
I0802 07:32:57.196992 18636 solver.cpp:375]     Train net output #0: loss = 1.3099 (* 1 = 1.3099 loss)
I0802 07:32:57.196996 18636 sgd_solver.cpp:136] Iteration 62400, lr = 0.0061, m = 0.9
I0802 07:33:11.056821 18636 solver.cpp:353] Iteration 62500 (7.21528 iter/s, 13.8595s/100 iter), loss = 1.49256
I0802 07:33:11.056913 18636 solver.cpp:375]     Train net output #0: loss = 1.3796 (* 1 = 1.3796 loss)
I0802 07:33:11.056932 18636 sgd_solver.cpp:136] Iteration 62500, lr = 0.00609375, m = 0.9
I0802 07:33:24.968339 18636 solver.cpp:353] Iteration 62600 (7.18848 iter/s, 13.9111s/100 iter), loss = 1.18628
I0802 07:33:24.968418 18636 solver.cpp:375]     Train net output #0: loss = 0.907872 (* 1 = 0.907872 loss)
I0802 07:33:24.968423 18636 sgd_solver.cpp:136] Iteration 62600, lr = 0.0060875, m = 0.9
I0802 07:33:38.861438 18636 solver.cpp:353] Iteration 62700 (7.19801 iter/s, 13.8927s/100 iter), loss = 1.31757
I0802 07:33:38.861464 18636 solver.cpp:375]     Train net output #0: loss = 1.6144 (* 1 = 1.6144 loss)
I0802 07:33:38.861469 18636 sgd_solver.cpp:136] Iteration 62700, lr = 0.00608125, m = 0.9
I0802 07:33:52.727260 18636 solver.cpp:353] Iteration 62800 (7.21217 iter/s, 13.8654s/100 iter), loss = 1.66265
I0802 07:33:52.727286 18636 solver.cpp:375]     Train net output #0: loss = 1.77026 (* 1 = 1.77026 loss)
I0802 07:33:52.727293 18636 sgd_solver.cpp:136] Iteration 62800, lr = 0.006075, m = 0.9
I0802 07:34:06.641360 18636 solver.cpp:353] Iteration 62900 (7.18715 iter/s, 13.9137s/100 iter), loss = 1.51339
I0802 07:34:06.641417 18636 solver.cpp:375]     Train net output #0: loss = 1.48016 (* 1 = 1.48016 loss)
I0802 07:34:06.641423 18636 sgd_solver.cpp:136] Iteration 62900, lr = 0.00606875, m = 0.9
I0802 07:34:20.367535 18636 solver.cpp:404] Sparsity after update:
I0802 07:34:20.380069 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:34:20.380102 18636 net.cpp:2270] conv1a_param_0(0.212) 
I0802 07:34:20.380117 18636 net.cpp:2270] conv1b_param_0(0.417) 
I0802 07:34:20.380125 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:34:20.380136 18636 net.cpp:2270] res2a_branch2a_param_0(0.427) 
I0802 07:34:20.380151 18636 net.cpp:2270] res2a_branch2b_param_0(0.424) 
I0802 07:34:20.380162 18636 net.cpp:2270] res3a_branch2a_param_0(0.429) 
I0802 07:34:20.380165 18636 net.cpp:2270] res3a_branch2b_param_0(0.427) 
I0802 07:34:20.380169 18636 net.cpp:2270] res4a_branch2a_param_0(0.43) 
I0802 07:34:20.380173 18636 net.cpp:2270] res4a_branch2b_param_0(0.429) 
I0802 07:34:20.380177 18636 net.cpp:2270] res5a_branch2a_param_0(0.43) 
I0802 07:34:20.380180 18636 net.cpp:2270] res5a_branch2b_param_0(0.43) 
I0802 07:34:20.380183 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.01086e+06/2.86678e+06) 0.353
I0802 07:34:20.510294 18661 solver.cpp:450] Finding and applying sparsity: 0.44
I0802 07:34:47.579383 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:34:47.581336 18636 solver.cpp:353] Iteration 63000 (2.44267 iter/s, 40.9389s/100 iter), loss = 1.48433
I0802 07:34:47.581360 18636 solver.cpp:375]     Train net output #0: loss = 1.06015 (* 1 = 1.06015 loss)
I0802 07:34:47.581370 18636 sgd_solver.cpp:136] Iteration 63000, lr = 0.0060625, m = 0.9
I0802 07:35:02.037474 18636 solver.cpp:353] Iteration 63100 (6.91767 iter/s, 14.4557s/100 iter), loss = 1.71332
I0802 07:35:02.037499 18636 solver.cpp:375]     Train net output #0: loss = 1.39971 (* 1 = 1.39971 loss)
I0802 07:35:02.037504 18636 sgd_solver.cpp:136] Iteration 63100, lr = 0.00605625, m = 0.9
I0802 07:35:15.907038 18636 solver.cpp:353] Iteration 63200 (7.21023 iter/s, 13.8692s/100 iter), loss = 1.48834
I0802 07:35:15.907068 18636 solver.cpp:375]     Train net output #0: loss = 1.43662 (* 1 = 1.43662 loss)
I0802 07:35:15.907073 18636 sgd_solver.cpp:136] Iteration 63200, lr = 0.00605, m = 0.9
I0802 07:35:29.842914 18636 solver.cpp:353] Iteration 63300 (7.17592 iter/s, 13.9355s/100 iter), loss = 1.32188
I0802 07:35:29.843008 18636 solver.cpp:375]     Train net output #0: loss = 1.2824 (* 1 = 1.2824 loss)
I0802 07:35:29.843016 18636 sgd_solver.cpp:136] Iteration 63300, lr = 0.00604375, m = 0.9
I0802 07:35:43.713835 18636 solver.cpp:353] Iteration 63400 (7.20953 iter/s, 13.8705s/100 iter), loss = 1.21602
I0802 07:35:43.714102 18636 solver.cpp:375]     Train net output #0: loss = 1.38435 (* 1 = 1.38435 loss)
I0802 07:35:43.714213 18636 sgd_solver.cpp:136] Iteration 63400, lr = 0.0060375, m = 0.9
I0802 07:35:57.593972 18636 solver.cpp:353] Iteration 63500 (7.20474 iter/s, 13.8798s/100 iter), loss = 1.33337
I0802 07:35:57.594000 18636 solver.cpp:375]     Train net output #0: loss = 1.40573 (* 1 = 1.40573 loss)
I0802 07:35:57.594007 18636 sgd_solver.cpp:136] Iteration 63500, lr = 0.00603125, m = 0.9
I0802 07:36:11.519785 18636 solver.cpp:353] Iteration 63600 (7.18111 iter/s, 13.9254s/100 iter), loss = 1.79018
I0802 07:36:11.520062 18636 solver.cpp:375]     Train net output #0: loss = 1.78139 (* 1 = 1.78139 loss)
I0802 07:36:11.520174 18636 sgd_solver.cpp:136] Iteration 63600, lr = 0.006025, m = 0.9
I0802 07:36:25.375258 18636 solver.cpp:353] Iteration 63700 (7.21756 iter/s, 13.8551s/100 iter), loss = 1.50495
I0802 07:36:25.375291 18636 solver.cpp:375]     Train net output #0: loss = 1.46092 (* 1 = 1.46092 loss)
I0802 07:36:25.375344 18636 sgd_solver.cpp:136] Iteration 63700, lr = 0.00601875, m = 0.9
I0802 07:36:39.428907 18636 solver.cpp:353] Iteration 63800 (7.11578 iter/s, 14.0533s/100 iter), loss = 1.16023
I0802 07:36:39.428935 18636 solver.cpp:375]     Train net output #0: loss = 1.18778 (* 1 = 1.18778 loss)
I0802 07:36:39.428941 18636 sgd_solver.cpp:136] Iteration 63800, lr = 0.0060125, m = 0.9
I0802 07:36:53.380240 18636 solver.cpp:353] Iteration 63900 (7.16797 iter/s, 13.951s/100 iter), loss = 1.42845
I0802 07:36:53.380313 18636 solver.cpp:375]     Train net output #0: loss = 1.46941 (* 1 = 1.46941 loss)
I0802 07:36:53.380319 18636 sgd_solver.cpp:136] Iteration 63900, lr = 0.00600625, m = 0.9
I0802 07:37:07.144001 18636 solver.cpp:404] Sparsity after update:
I0802 07:37:07.148421 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:37:07.148430 18636 net.cpp:2270] conv1a_param_0(0.213) 
I0802 07:37:07.148437 18636 net.cpp:2270] conv1b_param_0(0.431) 
I0802 07:37:07.148439 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:37:07.148442 18636 net.cpp:2270] res2a_branch2a_param_0(0.438) 
I0802 07:37:07.148443 18636 net.cpp:2270] res2a_branch2b_param_0(0.438) 
I0802 07:37:07.148447 18636 net.cpp:2270] res3a_branch2a_param_0(0.439) 
I0802 07:37:07.148449 18636 net.cpp:2270] res3a_branch2b_param_0(0.438) 
I0802 07:37:07.148452 18636 net.cpp:2270] res4a_branch2a_param_0(0.439) 
I0802 07:37:07.148453 18636 net.cpp:2270] res4a_branch2b_param_0(0.439) 
I0802 07:37:07.148455 18636 net.cpp:2270] res5a_branch2a_param_0(0.44) 
I0802 07:37:07.148458 18636 net.cpp:2270] res5a_branch2b_param_0(0.439) 
I0802 07:37:07.148459 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.03413e+06/2.86678e+06) 0.361
I0802 07:37:07.148468 18636 solver.cpp:550] Iteration 64000, Testing net (#0)
I0802 07:37:26.668401 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.572882
I0802 07:37:26.668512 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808115
I0802 07:37:26.668522 18636 solver.cpp:635]     Test net output #2: loss = 1.86762 (* 1 = 1.86762 loss)
I0802 07:37:26.668541 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5195s
I0802 07:37:26.806454 18661 solver.cpp:450] Finding and applying sparsity: 0.45
I0802 07:37:54.447587 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:37:54.449483 18636 solver.cpp:353] Iteration 64000 (1.63753 iter/s, 61.0676s/100 iter), loss = 1.36541
I0802 07:37:54.449501 18636 solver.cpp:375]     Train net output #0: loss = 1.75363 (* 1 = 1.75363 loss)
I0802 07:37:54.449508 18636 sgd_solver.cpp:136] Iteration 64000, lr = 0.006, m = 0.9
I0802 07:38:08.843225 18636 solver.cpp:353] Iteration 64100 (6.94766 iter/s, 14.3933s/100 iter), loss = 1.53945
I0802 07:38:08.852936 18636 solver.cpp:375]     Train net output #0: loss = 1.14346 (* 1 = 1.14346 loss)
I0802 07:38:08.852963 18636 sgd_solver.cpp:136] Iteration 64100, lr = 0.00599375, m = 0.9
I0802 07:38:22.830160 18636 solver.cpp:353] Iteration 64200 (7.14973 iter/s, 13.9865s/100 iter), loss = 1.25985
I0802 07:38:22.830185 18636 solver.cpp:375]     Train net output #0: loss = 1.31094 (* 1 = 1.31094 loss)
I0802 07:38:22.830190 18636 sgd_solver.cpp:136] Iteration 64200, lr = 0.0059875, m = 0.9
I0802 07:38:36.765686 18636 solver.cpp:353] Iteration 64300 (7.1761 iter/s, 13.9351s/100 iter), loss = 1.51629
I0802 07:38:36.765719 18636 solver.cpp:375]     Train net output #0: loss = 1.67176 (* 1 = 1.67176 loss)
I0802 07:38:36.765727 18636 sgd_solver.cpp:136] Iteration 64300, lr = 0.00598125, m = 0.9
I0802 07:38:50.706857 18636 solver.cpp:353] Iteration 64400 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.4062
I0802 07:38:50.706940 18636 solver.cpp:375]     Train net output #0: loss = 1.33929 (* 1 = 1.33929 loss)
I0802 07:38:50.706954 18636 sgd_solver.cpp:136] Iteration 64400, lr = 0.005975, m = 0.9
I0802 07:39:04.572878 18636 solver.cpp:353] Iteration 64500 (7.21208 iter/s, 13.8656s/100 iter), loss = 1.01918
I0802 07:39:04.572911 18636 solver.cpp:375]     Train net output #0: loss = 1.27415 (* 1 = 1.27415 loss)
I0802 07:39:04.572917 18636 sgd_solver.cpp:136] Iteration 64500, lr = 0.00596875, m = 0.9
I0802 07:39:18.445140 18636 solver.cpp:353] Iteration 64600 (7.20883 iter/s, 13.8719s/100 iter), loss = 1.85363
I0802 07:39:18.445169 18636 solver.cpp:375]     Train net output #0: loss = 1.96038 (* 1 = 1.96038 loss)
I0802 07:39:18.445175 18636 sgd_solver.cpp:136] Iteration 64600, lr = 0.0059625, m = 0.9
I0802 07:39:32.342420 18636 solver.cpp:353] Iteration 64700 (7.19585 iter/s, 13.8969s/100 iter), loss = 1.74791
I0802 07:39:32.342519 18636 solver.cpp:375]     Train net output #0: loss = 1.77092 (* 1 = 1.77092 loss)
I0802 07:39:32.342523 18636 sgd_solver.cpp:136] Iteration 64700, lr = 0.00595625, m = 0.9
I0802 07:39:46.279719 18636 solver.cpp:353] Iteration 64800 (7.17519 iter/s, 13.9369s/100 iter), loss = 1.80771
I0802 07:39:46.279749 18636 solver.cpp:375]     Train net output #0: loss = 1.77105 (* 1 = 1.77105 loss)
I0802 07:39:46.279755 18636 sgd_solver.cpp:136] Iteration 64800, lr = 0.00595, m = 0.9
I0802 07:40:00.151794 18636 solver.cpp:353] Iteration 64900 (7.20892 iter/s, 13.8717s/100 iter), loss = 1.43673
I0802 07:40:00.151823 18636 solver.cpp:375]     Train net output #0: loss = 1.46238 (* 1 = 1.46238 loss)
I0802 07:40:00.151829 18636 sgd_solver.cpp:136] Iteration 64900, lr = 0.00594375, m = 0.9
I0802 07:40:13.992605 18636 solver.cpp:404] Sparsity after update:
I0802 07:40:14.003777 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:40:14.003792 18636 net.cpp:2270] conv1a_param_0(0.213) 
I0802 07:40:14.003800 18636 net.cpp:2270] conv1b_param_0(0.444) 
I0802 07:40:14.003803 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:40:14.003808 18636 net.cpp:2270] res2a_branch2a_param_0(0.448) 
I0802 07:40:14.003810 18636 net.cpp:2270] res2a_branch2b_param_0(0.444) 
I0802 07:40:14.003813 18636 net.cpp:2270] res3a_branch2a_param_0(0.45) 
I0802 07:40:14.003816 18636 net.cpp:2270] res3a_branch2b_param_0(0.448) 
I0802 07:40:14.003819 18636 net.cpp:2270] res4a_branch2a_param_0(0.45) 
I0802 07:40:14.003823 18636 net.cpp:2270] res4a_branch2b_param_0(0.45) 
I0802 07:40:14.003852 18636 net.cpp:2270] res5a_branch2a_param_0(0.45) 
I0802 07:40:14.003865 18636 net.cpp:2270] res5a_branch2b_param_0(0.45) 
I0802 07:40:14.003875 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.0581e+06/2.86678e+06) 0.369
I0802 07:40:14.135583 18661 solver.cpp:450] Finding and applying sparsity: 0.46
I0802 07:40:42.461403 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:40:42.463345 18636 solver.cpp:353] Iteration 65000 (2.36349 iter/s, 42.3104s/100 iter), loss = 1.16467
I0802 07:40:42.463362 18636 solver.cpp:375]     Train net output #0: loss = 1.23418 (* 1 = 1.23418 loss)
I0802 07:40:42.463368 18636 sgd_solver.cpp:136] Iteration 65000, lr = 0.0059375, m = 0.9
I0802 07:40:56.910101 18636 solver.cpp:353] Iteration 65100 (6.92216 iter/s, 14.4464s/100 iter), loss = 1.26144
I0802 07:40:56.910163 18636 solver.cpp:375]     Train net output #0: loss = 1.27404 (* 1 = 1.27404 loss)
I0802 07:40:56.910169 18636 sgd_solver.cpp:136] Iteration 65100, lr = 0.00593125, m = 0.9
I0802 07:41:10.783941 18636 solver.cpp:353] Iteration 65200 (7.20801 iter/s, 13.8735s/100 iter), loss = 1.57076
I0802 07:41:10.783970 18636 solver.cpp:375]     Train net output #0: loss = 1.53381 (* 1 = 1.53381 loss)
I0802 07:41:10.783977 18636 sgd_solver.cpp:136] Iteration 65200, lr = 0.005925, m = 0.9
I0802 07:41:24.717042 18636 solver.cpp:353] Iteration 65300 (7.17735 iter/s, 13.9327s/100 iter), loss = 1.33193
I0802 07:41:24.717075 18636 solver.cpp:375]     Train net output #0: loss = 1.58152 (* 1 = 1.58152 loss)
I0802 07:41:24.717082 18636 sgd_solver.cpp:136] Iteration 65300, lr = 0.00591875, m = 0.9
I0802 07:41:38.697914 18636 solver.cpp:353] Iteration 65400 (7.15283 iter/s, 13.9805s/100 iter), loss = 1.39541
I0802 07:41:38.697963 18636 solver.cpp:375]     Train net output #0: loss = 1.71016 (* 1 = 1.71016 loss)
I0802 07:41:38.697968 18636 sgd_solver.cpp:136] Iteration 65400, lr = 0.0059125, m = 0.9
I0802 07:41:52.639107 18636 solver.cpp:353] Iteration 65500 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.15582
I0802 07:41:52.639135 18636 solver.cpp:375]     Train net output #0: loss = 1.03702 (* 1 = 1.03702 loss)
I0802 07:41:52.639415 18636 sgd_solver.cpp:136] Iteration 65500, lr = 0.00590625, m = 0.9
I0802 07:42:06.594452 18636 solver.cpp:353] Iteration 65600 (7.16591 iter/s, 13.955s/100 iter), loss = 1.53059
I0802 07:42:06.594477 18636 solver.cpp:375]     Train net output #0: loss = 1.31113 (* 1 = 1.31113 loss)
I0802 07:42:06.594483 18636 sgd_solver.cpp:136] Iteration 65600, lr = 0.0059, m = 0.9
I0802 07:42:20.539932 18636 solver.cpp:353] Iteration 65700 (7.17098 iter/s, 13.9451s/100 iter), loss = 1.4122
I0802 07:42:20.540002 18636 solver.cpp:375]     Train net output #0: loss = 1.21928 (* 1 = 1.21928 loss)
I0802 07:42:20.540007 18636 sgd_solver.cpp:136] Iteration 65700, lr = 0.00589375, m = 0.9
I0802 07:42:34.437901 18636 solver.cpp:353] Iteration 65800 (7.19549 iter/s, 13.8976s/100 iter), loss = 1.35234
I0802 07:42:34.437930 18636 solver.cpp:375]     Train net output #0: loss = 1.214 (* 1 = 1.214 loss)
I0802 07:42:34.437935 18636 sgd_solver.cpp:136] Iteration 65800, lr = 0.0058875, m = 0.9
I0802 07:42:48.459800 18636 solver.cpp:353] Iteration 65900 (7.1319 iter/s, 14.0215s/100 iter), loss = 1.74007
I0802 07:42:48.459825 18636 solver.cpp:375]     Train net output #0: loss = 2.22475 (* 1 = 2.22475 loss)
I0802 07:42:48.459830 18636 sgd_solver.cpp:136] Iteration 65900, lr = 0.00588125, m = 0.9
I0802 07:43:02.388413 18636 solver.cpp:404] Sparsity after update:
I0802 07:43:02.392331 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:43:02.392341 18636 net.cpp:2270] conv1a_param_0(0.225) 
I0802 07:43:02.392349 18636 net.cpp:2270] conv1b_param_0(0.458) 
I0802 07:43:02.392350 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:43:02.392352 18636 net.cpp:2270] res2a_branch2a_param_0(0.458) 
I0802 07:43:02.392354 18636 net.cpp:2270] res2a_branch2b_param_0(0.458) 
I0802 07:43:02.392356 18636 net.cpp:2270] res3a_branch2a_param_0(0.458) 
I0802 07:43:02.392359 18636 net.cpp:2270] res3a_branch2b_param_0(0.458) 
I0802 07:43:02.392360 18636 net.cpp:2270] res4a_branch2a_param_0(0.459) 
I0802 07:43:02.392362 18636 net.cpp:2270] res4a_branch2b_param_0(0.458) 
I0802 07:43:02.392364 18636 net.cpp:2270] res5a_branch2a_param_0(0.46) 
I0802 07:43:02.392365 18636 net.cpp:2270] res5a_branch2b_param_0(0.459) 
I0802 07:43:02.392367 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.081e+06/2.86678e+06) 0.377
I0802 07:43:02.392376 18636 solver.cpp:550] Iteration 66000, Testing net (#0)
I0802 07:43:19.925297 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:43:22.088539 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.567412
I0802 07:43:22.088567 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.798998
I0802 07:43:22.088574 18636 solver.cpp:635]     Test net output #2: loss = 1.89731 (* 1 = 1.89731 loss)
I0802 07:43:22.088639 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6957s
I0802 07:43:22.228395 18661 solver.cpp:450] Finding and applying sparsity: 0.47
I0802 07:43:51.233933 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:43:51.236095 18636 solver.cpp:353] Iteration 66000 (1.593 iter/s, 62.7746s/100 iter), loss = 1.58217
I0802 07:43:51.236132 18636 solver.cpp:375]     Train net output #0: loss = 1.61546 (* 1 = 1.61546 loss)
I0802 07:43:51.236141 18636 sgd_solver.cpp:136] Iteration 66000, lr = 0.005875, m = 0.9
I0802 07:44:05.639430 18636 solver.cpp:353] Iteration 66100 (6.94303 iter/s, 14.4029s/100 iter), loss = 1.32567
I0802 07:44:05.639457 18636 solver.cpp:375]     Train net output #0: loss = 1.08699 (* 1 = 1.08699 loss)
I0802 07:44:05.639461 18636 sgd_solver.cpp:136] Iteration 66100, lr = 0.00586875, m = 0.9
I0802 07:44:19.564285 18636 solver.cpp:353] Iteration 66200 (7.1816 iter/s, 13.9245s/100 iter), loss = 1.39844
I0802 07:44:19.564312 18636 solver.cpp:375]     Train net output #0: loss = 1.82646 (* 1 = 1.82646 loss)
I0802 07:44:19.564318 18636 sgd_solver.cpp:136] Iteration 66200, lr = 0.0058625, m = 0.9
I0802 07:44:33.565402 18636 solver.cpp:353] Iteration 66300 (7.14249 iter/s, 14.0007s/100 iter), loss = 1.68865
I0802 07:44:33.565546 18636 solver.cpp:375]     Train net output #0: loss = 1.5466 (* 1 = 1.5466 loss)
I0802 07:44:33.565567 18636 sgd_solver.cpp:136] Iteration 66300, lr = 0.00585625, m = 0.9
I0802 07:44:47.489442 18636 solver.cpp:353] Iteration 66400 (7.18202 iter/s, 13.9237s/100 iter), loss = 1.25565
I0802 07:44:47.489467 18636 solver.cpp:375]     Train net output #0: loss = 1.27664 (* 1 = 1.27664 loss)
I0802 07:44:47.489472 18636 sgd_solver.cpp:136] Iteration 66400, lr = 0.00585, m = 0.9
I0802 07:45:01.363088 18636 solver.cpp:353] Iteration 66500 (7.20811 iter/s, 13.8733s/100 iter), loss = 1.49215
I0802 07:45:01.363143 18636 solver.cpp:375]     Train net output #0: loss = 1.48417 (* 1 = 1.48417 loss)
I0802 07:45:01.363158 18636 sgd_solver.cpp:136] Iteration 66500, lr = 0.00584375, m = 0.9
I0802 07:45:15.423049 18636 solver.cpp:353] Iteration 66600 (7.11259 iter/s, 14.0596s/100 iter), loss = 1.08526
I0802 07:45:15.423125 18636 solver.cpp:375]     Train net output #0: loss = 1.19209 (* 1 = 1.19209 loss)
I0802 07:45:15.423130 18636 sgd_solver.cpp:136] Iteration 66600, lr = 0.0058375, m = 0.9
I0802 07:45:29.377828 18636 solver.cpp:353] Iteration 66700 (7.1662 iter/s, 13.9544s/100 iter), loss = 1.60817
I0802 07:45:29.377939 18636 solver.cpp:375]     Train net output #0: loss = 1.39533 (* 1 = 1.39533 loss)
I0802 07:45:29.377964 18636 sgd_solver.cpp:136] Iteration 66700, lr = 0.00583125, m = 0.9
I0802 07:45:43.244518 18636 solver.cpp:353] Iteration 66800 (7.21172 iter/s, 13.8663s/100 iter), loss = 1.16151
I0802 07:45:43.244612 18636 solver.cpp:375]     Train net output #0: loss = 0.982587 (* 1 = 0.982587 loss)
I0802 07:45:43.244632 18636 sgd_solver.cpp:136] Iteration 66800, lr = 0.005825, m = 0.9
I0802 07:45:57.263063 18636 solver.cpp:353] Iteration 66900 (7.1336 iter/s, 14.0182s/100 iter), loss = 1.52456
I0802 07:45:57.263126 18636 solver.cpp:375]     Train net output #0: loss = 1.42058 (* 1 = 1.42058 loss)
I0802 07:45:57.263131 18636 sgd_solver.cpp:136] Iteration 66900, lr = 0.00581875, m = 0.9
I0802 07:46:11.140434 18636 solver.cpp:404] Sparsity after update:
I0802 07:46:11.153281 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:46:11.153314 18636 net.cpp:2270] conv1a_param_0(0.225) 
I0802 07:46:11.153329 18636 net.cpp:2270] conv1b_param_0(0.458) 
I0802 07:46:11.153337 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:46:11.153345 18636 net.cpp:2270] res2a_branch2a_param_0(0.469) 
I0802 07:46:11.153359 18636 net.cpp:2270] res2a_branch2b_param_0(0.465) 
I0802 07:46:11.153368 18636 net.cpp:2270] res3a_branch2a_param_0(0.469) 
I0802 07:46:11.153376 18636 net.cpp:2270] res3a_branch2b_param_0(0.469) 
I0802 07:46:11.153386 18636 net.cpp:2270] res4a_branch2a_param_0(0.47) 
I0802 07:46:11.153393 18636 net.cpp:2270] res4a_branch2b_param_0(0.469) 
I0802 07:46:11.153401 18636 net.cpp:2270] res5a_branch2a_param_0(0.47) 
I0802 07:46:11.153409 18636 net.cpp:2270] res5a_branch2b_param_0(0.47) 
I0802 07:46:11.153416 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.10494e+06/2.86678e+06) 0.385
I0802 07:46:11.298895 18661 solver.cpp:450] Finding and applying sparsity: 0.48
I0802 07:46:40.714207 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:46:40.716116 18636 solver.cpp:353] Iteration 67000 (2.3014 iter/s, 43.4519s/100 iter), loss = 1.42981
I0802 07:46:40.716140 18636 solver.cpp:375]     Train net output #0: loss = 1.39155 (* 1 = 1.39155 loss)
I0802 07:46:40.716147 18636 sgd_solver.cpp:136] Iteration 67000, lr = 0.0058125, m = 0.9
I0802 07:46:55.049696 18636 solver.cpp:353] Iteration 67100 (6.97682 iter/s, 14.3332s/100 iter), loss = 1.31716
I0802 07:46:55.049724 18636 solver.cpp:375]     Train net output #0: loss = 1.24875 (* 1 = 1.24875 loss)
I0802 07:46:55.049731 18636 sgd_solver.cpp:136] Iteration 67100, lr = 0.00580625, m = 0.9
I0802 07:47:09.061275 18636 solver.cpp:353] Iteration 67200 (7.13715 iter/s, 14.0112s/100 iter), loss = 1.27174
I0802 07:47:09.061327 18636 solver.cpp:375]     Train net output #0: loss = 1.37132 (* 1 = 1.37132 loss)
I0802 07:47:09.061341 18636 sgd_solver.cpp:136] Iteration 67200, lr = 0.0058, m = 0.9
I0802 07:47:23.052278 18636 solver.cpp:353] Iteration 67300 (7.14765 iter/s, 13.9906s/100 iter), loss = 1.11125
I0802 07:47:23.052693 18636 solver.cpp:375]     Train net output #0: loss = 1.09042 (* 1 = 1.09042 loss)
I0802 07:47:23.052701 18636 sgd_solver.cpp:136] Iteration 67300, lr = 0.00579375, m = 0.9
I0802 07:47:37.029759 18636 solver.cpp:353] Iteration 67400 (7.15456 iter/s, 13.9771s/100 iter), loss = 1.34184
I0802 07:47:37.029786 18636 solver.cpp:375]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0802 07:47:37.029793 18636 sgd_solver.cpp:136] Iteration 67400, lr = 0.0057875, m = 0.9
I0802 07:47:51.001070 18636 solver.cpp:353] Iteration 67500 (7.15772 iter/s, 13.9709s/100 iter), loss = 1.36116
I0802 07:47:51.001098 18636 solver.cpp:375]     Train net output #0: loss = 1.16349 (* 1 = 1.16349 loss)
I0802 07:47:51.001104 18636 sgd_solver.cpp:136] Iteration 67500, lr = 0.00578125, m = 0.9
I0802 07:48:04.927791 18636 solver.cpp:353] Iteration 67600 (7.18064 iter/s, 13.9263s/100 iter), loss = 1.20023
I0802 07:48:04.927860 18636 solver.cpp:375]     Train net output #0: loss = 1.23168 (* 1 = 1.23168 loss)
I0802 07:48:04.927867 18636 sgd_solver.cpp:136] Iteration 67600, lr = 0.005775, m = 0.9
I0802 07:48:18.795410 18636 solver.cpp:353] Iteration 67700 (7.21124 iter/s, 13.8672s/100 iter), loss = 1.15618
I0802 07:48:18.795439 18636 solver.cpp:375]     Train net output #0: loss = 1.1508 (* 1 = 1.1508 loss)
I0802 07:48:18.795444 18636 sgd_solver.cpp:136] Iteration 67700, lr = 0.00576875, m = 0.9
I0802 07:48:32.789120 18636 solver.cpp:353] Iteration 67800 (7.14626 iter/s, 13.9933s/100 iter), loss = 1.21673
I0802 07:48:32.789147 18636 solver.cpp:375]     Train net output #0: loss = 1.28263 (* 1 = 1.28263 loss)
I0802 07:48:32.789152 18636 sgd_solver.cpp:136] Iteration 67800, lr = 0.0057625, m = 0.9
I0802 07:48:46.703519 18636 solver.cpp:353] Iteration 67900 (7.187 iter/s, 13.914s/100 iter), loss = 1.29765
I0802 07:48:46.703575 18636 solver.cpp:375]     Train net output #0: loss = 1.25619 (* 1 = 1.25619 loss)
I0802 07:48:46.703583 18636 sgd_solver.cpp:136] Iteration 67900, lr = 0.00575625, m = 0.9
I0802 07:49:00.529093 18636 solver.cpp:404] Sparsity after update:
I0802 07:49:00.533008 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:49:00.533017 18636 net.cpp:2270] conv1a_param_0(0.226) 
I0802 07:49:00.533025 18636 net.cpp:2270] conv1b_param_0(0.472) 
I0802 07:49:00.533026 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:49:00.533028 18636 net.cpp:2270] res2a_branch2a_param_0(0.479) 
I0802 07:49:00.533030 18636 net.cpp:2270] res2a_branch2b_param_0(0.479) 
I0802 07:49:00.533032 18636 net.cpp:2270] res3a_branch2a_param_0(0.479) 
I0802 07:49:00.533035 18636 net.cpp:2270] res3a_branch2b_param_0(0.479) 
I0802 07:49:00.533040 18636 net.cpp:2270] res4a_branch2a_param_0(0.479) 
I0802 07:49:00.533041 18636 net.cpp:2270] res4a_branch2b_param_0(0.479) 
I0802 07:49:00.533043 18636 net.cpp:2270] res5a_branch2a_param_0(0.48) 
I0802 07:49:00.533046 18636 net.cpp:2270] res5a_branch2b_param_0(0.479) 
I0802 07:49:00.533047 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.12821e+06/2.86678e+06) 0.394
I0802 07:49:00.533054 18636 solver.cpp:550] Iteration 68000, Testing net (#0)
I0802 07:49:19.829439 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574882
I0802 07:49:19.829552 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809116
I0802 07:49:19.829561 18636 solver.cpp:635]     Test net output #2: loss = 1.8555 (* 1 = 1.8555 loss)
I0802 07:49:19.829586 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.296s
I0802 07:49:19.981024 18661 solver.cpp:450] Finding and applying sparsity: 0.49
I0802 07:49:49.775996 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:49:49.777971 18636 solver.cpp:353] Iteration 68000 (1.58547 iter/s, 63.0727s/100 iter), loss = 1.67936
I0802 07:49:49.777995 18636 solver.cpp:375]     Train net output #0: loss = 1.40997 (* 1 = 1.40997 loss)
I0802 07:49:49.778004 18636 sgd_solver.cpp:136] Iteration 68000, lr = 0.00575, m = 0.9
I0802 07:50:04.061417 18636 solver.cpp:353] Iteration 68100 (7.00131 iter/s, 14.283s/100 iter), loss = 1.41305
I0802 07:50:04.061484 18636 solver.cpp:375]     Train net output #0: loss = 0.976402 (* 1 = 0.976402 loss)
I0802 07:50:04.061491 18636 sgd_solver.cpp:136] Iteration 68100, lr = 0.00574375, m = 0.9
I0802 07:50:17.960958 18636 solver.cpp:353] Iteration 68200 (7.19468 iter/s, 13.8992s/100 iter), loss = 1.35467
I0802 07:50:17.960988 18636 solver.cpp:375]     Train net output #0: loss = 1.33436 (* 1 = 1.33436 loss)
I0802 07:50:17.960994 18636 sgd_solver.cpp:136] Iteration 68200, lr = 0.0057375, m = 0.9
I0802 07:50:31.848479 18636 solver.cpp:353] Iteration 68300 (7.20091 iter/s, 13.8871s/100 iter), loss = 1.80343
I0802 07:50:31.848570 18636 solver.cpp:375]     Train net output #0: loss = 1.55111 (* 1 = 1.55111 loss)
I0802 07:50:31.848590 18636 sgd_solver.cpp:136] Iteration 68300, lr = 0.00573125, m = 0.9
I0802 07:50:45.822165 18636 solver.cpp:353] Iteration 68400 (7.15651 iter/s, 13.9733s/100 iter), loss = 1.64918
I0802 07:50:45.822239 18636 solver.cpp:375]     Train net output #0: loss = 1.93625 (* 1 = 1.93625 loss)
I0802 07:50:45.822253 18636 sgd_solver.cpp:136] Iteration 68400, lr = 0.005725, m = 0.9
I0802 07:50:59.748235 18636 solver.cpp:353] Iteration 68500 (7.18097 iter/s, 13.9257s/100 iter), loss = 1.20004
I0802 07:50:59.748265 18636 solver.cpp:375]     Train net output #0: loss = 1.46419 (* 1 = 1.46419 loss)
I0802 07:50:59.748271 18636 sgd_solver.cpp:136] Iteration 68500, lr = 0.00571875, m = 0.9
I0802 07:51:13.681089 18636 solver.cpp:353] Iteration 68600 (7.17748 iter/s, 13.9325s/100 iter), loss = 1.33721
I0802 07:51:13.681161 18636 solver.cpp:375]     Train net output #0: loss = 1.47377 (* 1 = 1.47377 loss)
I0802 07:51:13.681180 18636 sgd_solver.cpp:136] Iteration 68600, lr = 0.0057125, m = 0.9
I0802 07:51:27.611589 18636 solver.cpp:353] Iteration 68700 (7.17869 iter/s, 13.9301s/100 iter), loss = 1.39573
I0802 07:51:27.611660 18636 solver.cpp:375]     Train net output #0: loss = 1.259 (* 1 = 1.259 loss)
I0802 07:51:27.611667 18636 sgd_solver.cpp:136] Iteration 68700, lr = 0.00570625, m = 0.9
I0802 07:51:41.532148 18636 solver.cpp:353] Iteration 68800 (7.18382 iter/s, 13.9202s/100 iter), loss = 1.2406
I0802 07:51:41.532172 18636 solver.cpp:375]     Train net output #0: loss = 1.44715 (* 1 = 1.44715 loss)
I0802 07:51:41.532178 18636 sgd_solver.cpp:136] Iteration 68800, lr = 0.0057, m = 0.9
I0802 07:51:55.489465 18636 solver.cpp:353] Iteration 68900 (7.1649 iter/s, 13.9569s/100 iter), loss = 1.03995
I0802 07:51:55.489490 18636 solver.cpp:375]     Train net output #0: loss = 1.29312 (* 1 = 1.29312 loss)
I0802 07:51:55.489496 18636 sgd_solver.cpp:136] Iteration 68900, lr = 0.00569375, m = 0.9
I0802 07:52:09.308851 18636 solver.cpp:404] Sparsity after update:
I0802 07:52:09.319339 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:52:09.319352 18636 net.cpp:2270] conv1a_param_0(0.239) 
I0802 07:52:09.319361 18636 net.cpp:2270] conv1b_param_0(0.486) 
I0802 07:52:09.319365 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:52:09.319368 18636 net.cpp:2270] res2a_branch2a_param_0(0.49) 
I0802 07:52:09.319378 18636 net.cpp:2270] res2a_branch2b_param_0(0.486) 
I0802 07:52:09.319382 18636 net.cpp:2270] res3a_branch2a_param_0(0.49) 
I0802 07:52:09.319386 18636 net.cpp:2270] res3a_branch2b_param_0(0.49) 
I0802 07:52:09.319388 18636 net.cpp:2270] res4a_branch2a_param_0(0.49) 
I0802 07:52:09.319391 18636 net.cpp:2270] res4a_branch2b_param_0(0.49) 
I0802 07:52:09.319394 18636 net.cpp:2270] res5a_branch2a_param_0(0.49) 
I0802 07:52:09.319398 18636 net.cpp:2270] res5a_branch2b_param_0(0.49) 
I0802 07:52:09.319401 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.15221e+06/2.86678e+06) 0.402
I0802 07:52:09.452428 18661 solver.cpp:450] Finding and applying sparsity: 0.5
I0802 07:52:39.236739 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:52:39.238648 18636 solver.cpp:353] Iteration 69000 (2.28582 iter/s, 43.748s/100 iter), loss = 1.75969
I0802 07:52:39.238667 18636 solver.cpp:375]     Train net output #0: loss = 1.69373 (* 1 = 1.69373 loss)
I0802 07:52:39.238672 18636 sgd_solver.cpp:136] Iteration 69000, lr = 0.0056875, m = 0.9
I0802 07:52:53.641041 18636 solver.cpp:353] Iteration 69100 (6.94349 iter/s, 14.402s/100 iter), loss = 1.45194
I0802 07:52:53.641113 18636 solver.cpp:375]     Train net output #0: loss = 1.52745 (* 1 = 1.52745 loss)
I0802 07:52:53.641120 18636 sgd_solver.cpp:136] Iteration 69100, lr = 0.00568125, m = 0.9
I0802 07:53:07.564748 18636 solver.cpp:353] Iteration 69200 (7.18219 iter/s, 13.9233s/100 iter), loss = 1.21042
I0802 07:53:07.564779 18636 solver.cpp:375]     Train net output #0: loss = 1.07642 (* 1 = 1.07642 loss)
I0802 07:53:07.564785 18636 sgd_solver.cpp:136] Iteration 69200, lr = 0.005675, m = 0.9
I0802 07:53:21.485532 18636 solver.cpp:353] Iteration 69300 (7.1837 iter/s, 13.9204s/100 iter), loss = 1.56885
I0802 07:53:21.485560 18636 solver.cpp:375]     Train net output #0: loss = 1.22849 (* 1 = 1.22849 loss)
I0802 07:53:21.485566 18636 sgd_solver.cpp:136] Iteration 69300, lr = 0.00566875, m = 0.9
I0802 07:53:35.423655 18636 solver.cpp:353] Iteration 69400 (7.17476 iter/s, 13.9377s/100 iter), loss = 1.57649
I0802 07:53:35.423725 18636 solver.cpp:375]     Train net output #0: loss = 1.20864 (* 1 = 1.20864 loss)
I0802 07:53:35.423732 18636 sgd_solver.cpp:136] Iteration 69400, lr = 0.0056625, m = 0.9
I0802 07:53:49.334275 18636 solver.cpp:353] Iteration 69500 (7.18895 iter/s, 13.9102s/100 iter), loss = 1.45886
I0802 07:53:49.334302 18636 solver.cpp:375]     Train net output #0: loss = 1.63244 (* 1 = 1.63244 loss)
I0802 07:53:49.334309 18636 sgd_solver.cpp:136] Iteration 69500, lr = 0.00565625, m = 0.9
I0802 07:54:03.293103 18636 solver.cpp:353] Iteration 69600 (7.16412 iter/s, 13.9584s/100 iter), loss = 1.0838
I0802 07:54:03.293131 18636 solver.cpp:375]     Train net output #0: loss = 1.30775 (* 1 = 1.30775 loss)
I0802 07:54:03.293136 18636 sgd_solver.cpp:136] Iteration 69600, lr = 0.00565, m = 0.9
I0802 07:54:17.200891 18636 solver.cpp:353] Iteration 69700 (7.19042 iter/s, 13.9074s/100 iter), loss = 1.37905
I0802 07:54:17.204915 18636 solver.cpp:375]     Train net output #0: loss = 1.31419 (* 1 = 1.31419 loss)
I0802 07:54:17.204944 18636 sgd_solver.cpp:136] Iteration 69700, lr = 0.00564375, m = 0.9
I0802 07:54:31.128787 18636 solver.cpp:353] Iteration 69800 (7.18003 iter/s, 13.9275s/100 iter), loss = 1.68834
I0802 07:54:31.128823 18636 solver.cpp:375]     Train net output #0: loss = 1.84706 (* 1 = 1.84706 loss)
I0802 07:54:31.128829 18636 sgd_solver.cpp:136] Iteration 69800, lr = 0.0056375, m = 0.9
I0802 07:54:45.017858 18636 solver.cpp:353] Iteration 69900 (7.2001 iter/s, 13.8887s/100 iter), loss = 1.1604
I0802 07:54:45.017887 18636 solver.cpp:375]     Train net output #0: loss = 1.54404 (* 1 = 1.54404 loss)
I0802 07:54:45.017894 18636 sgd_solver.cpp:136] Iteration 69900, lr = 0.00563125, m = 0.9
I0802 07:54:58.777457 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_70000.caffemodel
I0802 07:54:58.911262 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_70000.solverstate
I0802 07:54:58.916059 18636 solver.cpp:404] Sparsity after update:
I0802 07:54:58.917249 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:54:58.917259 18636 net.cpp:2270] conv1a_param_0(0.239) 
I0802 07:54:58.917266 18636 net.cpp:2270] conv1b_param_0(0.486) 
I0802 07:54:58.917269 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:54:58.917274 18636 net.cpp:2270] res2a_branch2a_param_0(0.497) 
I0802 07:54:58.917276 18636 net.cpp:2270] res2a_branch2b_param_0(0.493) 
I0802 07:54:58.917279 18636 net.cpp:2270] res3a_branch2a_param_0(0.498) 
I0802 07:54:58.917280 18636 net.cpp:2270] res3a_branch2b_param_0(0.497) 
I0802 07:54:58.917282 18636 net.cpp:2270] res4a_branch2a_param_0(0.499) 
I0802 07:54:58.917284 18636 net.cpp:2270] res4a_branch2b_param_0(0.498) 
I0802 07:54:58.917287 18636 net.cpp:2270] res5a_branch2a_param_0(0.5) 
I0802 07:54:58.917289 18636 net.cpp:2270] res5a_branch2b_param_0(0.499) 
I0802 07:54:58.917291 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.1748e+06/2.86678e+06) 0.41
I0802 07:54:58.917300 18636 solver.cpp:550] Iteration 70000, Testing net (#0)
I0802 07:55:18.085870 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.575176
I0802 07:55:18.085891 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809703
I0802 07:55:18.085896 18636 solver.cpp:635]     Test net output #2: loss = 1.87494 (* 1 = 1.87494 loss)
I0802 07:55:18.085911 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1681s
I0802 07:55:18.223258 18661 solver.cpp:450] Finding and applying sparsity: 0.51
I0802 07:55:48.831424 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:55:48.833417 18636 solver.cpp:353] Iteration 70000 (1.56706 iter/s, 63.8138s/100 iter), loss = 1.4431
I0802 07:55:48.833436 18636 solver.cpp:375]     Train net output #0: loss = 1.45462 (* 1 = 1.45462 loss)
I0802 07:55:48.833441 18636 sgd_solver.cpp:136] Iteration 70000, lr = 0.005625, m = 0.9
I0802 07:56:03.231654 18636 solver.cpp:353] Iteration 70100 (6.94549 iter/s, 14.3978s/100 iter), loss = 1.3406
I0802 07:56:03.231685 18636 solver.cpp:375]     Train net output #0: loss = 1.33157 (* 1 = 1.33157 loss)
I0802 07:56:03.231691 18636 sgd_solver.cpp:136] Iteration 70100, lr = 0.00561875, m = 0.9
I0802 07:56:17.081763 18636 solver.cpp:353] Iteration 70200 (7.22037 iter/s, 13.8497s/100 iter), loss = 1.30579
I0802 07:56:17.082036 18636 solver.cpp:375]     Train net output #0: loss = 1.46223 (* 1 = 1.46223 loss)
I0802 07:56:17.082059 18636 sgd_solver.cpp:136] Iteration 70200, lr = 0.0056125, m = 0.9
I0802 07:56:31.088872 18636 solver.cpp:353] Iteration 70300 (7.13943 iter/s, 14.0067s/100 iter), loss = 1.57607
I0802 07:56:31.088984 18636 solver.cpp:375]     Train net output #0: loss = 1.10424 (* 1 = 1.10424 loss)
I0802 07:56:31.089005 18636 sgd_solver.cpp:136] Iteration 70300, lr = 0.00560625, m = 0.9
I0802 07:56:45.055557 18636 solver.cpp:353] Iteration 70400 (7.16009 iter/s, 13.9663s/100 iter), loss = 1.3838
I0802 07:56:45.055583 18636 solver.cpp:375]     Train net output #0: loss = 1.17459 (* 1 = 1.17459 loss)
I0802 07:56:45.055588 18636 sgd_solver.cpp:136] Iteration 70400, lr = 0.0056, m = 0.9
I0802 07:56:59.017473 18636 solver.cpp:353] Iteration 70500 (7.16254 iter/s, 13.9615s/100 iter), loss = 1.10995
I0802 07:56:59.017565 18636 solver.cpp:375]     Train net output #0: loss = 1.07344 (* 1 = 1.07344 loss)
I0802 07:56:59.017586 18636 sgd_solver.cpp:136] Iteration 70500, lr = 0.00559375, m = 0.9
I0802 07:57:13.087718 18636 solver.cpp:353] Iteration 70600 (7.10739 iter/s, 14.0699s/100 iter), loss = 1.75401
I0802 07:57:13.088457 18636 solver.cpp:375]     Train net output #0: loss = 1.53673 (* 1 = 1.53673 loss)
I0802 07:57:13.088465 18636 sgd_solver.cpp:136] Iteration 70600, lr = 0.0055875, m = 0.9
I0802 07:57:27.077567 18636 solver.cpp:353] Iteration 70700 (7.14823 iter/s, 13.9895s/100 iter), loss = 1.78046
I0802 07:57:27.077591 18636 solver.cpp:375]     Train net output #0: loss = 1.68208 (* 1 = 1.68208 loss)
I0802 07:57:27.077595 18636 sgd_solver.cpp:136] Iteration 70700, lr = 0.00558125, m = 0.9
I0802 07:57:40.979928 18636 solver.cpp:353] Iteration 70800 (7.19322 iter/s, 13.902s/100 iter), loss = 1.39341
I0802 07:57:40.980041 18636 solver.cpp:375]     Train net output #0: loss = 1.1439 (* 1 = 1.1439 loss)
I0802 07:57:40.980068 18636 sgd_solver.cpp:136] Iteration 70800, lr = 0.005575, m = 0.9
I0802 07:57:54.889436 18636 solver.cpp:353] Iteration 70900 (7.18952 iter/s, 13.9091s/100 iter), loss = 1.09789
I0802 07:57:54.889500 18636 solver.cpp:375]     Train net output #0: loss = 0.911678 (* 1 = 0.911678 loss)
I0802 07:57:54.889506 18636 sgd_solver.cpp:136] Iteration 70900, lr = 0.00556875, m = 0.9
I0802 07:58:08.759035 18636 solver.cpp:404] Sparsity after update:
I0802 07:58:08.770213 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:58:08.770226 18636 net.cpp:2270] conv1a_param_0(0.251) 
I0802 07:58:08.770236 18636 net.cpp:2270] conv1b_param_0(0.5) 
I0802 07:58:08.770237 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:58:08.770241 18636 net.cpp:2270] res2a_branch2a_param_0(0.507) 
I0802 07:58:08.770242 18636 net.cpp:2270] res2a_branch2b_param_0(0.506) 
I0802 07:58:08.770243 18636 net.cpp:2270] res3a_branch2a_param_0(0.509) 
I0802 07:58:08.770246 18636 net.cpp:2270] res3a_branch2b_param_0(0.507) 
I0802 07:58:08.770247 18636 net.cpp:2270] res4a_branch2a_param_0(0.51) 
I0802 07:58:08.770249 18636 net.cpp:2270] res4a_branch2b_param_0(0.509) 
I0802 07:58:08.770251 18636 net.cpp:2270] res5a_branch2a_param_0(0.51) 
I0802 07:58:08.770253 18636 net.cpp:2270] res5a_branch2b_param_0(0.51) 
I0802 07:58:08.770256 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.19938e+06/2.86678e+06) 0.418
I0802 07:58:08.899322 18661 solver.cpp:450] Finding and applying sparsity: 0.52
I0802 07:58:40.153949 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:58:40.155865 18636 solver.cpp:353] Iteration 71000 (2.2092 iter/s, 45.2652s/100 iter), loss = 1.04932
I0802 07:58:40.155885 18636 solver.cpp:375]     Train net output #0: loss = 1.12705 (* 1 = 1.12705 loss)
I0802 07:58:40.155892 18636 sgd_solver.cpp:136] Iteration 71000, lr = 0.0055625, m = 0.9
I0802 07:58:54.626370 18636 solver.cpp:353] Iteration 71100 (6.9108 iter/s, 14.4701s/100 iter), loss = 1.01022
I0802 07:58:54.626399 18636 solver.cpp:375]     Train net output #0: loss = 1.17045 (* 1 = 1.17045 loss)
I0802 07:58:54.626404 18636 sgd_solver.cpp:136] Iteration 71100, lr = 0.00555625, m = 0.9
I0802 07:59:08.594136 18636 solver.cpp:353] Iteration 71200 (7.15954 iter/s, 13.9674s/100 iter), loss = 1.28741
I0802 07:59:08.594214 18636 solver.cpp:375]     Train net output #0: loss = 1.10459 (* 1 = 1.10459 loss)
I0802 07:59:08.594234 18636 sgd_solver.cpp:136] Iteration 71200, lr = 0.00555, m = 0.9
I0802 07:59:22.590752 18636 solver.cpp:353] Iteration 71300 (7.14478 iter/s, 13.9962s/100 iter), loss = 1.25376
I0802 07:59:22.590854 18636 solver.cpp:375]     Train net output #0: loss = 1.20394 (* 1 = 1.20394 loss)
I0802 07:59:22.590873 18636 sgd_solver.cpp:136] Iteration 71300, lr = 0.00554375, m = 0.9
I0802 07:59:36.505765 18636 solver.cpp:353] Iteration 71400 (7.18668 iter/s, 13.9146s/100 iter), loss = 1.56604
I0802 07:59:36.505794 18636 solver.cpp:375]     Train net output #0: loss = 1.9287 (* 1 = 1.9287 loss)
I0802 07:59:36.505800 18636 sgd_solver.cpp:136] Iteration 71400, lr = 0.0055375, m = 0.9
I0802 07:59:50.401963 18636 solver.cpp:353] Iteration 71500 (7.19641 iter/s, 13.8958s/100 iter), loss = 1.11948
I0802 07:59:50.401988 18636 solver.cpp:375]     Train net output #0: loss = 1.15599 (* 1 = 1.15599 loss)
I0802 07:59:50.401994 18636 sgd_solver.cpp:136] Iteration 71500, lr = 0.00553125, m = 0.9
I0802 08:00:04.373935 18636 solver.cpp:353] Iteration 71600 (7.15739 iter/s, 13.9716s/100 iter), loss = 1.15567
I0802 08:00:04.374092 18636 solver.cpp:375]     Train net output #0: loss = 1.02003 (* 1 = 1.02003 loss)
I0802 08:00:04.374114 18636 sgd_solver.cpp:136] Iteration 71600, lr = 0.005525, m = 0.9
I0802 08:00:18.433351 18636 solver.cpp:353] Iteration 71700 (7.11286 iter/s, 14.059s/100 iter), loss = 1.55132
I0802 08:00:18.433447 18636 solver.cpp:375]     Train net output #0: loss = 1.36541 (* 1 = 1.36541 loss)
I0802 08:00:18.433470 18636 sgd_solver.cpp:136] Iteration 71700, lr = 0.00551875, m = 0.9
I0802 08:00:32.458916 18636 solver.cpp:353] Iteration 71800 (7.13003 iter/s, 14.0252s/100 iter), loss = 1.53104
I0802 08:00:32.458942 18636 solver.cpp:375]     Train net output #0: loss = 1.48322 (* 1 = 1.48322 loss)
I0802 08:00:32.458947 18636 sgd_solver.cpp:136] Iteration 71800, lr = 0.0055125, m = 0.9
I0802 08:00:46.374083 18636 solver.cpp:353] Iteration 71900 (7.1866 iter/s, 13.9148s/100 iter), loss = 1.49535
I0802 08:00:46.374204 18636 solver.cpp:375]     Train net output #0: loss = 1.61956 (* 1 = 1.61956 loss)
I0802 08:00:46.374213 18636 sgd_solver.cpp:136] Iteration 71900, lr = 0.00550625, m = 0.9
I0802 08:01:00.193200 18636 solver.cpp:404] Sparsity after update:
I0802 08:01:00.197470 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:01:00.197480 18636 net.cpp:2270] conv1a_param_0(0.252) 
I0802 08:01:00.197487 18636 net.cpp:2270] conv1b_param_0(0.513) 
I0802 08:01:00.197489 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:01:00.197491 18636 net.cpp:2270] res2a_branch2a_param_0(0.517) 
I0802 08:01:00.197494 18636 net.cpp:2270] res2a_branch2b_param_0(0.513) 
I0802 08:01:00.197495 18636 net.cpp:2270] res3a_branch2a_param_0(0.519) 
I0802 08:01:00.197497 18636 net.cpp:2270] res3a_branch2b_param_0(0.517) 
I0802 08:01:00.197499 18636 net.cpp:2270] res4a_branch2a_param_0(0.52) 
I0802 08:01:00.197501 18636 net.cpp:2270] res4a_branch2b_param_0(0.519) 
I0802 08:01:00.197504 18636 net.cpp:2270] res5a_branch2a_param_0(0.52) 
I0802 08:01:00.197505 18636 net.cpp:2270] res5a_branch2b_param_0(0.52) 
I0802 08:01:00.197510 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.22334e+06/2.86678e+06) 0.427
I0802 08:01:00.197520 18636 solver.cpp:550] Iteration 72000, Testing net (#0)
I0802 08:01:19.958081 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.572471
I0802 08:01:19.958209 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.804174
I0802 08:01:19.958220 18636 solver.cpp:635]     Test net output #2: loss = 1.88335 (* 1 = 1.88335 loss)
I0802 08:01:19.958242 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7602s
I0802 08:01:20.096855 18661 solver.cpp:450] Finding and applying sparsity: 0.53
I0802 08:01:52.283674 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:01:52.285619 18636 solver.cpp:353] Iteration 72000 (1.51723 iter/s, 65.9097s/100 iter), loss = 1.58838
I0802 08:01:52.285640 18636 solver.cpp:375]     Train net output #0: loss = 1.29715 (* 1 = 1.29715 loss)
I0802 08:01:52.285645 18636 sgd_solver.cpp:136] Iteration 72000, lr = 0.0055, m = 0.9
I0802 08:02:06.657491 18636 solver.cpp:353] Iteration 72100 (6.95823 iter/s, 14.3715s/100 iter), loss = 1.66071
I0802 08:02:06.657519 18636 solver.cpp:375]     Train net output #0: loss = 1.82002 (* 1 = 1.82002 loss)
I0802 08:02:06.657526 18636 sgd_solver.cpp:136] Iteration 72100, lr = 0.00549375, m = 0.9
I0802 08:02:20.582490 18636 solver.cpp:353] Iteration 72200 (7.18153 iter/s, 13.9246s/100 iter), loss = 1.33367
I0802 08:02:20.582523 18636 solver.cpp:375]     Train net output #0: loss = 1.33511 (* 1 = 1.33511 loss)
I0802 08:02:20.582530 18636 sgd_solver.cpp:136] Iteration 72200, lr = 0.0054875, m = 0.9
I0802 08:02:34.548604 18636 solver.cpp:353] Iteration 72300 (7.16039 iter/s, 13.9657s/100 iter), loss = 1.48072
I0802 08:02:34.552850 18636 solver.cpp:375]     Train net output #0: loss = 1.31978 (* 1 = 1.31978 loss)
I0802 08:02:34.552862 18636 sgd_solver.cpp:136] Iteration 72300, lr = 0.00548125, m = 0.9
I0802 08:02:48.545006 18636 solver.cpp:353] Iteration 72400 (7.14489 iter/s, 13.996s/100 iter), loss = 1.4859
I0802 08:02:48.545033 18636 solver.cpp:375]     Train net output #0: loss = 1.71166 (* 1 = 1.71166 loss)
I0802 08:02:48.545039 18636 sgd_solver.cpp:136] Iteration 72400, lr = 0.005475, m = 0.9
I0802 08:03:02.486632 18636 solver.cpp:353] Iteration 72500 (7.17296 iter/s, 13.9412s/100 iter), loss = 1.20358
I0802 08:03:02.486657 18636 solver.cpp:375]     Train net output #0: loss = 1.22072 (* 1 = 1.22072 loss)
I0802 08:03:02.486662 18636 sgd_solver.cpp:136] Iteration 72500, lr = 0.00546875, m = 0.9
I0802 08:03:16.403381 18636 solver.cpp:353] Iteration 72600 (7.18578 iter/s, 13.9164s/100 iter), loss = 1.08699
I0802 08:03:16.403439 18636 solver.cpp:375]     Train net output #0: loss = 1.26995 (* 1 = 1.26995 loss)
I0802 08:03:16.403443 18636 sgd_solver.cpp:136] Iteration 72600, lr = 0.0054625, m = 0.9
I0802 08:03:30.409562 18636 solver.cpp:353] Iteration 72700 (7.1399 iter/s, 14.0058s/100 iter), loss = 1.4426
I0802 08:03:30.409590 18636 solver.cpp:375]     Train net output #0: loss = 1.30968 (* 1 = 1.30968 loss)
I0802 08:03:30.409595 18636 sgd_solver.cpp:136] Iteration 72700, lr = 0.00545625, m = 0.9
I0802 08:03:44.280190 18636 solver.cpp:353] Iteration 72800 (7.20968 iter/s, 13.8702s/100 iter), loss = 1.32172
I0802 08:03:44.280216 18636 solver.cpp:375]     Train net output #0: loss = 1.47756 (* 1 = 1.47756 loss)
I0802 08:03:44.280222 18636 sgd_solver.cpp:136] Iteration 72800, lr = 0.00545, m = 0.9
I0802 08:03:58.198317 18636 solver.cpp:353] Iteration 72900 (7.18507 iter/s, 13.9177s/100 iter), loss = 1.33922
I0802 08:03:58.198395 18636 solver.cpp:375]     Train net output #0: loss = 1.29821 (* 1 = 1.29821 loss)
I0802 08:03:58.198402 18636 sgd_solver.cpp:136] Iteration 72900, lr = 0.00544375, m = 0.9
I0802 08:04:12.097672 18636 solver.cpp:404] Sparsity after update:
I0802 08:04:12.109246 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:04:12.109258 18636 net.cpp:2270] conv1a_param_0(0.252) 
I0802 08:04:12.109267 18636 net.cpp:2270] conv1b_param_0(0.527) 
I0802 08:04:12.109271 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:04:12.109282 18636 net.cpp:2270] res2a_branch2a_param_0(0.528) 
I0802 08:04:12.109292 18636 net.cpp:2270] res2a_branch2b_param_0(0.526) 
I0802 08:04:12.109299 18636 net.cpp:2270] res3a_branch2a_param_0(0.53) 
I0802 08:04:12.109308 18636 net.cpp:2270] res3a_branch2b_param_0(0.528) 
I0802 08:04:12.109316 18636 net.cpp:2270] res4a_branch2a_param_0(0.53) 
I0802 08:04:12.109324 18636 net.cpp:2270] res4a_branch2b_param_0(0.53) 
I0802 08:04:12.109333 18636 net.cpp:2270] res5a_branch2a_param_0(0.53) 
I0802 08:04:12.109344 18636 net.cpp:2270] res5a_branch2b_param_0(0.53) 
I0802 08:04:12.109354 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.24659e+06/2.86678e+06) 0.435
I0802 08:04:12.237202 18661 solver.cpp:450] Finding and applying sparsity: 0.54
I0802 08:04:44.603379 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:04:44.605329 18636 solver.cpp:353] Iteration 73000 (2.15491 iter/s, 46.4057s/100 iter), loss = 1.25414
I0802 08:04:44.605351 18636 solver.cpp:375]     Train net output #0: loss = 1.36101 (* 1 = 1.36101 loss)
I0802 08:04:44.605360 18636 sgd_solver.cpp:136] Iteration 73000, lr = 0.0054375, m = 0.9
I0802 08:04:59.307580 18636 solver.cpp:353] Iteration 73100 (6.80187 iter/s, 14.7018s/100 iter), loss = 1.44571
I0802 08:04:59.307610 18636 solver.cpp:375]     Train net output #0: loss = 1.345 (* 1 = 1.345 loss)
I0802 08:04:59.307615 18636 sgd_solver.cpp:136] Iteration 73100, lr = 0.00543125, m = 0.9
I0802 08:05:13.177667 18636 solver.cpp:353] Iteration 73200 (7.20996 iter/s, 13.8697s/100 iter), loss = 1.17028
I0802 08:05:13.177691 18636 solver.cpp:375]     Train net output #0: loss = 1.30014 (* 1 = 1.30014 loss)
I0802 08:05:13.177697 18636 sgd_solver.cpp:136] Iteration 73200, lr = 0.005425, m = 0.9
I0802 08:05:27.020087 18636 solver.cpp:353] Iteration 73300 (7.22437 iter/s, 13.842s/100 iter), loss = 1.13036
I0802 08:05:27.020140 18636 solver.cpp:375]     Train net output #0: loss = 1.15774 (* 1 = 1.15774 loss)
I0802 08:05:27.020146 18636 sgd_solver.cpp:136] Iteration 73300, lr = 0.00541875, m = 0.9
I0802 08:05:30.888306 18598 blocking_queue.cpp:40] Waiting for datum
I0802 08:05:41.034279 18636 solver.cpp:353] Iteration 73400 (7.13582 iter/s, 14.0138s/100 iter), loss = 1.2131
I0802 08:05:41.034303 18636 solver.cpp:375]     Train net output #0: loss = 1.15396 (* 1 = 1.15396 loss)
I0802 08:05:41.034307 18636 sgd_solver.cpp:136] Iteration 73400, lr = 0.0054125, m = 0.9
I0802 08:05:54.995373 18636 solver.cpp:353] Iteration 73500 (7.16296 iter/s, 13.9607s/100 iter), loss = 1.36263
I0802 08:05:54.995424 18636 solver.cpp:375]     Train net output #0: loss = 1.09646 (* 1 = 1.09646 loss)
I0802 08:05:54.995437 18636 sgd_solver.cpp:136] Iteration 73500, lr = 0.00540625, m = 0.9
I0802 08:06:08.931278 18636 solver.cpp:353] Iteration 73600 (7.17591 iter/s, 13.9355s/100 iter), loss = 1.2117
I0802 08:06:08.931365 18636 solver.cpp:375]     Train net output #0: loss = 1.1703 (* 1 = 1.1703 loss)
I0802 08:06:08.931371 18636 sgd_solver.cpp:136] Iteration 73600, lr = 0.0054, m = 0.9
I0802 08:06:22.911173 18636 solver.cpp:353] Iteration 73700 (7.15333 iter/s, 13.9795s/100 iter), loss = 1.33447
I0802 08:06:22.911197 18636 solver.cpp:375]     Train net output #0: loss = 1.40971 (* 1 = 1.40971 loss)
I0802 08:06:22.911201 18636 sgd_solver.cpp:136] Iteration 73700, lr = 0.00539375, m = 0.9
I0802 08:06:36.818135 18636 solver.cpp:353] Iteration 73800 (7.19084 iter/s, 13.9066s/100 iter), loss = 1.44144
I0802 08:06:36.818163 18636 solver.cpp:375]     Train net output #0: loss = 1.55613 (* 1 = 1.55613 loss)
I0802 08:06:36.818171 18636 sgd_solver.cpp:136] Iteration 73800, lr = 0.0053875, m = 0.9
I0802 08:06:50.626868 18636 solver.cpp:353] Iteration 73900 (7.24199 iter/s, 13.8084s/100 iter), loss = 1.54135
I0802 08:06:50.626955 18636 solver.cpp:375]     Train net output #0: loss = 1.50792 (* 1 = 1.50792 loss)
I0802 08:06:50.626962 18636 sgd_solver.cpp:136] Iteration 73900, lr = 0.00538125, m = 0.9
I0802 08:07:04.387171 18636 solver.cpp:404] Sparsity after update:
I0802 08:07:04.391553 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:07:04.391568 18636 net.cpp:2270] conv1a_param_0(0.264) 
I0802 08:07:04.391578 18636 net.cpp:2270] conv1b_param_0(0.527) 
I0802 08:07:04.391582 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:07:04.391587 18636 net.cpp:2270] res2a_branch2a_param_0(0.538) 
I0802 08:07:04.391590 18636 net.cpp:2270] res2a_branch2b_param_0(0.533) 
I0802 08:07:04.391594 18636 net.cpp:2270] res3a_branch2a_param_0(0.54) 
I0802 08:07:04.391597 18636 net.cpp:2270] res3a_branch2b_param_0(0.538) 
I0802 08:07:04.391600 18636 net.cpp:2270] res4a_branch2a_param_0(0.54) 
I0802 08:07:04.391603 18636 net.cpp:2270] res4a_branch2b_param_0(0.54) 
I0802 08:07:04.391607 18636 net.cpp:2270] res5a_branch2a_param_0(0.54) 
I0802 08:07:04.391609 18636 net.cpp:2270] res5a_branch2b_param_0(0.54) 
I0802 08:07:04.391613 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.27056e+06/2.86678e+06) 0.443
I0802 08:07:04.391623 18636 solver.cpp:550] Iteration 74000, Testing net (#0)
I0802 08:07:07.516822 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:07:09.473918 18619 data_reader.cpp:264] Starting prefetch of epoch 4
I0802 08:07:23.680622 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.580294
I0802 08:07:23.680735 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.812351
I0802 08:07:23.680744 18636 solver.cpp:635]     Test net output #2: loss = 1.83164 (* 1 = 1.83164 loss)
I0802 08:07:23.680764 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2886s
I0802 08:07:23.835762 18661 solver.cpp:450] Finding and applying sparsity: 0.55
I0802 08:07:56.570442 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:07:56.572371 18636 solver.cpp:353] Iteration 74000 (1.51644 iter/s, 65.9437s/100 iter), loss = 1.33973
I0802 08:07:56.572391 18636 solver.cpp:375]     Train net output #0: loss = 1.00397 (* 1 = 1.00397 loss)
I0802 08:07:56.572397 18636 sgd_solver.cpp:136] Iteration 74000, lr = 0.005375, m = 0.9
I0802 08:08:10.897367 18636 solver.cpp:353] Iteration 74100 (6.981 iter/s, 14.3246s/100 iter), loss = 1.569
I0802 08:08:10.897399 18636 solver.cpp:375]     Train net output #0: loss = 1.61277 (* 1 = 1.61277 loss)
I0802 08:08:10.897405 18636 sgd_solver.cpp:136] Iteration 74100, lr = 0.00536875, m = 0.9
I0802 08:08:24.883930 18636 solver.cpp:353] Iteration 74200 (7.14992 iter/s, 13.9862s/100 iter), loss = 1.69327
I0802 08:08:24.883963 18636 solver.cpp:375]     Train net output #0: loss = 1.93148 (* 1 = 1.93148 loss)
I0802 08:08:24.883970 18636 sgd_solver.cpp:136] Iteration 74200, lr = 0.0053625, m = 0.9
I0802 08:08:38.771098 18636 solver.cpp:353] Iteration 74300 (7.20109 iter/s, 13.8868s/100 iter), loss = 1.12379
I0802 08:08:38.771154 18636 solver.cpp:375]     Train net output #0: loss = 1.22194 (* 1 = 1.22194 loss)
I0802 08:08:38.771162 18636 sgd_solver.cpp:136] Iteration 74300, lr = 0.00535625, m = 0.9
I0802 08:08:52.687589 18636 solver.cpp:353] Iteration 74400 (7.18592 iter/s, 13.9161s/100 iter), loss = 1.13894
I0802 08:08:52.687680 18636 solver.cpp:375]     Train net output #0: loss = 1.06957 (* 1 = 1.06957 loss)
I0802 08:08:52.687698 18636 sgd_solver.cpp:136] Iteration 74400, lr = 0.00535, m = 0.9
I0802 08:09:06.646972 18636 solver.cpp:353] Iteration 74500 (7.16384 iter/s, 13.959s/100 iter), loss = 1.66617
I0802 08:09:06.646998 18636 solver.cpp:375]     Train net output #0: loss = 1.83807 (* 1 = 1.83807 loss)
I0802 08:09:06.647003 18636 sgd_solver.cpp:136] Iteration 74500, lr = 0.00534375, m = 0.9
I0802 08:09:20.549233 18636 solver.cpp:353] Iteration 74600 (7.19327 iter/s, 13.9019s/100 iter), loss = 1.25345
I0802 08:09:20.549315 18636 solver.cpp:375]     Train net output #0: loss = 0.997739 (* 1 = 0.997739 loss)
I0802 08:09:20.549324 18636 sgd_solver.cpp:136] Iteration 74600, lr = 0.0053375, m = 0.9
I0802 08:09:34.464601 18636 solver.cpp:353] Iteration 74700 (7.1865 iter/s, 13.915s/100 iter), loss = 1.11344
I0802 08:09:34.464624 18636 solver.cpp:375]     Train net output #0: loss = 1.25958 (* 1 = 1.25958 loss)
I0802 08:09:34.464628 18636 sgd_solver.cpp:136] Iteration 74700, lr = 0.00533125, m = 0.9
I0802 08:09:48.356710 18636 solver.cpp:353] Iteration 74800 (7.19853 iter/s, 13.8917s/100 iter), loss = 1.51957
I0802 08:09:48.356739 18636 solver.cpp:375]     Train net output #0: loss = 1.50459 (* 1 = 1.50459 loss)
I0802 08:09:48.356745 18636 sgd_solver.cpp:136] Iteration 74800, lr = 0.005325, m = 0.9
I0802 08:10:02.249914 18636 solver.cpp:353] Iteration 74900 (7.19796 iter/s, 13.8928s/100 iter), loss = 1.68665
I0802 08:10:02.249974 18636 solver.cpp:375]     Train net output #0: loss = 2.00398 (* 1 = 2.00398 loss)
I0802 08:10:02.249979 18636 sgd_solver.cpp:136] Iteration 74900, lr = 0.00531875, m = 0.9
I0802 08:10:15.996865 18636 solver.cpp:404] Sparsity after update:
I0802 08:10:16.007060 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:10:16.007072 18636 net.cpp:2270] conv1a_param_0(0.265) 
I0802 08:10:16.007082 18636 net.cpp:2270] conv1b_param_0(0.54) 
I0802 08:10:16.007086 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:10:16.007089 18636 net.cpp:2270] res2a_branch2a_param_0(0.549) 
I0802 08:10:16.007092 18636 net.cpp:2270] res2a_branch2b_param_0(0.546) 
I0802 08:10:16.007095 18636 net.cpp:2270] res3a_branch2a_param_0(0.549) 
I0802 08:10:16.007098 18636 net.cpp:2270] res3a_branch2b_param_0(0.548) 
I0802 08:10:16.007102 18636 net.cpp:2270] res4a_branch2a_param_0(0.549) 
I0802 08:10:16.007104 18636 net.cpp:2270] res4a_branch2b_param_0(0.549) 
I0802 08:10:16.007108 18636 net.cpp:2270] res5a_branch2a_param_0(0.55) 
I0802 08:10:16.007112 18636 net.cpp:2270] res5a_branch2b_param_0(0.549) 
I0802 08:10:16.007114 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.29343e+06/2.86678e+06) 0.451
I0802 08:10:16.135731 18661 solver.cpp:450] Finding and applying sparsity: 0.56
I0802 08:10:49.662852 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:10:49.664790 18636 solver.cpp:353] Iteration 75000 (2.1091 iter/s, 47.4136s/100 iter), loss = 1.08956
I0802 08:10:49.664809 18636 solver.cpp:375]     Train net output #0: loss = 1.13773 (* 1 = 1.13773 loss)
I0802 08:10:49.664819 18636 sgd_solver.cpp:136] Iteration 75000, lr = 0.0053125, m = 0.9
I0802 08:11:04.155052 18636 solver.cpp:353] Iteration 75100 (6.90138 iter/s, 14.4899s/100 iter), loss = 1.00517
I0802 08:11:04.155082 18636 solver.cpp:375]     Train net output #0: loss = 1.01676 (* 1 = 1.01676 loss)
I0802 08:11:04.155088 18636 sgd_solver.cpp:136] Iteration 75100, lr = 0.00530625, m = 0.9
I0802 08:11:18.108217 18636 solver.cpp:353] Iteration 75200 (7.16703 iter/s, 13.9528s/100 iter), loss = 1.24104
I0802 08:11:18.108253 18636 solver.cpp:375]     Train net output #0: loss = 1.40189 (* 1 = 1.40189 loss)
I0802 08:11:18.108260 18636 sgd_solver.cpp:136] Iteration 75200, lr = 0.0053, m = 0.9
I0802 08:11:32.021363 18636 solver.cpp:353] Iteration 75300 (7.18764 iter/s, 13.9128s/100 iter), loss = 1.62443
I0802 08:11:32.021915 18636 solver.cpp:375]     Train net output #0: loss = 2.08066 (* 1 = 2.08066 loss)
I0802 08:11:32.021920 18636 sgd_solver.cpp:136] Iteration 75300, lr = 0.00529375, m = 0.9
I0802 08:11:46.041849 18636 solver.cpp:353] Iteration 75400 (7.13262 iter/s, 14.0201s/100 iter), loss = 1.61623
I0802 08:11:46.041875 18636 solver.cpp:375]     Train net output #0: loss = 1.64552 (* 1 = 1.64552 loss)
I0802 08:11:46.041880 18636 sgd_solver.cpp:136] Iteration 75400, lr = 0.0052875, m = 0.9
I0802 08:11:59.962222 18636 solver.cpp:353] Iteration 75500 (7.18391 iter/s, 13.92s/100 iter), loss = 1.27937
I0802 08:11:59.962249 18636 solver.cpp:375]     Train net output #0: loss = 1.31399 (* 1 = 1.31399 loss)
I0802 08:11:59.962254 18636 sgd_solver.cpp:136] Iteration 75500, lr = 0.00528125, m = 0.9
I0802 08:12:13.908139 18636 solver.cpp:353] Iteration 75600 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.16087
I0802 08:12:13.908210 18636 solver.cpp:375]     Train net output #0: loss = 1.26023 (* 1 = 1.26023 loss)
I0802 08:12:13.908217 18636 sgd_solver.cpp:136] Iteration 75600, lr = 0.005275, m = 0.9
I0802 08:12:27.820760 18636 solver.cpp:353] Iteration 75700 (7.18792 iter/s, 13.9122s/100 iter), loss = 1.16611
I0802 08:12:27.820792 18636 solver.cpp:375]     Train net output #0: loss = 1.26403 (* 1 = 1.26403 loss)
I0802 08:12:27.820799 18636 sgd_solver.cpp:136] Iteration 75700, lr = 0.00526875, m = 0.9
I0802 08:12:41.764339 18636 solver.cpp:353] Iteration 75800 (7.17196 iter/s, 13.9432s/100 iter), loss = 1.09373
I0802 08:12:41.764420 18636 solver.cpp:375]     Train net output #0: loss = 1.01472 (* 1 = 1.01472 loss)
I0802 08:12:41.764443 18636 sgd_solver.cpp:136] Iteration 75800, lr = 0.0052625, m = 0.9
I0802 08:12:55.837488 18636 solver.cpp:353] Iteration 75900 (7.10593 iter/s, 14.0728s/100 iter), loss = 1.01327
I0802 08:12:55.837555 18636 solver.cpp:375]     Train net output #0: loss = 0.895902 (* 1 = 0.895902 loss)
I0802 08:12:55.837563 18636 sgd_solver.cpp:136] Iteration 75900, lr = 0.00525625, m = 0.9
I0802 08:13:09.685866 18636 solver.cpp:404] Sparsity after update:
I0802 08:13:09.690080 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:13:09.690091 18636 net.cpp:2270] conv1a_param_0(0.265) 
I0802 08:13:09.690099 18636 net.cpp:2270] conv1b_param_0(0.553) 
I0802 08:13:09.690101 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:13:09.690104 18636 net.cpp:2270] res2a_branch2a_param_0(0.559) 
I0802 08:13:09.690105 18636 net.cpp:2270] res2a_branch2b_param_0(0.553) 
I0802 08:13:09.690107 18636 net.cpp:2270] res3a_branch2a_param_0(0.559) 
I0802 08:13:09.690111 18636 net.cpp:2270] res3a_branch2b_param_0(0.559) 
I0802 08:13:09.690115 18636 net.cpp:2270] res4a_branch2a_param_0(0.56) 
I0802 08:13:09.690119 18636 net.cpp:2270] res4a_branch2b_param_0(0.559) 
I0802 08:13:09.690121 18636 net.cpp:2270] res5a_branch2a_param_0(0.56) 
I0802 08:13:09.690130 18636 net.cpp:2270] res5a_branch2b_param_0(0.56) 
I0802 08:13:09.690135 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.31739e+06/2.86678e+06) 0.46
I0802 08:13:09.690147 18636 solver.cpp:550] Iteration 76000, Testing net (#0)
I0802 08:13:29.311144 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574941
I0802 08:13:29.311261 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805761
I0802 08:13:29.311270 18636 solver.cpp:635]     Test net output #2: loss = 1.88112 (* 1 = 1.88112 loss)
I0802 08:13:29.311291 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6206s
I0802 08:13:29.458905 18661 solver.cpp:450] Finding and applying sparsity: 0.57
I0802 08:14:04.003764 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:14:04.005677 18636 solver.cpp:353] Iteration 76000 (1.467 iter/s, 68.1663s/100 iter), loss = 1.45668
I0802 08:14:04.005699 18636 solver.cpp:375]     Train net output #0: loss = 1.28637 (* 1 = 1.28637 loss)
I0802 08:14:04.005707 18636 sgd_solver.cpp:136] Iteration 76000, lr = 0.00525, m = 0.9
I0802 08:14:18.343466 18636 solver.cpp:353] Iteration 76100 (6.97478 iter/s, 14.3374s/100 iter), loss = 1.07852
I0802 08:14:18.343513 18636 solver.cpp:375]     Train net output #0: loss = 0.916718 (* 1 = 0.916718 loss)
I0802 08:14:18.343520 18636 sgd_solver.cpp:136] Iteration 76100, lr = 0.00524375, m = 0.9
I0802 08:14:32.326293 18636 solver.cpp:353] Iteration 76200 (7.15183 iter/s, 13.9824s/100 iter), loss = 1.10464
I0802 08:14:32.326344 18636 solver.cpp:375]     Train net output #0: loss = 1.46668 (* 1 = 1.46668 loss)
I0802 08:14:32.326356 18636 sgd_solver.cpp:136] Iteration 76200, lr = 0.0052375, m = 0.9
I0802 08:14:46.292982 18636 solver.cpp:353] Iteration 76300 (7.16009 iter/s, 13.9663s/100 iter), loss = 1.17117
I0802 08:14:46.293922 18636 solver.cpp:375]     Train net output #0: loss = 1.1837 (* 1 = 1.1837 loss)
I0802 08:14:46.293929 18636 sgd_solver.cpp:136] Iteration 76300, lr = 0.00523125, m = 0.9
I0802 08:15:00.200189 18636 solver.cpp:353] Iteration 76400 (7.19072 iter/s, 13.9068s/100 iter), loss = 1.24655
I0802 08:15:00.200218 18636 solver.cpp:375]     Train net output #0: loss = 1.08557 (* 1 = 1.08557 loss)
I0802 08:15:00.200225 18636 sgd_solver.cpp:136] Iteration 76400, lr = 0.005225, m = 0.9
I0802 08:15:14.188031 18636 solver.cpp:353] Iteration 76500 (7.14926 iter/s, 13.9875s/100 iter), loss = 1.25519
I0802 08:15:14.188138 18636 solver.cpp:375]     Train net output #0: loss = 1.24763 (* 1 = 1.24763 loss)
I0802 08:15:14.188156 18636 sgd_solver.cpp:136] Iteration 76500, lr = 0.00521875, m = 0.9
I0802 08:15:28.218001 18636 solver.cpp:353] Iteration 76600 (7.1278 iter/s, 14.0296s/100 iter), loss = 1.20024
I0802 08:15:28.218086 18636 solver.cpp:375]     Train net output #0: loss = 1.10367 (* 1 = 1.10367 loss)
I0802 08:15:28.218097 18636 sgd_solver.cpp:136] Iteration 76600, lr = 0.0052125, m = 0.9
I0802 08:15:42.292749 18636 solver.cpp:353] Iteration 76700 (7.10512 iter/s, 14.0744s/100 iter), loss = 1.31893
I0802 08:15:42.292779 18636 solver.cpp:375]     Train net output #0: loss = 1.53437 (* 1 = 1.53437 loss)
I0802 08:15:42.292785 18636 sgd_solver.cpp:136] Iteration 76700, lr = 0.00520625, m = 0.9
I0802 08:15:56.241667 18636 solver.cpp:353] Iteration 76800 (7.16921 iter/s, 13.9485s/100 iter), loss = 1.24894
I0802 08:15:56.241721 18636 solver.cpp:375]     Train net output #0: loss = 1.18864 (* 1 = 1.18864 loss)
I0802 08:15:56.241734 18636 sgd_solver.cpp:136] Iteration 76800, lr = 0.0052, m = 0.9
I0802 08:16:10.150779 18636 solver.cpp:353] Iteration 76900 (7.18973 iter/s, 13.9087s/100 iter), loss = 1.38769
I0802 08:16:10.150837 18636 solver.cpp:375]     Train net output #0: loss = 1.44202 (* 1 = 1.44202 loss)
I0802 08:16:10.150842 18636 sgd_solver.cpp:136] Iteration 76900, lr = 0.00519375, m = 0.9
I0802 08:16:24.028152 18636 solver.cpp:404] Sparsity after update:
I0802 08:16:24.038656 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:16:24.038671 18636 net.cpp:2270] conv1a_param_0(0.278) 
I0802 08:16:24.038679 18636 net.cpp:2270] conv1b_param_0(0.567) 
I0802 08:16:24.038682 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:16:24.038686 18636 net.cpp:2270] res2a_branch2a_param_0(0.569) 
I0802 08:16:24.038689 18636 net.cpp:2270] res2a_branch2b_param_0(0.566) 
I0802 08:16:24.038699 18636 net.cpp:2270] res3a_branch2a_param_0(0.569) 
I0802 08:16:24.038705 18636 net.cpp:2270] res3a_branch2b_param_0(0.569) 
I0802 08:16:24.038710 18636 net.cpp:2270] res4a_branch2a_param_0(0.569) 
I0802 08:16:24.038715 18636 net.cpp:2270] res4a_branch2b_param_0(0.569) 
I0802 08:16:24.038719 18636 net.cpp:2270] res5a_branch2a_param_0(0.57) 
I0802 08:16:24.038724 18636 net.cpp:2270] res5a_branch2b_param_0(0.569) 
I0802 08:16:24.038728 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.34068e+06/2.86678e+06) 0.468
I0802 08:16:24.167753 18661 solver.cpp:450] Finding and applying sparsity: 0.58
I0802 08:16:59.883116 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:16:59.885057 18636 solver.cpp:353] Iteration 77000 (2.01074 iter/s, 49.7329s/100 iter), loss = 1.29005
I0802 08:16:59.885074 18636 solver.cpp:375]     Train net output #0: loss = 1.4213 (* 1 = 1.4213 loss)
I0802 08:16:59.885079 18636 sgd_solver.cpp:136] Iteration 77000, lr = 0.0051875, m = 0.9
I0802 08:17:14.268240 18636 solver.cpp:353] Iteration 77100 (6.95276 iter/s, 14.3828s/100 iter), loss = 1.25629
I0802 08:17:14.268268 18636 solver.cpp:375]     Train net output #0: loss = 1.08426 (* 1 = 1.08426 loss)
I0802 08:17:14.268275 18636 sgd_solver.cpp:136] Iteration 77100, lr = 0.00518125, m = 0.9
I0802 08:17:28.153934 18636 solver.cpp:353] Iteration 77200 (7.20186 iter/s, 13.8853s/100 iter), loss = 1.19158
I0802 08:17:28.153959 18636 solver.cpp:375]     Train net output #0: loss = 0.868437 (* 1 = 0.868437 loss)
I0802 08:17:28.153964 18636 sgd_solver.cpp:136] Iteration 77200, lr = 0.005175, m = 0.9
I0802 08:17:42.071753 18636 solver.cpp:353] Iteration 77300 (7.18523 iter/s, 13.9174s/100 iter), loss = 1.28968
I0802 08:17:42.071847 18636 solver.cpp:375]     Train net output #0: loss = 1.15461 (* 1 = 1.15461 loss)
I0802 08:17:42.071854 18636 sgd_solver.cpp:136] Iteration 77300, lr = 0.00516875, m = 0.9
I0802 08:17:55.962553 18636 solver.cpp:353] Iteration 77400 (7.19921 iter/s, 13.8904s/100 iter), loss = 1.60079
I0802 08:17:55.962579 18636 solver.cpp:375]     Train net output #0: loss = 1.18907 (* 1 = 1.18907 loss)
I0802 08:17:55.962584 18636 sgd_solver.cpp:136] Iteration 77400, lr = 0.0051625, m = 0.9
I0802 08:18:09.949780 18636 solver.cpp:353] Iteration 77500 (7.14958 iter/s, 13.9868s/100 iter), loss = 1.64344
I0802 08:18:09.949856 18636 solver.cpp:375]     Train net output #0: loss = 1.39875 (* 1 = 1.39875 loss)
I0802 08:18:09.949874 18636 sgd_solver.cpp:136] Iteration 77500, lr = 0.00515625, m = 0.9
I0802 08:18:24.371942 18636 solver.cpp:353] Iteration 77600 (6.93396 iter/s, 14.4218s/100 iter), loss = 1.16385
I0802 08:18:24.372042 18636 solver.cpp:375]     Train net output #0: loss = 1.03967 (* 1 = 1.03967 loss)
I0802 08:18:24.372051 18636 sgd_solver.cpp:136] Iteration 77600, lr = 0.00515, m = 0.9
I0802 08:18:38.402966 18636 solver.cpp:353] Iteration 77700 (7.12726 iter/s, 14.0306s/100 iter), loss = 1.51309
I0802 08:18:38.402993 18636 solver.cpp:375]     Train net output #0: loss = 1.47739 (* 1 = 1.47739 loss)
I0802 08:18:38.402999 18636 sgd_solver.cpp:136] Iteration 77700, lr = 0.00514375, m = 0.9
I0802 08:18:52.366325 18636 solver.cpp:353] Iteration 77800 (7.1618 iter/s, 13.963s/100 iter), loss = 1.22672
I0802 08:18:52.366358 18636 solver.cpp:375]     Train net output #0: loss = 1.45643 (* 1 = 1.45643 loss)
I0802 08:18:52.366364 18636 sgd_solver.cpp:136] Iteration 77800, lr = 0.0051375, m = 0.9
I0802 08:19:06.256942 18636 solver.cpp:353] Iteration 77900 (7.1993 iter/s, 13.8902s/100 iter), loss = 0.986368
I0802 08:19:06.256999 18636 solver.cpp:375]     Train net output #0: loss = 0.845375 (* 1 = 0.845375 loss)
I0802 08:19:06.257004 18636 sgd_solver.cpp:136] Iteration 77900, lr = 0.00513125, m = 0.9
I0802 08:19:20.090966 18636 solver.cpp:404] Sparsity after update:
I0802 08:19:20.095268 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:19:20.095280 18636 net.cpp:2270] conv1a_param_0(0.278) 
I0802 08:19:20.095289 18636 net.cpp:2270] conv1b_param_0(0.567) 
I0802 08:19:20.095293 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:19:20.095299 18636 net.cpp:2270] res2a_branch2a_param_0(0.58) 
I0802 08:19:20.095301 18636 net.cpp:2270] res2a_branch2b_param_0(0.572) 
I0802 08:19:20.095304 18636 net.cpp:2270] res3a_branch2a_param_0(0.58) 
I0802 08:19:20.095309 18636 net.cpp:2270] res3a_branch2b_param_0(0.58) 
I0802 08:19:20.095311 18636 net.cpp:2270] res4a_branch2a_param_0(0.58) 
I0802 08:19:20.095315 18636 net.cpp:2270] res4a_branch2b_param_0(0.58) 
I0802 08:19:20.095319 18636 net.cpp:2270] res5a_branch2a_param_0(0.58) 
I0802 08:19:20.095324 18636 net.cpp:2270] res5a_branch2b_param_0(0.58) 
I0802 08:19:20.095327 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.3646e+06/2.86678e+06) 0.476
I0802 08:19:20.095340 18636 solver.cpp:550] Iteration 78000, Testing net (#0)
I0802 08:19:39.661051 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578765
I0802 08:19:39.661154 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810644
I0802 08:19:39.661164 18636 solver.cpp:635]     Test net output #2: loss = 1.83807 (* 1 = 1.83807 loss)
I0802 08:19:39.661190 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5653s
I0802 08:19:39.823632 18661 solver.cpp:450] Finding and applying sparsity: 0.59
I0802 08:20:15.916676 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:20:15.918823 18636 solver.cpp:353] Iteration 78000 (1.43554 iter/s, 69.66s/100 iter), loss = 1.28687
I0802 08:20:15.918860 18636 solver.cpp:375]     Train net output #0: loss = 1.25517 (* 1 = 1.25517 loss)
I0802 08:20:15.918870 18636 sgd_solver.cpp:136] Iteration 78000, lr = 0.005125, m = 0.9
I0802 08:20:30.354903 18636 solver.cpp:353] Iteration 78100 (6.92728 iter/s, 14.4357s/100 iter), loss = 1.34036
I0802 08:20:30.354928 18636 solver.cpp:375]     Train net output #0: loss = 1.27248 (* 1 = 1.27248 loss)
I0802 08:20:30.354933 18636 sgd_solver.cpp:136] Iteration 78100, lr = 0.00511875, m = 0.9
I0802 08:20:44.187207 18636 solver.cpp:353] Iteration 78200 (7.22965 iter/s, 13.8319s/100 iter), loss = 1.24309
I0802 08:20:44.187237 18636 solver.cpp:375]     Train net output #0: loss = 1.31145 (* 1 = 1.31145 loss)
I0802 08:20:44.187243 18636 sgd_solver.cpp:136] Iteration 78200, lr = 0.0051125, m = 0.9
I0802 08:20:58.086968 18636 solver.cpp:353] Iteration 78300 (7.19457 iter/s, 13.8994s/100 iter), loss = 1.34501
I0802 08:20:58.087075 18636 solver.cpp:375]     Train net output #0: loss = 1.25495 (* 1 = 1.25495 loss)
I0802 08:20:58.087082 18636 sgd_solver.cpp:136] Iteration 78300, lr = 0.00510625, m = 0.9
I0802 08:21:12.019338 18636 solver.cpp:353] Iteration 78400 (7.17773 iter/s, 13.932s/100 iter), loss = 1.6249
I0802 08:21:12.019368 18636 solver.cpp:375]     Train net output #0: loss = 1.61225 (* 1 = 1.61225 loss)
I0802 08:21:12.019374 18636 sgd_solver.cpp:136] Iteration 78400, lr = 0.0051, m = 0.9
I0802 08:21:26.033515 18636 solver.cpp:353] Iteration 78500 (7.13583 iter/s, 14.0138s/100 iter), loss = 1.07121
I0802 08:21:26.033545 18636 solver.cpp:375]     Train net output #0: loss = 1.14162 (* 1 = 1.14162 loss)
I0802 08:21:26.033551 18636 sgd_solver.cpp:136] Iteration 78500, lr = 0.00509375, m = 0.9
I0802 08:21:40.026865 18636 solver.cpp:353] Iteration 78600 (7.14645 iter/s, 13.993s/100 iter), loss = 1.37187
I0802 08:21:40.026952 18636 solver.cpp:375]     Train net output #0: loss = 1.58404 (* 1 = 1.58404 loss)
I0802 08:21:40.026958 18636 sgd_solver.cpp:136] Iteration 78600, lr = 0.0050875, m = 0.9
I0802 08:21:53.925032 18636 solver.cpp:353] Iteration 78700 (7.19539 iter/s, 13.8978s/100 iter), loss = 1.50024
I0802 08:21:53.925142 18636 solver.cpp:375]     Train net output #0: loss = 1.44175 (* 1 = 1.44175 loss)
I0802 08:21:53.925166 18636 sgd_solver.cpp:136] Iteration 78700, lr = 0.00508125, m = 0.9
I0802 08:22:07.840158 18636 solver.cpp:353] Iteration 78800 (7.18662 iter/s, 13.9147s/100 iter), loss = 1.52296
I0802 08:22:07.840194 18636 solver.cpp:375]     Train net output #0: loss = 1.31754 (* 1 = 1.31754 loss)
I0802 08:22:07.840200 18636 sgd_solver.cpp:136] Iteration 78800, lr = 0.005075, m = 0.9
I0802 08:22:21.799145 18636 solver.cpp:353] Iteration 78900 (7.16404 iter/s, 13.9586s/100 iter), loss = 1.12924
I0802 08:22:21.799223 18636 solver.cpp:375]     Train net output #0: loss = 1.18742 (* 1 = 1.18742 loss)
I0802 08:22:21.799232 18636 sgd_solver.cpp:136] Iteration 78900, lr = 0.00506875, m = 0.9
I0802 08:22:35.525624 18636 solver.cpp:404] Sparsity after update:
I0802 08:22:35.538538 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:22:35.538599 18636 net.cpp:2270] conv1a_param_0(0.29) 
I0802 08:22:35.538620 18636 net.cpp:2270] conv1b_param_0(0.58) 
I0802 08:22:35.538633 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:22:35.538652 18636 net.cpp:2270] res2a_branch2a_param_0(0.587) 
I0802 08:22:35.538666 18636 net.cpp:2270] res2a_branch2b_param_0(0.579) 
I0802 08:22:35.538678 18636 net.cpp:2270] res3a_branch2a_param_0(0.589) 
I0802 08:22:35.538691 18636 net.cpp:2270] res3a_branch2b_param_0(0.586) 
I0802 08:22:35.538702 18636 net.cpp:2270] res4a_branch2a_param_0(0.589) 
I0802 08:22:35.538714 18636 net.cpp:2270] res4a_branch2b_param_0(0.589) 
I0802 08:22:35.538727 18636 net.cpp:2270] res5a_branch2a_param_0(0.59) 
I0802 08:22:35.538738 18636 net.cpp:2270] res5a_branch2b_param_0(0.589) 
I0802 08:22:35.538750 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.38725e+06/2.86678e+06) 0.484
I0802 08:22:35.668232 18661 solver.cpp:450] Finding and applying sparsity: 0.6
I0802 08:23:12.899114 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:23:12.901078 18636 solver.cpp:353] Iteration 79000 (1.95693 iter/s, 51.1005s/100 iter), loss = 1.22542
I0802 08:23:12.901108 18636 solver.cpp:375]     Train net output #0: loss = 1.16044 (* 1 = 1.16044 loss)
I0802 08:23:12.901120 18636 sgd_solver.cpp:136] Iteration 79000, lr = 0.0050625, m = 0.9
I0802 08:23:27.249292 18636 solver.cpp:353] Iteration 79100 (6.9697 iter/s, 14.3478s/100 iter), loss = 1.38256
I0802 08:23:27.249322 18636 solver.cpp:375]     Train net output #0: loss = 1.07833 (* 1 = 1.07833 loss)
I0802 08:23:27.249328 18636 sgd_solver.cpp:136] Iteration 79100, lr = 0.00505625, m = 0.9
I0802 08:23:41.148561 18636 solver.cpp:353] Iteration 79200 (7.19483 iter/s, 13.8989s/100 iter), loss = 1.50554
I0802 08:23:41.148598 18636 solver.cpp:375]     Train net output #0: loss = 1.57927 (* 1 = 1.57927 loss)
I0802 08:23:41.148607 18636 sgd_solver.cpp:136] Iteration 79200, lr = 0.00505, m = 0.9
I0802 08:23:55.041637 18636 solver.cpp:353] Iteration 79300 (7.19803 iter/s, 13.8927s/100 iter), loss = 0.911328
I0802 08:23:55.041738 18636 solver.cpp:375]     Train net output #0: loss = 0.976643 (* 1 = 0.976643 loss)
I0802 08:23:55.041749 18636 sgd_solver.cpp:136] Iteration 79300, lr = 0.00504375, m = 0.9
I0802 08:24:08.928073 18636 solver.cpp:353] Iteration 79400 (7.20147 iter/s, 13.8861s/100 iter), loss = 1.57239
I0802 08:24:08.928143 18636 solver.cpp:375]     Train net output #0: loss = 1.75079 (* 1 = 1.75079 loss)
I0802 08:24:08.928156 18636 sgd_solver.cpp:136] Iteration 79400, lr = 0.0050375, m = 0.9
I0802 08:24:22.854384 18636 solver.cpp:353] Iteration 79500 (7.18085 iter/s, 13.9259s/100 iter), loss = 1.3449
I0802 08:24:22.854414 18636 solver.cpp:375]     Train net output #0: loss = 1.44048 (* 1 = 1.44048 loss)
I0802 08:24:22.854420 18636 sgd_solver.cpp:136] Iteration 79500, lr = 0.00503125, m = 0.9
I0802 08:24:36.779860 18636 solver.cpp:353] Iteration 79600 (7.18128 iter/s, 13.9251s/100 iter), loss = 1.04484
I0802 08:24:36.779914 18636 solver.cpp:375]     Train net output #0: loss = 1.1605 (* 1 = 1.1605 loss)
I0802 08:24:36.779920 18636 sgd_solver.cpp:136] Iteration 79600, lr = 0.005025, m = 0.9
I0802 08:24:50.643939 18636 solver.cpp:353] Iteration 79700 (7.21309 iter/s, 13.8637s/100 iter), loss = 1.41923
I0802 08:24:50.643967 18636 solver.cpp:375]     Train net output #0: loss = 1.61653 (* 1 = 1.61653 loss)
I0802 08:24:50.643973 18636 sgd_solver.cpp:136] Iteration 79700, lr = 0.00501875, m = 0.9
I0802 08:25:04.564327 18636 solver.cpp:353] Iteration 79800 (7.18391 iter/s, 13.92s/100 iter), loss = 1.2544
I0802 08:25:04.564353 18636 solver.cpp:375]     Train net output #0: loss = 0.954917 (* 1 = 0.954917 loss)
I0802 08:25:04.564359 18636 sgd_solver.cpp:136] Iteration 79800, lr = 0.0050125, m = 0.9
I0802 08:25:18.406965 18636 solver.cpp:353] Iteration 79900 (7.22426 iter/s, 13.8423s/100 iter), loss = 1.60874
I0802 08:25:18.407025 18636 solver.cpp:375]     Train net output #0: loss = 1.49709 (* 1 = 1.49709 loss)
I0802 08:25:18.407032 18636 sgd_solver.cpp:136] Iteration 79900, lr = 0.00500625, m = 0.9
I0802 08:25:32.104825 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_80000.caffemodel
I0802 08:25:32.213457 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_80000.solverstate
I0802 08:25:32.218302 18636 solver.cpp:404] Sparsity after update:
I0802 08:25:32.219527 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:25:32.219537 18636 net.cpp:2270] conv1a_param_0(0.29) 
I0802 08:25:32.219543 18636 net.cpp:2270] conv1b_param_0(0.594) 
I0802 08:25:32.219547 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:25:32.219548 18636 net.cpp:2270] res2a_branch2a_param_0(0.597) 
I0802 08:25:32.219554 18636 net.cpp:2270] res2a_branch2b_param_0(0.591) 
I0802 08:25:32.219557 18636 net.cpp:2270] res3a_branch2a_param_0(0.599) 
I0802 08:25:32.219561 18636 net.cpp:2270] res3a_branch2b_param_0(0.596) 
I0802 08:25:32.219563 18636 net.cpp:2270] res4a_branch2a_param_0(0.6) 
I0802 08:25:32.219565 18636 net.cpp:2270] res4a_branch2b_param_0(0.599) 
I0802 08:25:32.219568 18636 net.cpp:2270] res5a_branch2a_param_0(0.6) 
I0802 08:25:32.219568 18636 net.cpp:2270] res5a_branch2b_param_0(0.6) 
I0802 08:25:32.219571 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.41125e+06/2.86678e+06) 0.492
I0802 08:25:32.219583 18636 solver.cpp:550] Iteration 80000, Testing net (#0)
I0802 08:25:40.773552 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:25:51.836937 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.586235
I0802 08:25:51.837065 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817761
I0802 08:25:51.837074 18636 solver.cpp:635]     Test net output #2: loss = 1.80879 (* 1 = 1.80879 loss)
I0802 08:25:51.837096 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.617s
I0802 08:25:51.984975 18661 solver.cpp:450] Finding and applying sparsity: 0.61
I0802 08:26:29.894803 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:26:29.896733 18636 solver.cpp:353] Iteration 80000 (1.39884 iter/s, 71.4878s/100 iter), loss = 1.18251
I0802 08:26:29.896750 18636 solver.cpp:375]     Train net output #0: loss = 1.24914 (* 1 = 1.24914 loss)
I0802 08:26:29.896756 18636 sgd_solver.cpp:136] Iteration 80000, lr = 0.005, m = 0.9
I0802 08:26:44.253335 18636 solver.cpp:353] Iteration 80100 (6.96563 iter/s, 14.3562s/100 iter), loss = 1.42974
I0802 08:26:44.253360 18636 solver.cpp:375]     Train net output #0: loss = 1.50574 (* 1 = 1.50574 loss)
I0802 08:26:44.253365 18636 sgd_solver.cpp:136] Iteration 80100, lr = 0.00499375, m = 0.9
I0802 08:26:58.166296 18636 solver.cpp:353] Iteration 80200 (7.18775 iter/s, 13.9126s/100 iter), loss = 1.11287
I0802 08:26:58.166339 18636 solver.cpp:375]     Train net output #0: loss = 1.4231 (* 1 = 1.4231 loss)
I0802 08:26:58.166349 18636 sgd_solver.cpp:136] Iteration 80200, lr = 0.0049875, m = 0.9
I0802 08:27:12.129176 18636 solver.cpp:353] Iteration 80300 (7.16205 iter/s, 13.9625s/100 iter), loss = 1.00964
I0802 08:27:12.129305 18636 solver.cpp:375]     Train net output #0: loss = 1.07273 (* 1 = 1.07273 loss)
I0802 08:27:12.129318 18636 sgd_solver.cpp:136] Iteration 80300, lr = 0.00498125, m = 0.9
I0802 08:27:26.099581 18636 solver.cpp:353] Iteration 80400 (7.15819 iter/s, 13.97s/100 iter), loss = 1.28263
I0802 08:27:26.099671 18636 solver.cpp:375]     Train net output #0: loss = 1.32564 (* 1 = 1.32564 loss)
I0802 08:27:26.099691 18636 sgd_solver.cpp:136] Iteration 80400, lr = 0.004975, m = 0.9
I0802 08:27:40.020251 18636 solver.cpp:353] Iteration 80500 (7.18376 iter/s, 13.9203s/100 iter), loss = 1.39533
I0802 08:27:40.020277 18636 solver.cpp:375]     Train net output #0: loss = 1.24234 (* 1 = 1.24234 loss)
I0802 08:27:40.020283 18636 sgd_solver.cpp:136] Iteration 80500, lr = 0.00496875, m = 0.9
I0802 08:27:53.993978 18636 solver.cpp:353] Iteration 80600 (7.15649 iter/s, 13.9733s/100 iter), loss = 1.88848
I0802 08:27:53.994040 18636 solver.cpp:375]     Train net output #0: loss = 2.15348 (* 1 = 2.15348 loss)
I0802 08:27:53.994046 18636 sgd_solver.cpp:136] Iteration 80600, lr = 0.0049625, m = 0.9
I0802 08:28:07.955111 18636 solver.cpp:353] Iteration 80700 (7.16294 iter/s, 13.9607s/100 iter), loss = 1.36112
I0802 08:28:07.955144 18636 solver.cpp:375]     Train net output #0: loss = 1.59342 (* 1 = 1.59342 loss)
I0802 08:28:07.955149 18636 sgd_solver.cpp:136] Iteration 80700, lr = 0.00495625, m = 0.9
I0802 08:28:21.922616 18636 solver.cpp:353] Iteration 80800 (7.15968 iter/s, 13.9671s/100 iter), loss = 1.15291
I0802 08:28:21.922650 18636 solver.cpp:375]     Train net output #0: loss = 1.41829 (* 1 = 1.41829 loss)
I0802 08:28:21.922657 18636 sgd_solver.cpp:136] Iteration 80800, lr = 0.00495, m = 0.9
I0802 08:28:35.958209 18636 solver.cpp:353] Iteration 80900 (7.12494 iter/s, 14.0352s/100 iter), loss = 1.20137
I0802 08:28:35.958314 18636 solver.cpp:375]     Train net output #0: loss = 1.27187 (* 1 = 1.27187 loss)
I0802 08:28:35.958323 18636 sgd_solver.cpp:136] Iteration 80900, lr = 0.00494375, m = 0.9
I0802 08:28:49.810437 18636 solver.cpp:404] Sparsity after update:
I0802 08:28:49.820920 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:28:49.820935 18636 net.cpp:2270] conv1a_param_0(0.291) 
I0802 08:28:49.820945 18636 net.cpp:2270] conv1b_param_0(0.595) 
I0802 08:28:49.820950 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:28:49.820952 18636 net.cpp:2270] res2a_branch2a_param_0(0.608) 
I0802 08:28:49.820955 18636 net.cpp:2270] res2a_branch2b_param_0(0.597) 
I0802 08:28:49.820960 18636 net.cpp:2270] res3a_branch2a_param_0(0.609) 
I0802 08:28:49.820962 18636 net.cpp:2270] res3a_branch2b_param_0(0.607) 
I0802 08:28:49.820966 18636 net.cpp:2270] res4a_branch2a_param_0(0.609) 
I0802 08:28:49.820968 18636 net.cpp:2270] res4a_branch2b_param_0(0.609) 
I0802 08:28:49.820971 18636 net.cpp:2270] res5a_branch2a_param_0(0.61) 
I0802 08:28:49.820974 18636 net.cpp:2270] res5a_branch2b_param_0(0.609) 
I0802 08:28:49.820978 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.4344e+06/2.86678e+06) 0.5
I0802 08:28:49.953758 18661 solver.cpp:450] Finding and applying sparsity: 0.62
I0802 08:29:28.985553 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:29:28.990823 18636 solver.cpp:353] Iteration 81000 (1.88568 iter/s, 53.0312s/100 iter), loss = 1.35476
I0802 08:29:28.990846 18636 solver.cpp:375]     Train net output #0: loss = 1.29426 (* 1 = 1.29426 loss)
I0802 08:29:28.990852 18636 sgd_solver.cpp:136] Iteration 81000, lr = 0.0049375, m = 0.9
I0802 08:29:43.303635 18636 solver.cpp:353] Iteration 81100 (6.98694 iter/s, 14.3124s/100 iter), loss = 1.3264
I0802 08:29:43.303699 18636 solver.cpp:375]     Train net output #0: loss = 1.00546 (* 1 = 1.00546 loss)
I0802 08:29:43.303715 18636 sgd_solver.cpp:136] Iteration 81100, lr = 0.00493125, m = 0.9
I0802 08:29:57.279871 18636 solver.cpp:353] Iteration 81200 (7.1552 iter/s, 13.9758s/100 iter), loss = 1.39455
I0802 08:29:57.279896 18636 solver.cpp:375]     Train net output #0: loss = 1.48593 (* 1 = 1.48593 loss)
I0802 08:29:57.279901 18636 sgd_solver.cpp:136] Iteration 81200, lr = 0.004925, m = 0.9
I0802 08:30:11.161691 18636 solver.cpp:353] Iteration 81300 (7.20387 iter/s, 13.8814s/100 iter), loss = 1.2342
I0802 08:30:11.161773 18636 solver.cpp:375]     Train net output #0: loss = 0.823726 (* 1 = 0.823726 loss)
I0802 08:30:11.161780 18636 sgd_solver.cpp:136] Iteration 81300, lr = 0.00491875, m = 0.9
I0802 08:30:25.125581 18636 solver.cpp:353] Iteration 81400 (7.16153 iter/s, 13.9635s/100 iter), loss = 1.22532
I0802 08:30:25.125607 18636 solver.cpp:375]     Train net output #0: loss = 1.27855 (* 1 = 1.27855 loss)
I0802 08:30:25.125612 18636 sgd_solver.cpp:136] Iteration 81400, lr = 0.0049125, m = 0.9
I0802 08:30:39.130906 18636 solver.cpp:353] Iteration 81500 (7.14034 iter/s, 14.0049s/100 iter), loss = 1.39802
I0802 08:30:39.130933 18636 solver.cpp:375]     Train net output #0: loss = 1.33604 (* 1 = 1.33604 loss)
I0802 08:30:39.130937 18636 sgd_solver.cpp:136] Iteration 81500, lr = 0.00490625, m = 0.9
I0802 08:30:53.087574 18636 solver.cpp:353] Iteration 81600 (7.16523 iter/s, 13.9563s/100 iter), loss = 1.28745
I0802 08:30:53.087642 18636 solver.cpp:375]     Train net output #0: loss = 1.37188 (* 1 = 1.37188 loss)
I0802 08:30:53.087648 18636 sgd_solver.cpp:136] Iteration 81600, lr = 0.0049, m = 0.9
I0802 08:31:07.033478 18636 solver.cpp:353] Iteration 81700 (7.17076 iter/s, 13.9455s/100 iter), loss = 1.12058
I0802 08:31:07.033501 18636 solver.cpp:375]     Train net output #0: loss = 1.01834 (* 1 = 1.01834 loss)
I0802 08:31:07.033506 18636 sgd_solver.cpp:136] Iteration 81700, lr = 0.00489375, m = 0.9
I0802 08:31:20.947892 18636 solver.cpp:353] Iteration 81800 (7.18699 iter/s, 13.914s/100 iter), loss = 1.72613
I0802 08:31:20.947916 18636 solver.cpp:375]     Train net output #0: loss = 1.4465 (* 1 = 1.4465 loss)
I0802 08:31:20.947919 18636 sgd_solver.cpp:136] Iteration 81800, lr = 0.0048875, m = 0.9
I0802 08:31:34.986563 18636 solver.cpp:353] Iteration 81900 (7.12338 iter/s, 14.0383s/100 iter), loss = 1.2489
I0802 08:31:34.986642 18636 solver.cpp:375]     Train net output #0: loss = 1.07763 (* 1 = 1.07763 loss)
I0802 08:31:34.986649 18636 sgd_solver.cpp:136] Iteration 81900, lr = 0.00488125, m = 0.9
I0802 08:31:48.838657 18636 solver.cpp:404] Sparsity after update:
I0802 08:31:48.843839 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:31:48.843875 18636 net.cpp:2270] conv1a_param_0(0.303) 
I0802 08:31:48.843904 18636 net.cpp:2270] conv1b_param_0(0.607) 
I0802 08:31:48.843917 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:31:48.843930 18636 net.cpp:2270] res2a_branch2a_param_0(0.618) 
I0802 08:31:48.843945 18636 net.cpp:2270] res2a_branch2b_param_0(0.608) 
I0802 08:31:48.843957 18636 net.cpp:2270] res3a_branch2a_param_0(0.62) 
I0802 08:31:48.843971 18636 net.cpp:2270] res3a_branch2b_param_0(0.617) 
I0802 08:31:48.843982 18636 net.cpp:2270] res4a_branch2a_param_0(0.62) 
I0802 08:31:48.843996 18636 net.cpp:2270] res4a_branch2b_param_0(0.62) 
I0802 08:31:48.844009 18636 net.cpp:2270] res5a_branch2a_param_0(0.62) 
I0802 08:31:48.844022 18636 net.cpp:2270] res5a_branch2b_param_0(0.62) 
I0802 08:31:48.844034 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.45842e+06/2.86678e+06) 0.509
I0802 08:31:48.844060 18636 solver.cpp:550] Iteration 82000, Testing net (#0)
I0802 08:32:08.723357 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.57647
I0802 08:32:08.723456 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810115
I0802 08:32:08.723466 18636 solver.cpp:635]     Test net output #2: loss = 1.83166 (* 1 = 1.83166 loss)
I0802 08:32:08.723487 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8789s
I0802 08:32:08.862314 18661 solver.cpp:450] Finding and applying sparsity: 0.63
I0802 08:32:48.822274 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:32:48.824334 18636 solver.cpp:353] Iteration 82000 (1.35436 iter/s, 73.8357s/100 iter), loss = 1.30475
I0802 08:32:48.824357 18636 solver.cpp:375]     Train net output #0: loss = 1.23373 (* 1 = 1.23373 loss)
I0802 08:32:48.824369 18636 sgd_solver.cpp:136] Iteration 82000, lr = 0.004875, m = 0.9
I0802 08:33:03.167552 18636 solver.cpp:353] Iteration 82100 (6.97213 iter/s, 14.3428s/100 iter), loss = 1.11683
I0802 08:33:03.167580 18636 solver.cpp:375]     Train net output #0: loss = 1.10106 (* 1 = 1.10106 loss)
I0802 08:33:03.167587 18636 sgd_solver.cpp:136] Iteration 82100, lr = 0.00486875, m = 0.9
I0802 08:33:17.173638 18636 solver.cpp:353] Iteration 82200 (7.13995 iter/s, 14.0057s/100 iter), loss = 1.3144
I0802 08:33:17.173663 18636 solver.cpp:375]     Train net output #0: loss = 1.15361 (* 1 = 1.15361 loss)
I0802 08:33:17.173669 18636 sgd_solver.cpp:136] Iteration 82200, lr = 0.0048625, m = 0.9
I0802 08:33:31.180074 18636 solver.cpp:353] Iteration 82300 (7.13978 iter/s, 14.006s/100 iter), loss = 1.39811
I0802 08:33:31.180136 18636 solver.cpp:375]     Train net output #0: loss = 1.18271 (* 1 = 1.18271 loss)
I0802 08:33:31.180143 18636 sgd_solver.cpp:136] Iteration 82300, lr = 0.00485625, m = 0.9
I0802 08:33:45.142235 18636 solver.cpp:353] Iteration 82400 (7.16242 iter/s, 13.9618s/100 iter), loss = 1.30661
I0802 08:33:45.142335 18636 solver.cpp:375]     Train net output #0: loss = 1.51205 (* 1 = 1.51205 loss)
I0802 08:33:45.142356 18636 sgd_solver.cpp:136] Iteration 82400, lr = 0.00485, m = 0.9
I0802 08:33:59.083524 18636 solver.cpp:353] Iteration 82500 (7.17314 iter/s, 13.9409s/100 iter), loss = 1.16339
I0802 08:33:59.083554 18636 solver.cpp:375]     Train net output #0: loss = 0.870602 (* 1 = 0.870602 loss)
I0802 08:33:59.083559 18636 sgd_solver.cpp:136] Iteration 82500, lr = 0.00484375, m = 0.9
I0802 08:34:13.149065 18636 solver.cpp:353] Iteration 82600 (7.10977 iter/s, 14.0652s/100 iter), loss = 1.52479
I0802 08:34:13.149147 18636 solver.cpp:375]     Train net output #0: loss = 1.7122 (* 1 = 1.7122 loss)
I0802 08:34:13.149154 18636 sgd_solver.cpp:136] Iteration 82600, lr = 0.0048375, m = 0.9
I0802 08:34:27.137925 18636 solver.cpp:353] Iteration 82700 (7.14874 iter/s, 13.9885s/100 iter), loss = 1.52391
I0802 08:34:27.137953 18636 solver.cpp:375]     Train net output #0: loss = 1.47082 (* 1 = 1.47082 loss)
I0802 08:34:27.137959 18636 sgd_solver.cpp:136] Iteration 82700, lr = 0.00483125, m = 0.9
I0802 08:34:41.082917 18636 solver.cpp:353] Iteration 82800 (7.17123 iter/s, 13.9446s/100 iter), loss = 1.63197
I0802 08:34:41.082947 18636 solver.cpp:375]     Train net output #0: loss = 1.80693 (* 1 = 1.80693 loss)
I0802 08:34:41.082952 18636 sgd_solver.cpp:136] Iteration 82800, lr = 0.004825, m = 0.9
I0802 08:34:55.061313 18636 solver.cpp:353] Iteration 82900 (7.15409 iter/s, 13.978s/100 iter), loss = 1.30194
I0802 08:34:55.061388 18636 solver.cpp:375]     Train net output #0: loss = 1.50527 (* 1 = 1.50527 loss)
I0802 08:34:55.061393 18636 sgd_solver.cpp:136] Iteration 82900, lr = 0.00481875, m = 0.9
I0802 08:35:08.970690 18636 solver.cpp:404] Sparsity after update:
I0802 08:35:08.982228 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:35:08.982240 18636 net.cpp:2270] conv1a_param_0(0.304) 
I0802 08:35:08.982246 18636 net.cpp:2270] conv1b_param_0(0.619) 
I0802 08:35:08.982249 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:35:08.982251 18636 net.cpp:2270] res2a_branch2a_param_0(0.628) 
I0802 08:35:08.982254 18636 net.cpp:2270] res2a_branch2b_param_0(0.614) 
I0802 08:35:08.982255 18636 net.cpp:2270] res3a_branch2a_param_0(0.628) 
I0802 08:35:08.982256 18636 net.cpp:2270] res3a_branch2b_param_0(0.627) 
I0802 08:35:08.982259 18636 net.cpp:2270] res4a_branch2a_param_0(0.629) 
I0802 08:35:08.982260 18636 net.cpp:2270] res4a_branch2b_param_0(0.628) 
I0802 08:35:08.982262 18636 net.cpp:2270] res5a_branch2a_param_0(0.63) 
I0802 08:35:08.982267 18636 net.cpp:2270] res5a_branch2b_param_0(0.629) 
I0802 08:35:08.982270 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.4812e+06/2.86678e+06) 0.517
I0802 08:35:09.111374 18661 solver.cpp:450] Finding and applying sparsity: 0.64
I0802 08:35:50.176528 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:35:50.178519 18636 solver.cpp:353] Iteration 83000 (1.81437 iter/s, 55.1157s/100 iter), loss = 1.37236
I0802 08:35:50.178546 18636 solver.cpp:375]     Train net output #0: loss = 1.45526 (* 1 = 1.45526 loss)
I0802 08:35:50.178555 18636 sgd_solver.cpp:136] Iteration 83000, lr = 0.0048125, m = 0.9
I0802 08:36:04.537715 18636 solver.cpp:353] Iteration 83100 (6.96438 iter/s, 14.3588s/100 iter), loss = 1.6284
I0802 08:36:04.537771 18636 solver.cpp:375]     Train net output #0: loss = 1.82038 (* 1 = 1.82038 loss)
I0802 08:36:04.537786 18636 sgd_solver.cpp:136] Iteration 83100, lr = 0.00480625, m = 0.9
I0802 08:36:18.457523 18636 solver.cpp:353] Iteration 83200 (7.18421 iter/s, 13.9194s/100 iter), loss = 1.29568
I0802 08:36:18.457550 18636 solver.cpp:375]     Train net output #0: loss = 1.79353 (* 1 = 1.79353 loss)
I0802 08:36:18.457556 18636 sgd_solver.cpp:136] Iteration 83200, lr = 0.0048, m = 0.9
I0802 08:36:32.445777 18636 solver.cpp:353] Iteration 83300 (7.14906 iter/s, 13.9879s/100 iter), loss = 1.322
I0802 08:36:32.445840 18636 solver.cpp:375]     Train net output #0: loss = 1.32145 (* 1 = 1.32145 loss)
I0802 08:36:32.445844 18636 sgd_solver.cpp:136] Iteration 83300, lr = 0.00479375, m = 0.9
I0802 08:36:46.400741 18636 solver.cpp:353] Iteration 83400 (7.16611 iter/s, 13.9546s/100 iter), loss = 2.04376
I0802 08:36:46.400775 18636 solver.cpp:375]     Train net output #0: loss = 2.11902 (* 1 = 2.11902 loss)
I0802 08:36:46.400781 18636 sgd_solver.cpp:136] Iteration 83400, lr = 0.0047875, m = 0.9
I0802 08:37:00.289937 18636 solver.cpp:353] Iteration 83500 (7.20004 iter/s, 13.8888s/100 iter), loss = 1.31913
I0802 08:37:00.289968 18636 solver.cpp:375]     Train net output #0: loss = 1.51814 (* 1 = 1.51814 loss)
I0802 08:37:00.289973 18636 sgd_solver.cpp:136] Iteration 83500, lr = 0.00478125, m = 0.9
I0802 08:37:14.097812 18636 solver.cpp:353] Iteration 83600 (7.24245 iter/s, 13.8075s/100 iter), loss = 1.72159
I0802 08:37:14.097915 18636 solver.cpp:375]     Train net output #0: loss = 1.77538 (* 1 = 1.77538 loss)
I0802 08:37:14.097923 18636 sgd_solver.cpp:136] Iteration 83600, lr = 0.004775, m = 0.9
I0802 08:37:28.048424 18636 solver.cpp:353] Iteration 83700 (7.16834 iter/s, 13.9502s/100 iter), loss = 1.3064
I0802 08:37:28.048449 18636 solver.cpp:375]     Train net output #0: loss = 1.48389 (* 1 = 1.48389 loss)
I0802 08:37:28.048454 18636 sgd_solver.cpp:136] Iteration 83700, lr = 0.00476875, m = 0.9
I0802 08:37:42.085304 18636 solver.cpp:353] Iteration 83800 (7.12429 iter/s, 14.0365s/100 iter), loss = 1.46614
I0802 08:37:42.085331 18636 solver.cpp:375]     Train net output #0: loss = 1.62069 (* 1 = 1.62069 loss)
I0802 08:37:42.085337 18636 sgd_solver.cpp:136] Iteration 83800, lr = 0.0047625, m = 0.9
I0802 08:37:56.027633 18636 solver.cpp:353] Iteration 83900 (7.1726 iter/s, 13.9419s/100 iter), loss = 1.4161
I0802 08:37:56.027768 18636 solver.cpp:375]     Train net output #0: loss = 1.49624 (* 1 = 1.49624 loss)
I0802 08:37:56.027788 18636 sgd_solver.cpp:136] Iteration 83900, lr = 0.00475625, m = 0.9
I0802 08:38:09.809615 18636 solver.cpp:404] Sparsity after update:
I0802 08:38:09.814463 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:38:09.814473 18636 net.cpp:2270] conv1a_param_0(0.304) 
I0802 08:38:09.814481 18636 net.cpp:2270] conv1b_param_0(0.631) 
I0802 08:38:09.814482 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:38:09.814484 18636 net.cpp:2270] res2a_branch2a_param_0(0.638) 
I0802 08:38:09.814486 18636 net.cpp:2270] res2a_branch2b_param_0(0.624) 
I0802 08:38:09.814488 18636 net.cpp:2270] res3a_branch2a_param_0(0.639) 
I0802 08:38:09.814491 18636 net.cpp:2270] res3a_branch2b_param_0(0.636) 
I0802 08:38:09.814492 18636 net.cpp:2270] res4a_branch2a_param_0(0.64) 
I0802 08:38:09.814496 18636 net.cpp:2270] res4a_branch2b_param_0(0.639) 
I0802 08:38:09.814498 18636 net.cpp:2270] res5a_branch2a_param_0(0.64) 
I0802 08:38:09.814499 18636 net.cpp:2270] res5a_branch2b_param_0(0.64) 
I0802 08:38:09.814502 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.50516e+06/2.86678e+06) 0.525
I0802 08:38:09.814512 18636 solver.cpp:550] Iteration 84000, Testing net (#0)
I0802 08:38:29.068907 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581294
I0802 08:38:29.069006 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.812232
I0802 08:38:29.069020 18636 solver.cpp:635]     Test net output #2: loss = 1.82919 (* 1 = 1.82919 loss)
I0802 08:38:29.069041 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.254s
I0802 08:38:29.206245 18661 solver.cpp:450] Finding and applying sparsity: 0.65
I0802 08:39:11.353955 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:39:11.355943 18636 solver.cpp:353] Iteration 84000 (1.32756 iter/s, 75.3262s/100 iter), loss = 1.50909
I0802 08:39:11.355962 18636 solver.cpp:375]     Train net output #0: loss = 1.81334 (* 1 = 1.81334 loss)
I0802 08:39:11.355967 18636 sgd_solver.cpp:136] Iteration 84000, lr = 0.00475, m = 0.9
I0802 08:39:25.627679 18636 solver.cpp:353] Iteration 84100 (7.00705 iter/s, 14.2713s/100 iter), loss = 1.38418
I0802 08:39:25.627709 18636 solver.cpp:375]     Train net output #0: loss = 1.42063 (* 1 = 1.42063 loss)
I0802 08:39:25.627715 18636 sgd_solver.cpp:136] Iteration 84100, lr = 0.00474375, m = 0.9
I0802 08:39:39.510905 18636 solver.cpp:353] Iteration 84200 (7.20314 iter/s, 13.8828s/100 iter), loss = 1.28011
I0802 08:39:39.510938 18636 solver.cpp:375]     Train net output #0: loss = 1.51217 (* 1 = 1.51217 loss)
I0802 08:39:39.510944 18636 sgd_solver.cpp:136] Iteration 84200, lr = 0.0047375, m = 0.9
I0802 08:39:53.377825 18636 solver.cpp:353] Iteration 84300 (7.21161 iter/s, 13.8665s/100 iter), loss = 1.66469
I0802 08:39:53.377887 18636 solver.cpp:375]     Train net output #0: loss = 1.52806 (* 1 = 1.52806 loss)
I0802 08:39:53.377894 18636 sgd_solver.cpp:136] Iteration 84300, lr = 0.00473125, m = 0.9
I0802 08:40:07.245970 18636 solver.cpp:353] Iteration 84400 (7.21097 iter/s, 13.8678s/100 iter), loss = 1.35266
I0802 08:40:07.245996 18636 solver.cpp:375]     Train net output #0: loss = 1.48416 (* 1 = 1.48416 loss)
I0802 08:40:07.246002 18636 sgd_solver.cpp:136] Iteration 84400, lr = 0.004725, m = 0.9
I0802 08:40:21.130336 18636 solver.cpp:353] Iteration 84500 (7.20255 iter/s, 13.884s/100 iter), loss = 1.53167
I0802 08:40:21.130363 18636 solver.cpp:375]     Train net output #0: loss = 1.29905 (* 1 = 1.29905 loss)
I0802 08:40:21.130369 18636 sgd_solver.cpp:136] Iteration 84500, lr = 0.00471875, m = 0.9
I0802 08:40:35.031826 18636 solver.cpp:353] Iteration 84600 (7.19367 iter/s, 13.9011s/100 iter), loss = 1.38658
I0802 08:40:35.031893 18636 solver.cpp:375]     Train net output #0: loss = 1.0045 (* 1 = 1.0045 loss)
I0802 08:40:35.031899 18636 sgd_solver.cpp:136] Iteration 84600, lr = 0.0047125, m = 0.9
I0802 08:40:48.909915 18636 solver.cpp:353] Iteration 84700 (7.2058 iter/s, 13.8777s/100 iter), loss = 1.40321
I0802 08:40:48.909940 18636 solver.cpp:375]     Train net output #0: loss = 1.1543 (* 1 = 1.1543 loss)
I0802 08:40:48.909945 18636 sgd_solver.cpp:136] Iteration 84700, lr = 0.00470625, m = 0.9
I0802 08:41:02.831507 18636 solver.cpp:353] Iteration 84800 (7.18329 iter/s, 13.9212s/100 iter), loss = 1.36079
I0802 08:41:02.831533 18636 solver.cpp:375]     Train net output #0: loss = 0.899291 (* 1 = 0.899291 loss)
I0802 08:41:02.831539 18636 sgd_solver.cpp:136] Iteration 84800, lr = 0.0047, m = 0.9
I0802 08:41:16.707743 18636 solver.cpp:353] Iteration 84900 (7.20676 iter/s, 13.8759s/100 iter), loss = 1.35346
I0802 08:41:16.707866 18636 solver.cpp:375]     Train net output #0: loss = 1.4303 (* 1 = 1.4303 loss)
I0802 08:41:16.707886 18636 sgd_solver.cpp:136] Iteration 84900, lr = 0.00469375, m = 0.9
I0802 08:41:30.561363 18636 solver.cpp:404] Sparsity after update:
I0802 08:41:30.572913 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:41:30.572928 18636 net.cpp:2270] conv1a_param_0(0.317) 
I0802 08:41:30.572937 18636 net.cpp:2270] conv1b_param_0(0.632) 
I0802 08:41:30.572940 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:41:30.572943 18636 net.cpp:2270] res2a_branch2a_param_0(0.648) 
I0802 08:41:30.572947 18636 net.cpp:2270] res2a_branch2b_param_0(0.63) 
I0802 08:41:30.572950 18636 net.cpp:2270] res3a_branch2a_param_0(0.649) 
I0802 08:41:30.572953 18636 net.cpp:2270] res3a_branch2b_param_0(0.646) 
I0802 08:41:30.572957 18636 net.cpp:2270] res4a_branch2a_param_0(0.649) 
I0802 08:41:30.572959 18636 net.cpp:2270] res4a_branch2b_param_0(0.649) 
I0802 08:41:30.572962 18636 net.cpp:2270] res5a_branch2a_param_0(0.65) 
I0802 08:41:30.572965 18636 net.cpp:2270] res5a_branch2b_param_0(0.649) 
I0802 08:41:30.572985 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.52831e+06/2.86678e+06) 0.533
I0802 08:41:30.702749 18661 solver.cpp:450] Finding and applying sparsity: 0.66
I0802 08:42:14.258988 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:42:14.261000 18636 solver.cpp:353] Iteration 85000 (1.73757 iter/s, 57.5517s/100 iter), loss = 1.25734
I0802 08:42:14.261046 18636 solver.cpp:375]     Train net output #0: loss = 1.01407 (* 1 = 1.01407 loss)
I0802 08:42:14.261055 18636 sgd_solver.cpp:136] Iteration 85000, lr = 0.0046875, m = 0.9
I0802 08:42:28.646077 18636 solver.cpp:353] Iteration 85100 (6.95184 iter/s, 14.3847s/100 iter), loss = 1.47939
I0802 08:42:28.646105 18636 solver.cpp:375]     Train net output #0: loss = 1.54512 (* 1 = 1.54512 loss)
I0802 08:42:28.646109 18636 sgd_solver.cpp:136] Iteration 85100, lr = 0.00468125, m = 0.9
I0802 08:42:42.676409 18636 solver.cpp:353] Iteration 85200 (7.12761 iter/s, 14.0299s/100 iter), loss = 1.09353
I0802 08:42:42.676434 18636 solver.cpp:375]     Train net output #0: loss = 1.01421 (* 1 = 1.01421 loss)
I0802 08:42:42.676439 18636 sgd_solver.cpp:136] Iteration 85200, lr = 0.004675, m = 0.9
I0802 08:42:56.656628 18636 solver.cpp:353] Iteration 85300 (7.15316 iter/s, 13.9798s/100 iter), loss = 1.60625
I0802 08:42:56.656682 18636 solver.cpp:375]     Train net output #0: loss = 1.42149 (* 1 = 1.42149 loss)
I0802 08:42:56.656688 18636 sgd_solver.cpp:136] Iteration 85300, lr = 0.00466875, m = 0.9
I0802 08:43:10.561394 18636 solver.cpp:353] Iteration 85400 (7.19198 iter/s, 13.9044s/100 iter), loss = 1.09982
I0802 08:43:10.561422 18636 solver.cpp:375]     Train net output #0: loss = 1.19813 (* 1 = 1.19813 loss)
I0802 08:43:10.561429 18636 sgd_solver.cpp:136] Iteration 85400, lr = 0.0046625, m = 0.9
I0802 08:43:24.499294 18636 solver.cpp:353] Iteration 85500 (7.17488 iter/s, 13.9375s/100 iter), loss = 1.41403
I0802 08:43:24.499321 18636 solver.cpp:375]     Train net output #0: loss = 1.52008 (* 1 = 1.52008 loss)
I0802 08:43:24.499327 18636 sgd_solver.cpp:136] Iteration 85500, lr = 0.00465625, m = 0.9
I0802 08:43:38.411670 18636 solver.cpp:353] Iteration 85600 (7.18805 iter/s, 13.912s/100 iter), loss = 1.59299
I0802 08:43:38.411749 18636 solver.cpp:375]     Train net output #0: loss = 1.72131 (* 1 = 1.72131 loss)
I0802 08:43:38.411756 18636 sgd_solver.cpp:136] Iteration 85600, lr = 0.00465, m = 0.9
I0802 08:43:52.422169 18636 solver.cpp:353] Iteration 85700 (7.1377 iter/s, 14.0101s/100 iter), loss = 1.14781
I0802 08:43:52.422248 18636 solver.cpp:375]     Train net output #0: loss = 1.32066 (* 1 = 1.32066 loss)
I0802 08:43:52.422272 18636 sgd_solver.cpp:136] Iteration 85700, lr = 0.00464375, m = 0.9
I0802 08:44:06.333395 18636 solver.cpp:353] Iteration 85800 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.11974
I0802 08:44:06.333511 18636 solver.cpp:375]     Train net output #0: loss = 1.27032 (* 1 = 1.27032 loss)
I0802 08:44:06.333535 18636 sgd_solver.cpp:136] Iteration 85800, lr = 0.0046375, m = 0.9
I0802 08:44:20.271857 18636 solver.cpp:353] Iteration 85900 (7.17459 iter/s, 13.9381s/100 iter), loss = 1.4261
I0802 08:44:20.276914 18636 solver.cpp:375]     Train net output #0: loss = 1.69123 (* 1 = 1.69123 loss)
I0802 08:44:20.276938 18636 sgd_solver.cpp:136] Iteration 85900, lr = 0.00463125, m = 0.9
I0802 08:44:34.047463 18636 solver.cpp:404] Sparsity after update:
I0802 08:44:34.054312 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:44:34.054330 18636 net.cpp:2270] conv1a_param_0(0.317) 
I0802 08:44:34.054338 18636 net.cpp:2270] conv1b_param_0(0.642) 
I0802 08:44:34.054342 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:44:34.054345 18636 net.cpp:2270] res2a_branch2a_param_0(0.658) 
I0802 08:44:34.054349 18636 net.cpp:2270] res2a_branch2b_param_0(0.64) 
I0802 08:44:34.054353 18636 net.cpp:2270] res3a_branch2a_param_0(0.66) 
I0802 08:44:34.054356 18636 net.cpp:2270] res3a_branch2b_param_0(0.655) 
I0802 08:44:34.054359 18636 net.cpp:2270] res4a_branch2a_param_0(0.66) 
I0802 08:44:34.054363 18636 net.cpp:2270] res4a_branch2b_param_0(0.659) 
I0802 08:44:34.054366 18636 net.cpp:2270] res5a_branch2a_param_0(0.66) 
I0802 08:44:34.054369 18636 net.cpp:2270] res5a_branch2b_param_0(0.66) 
I0802 08:44:34.054373 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.55223e+06/2.86678e+06) 0.541
I0802 08:44:34.054384 18636 solver.cpp:550] Iteration 86000, Testing net (#0)
I0802 08:44:48.171142 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:44:53.460463 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574705
I0802 08:44:53.460544 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811939
I0802 08:44:53.460551 18636 solver.cpp:635]     Test net output #2: loss = 1.85063 (* 1 = 1.85063 loss)
I0802 08:44:53.460571 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4057s
I0802 08:44:53.608839 18661 solver.cpp:450] Finding and applying sparsity: 0.67
I0802 08:45:38.115324 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:45:38.117326 18636 solver.cpp:353] Iteration 86000 (1.28463 iter/s, 77.8433s/100 iter), loss = 1.32319
I0802 08:45:38.117343 18636 solver.cpp:375]     Train net output #0: loss = 1.59326 (* 1 = 1.59326 loss)
I0802 08:45:38.117349 18636 sgd_solver.cpp:136] Iteration 86000, lr = 0.004625, m = 0.9
I0802 08:45:52.358584 18636 solver.cpp:353] Iteration 86100 (7.02205 iter/s, 14.2409s/100 iter), loss = 1.3768
I0802 08:45:52.358614 18636 solver.cpp:375]     Train net output #0: loss = 1.27371 (* 1 = 1.27371 loss)
I0802 08:45:52.358654 18636 sgd_solver.cpp:136] Iteration 86100, lr = 0.00461875, m = 0.9
I0802 08:46:06.321938 18636 solver.cpp:353] Iteration 86200 (7.1618 iter/s, 13.963s/100 iter), loss = 1.52258
I0802 08:46:06.321967 18636 solver.cpp:375]     Train net output #0: loss = 1.12805 (* 1 = 1.12805 loss)
I0802 08:46:06.321972 18636 sgd_solver.cpp:136] Iteration 86200, lr = 0.0046125, m = 0.9
I0802 08:46:20.257473 18636 solver.cpp:353] Iteration 86300 (7.1761 iter/s, 13.9351s/100 iter), loss = 1.40451
I0802 08:46:20.257572 18636 solver.cpp:375]     Train net output #0: loss = 1.42826 (* 1 = 1.42826 loss)
I0802 08:46:20.257586 18636 sgd_solver.cpp:136] Iteration 86300, lr = 0.00460625, m = 0.9
I0802 08:46:34.171502 18636 solver.cpp:353] Iteration 86400 (7.18719 iter/s, 13.9136s/100 iter), loss = 1.44121
I0802 08:46:34.171531 18636 solver.cpp:375]     Train net output #0: loss = 1.18439 (* 1 = 1.18439 loss)
I0802 08:46:34.171537 18636 sgd_solver.cpp:136] Iteration 86400, lr = 0.0046, m = 0.9
I0802 08:46:48.061694 18636 solver.cpp:353] Iteration 86500 (7.19953 iter/s, 13.8898s/100 iter), loss = 1.2828
I0802 08:46:48.061736 18636 solver.cpp:375]     Train net output #0: loss = 1.26162 (* 1 = 1.26162 loss)
I0802 08:46:48.061743 18636 sgd_solver.cpp:136] Iteration 86500, lr = 0.00459375, m = 0.9
I0802 08:47:02.025527 18636 solver.cpp:353] Iteration 86600 (7.16156 iter/s, 13.9634s/100 iter), loss = 1.57253
I0802 08:47:02.025600 18636 solver.cpp:375]     Train net output #0: loss = 1.23145 (* 1 = 1.23145 loss)
I0802 08:47:02.025607 18636 sgd_solver.cpp:136] Iteration 86600, lr = 0.0045875, m = 0.9
I0802 08:47:15.893581 18636 solver.cpp:353] Iteration 86700 (7.21102 iter/s, 13.8677s/100 iter), loss = 1.32981
I0802 08:47:15.893607 18636 solver.cpp:375]     Train net output #0: loss = 1.14904 (* 1 = 1.14904 loss)
I0802 08:47:15.893612 18636 sgd_solver.cpp:136] Iteration 86700, lr = 0.00458125, m = 0.9
I0802 08:47:29.818837 18636 solver.cpp:353] Iteration 86800 (7.1814 iter/s, 13.9249s/100 iter), loss = 1.51511
I0802 08:47:29.818861 18636 solver.cpp:375]     Train net output #0: loss = 1.66036 (* 1 = 1.66036 loss)
I0802 08:47:29.818867 18636 sgd_solver.cpp:136] Iteration 86800, lr = 0.004575, m = 0.9
I0802 08:47:43.690582 18636 solver.cpp:353] Iteration 86900 (7.2091 iter/s, 13.8714s/100 iter), loss = 1.27293
I0802 08:47:43.690651 18636 solver.cpp:375]     Train net output #0: loss = 1.17823 (* 1 = 1.17823 loss)
I0802 08:47:43.690659 18636 sgd_solver.cpp:136] Iteration 86900, lr = 0.00456875, m = 0.9
I0802 08:47:57.506793 18636 solver.cpp:404] Sparsity after update:
I0802 08:47:57.519568 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:47:57.519623 18636 net.cpp:2270] conv1a_param_0(0.328) 
I0802 08:47:57.519642 18636 net.cpp:2270] conv1b_param_0(0.652) 
I0802 08:47:57.519651 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:47:57.519659 18636 net.cpp:2270] res2a_branch2a_param_0(0.665) 
I0802 08:47:57.519667 18636 net.cpp:2270] res2a_branch2b_param_0(0.645) 
I0802 08:47:57.519676 18636 net.cpp:2270] res3a_branch2a_param_0(0.668) 
I0802 08:47:57.519685 18636 net.cpp:2270] res3a_branch2b_param_0(0.662) 
I0802 08:47:57.519692 18636 net.cpp:2270] res4a_branch2a_param_0(0.669) 
I0802 08:47:57.519701 18636 net.cpp:2270] res4a_branch2b_param_0(0.668) 
I0802 08:47:57.519709 18636 net.cpp:2270] res5a_branch2a_param_0(0.67) 
I0802 08:47:57.519717 18636 net.cpp:2270] res5a_branch2b_param_0(0.669) 
I0802 08:47:57.519726 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.57483e+06/2.86678e+06) 0.549
I0802 08:47:57.651391 18661 solver.cpp:450] Finding and applying sparsity: 0.68
I0802 08:48:43.213217 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:48:43.215142 18636 solver.cpp:353] Iteration 87000 (1.68002 iter/s, 59.5229s/100 iter), loss = 0.962858
I0802 08:48:43.215160 18636 solver.cpp:375]     Train net output #0: loss = 1.22429 (* 1 = 1.22429 loss)
I0802 08:48:43.215167 18636 sgd_solver.cpp:136] Iteration 87000, lr = 0.0045625, m = 0.9
I0802 08:48:57.519390 18636 solver.cpp:353] Iteration 87100 (6.99113 iter/s, 14.3038s/100 iter), loss = 1.11381
I0802 08:48:57.519541 18636 solver.cpp:375]     Train net output #0: loss = 1.29369 (* 1 = 1.29369 loss)
I0802 08:48:57.519554 18636 sgd_solver.cpp:136] Iteration 87100, lr = 0.00455625, m = 0.9
I0802 08:49:11.434891 18636 solver.cpp:353] Iteration 87200 (7.18643 iter/s, 13.9151s/100 iter), loss = 1.51388
I0802 08:49:11.434916 18636 solver.cpp:375]     Train net output #0: loss = 1.17931 (* 1 = 1.17931 loss)
I0802 08:49:11.434921 18636 sgd_solver.cpp:136] Iteration 87200, lr = 0.00455, m = 0.9
I0802 08:49:25.351001 18636 solver.cpp:353] Iteration 87300 (7.18612 iter/s, 13.9157s/100 iter), loss = 1.84624
I0802 08:49:25.351120 18636 solver.cpp:375]     Train net output #0: loss = 2.21072 (* 1 = 2.21072 loss)
I0802 08:49:25.351140 18636 sgd_solver.cpp:136] Iteration 87300, lr = 0.00454375, m = 0.9
I0802 08:49:39.298013 18636 solver.cpp:353] Iteration 87400 (7.17019 iter/s, 13.9466s/100 iter), loss = 1.49797
I0802 08:49:39.298038 18636 solver.cpp:375]     Train net output #0: loss = 1.72144 (* 1 = 1.72144 loss)
I0802 08:49:39.298041 18636 sgd_solver.cpp:136] Iteration 87400, lr = 0.0045375, m = 0.9
I0802 08:49:53.263254 18636 solver.cpp:353] Iteration 87500 (7.16083 iter/s, 13.9649s/100 iter), loss = 1.26
I0802 08:49:53.263353 18636 solver.cpp:375]     Train net output #0: loss = 1.63028 (* 1 = 1.63028 loss)
I0802 08:49:53.263375 18636 sgd_solver.cpp:136] Iteration 87500, lr = 0.00453125, m = 0.9
I0802 08:50:07.202610 18636 solver.cpp:353] Iteration 87600 (7.17413 iter/s, 13.939s/100 iter), loss = 1.3509
I0802 08:50:07.202711 18636 solver.cpp:375]     Train net output #0: loss = 1.64186 (* 1 = 1.64186 loss)
I0802 08:50:07.202729 18636 sgd_solver.cpp:136] Iteration 87600, lr = 0.004525, m = 0.9
I0802 08:50:21.165262 18636 solver.cpp:353] Iteration 87700 (7.16216 iter/s, 13.9623s/100 iter), loss = 1.38938
I0802 08:50:21.165288 18636 solver.cpp:375]     Train net output #0: loss = 1.42266 (* 1 = 1.42266 loss)
I0802 08:50:21.165293 18636 sgd_solver.cpp:136] Iteration 87700, lr = 0.00451875, m = 0.9
I0802 08:50:35.148449 18636 solver.cpp:353] Iteration 87800 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.52252
I0802 08:50:35.148476 18636 solver.cpp:375]     Train net output #0: loss = 1.565 (* 1 = 1.565 loss)
I0802 08:50:35.148481 18636 sgd_solver.cpp:136] Iteration 87800, lr = 0.0045125, m = 0.9
I0802 08:50:49.105473 18636 solver.cpp:353] Iteration 87900 (7.16505 iter/s, 13.9566s/100 iter), loss = 1.39721
I0802 08:50:49.105571 18636 solver.cpp:375]     Train net output #0: loss = 1.45263 (* 1 = 1.45263 loss)
I0802 08:50:49.105581 18636 sgd_solver.cpp:136] Iteration 87900, lr = 0.00450625, m = 0.9
I0802 08:51:02.883594 18636 solver.cpp:404] Sparsity after update:
I0802 08:51:02.888474 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:51:02.888487 18636 net.cpp:2270] conv1a_param_0(0.329) 
I0802 08:51:02.888497 18636 net.cpp:2270] conv1b_param_0(0.655) 
I0802 08:51:02.888501 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:51:02.888505 18636 net.cpp:2270] res2a_branch2a_param_0(0.675) 
I0802 08:51:02.888509 18636 net.cpp:2270] res2a_branch2b_param_0(0.651) 
I0802 08:51:02.888514 18636 net.cpp:2270] res3a_branch2a_param_0(0.679) 
I0802 08:51:02.888516 18636 net.cpp:2270] res3a_branch2b_param_0(0.671) 
I0802 08:51:02.888520 18636 net.cpp:2270] res4a_branch2a_param_0(0.68) 
I0802 08:51:02.888523 18636 net.cpp:2270] res4a_branch2b_param_0(0.678) 
I0802 08:51:02.888527 18636 net.cpp:2270] res5a_branch2a_param_0(0.68) 
I0802 08:51:02.888537 18636 net.cpp:2270] res5a_branch2b_param_0(0.68) 
I0802 08:51:02.888541 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.59867e+06/2.86678e+06) 0.558
I0802 08:51:02.888552 18636 solver.cpp:550] Iteration 88000, Testing net (#0)
I0802 08:51:05.512367 18619 data_reader.cpp:264] Starting prefetch of epoch 5
I0802 08:51:22.364962 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.583235
I0802 08:51:22.365092 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809115
I0802 08:51:22.365103 18636 solver.cpp:635]     Test net output #2: loss = 1.82375 (* 1 = 1.82375 loss)
I0802 08:51:22.365120 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.476s
I0802 08:51:22.530488 18661 solver.cpp:450] Finding and applying sparsity: 0.69
I0802 08:52:08.930378 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:52:08.932440 18636 solver.cpp:353] Iteration 88000 (1.25274 iter/s, 79.8248s/100 iter), loss = 1.23901
I0802 08:52:08.932468 18636 solver.cpp:375]     Train net output #0: loss = 1.22075 (* 1 = 1.22075 loss)
I0802 08:52:08.932477 18636 sgd_solver.cpp:136] Iteration 88000, lr = 0.0045, m = 0.9
I0802 08:52:23.202023 18636 solver.cpp:353] Iteration 88100 (7.00811 iter/s, 14.2692s/100 iter), loss = 1.20662
I0802 08:52:23.202049 18636 solver.cpp:375]     Train net output #0: loss = 1.10975 (* 1 = 1.10975 loss)
I0802 08:52:23.202054 18636 sgd_solver.cpp:136] Iteration 88100, lr = 0.00449375, m = 0.9
I0802 08:52:37.092562 18636 solver.cpp:353] Iteration 88200 (7.19935 iter/s, 13.8902s/100 iter), loss = 1.18488
I0802 08:52:37.092591 18636 solver.cpp:375]     Train net output #0: loss = 1.02874 (* 1 = 1.02874 loss)
I0802 08:52:37.092597 18636 sgd_solver.cpp:136] Iteration 88200, lr = 0.0044875, m = 0.9
I0802 08:52:51.088282 18636 solver.cpp:353] Iteration 88300 (7.14524 iter/s, 13.9953s/100 iter), loss = 1.50409
I0802 08:52:51.088409 18636 solver.cpp:375]     Train net output #0: loss = 1.46664 (* 1 = 1.46664 loss)
I0802 08:52:51.088428 18636 sgd_solver.cpp:136] Iteration 88300, lr = 0.00448125, m = 0.9
I0802 08:53:05.018251 18636 solver.cpp:353] Iteration 88400 (7.17897 iter/s, 13.9296s/100 iter), loss = 1.53924
I0802 08:53:05.018276 18636 solver.cpp:375]     Train net output #0: loss = 1.67828 (* 1 = 1.67828 loss)
I0802 08:53:05.018282 18636 sgd_solver.cpp:136] Iteration 88400, lr = 0.004475, m = 0.9
I0802 08:53:18.949398 18636 solver.cpp:353] Iteration 88500 (7.17836 iter/s, 13.9308s/100 iter), loss = 1.35887
I0802 08:53:18.949425 18636 solver.cpp:375]     Train net output #0: loss = 1.1978 (* 1 = 1.1978 loss)
I0802 08:53:18.949430 18636 sgd_solver.cpp:136] Iteration 88500, lr = 0.00446875, m = 0.9
I0802 08:53:32.838855 18636 solver.cpp:353] Iteration 88600 (7.19991 iter/s, 13.8891s/100 iter), loss = 1.35303
I0802 08:53:32.838958 18636 solver.cpp:375]     Train net output #0: loss = 1.53147 (* 1 = 1.53147 loss)
I0802 08:53:32.838976 18636 sgd_solver.cpp:136] Iteration 88600, lr = 0.0044625, m = 0.9
I0802 08:53:46.729542 18636 solver.cpp:353] Iteration 88700 (7.19927 iter/s, 13.8903s/100 iter), loss = 1.55227
I0802 08:53:46.729569 18636 solver.cpp:375]     Train net output #0: loss = 1.97111 (* 1 = 1.97111 loss)
I0802 08:53:46.729574 18636 sgd_solver.cpp:136] Iteration 88700, lr = 0.00445625, m = 0.9
I0802 08:54:00.608783 18636 solver.cpp:353] Iteration 88800 (7.2052 iter/s, 13.8789s/100 iter), loss = 1.34878
I0802 08:54:00.608808 18636 solver.cpp:375]     Train net output #0: loss = 1.2469 (* 1 = 1.2469 loss)
I0802 08:54:00.608814 18636 sgd_solver.cpp:136] Iteration 88800, lr = 0.00445, m = 0.9
I0802 08:54:14.559067 18636 solver.cpp:353] Iteration 88900 (7.16851 iter/s, 13.9499s/100 iter), loss = 1.52187
I0802 08:54:14.559345 18636 solver.cpp:375]     Train net output #0: loss = 0.811696 (* 1 = 0.811696 loss)
I0802 08:54:14.559458 18636 sgd_solver.cpp:136] Iteration 88900, lr = 0.00444375, m = 0.9
I0802 08:54:28.309801 18636 solver.cpp:404] Sparsity after update:
I0802 08:54:28.321324 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:54:28.321338 18636 net.cpp:2270] conv1a_param_0(0.329) 
I0802 08:54:28.321347 18636 net.cpp:2270] conv1b_param_0(0.665) 
I0802 08:54:28.321350 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:54:28.321362 18636 net.cpp:2270] res2a_branch2a_param_0(0.684) 
I0802 08:54:28.321372 18636 net.cpp:2270] res2a_branch2b_param_0(0.66) 
I0802 08:54:28.321382 18636 net.cpp:2270] res3a_branch2a_param_0(0.689) 
I0802 08:54:28.321390 18636 net.cpp:2270] res3a_branch2b_param_0(0.68) 
I0802 08:54:28.321398 18636 net.cpp:2270] res4a_branch2a_param_0(0.689) 
I0802 08:54:28.321413 18636 net.cpp:2270] res4a_branch2b_param_0(0.688) 
I0802 08:54:28.321421 18636 net.cpp:2270] res5a_branch2a_param_0(0.69) 
I0802 08:54:28.321431 18636 net.cpp:2270] res5a_branch2b_param_0(0.689) 
I0802 08:54:28.321440 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.62174e+06/2.86678e+06) 0.566
I0802 08:54:28.450793 18661 solver.cpp:450] Finding and applying sparsity: 0.7
I0802 08:55:15.661182 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:55:15.663120 18636 solver.cpp:353] Iteration 89000 (1.6366 iter/s, 61.1024s/100 iter), loss = 1.45586
I0802 08:55:15.663141 18636 solver.cpp:375]     Train net output #0: loss = 1.55272 (* 1 = 1.55272 loss)
I0802 08:55:15.663148 18636 sgd_solver.cpp:136] Iteration 89000, lr = 0.0044375, m = 0.9
I0802 08:55:30.009748 18636 solver.cpp:353] Iteration 89100 (6.97048 iter/s, 14.3462s/100 iter), loss = 1.2203
I0802 08:55:30.009774 18636 solver.cpp:375]     Train net output #0: loss = 1.52629 (* 1 = 1.52629 loss)
I0802 08:55:30.009779 18636 sgd_solver.cpp:136] Iteration 89100, lr = 0.00443125, m = 0.9
I0802 08:55:43.866152 18636 solver.cpp:353] Iteration 89200 (7.21708 iter/s, 13.856s/100 iter), loss = 1.82391
I0802 08:55:43.866181 18636 solver.cpp:375]     Train net output #0: loss = 1.48263 (* 1 = 1.48263 loss)
I0802 08:55:43.866186 18636 sgd_solver.cpp:136] Iteration 89200, lr = 0.004425, m = 0.9
I0802 08:55:57.764144 18636 solver.cpp:353] Iteration 89300 (7.19549 iter/s, 13.8976s/100 iter), loss = 1.4085
I0802 08:55:57.764226 18636 solver.cpp:375]     Train net output #0: loss = 1.05281 (* 1 = 1.05281 loss)
I0802 08:55:57.764235 18636 sgd_solver.cpp:136] Iteration 89300, lr = 0.00441875, m = 0.9
I0802 08:56:11.664780 18636 solver.cpp:353] Iteration 89400 (7.19411 iter/s, 13.9003s/100 iter), loss = 1.15619
I0802 08:56:11.664809 18636 solver.cpp:375]     Train net output #0: loss = 1.15286 (* 1 = 1.15286 loss)
I0802 08:56:11.664822 18636 sgd_solver.cpp:136] Iteration 89400, lr = 0.0044125, m = 0.9
I0802 08:56:25.489771 18636 solver.cpp:353] Iteration 89500 (7.23348 iter/s, 13.8246s/100 iter), loss = 1.25944
I0802 08:56:25.489794 18636 solver.cpp:375]     Train net output #0: loss = 1.04668 (* 1 = 1.04668 loss)
I0802 08:56:25.489799 18636 sgd_solver.cpp:136] Iteration 89500, lr = 0.00440625, m = 0.9
I0802 08:56:39.341161 18636 solver.cpp:353] Iteration 89600 (7.21969 iter/s, 13.851s/100 iter), loss = 1.36002
I0802 08:56:39.341223 18636 solver.cpp:375]     Train net output #0: loss = 1.48537 (* 1 = 1.48537 loss)
I0802 08:56:39.341228 18636 sgd_solver.cpp:136] Iteration 89600, lr = 0.0044, m = 0.9
I0802 08:56:53.181243 18636 solver.cpp:353] Iteration 89700 (7.22559 iter/s, 13.8397s/100 iter), loss = 1.32503
I0802 08:56:53.181274 18636 solver.cpp:375]     Train net output #0: loss = 1.35539 (* 1 = 1.35539 loss)
I0802 08:56:53.181282 18636 sgd_solver.cpp:136] Iteration 89700, lr = 0.00439375, m = 0.9
I0802 08:57:07.037693 18636 solver.cpp:353] Iteration 89800 (7.21706 iter/s, 13.8561s/100 iter), loss = 1.48107
I0802 08:57:07.037719 18636 solver.cpp:375]     Train net output #0: loss = 1.68988 (* 1 = 1.68988 loss)
I0802 08:57:07.037724 18636 sgd_solver.cpp:136] Iteration 89800, lr = 0.0043875, m = 0.9
I0802 08:57:20.912775 18636 solver.cpp:353] Iteration 89900 (7.20736 iter/s, 13.8747s/100 iter), loss = 1.40908
I0802 08:57:20.913442 18636 solver.cpp:375]     Train net output #0: loss = 1.77448 (* 1 = 1.77448 loss)
I0802 08:57:20.913449 18636 sgd_solver.cpp:136] Iteration 89900, lr = 0.00438125, m = 0.9
I0802 08:57:34.626440 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_90000.caffemodel
I0802 08:57:34.697134 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_90000.solverstate
I0802 08:57:34.701521 18636 solver.cpp:404] Sparsity after update:
I0802 08:57:34.704785 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:57:34.704794 18636 net.cpp:2270] conv1a_param_0(0.342) 
I0802 08:57:34.704803 18636 net.cpp:2270] conv1b_param_0(0.675) 
I0802 08:57:34.704807 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:57:34.704825 18636 net.cpp:2270] res2a_branch2a_param_0(0.694) 
I0802 08:57:34.704835 18636 net.cpp:2270] res2a_branch2b_param_0(0.665) 
I0802 08:57:34.704843 18636 net.cpp:2270] res3a_branch2a_param_0(0.699) 
I0802 08:57:34.704852 18636 net.cpp:2270] res3a_branch2b_param_0(0.689) 
I0802 08:57:34.704860 18636 net.cpp:2270] res4a_branch2a_param_0(0.7) 
I0802 08:57:34.704870 18636 net.cpp:2270] res4a_branch2b_param_0(0.698) 
I0802 08:57:34.704883 18636 net.cpp:2270] res5a_branch2a_param_0(0.7) 
I0802 08:57:34.704890 18636 net.cpp:2270] res5a_branch2b_param_0(0.7) 
I0802 08:57:34.704896 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.64553e+06/2.86678e+06) 0.574
I0802 08:57:34.704913 18636 solver.cpp:550] Iteration 90000, Testing net (#0)
I0802 08:57:53.763344 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584823
I0802 08:57:53.763478 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816526
I0802 08:57:53.763487 18636 solver.cpp:635]     Test net output #2: loss = 1.80895 (* 1 = 1.80895 loss)
I0802 08:57:53.763506 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.0581s
I0802 08:57:53.901083 18661 solver.cpp:450] Finding and applying sparsity: 0.71
I0802 08:58:41.912343 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:58:41.914276 18636 solver.cpp:353] Iteration 90000 (1.23458 iter/s, 80.9993s/100 iter), loss = 1.5666
I0802 08:58:41.914295 18636 solver.cpp:375]     Train net output #0: loss = 1.70678 (* 1 = 1.70678 loss)
I0802 08:58:41.914304 18636 sgd_solver.cpp:136] Iteration 90000, lr = 0.004375, m = 0.9
I0802 08:58:56.175129 18636 solver.cpp:353] Iteration 90100 (7.0124 iter/s, 14.2604s/100 iter), loss = 1.53521
I0802 08:58:56.175158 18636 solver.cpp:375]     Train net output #0: loss = 1.46559 (* 1 = 1.46559 loss)
I0802 08:58:56.175161 18636 sgd_solver.cpp:136] Iteration 90100, lr = 0.00436875, m = 0.9
I0802 08:59:09.999436 18636 solver.cpp:353] Iteration 90200 (7.23384 iter/s, 13.8239s/100 iter), loss = 1.55019
I0802 08:59:09.999465 18636 solver.cpp:375]     Train net output #0: loss = 1.6271 (* 1 = 1.6271 loss)
I0802 08:59:09.999470 18636 sgd_solver.cpp:136] Iteration 90200, lr = 0.0043625, m = 0.9
I0802 08:59:23.915781 18636 solver.cpp:353] Iteration 90300 (7.186 iter/s, 13.916s/100 iter), loss = 1.23606
I0802 08:59:23.915848 18636 solver.cpp:375]     Train net output #0: loss = 1.06332 (* 1 = 1.06332 loss)
I0802 08:59:23.915855 18636 sgd_solver.cpp:136] Iteration 90300, lr = 0.00435625, m = 0.9
I0802 08:59:37.837008 18636 solver.cpp:353] Iteration 90400 (7.18348 iter/s, 13.9208s/100 iter), loss = 1.37117
I0802 08:59:37.837038 18636 solver.cpp:375]     Train net output #0: loss = 1.257 (* 1 = 1.257 loss)
I0802 08:59:37.837041 18636 sgd_solver.cpp:136] Iteration 90400, lr = 0.00435, m = 0.9
I0802 08:59:51.712304 18636 solver.cpp:353] Iteration 90500 (7.20725 iter/s, 13.8749s/100 iter), loss = 1.1092
I0802 08:59:51.712330 18636 solver.cpp:375]     Train net output #0: loss = 1.25577 (* 1 = 1.25577 loss)
I0802 08:59:51.712334 18636 sgd_solver.cpp:136] Iteration 90500, lr = 0.00434375, m = 0.9
I0802 09:00:05.619259 18636 solver.cpp:353] Iteration 90600 (7.19085 iter/s, 13.9066s/100 iter), loss = 1.34664
I0802 09:00:05.619338 18636 solver.cpp:375]     Train net output #0: loss = 1.15817 (* 1 = 1.15817 loss)
I0802 09:00:05.619344 18636 sgd_solver.cpp:136] Iteration 90600, lr = 0.0043375, m = 0.9
I0802 09:00:19.609673 18636 solver.cpp:353] Iteration 90700 (7.14795 iter/s, 13.99s/100 iter), loss = 1.00384
I0802 09:00:19.609704 18636 solver.cpp:375]     Train net output #0: loss = 0.995206 (* 1 = 0.995206 loss)
I0802 09:00:19.609710 18636 sgd_solver.cpp:136] Iteration 90700, lr = 0.00433125, m = 0.9
I0802 09:00:33.477140 18636 solver.cpp:353] Iteration 90800 (7.21132 iter/s, 13.8671s/100 iter), loss = 1.71948
I0802 09:00:33.477169 18636 solver.cpp:375]     Train net output #0: loss = 1.30504 (* 1 = 1.30504 loss)
I0802 09:00:33.477175 18636 sgd_solver.cpp:136] Iteration 90800, lr = 0.004325, m = 0.9
I0802 09:00:47.344890 18636 solver.cpp:353] Iteration 90900 (7.21118 iter/s, 13.8674s/100 iter), loss = 1.99398
I0802 09:00:47.344960 18636 solver.cpp:375]     Train net output #0: loss = 2.1506 (* 1 = 2.1506 loss)
I0802 09:00:47.344967 18636 sgd_solver.cpp:136] Iteration 90900, lr = 0.00431875, m = 0.9
I0802 09:01:01.126853 18636 solver.cpp:404] Sparsity after update:
I0802 09:01:01.138432 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:01:01.138447 18636 net.cpp:2270] conv1a_param_0(0.331) 
I0802 09:01:01.138456 18636 net.cpp:2270] conv1b_param_0(0.685) 
I0802 09:01:01.138459 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:01:01.138470 18636 net.cpp:2270] res2a_branch2a_param_0(0.703) 
I0802 09:01:01.138476 18636 net.cpp:2270] res2a_branch2b_param_0(0.672) 
I0802 09:01:01.138481 18636 net.cpp:2270] res3a_branch2a_param_0(0.708) 
I0802 09:01:01.138485 18636 net.cpp:2270] res3a_branch2b_param_0(0.697) 
I0802 09:01:01.138490 18636 net.cpp:2270] res4a_branch2a_param_0(0.709) 
I0802 09:01:01.138494 18636 net.cpp:2270] res4a_branch2b_param_0(0.706) 
I0802 09:01:01.138499 18636 net.cpp:2270] res5a_branch2a_param_0(0.71) 
I0802 09:01:01.138504 18636 net.cpp:2270] res5a_branch2b_param_0(0.709) 
I0802 09:01:01.138507 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.66811e+06/2.86678e+06) 0.582
I0802 09:01:01.280616 18661 solver.cpp:450] Finding and applying sparsity: 0.72
I0802 09:01:51.034814 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:01:51.036746 18636 solver.cpp:353] Iteration 91000 (1.5701 iter/s, 63.6901s/100 iter), loss = 1.73759
I0802 09:01:51.036767 18636 solver.cpp:375]     Train net output #0: loss = 1.89228 (* 1 = 1.89228 loss)
I0802 09:01:51.036775 18636 sgd_solver.cpp:136] Iteration 91000, lr = 0.0043125, m = 0.9
I0802 09:02:05.313053 18636 solver.cpp:353] Iteration 91100 (7.00481 iter/s, 14.2759s/100 iter), loss = 1.32941
I0802 09:02:05.313153 18636 solver.cpp:375]     Train net output #0: loss = 1.52134 (* 1 = 1.52134 loss)
I0802 09:02:05.313175 18636 sgd_solver.cpp:136] Iteration 91100, lr = 0.00430625, m = 0.9
I0802 09:02:19.171399 18636 solver.cpp:353] Iteration 91200 (7.21607 iter/s, 13.858s/100 iter), loss = 1.35759
I0802 09:02:19.171425 18636 solver.cpp:375]     Train net output #0: loss = 1.16341 (* 1 = 1.16341 loss)
I0802 09:02:19.171430 18636 sgd_solver.cpp:136] Iteration 91200, lr = 0.0043, m = 0.9
I0802 09:02:33.091248 18636 solver.cpp:353] Iteration 91300 (7.18419 iter/s, 13.9195s/100 iter), loss = 1.03429
I0802 09:02:33.091369 18636 solver.cpp:375]     Train net output #0: loss = 1.11414 (* 1 = 1.11414 loss)
I0802 09:02:33.091388 18636 sgd_solver.cpp:136] Iteration 91300, lr = 0.00429375, m = 0.9
I0802 09:02:46.932096 18636 solver.cpp:353] Iteration 91400 (7.22519 iter/s, 13.8405s/100 iter), loss = 1.11031
I0802 09:02:46.932127 18636 solver.cpp:375]     Train net output #0: loss = 1.33782 (* 1 = 1.33782 loss)
I0802 09:02:46.932134 18636 sgd_solver.cpp:136] Iteration 91400, lr = 0.0042875, m = 0.9
I0802 09:03:00.800863 18636 solver.cpp:353] Iteration 91500 (7.21065 iter/s, 13.8684s/100 iter), loss = 1.31878
I0802 09:03:00.800894 18636 solver.cpp:375]     Train net output #0: loss = 1.25964 (* 1 = 1.25964 loss)
I0802 09:03:00.800899 18636 sgd_solver.cpp:136] Iteration 91500, lr = 0.00428125, m = 0.9
I0802 09:03:14.771708 18636 solver.cpp:353] Iteration 91600 (7.15796 iter/s, 13.9705s/100 iter), loss = 1.18656
I0802 09:03:14.771770 18636 solver.cpp:375]     Train net output #0: loss = 1.09562 (* 1 = 1.09562 loss)
I0802 09:03:14.771775 18636 sgd_solver.cpp:136] Iteration 91600, lr = 0.004275, m = 0.9
I0802 09:03:28.659773 18636 solver.cpp:353] Iteration 91700 (7.20063 iter/s, 13.8877s/100 iter), loss = 1.19929
I0802 09:03:28.659802 18636 solver.cpp:375]     Train net output #0: loss = 1.03104 (* 1 = 1.03104 loss)
I0802 09:03:28.659809 18636 sgd_solver.cpp:136] Iteration 91700, lr = 0.00426875, m = 0.9
I0802 09:03:42.535064 18636 solver.cpp:353] Iteration 91800 (7.20726 iter/s, 13.8749s/100 iter), loss = 1.20735
I0802 09:03:42.535095 18636 solver.cpp:375]     Train net output #0: loss = 1.19184 (* 1 = 1.19184 loss)
I0802 09:03:42.535100 18636 sgd_solver.cpp:136] Iteration 91800, lr = 0.0042625, m = 0.9
I0802 09:03:56.404919 18636 solver.cpp:353] Iteration 91900 (7.21008 iter/s, 13.8695s/100 iter), loss = 1.44965
I0802 09:03:56.405020 18636 solver.cpp:375]     Train net output #0: loss = 1.52524 (* 1 = 1.52524 loss)
I0802 09:03:56.405027 18636 sgd_solver.cpp:136] Iteration 91900, lr = 0.00425625, m = 0.9
I0802 09:04:10.136062 18636 solver.cpp:404] Sparsity after update:
I0802 09:04:10.141319 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:04:10.141330 18636 net.cpp:2270] conv1a_param_0(0.335) 
I0802 09:04:10.141340 18636 net.cpp:2270] conv1b_param_0(0.686) 
I0802 09:04:10.141343 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:04:10.141360 18636 net.cpp:2270] res2a_branch2a_param_0(0.712) 
I0802 09:04:10.141368 18636 net.cpp:2270] res2a_branch2b_param_0(0.677) 
I0802 09:04:10.141376 18636 net.cpp:2270] res3a_branch2a_param_0(0.718) 
I0802 09:04:10.141386 18636 net.cpp:2270] res3a_branch2b_param_0(0.705) 
I0802 09:04:10.141392 18636 net.cpp:2270] res4a_branch2a_param_0(0.72) 
I0802 09:04:10.141400 18636 net.cpp:2270] res4a_branch2b_param_0(0.716) 
I0802 09:04:10.141410 18636 net.cpp:2270] res5a_branch2a_param_0(0.72) 
I0802 09:04:10.141419 18636 net.cpp:2270] res5a_branch2b_param_0(0.72) 
I0802 09:04:10.141427 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.69178e+06/2.86678e+06) 0.59
I0802 09:04:10.141443 18636 solver.cpp:550] Iteration 92000, Testing net (#0)
I0802 09:04:29.432979 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.575059
I0802 09:04:29.433079 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805233
I0802 09:04:29.433089 18636 solver.cpp:635]     Test net output #2: loss = 1.85073 (* 1 = 1.85073 loss)
I0802 09:04:29.433107 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2911s
I0802 09:04:29.571313 18661 solver.cpp:450] Finding and applying sparsity: 0.73
I0802 09:05:19.084910 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:05:19.086846 18636 solver.cpp:353] Iteration 92000 (1.20949 iter/s, 82.6796s/100 iter), loss = 1.43995
I0802 09:05:19.086864 18636 solver.cpp:375]     Train net output #0: loss = 1.33322 (* 1 = 1.33322 loss)
I0802 09:05:19.086870 18636 sgd_solver.cpp:136] Iteration 92000, lr = 0.00425, m = 0.9
I0802 09:05:33.279531 18636 solver.cpp:353] Iteration 92100 (7.04608 iter/s, 14.1923s/100 iter), loss = 1.43048
I0802 09:05:33.279558 18636 solver.cpp:375]     Train net output #0: loss = 1.07722 (* 1 = 1.07722 loss)
I0802 09:05:33.279563 18636 sgd_solver.cpp:136] Iteration 92100, lr = 0.00424375, m = 0.9
I0802 09:05:47.153479 18636 solver.cpp:353] Iteration 92200 (7.20796 iter/s, 13.8736s/100 iter), loss = 1.42904
I0802 09:05:47.153508 18636 solver.cpp:375]     Train net output #0: loss = 1.26045 (* 1 = 1.26045 loss)
I0802 09:05:47.153514 18636 sgd_solver.cpp:136] Iteration 92200, lr = 0.0042375, m = 0.9
I0802 09:06:01.023161 18636 solver.cpp:353] Iteration 92300 (7.21017 iter/s, 13.8693s/100 iter), loss = 1.76016
I0802 09:06:01.023221 18636 solver.cpp:375]     Train net output #0: loss = 1.74641 (* 1 = 1.74641 loss)
I0802 09:06:01.023226 18636 sgd_solver.cpp:136] Iteration 92300, lr = 0.00423125, m = 0.9
I0802 09:06:14.839328 18636 solver.cpp:353] Iteration 92400 (7.2381 iter/s, 13.8158s/100 iter), loss = 1.12946
I0802 09:06:14.839368 18636 solver.cpp:375]     Train net output #0: loss = 0.972882 (* 1 = 0.972882 loss)
I0802 09:06:14.839375 18636 sgd_solver.cpp:136] Iteration 92400, lr = 0.004225, m = 0.9
I0802 09:06:28.676776 18636 solver.cpp:353] Iteration 92500 (7.22696 iter/s, 13.8371s/100 iter), loss = 1.02756
I0802 09:06:28.676805 18636 solver.cpp:375]     Train net output #0: loss = 0.999278 (* 1 = 0.999278 loss)
I0802 09:06:28.676811 18636 sgd_solver.cpp:136] Iteration 92500, lr = 0.00421875, m = 0.9
I0802 09:06:42.524588 18636 solver.cpp:353] Iteration 92600 (7.22156 iter/s, 13.8474s/100 iter), loss = 1.55658
I0802 09:06:42.524708 18636 solver.cpp:375]     Train net output #0: loss = 1.61406 (* 1 = 1.61406 loss)
I0802 09:06:42.524715 18636 sgd_solver.cpp:136] Iteration 92600, lr = 0.0042125, m = 0.9
I0802 09:06:56.411448 18636 solver.cpp:353] Iteration 92700 (7.20125 iter/s, 13.8865s/100 iter), loss = 1.43113
I0802 09:06:56.411473 18636 solver.cpp:375]     Train net output #0: loss = 1.09897 (* 1 = 1.09897 loss)
I0802 09:06:56.411478 18636 sgd_solver.cpp:136] Iteration 92700, lr = 0.00420625, m = 0.9
I0802 09:07:10.275451 18636 solver.cpp:353] Iteration 92800 (7.21312 iter/s, 13.8636s/100 iter), loss = 1.56438
I0802 09:07:10.275478 18636 solver.cpp:375]     Train net output #0: loss = 1.83227 (* 1 = 1.83227 loss)
I0802 09:07:10.275485 18636 sgd_solver.cpp:136] Iteration 92800, lr = 0.0042, m = 0.9
I0802 09:07:24.178577 18636 solver.cpp:353] Iteration 92900 (7.19283 iter/s, 13.9027s/100 iter), loss = 1.43547
I0802 09:07:24.178643 18636 solver.cpp:375]     Train net output #0: loss = 1.48784 (* 1 = 1.48784 loss)
I0802 09:07:24.178650 18636 sgd_solver.cpp:136] Iteration 92900, lr = 0.00419375, m = 0.9
I0802 09:07:37.872086 18636 solver.cpp:404] Sparsity after update:
I0802 09:07:37.886112 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:07:37.886128 18636 net.cpp:2270] conv1a_param_0(0.349) 
I0802 09:07:37.886138 18636 net.cpp:2270] conv1b_param_0(0.694) 
I0802 09:07:37.886142 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:07:37.886144 18636 net.cpp:2270] res2a_branch2a_param_0(0.721) 
I0802 09:07:37.886148 18636 net.cpp:2270] res2a_branch2b_param_0(0.682) 
I0802 09:07:37.886152 18636 net.cpp:2270] res3a_branch2a_param_0(0.728) 
I0802 09:07:37.886154 18636 net.cpp:2270] res3a_branch2b_param_0(0.712) 
I0802 09:07:37.886157 18636 net.cpp:2270] res4a_branch2a_param_0(0.729) 
I0802 09:07:37.886160 18636 net.cpp:2270] res4a_branch2b_param_0(0.725) 
I0802 09:07:37.886163 18636 net.cpp:2270] res5a_branch2a_param_0(0.73) 
I0802 09:07:37.886168 18636 net.cpp:2270] res5a_branch2b_param_0(0.729) 
I0802 09:07:37.886170 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.71469e+06/2.86678e+06) 0.598
I0802 09:07:38.016484 18661 solver.cpp:450] Finding and applying sparsity: 0.74
I0802 09:08:29.251960 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:08:29.253918 18636 solver.cpp:353] Iteration 93000 (1.53672 iter/s, 65.0735s/100 iter), loss = 1.31286
I0802 09:08:29.253937 18636 solver.cpp:375]     Train net output #0: loss = 1.43413 (* 1 = 1.43413 loss)
I0802 09:08:29.253944 18636 sgd_solver.cpp:136] Iteration 93000, lr = 0.0041875, m = 0.9
I0802 09:08:43.463793 18636 solver.cpp:353] Iteration 93100 (7.03756 iter/s, 14.2095s/100 iter), loss = 1.48675
I0802 09:08:43.463845 18636 solver.cpp:375]     Train net output #0: loss = 1.72398 (* 1 = 1.72398 loss)
I0802 09:08:43.463857 18636 sgd_solver.cpp:136] Iteration 93100, lr = 0.00418125, m = 0.9
I0802 09:08:57.303495 18636 solver.cpp:353] Iteration 93200 (7.22579 iter/s, 13.8393s/100 iter), loss = 1.25355
I0802 09:08:57.303524 18636 solver.cpp:375]     Train net output #0: loss = 1.25102 (* 1 = 1.25102 loss)
I0802 09:08:57.303529 18636 sgd_solver.cpp:136] Iteration 93200, lr = 0.004175, m = 0.9
I0802 09:09:11.238610 18636 solver.cpp:353] Iteration 93300 (7.17632 iter/s, 13.9347s/100 iter), loss = 1.38078
I0802 09:09:11.238700 18636 solver.cpp:375]     Train net output #0: loss = 1.09018 (* 1 = 1.09018 loss)
I0802 09:09:11.238708 18636 sgd_solver.cpp:136] Iteration 93300, lr = 0.00416875, m = 0.9
I0802 09:09:25.213346 18636 solver.cpp:353] Iteration 93400 (7.15597 iter/s, 13.9743s/100 iter), loss = 1.78342
I0802 09:09:25.213372 18636 solver.cpp:375]     Train net output #0: loss = 1.82909 (* 1 = 1.82909 loss)
I0802 09:09:25.213379 18636 sgd_solver.cpp:136] Iteration 93400, lr = 0.0041625, m = 0.9
I0802 09:09:39.135700 18636 solver.cpp:353] Iteration 93500 (7.18289 iter/s, 13.922s/100 iter), loss = 1.34983
I0802 09:09:39.135730 18636 solver.cpp:375]     Train net output #0: loss = 1.47399 (* 1 = 1.47399 loss)
I0802 09:09:39.135771 18636 sgd_solver.cpp:136] Iteration 93500, lr = 0.00415625, m = 0.9
I0802 09:09:53.012441 18636 solver.cpp:353] Iteration 93600 (7.2065 iter/s, 13.8764s/100 iter), loss = 1.70012
I0802 09:09:53.013111 18636 solver.cpp:375]     Train net output #0: loss = 1.37061 (* 1 = 1.37061 loss)
I0802 09:09:53.013134 18636 sgd_solver.cpp:136] Iteration 93600, lr = 0.00415, m = 0.9
I0802 09:10:06.929141 18636 solver.cpp:353] Iteration 93700 (7.18581 iter/s, 13.9163s/100 iter), loss = 1.01916
I0802 09:10:06.929173 18636 solver.cpp:375]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0802 09:10:06.929180 18636 sgd_solver.cpp:136] Iteration 93700, lr = 0.00414375, m = 0.9
I0802 09:10:20.874249 18636 solver.cpp:353] Iteration 93800 (7.17117 iter/s, 13.9447s/100 iter), loss = 0.964316
I0802 09:10:20.874280 18636 solver.cpp:375]     Train net output #0: loss = 0.968726 (* 1 = 0.968726 loss)
I0802 09:10:20.874286 18636 sgd_solver.cpp:136] Iteration 93800, lr = 0.0041375, m = 0.9
I0802 09:10:34.808835 18636 solver.cpp:353] Iteration 93900 (7.17659 iter/s, 13.9342s/100 iter), loss = 1.43874
I0802 09:10:34.808900 18636 solver.cpp:375]     Train net output #0: loss = 1.42453 (* 1 = 1.42453 loss)
I0802 09:10:34.808908 18636 sgd_solver.cpp:136] Iteration 93900, lr = 0.00413125, m = 0.9
I0802 09:10:48.630020 18636 solver.cpp:404] Sparsity after update:
I0802 09:10:48.636037 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:10:48.636050 18636 net.cpp:2270] conv1a_param_0(0.352) 
I0802 09:10:48.636059 18636 net.cpp:2270] conv1b_param_0(0.701) 
I0802 09:10:48.636062 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:10:48.636067 18636 net.cpp:2270] res2a_branch2a_param_0(0.73) 
I0802 09:10:48.636070 18636 net.cpp:2270] res2a_branch2b_param_0(0.685) 
I0802 09:10:48.636073 18636 net.cpp:2270] res3a_branch2a_param_0(0.738) 
I0802 09:10:48.636076 18636 net.cpp:2270] res3a_branch2b_param_0(0.719) 
I0802 09:10:48.636080 18636 net.cpp:2270] res4a_branch2a_param_0(0.74) 
I0802 09:10:48.636085 18636 net.cpp:2270] res4a_branch2b_param_0(0.734) 
I0802 09:10:48.636088 18636 net.cpp:2270] res5a_branch2a_param_0(0.74) 
I0802 09:10:48.636091 18636 net.cpp:2270] res5a_branch2b_param_0(0.74) 
I0802 09:10:48.636096 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.73823e+06/2.86678e+06) 0.606
I0802 09:10:48.636109 18636 solver.cpp:550] Iteration 94000, Testing net (#0)
I0802 09:10:49.173979 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:11:08.486057 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.579294
I0802 09:11:08.486109 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811703
I0802 09:11:08.486114 18636 solver.cpp:635]     Test net output #2: loss = 1.84217 (* 1 = 1.84217 loss)
I0802 09:11:08.486133 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8495s
I0802 09:11:08.638149 18661 solver.cpp:450] Finding and applying sparsity: 0.75
I0802 09:12:01.096415 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:12:01.098361 18636 solver.cpp:353] Iteration 94000 (1.15892 iter/s, 86.2871s/100 iter), loss = 1.61096
I0802 09:12:01.098379 18636 solver.cpp:375]     Train net output #0: loss = 1.9893 (* 1 = 1.9893 loss)
I0802 09:12:01.098388 18636 sgd_solver.cpp:136] Iteration 94000, lr = 0.004125, m = 0.9
I0802 09:12:15.365159 18636 solver.cpp:353] Iteration 94100 (7.00948 iter/s, 14.2664s/100 iter), loss = 1.52549
I0802 09:12:15.365193 18636 solver.cpp:375]     Train net output #0: loss = 1.30401 (* 1 = 1.30401 loss)
I0802 09:12:15.365200 18636 sgd_solver.cpp:136] Iteration 94100, lr = 0.00411875, m = 0.9
I0802 09:12:29.304847 18636 solver.cpp:353] Iteration 94200 (7.17396 iter/s, 13.9393s/100 iter), loss = 1.52705
I0802 09:12:29.304939 18636 solver.cpp:375]     Train net output #0: loss = 1.55584 (* 1 = 1.55584 loss)
I0802 09:12:29.304960 18636 sgd_solver.cpp:136] Iteration 94200, lr = 0.0041125, m = 0.9
I0802 09:12:43.317581 18636 solver.cpp:353] Iteration 94300 (7.13657 iter/s, 14.0123s/100 iter), loss = 1.33492
I0802 09:12:43.317685 18636 solver.cpp:375]     Train net output #0: loss = 1.67652 (* 1 = 1.67652 loss)
I0802 09:12:43.317693 18636 sgd_solver.cpp:136] Iteration 94300, lr = 0.00410625, m = 0.9
I0802 09:12:57.275323 18636 solver.cpp:353] Iteration 94400 (7.16469 iter/s, 13.9573s/100 iter), loss = 1.84577
I0802 09:12:57.275365 18636 solver.cpp:375]     Train net output #0: loss = 2.23878 (* 1 = 2.23878 loss)
I0802 09:12:57.275372 18636 sgd_solver.cpp:136] Iteration 94400, lr = 0.0041, m = 0.9
I0802 09:13:11.262715 18636 solver.cpp:353] Iteration 94500 (7.1495 iter/s, 13.987s/100 iter), loss = 1.7174
I0802 09:13:11.262816 18636 solver.cpp:375]     Train net output #0: loss = 1.41863 (* 1 = 1.41863 loss)
I0802 09:13:11.262838 18636 sgd_solver.cpp:136] Iteration 94500, lr = 0.00409375, m = 0.9
I0802 09:13:25.210671 18636 solver.cpp:353] Iteration 94600 (7.1697 iter/s, 13.9476s/100 iter), loss = 0.876213
I0802 09:13:25.210728 18636 solver.cpp:375]     Train net output #0: loss = 1.17565 (* 1 = 1.17565 loss)
I0802 09:13:25.210734 18636 sgd_solver.cpp:136] Iteration 94600, lr = 0.0040875, m = 0.9
I0802 09:13:39.220795 18636 solver.cpp:353] Iteration 94700 (7.13789 iter/s, 14.0097s/100 iter), loss = 1.61629
I0802 09:13:39.220824 18636 solver.cpp:375]     Train net output #0: loss = 1.87358 (* 1 = 1.87358 loss)
I0802 09:13:39.220830 18636 sgd_solver.cpp:136] Iteration 94700, lr = 0.00408125, m = 0.9
I0802 09:13:53.163422 18636 solver.cpp:353] Iteration 94800 (7.17245 iter/s, 13.9422s/100 iter), loss = 1.04097
I0802 09:13:53.163447 18636 solver.cpp:375]     Train net output #0: loss = 0.97897 (* 1 = 0.97897 loss)
I0802 09:13:53.163453 18636 sgd_solver.cpp:136] Iteration 94800, lr = 0.004075, m = 0.9
I0802 09:14:07.197845 18636 solver.cpp:353] Iteration 94900 (7.12554 iter/s, 14.034s/100 iter), loss = 1.29103
I0802 09:14:07.197901 18636 solver.cpp:375]     Train net output #0: loss = 1.36321 (* 1 = 1.36321 loss)
I0802 09:14:07.197907 18636 sgd_solver.cpp:136] Iteration 94900, lr = 0.00406875, m = 0.9
I0802 09:14:21.047907 18636 solver.cpp:404] Sparsity after update:
I0802 09:14:21.061589 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:14:21.061601 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:14:21.061609 18636 net.cpp:2270] conv1b_param_0(0.703) 
I0802 09:14:21.061610 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:14:21.061612 18636 net.cpp:2270] res2a_branch2a_param_0(0.736) 
I0802 09:14:21.061614 18636 net.cpp:2270] res2a_branch2b_param_0(0.688) 
I0802 09:14:21.061616 18636 net.cpp:2270] res3a_branch2a_param_0(0.747) 
I0802 09:14:21.061619 18636 net.cpp:2270] res3a_branch2b_param_0(0.724) 
I0802 09:14:21.061622 18636 net.cpp:2270] res4a_branch2a_param_0(0.749) 
I0802 09:14:21.061625 18636 net.cpp:2270] res4a_branch2b_param_0(0.742) 
I0802 09:14:21.061626 18636 net.cpp:2270] res5a_branch2a_param_0(0.75) 
I0802 09:14:21.061628 18636 net.cpp:2270] res5a_branch2b_param_0(0.749) 
I0802 09:14:21.061630 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.76048e+06/2.86678e+06) 0.614
I0802 09:14:21.191269 18661 solver.cpp:450] Finding and applying sparsity: 0.76
I0802 09:15:14.861099 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:15:14.863003 18636 solver.cpp:353] Iteration 95000 (1.47791 iter/s, 67.6633s/100 iter), loss = 1.64177
I0802 09:15:14.863021 18636 solver.cpp:375]     Train net output #0: loss = 1.72137 (* 1 = 1.72137 loss)
I0802 09:15:14.863028 18636 sgd_solver.cpp:136] Iteration 95000, lr = 0.0040625, m = 0.9
I0802 09:15:29.136780 18636 solver.cpp:353] Iteration 95100 (7.00605 iter/s, 14.2734s/100 iter), loss = 1.32893
I0802 09:15:29.136808 18636 solver.cpp:375]     Train net output #0: loss = 1.43546 (* 1 = 1.43546 loss)
I0802 09:15:29.136823 18636 sgd_solver.cpp:136] Iteration 95100, lr = 0.00405625, m = 0.9
I0802 09:15:43.090350 18636 solver.cpp:353] Iteration 95200 (7.16683 iter/s, 13.9532s/100 iter), loss = 1.36915
I0802 09:15:43.090379 18636 solver.cpp:375]     Train net output #0: loss = 1.48339 (* 1 = 1.48339 loss)
I0802 09:15:43.090384 18636 sgd_solver.cpp:136] Iteration 95200, lr = 0.00405, m = 0.9
I0802 09:15:56.992043 18636 solver.cpp:353] Iteration 95300 (7.19357 iter/s, 13.9013s/100 iter), loss = 1.06387
I0802 09:15:56.992121 18636 solver.cpp:375]     Train net output #0: loss = 1.38316 (* 1 = 1.38316 loss)
I0802 09:15:56.992128 18636 sgd_solver.cpp:136] Iteration 95300, lr = 0.00404375, m = 0.9
I0802 09:16:10.931789 18636 solver.cpp:353] Iteration 95400 (7.17393 iter/s, 13.9394s/100 iter), loss = 1.78959
I0802 09:16:10.931818 18636 solver.cpp:375]     Train net output #0: loss = 1.78789 (* 1 = 1.78789 loss)
I0802 09:16:10.931824 18636 sgd_solver.cpp:136] Iteration 95400, lr = 0.0040375, m = 0.9
I0802 09:16:24.846587 18636 solver.cpp:353] Iteration 95500 (7.1868 iter/s, 13.9144s/100 iter), loss = 1.75896
I0802 09:16:24.846614 18636 solver.cpp:375]     Train net output #0: loss = 1.44924 (* 1 = 1.44924 loss)
I0802 09:16:24.846618 18636 sgd_solver.cpp:136] Iteration 95500, lr = 0.00403125, m = 0.9
I0802 09:16:38.869429 18636 solver.cpp:353] Iteration 95600 (7.13142 iter/s, 14.0224s/100 iter), loss = 1.18899
I0802 09:16:38.869488 18636 solver.cpp:375]     Train net output #0: loss = 1.21697 (* 1 = 1.21697 loss)
I0802 09:16:38.869529 18636 sgd_solver.cpp:136] Iteration 95600, lr = 0.004025, m = 0.9
I0802 09:16:52.790230 18636 solver.cpp:353] Iteration 95700 (7.1837 iter/s, 13.9204s/100 iter), loss = 1.87014
I0802 09:16:52.790256 18636 solver.cpp:375]     Train net output #0: loss = 1.6599 (* 1 = 1.6599 loss)
I0802 09:16:52.790261 18636 sgd_solver.cpp:136] Iteration 95700, lr = 0.00401875, m = 0.9
I0802 09:17:06.760025 18636 solver.cpp:353] Iteration 95800 (7.1585 iter/s, 13.9694s/100 iter), loss = 1.4117
I0802 09:17:06.760082 18636 solver.cpp:375]     Train net output #0: loss = 1.38653 (* 1 = 1.38653 loss)
I0802 09:17:06.760094 18636 sgd_solver.cpp:136] Iteration 95800, lr = 0.0040125, m = 0.9
I0802 09:17:20.712826 18636 solver.cpp:353] Iteration 95900 (7.16722 iter/s, 13.9524s/100 iter), loss = 1.46208
I0802 09:17:20.712888 18636 solver.cpp:375]     Train net output #0: loss = 1.57686 (* 1 = 1.57686 loss)
I0802 09:17:20.712895 18636 sgd_solver.cpp:136] Iteration 95900, lr = 0.00400625, m = 0.9
I0802 09:17:34.525063 18636 solver.cpp:404] Sparsity after update:
I0802 09:17:34.528950 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:17:34.528959 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:17:34.528969 18636 net.cpp:2270] conv1b_param_0(0.71) 
I0802 09:17:34.528972 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:17:34.528977 18636 net.cpp:2270] res2a_branch2a_param_0(0.745) 
I0802 09:17:34.528981 18636 net.cpp:2270] res2a_branch2b_param_0(0.692) 
I0802 09:17:34.528985 18636 net.cpp:2270] res3a_branch2a_param_0(0.757) 
I0802 09:17:34.528987 18636 net.cpp:2270] res3a_branch2b_param_0(0.731) 
I0802 09:17:34.528990 18636 net.cpp:2270] res4a_branch2a_param_0(0.759) 
I0802 09:17:34.528993 18636 net.cpp:2270] res4a_branch2b_param_0(0.75) 
I0802 09:17:34.528996 18636 net.cpp:2270] res5a_branch2a_param_0(0.76) 
I0802 09:17:34.529000 18636 net.cpp:2270] res5a_branch2b_param_0(0.76) 
I0802 09:17:34.529003 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.78432e+06/2.86678e+06) 0.622
I0802 09:17:34.529014 18636 solver.cpp:550] Iteration 96000, Testing net (#0)
I0802 09:17:54.608105 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.577706
I0802 09:17:54.608209 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809645
I0802 09:17:54.608220 18636 solver.cpp:635]     Test net output #2: loss = 1.85062 (* 1 = 1.85062 loss)
I0802 09:17:54.608244 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0787s
I0802 09:17:54.765228 18661 solver.cpp:450] Finding and applying sparsity: 0.77
I0802 09:18:49.853689 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:18:49.855682 18636 solver.cpp:353] Iteration 96000 (1.12183 iter/s, 89.1404s/100 iter), loss = 1.76848
I0802 09:18:49.855702 18636 solver.cpp:375]     Train net output #0: loss = 1.84809 (* 1 = 1.84809 loss)
I0802 09:18:49.855708 18636 sgd_solver.cpp:136] Iteration 96000, lr = 0.004, m = 0.9
I0802 09:19:04.137110 18636 solver.cpp:353] Iteration 96100 (7.0023 iter/s, 14.281s/100 iter), loss = 1.52795
I0802 09:19:04.137140 18636 solver.cpp:375]     Train net output #0: loss = 1.6318 (* 1 = 1.6318 loss)
I0802 09:19:04.137147 18636 sgd_solver.cpp:136] Iteration 96100, lr = 0.00399375, m = 0.9
I0802 09:19:18.048338 18636 solver.cpp:353] Iteration 96200 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.60839
I0802 09:19:18.048363 18636 solver.cpp:375]     Train net output #0: loss = 1.33641 (* 1 = 1.33641 loss)
I0802 09:19:18.048368 18636 sgd_solver.cpp:136] Iteration 96200, lr = 0.0039875, m = 0.9
I0802 09:19:31.997923 18636 solver.cpp:353] Iteration 96300 (7.16888 iter/s, 13.9492s/100 iter), loss = 1.42451
I0802 09:19:31.998003 18636 solver.cpp:375]     Train net output #0: loss = 1.40979 (* 1 = 1.40979 loss)
I0802 09:19:31.998009 18636 sgd_solver.cpp:136] Iteration 96300, lr = 0.00398125, m = 0.9
I0802 09:19:45.935307 18636 solver.cpp:353] Iteration 96400 (7.17515 iter/s, 13.937s/100 iter), loss = 1.31048
I0802 09:19:45.935331 18636 solver.cpp:375]     Train net output #0: loss = 1.22957 (* 1 = 1.22957 loss)
I0802 09:19:45.935335 18636 sgd_solver.cpp:136] Iteration 96400, lr = 0.003975, m = 0.9
I0802 09:19:59.882690 18636 solver.cpp:353] Iteration 96500 (7.17 iter/s, 13.947s/100 iter), loss = 1.40212
I0802 09:19:59.882715 18636 solver.cpp:375]     Train net output #0: loss = 1.5218 (* 1 = 1.5218 loss)
I0802 09:19:59.882720 18636 sgd_solver.cpp:136] Iteration 96500, lr = 0.00396875, m = 0.9
I0802 09:20:13.837250 18636 solver.cpp:353] Iteration 96600 (7.16632 iter/s, 13.9542s/100 iter), loss = 1.13521
I0802 09:20:13.837311 18636 solver.cpp:375]     Train net output #0: loss = 1.15758 (* 1 = 1.15758 loss)
I0802 09:20:13.837316 18636 sgd_solver.cpp:136] Iteration 96600, lr = 0.0039625, m = 0.9
I0802 09:20:27.787292 18636 solver.cpp:353] Iteration 96700 (7.16864 iter/s, 13.9496s/100 iter), loss = 1.39145
I0802 09:20:27.787328 18636 solver.cpp:375]     Train net output #0: loss = 1.34268 (* 1 = 1.34268 loss)
I0802 09:20:27.787333 18636 sgd_solver.cpp:136] Iteration 96700, lr = 0.00395625, m = 0.9
I0802 09:20:41.676031 18636 solver.cpp:353] Iteration 96800 (7.20028 iter/s, 13.8884s/100 iter), loss = 1.38418
I0802 09:20:41.676059 18636 solver.cpp:375]     Train net output #0: loss = 0.992555 (* 1 = 0.992555 loss)
I0802 09:20:41.676064 18636 sgd_solver.cpp:136] Iteration 96800, lr = 0.00395, m = 0.9
I0802 09:20:55.673876 18636 solver.cpp:353] Iteration 96900 (7.14416 iter/s, 13.9975s/100 iter), loss = 1.10794
I0802 09:20:55.673960 18636 solver.cpp:375]     Train net output #0: loss = 1.00191 (* 1 = 1.00191 loss)
I0802 09:20:55.673966 18636 sgd_solver.cpp:136] Iteration 96900, lr = 0.00394375, m = 0.9
I0802 09:21:09.507333 18636 solver.cpp:404] Sparsity after update:
I0802 09:21:09.521702 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:21:09.521716 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:21:09.521725 18636 net.cpp:2270] conv1b_param_0(0.716) 
I0802 09:21:09.521728 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:21:09.521733 18636 net.cpp:2270] res2a_branch2a_param_0(0.753) 
I0802 09:21:09.521735 18636 net.cpp:2270] res2a_branch2b_param_0(0.695) 
I0802 09:21:09.521739 18636 net.cpp:2270] res3a_branch2a_param_0(0.766) 
I0802 09:21:09.521741 18636 net.cpp:2270] res3a_branch2b_param_0(0.736) 
I0802 09:21:09.521745 18636 net.cpp:2270] res4a_branch2a_param_0(0.769) 
I0802 09:21:09.521749 18636 net.cpp:2270] res4a_branch2b_param_0(0.758) 
I0802 09:21:09.521751 18636 net.cpp:2270] res5a_branch2a_param_0(0.77) 
I0802 09:21:09.521754 18636 net.cpp:2270] res5a_branch2b_param_0(0.77) 
I0802 09:21:09.521764 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.80755e+06/2.86678e+06) 0.631
I0802 09:21:09.650537 18661 solver.cpp:450] Finding and applying sparsity: 0.78
I0802 09:22:05.689914 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:22:05.691857 18636 solver.cpp:353] Iteration 97000 (1.42824 iter/s, 70.016s/100 iter), loss = 1.69221
I0802 09:22:05.691879 18636 solver.cpp:375]     Train net output #0: loss = 1.64771 (* 1 = 1.64771 loss)
I0802 09:22:05.691889 18636 sgd_solver.cpp:136] Iteration 97000, lr = 0.0039375, m = 0.9
I0802 09:22:19.876739 18636 solver.cpp:353] Iteration 97100 (7.04996 iter/s, 14.1845s/100 iter), loss = 1.68533
I0802 09:22:19.876762 18636 solver.cpp:375]     Train net output #0: loss = 1.47322 (* 1 = 1.47322 loss)
I0802 09:22:19.876767 18636 sgd_solver.cpp:136] Iteration 97100, lr = 0.00393125, m = 0.9
I0802 09:22:33.759124 18636 solver.cpp:353] Iteration 97200 (7.20358 iter/s, 13.882s/100 iter), loss = 1.3261
I0802 09:22:33.759153 18636 solver.cpp:375]     Train net output #0: loss = 1.27275 (* 1 = 1.27275 loss)
I0802 09:22:33.759160 18636 sgd_solver.cpp:136] Iteration 97200, lr = 0.003925, m = 0.9
I0802 09:22:47.589381 18636 solver.cpp:353] Iteration 97300 (7.23073 iter/s, 13.8299s/100 iter), loss = 1.43066
I0802 09:22:47.589447 18636 solver.cpp:375]     Train net output #0: loss = 1.26803 (* 1 = 1.26803 loss)
I0802 09:22:47.589454 18636 sgd_solver.cpp:136] Iteration 97300, lr = 0.00391875, m = 0.9
I0802 09:23:01.417098 18636 solver.cpp:353] Iteration 97400 (7.23206 iter/s, 13.8273s/100 iter), loss = 1.54721
I0802 09:23:01.417124 18636 solver.cpp:375]     Train net output #0: loss = 1.04439 (* 1 = 1.04439 loss)
I0802 09:23:01.417130 18636 sgd_solver.cpp:136] Iteration 97400, lr = 0.0039125, m = 0.9
I0802 09:23:15.328413 18636 solver.cpp:353] Iteration 97500 (7.1886 iter/s, 13.9109s/100 iter), loss = 1.21448
I0802 09:23:15.328446 18636 solver.cpp:375]     Train net output #0: loss = 1.1555 (* 1 = 1.1555 loss)
I0802 09:23:15.328454 18636 sgd_solver.cpp:136] Iteration 97500, lr = 0.00390625, m = 0.9
I0802 09:23:29.193457 18636 solver.cpp:353] Iteration 97600 (7.21258 iter/s, 13.8647s/100 iter), loss = 1.06108
I0802 09:23:29.193518 18636 solver.cpp:375]     Train net output #0: loss = 1.16389 (* 1 = 1.16389 loss)
I0802 09:23:29.193526 18636 sgd_solver.cpp:136] Iteration 97600, lr = 0.0039, m = 0.9
I0802 09:23:43.021287 18636 solver.cpp:353] Iteration 97700 (7.232 iter/s, 13.8274s/100 iter), loss = 1.73912
I0802 09:23:43.021327 18636 solver.cpp:375]     Train net output #0: loss = 1.58647 (* 1 = 1.58647 loss)
I0802 09:23:43.021332 18636 sgd_solver.cpp:136] Iteration 97700, lr = 0.00389375, m = 0.9
I0802 09:23:56.844413 18636 solver.cpp:353] Iteration 97800 (7.23445 iter/s, 13.8227s/100 iter), loss = 1.43812
I0802 09:23:56.844441 18636 solver.cpp:375]     Train net output #0: loss = 0.827959 (* 1 = 0.827959 loss)
I0802 09:23:56.844447 18636 sgd_solver.cpp:136] Iteration 97800, lr = 0.0038875, m = 0.9
I0802 09:24:10.655431 18636 solver.cpp:353] Iteration 97900 (7.2408 iter/s, 13.8106s/100 iter), loss = 1.45125
I0802 09:24:10.655494 18636 solver.cpp:375]     Train net output #0: loss = 1.57395 (* 1 = 1.57395 loss)
I0802 09:24:10.655501 18636 sgd_solver.cpp:136] Iteration 97900, lr = 0.00388125, m = 0.9
I0802 09:24:24.431077 18636 solver.cpp:404] Sparsity after update:
I0802 09:24:24.435014 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:24:24.435025 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:24:24.435034 18636 net.cpp:2270] conv1b_param_0(0.72) 
I0802 09:24:24.435037 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:24:24.435046 18636 net.cpp:2270] res2a_branch2a_param_0(0.762) 
I0802 09:24:24.435051 18636 net.cpp:2270] res2a_branch2b_param_0(0.7) 
I0802 09:24:24.435057 18636 net.cpp:2270] res3a_branch2a_param_0(0.775) 
I0802 09:24:24.435060 18636 net.cpp:2270] res3a_branch2b_param_0(0.742) 
I0802 09:24:24.435063 18636 net.cpp:2270] res4a_branch2a_param_0(0.779) 
I0802 09:24:24.435067 18636 net.cpp:2270] res4a_branch2b_param_0(0.765) 
I0802 09:24:24.435070 18636 net.cpp:2270] res5a_branch2a_param_0(0.78) 
I0802 09:24:24.435075 18636 net.cpp:2270] res5a_branch2b_param_0(0.779) 
I0802 09:24:24.435078 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.82989e+06/2.86678e+06) 0.638
I0802 09:24:24.435089 18636 solver.cpp:550] Iteration 98000, Testing net (#0)
I0802 09:24:43.385797 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578294
I0802 09:24:43.385861 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810174
I0802 09:24:43.385869 18636 solver.cpp:635]     Test net output #2: loss = 1.8377 (* 1 = 1.8377 loss)
I0802 09:24:43.385888 18636 solver.cpp:305] [MultiGPU] Tests completed in 18.9503s
I0802 09:24:43.527159 18661 solver.cpp:450] Finding and applying sparsity: 0.79
I0802 09:25:40.339295 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:25:40.341307 18636 solver.cpp:353] Iteration 98000 (1.11503 iter/s, 89.6834s/100 iter), loss = 1.50464
I0802 09:25:40.341327 18636 solver.cpp:375]     Train net output #0: loss = 1.48014 (* 1 = 1.48014 loss)
I0802 09:25:40.341336 18636 sgd_solver.cpp:136] Iteration 98000, lr = 0.003875, m = 0.9
I0802 09:25:54.496304 18636 solver.cpp:353] Iteration 98100 (7.06484 iter/s, 14.1546s/100 iter), loss = 1.32414
I0802 09:25:54.496328 18636 solver.cpp:375]     Train net output #0: loss = 1.29798 (* 1 = 1.29798 loss)
I0802 09:25:54.496333 18636 sgd_solver.cpp:136] Iteration 98100, lr = 0.00386875, m = 0.9
I0802 09:26:08.438084 18636 solver.cpp:353] Iteration 98200 (7.17289 iter/s, 13.9414s/100 iter), loss = 1.52907
I0802 09:26:08.438112 18636 solver.cpp:375]     Train net output #0: loss = 1.53238 (* 1 = 1.53238 loss)
I0802 09:26:08.438117 18636 sgd_solver.cpp:136] Iteration 98200, lr = 0.0038625, m = 0.9
I0802 09:26:22.286980 18636 solver.cpp:353] Iteration 98300 (7.22099 iter/s, 13.8485s/100 iter), loss = 1.72646
I0802 09:26:22.287063 18636 solver.cpp:375]     Train net output #0: loss = 1.41555 (* 1 = 1.41555 loss)
I0802 09:26:22.287070 18636 sgd_solver.cpp:136] Iteration 98300, lr = 0.00385625, m = 0.9
I0802 09:26:36.221694 18636 solver.cpp:353] Iteration 98400 (7.17653 iter/s, 13.9343s/100 iter), loss = 1.59057
I0802 09:26:36.221760 18636 solver.cpp:375]     Train net output #0: loss = 1.34421 (* 1 = 1.34421 loss)
I0802 09:26:36.221773 18636 sgd_solver.cpp:136] Iteration 98400, lr = 0.00385, m = 0.9
I0802 09:26:50.211385 18636 solver.cpp:353] Iteration 98500 (7.14832 iter/s, 13.9893s/100 iter), loss = 1.74565
I0802 09:26:50.211422 18636 solver.cpp:375]     Train net output #0: loss = 1.20495 (* 1 = 1.20495 loss)
I0802 09:26:50.211427 18636 sgd_solver.cpp:136] Iteration 98500, lr = 0.00384375, m = 0.9
I0802 09:27:04.151973 18636 solver.cpp:353] Iteration 98600 (7.1735 iter/s, 13.9402s/100 iter), loss = 1.72803
I0802 09:27:04.152039 18636 solver.cpp:375]     Train net output #0: loss = 1.50731 (* 1 = 1.50731 loss)
I0802 09:27:04.152045 18636 sgd_solver.cpp:136] Iteration 98600, lr = 0.0038375, m = 0.9
I0802 09:27:18.097182 18636 solver.cpp:353] Iteration 98700 (7.17112 iter/s, 13.9448s/100 iter), loss = 1.30107
I0802 09:27:18.097208 18636 solver.cpp:375]     Train net output #0: loss = 1.00097 (* 1 = 1.00097 loss)
I0802 09:27:18.097213 18636 sgd_solver.cpp:136] Iteration 98700, lr = 0.00383125, m = 0.9
I0802 09:27:32.035022 18636 solver.cpp:353] Iteration 98800 (7.17491 iter/s, 13.9375s/100 iter), loss = 1.48978
I0802 09:27:32.035049 18636 solver.cpp:375]     Train net output #0: loss = 1.77942 (* 1 = 1.77942 loss)
I0802 09:27:32.035055 18636 sgd_solver.cpp:136] Iteration 98800, lr = 0.003825, m = 0.9
I0802 09:27:46.041523 18636 solver.cpp:353] Iteration 98900 (7.13974 iter/s, 14.0061s/100 iter), loss = 1.532
I0802 09:27:46.041584 18636 solver.cpp:375]     Train net output #0: loss = 1.48488 (* 1 = 1.48488 loss)
I0802 09:27:46.041589 18636 sgd_solver.cpp:136] Iteration 98900, lr = 0.00381875, m = 0.9
I0802 09:27:59.862835 18636 solver.cpp:404] Sparsity after update:
I0802 09:27:59.873970 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:27:59.873981 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:27:59.873988 18636 net.cpp:2270] conv1b_param_0(0.723) 
I0802 09:27:59.873991 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:27:59.873992 18636 net.cpp:2270] res2a_branch2a_param_0(0.771) 
I0802 09:27:59.873994 18636 net.cpp:2270] res2a_branch2b_param_0(0.702) 
I0802 09:27:59.873996 18636 net.cpp:2270] res3a_branch2a_param_0(0.784) 
I0802 09:27:59.873997 18636 net.cpp:2270] res3a_branch2b_param_0(0.747) 
I0802 09:27:59.873999 18636 net.cpp:2270] res4a_branch2a_param_0(0.789) 
I0802 09:27:59.874001 18636 net.cpp:2270] res4a_branch2b_param_0(0.772) 
I0802 09:27:59.874003 18636 net.cpp:2270] res5a_branch2a_param_0(0.79) 
I0802 09:27:59.874006 18636 net.cpp:2270] res5a_branch2b_param_0(0.79) 
I0802 09:27:59.874007 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.85274e+06/2.86678e+06) 0.646
I0802 09:28:00.003440 18661 solver.cpp:450] Finding and applying sparsity: 0.8
I0802 09:28:59.111878 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:28:59.113847 18636 solver.cpp:353] Iteration 99000 (1.36855 iter/s, 73.0703s/100 iter), loss = 1.72222
I0802 09:28:59.113867 18636 solver.cpp:375]     Train net output #0: loss = 2.05928 (* 1 = 2.05928 loss)
I0802 09:28:59.113875 18636 sgd_solver.cpp:136] Iteration 99000, lr = 0.0038125, m = 0.9
I0802 09:29:13.270308 18636 solver.cpp:353] Iteration 99100 (7.06411 iter/s, 14.1561s/100 iter), loss = 1.59446
I0802 09:29:13.270337 18636 solver.cpp:375]     Train net output #0: loss = 1.55107 (* 1 = 1.55107 loss)
I0802 09:29:13.270344 18636 sgd_solver.cpp:136] Iteration 99100, lr = 0.00380625, m = 0.9
I0802 09:29:27.231827 18636 solver.cpp:353] Iteration 99200 (7.16275 iter/s, 13.9611s/100 iter), loss = 1.69119
I0802 09:29:27.231854 18636 solver.cpp:375]     Train net output #0: loss = 1.76497 (* 1 = 1.76497 loss)
I0802 09:29:27.231858 18636 sgd_solver.cpp:136] Iteration 99200, lr = 0.0038, m = 0.9
I0802 09:29:41.164608 18636 solver.cpp:353] Iteration 99300 (7.17752 iter/s, 13.9324s/100 iter), loss = 1.57669
I0802 09:29:41.164666 18636 solver.cpp:375]     Train net output #0: loss = 1.45035 (* 1 = 1.45035 loss)
I0802 09:29:41.164671 18636 sgd_solver.cpp:136] Iteration 99300, lr = 0.00379375, m = 0.9
I0802 09:29:55.059517 18636 solver.cpp:353] Iteration 99400 (7.19708 iter/s, 13.8945s/100 iter), loss = 1.55947
I0802 09:29:55.059545 18636 solver.cpp:375]     Train net output #0: loss = 1.51574 (* 1 = 1.51574 loss)
I0802 09:29:55.059551 18636 sgd_solver.cpp:136] Iteration 99400, lr = 0.0037875, m = 0.9
I0802 09:30:09.069967 18636 solver.cpp:353] Iteration 99500 (7.13773 iter/s, 14.0101s/100 iter), loss = 1.78114
I0802 09:30:09.069994 18636 solver.cpp:375]     Train net output #0: loss = 1.67765 (* 1 = 1.67765 loss)
I0802 09:30:09.070000 18636 sgd_solver.cpp:136] Iteration 99500, lr = 0.00378125, m = 0.9
I0802 09:30:23.156080 18636 solver.cpp:353] Iteration 99600 (7.09939 iter/s, 14.0857s/100 iter), loss = 1.24045
I0802 09:30:23.156227 18636 solver.cpp:375]     Train net output #0: loss = 1.08646 (* 1 = 1.08646 loss)
I0802 09:30:23.156252 18636 sgd_solver.cpp:136] Iteration 99600, lr = 0.003775, m = 0.9
I0802 09:30:37.098304 18636 solver.cpp:353] Iteration 99700 (7.17266 iter/s, 13.9418s/100 iter), loss = 1.54153
I0802 09:30:37.098332 18636 solver.cpp:375]     Train net output #0: loss = 1.73266 (* 1 = 1.73266 loss)
I0802 09:30:37.098337 18636 sgd_solver.cpp:136] Iteration 99700, lr = 0.00376875, m = 0.9
I0802 09:30:50.983302 18636 solver.cpp:353] Iteration 99800 (7.20222 iter/s, 13.8846s/100 iter), loss = 1.53903
I0802 09:30:50.983326 18636 solver.cpp:375]     Train net output #0: loss = 1.16461 (* 1 = 1.16461 loss)
I0802 09:30:50.983330 18636 sgd_solver.cpp:136] Iteration 99800, lr = 0.0037625, m = 0.9
I0802 09:31:04.876701 18636 solver.cpp:353] Iteration 99900 (7.19786 iter/s, 13.893s/100 iter), loss = 1.44928
I0802 09:31:04.876762 18636 solver.cpp:375]     Train net output #0: loss = 1.25062 (* 1 = 1.25062 loss)
I0802 09:31:04.876768 18636 sgd_solver.cpp:136] Iteration 99900, lr = 0.00375625, m = 0.9
I0802 09:31:18.618074 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_100000.caffemodel
I0802 09:31:18.678428 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_100000.solverstate
I0802 09:31:18.683329 18636 solver.cpp:404] Sparsity after update:
I0802 09:31:18.688526 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:31:18.688563 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:31:18.688585 18636 net.cpp:2270] conv1b_param_0(0.727) 
I0802 09:31:18.688599 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:31:18.688613 18636 net.cpp:2270] res2a_branch2a_param_0(0.779) 
I0802 09:31:18.688627 18636 net.cpp:2270] res2a_branch2b_param_0(0.706) 
I0802 09:31:18.688639 18636 net.cpp:2270] res3a_branch2a_param_0(0.791) 
I0802 09:31:18.688652 18636 net.cpp:2270] res3a_branch2b_param_0(0.752) 
I0802 09:31:18.688664 18636 net.cpp:2270] res4a_branch2a_param_0(0.798) 
I0802 09:31:18.688676 18636 net.cpp:2270] res4a_branch2b_param_0(0.777) 
I0802 09:31:18.688689 18636 net.cpp:2270] res5a_branch2a_param_0(0.8) 
I0802 09:31:18.688704 18636 net.cpp:2270] res5a_branch2b_param_0(0.799) 
I0802 09:31:18.688715 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.87442e+06/2.86678e+06) 0.654
I0802 09:31:18.688737 18636 solver.cpp:550] Iteration 100000, Testing net (#0)
I0802 09:31:24.579694 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:31:37.392954 18619 data_reader.cpp:264] Starting prefetch of epoch 6
I0802 09:31:38.346082 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.579588
I0802 09:31:38.346107 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811703
I0802 09:31:38.346112 18636 solver.cpp:635]     Test net output #2: loss = 1.84294 (* 1 = 1.84294 loss)
I0802 09:31:38.346132 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6568s
I0802 09:31:38.484393 18661 solver.cpp:450] Finding and applying sparsity: 0.81
I0802 09:32:38.909106 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:32:38.911051 18636 solver.cpp:353] Iteration 100000 (1.06347 iter/s, 94.0317s/100 iter), loss = 1.05636
I0802 09:32:38.911069 18636 solver.cpp:375]     Train net output #0: loss = 1.12629 (* 1 = 1.12629 loss)
I0802 09:32:38.911077 18636 sgd_solver.cpp:136] Iteration 100000, lr = 0.00375, m = 0.9
I0802 09:32:53.009567 18636 solver.cpp:353] Iteration 100100 (7.09315 iter/s, 14.0981s/100 iter), loss = 1.75593
I0802 09:32:53.009589 18636 solver.cpp:375]     Train net output #0: loss = 1.83332 (* 1 = 1.83332 loss)
I0802 09:32:53.009595 18636 sgd_solver.cpp:136] Iteration 100100, lr = 0.00374375, m = 0.9
I0802 09:33:06.950006 18636 solver.cpp:353] Iteration 100200 (7.17358 iter/s, 13.94s/100 iter), loss = 1.65658
I0802 09:33:06.950031 18636 solver.cpp:375]     Train net output #0: loss = 1.89256 (* 1 = 1.89256 loss)
I0802 09:33:06.950034 18636 sgd_solver.cpp:136] Iteration 100200, lr = 0.0037375, m = 0.9
I0802 09:33:20.789495 18636 solver.cpp:353] Iteration 100300 (7.2259 iter/s, 13.8391s/100 iter), loss = 1.13369
I0802 09:33:20.789793 18636 solver.cpp:375]     Train net output #0: loss = 1.01064 (* 1 = 1.01064 loss)
I0802 09:33:20.789916 18636 sgd_solver.cpp:136] Iteration 100300, lr = 0.00373125, m = 0.9
I0802 09:33:34.686321 18636 solver.cpp:353] Iteration 100400 (7.19609 iter/s, 13.8964s/100 iter), loss = 1.83013
I0802 09:33:34.686379 18636 solver.cpp:375]     Train net output #0: loss = 1.87397 (* 1 = 1.87397 loss)
I0802 09:33:34.686403 18636 sgd_solver.cpp:136] Iteration 100400, lr = 0.003725, m = 0.9
I0802 09:33:48.620753 18636 solver.cpp:353] Iteration 100500 (7.17667 iter/s, 13.934s/100 iter), loss = 1.45339
I0802 09:33:48.620836 18636 solver.cpp:375]     Train net output #0: loss = 1.6827 (* 1 = 1.6827 loss)
I0802 09:33:48.620860 18636 sgd_solver.cpp:136] Iteration 100500, lr = 0.00371875, m = 0.9
I0802 09:34:02.628841 18636 solver.cpp:353] Iteration 100600 (7.13893 iter/s, 14.0077s/100 iter), loss = 1.73787
I0802 09:34:02.628929 18636 solver.cpp:375]     Train net output #0: loss = 1.90965 (* 1 = 1.90965 loss)
I0802 09:34:02.628937 18636 sgd_solver.cpp:136] Iteration 100600, lr = 0.0037125, m = 0.9
I0802 09:34:16.565910 18636 solver.cpp:353] Iteration 100700 (7.17531 iter/s, 13.9367s/100 iter), loss = 1.50043
I0802 09:34:16.565939 18636 solver.cpp:375]     Train net output #0: loss = 2.01057 (* 1 = 2.01057 loss)
I0802 09:34:16.565945 18636 sgd_solver.cpp:136] Iteration 100700, lr = 0.00370625, m = 0.9
I0802 09:34:30.497944 18636 solver.cpp:353] Iteration 100800 (7.1779 iter/s, 13.9316s/100 iter), loss = 1.13327
I0802 09:34:30.497969 18636 solver.cpp:375]     Train net output #0: loss = 1.17901 (* 1 = 1.17901 loss)
I0802 09:34:30.497974 18636 sgd_solver.cpp:136] Iteration 100800, lr = 0.0037, m = 0.9
I0802 09:34:44.420953 18636 solver.cpp:353] Iteration 100900 (7.18256 iter/s, 13.9226s/100 iter), loss = 1.28511
I0802 09:34:44.421010 18636 solver.cpp:375]     Train net output #0: loss = 1.42288 (* 1 = 1.42288 loss)
I0802 09:34:44.421015 18636 sgd_solver.cpp:136] Iteration 100900, lr = 0.00369375, m = 0.9
I0802 09:34:58.268474 18636 solver.cpp:404] Sparsity after update:
I0802 09:34:58.280022 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:34:58.280038 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:34:58.280048 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:34:58.280051 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:34:58.280055 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:34:58.280058 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:34:58.280061 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:34:58.280066 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:34:58.280068 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:34:58.280071 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:34:58.280076 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:34:58.280078 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:34:58.280087 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:34:58.409523 18636 solver.cpp:353] Iteration 101000 (7.14889 iter/s, 13.9882s/100 iter), loss = 2.10897
I0802 09:34:58.409546 18636 solver.cpp:375]     Train net output #0: loss = 2.07723 (* 1 = 2.07723 loss)
I0802 09:34:58.409551 18636 sgd_solver.cpp:136] Iteration 101000, lr = 0.0036875, m = 0.9
I0802 09:35:12.315387 18636 solver.cpp:353] Iteration 101100 (7.19141 iter/s, 13.9055s/100 iter), loss = 1.62913
I0802 09:35:12.315412 18636 solver.cpp:375]     Train net output #0: loss = 1.44452 (* 1 = 1.44452 loss)
I0802 09:35:12.315418 18636 sgd_solver.cpp:136] Iteration 101100, lr = 0.00368125, m = 0.9
I0802 09:35:26.254663 18636 solver.cpp:353] Iteration 101200 (7.17417 iter/s, 13.9389s/100 iter), loss = 1.15224
I0802 09:35:26.254720 18636 solver.cpp:375]     Train net output #0: loss = 1.23748 (* 1 = 1.23748 loss)
I0802 09:35:26.254725 18636 sgd_solver.cpp:136] Iteration 101200, lr = 0.003675, m = 0.9
I0802 09:35:40.176602 18636 solver.cpp:353] Iteration 101300 (7.18311 iter/s, 13.9216s/100 iter), loss = 1.39322
I0802 09:35:40.176626 18636 solver.cpp:375]     Train net output #0: loss = 1.49874 (* 1 = 1.49874 loss)
I0802 09:35:40.176630 18636 sgd_solver.cpp:136] Iteration 101300, lr = 0.00366875, m = 0.9
I0802 09:35:54.035303 18636 solver.cpp:353] Iteration 101400 (7.21588 iter/s, 13.8583s/100 iter), loss = 1.09496
I0802 09:35:54.035331 18636 solver.cpp:375]     Train net output #0: loss = 1.10446 (* 1 = 1.10446 loss)
I0802 09:35:54.035337 18636 sgd_solver.cpp:136] Iteration 101400, lr = 0.0036625, m = 0.9
I0802 09:36:07.987918 18636 solver.cpp:353] Iteration 101500 (7.16731 iter/s, 13.9522s/100 iter), loss = 1.53272
I0802 09:36:07.987990 18636 solver.cpp:375]     Train net output #0: loss = 1.6388 (* 1 = 1.6388 loss)
I0802 09:36:07.987998 18636 sgd_solver.cpp:136] Iteration 101500, lr = 0.00365625, m = 0.9
I0802 09:36:21.901752 18636 solver.cpp:353] Iteration 101600 (7.18729 iter/s, 13.9134s/100 iter), loss = 1.34612
I0802 09:36:21.901777 18636 solver.cpp:375]     Train net output #0: loss = 1.52886 (* 1 = 1.52886 loss)
I0802 09:36:21.901783 18636 sgd_solver.cpp:136] Iteration 101600, lr = 0.00365, m = 0.9
I0802 09:36:35.772459 18636 solver.cpp:353] Iteration 101700 (7.20964 iter/s, 13.8703s/100 iter), loss = 1.34812
I0802 09:36:35.772486 18636 solver.cpp:375]     Train net output #0: loss = 0.76577 (* 1 = 0.76577 loss)
I0802 09:36:35.772491 18636 sgd_solver.cpp:136] Iteration 101700, lr = 0.00364375, m = 0.9
I0802 09:36:49.666208 18636 solver.cpp:353] Iteration 101800 (7.19768 iter/s, 13.8934s/100 iter), loss = 1.49958
I0802 09:36:49.666314 18636 solver.cpp:375]     Train net output #0: loss = 1.85362 (* 1 = 1.85362 loss)
I0802 09:36:49.666321 18636 sgd_solver.cpp:136] Iteration 101800, lr = 0.0036375, m = 0.9
I0802 09:37:03.500195 18636 solver.cpp:353] Iteration 101900 (7.22877 iter/s, 13.8336s/100 iter), loss = 1.52082
I0802 09:37:03.500223 18636 solver.cpp:375]     Train net output #0: loss = 1.75047 (* 1 = 1.75047 loss)
I0802 09:37:03.500229 18636 sgd_solver.cpp:136] Iteration 101900, lr = 0.00363125, m = 0.9
I0802 09:37:17.341089 18636 solver.cpp:404] Sparsity after update:
I0802 09:37:17.345057 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:37:17.345083 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:37:17.345100 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:37:17.345109 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:37:17.345119 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:37:17.345129 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:37:17.345137 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:37:17.345145 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:37:17.345155 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:37:17.345163 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:37:17.345172 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:37:17.345180 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:37:17.345190 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:37:17.345206 18636 solver.cpp:550] Iteration 102000, Testing net (#0)
I0802 09:37:37.025959 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574176
I0802 09:37:37.026068 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805703
I0802 09:37:37.026077 18636 solver.cpp:635]     Test net output #2: loss = 1.86111 (* 1 = 1.86111 loss)
I0802 09:37:37.026096 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6803s
I0802 09:37:37.194598 18636 solver.cpp:353] Iteration 102000 (2.96793 iter/s, 33.6935s/100 iter), loss = 1.99437
I0802 09:37:37.194624 18636 solver.cpp:375]     Train net output #0: loss = 2.46158 (* 1 = 2.46158 loss)
I0802 09:37:37.194629 18636 sgd_solver.cpp:136] Iteration 102000, lr = 0.003625, m = 0.9
I0802 09:37:51.090293 18636 solver.cpp:353] Iteration 102100 (7.19667 iter/s, 13.8953s/100 iter), loss = 1.21927
I0802 09:37:51.090317 18636 solver.cpp:375]     Train net output #0: loss = 1.22717 (* 1 = 1.22717 loss)
I0802 09:37:51.090322 18636 sgd_solver.cpp:136] Iteration 102100, lr = 0.00361875, m = 0.9
I0802 09:38:04.930346 18636 solver.cpp:353] Iteration 102200 (7.22561 iter/s, 13.8397s/100 iter), loss = 1.32408
I0802 09:38:04.930379 18636 solver.cpp:375]     Train net output #0: loss = 1.2771 (* 1 = 1.2771 loss)
I0802 09:38:04.930387 18636 sgd_solver.cpp:136] Iteration 102200, lr = 0.0036125, m = 0.9
I0802 09:38:18.839226 18636 solver.cpp:353] Iteration 102300 (7.18985 iter/s, 13.9085s/100 iter), loss = 1.83622
I0802 09:38:18.839292 18636 solver.cpp:375]     Train net output #0: loss = 2.18686 (* 1 = 2.18686 loss)
I0802 09:38:18.839298 18636 sgd_solver.cpp:136] Iteration 102300, lr = 0.00360625, m = 0.9
I0802 09:38:32.692760 18636 solver.cpp:353] Iteration 102400 (7.21858 iter/s, 13.8531s/100 iter), loss = 1.25369
I0802 09:38:32.692785 18636 solver.cpp:375]     Train net output #0: loss = 1.54582 (* 1 = 1.54582 loss)
I0802 09:38:32.692792 18636 sgd_solver.cpp:136] Iteration 102400, lr = 0.0036, m = 0.9
I0802 09:38:46.598501 18636 solver.cpp:353] Iteration 102500 (7.19147 iter/s, 13.9054s/100 iter), loss = 1.24543
I0802 09:38:46.598556 18636 solver.cpp:375]     Train net output #0: loss = 1.05792 (* 1 = 1.05792 loss)
I0802 09:38:46.598568 18636 sgd_solver.cpp:136] Iteration 102500, lr = 0.00359375, m = 0.9
I0802 09:39:00.550827 18636 solver.cpp:353] Iteration 102600 (7.16746 iter/s, 13.9519s/100 iter), loss = 1.03739
I0802 09:39:00.550935 18636 solver.cpp:375]     Train net output #0: loss = 0.730379 (* 1 = 0.730379 loss)
I0802 09:39:00.550947 18636 sgd_solver.cpp:136] Iteration 102600, lr = 0.0035875, m = 0.9
I0802 09:39:14.460743 18636 solver.cpp:353] Iteration 102700 (7.18931 iter/s, 13.9095s/100 iter), loss = 1.35219
I0802 09:39:14.460769 18636 solver.cpp:375]     Train net output #0: loss = 1.42928 (* 1 = 1.42928 loss)
I0802 09:39:14.460773 18636 sgd_solver.cpp:136] Iteration 102700, lr = 0.00358125, m = 0.9
I0802 09:39:28.414854 18636 solver.cpp:353] Iteration 102800 (7.16655 iter/s, 13.9537s/100 iter), loss = 1.6574
I0802 09:39:28.414881 18636 solver.cpp:375]     Train net output #0: loss = 1.36031 (* 1 = 1.36031 loss)
I0802 09:39:28.414887 18636 sgd_solver.cpp:136] Iteration 102800, lr = 0.003575, m = 0.9
I0802 09:39:42.368685 18636 solver.cpp:353] Iteration 102900 (7.16669 iter/s, 13.9534s/100 iter), loss = 1.63915
I0802 09:39:42.368770 18636 solver.cpp:375]     Train net output #0: loss = 1.35476 (* 1 = 1.35476 loss)
I0802 09:39:42.368777 18636 sgd_solver.cpp:136] Iteration 102900, lr = 0.00356875, m = 0.9
I0802 09:39:56.219862 18636 solver.cpp:404] Sparsity after update:
I0802 09:39:56.232403 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:39:56.232491 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:39:56.232518 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:39:56.232532 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:39:56.232544 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:39:56.232558 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:39:56.232569 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:39:56.232580 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:39:56.232592 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:39:56.232604 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:39:56.232616 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:39:56.232630 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:39:56.232641 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:39:56.361999 18636 solver.cpp:353] Iteration 103000 (7.14647 iter/s, 13.9929s/100 iter), loss = 1.56361
I0802 09:39:56.362078 18636 solver.cpp:375]     Train net output #0: loss = 1.01154 (* 1 = 1.01154 loss)
I0802 09:39:56.362095 18636 sgd_solver.cpp:136] Iteration 103000, lr = 0.0035625, m = 0.9
I0802 09:40:10.358038 18636 solver.cpp:353] Iteration 103100 (7.14508 iter/s, 13.9957s/100 iter), loss = 1.18107
I0802 09:40:10.358069 18636 solver.cpp:375]     Train net output #0: loss = 1.10753 (* 1 = 1.10753 loss)
I0802 09:40:10.358075 18636 sgd_solver.cpp:136] Iteration 103100, lr = 0.00355625, m = 0.9
I0802 09:40:24.247227 18636 solver.cpp:353] Iteration 103200 (7.20004 iter/s, 13.8888s/100 iter), loss = 1.55026
I0802 09:40:24.247328 18636 solver.cpp:375]     Train net output #0: loss = 1.3097 (* 1 = 1.3097 loss)
I0802 09:40:24.247337 18636 sgd_solver.cpp:136] Iteration 103200, lr = 0.00355, m = 0.9
I0802 09:40:38.174479 18636 solver.cpp:353] Iteration 103300 (7.18036 iter/s, 13.9269s/100 iter), loss = 1.53082
I0802 09:40:38.174510 18636 solver.cpp:375]     Train net output #0: loss = 1.83109 (* 1 = 1.83109 loss)
I0802 09:40:38.174516 18636 sgd_solver.cpp:136] Iteration 103300, lr = 0.00354375, m = 0.9
I0802 09:40:52.105681 18636 solver.cpp:353] Iteration 103400 (7.17833 iter/s, 13.9308s/100 iter), loss = 1.57074
I0802 09:40:52.105710 18636 solver.cpp:375]     Train net output #0: loss = 1.96531 (* 1 = 1.96531 loss)
I0802 09:40:52.105716 18636 sgd_solver.cpp:136] Iteration 103400, lr = 0.0035375, m = 0.9
I0802 09:41:06.034324 18636 solver.cpp:353] Iteration 103500 (7.17965 iter/s, 13.9283s/100 iter), loss = 1.22471
I0802 09:41:06.034440 18636 solver.cpp:375]     Train net output #0: loss = 1.03625 (* 1 = 1.03625 loss)
I0802 09:41:06.034461 18636 sgd_solver.cpp:136] Iteration 103500, lr = 0.00353125, m = 0.9
I0802 09:41:20.050493 18636 solver.cpp:353] Iteration 103600 (7.13481 iter/s, 14.0158s/100 iter), loss = 1.26582
I0802 09:41:20.050523 18636 solver.cpp:375]     Train net output #0: loss = 1.20506 (* 1 = 1.20506 loss)
I0802 09:41:20.050529 18636 sgd_solver.cpp:136] Iteration 103600, lr = 0.003525, m = 0.9
I0802 09:41:33.916713 18636 solver.cpp:353] Iteration 103700 (7.21197 iter/s, 13.8658s/100 iter), loss = 1.01781
I0802 09:41:33.916739 18636 solver.cpp:375]     Train net output #0: loss = 1.20099 (* 1 = 1.20099 loss)
I0802 09:41:33.916745 18636 sgd_solver.cpp:136] Iteration 103700, lr = 0.00351875, m = 0.9
I0802 09:41:47.866715 18636 solver.cpp:353] Iteration 103800 (7.16865 iter/s, 13.9496s/100 iter), loss = 1.51808
I0802 09:41:47.866771 18636 solver.cpp:375]     Train net output #0: loss = 1.57503 (* 1 = 1.57503 loss)
I0802 09:41:47.866776 18636 sgd_solver.cpp:136] Iteration 103800, lr = 0.0035125, m = 0.9
I0802 09:42:01.809232 18636 solver.cpp:353] Iteration 103900 (7.1725 iter/s, 13.9421s/100 iter), loss = 1.54744
I0802 09:42:01.809260 18636 solver.cpp:375]     Train net output #0: loss = 1.41026 (* 1 = 1.41026 loss)
I0802 09:42:01.809264 18636 sgd_solver.cpp:136] Iteration 103900, lr = 0.00350625, m = 0.9
I0802 09:42:15.655648 18636 solver.cpp:404] Sparsity after update:
I0802 09:42:15.659632 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:42:15.659644 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:42:15.659653 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:42:15.659657 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:42:15.659664 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:42:15.659670 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:42:15.659675 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:42:15.659680 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:42:15.659684 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:42:15.659688 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:42:15.659693 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:42:15.659696 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:42:15.659700 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:42:15.659710 18636 solver.cpp:550] Iteration 104000, Testing net (#0)
I0802 09:42:35.089581 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578294
I0802 09:42:35.089691 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808115
I0802 09:42:35.089700 18636 solver.cpp:635]     Test net output #2: loss = 1.84777 (* 1 = 1.84777 loss)
I0802 09:42:35.089720 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4295s
I0802 09:42:35.227929 18636 solver.cpp:353] Iteration 104000 (2.99242 iter/s, 33.4178s/100 iter), loss = 1.2111
I0802 09:42:35.227957 18636 solver.cpp:375]     Train net output #0: loss = 1.03677 (* 1 = 1.03677 loss)
I0802 09:42:35.227962 18636 sgd_solver.cpp:136] Iteration 104000, lr = 0.0035, m = 0.9
I0802 09:42:49.149415 18636 solver.cpp:353] Iteration 104100 (7.18334 iter/s, 13.9211s/100 iter), loss = 1.332
I0802 09:42:49.149443 18636 solver.cpp:375]     Train net output #0: loss = 1.23387 (* 1 = 1.23387 loss)
I0802 09:42:49.149451 18636 sgd_solver.cpp:136] Iteration 104100, lr = 0.00349375, m = 0.9
I0802 09:43:03.106521 18636 solver.cpp:353] Iteration 104200 (7.16501 iter/s, 13.9567s/100 iter), loss = 1.36598
I0802 09:43:03.106550 18636 solver.cpp:375]     Train net output #0: loss = 1.60109 (* 1 = 1.60109 loss)
I0802 09:43:03.106556 18636 sgd_solver.cpp:136] Iteration 104200, lr = 0.0034875, m = 0.9
I0802 09:43:17.000056 18636 solver.cpp:353] Iteration 104300 (7.19779 iter/s, 13.8931s/100 iter), loss = 1.39647
I0802 09:43:17.000149 18636 solver.cpp:375]     Train net output #0: loss = 1.71228 (* 1 = 1.71228 loss)
I0802 09:43:17.000157 18636 sgd_solver.cpp:136] Iteration 104300, lr = 0.00348125, m = 0.9
I0802 09:43:30.890250 18636 solver.cpp:353] Iteration 104400 (7.19952 iter/s, 13.8898s/100 iter), loss = 1.79687
I0802 09:43:30.890275 18636 solver.cpp:375]     Train net output #0: loss = 1.6572 (* 1 = 1.6572 loss)
I0802 09:43:30.890280 18636 sgd_solver.cpp:136] Iteration 104400, lr = 0.003475, m = 0.9
I0802 09:43:44.850674 18636 solver.cpp:353] Iteration 104500 (7.16331 iter/s, 13.96s/100 iter), loss = 1.4613
I0802 09:43:44.850728 18636 solver.cpp:375]     Train net output #0: loss = 1.23126 (* 1 = 1.23126 loss)
I0802 09:43:44.850740 18636 sgd_solver.cpp:136] Iteration 104500, lr = 0.00346875, m = 0.9
I0802 09:43:58.745499 18636 solver.cpp:353] Iteration 104600 (7.19712 iter/s, 13.8944s/100 iter), loss = 1.49202
I0802 09:43:58.745609 18636 solver.cpp:375]     Train net output #0: loss = 1.42756 (* 1 = 1.42756 loss)
I0802 09:43:58.745630 18636 sgd_solver.cpp:136] Iteration 104600, lr = 0.0034625, m = 0.9
I0802 09:44:12.627842 18636 solver.cpp:353] Iteration 104700 (7.20359 iter/s, 13.882s/100 iter), loss = 1.11219
I0802 09:44:12.627876 18636 solver.cpp:375]     Train net output #0: loss = 1.19194 (* 1 = 1.19194 loss)
I0802 09:44:12.627882 18636 sgd_solver.cpp:136] Iteration 104700, lr = 0.00345625, m = 0.9
I0802 09:44:26.601918 18636 solver.cpp:353] Iteration 104800 (7.15631 iter/s, 13.9737s/100 iter), loss = 1.36374
I0802 09:44:26.601946 18636 solver.cpp:375]     Train net output #0: loss = 0.988896 (* 1 = 0.988896 loss)
I0802 09:44:26.601953 18636 sgd_solver.cpp:136] Iteration 104800, lr = 0.00345, m = 0.9
I0802 09:44:40.536388 18636 solver.cpp:353] Iteration 104900 (7.17665 iter/s, 13.9341s/100 iter), loss = 1.63781
I0802 09:44:40.536444 18636 solver.cpp:375]     Train net output #0: loss = 1.51105 (* 1 = 1.51105 loss)
I0802 09:44:40.536450 18636 sgd_solver.cpp:136] Iteration 104900, lr = 0.00344375, m = 0.9
I0802 09:44:54.318403 18636 solver.cpp:404] Sparsity after update:
I0802 09:44:54.328938 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:44:54.328953 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:44:54.328963 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:44:54.328966 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:44:54.328982 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:44:54.328992 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:44:54.329000 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:44:54.329010 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:44:54.329017 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:44:54.329026 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:44:54.329035 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:44:54.329042 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:44:54.329051 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:44:54.458329 18636 solver.cpp:353] Iteration 105000 (7.1831 iter/s, 13.9216s/100 iter), loss = 1.0689
I0802 09:44:54.458354 18636 solver.cpp:375]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0802 09:44:54.458359 18636 sgd_solver.cpp:136] Iteration 105000, lr = 0.0034375, m = 0.9
I0802 09:45:08.341802 18636 solver.cpp:353] Iteration 105100 (7.20301 iter/s, 13.8831s/100 iter), loss = 1.33651
I0802 09:45:08.341984 18636 solver.cpp:375]     Train net output #0: loss = 1.30175 (* 1 = 1.30175 loss)
I0802 09:45:08.342068 18636 sgd_solver.cpp:136] Iteration 105100, lr = 0.00343125, m = 0.9
I0802 09:45:22.325664 18636 solver.cpp:353] Iteration 105200 (7.1513 iter/s, 13.9835s/100 iter), loss = 1.69766
I0802 09:45:22.325749 18636 solver.cpp:375]     Train net output #0: loss = 1.497 (* 1 = 1.497 loss)
I0802 09:45:22.325762 18636 sgd_solver.cpp:136] Iteration 105200, lr = 0.003425, m = 0.9
I0802 09:45:36.322141 18636 solver.cpp:353] Iteration 105300 (7.14485 iter/s, 13.9961s/100 iter), loss = 1.63983
I0802 09:45:36.322163 18636 solver.cpp:375]     Train net output #0: loss = 1.62252 (* 1 = 1.62252 loss)
I0802 09:45:36.322170 18636 sgd_solver.cpp:136] Iteration 105300, lr = 0.00341875, m = 0.9
I0802 09:45:50.254701 18636 solver.cpp:353] Iteration 105400 (7.17763 iter/s, 13.9322s/100 iter), loss = 1.22358
I0802 09:45:50.254729 18636 solver.cpp:375]     Train net output #0: loss = 1.07443 (* 1 = 1.07443 loss)
I0802 09:45:50.254736 18636 sgd_solver.cpp:136] Iteration 105400, lr = 0.0034125, m = 0.9
I0802 09:46:04.260617 18636 solver.cpp:353] Iteration 105500 (7.14004 iter/s, 14.0055s/100 iter), loss = 1.20908
I0802 09:46:04.260704 18636 solver.cpp:375]     Train net output #0: loss = 1.13749 (* 1 = 1.13749 loss)
I0802 09:46:04.260711 18636 sgd_solver.cpp:136] Iteration 105500, lr = 0.00340625, m = 0.9
I0802 09:46:18.179473 18636 solver.cpp:353] Iteration 105600 (7.1847 iter/s, 13.9185s/100 iter), loss = 1.37035
I0802 09:46:18.179502 18636 solver.cpp:375]     Train net output #0: loss = 1.10046 (* 1 = 1.10046 loss)
I0802 09:46:18.179508 18636 sgd_solver.cpp:136] Iteration 105600, lr = 0.0034, m = 0.9
I0802 09:46:32.125982 18636 solver.cpp:353] Iteration 105700 (7.17045 iter/s, 13.9461s/100 iter), loss = 1.55902
I0802 09:46:32.126010 18636 solver.cpp:375]     Train net output #0: loss = 1.72694 (* 1 = 1.72694 loss)
I0802 09:46:32.126016 18636 sgd_solver.cpp:136] Iteration 105700, lr = 0.00339375, m = 0.9
I0802 09:46:46.102259 18636 solver.cpp:353] Iteration 105800 (7.15518 iter/s, 13.9759s/100 iter), loss = 1.52161
I0802 09:46:46.102362 18636 solver.cpp:375]     Train net output #0: loss = 1.60564 (* 1 = 1.60564 loss)
I0802 09:46:46.102381 18636 sgd_solver.cpp:136] Iteration 105800, lr = 0.0033875, m = 0.9
I0802 09:47:00.129954 18636 solver.cpp:353] Iteration 105900 (7.12895 iter/s, 14.0273s/100 iter), loss = 1.22783
I0802 09:47:00.129981 18636 solver.cpp:375]     Train net output #0: loss = 1.56583 (* 1 = 1.56583 loss)
I0802 09:47:00.129987 18636 sgd_solver.cpp:136] Iteration 105900, lr = 0.00338125, m = 0.9
I0802 09:47:13.921906 18636 solver.cpp:404] Sparsity after update:
I0802 09:47:13.926381 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:47:13.926417 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:47:13.926430 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:47:13.926439 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:47:13.926450 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:47:13.926460 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:47:13.926470 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:47:13.926481 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:47:13.926488 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:47:13.926496 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:47:13.926512 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:47:13.926520 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:47:13.926528 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:47:13.926549 18636 solver.cpp:550] Iteration 106000, Testing net (#0)
I0802 09:47:25.376945 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:47:33.440882 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578
I0802 09:47:33.440906 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809292
I0802 09:47:33.440912 18636 solver.cpp:635]     Test net output #2: loss = 1.82838 (* 1 = 1.82838 loss)
I0802 09:47:33.441009 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5139s
I0802 09:47:33.578055 18636 solver.cpp:353] Iteration 106000 (2.98979 iter/s, 33.4472s/100 iter), loss = 1.43387
I0802 09:47:33.578305 18636 solver.cpp:375]     Train net output #0: loss = 1.28378 (* 1 = 1.28378 loss)
I0802 09:47:33.578418 18636 sgd_solver.cpp:136] Iteration 106000, lr = 0.003375, m = 0.9
I0802 09:47:47.503957 18636 solver.cpp:353] Iteration 106100 (7.18106 iter/s, 13.9255s/100 iter), loss = 1.44487
I0802 09:47:47.503984 18636 solver.cpp:375]     Train net output #0: loss = 1.67332 (* 1 = 1.67332 loss)
I0802 09:47:47.503988 18636 sgd_solver.cpp:136] Iteration 106100, lr = 0.00336875, m = 0.9
I0802 09:48:01.487061 18636 solver.cpp:353] Iteration 106200 (7.15169 iter/s, 13.9827s/100 iter), loss = 1.39506
I0802 09:48:01.487180 18636 solver.cpp:375]     Train net output #0: loss = 1.25272 (* 1 = 1.25272 loss)
I0802 09:48:01.487190 18636 sgd_solver.cpp:136] Iteration 106200, lr = 0.0033625, m = 0.9
I0802 09:48:15.390166 18636 solver.cpp:353] Iteration 106300 (7.19284 iter/s, 13.9027s/100 iter), loss = 1.12708
I0802 09:48:15.390195 18636 solver.cpp:375]     Train net output #0: loss = 1.21603 (* 1 = 1.21603 loss)
I0802 09:48:15.390202 18636 sgd_solver.cpp:136] Iteration 106300, lr = 0.00335625, m = 0.9
I0802 09:48:29.330901 18636 solver.cpp:353] Iteration 106400 (7.17342 iter/s, 13.9404s/100 iter), loss = 1.33752
I0802 09:48:29.330930 18636 solver.cpp:375]     Train net output #0: loss = 1.55121 (* 1 = 1.55121 loss)
I0802 09:48:29.330937 18636 sgd_solver.cpp:136] Iteration 106400, lr = 0.00335, m = 0.9
I0802 09:48:43.346096 18636 solver.cpp:353] Iteration 106500 (7.13531 iter/s, 14.0148s/100 iter), loss = 1.43256
I0802 09:48:43.346165 18636 solver.cpp:375]     Train net output #0: loss = 1.34552 (* 1 = 1.34552 loss)
I0802 09:48:43.346173 18636 sgd_solver.cpp:136] Iteration 106500, lr = 0.00334375, m = 0.9
I0802 09:48:57.271948 18636 solver.cpp:353] Iteration 106600 (7.18109 iter/s, 13.9255s/100 iter), loss = 1.6253
I0802 09:48:57.271978 18636 solver.cpp:375]     Train net output #0: loss = 1.70686 (* 1 = 1.70686 loss)
I0802 09:48:57.271984 18636 sgd_solver.cpp:136] Iteration 106600, lr = 0.0033375, m = 0.9
I0802 09:49:11.233012 18636 solver.cpp:353] Iteration 106700 (7.16298 iter/s, 13.9607s/100 iter), loss = 1.55936
I0802 09:49:11.233041 18636 solver.cpp:375]     Train net output #0: loss = 1.36271 (* 1 = 1.36271 loss)
I0802 09:49:11.233047 18636 sgd_solver.cpp:136] Iteration 106700, lr = 0.00333125, m = 0.9
I0802 09:49:25.130383 18636 solver.cpp:353] Iteration 106800 (7.19581 iter/s, 13.897s/100 iter), loss = 1.68735
I0802 09:49:25.130481 18636 solver.cpp:375]     Train net output #0: loss = 1.44218 (* 1 = 1.44218 loss)
I0802 09:49:25.130499 18636 sgd_solver.cpp:136] Iteration 106800, lr = 0.003325, m = 0.9
I0802 09:49:39.088791 18636 solver.cpp:353] Iteration 106900 (7.16434 iter/s, 13.958s/100 iter), loss = 1.91405
I0802 09:49:39.088829 18636 solver.cpp:375]     Train net output #0: loss = 1.78122 (* 1 = 1.78122 loss)
I0802 09:49:39.088878 18636 sgd_solver.cpp:136] Iteration 106900, lr = 0.00331875, m = 0.9
I0802 09:49:53.062469 18636 solver.cpp:404] Sparsity after update:
I0802 09:49:53.073631 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:49:53.073648 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:49:53.073657 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:49:53.073660 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:49:53.073663 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:49:53.073667 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:49:53.073670 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:49:53.073673 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:49:53.073676 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:49:53.073679 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:49:53.073683 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:49:53.073685 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:49:53.073688 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:49:53.203754 18636 solver.cpp:353] Iteration 107000 (7.08488 iter/s, 14.1146s/100 iter), loss = 1.6388
I0802 09:49:53.203781 18636 solver.cpp:375]     Train net output #0: loss = 1.59377 (* 1 = 1.59377 loss)
I0802 09:49:53.203788 18636 sgd_solver.cpp:136] Iteration 107000, lr = 0.0033125, m = 0.9
I0802 09:50:07.220563 18636 solver.cpp:353] Iteration 107100 (7.13449 iter/s, 14.0164s/100 iter), loss = 1.42288
I0802 09:50:07.220651 18636 solver.cpp:375]     Train net output #0: loss = 1.58914 (* 1 = 1.58914 loss)
I0802 09:50:07.220659 18636 sgd_solver.cpp:136] Iteration 107100, lr = 0.00330625, m = 0.9
I0802 09:50:21.151489 18636 solver.cpp:353] Iteration 107200 (7.17847 iter/s, 13.9305s/100 iter), loss = 1.53385
I0802 09:50:21.151515 18636 solver.cpp:375]     Train net output #0: loss = 1.15959 (* 1 = 1.15959 loss)
I0802 09:50:21.151522 18636 sgd_solver.cpp:136] Iteration 107200, lr = 0.0033, m = 0.9
I0802 09:50:35.035845 18636 solver.cpp:353] Iteration 107300 (7.20255 iter/s, 13.884s/100 iter), loss = 1.23671
I0802 09:50:35.035873 18636 solver.cpp:375]     Train net output #0: loss = 1.19911 (* 1 = 1.19911 loss)
I0802 09:50:35.035879 18636 sgd_solver.cpp:136] Iteration 107300, lr = 0.00329375, m = 0.9
I0802 09:50:48.963404 18636 solver.cpp:353] Iteration 107400 (7.18021 iter/s, 13.9272s/100 iter), loss = 1.33468
I0802 09:50:48.963508 18636 solver.cpp:375]     Train net output #0: loss = 1.44681 (* 1 = 1.44681 loss)
I0802 09:50:48.963515 18636 sgd_solver.cpp:136] Iteration 107400, lr = 0.0032875, m = 0.9
I0802 09:51:02.870666 18636 solver.cpp:353] Iteration 107500 (7.19069 iter/s, 13.9069s/100 iter), loss = 1.67017
I0802 09:51:02.870695 18636 solver.cpp:375]     Train net output #0: loss = 2.04814 (* 1 = 2.04814 loss)
I0802 09:51:02.870702 18636 sgd_solver.cpp:136] Iteration 107500, lr = 0.00328125, m = 0.9
I0802 09:51:16.766012 18636 solver.cpp:353] Iteration 107600 (7.19686 iter/s, 13.895s/100 iter), loss = 1.31426
I0802 09:51:16.766046 18636 solver.cpp:375]     Train net output #0: loss = 1.40396 (* 1 = 1.40396 loss)
I0802 09:51:16.766052 18636 sgd_solver.cpp:136] Iteration 107600, lr = 0.003275, m = 0.9
I0802 09:51:30.710449 18636 solver.cpp:353] Iteration 107700 (7.17152 iter/s, 13.9441s/100 iter), loss = 1.44487
I0802 09:51:30.710579 18636 solver.cpp:375]     Train net output #0: loss = 1.50806 (* 1 = 1.50806 loss)
I0802 09:51:30.710588 18636 sgd_solver.cpp:136] Iteration 107700, lr = 0.00326875, m = 0.9
I0802 09:51:44.601438 18636 solver.cpp:353] Iteration 107800 (7.19911 iter/s, 13.8906s/100 iter), loss = 1.30251
I0802 09:51:44.601470 18636 solver.cpp:375]     Train net output #0: loss = 1.37887 (* 1 = 1.37887 loss)
I0802 09:51:44.601476 18636 sgd_solver.cpp:136] Iteration 107800, lr = 0.0032625, m = 0.9
I0802 09:51:58.508955 18636 solver.cpp:353] Iteration 107900 (7.19056 iter/s, 13.9071s/100 iter), loss = 1.51297
I0802 09:51:58.508985 18636 solver.cpp:375]     Train net output #0: loss = 1.60829 (* 1 = 1.60829 loss)
I0802 09:51:58.508988 18636 sgd_solver.cpp:136] Iteration 107900, lr = 0.00325625, m = 0.9
I0802 09:52:12.235821 18636 solver.cpp:404] Sparsity after update:
I0802 09:52:12.239812 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:52:12.239825 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:52:12.239833 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:52:12.239836 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:52:12.239840 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:52:12.239843 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:52:12.239846 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:52:12.239850 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:52:12.239852 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:52:12.239856 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:52:12.239857 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:52:12.239861 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:52:12.239864 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:52:12.239876 18636 solver.cpp:550] Iteration 108000, Testing net (#0)
I0802 09:52:31.359550 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578765
I0802 09:52:31.359586 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.81188
I0802 09:52:31.359591 18636 solver.cpp:635]     Test net output #2: loss = 1.84376 (* 1 = 1.84376 loss)
I0802 09:52:31.360846 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1193s
I0802 09:52:31.500010 18636 solver.cpp:353] Iteration 108000 (3.03121 iter/s, 32.9901s/100 iter), loss = 1.21066
I0802 09:52:31.500036 18636 solver.cpp:375]     Train net output #0: loss = 1.08903 (* 1 = 1.08903 loss)
I0802 09:52:31.500041 18636 sgd_solver.cpp:136] Iteration 108000, lr = 0.00325, m = 0.9
I0802 09:52:45.461787 18636 solver.cpp:353] Iteration 108100 (7.16261 iter/s, 13.9614s/100 iter), loss = 1.54481
I0802 09:52:45.461869 18636 solver.cpp:375]     Train net output #0: loss = 1.65168 (* 1 = 1.65168 loss)
I0802 09:52:45.461875 18636 sgd_solver.cpp:136] Iteration 108100, lr = 0.00324375, m = 0.9
I0802 09:52:59.398116 18636 solver.cpp:353] Iteration 108200 (7.17569 iter/s, 13.9359s/100 iter), loss = 1.445
I0802 09:52:59.398145 18636 solver.cpp:375]     Train net output #0: loss = 1.31885 (* 1 = 1.31885 loss)
I0802 09:52:59.398152 18636 sgd_solver.cpp:136] Iteration 108200, lr = 0.0032375, m = 0.9
I0802 09:53:13.314244 18636 solver.cpp:353] Iteration 108300 (7.18611 iter/s, 13.9157s/100 iter), loss = 1.53293
I0802 09:53:13.314270 18636 solver.cpp:375]     Train net output #0: loss = 1.64212 (* 1 = 1.64212 loss)
I0802 09:53:13.314276 18636 sgd_solver.cpp:136] Iteration 108300, lr = 0.00323125, m = 0.9
I0802 09:53:27.187794 18636 solver.cpp:353] Iteration 108400 (7.20816 iter/s, 13.8732s/100 iter), loss = 1.92139
I0802 09:53:27.187855 18636 solver.cpp:375]     Train net output #0: loss = 1.87155 (* 1 = 1.87155 loss)
I0802 09:53:27.187860 18636 sgd_solver.cpp:136] Iteration 108400, lr = 0.003225, m = 0.9
I0802 09:53:41.089586 18636 solver.cpp:353] Iteration 108500 (7.19352 iter/s, 13.9014s/100 iter), loss = 1.4418
I0802 09:53:41.089614 18636 solver.cpp:375]     Train net output #0: loss = 1.74164 (* 1 = 1.74164 loss)
I0802 09:53:41.089622 18636 sgd_solver.cpp:136] Iteration 108500, lr = 0.00321875, m = 0.9
I0802 09:53:54.912930 18636 solver.cpp:353] Iteration 108600 (7.23434 iter/s, 13.823s/100 iter), loss = 1.43752
I0802 09:53:54.912958 18636 solver.cpp:375]     Train net output #0: loss = 1.59108 (* 1 = 1.59108 loss)
I0802 09:53:54.912964 18636 sgd_solver.cpp:136] Iteration 108600, lr = 0.0032125, m = 0.9
I0802 09:54:08.803300 18636 solver.cpp:353] Iteration 108700 (7.19943 iter/s, 13.89s/100 iter), loss = 1.43184
I0802 09:54:08.803360 18636 solver.cpp:375]     Train net output #0: loss = 1.27682 (* 1 = 1.27682 loss)
I0802 09:54:08.803367 18636 sgd_solver.cpp:136] Iteration 108700, lr = 0.00320625, m = 0.9
I0802 09:54:22.686467 18636 solver.cpp:353] Iteration 108800 (7.20317 iter/s, 13.8828s/100 iter), loss = 1.50791
I0802 09:54:22.686568 18636 solver.cpp:375]     Train net output #0: loss = 1.32833 (* 1 = 1.32833 loss)
I0802 09:54:22.686589 18636 sgd_solver.cpp:136] Iteration 108800, lr = 0.0032, m = 0.9
I0802 09:54:36.691031 18636 solver.cpp:353] Iteration 108900 (7.14073 iter/s, 14.0042s/100 iter), loss = 1.62764
I0802 09:54:36.691099 18636 solver.cpp:375]     Train net output #0: loss = 1.76581 (* 1 = 1.76581 loss)
I0802 09:54:36.691118 18636 sgd_solver.cpp:136] Iteration 108900, lr = 0.00319375, m = 0.9
I0802 09:54:50.523632 18636 solver.cpp:404] Sparsity after update:
I0802 09:54:50.534070 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:54:50.534080 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:54:50.534087 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:54:50.534090 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:54:50.534091 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:54:50.534093 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:54:50.534096 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:54:50.534106 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:54:50.534109 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:54:50.534112 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:54:50.534116 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:54:50.534118 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:54:50.534127 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:54:50.664719 18636 solver.cpp:353] Iteration 109000 (7.15651 iter/s, 13.9733s/100 iter), loss = 1.38409
I0802 09:54:50.664750 18636 solver.cpp:375]     Train net output #0: loss = 1.27052 (* 1 = 1.27052 loss)
I0802 09:54:50.664757 18636 sgd_solver.cpp:136] Iteration 109000, lr = 0.0031875, m = 0.9
I0802 09:55:04.629637 18636 solver.cpp:353] Iteration 109100 (7.161 iter/s, 13.9645s/100 iter), loss = 1.64361
I0802 09:55:04.629688 18636 solver.cpp:375]     Train net output #0: loss = 1.77281 (* 1 = 1.77281 loss)
I0802 09:55:04.629701 18636 sgd_solver.cpp:136] Iteration 109100, lr = 0.00318125, m = 0.9
I0802 09:55:18.633031 18636 solver.cpp:353] Iteration 109200 (7.14133 iter/s, 14.003s/100 iter), loss = 1.53448
I0802 09:55:18.633085 18636 solver.cpp:375]     Train net output #0: loss = 1.54255 (* 1 = 1.54255 loss)
I0802 09:55:18.633098 18636 sgd_solver.cpp:136] Iteration 109200, lr = 0.003175, m = 0.9
I0802 09:55:32.551074 18636 solver.cpp:353] Iteration 109300 (7.18512 iter/s, 13.9177s/100 iter), loss = 1.43142
I0802 09:55:32.551142 18636 solver.cpp:375]     Train net output #0: loss = 1.64677 (* 1 = 1.64677 loss)
I0802 09:55:32.551147 18636 sgd_solver.cpp:136] Iteration 109300, lr = 0.00316875, m = 0.9
I0802 09:55:46.535156 18636 solver.cpp:353] Iteration 109400 (7.15119 iter/s, 13.9837s/100 iter), loss = 1.26337
I0802 09:55:46.535184 18636 solver.cpp:375]     Train net output #0: loss = 1.25766 (* 1 = 1.25766 loss)
I0802 09:55:46.535190 18636 sgd_solver.cpp:136] Iteration 109400, lr = 0.0031625, m = 0.9
I0802 09:56:00.438591 18636 solver.cpp:353] Iteration 109500 (7.19267 iter/s, 13.9031s/100 iter), loss = 1.18013
I0802 09:56:00.438614 18636 solver.cpp:375]     Train net output #0: loss = 0.886575 (* 1 = 0.886575 loss)
I0802 09:56:00.438618 18636 sgd_solver.cpp:136] Iteration 109500, lr = 0.00315625, m = 0.9
I0802 09:56:14.330024 18636 solver.cpp:353] Iteration 109600 (7.19888 iter/s, 13.891s/100 iter), loss = 1.06956
I0802 09:56:14.330083 18636 solver.cpp:375]     Train net output #0: loss = 0.973335 (* 1 = 0.973335 loss)
I0802 09:56:14.330088 18636 sgd_solver.cpp:136] Iteration 109600, lr = 0.00315, m = 0.9
I0802 09:56:28.331392 18636 solver.cpp:353] Iteration 109700 (7.14236 iter/s, 14.001s/100 iter), loss = 1.50621
I0802 09:56:28.331419 18636 solver.cpp:375]     Train net output #0: loss = 1.65386 (* 1 = 1.65386 loss)
I0802 09:56:28.331426 18636 sgd_solver.cpp:136] Iteration 109700, lr = 0.00314375, m = 0.9
I0802 09:56:42.287451 18636 solver.cpp:353] Iteration 109800 (7.16555 iter/s, 13.9557s/100 iter), loss = 1.37565
I0802 09:56:42.287549 18636 solver.cpp:375]     Train net output #0: loss = 1.28733 (* 1 = 1.28733 loss)
I0802 09:56:42.287571 18636 sgd_solver.cpp:136] Iteration 109800, lr = 0.0031375, m = 0.9
I0802 09:56:56.294145 18636 solver.cpp:353] Iteration 109900 (7.13964 iter/s, 14.0063s/100 iter), loss = 1.55475
I0802 09:56:56.294253 18636 solver.cpp:375]     Train net output #0: loss = 1.72318 (* 1 = 1.72318 loss)
I0802 09:56:56.294261 18636 sgd_solver.cpp:136] Iteration 109900, lr = 0.00313125, m = 0.9
I0802 09:57:10.049906 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_110000.caffemodel
I0802 09:57:10.133685 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_110000.solverstate
I0802 09:57:10.138453 18636 solver.cpp:404] Sparsity after update:
I0802 09:57:10.139535 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:57:10.139544 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:57:10.139551 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:57:10.139554 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:57:10.139555 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:57:10.139557 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:57:10.139559 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:57:10.139561 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:57:10.139564 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:57:10.139564 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:57:10.139566 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:57:10.139569 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:57:10.139570 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:57:10.139578 18636 solver.cpp:550] Iteration 110000, Testing net (#0)
I0802 09:57:29.896694 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587176
I0802 09:57:29.896785 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.814761
I0802 09:57:29.896792 18636 solver.cpp:635]     Test net output #2: loss = 1.82084 (* 1 = 1.82084 loss)
I0802 09:57:29.896823 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7567s
I0802 09:57:30.061194 18636 solver.cpp:353] Iteration 110000 (2.96155 iter/s, 33.7661s/100 iter), loss = 1.54245
I0802 09:57:30.061223 18636 solver.cpp:375]     Train net output #0: loss = 1.98987 (* 1 = 1.98987 loss)
I0802 09:57:30.061229 18636 sgd_solver.cpp:136] Iteration 110000, lr = 0.003125, m = 0.9
I0802 09:57:43.999763 18636 solver.cpp:353] Iteration 110100 (7.17454 iter/s, 13.9382s/100 iter), loss = 1.42871
I0802 09:57:43.999792 18636 solver.cpp:375]     Train net output #0: loss = 0.943846 (* 1 = 0.943846 loss)
I0802 09:57:43.999799 18636 sgd_solver.cpp:136] Iteration 110100, lr = 0.00311875, m = 0.9
I0802 09:57:57.951606 18636 solver.cpp:353] Iteration 110200 (7.16771 iter/s, 13.9515s/100 iter), loss = 1.56683
I0802 09:57:57.951630 18636 solver.cpp:375]     Train net output #0: loss = 1.39526 (* 1 = 1.39526 loss)
I0802 09:57:57.951634 18636 sgd_solver.cpp:136] Iteration 110200, lr = 0.0031125, m = 0.9
I0802 09:58:11.862828 18636 solver.cpp:353] Iteration 110300 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.37877
I0802 09:58:11.862887 18636 solver.cpp:375]     Train net output #0: loss = 1.34745 (* 1 = 1.34745 loss)
I0802 09:58:11.862895 18636 sgd_solver.cpp:136] Iteration 110300, lr = 0.00310625, m = 0.9
I0802 09:58:25.759505 18636 solver.cpp:353] Iteration 110400 (7.19617 iter/s, 13.8963s/100 iter), loss = 1.60023
I0802 09:58:25.759534 18636 solver.cpp:375]     Train net output #0: loss = 1.60565 (* 1 = 1.60565 loss)
I0802 09:58:25.759541 18636 sgd_solver.cpp:136] Iteration 110400, lr = 0.0031, m = 0.9
I0802 09:58:39.693251 18636 solver.cpp:353] Iteration 110500 (7.17702 iter/s, 13.9334s/100 iter), loss = 0.899308
I0802 09:58:39.693280 18636 solver.cpp:375]     Train net output #0: loss = 0.705947 (* 1 = 0.705947 loss)
I0802 09:58:39.693284 18636 sgd_solver.cpp:136] Iteration 110500, lr = 0.00309375, m = 0.9
I0802 09:58:53.647609 18636 solver.cpp:353] Iteration 110600 (7.16642 iter/s, 13.954s/100 iter), loss = 1.66885
I0802 09:58:53.647687 18636 solver.cpp:375]     Train net output #0: loss = 1.31351 (* 1 = 1.31351 loss)
I0802 09:58:53.647694 18636 sgd_solver.cpp:136] Iteration 110600, lr = 0.0030875, m = 0.9
I0802 09:59:07.584286 18636 solver.cpp:353] Iteration 110700 (7.17551 iter/s, 13.9363s/100 iter), loss = 1.432
I0802 09:59:07.584338 18636 solver.cpp:375]     Train net output #0: loss = 1.36339 (* 1 = 1.36339 loss)
I0802 09:59:07.584352 18636 sgd_solver.cpp:136] Iteration 110700, lr = 0.00308125, m = 0.9
I0802 09:59:21.551941 18636 solver.cpp:353] Iteration 110800 (7.1596 iter/s, 13.9673s/100 iter), loss = 1.69279
I0802 09:59:21.551971 18636 solver.cpp:375]     Train net output #0: loss = 1.97351 (* 1 = 1.97351 loss)
I0802 09:59:21.551976 18636 sgd_solver.cpp:136] Iteration 110800, lr = 0.003075, m = 0.9
I0802 09:59:35.541040 18636 solver.cpp:353] Iteration 110900 (7.14862 iter/s, 13.9887s/100 iter), loss = 1.5668
I0802 09:59:35.541118 18636 solver.cpp:375]     Train net output #0: loss = 1.42046 (* 1 = 1.42046 loss)
I0802 09:59:35.541124 18636 sgd_solver.cpp:136] Iteration 110900, lr = 0.00306875, m = 0.9
I0802 09:59:49.294559 18636 solver.cpp:404] Sparsity after update:
I0802 09:59:49.308532 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:59:49.308547 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:59:49.308555 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:59:49.308559 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:59:49.308562 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:59:49.308567 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:59:49.308571 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:59:49.308575 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:59:49.308579 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:59:49.308583 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:59:49.308586 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:59:49.308590 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:59:49.308594 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:59:49.438077 18636 solver.cpp:353] Iteration 111000 (7.19598 iter/s, 13.8966s/100 iter), loss = 1.22502
I0802 09:59:49.438123 18636 solver.cpp:375]     Train net output #0: loss = 1.4101 (* 1 = 1.4101 loss)
I0802 09:59:49.438132 18636 sgd_solver.cpp:136] Iteration 111000, lr = 0.0030625, m = 0.9
I0802 10:00:03.381567 18636 solver.cpp:353] Iteration 111100 (7.17201 iter/s, 13.9431s/100 iter), loss = 1.45615
I0802 10:00:03.381666 18636 solver.cpp:375]     Train net output #0: loss = 1.70429 (* 1 = 1.70429 loss)
I0802 10:00:03.381687 18636 sgd_solver.cpp:136] Iteration 111100, lr = 0.00305625, m = 0.9
I0802 10:00:17.235638 18636 solver.cpp:353] Iteration 111200 (7.2183 iter/s, 13.8537s/100 iter), loss = 1.59103
I0802 10:00:17.235751 18636 solver.cpp:375]     Train net output #0: loss = 1.52261 (* 1 = 1.52261 loss)
I0802 10:00:17.235774 18636 sgd_solver.cpp:136] Iteration 111200, lr = 0.00305, m = 0.9
I0802 10:00:31.216117 18636 solver.cpp:353] Iteration 111300 (7.15303 iter/s, 13.9801s/100 iter), loss = 1.72469
I0802 10:00:31.216210 18636 solver.cpp:375]     Train net output #0: loss = 1.9546 (* 1 = 1.9546 loss)
I0802 10:00:31.216230 18636 sgd_solver.cpp:136] Iteration 111300, lr = 0.00304375, m = 0.9
I0802 10:00:45.175932 18636 solver.cpp:353] Iteration 111400 (7.16362 iter/s, 13.9594s/100 iter), loss = 1.60009
I0802 10:00:45.175963 18636 solver.cpp:375]     Train net output #0: loss = 1.76351 (* 1 = 1.76351 loss)
I0802 10:00:45.175969 18636 sgd_solver.cpp:136] Iteration 111400, lr = 0.0030375, m = 0.9
I0802 10:00:59.124423 18636 solver.cpp:353] Iteration 111500 (7.16943 iter/s, 13.9481s/100 iter), loss = 1.45916
I0802 10:00:59.124488 18636 solver.cpp:375]     Train net output #0: loss = 1.30357 (* 1 = 1.30357 loss)
I0802 10:00:59.124495 18636 sgd_solver.cpp:136] Iteration 111500, lr = 0.00303125, m = 0.9
I0802 10:01:13.140432 18636 solver.cpp:353] Iteration 111600 (7.1349 iter/s, 14.0156s/100 iter), loss = 1.1732
I0802 10:01:13.140458 18636 solver.cpp:375]     Train net output #0: loss = 1.2387 (* 1 = 1.2387 loss)
I0802 10:01:13.140465 18636 sgd_solver.cpp:136] Iteration 111600, lr = 0.003025, m = 0.9
I0802 10:01:27.083883 18636 solver.cpp:353] Iteration 111700 (7.17203 iter/s, 13.9431s/100 iter), loss = 1.26682
I0802 10:01:27.083935 18636 solver.cpp:375]     Train net output #0: loss = 1.34781 (* 1 = 1.34781 loss)
I0802 10:01:27.083947 18636 sgd_solver.cpp:136] Iteration 111700, lr = 0.00301875, m = 0.9
I0802 10:01:40.986263 18636 solver.cpp:353] Iteration 111800 (7.19321 iter/s, 13.902s/100 iter), loss = 1.1719
I0802 10:01:40.986347 18636 solver.cpp:375]     Train net output #0: loss = 0.891695 (* 1 = 0.891695 loss)
I0802 10:01:40.986356 18636 sgd_solver.cpp:136] Iteration 111800, lr = 0.0030125, m = 0.9
I0802 10:01:54.894105 18636 solver.cpp:353] Iteration 111900 (7.19039 iter/s, 13.9075s/100 iter), loss = 1.47227
I0802 10:01:54.894134 18636 solver.cpp:375]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0802 10:01:54.894140 18636 sgd_solver.cpp:136] Iteration 111900, lr = 0.00300625, m = 0.9
I0802 10:02:08.691491 18636 solver.cpp:404] Sparsity after update:
I0802 10:02:08.695911 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:02:08.695924 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:02:08.695932 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:02:08.695935 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:02:08.695943 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:02:08.695948 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:02:08.695953 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:02:08.695958 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:02:08.695962 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:02:08.695967 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:02:08.695971 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:02:08.695976 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:02:08.695979 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:02:08.695991 18636 solver.cpp:550] Iteration 112000, Testing net (#0)
I0802 10:02:25.807714 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:02:28.220942 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581235
I0802 10:02:28.220966 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809409
I0802 10:02:28.220971 18636 solver.cpp:635]     Test net output #2: loss = 1.83961 (* 1 = 1.83961 loss)
I0802 10:02:28.221216 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5247s
I0802 10:02:28.365306 18636 solver.cpp:353] Iteration 112000 (2.98773 iter/s, 33.4703s/100 iter), loss = 1.51207
I0802 10:02:28.365339 18636 solver.cpp:375]     Train net output #0: loss = 1.71552 (* 1 = 1.71552 loss)
I0802 10:02:28.365345 18636 sgd_solver.cpp:136] Iteration 112000, lr = 0.003, m = 0.9
I0802 10:02:42.256425 18636 solver.cpp:353] Iteration 112100 (7.19904 iter/s, 13.8907s/100 iter), loss = 1.39908
I0802 10:02:42.256479 18636 solver.cpp:375]     Train net output #0: loss = 1.46986 (* 1 = 1.46986 loss)
I0802 10:02:42.256491 18636 sgd_solver.cpp:136] Iteration 112100, lr = 0.00299375, m = 0.9
I0802 10:02:56.214717 18636 solver.cpp:353] Iteration 112200 (7.1644 iter/s, 13.9579s/100 iter), loss = 1.15719
I0802 10:02:56.214818 18636 solver.cpp:375]     Train net output #0: loss = 1.06433 (* 1 = 1.06433 loss)
I0802 10:02:56.214836 18636 sgd_solver.cpp:136] Iteration 112200, lr = 0.0029875, m = 0.9
I0802 10:03:10.220976 18636 solver.cpp:353] Iteration 112300 (7.13986 iter/s, 14.0059s/100 iter), loss = 1.48543
I0802 10:03:10.221004 18636 solver.cpp:375]     Train net output #0: loss = 1.42599 (* 1 = 1.42599 loss)
I0802 10:03:10.221007 18636 sgd_solver.cpp:136] Iteration 112300, lr = 0.00298125, m = 0.9
I0802 10:03:24.168282 18636 solver.cpp:353] Iteration 112400 (7.17004 iter/s, 13.9469s/100 iter), loss = 1.2516
I0802 10:03:24.168505 18636 solver.cpp:375]     Train net output #0: loss = 1.13621 (* 1 = 1.13621 loss)
I0802 10:03:24.168615 18636 sgd_solver.cpp:136] Iteration 112400, lr = 0.002975, m = 0.9
I0802 10:03:38.097812 18636 solver.cpp:353] Iteration 112500 (7.17919 iter/s, 13.9291s/100 iter), loss = 1.63233
I0802 10:03:38.097895 18636 solver.cpp:375]     Train net output #0: loss = 1.43651 (* 1 = 1.43651 loss)
I0802 10:03:38.097903 18636 sgd_solver.cpp:136] Iteration 112500, lr = 0.00296875, m = 0.9
I0802 10:03:52.156004 18636 solver.cpp:353] Iteration 112600 (7.11349 iter/s, 14.0578s/100 iter), loss = 1.50537
I0802 10:03:52.156030 18636 solver.cpp:375]     Train net output #0: loss = 1.54782 (* 1 = 1.54782 loss)
I0802 10:03:52.156035 18636 sgd_solver.cpp:136] Iteration 112600, lr = 0.0029625, m = 0.9
I0802 10:04:06.066702 18636 solver.cpp:353] Iteration 112700 (7.18891 iter/s, 13.9103s/100 iter), loss = 1.38207
I0802 10:04:06.066731 18636 solver.cpp:375]     Train net output #0: loss = 1.62054 (* 1 = 1.62054 loss)
I0802 10:04:06.066737 18636 sgd_solver.cpp:136] Iteration 112700, lr = 0.00295625, m = 0.9
I0802 10:04:19.999792 18636 solver.cpp:353] Iteration 112800 (7.17736 iter/s, 13.9327s/100 iter), loss = 1.4825
I0802 10:04:19.999855 18636 solver.cpp:375]     Train net output #0: loss = 1.74482 (* 1 = 1.74482 loss)
I0802 10:04:19.999861 18636 sgd_solver.cpp:136] Iteration 112800, lr = 0.00295, m = 0.9
I0802 10:04:34.025063 18636 solver.cpp:353] Iteration 112900 (7.13018 iter/s, 14.0249s/100 iter), loss = 1.74798
I0802 10:04:34.025092 18636 solver.cpp:375]     Train net output #0: loss = 1.6714 (* 1 = 1.6714 loss)
I0802 10:04:34.025099 18636 sgd_solver.cpp:136] Iteration 112900, lr = 0.00294375, m = 0.9
I0802 10:04:47.829897 18636 solver.cpp:404] Sparsity after update:
I0802 10:04:47.842758 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:04:47.842772 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:04:47.842780 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:04:47.842782 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:04:47.842784 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:04:47.842787 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:04:47.842788 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:04:47.842790 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:04:47.842792 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:04:47.842793 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:04:47.842795 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:04:47.842797 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:04:47.842799 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:04:47.971690 18636 solver.cpp:353] Iteration 113000 (7.17039 iter/s, 13.9462s/100 iter), loss = 1.55995
I0802 10:04:47.971741 18636 solver.cpp:375]     Train net output #0: loss = 1.1716 (* 1 = 1.1716 loss)
I0802 10:04:47.971755 18636 sgd_solver.cpp:136] Iteration 113000, lr = 0.0029375, m = 0.9
I0802 10:05:01.949004 18636 solver.cpp:353] Iteration 113100 (7.15465 iter/s, 13.9769s/100 iter), loss = 1.59824
I0802 10:05:01.949098 18636 solver.cpp:375]     Train net output #0: loss = 1.68197 (* 1 = 1.68197 loss)
I0802 10:05:01.949111 18636 sgd_solver.cpp:136] Iteration 113100, lr = 0.00293125, m = 0.9
I0802 10:05:15.855602 18636 solver.cpp:353] Iteration 113200 (7.19103 iter/s, 13.9062s/100 iter), loss = 1.27216
I0802 10:05:15.855630 18636 solver.cpp:375]     Train net output #0: loss = 1.14336 (* 1 = 1.14336 loss)
I0802 10:05:15.855635 18636 sgd_solver.cpp:136] Iteration 113200, lr = 0.002925, m = 0.9
I0802 10:05:29.762634 18636 solver.cpp:353] Iteration 113300 (7.19081 iter/s, 13.9066s/100 iter), loss = 1.53708
I0802 10:05:29.762661 18636 solver.cpp:375]     Train net output #0: loss = 0.987813 (* 1 = 0.987813 loss)
I0802 10:05:29.762667 18636 sgd_solver.cpp:136] Iteration 113300, lr = 0.00291875, m = 0.9
I0802 10:05:43.789441 18636 solver.cpp:353] Iteration 113400 (7.12941 iter/s, 14.0264s/100 iter), loss = 1.38819
I0802 10:05:43.789589 18636 solver.cpp:375]     Train net output #0: loss = 1.46613 (* 1 = 1.46613 loss)
I0802 10:05:43.789609 18636 sgd_solver.cpp:136] Iteration 113400, lr = 0.0029125, m = 0.9
I0802 10:05:57.762074 18636 solver.cpp:353] Iteration 113500 (7.15704 iter/s, 13.9722s/100 iter), loss = 1.34474
I0802 10:05:57.762101 18636 solver.cpp:375]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I0802 10:05:57.762106 18636 sgd_solver.cpp:136] Iteration 113500, lr = 0.00290625, m = 0.9
I0802 10:06:11.718737 18636 solver.cpp:353] Iteration 113600 (7.16524 iter/s, 13.9563s/100 iter), loss = 1.24925
I0802 10:06:11.718761 18636 solver.cpp:375]     Train net output #0: loss = 1.27021 (* 1 = 1.27021 loss)
I0802 10:06:11.718767 18636 sgd_solver.cpp:136] Iteration 113600, lr = 0.0029, m = 0.9
I0802 10:06:25.852998 18636 solver.cpp:353] Iteration 113700 (7.0752 iter/s, 14.1339s/100 iter), loss = 1.70991
I0802 10:06:25.853081 18636 solver.cpp:375]     Train net output #0: loss = 1.89208 (* 1 = 1.89208 loss)
I0802 10:06:25.853088 18636 sgd_solver.cpp:136] Iteration 113700, lr = 0.00289375, m = 0.9
I0802 10:06:39.865314 18636 solver.cpp:353] Iteration 113800 (7.13678 iter/s, 14.0119s/100 iter), loss = 1.31448
I0802 10:06:39.865340 18636 solver.cpp:375]     Train net output #0: loss = 1.70257 (* 1 = 1.70257 loss)
I0802 10:06:39.865345 18636 sgd_solver.cpp:136] Iteration 113800, lr = 0.0028875, m = 0.9
I0802 10:06:53.767094 18636 solver.cpp:353] Iteration 113900 (7.19352 iter/s, 13.9014s/100 iter), loss = 1.59577
I0802 10:06:53.767124 18636 solver.cpp:375]     Train net output #0: loss = 1.5135 (* 1 = 1.5135 loss)
I0802 10:06:53.767130 18636 sgd_solver.cpp:136] Iteration 113900, lr = 0.00288125, m = 0.9
I0802 10:07:07.618507 18636 solver.cpp:404] Sparsity after update:
I0802 10:07:07.623481 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:07:07.623492 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:07:07.623500 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:07:07.623504 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:07:07.623512 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:07:07.623517 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:07:07.623522 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:07:07.623527 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:07:07.623531 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:07:07.623535 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:07:07.623540 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:07:07.623543 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:07:07.623548 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:07:07.623560 18636 solver.cpp:550] Iteration 114000, Testing net (#0)
I0802 10:07:27.359398 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.577353
I0802 10:07:27.359424 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810173
I0802 10:07:27.359429 18636 solver.cpp:635]     Test net output #2: loss = 1.85034 (* 1 = 1.85034 loss)
I0802 10:07:27.359480 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7354s
I0802 10:07:27.508147 18636 solver.cpp:353] Iteration 114000 (2.96383 iter/s, 33.7401s/100 iter), loss = 0.91309
I0802 10:07:27.508347 18636 solver.cpp:375]     Train net output #0: loss = 0.764577 (* 1 = 0.764577 loss)
I0802 10:07:27.508437 18636 sgd_solver.cpp:136] Iteration 114000, lr = 0.002875, m = 0.9
I0802 10:07:41.491348 18636 solver.cpp:353] Iteration 114100 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.34853
I0802 10:07:41.491435 18636 solver.cpp:375]     Train net output #0: loss = 1.35189 (* 1 = 1.35189 loss)
I0802 10:07:41.491441 18636 sgd_solver.cpp:136] Iteration 114100, lr = 0.00286875, m = 0.9
I0802 10:07:55.438851 18636 solver.cpp:353] Iteration 114200 (7.16994 iter/s, 13.9471s/100 iter), loss = 1.26506
I0802 10:07:55.438947 18636 solver.cpp:375]     Train net output #0: loss = 1.3461 (* 1 = 1.3461 loss)
I0802 10:07:55.438966 18636 sgd_solver.cpp:136] Iteration 114200, lr = 0.0028625, m = 0.9
I0802 10:07:56.891306 18597 data_reader.cpp:264] Starting prefetch of epoch 3
I0802 10:08:09.345686 18636 solver.cpp:353] Iteration 114300 (7.19091 iter/s, 13.9064s/100 iter), loss = 1.5841
I0802 10:08:09.345715 18636 solver.cpp:375]     Train net output #0: loss = 2.10423 (* 1 = 2.10423 loss)
I0802 10:08:09.345721 18636 sgd_solver.cpp:136] Iteration 114300, lr = 0.00285625, m = 0.9
I0802 10:08:23.400413 18636 solver.cpp:353] Iteration 114400 (7.11524 iter/s, 14.0543s/100 iter), loss = 1.5817
I0802 10:08:23.400475 18636 solver.cpp:375]     Train net output #0: loss = 1.74919 (* 1 = 1.74919 loss)
I0802 10:08:23.400481 18636 sgd_solver.cpp:136] Iteration 114400, lr = 0.00285, m = 0.9
I0802 10:08:37.269358 18636 solver.cpp:353] Iteration 114500 (7.21056 iter/s, 13.8686s/100 iter), loss = 2.00215
I0802 10:08:37.269409 18636 solver.cpp:375]     Train net output #0: loss = 2.21537 (* 1 = 2.21537 loss)
I0802 10:08:37.269423 18636 sgd_solver.cpp:136] Iteration 114500, lr = 0.00284375, m = 0.9
I0802 10:08:51.389118 18636 solver.cpp:353] Iteration 114600 (7.08247 iter/s, 14.1194s/100 iter), loss = 1.50907
I0802 10:08:51.389147 18636 solver.cpp:375]     Train net output #0: loss = 1.39477 (* 1 = 1.39477 loss)
I0802 10:08:51.389153 18636 sgd_solver.cpp:136] Iteration 114600, lr = 0.0028375, m = 0.9
I0802 10:09:05.277951 18636 solver.cpp:353] Iteration 114700 (7.20023 iter/s, 13.8884s/100 iter), loss = 1.1697
I0802 10:09:05.278053 18636 solver.cpp:375]     Train net output #0: loss = 1.18772 (* 1 = 1.18772 loss)
I0802 10:09:05.278064 18636 sgd_solver.cpp:136] Iteration 114700, lr = 0.00283125, m = 0.9
I0802 10:09:19.196823 18636 solver.cpp:353] Iteration 114800 (7.18469 iter/s, 13.9185s/100 iter), loss = 1.55788
I0802 10:09:19.196852 18636 solver.cpp:375]     Train net output #0: loss = 1.59841 (* 1 = 1.59841 loss)
I0802 10:09:19.196858 18636 sgd_solver.cpp:136] Iteration 114800, lr = 0.002825, m = 0.9
I0802 10:09:33.123132 18636 solver.cpp:353] Iteration 114900 (7.18085 iter/s, 13.9259s/100 iter), loss = 1.15911
I0802 10:09:33.123164 18636 solver.cpp:375]     Train net output #0: loss = 1.25971 (* 1 = 1.25971 loss)
I0802 10:09:33.123172 18636 sgd_solver.cpp:136] Iteration 114900, lr = 0.00281875, m = 0.9
I0802 10:09:46.929257 18636 solver.cpp:404] Sparsity after update:
I0802 10:09:46.940212 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:09:46.940244 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:09:46.940260 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:09:46.940270 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:09:46.940280 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:09:46.940289 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:09:46.940299 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:09:46.940309 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:09:46.940317 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:09:46.940326 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:09:46.940335 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:09:46.940345 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:09:46.940353 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:09:47.071051 18636 solver.cpp:353] Iteration 115000 (7.16973 iter/s, 13.9475s/100 iter), loss = 1.47883
I0802 10:09:47.071080 18636 solver.cpp:375]     Train net output #0: loss = 1.34086 (* 1 = 1.34086 loss)
I0802 10:09:47.071085 18636 sgd_solver.cpp:136] Iteration 115000, lr = 0.0028125, m = 0.9
I0802 10:10:01.087105 18636 solver.cpp:353] Iteration 115100 (7.13488 iter/s, 14.0157s/100 iter), loss = 1.60786
I0802 10:10:01.087157 18636 solver.cpp:375]     Train net output #0: loss = 1.28492 (* 1 = 1.28492 loss)
I0802 10:10:01.087167 18636 sgd_solver.cpp:136] Iteration 115100, lr = 0.00280625, m = 0.9
I0802 10:10:15.190274 18636 solver.cpp:353] Iteration 115200 (7.0908 iter/s, 14.1028s/100 iter), loss = 1.33766
I0802 10:10:15.190299 18636 solver.cpp:375]     Train net output #0: loss = 1.29343 (* 1 = 1.29343 loss)
I0802 10:10:15.190304 18636 sgd_solver.cpp:136] Iteration 115200, lr = 0.0028, m = 0.9
I0802 10:10:29.220010 18636 solver.cpp:353] Iteration 115300 (7.12792 iter/s, 14.0293s/100 iter), loss = 1.71744
I0802 10:10:29.220069 18636 solver.cpp:375]     Train net output #0: loss = 2.18873 (* 1 = 2.18873 loss)
I0802 10:10:29.220078 18636 sgd_solver.cpp:136] Iteration 115300, lr = 0.00279375, m = 0.9
I0802 10:10:43.194103 18636 solver.cpp:353] Iteration 115400 (7.1563 iter/s, 13.9737s/100 iter), loss = 0.949011
I0802 10:10:43.194139 18636 solver.cpp:375]     Train net output #0: loss = 1.0021 (* 1 = 1.0021 loss)
I0802 10:10:43.194146 18636 sgd_solver.cpp:136] Iteration 115400, lr = 0.0027875, m = 0.9
I0802 10:10:57.485473 18636 solver.cpp:353] Iteration 115500 (6.99742 iter/s, 14.291s/100 iter), loss = 1.64631
I0802 10:10:57.485503 18636 solver.cpp:375]     Train net output #0: loss = 1.68729 (* 1 = 1.68729 loss)
I0802 10:10:57.485509 18636 sgd_solver.cpp:136] Iteration 115500, lr = 0.00278125, m = 0.9
I0802 10:11:11.456862 18636 solver.cpp:353] Iteration 115600 (7.15768 iter/s, 13.971s/100 iter), loss = 1.74328
I0802 10:11:11.456967 18636 solver.cpp:375]     Train net output #0: loss = 1.91956 (* 1 = 1.91956 loss)
I0802 10:11:11.456974 18636 sgd_solver.cpp:136] Iteration 115600, lr = 0.002775, m = 0.9
I0802 10:11:25.411651 18636 solver.cpp:353] Iteration 115700 (7.1662 iter/s, 13.9544s/100 iter), loss = 1.01207
I0802 10:11:25.411680 18636 solver.cpp:375]     Train net output #0: loss = 0.98901 (* 1 = 0.98901 loss)
I0802 10:11:25.411686 18636 sgd_solver.cpp:136] Iteration 115700, lr = 0.00276875, m = 0.9
I0802 10:11:39.485565 18636 solver.cpp:353] Iteration 115800 (7.10554 iter/s, 14.0735s/100 iter), loss = 1.77353
I0802 10:11:39.485594 18636 solver.cpp:375]     Train net output #0: loss = 2.0803 (* 1 = 2.0803 loss)
I0802 10:11:39.485599 18636 sgd_solver.cpp:136] Iteration 115800, lr = 0.0027625, m = 0.9
I0802 10:11:53.385000 18636 solver.cpp:353] Iteration 115900 (7.19474 iter/s, 13.8991s/100 iter), loss = 1.52729
I0802 10:11:53.385087 18636 solver.cpp:375]     Train net output #0: loss = 1.65443 (* 1 = 1.65443 loss)
I0802 10:11:53.385098 18636 sgd_solver.cpp:136] Iteration 115900, lr = 0.00275625, m = 0.9
I0802 10:12:07.182519 18636 solver.cpp:404] Sparsity after update:
I0802 10:12:07.186753 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:12:07.186765 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:12:07.186774 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:12:07.186777 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:12:07.186790 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:12:07.186800 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:12:07.186810 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:12:07.186818 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:12:07.186826 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:12:07.186836 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:12:07.186844 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:12:07.186854 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:12:07.186864 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:12:07.186883 18636 solver.cpp:550] Iteration 116000, Testing net (#0)
I0802 10:12:26.842962 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584471
I0802 10:12:26.843070 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.813644
I0802 10:12:26.843080 18636 solver.cpp:635]     Test net output #2: loss = 1.80801 (* 1 = 1.80801 loss)
I0802 10:12:26.843098 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6557s
I0802 10:12:26.982319 18636 solver.cpp:353] Iteration 116000 (2.97651 iter/s, 33.5964s/100 iter), loss = 1.2782
I0802 10:12:26.982373 18636 solver.cpp:375]     Train net output #0: loss = 1.27656 (* 1 = 1.27656 loss)
I0802 10:12:26.982386 18636 sgd_solver.cpp:136] Iteration 116000, lr = 0.00275, m = 0.9
I0802 10:12:40.941445 18636 solver.cpp:353] Iteration 116100 (7.16397 iter/s, 13.9587s/100 iter), loss = 1.39822
I0802 10:12:40.941473 18636 solver.cpp:375]     Train net output #0: loss = 1.22729 (* 1 = 1.22729 loss)
I0802 10:12:40.941478 18636 sgd_solver.cpp:136] Iteration 116100, lr = 0.00274375, m = 0.9
I0802 10:12:54.906072 18636 solver.cpp:353] Iteration 116200 (7.16115 iter/s, 13.9642s/100 iter), loss = 1.44122
I0802 10:12:54.906096 18636 solver.cpp:375]     Train net output #0: loss = 1.43812 (* 1 = 1.43812 loss)
I0802 10:12:54.906102 18636 sgd_solver.cpp:136] Iteration 116200, lr = 0.0027375, m = 0.9
I0802 10:13:08.883584 18636 solver.cpp:353] Iteration 116300 (7.15455 iter/s, 13.9771s/100 iter), loss = 1.64097
I0802 10:13:08.883641 18636 solver.cpp:375]     Train net output #0: loss = 1.85543 (* 1 = 1.85543 loss)
I0802 10:13:08.883646 18636 sgd_solver.cpp:136] Iteration 116300, lr = 0.00273125, m = 0.9
I0802 10:13:22.914695 18636 solver.cpp:353] Iteration 116400 (7.12722 iter/s, 14.0307s/100 iter), loss = 1.32614
I0802 10:13:22.914721 18636 solver.cpp:375]     Train net output #0: loss = 0.980576 (* 1 = 0.980576 loss)
I0802 10:13:22.914724 18636 sgd_solver.cpp:136] Iteration 116400, lr = 0.002725, m = 0.9
I0802 10:13:36.847661 18636 solver.cpp:353] Iteration 116500 (7.17742 iter/s, 13.9326s/100 iter), loss = 1.27136
I0802 10:13:36.847697 18636 solver.cpp:375]     Train net output #0: loss = 1.22615 (* 1 = 1.22615 loss)
I0802 10:13:36.847703 18636 sgd_solver.cpp:136] Iteration 116500, lr = 0.00271875, m = 0.9
I0802 10:13:50.887928 18636 solver.cpp:353] Iteration 116600 (7.12257 iter/s, 14.0399s/100 iter), loss = 1.30314
I0802 10:13:50.888010 18636 solver.cpp:375]     Train net output #0: loss = 1.31045 (* 1 = 1.31045 loss)
I0802 10:13:50.888016 18636 sgd_solver.cpp:136] Iteration 116600, lr = 0.0027125, m = 0.9
I0802 10:14:04.846424 18636 solver.cpp:353] Iteration 116700 (7.1643 iter/s, 13.9581s/100 iter), loss = 1.10706
I0802 10:14:04.846451 18636 solver.cpp:375]     Train net output #0: loss = 1.19037 (* 1 = 1.19037 loss)
I0802 10:14:04.846457 18636 sgd_solver.cpp:136] Iteration 116700, lr = 0.00270625, m = 0.9
I0802 10:14:18.736294 18636 solver.cpp:353] Iteration 116800 (7.19969 iter/s, 13.8895s/100 iter), loss = 1.68322
I0802 10:14:18.736323 18636 solver.cpp:375]     Train net output #0: loss = 1.68153 (* 1 = 1.68153 loss)
I0802 10:14:18.736330 18636 sgd_solver.cpp:136] Iteration 116800, lr = 0.0027, m = 0.9
I0802 10:14:32.684116 18636 solver.cpp:353] Iteration 116900 (7.16978 iter/s, 13.9474s/100 iter), loss = 1.4956
I0802 10:14:32.684226 18636 solver.cpp:375]     Train net output #0: loss = 1.49683 (* 1 = 1.49683 loss)
I0802 10:14:32.684231 18636 sgd_solver.cpp:136] Iteration 116900, lr = 0.00269375, m = 0.9
I0802 10:14:46.714704 18636 solver.cpp:404] Sparsity after update:
I0802 10:14:46.727128 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:14:46.727140 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:14:46.727147 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:14:46.727149 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:14:46.727151 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:14:46.727154 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:14:46.727155 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:14:46.727157 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:14:46.727162 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:14:46.727165 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:14:46.727169 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:14:46.727171 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:14:46.727175 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:14:46.856703 18636 solver.cpp:353] Iteration 117000 (7.05607 iter/s, 14.1722s/100 iter), loss = 1.36616
I0802 10:14:46.856727 18636 solver.cpp:375]     Train net output #0: loss = 1.15066 (* 1 = 1.15066 loss)
I0802 10:14:46.856734 18636 sgd_solver.cpp:136] Iteration 117000, lr = 0.0026875, m = 0.9
I0802 10:15:00.813944 18636 solver.cpp:353] Iteration 117100 (7.16494 iter/s, 13.9569s/100 iter), loss = 1.02112
I0802 10:15:00.813971 18636 solver.cpp:375]     Train net output #0: loss = 1.02217 (* 1 = 1.02217 loss)
I0802 10:15:00.813976 18636 sgd_solver.cpp:136] Iteration 117100, lr = 0.00268125, m = 0.9
I0802 10:15:14.774521 18636 solver.cpp:353] Iteration 117200 (7.16323 iter/s, 13.9602s/100 iter), loss = 1.7225
I0802 10:15:14.774606 18636 solver.cpp:375]     Train net output #0: loss = 1.46356 (* 1 = 1.46356 loss)
I0802 10:15:14.774613 18636 sgd_solver.cpp:136] Iteration 117200, lr = 0.002675, m = 0.9
I0802 10:15:28.646308 18636 solver.cpp:353] Iteration 117300 (7.20908 iter/s, 13.8714s/100 iter), loss = 1.48062
I0802 10:15:28.646337 18636 solver.cpp:375]     Train net output #0: loss = 1.74852 (* 1 = 1.74852 loss)
I0802 10:15:28.646342 18636 sgd_solver.cpp:136] Iteration 117300, lr = 0.00266875, m = 0.9
I0802 10:15:42.877852 18636 solver.cpp:353] Iteration 117400 (7.02684 iter/s, 14.2312s/100 iter), loss = 1.53866
I0802 10:15:42.877878 18636 solver.cpp:375]     Train net output #0: loss = 1.51422 (* 1 = 1.51422 loss)
I0802 10:15:42.877884 18636 sgd_solver.cpp:136] Iteration 117400, lr = 0.0026625, m = 0.9
I0802 10:15:56.808331 18636 solver.cpp:353] Iteration 117500 (7.1787 iter/s, 13.9301s/100 iter), loss = 1.60402
I0802 10:15:56.808410 18636 solver.cpp:375]     Train net output #0: loss = 1.20729 (* 1 = 1.20729 loss)
I0802 10:15:56.808418 18636 sgd_solver.cpp:136] Iteration 117500, lr = 0.00265625, m = 0.9
I0802 10:16:10.805320 18636 solver.cpp:353] Iteration 117600 (7.14459 iter/s, 13.9966s/100 iter), loss = 1.21281
I0802 10:16:10.805343 18636 solver.cpp:375]     Train net output #0: loss = 1.09235 (* 1 = 1.09235 loss)
I0802 10:16:10.805347 18636 sgd_solver.cpp:136] Iteration 117600, lr = 0.00265, m = 0.9
I0802 10:16:24.966953 18636 solver.cpp:353] Iteration 117700 (7.06153 iter/s, 14.1612s/100 iter), loss = 1.09583
I0802 10:16:24.967047 18636 solver.cpp:375]     Train net output #0: loss = 1.04774 (* 1 = 1.04774 loss)
I0802 10:16:24.967067 18636 sgd_solver.cpp:136] Iteration 117700, lr = 0.00264375, m = 0.9
I0802 10:16:38.959575 18636 solver.cpp:353] Iteration 117800 (7.14682 iter/s, 13.9922s/100 iter), loss = 1.49
I0802 10:16:38.959663 18636 solver.cpp:375]     Train net output #0: loss = 1.46232 (* 1 = 1.46232 loss)
I0802 10:16:38.959676 18636 sgd_solver.cpp:136] Iteration 117800, lr = 0.0026375, m = 0.9
I0802 10:16:52.881922 18636 solver.cpp:353] Iteration 117900 (7.1829 iter/s, 13.922s/100 iter), loss = 1.17485
I0802 10:16:52.881954 18636 solver.cpp:375]     Train net output #0: loss = 1.14365 (* 1 = 1.14365 loss)
I0802 10:16:52.881960 18636 sgd_solver.cpp:136] Iteration 117900, lr = 0.00263125, m = 0.9
I0802 10:17:06.730336 18636 solver.cpp:404] Sparsity after update:
I0802 10:17:06.736109 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:17:06.736155 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:17:06.736173 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:17:06.736181 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:17:06.736189 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:17:06.736197 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:17:06.736204 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:17:06.736212 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:17:06.736222 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:17:06.736232 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:17:06.736241 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:17:06.736250 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:17:06.736258 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:17:06.736276 18636 solver.cpp:550] Iteration 118000, Testing net (#0)
I0802 10:17:26.275025 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581
I0802 10:17:26.275140 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811233
I0802 10:17:26.275149 18636 solver.cpp:635]     Test net output #2: loss = 1.82966 (* 1 = 1.82966 loss)
I0802 10:17:26.275173 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5384s
I0802 10:17:26.421171 18636 solver.cpp:353] Iteration 118000 (2.98166 iter/s, 33.5383s/100 iter), loss = 1.45173
I0802 10:17:26.421196 18636 solver.cpp:375]     Train net output #0: loss = 1.53097 (* 1 = 1.53097 loss)
I0802 10:17:26.421201 18636 sgd_solver.cpp:136] Iteration 118000, lr = 0.002625, m = 0.9
I0802 10:17:40.343070 18636 solver.cpp:353] Iteration 118100 (7.18313 iter/s, 13.9215s/100 iter), loss = 1.44201
I0802 10:17:40.343097 18636 solver.cpp:375]     Train net output #0: loss = 1.52047 (* 1 = 1.52047 loss)
I0802 10:17:40.343103 18636 sgd_solver.cpp:136] Iteration 118100, lr = 0.00261875, m = 0.9
I0802 10:17:54.231024 18636 solver.cpp:353] Iteration 118200 (7.20069 iter/s, 13.8876s/100 iter), loss = 1.64977
I0802 10:17:54.231122 18636 solver.cpp:375]     Train net output #0: loss = 1.16506 (* 1 = 1.16506 loss)
I0802 10:17:54.231144 18636 sgd_solver.cpp:136] Iteration 118200, lr = 0.0026125, m = 0.9
I0802 10:18:08.225963 18636 solver.cpp:353] Iteration 118300 (7.14564 iter/s, 13.9945s/100 iter), loss = 1.23777
I0802 10:18:08.226042 18636 solver.cpp:375]     Train net output #0: loss = 1.33069 (* 1 = 1.33069 loss)
I0802 10:18:08.226047 18636 sgd_solver.cpp:136] Iteration 118300, lr = 0.00260625, m = 0.9
I0802 10:18:22.159646 18636 solver.cpp:353] Iteration 118400 (7.17705 iter/s, 13.9333s/100 iter), loss = 1.59327
I0802 10:18:22.159677 18636 solver.cpp:375]     Train net output #0: loss = 1.46228 (* 1 = 1.46228 loss)
I0802 10:18:22.159683 18636 sgd_solver.cpp:136] Iteration 118400, lr = 0.0026, m = 0.9
I0802 10:18:36.106509 18636 solver.cpp:353] Iteration 118500 (7.17027 iter/s, 13.9465s/100 iter), loss = 1.65896
I0802 10:18:36.106537 18636 solver.cpp:375]     Train net output #0: loss = 1.88491 (* 1 = 1.88491 loss)
I0802 10:18:36.106542 18636 sgd_solver.cpp:136] Iteration 118500, lr = 0.00259375, m = 0.9
I0802 10:18:50.062742 18636 solver.cpp:353] Iteration 118600 (7.16546 iter/s, 13.9558s/100 iter), loss = 1.12877
I0802 10:18:50.062826 18636 solver.cpp:375]     Train net output #0: loss = 1.14675 (* 1 = 1.14675 loss)
I0802 10:18:50.062840 18636 sgd_solver.cpp:136] Iteration 118600, lr = 0.0025875, m = 0.9
I0802 10:19:03.978341 18636 solver.cpp:353] Iteration 118700 (7.18638 iter/s, 13.9152s/100 iter), loss = 1.68054
I0802 10:19:03.978369 18636 solver.cpp:375]     Train net output #0: loss = 1.66131 (* 1 = 1.66131 loss)
I0802 10:19:03.978375 18636 sgd_solver.cpp:136] Iteration 118700, lr = 0.00258125, m = 0.9
I0802 10:19:17.980592 18636 solver.cpp:353] Iteration 118800 (7.14191 iter/s, 14.0019s/100 iter), loss = 1.31926
I0802 10:19:17.980620 18636 solver.cpp:375]     Train net output #0: loss = 1.39081 (* 1 = 1.39081 loss)
I0802 10:19:17.980625 18636 sgd_solver.cpp:136] Iteration 118800, lr = 0.002575, m = 0.9
I0802 10:19:31.868602 18636 solver.cpp:353] Iteration 118900 (7.20065 iter/s, 13.8876s/100 iter), loss = 1.2019
I0802 10:19:31.868656 18636 solver.cpp:375]     Train net output #0: loss = 1.15696 (* 1 = 1.15696 loss)
I0802 10:19:31.868664 18636 sgd_solver.cpp:136] Iteration 118900, lr = 0.00256875, m = 0.9
I0802 10:19:45.675964 18636 solver.cpp:404] Sparsity after update:
I0802 10:19:45.686460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:19:45.686477 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:19:45.686487 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:19:45.686491 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:19:45.686494 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:19:45.686497 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:19:45.686501 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:19:45.686511 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:19:45.686513 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:19:45.686518 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:19:45.686523 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:19:45.686527 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:19:45.686532 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:19:45.817364 18636 solver.cpp:353] Iteration 119000 (7.16929 iter/s, 13.9484s/100 iter), loss = 1.21921
I0802 10:19:45.817392 18636 solver.cpp:375]     Train net output #0: loss = 1.27606 (* 1 = 1.27606 loss)
I0802 10:19:45.817399 18636 sgd_solver.cpp:136] Iteration 119000, lr = 0.0025625, m = 0.9
I0802 10:19:59.843375 18636 solver.cpp:353] Iteration 119100 (7.12981 iter/s, 14.0256s/100 iter), loss = 1.33124
I0802 10:19:59.843405 18636 solver.cpp:375]     Train net output #0: loss = 1.66949 (* 1 = 1.66949 loss)
I0802 10:19:59.843411 18636 sgd_solver.cpp:136] Iteration 119100, lr = 0.00255625, m = 0.9
I0802 10:20:13.938814 18636 solver.cpp:353] Iteration 119200 (7.09469 iter/s, 14.095s/100 iter), loss = 1.07882
I0802 10:20:13.938899 18636 solver.cpp:375]     Train net output #0: loss = 0.845329 (* 1 = 0.845329 loss)
I0802 10:20:13.938906 18636 sgd_solver.cpp:136] Iteration 119200, lr = 0.00255, m = 0.9
I0802 10:20:27.906287 18636 solver.cpp:353] Iteration 119300 (7.15969 iter/s, 13.9671s/100 iter), loss = 1.06553
I0802 10:20:27.906555 18636 solver.cpp:375]     Train net output #0: loss = 1.14193 (* 1 = 1.14193 loss)
I0802 10:20:27.906677 18636 sgd_solver.cpp:136] Iteration 119300, lr = 0.00254375, m = 0.9
I0802 10:20:41.896365 18636 solver.cpp:353] Iteration 119400 (7.14812 iter/s, 13.9897s/100 iter), loss = 1.38762
I0802 10:20:41.896394 18636 solver.cpp:375]     Train net output #0: loss = 1.08779 (* 1 = 1.08779 loss)
I0802 10:20:41.896399 18636 sgd_solver.cpp:136] Iteration 119400, lr = 0.0025375, m = 0.9
I0802 10:20:55.820029 18636 solver.cpp:353] Iteration 119500 (7.18222 iter/s, 13.9233s/100 iter), loss = 1.42313
I0802 10:20:55.820127 18636 solver.cpp:375]     Train net output #0: loss = 0.943013 (* 1 = 0.943013 loss)
I0802 10:20:55.820137 18636 sgd_solver.cpp:136] Iteration 119500, lr = 0.00253125, m = 0.9
I0802 10:21:09.774708 18636 solver.cpp:353] Iteration 119600 (7.16626 iter/s, 13.9543s/100 iter), loss = 1.45692
I0802 10:21:09.774731 18636 solver.cpp:375]     Train net output #0: loss = 1.65854 (* 1 = 1.65854 loss)
I0802 10:21:09.774735 18636 sgd_solver.cpp:136] Iteration 119600, lr = 0.002525, m = 0.9
I0802 10:21:23.687458 18636 solver.cpp:353] Iteration 119700 (7.18785 iter/s, 13.9124s/100 iter), loss = 1.09034
I0802 10:21:23.687487 18636 solver.cpp:375]     Train net output #0: loss = 0.988528 (* 1 = 0.988528 loss)
I0802 10:21:23.687494 18636 sgd_solver.cpp:136] Iteration 119700, lr = 0.00251875, m = 0.9
I0802 10:21:37.681584 18636 solver.cpp:353] Iteration 119800 (7.14605 iter/s, 13.9937s/100 iter), loss = 1.52346
I0802 10:21:37.681666 18636 solver.cpp:375]     Train net output #0: loss = 1.32251 (* 1 = 1.32251 loss)
I0802 10:21:37.681674 18636 sgd_solver.cpp:136] Iteration 119800, lr = 0.0025125, m = 0.9
I0802 10:21:51.838387 18636 solver.cpp:353] Iteration 119900 (7.06394 iter/s, 14.1564s/100 iter), loss = 1.26304
I0802 10:21:51.838414 18636 solver.cpp:375]     Train net output #0: loss = 1.19972 (* 1 = 1.19972 loss)
I0802 10:21:51.838420 18636 sgd_solver.cpp:136] Iteration 119900, lr = 0.00250625, m = 0.9
I0802 10:22:05.583375 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_120000.caffemodel
I0802 10:22:05.637727 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_120000.solverstate
I0802 10:22:05.644142 18636 solver.cpp:404] Sparsity after update:
I0802 10:22:05.648171 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:22:05.648187 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:22:05.648196 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:22:05.648200 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:22:05.648203 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:22:05.648206 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:22:05.648210 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:22:05.648212 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:22:05.648216 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:22:05.648218 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:22:05.648221 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:22:05.648224 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:22:05.648227 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:22:05.648238 18636 solver.cpp:550] Iteration 120000, Testing net (#0)
I0802 10:22:06.212010 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:22:26.146622 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.588353
I0802 10:22:26.146718 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816174
I0802 10:22:26.146728 18636 solver.cpp:635]     Test net output #2: loss = 1.79882 (* 1 = 1.79882 loss)
I0802 10:22:26.146746 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.4979s
I0802 10:22:26.285859 18636 solver.cpp:353] Iteration 120000 (2.90305 iter/s, 34.4465s/100 iter), loss = 1.53001
I0802 10:22:26.285887 18636 solver.cpp:375]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0802 10:22:26.285892 18636 sgd_solver.cpp:136] Iteration 120000, lr = 0.0025, m = 0.9
I0802 10:22:40.444013 18636 solver.cpp:353] Iteration 120100 (7.06326 iter/s, 14.1578s/100 iter), loss = 1.50322
I0802 10:22:40.444042 18636 solver.cpp:375]     Train net output #0: loss = 1.85385 (* 1 = 1.85385 loss)
I0802 10:22:40.444048 18636 sgd_solver.cpp:136] Iteration 120100, lr = 0.00249375, m = 0.9
I0802 10:22:54.430203 18636 solver.cpp:353] Iteration 120200 (7.15011 iter/s, 13.9858s/100 iter), loss = 1.73912
I0802 10:22:54.430232 18636 solver.cpp:375]     Train net output #0: loss = 1.46637 (* 1 = 1.46637 loss)
I0802 10:22:54.430238 18636 sgd_solver.cpp:136] Iteration 120200, lr = 0.0024875, m = 0.9
I0802 10:23:08.341454 18636 solver.cpp:353] Iteration 120300 (7.18863 iter/s, 13.9109s/100 iter), loss = 1.57143
I0802 10:23:08.341542 18636 solver.cpp:375]     Train net output #0: loss = 0.853292 (* 1 = 0.853292 loss)
I0802 10:23:08.341547 18636 sgd_solver.cpp:136] Iteration 120300, lr = 0.00248125, m = 0.9
I0802 10:23:22.193362 18636 solver.cpp:353] Iteration 120400 (7.21942 iter/s, 13.8515s/100 iter), loss = 1.2672
I0802 10:23:22.193387 18636 solver.cpp:375]     Train net output #0: loss = 1.10881 (* 1 = 1.10881 loss)
I0802 10:23:22.193392 18636 sgd_solver.cpp:136] Iteration 120400, lr = 0.002475, m = 0.9
I0802 10:23:36.225322 18636 solver.cpp:353] Iteration 120500 (7.12679 iter/s, 14.0316s/100 iter), loss = 1.64652
I0802 10:23:36.225352 18636 solver.cpp:375]     Train net output #0: loss = 1.34888 (* 1 = 1.34888 loss)
I0802 10:23:36.225358 18636 sgd_solver.cpp:136] Iteration 120500, lr = 0.00246875, m = 0.9
I0802 10:23:50.336848 18636 solver.cpp:353] Iteration 120600 (7.0866 iter/s, 14.1111s/100 iter), loss = 1.14811
I0802 10:23:50.336910 18636 solver.cpp:375]     Train net output #0: loss = 1.13971 (* 1 = 1.13971 loss)
I0802 10:23:50.336916 18636 sgd_solver.cpp:136] Iteration 120600, lr = 0.0024625, m = 0.9
I0802 10:24:04.302829 18636 solver.cpp:353] Iteration 120700 (7.16046 iter/s, 13.9656s/100 iter), loss = 1.04241
I0802 10:24:04.302858 18636 solver.cpp:375]     Train net output #0: loss = 0.688617 (* 1 = 0.688617 loss)
I0802 10:24:04.302865 18636 sgd_solver.cpp:136] Iteration 120700, lr = 0.00245625, m = 0.9
I0802 10:24:18.390738 18636 solver.cpp:353] Iteration 120800 (7.09848 iter/s, 14.0875s/100 iter), loss = 1.70143
I0802 10:24:18.390769 18636 solver.cpp:375]     Train net output #0: loss = 1.68669 (* 1 = 1.68669 loss)
I0802 10:24:18.390774 18636 sgd_solver.cpp:136] Iteration 120800, lr = 0.00245, m = 0.9
I0802 10:24:32.308394 18636 solver.cpp:353] Iteration 120900 (7.18532 iter/s, 13.9173s/100 iter), loss = 1.18431
I0802 10:24:32.308470 18636 solver.cpp:375]     Train net output #0: loss = 1.15101 (* 1 = 1.15101 loss)
I0802 10:24:32.308476 18636 sgd_solver.cpp:136] Iteration 120900, lr = 0.00244375, m = 0.9
I0802 10:24:46.126444 18636 solver.cpp:404] Sparsity after update:
I0802 10:24:46.137917 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:24:46.137930 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:24:46.137939 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:24:46.137943 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:24:46.137956 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:24:46.137965 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:24:46.137974 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:24:46.137982 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:24:46.137991 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:24:46.138000 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:24:46.138008 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:24:46.138021 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:24:46.138027 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:24:46.267364 18636 solver.cpp:353] Iteration 121000 (7.16405 iter/s, 13.9586s/100 iter), loss = 1.30205
I0802 10:24:46.267390 18636 solver.cpp:375]     Train net output #0: loss = 1.03801 (* 1 = 1.03801 loss)
I0802 10:24:46.267395 18636 sgd_solver.cpp:136] Iteration 121000, lr = 0.0024375, m = 0.9
I0802 10:25:00.232249 18636 solver.cpp:353] Iteration 121100 (7.16102 iter/s, 13.9645s/100 iter), loss = 1.41153
I0802 10:25:00.232272 18636 solver.cpp:375]     Train net output #0: loss = 1.40017 (* 1 = 1.40017 loss)
I0802 10:25:00.232276 18636 sgd_solver.cpp:136] Iteration 121100, lr = 0.00243125, m = 0.9
I0802 10:25:14.275840 18636 solver.cpp:353] Iteration 121200 (7.12088 iter/s, 14.0432s/100 iter), loss = 1.72838
I0802 10:25:14.275909 18636 solver.cpp:375]     Train net output #0: loss = 1.53963 (* 1 = 1.53963 loss)
I0802 10:25:14.275914 18636 sgd_solver.cpp:136] Iteration 121200, lr = 0.002425, m = 0.9
I0802 10:25:28.200256 18636 solver.cpp:353] Iteration 121300 (7.18183 iter/s, 13.924s/100 iter), loss = 1.56015
I0802 10:25:28.200286 18636 solver.cpp:375]     Train net output #0: loss = 1.16389 (* 1 = 1.16389 loss)
I0802 10:25:28.200291 18636 sgd_solver.cpp:136] Iteration 121300, lr = 0.00241875, m = 0.9
I0802 10:25:42.171277 18636 solver.cpp:353] Iteration 121400 (7.15787 iter/s, 13.9706s/100 iter), loss = 1.38161
I0802 10:25:42.171304 18636 solver.cpp:375]     Train net output #0: loss = 0.921456 (* 1 = 0.921456 loss)
I0802 10:25:42.171309 18636 sgd_solver.cpp:136] Iteration 121400, lr = 0.0024125, m = 0.9
I0802 10:25:56.272372 18636 solver.cpp:353] Iteration 121500 (7.09185 iter/s, 14.1007s/100 iter), loss = 1.4821
I0802 10:25:56.276852 18636 solver.cpp:375]     Train net output #0: loss = 1.45402 (* 1 = 1.45402 loss)
I0802 10:25:56.276875 18636 sgd_solver.cpp:136] Iteration 121500, lr = 0.00240625, m = 0.9
I0802 10:26:10.303227 18636 solver.cpp:353] Iteration 121600 (7.12735 iter/s, 14.0305s/100 iter), loss = 1.55965
I0802 10:26:10.303267 18636 solver.cpp:375]     Train net output #0: loss = 1.42389 (* 1 = 1.42389 loss)
I0802 10:26:10.303275 18636 sgd_solver.cpp:136] Iteration 121600, lr = 0.0024, m = 0.9
I0802 10:26:24.324072 18636 solver.cpp:353] Iteration 121700 (7.13243 iter/s, 14.0205s/100 iter), loss = 1.40915
I0802 10:26:24.324102 18636 solver.cpp:375]     Train net output #0: loss = 1.43191 (* 1 = 1.43191 loss)
I0802 10:26:24.324108 18636 sgd_solver.cpp:136] Iteration 121700, lr = 0.00239375, m = 0.9
I0802 10:26:38.448526 18636 solver.cpp:353] Iteration 121800 (7.08012 iter/s, 14.1241s/100 iter), loss = 1.36707
I0802 10:26:38.448606 18636 solver.cpp:375]     Train net output #0: loss = 1.43998 (* 1 = 1.43998 loss)
I0802 10:26:38.448612 18636 sgd_solver.cpp:136] Iteration 121800, lr = 0.0023875, m = 0.9
I0802 10:26:52.481994 18636 solver.cpp:353] Iteration 121900 (7.12602 iter/s, 14.0331s/100 iter), loss = 1.64323
I0802 10:26:52.482023 18636 solver.cpp:375]     Train net output #0: loss = 1.60681 (* 1 = 1.60681 loss)
I0802 10:26:52.482029 18636 sgd_solver.cpp:136] Iteration 121900, lr = 0.00238125, m = 0.9
I0802 10:27:06.394404 18636 solver.cpp:404] Sparsity after update:
I0802 10:27:06.398707 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:27:06.398720 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:27:06.398855 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:27:06.398900 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:27:06.398939 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:27:06.398982 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:27:06.399022 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:27:06.399062 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:27:06.399103 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:27:06.399143 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:27:06.399184 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:27:06.399224 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:27:06.399265 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:27:06.399281 18636 solver.cpp:550] Iteration 122000, Testing net (#0)
I0802 10:27:25.634285 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.585529
I0802 10:27:25.634410 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810644
I0802 10:27:25.634419 18636 solver.cpp:635]     Test net output #2: loss = 1.82079 (* 1 = 1.82079 loss)
I0802 10:27:25.634438 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2346s
I0802 10:27:25.772424 18636 solver.cpp:353] Iteration 122000 (3.00395 iter/s, 33.2895s/100 iter), loss = 1.28656
I0802 10:27:25.772476 18636 solver.cpp:375]     Train net output #0: loss = 1.17683 (* 1 = 1.17683 loss)
I0802 10:27:25.772488 18636 sgd_solver.cpp:136] Iteration 122000, lr = 0.002375, m = 0.9
I0802 10:27:39.830593 18636 solver.cpp:353] Iteration 122100 (7.1135 iter/s, 14.0578s/100 iter), loss = 1.39148
I0802 10:27:39.830622 18636 solver.cpp:375]     Train net output #0: loss = 1.37227 (* 1 = 1.37227 loss)
I0802 10:27:39.830628 18636 sgd_solver.cpp:136] Iteration 122100, lr = 0.00236875, m = 0.9
I0802 10:27:53.869428 18636 solver.cpp:353] Iteration 122200 (7.1233 iter/s, 14.0384s/100 iter), loss = 1.21639
I0802 10:27:53.869457 18636 solver.cpp:375]     Train net output #0: loss = 1.20847 (* 1 = 1.20847 loss)
I0802 10:27:53.869463 18636 sgd_solver.cpp:136] Iteration 122200, lr = 0.0023625, m = 0.9
I0802 10:28:07.882468 18636 solver.cpp:353] Iteration 122300 (7.13641 iter/s, 14.0126s/100 iter), loss = 1.42819
I0802 10:28:07.882542 18636 solver.cpp:375]     Train net output #0: loss = 1.38671 (* 1 = 1.38671 loss)
I0802 10:28:07.882550 18636 sgd_solver.cpp:136] Iteration 122300, lr = 0.00235625, m = 0.9
I0802 10:28:22.048732 18636 solver.cpp:353] Iteration 122400 (7.05922 iter/s, 14.1659s/100 iter), loss = 1.21884
I0802 10:28:22.048836 18636 solver.cpp:375]     Train net output #0: loss = 1.33957 (* 1 = 1.33957 loss)
I0802 10:28:22.048847 18636 sgd_solver.cpp:136] Iteration 122400, lr = 0.00235, m = 0.9
I0802 10:28:36.098235 18636 solver.cpp:353] Iteration 122500 (7.11789 iter/s, 14.0491s/100 iter), loss = 1.30233
I0802 10:28:36.098258 18636 solver.cpp:375]     Train net output #0: loss = 1.22268 (* 1 = 1.22268 loss)
I0802 10:28:36.098263 18636 sgd_solver.cpp:136] Iteration 122500, lr = 0.00234375, m = 0.9
I0802 10:28:50.216099 18636 solver.cpp:353] Iteration 122600 (7.08342 iter/s, 14.1175s/100 iter), loss = 1.46555
I0802 10:28:50.216159 18636 solver.cpp:375]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I0802 10:28:50.216166 18636 sgd_solver.cpp:136] Iteration 122600, lr = 0.0023375, m = 0.9
I0802 10:29:04.175253 18636 solver.cpp:353] Iteration 122700 (7.16396 iter/s, 13.9588s/100 iter), loss = 1.48203
I0802 10:29:04.175282 18636 solver.cpp:375]     Train net output #0: loss = 1.64611 (* 1 = 1.64611 loss)
I0802 10:29:04.175285 18636 sgd_solver.cpp:136] Iteration 122700, lr = 0.00233125, m = 0.9
I0802 10:29:18.254364 18636 solver.cpp:353] Iteration 122800 (7.10292 iter/s, 14.0787s/100 iter), loss = 1.62132
I0802 10:29:18.254391 18636 solver.cpp:375]     Train net output #0: loss = 1.39254 (* 1 = 1.39254 loss)
I0802 10:29:18.254397 18636 sgd_solver.cpp:136] Iteration 122800, lr = 0.002325, m = 0.9
I0802 10:29:32.232586 18636 solver.cpp:353] Iteration 122900 (7.15418 iter/s, 13.9778s/100 iter), loss = 1.43189
I0802 10:29:32.232653 18636 solver.cpp:375]     Train net output #0: loss = 1.72661 (* 1 = 1.72661 loss)
I0802 10:29:32.232661 18636 sgd_solver.cpp:136] Iteration 122900, lr = 0.00231875, m = 0.9
I0802 10:29:46.085816 18636 solver.cpp:404] Sparsity after update:
I0802 10:29:46.097561 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:29:46.097579 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:29:46.097586 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:29:46.097590 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:29:46.097594 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:29:46.097597 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:29:46.097600 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:29:46.097604 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:29:46.097606 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:29:46.097609 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:29:46.097612 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:29:46.097616 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:29:46.097620 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:29:46.226452 18636 solver.cpp:353] Iteration 123000 (7.14619 iter/s, 13.9935s/100 iter), loss = 1.49119
I0802 10:29:46.226481 18636 solver.cpp:375]     Train net output #0: loss = 1.45813 (* 1 = 1.45813 loss)
I0802 10:29:46.226487 18636 sgd_solver.cpp:136] Iteration 123000, lr = 0.0023125, m = 0.9
I0802 10:30:00.266937 18636 solver.cpp:353] Iteration 123100 (7.12246 iter/s, 14.0401s/100 iter), loss = 1.32709
I0802 10:30:00.266961 18636 solver.cpp:375]     Train net output #0: loss = 1.72187 (* 1 = 1.72187 loss)
I0802 10:30:00.266968 18636 sgd_solver.cpp:136] Iteration 123100, lr = 0.00230625, m = 0.9
I0802 10:30:14.621865 18636 solver.cpp:353] Iteration 123200 (6.96644 iter/s, 14.3545s/100 iter), loss = 1.59676
I0802 10:30:14.621942 18636 solver.cpp:375]     Train net output #0: loss = 1.39444 (* 1 = 1.39444 loss)
I0802 10:30:14.621948 18636 sgd_solver.cpp:136] Iteration 123200, lr = 0.0023, m = 0.9
I0802 10:30:28.610344 18636 solver.cpp:353] Iteration 123300 (7.14894 iter/s, 13.9881s/100 iter), loss = 1.55918
I0802 10:30:28.610374 18636 solver.cpp:375]     Train net output #0: loss = 1.23413 (* 1 = 1.23413 loss)
I0802 10:30:28.610380 18636 sgd_solver.cpp:136] Iteration 123300, lr = 0.00229375, m = 0.9
I0802 10:30:42.548075 18636 solver.cpp:353] Iteration 123400 (7.17497 iter/s, 13.9373s/100 iter), loss = 1.41108
I0802 10:30:42.548104 18636 solver.cpp:375]     Train net output #0: loss = 1.50678 (* 1 = 1.50678 loss)
I0802 10:30:42.548108 18636 sgd_solver.cpp:136] Iteration 123400, lr = 0.0022875, m = 0.9
I0802 10:30:56.449455 18636 solver.cpp:353] Iteration 123500 (7.19373 iter/s, 13.901s/100 iter), loss = 1.21396
I0802 10:30:56.449530 18636 solver.cpp:375]     Train net output #0: loss = 1.02108 (* 1 = 1.02108 loss)
I0802 10:30:56.449537 18636 sgd_solver.cpp:136] Iteration 123500, lr = 0.00228125, m = 0.9
I0802 10:31:10.353868 18636 solver.cpp:353] Iteration 123600 (7.19216 iter/s, 13.904s/100 iter), loss = 1.37475
I0802 10:31:10.353899 18636 solver.cpp:375]     Train net output #0: loss = 1.4133 (* 1 = 1.4133 loss)
I0802 10:31:10.353904 18636 sgd_solver.cpp:136] Iteration 123600, lr = 0.002275, m = 0.9
I0802 10:31:24.194486 18636 solver.cpp:353] Iteration 123700 (7.22531 iter/s, 13.8402s/100 iter), loss = 1.54896
I0802 10:31:24.194512 18636 solver.cpp:375]     Train net output #0: loss = 1.69741 (* 1 = 1.69741 loss)
I0802 10:31:24.194517 18636 sgd_solver.cpp:136] Iteration 123700, lr = 0.00226875, m = 0.9
I0802 10:31:38.192493 18636 solver.cpp:353] Iteration 123800 (7.14407 iter/s, 13.9976s/100 iter), loss = 1.10141
I0802 10:31:38.192576 18636 solver.cpp:375]     Train net output #0: loss = 1.31106 (* 1 = 1.31106 loss)
I0802 10:31:38.192584 18636 sgd_solver.cpp:136] Iteration 123800, lr = 0.0022625, m = 0.9
I0802 10:31:52.087831 18636 solver.cpp:353] Iteration 123900 (7.19686 iter/s, 13.8949s/100 iter), loss = 1.56661
I0802 10:31:52.087863 18636 solver.cpp:375]     Train net output #0: loss = 1.74073 (* 1 = 1.74073 loss)
I0802 10:31:52.087869 18636 sgd_solver.cpp:136] Iteration 123900, lr = 0.00225625, m = 0.9
I0802 10:32:06.010910 18636 solver.cpp:404] Sparsity after update:
I0802 10:32:06.016975 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:32:06.016989 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:32:06.016999 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:32:06.017004 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:32:06.017071 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:32:06.017077 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:32:06.017081 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:32:06.017084 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:32:06.017087 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:32:06.017091 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:32:06.017093 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:32:06.017097 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:32:06.017101 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:32:06.017112 18636 solver.cpp:550] Iteration 124000, Testing net (#0)
I0802 10:32:25.209769 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.58747
I0802 10:32:25.209904 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816879
I0802 10:32:25.209913 18636 solver.cpp:635]     Test net output #2: loss = 1.80071 (* 1 = 1.80071 loss)
I0802 10:32:25.209935 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1923s
I0802 10:32:25.349867 18636 solver.cpp:353] Iteration 124000 (3.00651 iter/s, 33.2611s/100 iter), loss = 1.53339
I0802 10:32:25.349896 18636 solver.cpp:375]     Train net output #0: loss = 1.42815 (* 1 = 1.42815 loss)
I0802 10:32:25.349902 18636 sgd_solver.cpp:136] Iteration 124000, lr = 0.00225, m = 0.9
I0802 10:32:39.252344 18636 solver.cpp:353] Iteration 124100 (7.19316 iter/s, 13.9021s/100 iter), loss = 1.39585
I0802 10:32:39.252372 18636 solver.cpp:375]     Train net output #0: loss = 1.27577 (* 1 = 1.27577 loss)
I0802 10:32:39.252378 18636 sgd_solver.cpp:136] Iteration 124100, lr = 0.00224375, m = 0.9
I0802 10:32:53.284677 18636 solver.cpp:353] Iteration 124200 (7.1266 iter/s, 14.0319s/100 iter), loss = 1.52668
I0802 10:32:53.284771 18636 solver.cpp:375]     Train net output #0: loss = 1.14951 (* 1 = 1.14951 loss)
I0802 10:32:53.284791 18636 sgd_solver.cpp:136] Iteration 124200, lr = 0.0022375, m = 0.9
I0802 10:33:07.197041 18636 solver.cpp:353] Iteration 124300 (7.18805 iter/s, 13.912s/100 iter), loss = 1.25
I0802 10:33:07.197103 18636 solver.cpp:375]     Train net output #0: loss = 1.36511 (* 1 = 1.36511 loss)
I0802 10:33:07.197110 18636 sgd_solver.cpp:136] Iteration 124300, lr = 0.00223125, m = 0.9
I0802 10:33:21.067073 18636 solver.cpp:353] Iteration 124400 (7.20999 iter/s, 13.8696s/100 iter), loss = 1.3178
I0802 10:33:21.067108 18636 solver.cpp:375]     Train net output #0: loss = 1.58009 (* 1 = 1.58009 loss)
I0802 10:33:21.067114 18636 sgd_solver.cpp:136] Iteration 124400, lr = 0.002225, m = 0.9
I0802 10:33:34.973579 18636 solver.cpp:353] Iteration 124500 (7.19108 iter/s, 13.9061s/100 iter), loss = 1.49912
I0802 10:33:34.973634 18636 solver.cpp:375]     Train net output #0: loss = 1.37536 (* 1 = 1.37536 loss)
I0802 10:33:34.973646 18636 sgd_solver.cpp:136] Iteration 124500, lr = 0.00221875, m = 0.9
I0802 10:33:48.926632 18636 solver.cpp:353] Iteration 124600 (7.16709 iter/s, 13.9527s/100 iter), loss = 1.36149
I0802 10:33:48.926705 18636 solver.cpp:375]     Train net output #0: loss = 1.34846 (* 1 = 1.34846 loss)
I0802 10:33:48.926712 18636 sgd_solver.cpp:136] Iteration 124600, lr = 0.0022125, m = 0.9
I0802 10:34:02.846715 18636 solver.cpp:353] Iteration 124700 (7.18406 iter/s, 13.9197s/100 iter), loss = 1.38187
I0802 10:34:02.846745 18636 solver.cpp:375]     Train net output #0: loss = 1.22883 (* 1 = 1.22883 loss)
I0802 10:34:02.846750 18636 sgd_solver.cpp:136] Iteration 124700, lr = 0.00220625, m = 0.9
I0802 10:34:16.934561 18636 solver.cpp:353] Iteration 124800 (7.09852 iter/s, 14.0875s/100 iter), loss = 1.28286
I0802 10:34:16.934658 18636 solver.cpp:375]     Train net output #0: loss = 1.0544 (* 1 = 1.0544 loss)
I0802 10:34:16.934679 18636 sgd_solver.cpp:136] Iteration 124800, lr = 0.0022, m = 0.9
I0802 10:34:31.009464 18636 solver.cpp:353] Iteration 124900 (7.10504 iter/s, 14.0745s/100 iter), loss = 1.40133
I0802 10:34:31.009569 18636 solver.cpp:375]     Train net output #0: loss = 1.39136 (* 1 = 1.39136 loss)
I0802 10:34:31.009578 18636 sgd_solver.cpp:136] Iteration 124900, lr = 0.00219375, m = 0.9
I0802 10:34:44.811422 18636 solver.cpp:404] Sparsity after update:
I0802 10:34:44.822659 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:34:44.822718 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:34:44.822739 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:34:44.822751 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:34:44.822759 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:34:44.822768 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:34:44.822777 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:34:44.822785 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:34:44.822793 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:34:44.822803 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:34:44.822811 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:34:44.822819 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:34:44.822827 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:34:44.952342 18636 solver.cpp:353] Iteration 125000 (7.17232 iter/s, 13.9425s/100 iter), loss = 1.6776
I0802 10:34:44.952373 18636 solver.cpp:375]     Train net output #0: loss = 1.30366 (* 1 = 1.30366 loss)
I0802 10:34:44.952380 18636 sgd_solver.cpp:136] Iteration 125000, lr = 0.0021875, m = 0.9
I0802 10:34:58.987972 18636 solver.cpp:353] Iteration 125100 (7.12492 iter/s, 14.0352s/100 iter), loss = 1.37337
I0802 10:34:58.987999 18636 solver.cpp:375]     Train net output #0: loss = 1.268 (* 1 = 1.268 loss)
I0802 10:34:58.988006 18636 sgd_solver.cpp:136] Iteration 125100, lr = 0.00218125, m = 0.9
I0802 10:35:12.812402 18636 solver.cpp:353] Iteration 125200 (7.23377 iter/s, 13.824s/100 iter), loss = 0.922937
I0802 10:35:12.812516 18636 solver.cpp:375]     Train net output #0: loss = 0.970998 (* 1 = 0.970998 loss)
I0802 10:35:12.812527 18636 sgd_solver.cpp:136] Iteration 125200, lr = 0.002175, m = 0.9
I0802 10:35:26.966352 18636 solver.cpp:353] Iteration 125300 (7.06536 iter/s, 14.1536s/100 iter), loss = 1.65907
I0802 10:35:26.966406 18636 solver.cpp:375]     Train net output #0: loss = 1.47654 (* 1 = 1.47654 loss)
I0802 10:35:26.966418 18636 sgd_solver.cpp:136] Iteration 125300, lr = 0.00216875, m = 0.9
I0802 10:35:40.866487 18636 solver.cpp:353] Iteration 125400 (7.19437 iter/s, 13.8997s/100 iter), loss = 1.53847
I0802 10:35:40.866511 18636 solver.cpp:375]     Train net output #0: loss = 1.44464 (* 1 = 1.44464 loss)
I0802 10:35:40.866518 18636 sgd_solver.cpp:136] Iteration 125400, lr = 0.0021625, m = 0.9
I0802 10:35:54.755765 18636 solver.cpp:353] Iteration 125500 (7.2 iter/s, 13.8889s/100 iter), loss = 1.55569
I0802 10:35:54.755822 18636 solver.cpp:375]     Train net output #0: loss = 1.36267 (* 1 = 1.36267 loss)
I0802 10:35:54.755828 18636 sgd_solver.cpp:136] Iteration 125500, lr = 0.00215625, m = 0.9
I0802 10:36:08.673485 18636 solver.cpp:353] Iteration 125600 (7.18528 iter/s, 13.9173s/100 iter), loss = 1.79303
I0802 10:36:08.673509 18636 solver.cpp:375]     Train net output #0: loss = 2.07458 (* 1 = 2.07458 loss)
I0802 10:36:08.673513 18636 sgd_solver.cpp:136] Iteration 125600, lr = 0.00215, m = 0.9
I0802 10:36:22.565158 18636 solver.cpp:353] Iteration 125700 (7.19876 iter/s, 13.8913s/100 iter), loss = 1.44903
I0802 10:36:22.565186 18636 solver.cpp:375]     Train net output #0: loss = 1.50722 (* 1 = 1.50722 loss)
I0802 10:36:22.565192 18636 sgd_solver.cpp:136] Iteration 125700, lr = 0.00214375, m = 0.9
I0802 10:36:36.542999 18636 solver.cpp:353] Iteration 125800 (7.15438 iter/s, 13.9775s/100 iter), loss = 1.30065
I0802 10:36:36.543066 18636 solver.cpp:375]     Train net output #0: loss = 1.45253 (* 1 = 1.45253 loss)
I0802 10:36:36.543073 18636 sgd_solver.cpp:136] Iteration 125800, lr = 0.0021375, m = 0.9
I0802 10:36:50.610205 18636 solver.cpp:353] Iteration 125900 (7.10893 iter/s, 14.0668s/100 iter), loss = 1.37642
I0802 10:36:50.610231 18636 solver.cpp:375]     Train net output #0: loss = 1.4357 (* 1 = 1.4357 loss)
I0802 10:36:50.610235 18636 sgd_solver.cpp:136] Iteration 125900, lr = 0.00213125, m = 0.9
I0802 10:37:04.402117 18636 solver.cpp:404] Sparsity after update:
I0802 10:37:04.406569 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:37:04.406584 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:37:04.406590 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:37:04.406594 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:37:04.406597 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:37:04.406600 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:37:04.406605 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:37:04.406607 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:37:04.406610 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:37:04.406613 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:37:04.406616 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:37:04.406620 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:37:04.406623 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:37:04.406633 18636 solver.cpp:550] Iteration 126000, Testing net (#0)
I0802 10:37:08.091444 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:37:24.099871 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.585823
I0802 10:37:24.099891 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.815056
I0802 10:37:24.099898 18636 solver.cpp:635]     Test net output #2: loss = 1.81104 (* 1 = 1.81104 loss)
I0802 10:37:24.099936 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6928s
I0802 10:37:24.261355 18636 solver.cpp:353] Iteration 126000 (2.97175 iter/s, 33.6502s/100 iter), loss = 1.7184
I0802 10:37:24.261381 18636 solver.cpp:375]     Train net output #0: loss = 1.6471 (* 1 = 1.6471 loss)
I0802 10:37:24.261386 18636 sgd_solver.cpp:136] Iteration 126000, lr = 0.002125, m = 0.9
I0802 10:37:38.251597 18636 solver.cpp:353] Iteration 126100 (7.14804 iter/s, 13.9898s/100 iter), loss = 1.26601
I0802 10:37:38.251664 18636 solver.cpp:375]     Train net output #0: loss = 1.16532 (* 1 = 1.16532 loss)
I0802 10:37:38.251672 18636 sgd_solver.cpp:136] Iteration 126100, lr = 0.00211875, m = 0.9
I0802 10:37:52.253252 18636 solver.cpp:353] Iteration 126200 (7.14221 iter/s, 14.0013s/100 iter), loss = 1.54688
I0802 10:37:52.253278 18636 solver.cpp:375]     Train net output #0: loss = 1.61398 (* 1 = 1.61398 loss)
I0802 10:37:52.253284 18636 sgd_solver.cpp:136] Iteration 126200, lr = 0.0021125, m = 0.9
I0802 10:38:06.199187 18636 solver.cpp:353] Iteration 126300 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.50402
I0802 10:38:06.199215 18636 solver.cpp:375]     Train net output #0: loss = 1.89781 (* 1 = 1.89781 loss)
I0802 10:38:06.199221 18636 sgd_solver.cpp:136] Iteration 126300, lr = 0.00210625, m = 0.9
I0802 10:38:20.063993 18636 solver.cpp:353] Iteration 126400 (7.21271 iter/s, 13.8644s/100 iter), loss = 1.19733
I0802 10:38:20.064137 18636 solver.cpp:375]     Train net output #0: loss = 0.955924 (* 1 = 0.955924 loss)
I0802 10:38:20.064160 18636 sgd_solver.cpp:136] Iteration 126400, lr = 0.0021, m = 0.9
I0802 10:38:34.001648 18636 solver.cpp:353] Iteration 126500 (7.17501 iter/s, 13.9373s/100 iter), loss = 1.76423
I0802 10:38:34.001888 18636 solver.cpp:375]     Train net output #0: loss = 1.6883 (* 1 = 1.6883 loss)
I0802 10:38:34.002009 18636 sgd_solver.cpp:136] Iteration 126500, lr = 0.00209375, m = 0.9
I0802 10:38:47.902889 18636 solver.cpp:353] Iteration 126600 (7.1938 iter/s, 13.9009s/100 iter), loss = 1.4839
I0802 10:38:47.902915 18636 solver.cpp:375]     Train net output #0: loss = 1.32126 (* 1 = 1.32126 loss)
I0802 10:38:47.902920 18636 sgd_solver.cpp:136] Iteration 126600, lr = 0.0020875, m = 0.9
I0802 10:39:01.871222 18636 solver.cpp:353] Iteration 126700 (7.15925 iter/s, 13.9679s/100 iter), loss = 1.29294
I0802 10:39:01.871328 18636 solver.cpp:375]     Train net output #0: loss = 1.37428 (* 1 = 1.37428 loss)
I0802 10:39:01.871335 18636 sgd_solver.cpp:136] Iteration 126700, lr = 0.00208125, m = 0.9
I0802 10:39:15.833292 18636 solver.cpp:353] Iteration 126800 (7.16246 iter/s, 13.9617s/100 iter), loss = 1.13902
I0802 10:39:15.833410 18636 solver.cpp:375]     Train net output #0: loss = 1.36856 (* 1 = 1.36856 loss)
I0802 10:39:15.833432 18636 sgd_solver.cpp:136] Iteration 126800, lr = 0.002075, m = 0.9
I0802 10:39:29.897500 18636 solver.cpp:353] Iteration 126900 (7.11045 iter/s, 14.0638s/100 iter), loss = 1.1546
I0802 10:39:29.897555 18636 solver.cpp:375]     Train net output #0: loss = 1.13853 (* 1 = 1.13853 loss)
I0802 10:39:29.897568 18636 sgd_solver.cpp:136] Iteration 126900, lr = 0.00206875, m = 0.9
I0802 10:39:43.725003 18636 solver.cpp:404] Sparsity after update:
I0802 10:39:43.736534 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:39:43.736549 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:39:43.736558 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:39:43.736562 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:39:43.736573 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:39:43.736582 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:39:43.736591 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:39:43.736600 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:39:43.736609 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:39:43.736618 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:39:43.736626 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:39:43.736639 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:39:43.736647 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:39:43.865221 18636 solver.cpp:353] Iteration 127000 (7.15956 iter/s, 13.9673s/100 iter), loss = 1.32047
I0802 10:39:43.865309 18636 solver.cpp:375]     Train net output #0: loss = 1.56258 (* 1 = 1.56258 loss)
I0802 10:39:43.865329 18636 sgd_solver.cpp:136] Iteration 127000, lr = 0.0020625, m = 0.9
I0802 10:39:57.804968 18636 solver.cpp:353] Iteration 127100 (7.17393 iter/s, 13.9394s/100 iter), loss = 1.37623
I0802 10:39:57.804994 18636 solver.cpp:375]     Train net output #0: loss = 1.5418 (* 1 = 1.5418 loss)
I0802 10:39:57.804999 18636 sgd_solver.cpp:136] Iteration 127100, lr = 0.00205625, m = 0.9
I0802 10:40:11.876392 18636 solver.cpp:353] Iteration 127200 (7.1068 iter/s, 14.071s/100 iter), loss = 1.14033
I0802 10:40:11.876420 18636 solver.cpp:375]     Train net output #0: loss = 1.14445 (* 1 = 1.14445 loss)
I0802 10:40:11.876425 18636 sgd_solver.cpp:136] Iteration 127200, lr = 0.00205, m = 0.9
I0802 10:40:25.795935 18636 solver.cpp:353] Iteration 127300 (7.18434 iter/s, 13.9192s/100 iter), loss = 1.36284
I0802 10:40:25.796000 18636 solver.cpp:375]     Train net output #0: loss = 1.38816 (* 1 = 1.38816 loss)
I0802 10:40:25.796007 18636 sgd_solver.cpp:136] Iteration 127300, lr = 0.00204375, m = 0.9
I0802 10:40:39.758096 18636 solver.cpp:353] Iteration 127400 (7.16241 iter/s, 13.9618s/100 iter), loss = 1.29579
I0802 10:40:39.758123 18636 solver.cpp:375]     Train net output #0: loss = 1.4781 (* 1 = 1.4781 loss)
I0802 10:40:39.758129 18636 sgd_solver.cpp:136] Iteration 127400, lr = 0.0020375, m = 0.9
I0802 10:40:53.801403 18636 solver.cpp:353] Iteration 127500 (7.12103 iter/s, 14.0429s/100 iter), loss = 1.47354
I0802 10:40:53.801434 18636 solver.cpp:375]     Train net output #0: loss = 1.52387 (* 1 = 1.52387 loss)
I0802 10:40:53.801440 18636 sgd_solver.cpp:136] Iteration 127500, lr = 0.00203125, m = 0.9
I0802 10:41:08.015792 18636 solver.cpp:353] Iteration 127600 (7.03532 iter/s, 14.214s/100 iter), loss = 1.32305
I0802 10:41:08.015862 18636 solver.cpp:375]     Train net output #0: loss = 1.61213 (* 1 = 1.61213 loss)
I0802 10:41:08.015918 18636 sgd_solver.cpp:136] Iteration 127600, lr = 0.002025, m = 0.9
I0802 10:41:21.961410 18636 solver.cpp:353] Iteration 127700 (7.17091 iter/s, 13.9452s/100 iter), loss = 1.39618
I0802 10:41:21.961442 18636 solver.cpp:375]     Train net output #0: loss = 1.77732 (* 1 = 1.77732 loss)
I0802 10:41:21.961449 18636 sgd_solver.cpp:136] Iteration 127700, lr = 0.00201875, m = 0.9
I0802 10:41:36.063915 18636 solver.cpp:353] Iteration 127800 (7.09113 iter/s, 14.1021s/100 iter), loss = 1.48899
I0802 10:41:36.063948 18636 solver.cpp:375]     Train net output #0: loss = 1.41362 (* 1 = 1.41362 loss)
I0802 10:41:36.063954 18636 sgd_solver.cpp:136] Iteration 127800, lr = 0.0020125, m = 0.9
I0802 10:41:50.111706 18636 solver.cpp:353] Iteration 127900 (7.11875 iter/s, 14.0474s/100 iter), loss = 1.26211
I0802 10:41:50.111822 18636 solver.cpp:375]     Train net output #0: loss = 1.17691 (* 1 = 1.17691 loss)
I0802 10:41:50.111840 18636 sgd_solver.cpp:136] Iteration 127900, lr = 0.00200625, m = 0.9
I0802 10:42:03.974838 18636 solver.cpp:404] Sparsity after update:
I0802 10:42:03.979104 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:42:03.979147 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:42:03.979166 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:42:03.979179 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:42:03.979192 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:42:03.979212 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:42:03.979235 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:42:03.979249 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:42:03.979261 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:42:03.979276 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:42:03.979290 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:42:03.979307 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:42:03.979321 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:42:03.979342 18636 solver.cpp:550] Iteration 128000, Testing net (#0)
I0802 10:42:23.996559 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584823
I0802 10:42:23.996618 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.815997
I0802 10:42:23.996625 18636 solver.cpp:635]     Test net output #2: loss = 1.79809 (* 1 = 1.79809 loss)
I0802 10:42:23.996644 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0168s
I0802 10:42:24.140820 18636 solver.cpp:353] Iteration 128000 (2.93874 iter/s, 34.0282s/100 iter), loss = 1.22393
I0802 10:42:24.140846 18636 solver.cpp:375]     Train net output #0: loss = 1.30582 (* 1 = 1.30582 loss)
I0802 10:42:24.140851 18636 sgd_solver.cpp:136] Iteration 128000, lr = 0.002, m = 0.9
I0802 10:42:38.227772 18636 solver.cpp:353] Iteration 128100 (7.09896 iter/s, 14.0866s/100 iter), loss = 1.13438
I0802 10:42:38.227799 18636 solver.cpp:375]     Train net output #0: loss = 0.906485 (* 1 = 0.906485 loss)
I0802 10:42:38.227804 18636 sgd_solver.cpp:136] Iteration 128100, lr = 0.00199375, m = 0.9
I0802 10:42:52.226603 18636 solver.cpp:353] Iteration 128200 (7.14365 iter/s, 13.9984s/100 iter), loss = 1.13099
I0802 10:42:52.226629 18636 solver.cpp:375]     Train net output #0: loss = 0.845308 (* 1 = 0.845308 loss)
I0802 10:42:52.226634 18636 sgd_solver.cpp:136] Iteration 128200, lr = 0.0019875, m = 0.9
I0802 10:43:06.366298 18636 solver.cpp:353] Iteration 128300 (7.07249 iter/s, 14.1393s/100 iter), loss = 1.23407
I0802 10:43:06.366443 18636 solver.cpp:375]     Train net output #0: loss = 1.23084 (* 1 = 1.23084 loss)
I0802 10:43:06.366467 18636 sgd_solver.cpp:136] Iteration 128300, lr = 0.00198125, m = 0.9
I0802 10:43:20.296720 18636 solver.cpp:353] Iteration 128400 (7.17873 iter/s, 13.93s/100 iter), loss = 1.37139
I0802 10:43:20.296748 18636 solver.cpp:375]     Train net output #0: loss = 1.58417 (* 1 = 1.58417 loss)
I0802 10:43:20.296754 18636 sgd_solver.cpp:136] Iteration 128400, lr = 0.001975, m = 0.9
I0802 10:43:34.233956 18636 solver.cpp:353] Iteration 128500 (7.17522 iter/s, 13.9368s/100 iter), loss = 1.47294
I0802 10:43:34.234056 18636 solver.cpp:375]     Train net output #0: loss = 1.38609 (* 1 = 1.38609 loss)
I0802 10:43:34.234064 18636 sgd_solver.cpp:136] Iteration 128500, lr = 0.00196875, m = 0.9
I0802 10:43:48.217932 18636 solver.cpp:353] Iteration 128600 (7.15124 iter/s, 13.9836s/100 iter), loss = 1.22176
I0802 10:43:48.218017 18636 solver.cpp:375]     Train net output #0: loss = 1.00287 (* 1 = 1.00287 loss)
I0802 10:43:48.218024 18636 sgd_solver.cpp:136] Iteration 128600, lr = 0.0019625, m = 0.9
I0802 10:44:02.443891 18636 solver.cpp:353] Iteration 128700 (7.0296 iter/s, 14.2256s/100 iter), loss = 1.17207
I0802 10:44:02.443923 18636 solver.cpp:375]     Train net output #0: loss = 0.973115 (* 1 = 0.973115 loss)
I0802 10:44:02.443929 18636 sgd_solver.cpp:136] Iteration 128700, lr = 0.00195625, m = 0.9
I0802 10:44:16.415683 18636 solver.cpp:353] Iteration 128800 (7.15747 iter/s, 13.9714s/100 iter), loss = 1.33028
I0802 10:44:16.415710 18636 solver.cpp:375]     Train net output #0: loss = 1.37935 (* 1 = 1.37935 loss)
I0802 10:44:16.415716 18636 sgd_solver.cpp:136] Iteration 128800, lr = 0.00195, m = 0.9
I0802 10:44:30.392012 18636 solver.cpp:353] Iteration 128900 (7.15515 iter/s, 13.9759s/100 iter), loss = 1.62931
I0802 10:44:30.392855 18636 solver.cpp:375]     Train net output #0: loss = 1.68193 (* 1 = 1.68193 loss)
I0802 10:44:30.392864 18636 sgd_solver.cpp:136] Iteration 128900, lr = 0.00194375, m = 0.9
I0802 10:44:44.248262 18636 solver.cpp:404] Sparsity after update:
I0802 10:44:44.258203 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:44:44.258222 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:44:44.258232 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:44:44.258237 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:44:44.258242 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:44:44.258246 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:44:44.258252 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:44:44.258257 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:44:44.258261 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:44:44.258267 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:44:44.258271 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:44:44.258276 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:44:44.258280 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:44:44.425493 18636 solver.cpp:353] Iteration 129000 (7.12601 iter/s, 14.0331s/100 iter), loss = 1.48048
I0802 10:44:44.425529 18636 solver.cpp:375]     Train net output #0: loss = 1.4718 (* 1 = 1.4718 loss)
I0802 10:44:44.425534 18636 sgd_solver.cpp:136] Iteration 129000, lr = 0.0019375, m = 0.9
I0802 10:44:58.465214 18636 solver.cpp:353] Iteration 129100 (7.12284 iter/s, 14.0393s/100 iter), loss = 1.69769
I0802 10:44:58.465322 18636 solver.cpp:375]     Train net output #0: loss = 1.73979 (* 1 = 1.73979 loss)
I0802 10:44:58.465343 18636 sgd_solver.cpp:136] Iteration 129100, lr = 0.00193125, m = 0.9
I0802 10:44:59.547487 18597 data_reader.cpp:264] Starting prefetch of epoch 4
I0802 10:45:12.472998 18636 solver.cpp:353] Iteration 129200 (7.13909 iter/s, 14.0074s/100 iter), loss = 1.53326
I0802 10:45:12.473099 18636 solver.cpp:375]     Train net output #0: loss = 1.18325 (* 1 = 1.18325 loss)
I0802 10:45:12.473121 18636 sgd_solver.cpp:136] Iteration 129200, lr = 0.001925, m = 0.9
I0802 10:45:26.491858 18636 solver.cpp:353] Iteration 129300 (7.13344 iter/s, 14.0185s/100 iter), loss = 1.07509
I0802 10:45:26.491897 18636 solver.cpp:375]     Train net output #0: loss = 1.10359 (* 1 = 1.10359 loss)
I0802 10:45:26.491904 18636 sgd_solver.cpp:136] Iteration 129300, lr = 0.00191875, m = 0.9
I0802 10:45:40.451555 18636 solver.cpp:353] Iteration 129400 (7.16368 iter/s, 13.9593s/100 iter), loss = 1.48224
I0802 10:45:40.451581 18636 solver.cpp:375]     Train net output #0: loss = 1.35509 (* 1 = 1.35509 loss)
I0802 10:45:40.451586 18636 sgd_solver.cpp:136] Iteration 129400, lr = 0.0019125, m = 0.9
I0802 10:45:54.390617 18636 solver.cpp:353] Iteration 129500 (7.17428 iter/s, 13.9387s/100 iter), loss = 1.10945
I0802 10:45:54.391253 18636 solver.cpp:375]     Train net output #0: loss = 1.41789 (* 1 = 1.41789 loss)
I0802 10:45:54.391258 18636 sgd_solver.cpp:136] Iteration 129500, lr = 0.00190625, m = 0.9
I0802 10:46:08.488770 18636 solver.cpp:353] Iteration 129600 (7.09332 iter/s, 14.0978s/100 iter), loss = 1.80776
I0802 10:46:08.488798 18636 solver.cpp:375]     Train net output #0: loss = 2.38071 (* 1 = 2.38071 loss)
I0802 10:46:08.488804 18636 sgd_solver.cpp:136] Iteration 129600, lr = 0.0019, m = 0.9
I0802 10:46:22.457442 18636 solver.cpp:353] Iteration 129700 (7.15907 iter/s, 13.9683s/100 iter), loss = 1.15136
I0802 10:46:22.457473 18636 solver.cpp:375]     Train net output #0: loss = 1.46839 (* 1 = 1.46839 loss)
I0802 10:46:22.457479 18636 sgd_solver.cpp:136] Iteration 129700, lr = 0.00189375, m = 0.9
I0802 10:46:36.376380 18636 solver.cpp:353] Iteration 129800 (7.18466 iter/s, 13.9186s/100 iter), loss = 1.75692
I0802 10:46:36.376508 18636 solver.cpp:375]     Train net output #0: loss = 1.80477 (* 1 = 1.80477 loss)
I0802 10:46:36.376523 18636 sgd_solver.cpp:136] Iteration 129800, lr = 0.0018875, m = 0.9
I0802 10:46:50.328701 18636 solver.cpp:353] Iteration 129900 (7.16746 iter/s, 13.9519s/100 iter), loss = 1.71175
I0802 10:46:50.328732 18636 solver.cpp:375]     Train net output #0: loss = 1.74195 (* 1 = 1.74195 loss)
I0802 10:46:50.328737 18636 sgd_solver.cpp:136] Iteration 129900, lr = 0.00188125, m = 0.9
I0802 10:47:04.340049 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_130000.caffemodel
I0802 10:47:04.466578 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_130000.solverstate
I0802 10:47:04.471041 18636 solver.cpp:404] Sparsity after update:
I0802 10:47:04.476486 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:47:04.476500 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:47:04.476508 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:47:04.476511 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:47:04.476516 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:47:04.476531 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:47:04.476539 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:47:04.476548 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:47:04.476557 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:47:04.476564 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:47:04.476572 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:47:04.476580 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:47:04.476588 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:47:04.476605 18636 solver.cpp:550] Iteration 130000, Testing net (#0)
I0802 10:47:24.052140 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591
I0802 10:47:24.052251 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817939
I0802 10:47:24.052260 18636 solver.cpp:635]     Test net output #2: loss = 1.78912 (* 1 = 1.78912 loss)
I0802 10:47:24.052280 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5751s
I0802 10:47:24.200960 18636 solver.cpp:353] Iteration 130000 (2.95235 iter/s, 33.8713s/100 iter), loss = 1.23416
I0802 10:47:24.200994 18636 solver.cpp:375]     Train net output #0: loss = 1.4953 (* 1 = 1.4953 loss)
I0802 10:47:24.200999 18636 sgd_solver.cpp:136] Iteration 130000, lr = 0.001875, m = 0.9
I0802 10:47:38.127789 18636 solver.cpp:353] Iteration 130100 (7.18059 iter/s, 13.9264s/100 iter), loss = 1.63635
I0802 10:47:38.127816 18636 solver.cpp:375]     Train net output #0: loss = 1.46394 (* 1 = 1.46394 loss)
I0802 10:47:38.127822 18636 sgd_solver.cpp:136] Iteration 130100, lr = 0.00186875, m = 0.9
I0802 10:47:52.111613 18636 solver.cpp:353] Iteration 130200 (7.15132 iter/s, 13.9834s/100 iter), loss = 1.56229
I0802 10:47:52.111639 18636 solver.cpp:375]     Train net output #0: loss = 1.49774 (* 1 = 1.49774 loss)
I0802 10:47:52.111644 18636 sgd_solver.cpp:136] Iteration 130200, lr = 0.0018625, m = 0.9
I0802 10:48:06.033505 18636 solver.cpp:353] Iteration 130300 (7.18313 iter/s, 13.9215s/100 iter), loss = 1.34422
I0802 10:48:06.033572 18636 solver.cpp:375]     Train net output #0: loss = 1.25499 (* 1 = 1.25499 loss)
I0802 10:48:06.033578 18636 sgd_solver.cpp:136] Iteration 130300, lr = 0.00185625, m = 0.9
I0802 10:48:19.934944 18636 solver.cpp:353] Iteration 130400 (7.1937 iter/s, 13.9011s/100 iter), loss = 1.06763
I0802 10:48:19.935019 18636 solver.cpp:375]     Train net output #0: loss = 1.18339 (* 1 = 1.18339 loss)
I0802 10:48:19.935040 18636 sgd_solver.cpp:136] Iteration 130400, lr = 0.00185, m = 0.9
I0802 10:48:33.892046 18636 solver.cpp:353] Iteration 130500 (7.16501 iter/s, 13.9567s/100 iter), loss = 1.36848
I0802 10:48:33.892072 18636 solver.cpp:375]     Train net output #0: loss = 1.58564 (* 1 = 1.58564 loss)
I0802 10:48:33.892112 18636 sgd_solver.cpp:136] Iteration 130500, lr = 0.00184375, m = 0.9
I0802 10:48:47.788547 18636 solver.cpp:353] Iteration 130600 (7.19626 iter/s, 13.8961s/100 iter), loss = 1.74909
I0802 10:48:47.788676 18636 solver.cpp:375]     Train net output #0: loss = 2.22989 (* 1 = 2.22989 loss)
I0802 10:48:47.788697 18636 sgd_solver.cpp:136] Iteration 130600, lr = 0.0018375, m = 0.9
I0802 10:49:01.820412 18636 solver.cpp:353] Iteration 130700 (7.12683 iter/s, 14.0315s/100 iter), loss = 1.37421
I0802 10:49:01.820521 18636 solver.cpp:375]     Train net output #0: loss = 1.47853 (* 1 = 1.47853 loss)
I0802 10:49:01.820544 18636 sgd_solver.cpp:136] Iteration 130700, lr = 0.00183125, m = 0.9
I0802 10:49:15.827250 18636 solver.cpp:353] Iteration 130800 (7.13957 iter/s, 14.0064s/100 iter), loss = 1.49381
I0802 10:49:15.827323 18636 solver.cpp:375]     Train net output #0: loss = 1.55529 (* 1 = 1.55529 loss)
I0802 10:49:15.827337 18636 sgd_solver.cpp:136] Iteration 130800, lr = 0.001825, m = 0.9
I0802 10:49:29.837476 18636 solver.cpp:353] Iteration 130900 (7.13784 iter/s, 14.0098s/100 iter), loss = 1.20213
I0802 10:49:29.837564 18636 solver.cpp:375]     Train net output #0: loss = 1.23876 (* 1 = 1.23876 loss)
I0802 10:49:29.837574 18636 sgd_solver.cpp:136] Iteration 130900, lr = 0.00181875, m = 0.9
I0802 10:49:43.664014 18636 solver.cpp:404] Sparsity after update:
I0802 10:49:43.675660 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:49:43.675715 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:49:43.675736 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:49:43.675750 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:49:43.675762 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:49:43.675776 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:49:43.675788 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:49:43.675801 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:49:43.675813 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:49:43.675827 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:49:43.675838 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:49:43.675851 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:49:43.675863 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:49:43.822743 18636 solver.cpp:353] Iteration 131000 (7.15058 iter/s, 13.9849s/100 iter), loss = 1.80075
I0802 10:49:43.822808 18636 solver.cpp:375]     Train net output #0: loss = 1.89711 (* 1 = 1.89711 loss)
I0802 10:49:43.822821 18636 sgd_solver.cpp:136] Iteration 131000, lr = 0.0018125, m = 0.9
I0802 10:49:57.780027 18636 solver.cpp:353] Iteration 131100 (7.16492 iter/s, 13.9569s/100 iter), loss = 1.39288
I0802 10:49:57.780109 18636 solver.cpp:375]     Train net output #0: loss = 1.56057 (* 1 = 1.56057 loss)
I0802 10:49:57.780129 18636 sgd_solver.cpp:136] Iteration 131100, lr = 0.00180625, m = 0.9
I0802 10:50:11.700489 18636 solver.cpp:353] Iteration 131200 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.34142
I0802 10:50:11.700542 18636 solver.cpp:375]     Train net output #0: loss = 1.59412 (* 1 = 1.59412 loss)
I0802 10:50:11.700548 18636 sgd_solver.cpp:136] Iteration 131200, lr = 0.0018, m = 0.9
I0802 10:50:25.808435 18636 solver.cpp:353] Iteration 131300 (7.0884 iter/s, 14.1076s/100 iter), loss = 1.45082
I0802 10:50:25.808460 18636 solver.cpp:375]     Train net output #0: loss = 1.51055 (* 1 = 1.51055 loss)
I0802 10:50:25.808465 18636 sgd_solver.cpp:136] Iteration 131300, lr = 0.00179375, m = 0.9
I0802 10:50:39.667026 18636 solver.cpp:353] Iteration 131400 (7.21594 iter/s, 13.8582s/100 iter), loss = 1.20729
I0802 10:50:39.667050 18636 solver.cpp:375]     Train net output #0: loss = 1.2329 (* 1 = 1.2329 loss)
I0802 10:50:39.667057 18636 sgd_solver.cpp:136] Iteration 131400, lr = 0.0017875, m = 0.9
I0802 10:50:53.595650 18636 solver.cpp:353] Iteration 131500 (7.17966 iter/s, 13.9282s/100 iter), loss = 1.7916
I0802 10:50:53.595717 18636 solver.cpp:375]     Train net output #0: loss = 1.81535 (* 1 = 1.81535 loss)
I0802 10:50:53.595723 18636 sgd_solver.cpp:136] Iteration 131500, lr = 0.00178125, m = 0.9
I0802 10:51:07.613113 18636 solver.cpp:353] Iteration 131600 (7.13416 iter/s, 14.0171s/100 iter), loss = 0.818414
I0802 10:51:07.613209 18636 solver.cpp:375]     Train net output #0: loss = 0.6297 (* 1 = 0.6297 loss)
I0802 10:51:07.613230 18636 sgd_solver.cpp:136] Iteration 131600, lr = 0.001775, m = 0.9
I0802 10:51:21.543830 18636 solver.cpp:353] Iteration 131700 (7.17858 iter/s, 13.9303s/100 iter), loss = 1.38166
I0802 10:51:21.543857 18636 solver.cpp:375]     Train net output #0: loss = 1.5634 (* 1 = 1.5634 loss)
I0802 10:51:21.543861 18636 sgd_solver.cpp:136] Iteration 131700, lr = 0.00176875, m = 0.9
I0802 10:51:35.535920 18636 solver.cpp:353] Iteration 131800 (7.14709 iter/s, 13.9917s/100 iter), loss = 1.3804
I0802 10:51:35.536074 18636 solver.cpp:375]     Train net output #0: loss = 1.48057 (* 1 = 1.48057 loss)
I0802 10:51:35.536103 18636 sgd_solver.cpp:136] Iteration 131800, lr = 0.0017625, m = 0.9
I0802 10:51:49.466671 18636 solver.cpp:353] Iteration 131900 (7.17856 iter/s, 13.9304s/100 iter), loss = 1.60318
I0802 10:51:49.466696 18636 solver.cpp:375]     Train net output #0: loss = 1.58725 (* 1 = 1.58725 loss)
I0802 10:51:49.466699 18636 sgd_solver.cpp:136] Iteration 131900, lr = 0.00175625, m = 0.9
I0802 10:52:03.442961 18636 solver.cpp:404] Sparsity after update:
I0802 10:52:03.447903 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:52:03.447921 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:52:03.447928 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:52:03.447932 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:52:03.447935 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:52:03.447940 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:52:03.447945 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:52:03.447948 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:52:03.447952 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:52:03.447955 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:52:03.447958 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:52:03.447962 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:52:03.447968 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:52:03.447979 18636 solver.cpp:550] Iteration 132000, Testing net (#0)
I0802 10:52:10.546973 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:52:23.238548 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591235
I0802 10:52:23.238572 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817055
I0802 10:52:23.238577 18636 solver.cpp:635]     Test net output #2: loss = 1.7854 (* 1 = 1.7854 loss)
I0802 10:52:23.238689 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7902s
I0802 10:52:23.380903 18636 solver.cpp:353] Iteration 132000 (2.9487 iter/s, 33.9133s/100 iter), loss = 1.4178
I0802 10:52:23.380955 18636 solver.cpp:375]     Train net output #0: loss = 1.21796 (* 1 = 1.21796 loss)
I0802 10:52:23.380967 18636 sgd_solver.cpp:136] Iteration 132000, lr = 0.00175, m = 0.9
I0802 10:52:37.280565 18636 solver.cpp:353] Iteration 132100 (7.19462 iter/s, 13.8993s/100 iter), loss = 1.8376
I0802 10:52:37.280591 18636 solver.cpp:375]     Train net output #0: loss = 1.62969 (* 1 = 1.62969 loss)
I0802 10:52:37.280596 18636 sgd_solver.cpp:136] Iteration 132100, lr = 0.00174375, m = 0.9
I0802 10:52:51.247493 18636 solver.cpp:353] Iteration 132200 (7.15997 iter/s, 13.9665s/100 iter), loss = 1.21308
I0802 10:52:51.247591 18636 solver.cpp:375]     Train net output #0: loss = 0.947242 (* 1 = 0.947242 loss)
I0802 10:52:51.247598 18636 sgd_solver.cpp:136] Iteration 132200, lr = 0.0017375, m = 0.9
I0802 10:53:05.135985 18636 solver.cpp:353] Iteration 132300 (7.20041 iter/s, 13.8881s/100 iter), loss = 1.48625
I0802 10:53:05.136066 18636 solver.cpp:375]     Train net output #0: loss = 1.91055 (* 1 = 1.91055 loss)
I0802 10:53:05.136087 18636 sgd_solver.cpp:136] Iteration 132300, lr = 0.00173125, m = 0.9
I0802 10:53:19.086601 18636 solver.cpp:353] Iteration 132400 (7.16834 iter/s, 13.9502s/100 iter), loss = 1.47904
I0802 10:53:19.086638 18636 solver.cpp:375]     Train net output #0: loss = 1.32819 (* 1 = 1.32819 loss)
I0802 10:53:19.086645 18636 sgd_solver.cpp:136] Iteration 132400, lr = 0.001725, m = 0.9
I0802 10:53:32.964922 18636 solver.cpp:353] Iteration 132500 (7.20568 iter/s, 13.8779s/100 iter), loss = 1.19309
I0802 10:53:32.964987 18636 solver.cpp:375]     Train net output #0: loss = 1.24754 (* 1 = 1.24754 loss)
I0802 10:53:32.964994 18636 sgd_solver.cpp:136] Iteration 132500, lr = 0.00171875, m = 0.9
I0802 10:53:47.050106 18636 solver.cpp:353] Iteration 132600 (7.09986 iter/s, 14.0848s/100 iter), loss = 1.36187
I0802 10:53:47.050393 18636 solver.cpp:375]     Train net output #0: loss = 1.28927 (* 1 = 1.28927 loss)
I0802 10:53:47.050510 18636 sgd_solver.cpp:136] Iteration 132600, lr = 0.0017125, m = 0.9
I0802 10:54:00.987725 18636 solver.cpp:353] Iteration 132700 (7.17502 iter/s, 13.9372s/100 iter), loss = 1.45726
I0802 10:54:00.987753 18636 solver.cpp:375]     Train net output #0: loss = 1.40137 (* 1 = 1.40137 loss)
I0802 10:54:00.987758 18636 sgd_solver.cpp:136] Iteration 132700, lr = 0.00170625, m = 0.9
I0802 10:54:14.906196 18636 solver.cpp:353] Iteration 132800 (7.1849 iter/s, 13.9181s/100 iter), loss = 1.34404
I0802 10:54:14.906332 18636 solver.cpp:375]     Train net output #0: loss = 0.924179 (* 1 = 0.924179 loss)
I0802 10:54:14.906352 18636 sgd_solver.cpp:136] Iteration 132800, lr = 0.0017, m = 0.9
I0802 10:54:28.953744 18636 solver.cpp:353] Iteration 132900 (7.11887 iter/s, 14.0472s/100 iter), loss = 1.44871
I0802 10:54:28.953774 18636 solver.cpp:375]     Train net output #0: loss = 1.17802 (* 1 = 1.17802 loss)
I0802 10:54:28.953780 18636 sgd_solver.cpp:136] Iteration 132900, lr = 0.00169375, m = 0.9
I0802 10:54:42.868659 18636 solver.cpp:404] Sparsity after update:
I0802 10:54:42.880317 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:54:42.880329 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:54:42.880336 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:54:42.880338 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:54:42.880340 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:54:42.880342 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:54:42.880344 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:54:42.880347 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:54:42.880348 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:54:42.880350 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:54:42.880352 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:54:42.880357 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:54:42.880359 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:54:43.008481 18636 solver.cpp:353] Iteration 133000 (7.11523 iter/s, 14.0544s/100 iter), loss = 0.94251
I0802 10:54:43.008507 18636 solver.cpp:375]     Train net output #0: loss = 1.01859 (* 1 = 1.01859 loss)
I0802 10:54:43.008512 18636 sgd_solver.cpp:136] Iteration 133000, lr = 0.0016875, m = 0.9
I0802 10:54:57.091567 18636 solver.cpp:353] Iteration 133100 (7.10091 iter/s, 14.0827s/100 iter), loss = 1.41639
I0802 10:54:57.091671 18636 solver.cpp:375]     Train net output #0: loss = 1.55453 (* 1 = 1.55453 loss)
I0802 10:54:57.091691 18636 sgd_solver.cpp:136] Iteration 133100, lr = 0.00168125, m = 0.9
I0802 10:55:11.188513 18636 solver.cpp:353] Iteration 133200 (7.09393 iter/s, 14.0966s/100 iter), loss = 1.26932
I0802 10:55:11.188542 18636 solver.cpp:375]     Train net output #0: loss = 1.34499 (* 1 = 1.34499 loss)
I0802 10:55:11.188547 18636 sgd_solver.cpp:136] Iteration 133200, lr = 0.001675, m = 0.9
I0802 10:55:25.254235 18636 solver.cpp:353] Iteration 133300 (7.10968 iter/s, 14.0653s/100 iter), loss = 1.54261
I0802 10:55:25.254261 18636 solver.cpp:375]     Train net output #0: loss = 1.72605 (* 1 = 1.72605 loss)
I0802 10:55:25.254264 18636 sgd_solver.cpp:136] Iteration 133300, lr = 0.00166875, m = 0.9
I0802 10:55:39.382041 18636 solver.cpp:353] Iteration 133400 (7.07844 iter/s, 14.1274s/100 iter), loss = 1.41054
I0802 10:55:39.382143 18636 solver.cpp:375]     Train net output #0: loss = 1.28096 (* 1 = 1.28096 loss)
I0802 10:55:39.382150 18636 sgd_solver.cpp:136] Iteration 133400, lr = 0.0016625, m = 0.9
I0802 10:55:53.323215 18636 solver.cpp:353] Iteration 133500 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.15845
I0802 10:55:53.323426 18636 solver.cpp:375]     Train net output #0: loss = 1.13737 (* 1 = 1.13737 loss)
I0802 10:55:53.323534 18636 sgd_solver.cpp:136] Iteration 133500, lr = 0.00165625, m = 0.9
I0802 10:56:07.361366 18636 solver.cpp:353] Iteration 133600 (7.12364 iter/s, 14.0378s/100 iter), loss = 1.65164
I0802 10:56:07.361402 18636 solver.cpp:375]     Train net output #0: loss = 1.66275 (* 1 = 1.66275 loss)
I0802 10:56:07.361408 18636 sgd_solver.cpp:136] Iteration 133600, lr = 0.00165, m = 0.9
I0802 10:56:21.460191 18636 solver.cpp:353] Iteration 133700 (7.09299 iter/s, 14.0984s/100 iter), loss = 1.53652
I0802 10:56:21.460314 18636 solver.cpp:375]     Train net output #0: loss = 1.19141 (* 1 = 1.19141 loss)
I0802 10:56:21.460321 18636 sgd_solver.cpp:136] Iteration 133700, lr = 0.00164375, m = 0.9
I0802 10:56:35.675984 18636 solver.cpp:353] Iteration 133800 (7.03462 iter/s, 14.2154s/100 iter), loss = 0.897293
I0802 10:56:35.676010 18636 solver.cpp:375]     Train net output #0: loss = 0.946251 (* 1 = 0.946251 loss)
I0802 10:56:35.676017 18636 sgd_solver.cpp:136] Iteration 133800, lr = 0.0016375, m = 0.9
I0802 10:56:49.785593 18636 solver.cpp:353] Iteration 133900 (7.08756 iter/s, 14.1092s/100 iter), loss = 1.28601
I0802 10:56:49.785620 18636 solver.cpp:375]     Train net output #0: loss = 1.57509 (* 1 = 1.57509 loss)
I0802 10:56:49.785626 18636 sgd_solver.cpp:136] Iteration 133900, lr = 0.00163125, m = 0.9
I0802 10:57:03.689306 18636 solver.cpp:404] Sparsity after update:
I0802 10:57:03.694501 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:57:03.694512 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:57:03.694520 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:57:03.694525 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:57:03.694535 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:57:03.694538 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:57:03.694541 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:57:03.694547 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:57:03.694551 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:57:03.694555 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:57:03.694561 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:57:03.694564 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:57:03.694568 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:57:03.694581 18636 solver.cpp:550] Iteration 134000, Testing net (#0)
I0802 10:57:23.292168 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587177
I0802 10:57:23.292193 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.819527
I0802 10:57:23.292201 18636 solver.cpp:635]     Test net output #2: loss = 1.78841 (* 1 = 1.78841 loss)
I0802 10:57:23.292255 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5971s
I0802 10:57:23.458808 18636 solver.cpp:353] Iteration 134000 (2.9698 iter/s, 33.6723s/100 iter), loss = 1.2957
I0802 10:57:23.458835 18636 solver.cpp:375]     Train net output #0: loss = 1.23551 (* 1 = 1.23551 loss)
I0802 10:57:23.458885 18636 sgd_solver.cpp:136] Iteration 134000, lr = 0.001625, m = 0.9
I0802 10:57:37.694674 18636 solver.cpp:353] Iteration 134100 (7.02471 iter/s, 14.2355s/100 iter), loss = 1.54346
I0802 10:57:37.694749 18636 solver.cpp:375]     Train net output #0: loss = 1.73716 (* 1 = 1.73716 loss)
I0802 10:57:37.694756 18636 sgd_solver.cpp:136] Iteration 134100, lr = 0.00161875, m = 0.9
I0802 10:57:51.661579 18636 solver.cpp:353] Iteration 134200 (7.15998 iter/s, 13.9665s/100 iter), loss = 1.38435
I0802 10:57:51.661607 18636 solver.cpp:375]     Train net output #0: loss = 1.62731 (* 1 = 1.62731 loss)
I0802 10:57:51.661610 18636 sgd_solver.cpp:136] Iteration 134200, lr = 0.0016125, m = 0.9
I0802 10:58:05.657759 18636 solver.cpp:353] Iteration 134300 (7.14501 iter/s, 13.9958s/100 iter), loss = 1.31104
I0802 10:58:05.657791 18636 solver.cpp:375]     Train net output #0: loss = 1.15077 (* 1 = 1.15077 loss)
I0802 10:58:05.657799 18636 sgd_solver.cpp:136] Iteration 134300, lr = 0.00160625, m = 0.9
I0802 10:58:19.878829 18636 solver.cpp:353] Iteration 134400 (7.03202 iter/s, 14.2207s/100 iter), loss = 1.64566
I0802 10:58:19.878907 18636 solver.cpp:375]     Train net output #0: loss = 1.83631 (* 1 = 1.83631 loss)
I0802 10:58:19.878917 18636 sgd_solver.cpp:136] Iteration 134400, lr = 0.0016, m = 0.9
I0802 10:58:33.850033 18636 solver.cpp:353] Iteration 134500 (7.15777 iter/s, 13.9708s/100 iter), loss = 1.27295
I0802 10:58:33.850059 18636 solver.cpp:375]     Train net output #0: loss = 1.41003 (* 1 = 1.41003 loss)
I0802 10:58:33.850064 18636 sgd_solver.cpp:136] Iteration 134500, lr = 0.00159375, m = 0.9
I0802 10:58:47.841738 18636 solver.cpp:353] Iteration 134600 (7.14729 iter/s, 13.9913s/100 iter), loss = 1.50706
I0802 10:58:47.841766 18636 solver.cpp:375]     Train net output #0: loss = 1.10679 (* 1 = 1.10679 loss)
I0802 10:58:47.841773 18636 sgd_solver.cpp:136] Iteration 134600, lr = 0.0015875, m = 0.9
I0802 10:59:01.801584 18636 solver.cpp:353] Iteration 134700 (7.1636 iter/s, 13.9595s/100 iter), loss = 1.54624
I0802 10:59:01.801656 18636 solver.cpp:375]     Train net output #0: loss = 1.53643 (* 1 = 1.53643 loss)
I0802 10:59:01.801663 18636 sgd_solver.cpp:136] Iteration 134700, lr = 0.00158125, m = 0.9
I0802 10:59:15.811053 18636 solver.cpp:353] Iteration 134800 (7.13823 iter/s, 14.0091s/100 iter), loss = 1.05589
I0802 10:59:15.811080 18636 solver.cpp:375]     Train net output #0: loss = 1.26774 (* 1 = 1.26774 loss)
I0802 10:59:15.811086 18636 sgd_solver.cpp:136] Iteration 134800, lr = 0.001575, m = 0.9
I0802 10:59:29.847959 18636 solver.cpp:353] Iteration 134900 (7.12427 iter/s, 14.0365s/100 iter), loss = 1.22279
I0802 10:59:29.847995 18636 solver.cpp:375]     Train net output #0: loss = 1.24797 (* 1 = 1.24797 loss)
I0802 10:59:29.848001 18636 sgd_solver.cpp:136] Iteration 134900, lr = 0.00156875, m = 0.9
I0802 10:59:43.646406 18636 solver.cpp:404] Sparsity after update:
I0802 10:59:43.658041 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:59:43.658061 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:59:43.658071 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:59:43.658074 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:59:43.658078 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:59:43.658082 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:59:43.658085 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:59:43.658089 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:59:43.658093 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:59:43.658097 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:59:43.658099 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:59:43.658103 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:59:43.658120 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:59:43.793201 18636 solver.cpp:353] Iteration 135000 (7.1711 iter/s, 13.9449s/100 iter), loss = 1.75288
I0802 10:59:43.793231 18636 solver.cpp:375]     Train net output #0: loss = 2.34828 (* 1 = 2.34828 loss)
I0802 10:59:43.793238 18636 sgd_solver.cpp:136] Iteration 135000, lr = 0.0015625, m = 0.9
I0802 10:59:57.791503 18636 solver.cpp:353] Iteration 135100 (7.14392 iter/s, 13.9979s/100 iter), loss = 1.98778
I0802 10:59:57.791528 18636 solver.cpp:375]     Train net output #0: loss = 2.11033 (* 1 = 2.11033 loss)
I0802 10:59:57.791533 18636 sgd_solver.cpp:136] Iteration 135100, lr = 0.00155625, m = 0.9
I0802 11:00:11.997627 18636 solver.cpp:353] Iteration 135200 (7.03941 iter/s, 14.2057s/100 iter), loss = 1.80491
I0802 11:00:11.997653 18636 solver.cpp:375]     Train net output #0: loss = 1.89167 (* 1 = 1.89167 loss)
I0802 11:00:11.997658 18636 sgd_solver.cpp:136] Iteration 135200, lr = 0.00155, m = 0.9
I0802 11:00:26.188418 18636 solver.cpp:353] Iteration 135300 (7.04702 iter/s, 14.1904s/100 iter), loss = 1.29216
I0802 11:00:26.188519 18636 solver.cpp:375]     Train net output #0: loss = 1.22987 (* 1 = 1.22987 loss)
I0802 11:00:26.188530 18636 sgd_solver.cpp:136] Iteration 135300, lr = 0.00154375, m = 0.9
I0802 11:00:40.275568 18636 solver.cpp:353] Iteration 135400 (7.09886 iter/s, 14.0868s/100 iter), loss = 1.31622
I0802 11:00:40.275594 18636 solver.cpp:375]     Train net output #0: loss = 1.4844 (* 1 = 1.4844 loss)
I0802 11:00:40.275599 18636 sgd_solver.cpp:136] Iteration 135400, lr = 0.0015375, m = 0.9
I0802 11:00:54.240270 18636 solver.cpp:353] Iteration 135500 (7.16111 iter/s, 13.9643s/100 iter), loss = 1.34158
I0802 11:00:54.240295 18636 solver.cpp:375]     Train net output #0: loss = 0.910261 (* 1 = 0.910261 loss)
I0802 11:00:54.240299 18636 sgd_solver.cpp:136] Iteration 135500, lr = 0.00153125, m = 0.9
I0802 11:01:08.280275 18636 solver.cpp:353] Iteration 135600 (7.1227 iter/s, 14.0396s/100 iter), loss = 1.54704
I0802 11:01:08.280385 18636 solver.cpp:375]     Train net output #0: loss = 1.57443 (* 1 = 1.57443 loss)
I0802 11:01:08.280392 18636 sgd_solver.cpp:136] Iteration 135600, lr = 0.001525, m = 0.9
I0802 11:01:22.212112 18636 solver.cpp:353] Iteration 135700 (7.178 iter/s, 13.9315s/100 iter), loss = 1.40761
I0802 11:01:22.212141 18636 solver.cpp:375]     Train net output #0: loss = 1.72757 (* 1 = 1.72757 loss)
I0802 11:01:22.212146 18636 sgd_solver.cpp:136] Iteration 135700, lr = 0.00151875, m = 0.9
I0802 11:01:36.133363 18636 solver.cpp:353] Iteration 135800 (7.18346 iter/s, 13.9209s/100 iter), loss = 1.40727
I0802 11:01:36.133390 18636 solver.cpp:375]     Train net output #0: loss = 1.70456 (* 1 = 1.70456 loss)
I0802 11:01:36.133396 18636 sgd_solver.cpp:136] Iteration 135800, lr = 0.0015125, m = 0.9
I0802 11:01:50.222350 18636 solver.cpp:353] Iteration 135900 (7.09794 iter/s, 14.0886s/100 iter), loss = 0.992058
I0802 11:01:50.222434 18636 solver.cpp:375]     Train net output #0: loss = 1.13859 (* 1 = 1.13859 loss)
I0802 11:01:50.222440 18636 sgd_solver.cpp:136] Iteration 135900, lr = 0.00150625, m = 0.9
I0802 11:02:04.082376 18636 solver.cpp:404] Sparsity after update:
I0802 11:02:04.086755 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:02:04.086765 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:02:04.086771 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:02:04.086772 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:02:04.086774 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:02:04.086776 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:02:04.086778 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:02:04.086781 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:02:04.086782 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:02:04.086784 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:02:04.086786 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:02:04.086787 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:02:04.086789 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:02:04.086797 18636 solver.cpp:550] Iteration 136000, Testing net (#0)
I0802 11:02:23.788300 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.592235
I0802 11:02:23.788427 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821056
I0802 11:02:23.788436 18636 solver.cpp:635]     Test net output #2: loss = 1.76265 (* 1 = 1.76265 loss)
I0802 11:02:23.788458 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7011s
I0802 11:02:23.929625 18636 solver.cpp:353] Iteration 136000 (2.9668 iter/s, 33.7064s/100 iter), loss = 1.18168
I0802 11:02:23.929648 18636 solver.cpp:375]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0802 11:02:23.929652 18636 sgd_solver.cpp:136] Iteration 136000, lr = 0.0015, m = 0.9
I0802 11:02:37.946132 18636 solver.cpp:353] Iteration 136100 (7.13464 iter/s, 14.0161s/100 iter), loss = 1.52869
I0802 11:02:37.946161 18636 solver.cpp:375]     Train net output #0: loss = 1.37779 (* 1 = 1.37779 loss)
I0802 11:02:37.946167 18636 sgd_solver.cpp:136] Iteration 136100, lr = 0.00149375, m = 0.9
I0802 11:02:51.929813 18636 solver.cpp:353] Iteration 136200 (7.15139 iter/s, 13.9833s/100 iter), loss = 1.04117
I0802 11:02:51.929841 18636 solver.cpp:375]     Train net output #0: loss = 1.05713 (* 1 = 1.05713 loss)
I0802 11:02:51.929847 18636 sgd_solver.cpp:136] Iteration 136200, lr = 0.0014875, m = 0.9
I0802 11:03:05.763082 18636 solver.cpp:353] Iteration 136300 (7.22915 iter/s, 13.8329s/100 iter), loss = 1.21047
I0802 11:03:05.763170 18636 solver.cpp:375]     Train net output #0: loss = 1.06629 (* 1 = 1.06629 loss)
I0802 11:03:05.763180 18636 sgd_solver.cpp:136] Iteration 136300, lr = 0.00148125, m = 0.9
I0802 11:03:19.695267 18636 solver.cpp:353] Iteration 136400 (7.17782 iter/s, 13.9318s/100 iter), loss = 1.39079
I0802 11:03:19.695528 18636 solver.cpp:375]     Train net output #0: loss = 1.2027 (* 1 = 1.2027 loss)
I0802 11:03:19.695619 18636 sgd_solver.cpp:136] Iteration 136400, lr = 0.001475, m = 0.9
I0802 11:03:33.765907 18636 solver.cpp:353] Iteration 136500 (7.10719 iter/s, 14.0703s/100 iter), loss = 1.33419
I0802 11:03:33.765933 18636 solver.cpp:375]     Train net output #0: loss = 1.24645 (* 1 = 1.24645 loss)
I0802 11:03:33.765936 18636 sgd_solver.cpp:136] Iteration 136500, lr = 0.00146875, m = 0.9
I0802 11:03:47.783540 18636 solver.cpp:353] Iteration 136600 (7.13407 iter/s, 14.0172s/100 iter), loss = 1.08018
I0802 11:03:47.783807 18636 solver.cpp:375]     Train net output #0: loss = 0.954852 (* 1 = 0.954852 loss)
I0802 11:03:47.783927 18636 sgd_solver.cpp:136] Iteration 136600, lr = 0.0014625, m = 0.9
I0802 11:04:01.782974 18636 solver.cpp:353] Iteration 136700 (7.14334 iter/s, 13.9991s/100 iter), loss = 1.35047
I0802 11:04:01.783006 18636 solver.cpp:375]     Train net output #0: loss = 1.48949 (* 1 = 1.48949 loss)
I0802 11:04:01.783013 18636 sgd_solver.cpp:136] Iteration 136700, lr = 0.00145625, m = 0.9
I0802 11:04:15.743969 18636 solver.cpp:353] Iteration 136800 (7.16302 iter/s, 13.9606s/100 iter), loss = 1.52766
I0802 11:04:15.744009 18636 solver.cpp:375]     Train net output #0: loss = 1.62443 (* 1 = 1.62443 loss)
I0802 11:04:15.744014 18636 sgd_solver.cpp:136] Iteration 136800, lr = 0.00145, m = 0.9
I0802 11:04:29.913023 18636 solver.cpp:353] Iteration 136900 (7.05783 iter/s, 14.1687s/100 iter), loss = 1.23868
I0802 11:04:29.913105 18636 solver.cpp:375]     Train net output #0: loss = 1.0682 (* 1 = 1.0682 loss)
I0802 11:04:29.913116 18636 sgd_solver.cpp:136] Iteration 136900, lr = 0.00144375, m = 0.9
I0802 11:04:43.732321 18636 solver.cpp:404] Sparsity after update:
I0802 11:04:43.742844 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:04:43.742861 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:04:43.742869 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:04:43.742873 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:04:43.742877 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:04:43.742879 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:04:43.742890 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:04:43.742894 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:04:43.742898 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:04:43.742902 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:04:43.742905 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:04:43.742909 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:04:43.742913 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:04:43.871795 18636 solver.cpp:353] Iteration 137000 (7.16415 iter/s, 13.9584s/100 iter), loss = 1.22763
I0802 11:04:43.871846 18636 solver.cpp:375]     Train net output #0: loss = 1.20101 (* 1 = 1.20101 loss)
I0802 11:04:43.871858 18636 sgd_solver.cpp:136] Iteration 137000, lr = 0.0014375, m = 0.9
I0802 11:04:57.817221 18636 solver.cpp:353] Iteration 137100 (7.17101 iter/s, 13.945s/100 iter), loss = 1.33389
I0802 11:04:57.817250 18636 solver.cpp:375]     Train net output #0: loss = 1.61257 (* 1 = 1.61257 loss)
I0802 11:04:57.817258 18636 sgd_solver.cpp:136] Iteration 137100, lr = 0.00143125, m = 0.9
I0802 11:05:11.745789 18636 solver.cpp:353] Iteration 137200 (7.17969 iter/s, 13.9282s/100 iter), loss = 1.26186
I0802 11:05:11.747647 18636 solver.cpp:375]     Train net output #0: loss = 1.27802 (* 1 = 1.27802 loss)
I0802 11:05:11.747670 18636 sgd_solver.cpp:136] Iteration 137200, lr = 0.001425, m = 0.9
I0802 11:05:25.726739 18636 solver.cpp:353] Iteration 137300 (7.15279 iter/s, 13.9806s/100 iter), loss = 1.25161
I0802 11:05:25.726766 18636 solver.cpp:375]     Train net output #0: loss = 1.30269 (* 1 = 1.30269 loss)
I0802 11:05:25.726771 18636 sgd_solver.cpp:136] Iteration 137300, lr = 0.00141875, m = 0.9
I0802 11:05:39.711583 18636 solver.cpp:353] Iteration 137400 (7.1508 iter/s, 13.9845s/100 iter), loss = 1.68546
I0802 11:05:39.711609 18636 solver.cpp:375]     Train net output #0: loss = 1.77683 (* 1 = 1.77683 loss)
I0802 11:05:39.711616 18636 sgd_solver.cpp:136] Iteration 137400, lr = 0.0014125, m = 0.9
I0802 11:05:53.633442 18636 solver.cpp:353] Iteration 137500 (7.18315 iter/s, 13.9215s/100 iter), loss = 1.18459
I0802 11:05:53.633502 18636 solver.cpp:375]     Train net output #0: loss = 1.44322 (* 1 = 1.44322 loss)
I0802 11:05:53.633508 18636 sgd_solver.cpp:136] Iteration 137500, lr = 0.00140625, m = 0.9
I0802 11:06:07.989102 18636 solver.cpp:353] Iteration 137600 (6.96609 iter/s, 14.3553s/100 iter), loss = 1.24664
I0802 11:06:07.989130 18636 solver.cpp:375]     Train net output #0: loss = 1.24466 (* 1 = 1.24466 loss)
I0802 11:06:07.989133 18636 sgd_solver.cpp:136] Iteration 137600, lr = 0.0014, m = 0.9
I0802 11:06:22.086616 18636 solver.cpp:353] Iteration 137700 (7.09364 iter/s, 14.0971s/100 iter), loss = 1.20273
I0802 11:06:22.086642 18636 solver.cpp:375]     Train net output #0: loss = 1.12886 (* 1 = 1.12886 loss)
I0802 11:06:22.086647 18636 sgd_solver.cpp:136] Iteration 137700, lr = 0.00139375, m = 0.9
I0802 11:06:36.087189 18636 solver.cpp:353] Iteration 137800 (7.14276 iter/s, 14.0002s/100 iter), loss = 1.46494
I0802 11:06:36.087249 18636 solver.cpp:375]     Train net output #0: loss = 1.6372 (* 1 = 1.6372 loss)
I0802 11:06:36.087256 18636 sgd_solver.cpp:136] Iteration 137800, lr = 0.0013875, m = 0.9
I0802 11:06:50.156350 18636 solver.cpp:353] Iteration 137900 (7.10794 iter/s, 14.0688s/100 iter), loss = 1.04278
I0802 11:06:50.156384 18636 solver.cpp:375]     Train net output #0: loss = 1.02119 (* 1 = 1.02119 loss)
I0802 11:06:50.156390 18636 sgd_solver.cpp:136] Iteration 137900, lr = 0.00138125, m = 0.9
I0802 11:07:04.067942 18636 solver.cpp:404] Sparsity after update:
I0802 11:07:04.072870 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:07:04.072882 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:07:04.072890 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:07:04.072895 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:07:04.072897 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:07:04.072901 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:07:04.072904 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:07:04.072907 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:07:04.072911 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:07:04.072938 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:07:04.072944 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:07:04.072948 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:07:04.072952 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:07:04.072962 18636 solver.cpp:550] Iteration 138000, Testing net (#0)
I0802 11:07:13.728456 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:07:23.988601 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589235
I0802 11:07:23.988626 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.814468
I0802 11:07:23.988631 18636 solver.cpp:635]     Test net output #2: loss = 1.79738 (* 1 = 1.79738 loss)
I0802 11:07:23.988726 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9152s
I0802 11:07:24.125946 18636 solver.cpp:353] Iteration 138000 (2.94389 iter/s, 33.9687s/100 iter), loss = 1.29298
I0802 11:07:24.125972 18636 solver.cpp:375]     Train net output #0: loss = 1.20092 (* 1 = 1.20092 loss)
I0802 11:07:24.125977 18636 sgd_solver.cpp:136] Iteration 138000, lr = 0.001375, m = 0.9
I0802 11:07:38.048163 18636 solver.cpp:353] Iteration 138100 (7.18297 iter/s, 13.9218s/100 iter), loss = 1.07743
I0802 11:07:38.048197 18636 solver.cpp:375]     Train net output #0: loss = 0.943131 (* 1 = 0.943131 loss)
I0802 11:07:38.048204 18636 sgd_solver.cpp:136] Iteration 138100, lr = 0.00136875, m = 0.9
I0802 11:07:51.970371 18636 solver.cpp:353] Iteration 138200 (7.18297 iter/s, 13.9218s/100 iter), loss = 1.38149
I0802 11:07:51.970424 18636 solver.cpp:375]     Train net output #0: loss = 1.20915 (* 1 = 1.20915 loss)
I0802 11:07:51.970432 18636 sgd_solver.cpp:136] Iteration 138200, lr = 0.0013625, m = 0.9
I0802 11:08:06.178175 18636 solver.cpp:353] Iteration 138300 (7.03858 iter/s, 14.2074s/100 iter), loss = 1.29331
I0802 11:08:06.178203 18636 solver.cpp:375]     Train net output #0: loss = 1.2515 (* 1 = 1.2515 loss)
I0802 11:08:06.178210 18636 sgd_solver.cpp:136] Iteration 138300, lr = 0.00135625, m = 0.9
I0802 11:08:20.305958 18636 solver.cpp:353] Iteration 138400 (7.07845 iter/s, 14.1274s/100 iter), loss = 1.15253
I0802 11:08:20.305985 18636 solver.cpp:375]     Train net output #0: loss = 1.20367 (* 1 = 1.20367 loss)
I0802 11:08:20.305990 18636 sgd_solver.cpp:136] Iteration 138400, lr = 0.00135, m = 0.9
I0802 11:08:34.205858 18636 solver.cpp:353] Iteration 138500 (7.19449 iter/s, 13.8995s/100 iter), loss = 1.53748
I0802 11:08:34.205920 18636 solver.cpp:375]     Train net output #0: loss = 1.4217 (* 1 = 1.4217 loss)
I0802 11:08:34.205927 18636 sgd_solver.cpp:136] Iteration 138500, lr = 0.00134375, m = 0.9
I0802 11:08:48.317706 18636 solver.cpp:353] Iteration 138600 (7.08644 iter/s, 14.1115s/100 iter), loss = 1.56189
I0802 11:08:48.317733 18636 solver.cpp:375]     Train net output #0: loss = 1.40548 (* 1 = 1.40548 loss)
I0802 11:08:48.317737 18636 sgd_solver.cpp:136] Iteration 138600, lr = 0.0013375, m = 0.9
I0802 11:09:02.210073 18636 solver.cpp:353] Iteration 138700 (7.1984 iter/s, 13.892s/100 iter), loss = 1.65857
I0802 11:09:02.210153 18636 solver.cpp:375]     Train net output #0: loss = 1.09167 (* 1 = 1.09167 loss)
I0802 11:09:02.210176 18636 sgd_solver.cpp:136] Iteration 138700, lr = 0.00133125, m = 0.9
I0802 11:09:16.162526 18636 solver.cpp:353] Iteration 138800 (7.1674 iter/s, 13.9521s/100 iter), loss = 1.39808
I0802 11:09:16.162614 18636 solver.cpp:375]     Train net output #0: loss = 1.5144 (* 1 = 1.5144 loss)
I0802 11:09:16.162621 18636 sgd_solver.cpp:136] Iteration 138800, lr = 0.001325, m = 0.9
I0802 11:09:30.244060 18636 solver.cpp:353] Iteration 138900 (7.10169 iter/s, 14.0811s/100 iter), loss = 1.10086
I0802 11:09:30.244092 18636 solver.cpp:375]     Train net output #0: loss = 0.949328 (* 1 = 0.949328 loss)
I0802 11:09:30.244096 18636 sgd_solver.cpp:136] Iteration 138900, lr = 0.00131875, m = 0.9
I0802 11:09:44.240813 18636 solver.cpp:404] Sparsity after update:
I0802 11:09:44.252354 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:09:44.252367 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:09:44.252374 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:09:44.252377 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:09:44.252378 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:09:44.252380 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:09:44.252382 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:09:44.252384 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:09:44.252387 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:09:44.252388 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:09:44.252390 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:09:44.252393 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:09:44.252401 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:09:44.381583 18636 solver.cpp:353] Iteration 139000 (7.07357 iter/s, 14.1371s/100 iter), loss = 1.48479
I0802 11:09:44.381610 18636 solver.cpp:375]     Train net output #0: loss = 1.27964 (* 1 = 1.27964 loss)
I0802 11:09:44.381615 18636 sgd_solver.cpp:136] Iteration 139000, lr = 0.0013125, m = 0.9
I0802 11:09:58.408828 18636 solver.cpp:353] Iteration 139100 (7.12918 iter/s, 14.0269s/100 iter), loss = 1.56852
I0802 11:09:58.408901 18636 solver.cpp:375]     Train net output #0: loss = 1.69397 (* 1 = 1.69397 loss)
I0802 11:09:58.408908 18636 sgd_solver.cpp:136] Iteration 139100, lr = 0.00130625, m = 0.9
I0802 11:10:12.554687 18636 solver.cpp:353] Iteration 139200 (7.0694 iter/s, 14.1455s/100 iter), loss = 1.03359
I0802 11:10:12.554714 18636 solver.cpp:375]     Train net output #0: loss = 1.15937 (* 1 = 1.15937 loss)
I0802 11:10:12.554720 18636 sgd_solver.cpp:136] Iteration 139200, lr = 0.0013, m = 0.9
I0802 11:10:26.640630 18636 solver.cpp:353] Iteration 139300 (7.09947 iter/s, 14.0856s/100 iter), loss = 1.32019
I0802 11:10:26.640661 18636 solver.cpp:375]     Train net output #0: loss = 1.27156 (* 1 = 1.27156 loss)
I0802 11:10:26.640667 18636 sgd_solver.cpp:136] Iteration 139300, lr = 0.00129375, m = 0.9
I0802 11:10:41.225664 18636 solver.cpp:353] Iteration 139400 (6.85653 iter/s, 14.5846s/100 iter), loss = 1.47844
I0802 11:10:41.225724 18636 solver.cpp:375]     Train net output #0: loss = 1.47475 (* 1 = 1.47475 loss)
I0802 11:10:41.225731 18636 sgd_solver.cpp:136] Iteration 139400, lr = 0.0012875, m = 0.9
I0802 11:10:55.229275 18636 solver.cpp:353] Iteration 139500 (7.14121 iter/s, 14.0032s/100 iter), loss = 1.14839
I0802 11:10:55.229305 18636 solver.cpp:375]     Train net output #0: loss = 1.1948 (* 1 = 1.1948 loss)
I0802 11:10:55.229311 18636 sgd_solver.cpp:136] Iteration 139500, lr = 0.00128125, m = 0.9
I0802 11:11:09.335073 18636 solver.cpp:353] Iteration 139600 (7.08948 iter/s, 14.1054s/100 iter), loss = 1.51389
I0802 11:11:09.335103 18636 solver.cpp:375]     Train net output #0: loss = 1.55261 (* 1 = 1.55261 loss)
I0802 11:11:09.335109 18636 sgd_solver.cpp:136] Iteration 139600, lr = 0.001275, m = 0.9
I0802 11:11:23.560186 18636 solver.cpp:353] Iteration 139700 (7.03002 iter/s, 14.2247s/100 iter), loss = 1.30979
I0802 11:11:23.560268 18636 solver.cpp:375]     Train net output #0: loss = 1.07211 (* 1 = 1.07211 loss)
I0802 11:11:23.560277 18636 sgd_solver.cpp:136] Iteration 139700, lr = 0.00126875, m = 0.9
I0802 11:11:37.820204 18636 solver.cpp:353] Iteration 139800 (7.01281 iter/s, 14.2596s/100 iter), loss = 1.37354
I0802 11:11:37.820228 18636 solver.cpp:375]     Train net output #0: loss = 1.41992 (* 1 = 1.41992 loss)
I0802 11:11:37.820233 18636 sgd_solver.cpp:136] Iteration 139800, lr = 0.0012625, m = 0.9
I0802 11:11:51.894024 18636 solver.cpp:353] Iteration 139900 (7.10559 iter/s, 14.0734s/100 iter), loss = 1.18228
I0802 11:11:51.894117 18636 solver.cpp:375]     Train net output #0: loss = 1.0052 (* 1 = 1.0052 loss)
I0802 11:11:51.894136 18636 sgd_solver.cpp:136] Iteration 139900, lr = 0.00125625, m = 0.9
I0802 11:12:05.752779 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_140000.caffemodel
I0802 11:12:05.856480 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_140000.solverstate
I0802 11:12:05.862812 18636 solver.cpp:404] Sparsity after update:
I0802 11:12:05.864459 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:12:05.864470 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:12:05.864478 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:12:05.864482 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:12:05.864486 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:12:05.864491 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:12:05.864495 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:12:05.864500 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:12:05.864503 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:12:05.864507 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:12:05.864511 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:12:05.864516 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:12:05.864521 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:12:05.864531 18636 solver.cpp:550] Iteration 140000, Testing net (#0)
I0802 11:12:25.770706 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589176
I0802 11:12:25.770730 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818468
I0802 11:12:25.770736 18636 solver.cpp:635]     Test net output #2: loss = 1.7797 (* 1 = 1.7797 loss)
I0802 11:12:25.784838 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9198s
I0802 11:12:25.919323 18636 solver.cpp:353] Iteration 140000 (2.93907 iter/s, 34.0244s/100 iter), loss = 1.31527
I0802 11:12:25.919348 18636 solver.cpp:375]     Train net output #0: loss = 1.4923 (* 1 = 1.4923 loss)
I0802 11:12:25.919350 18636 sgd_solver.cpp:136] Iteration 140000, lr = 0.00125, m = 0.9
I0802 11:12:39.861150 18636 solver.cpp:353] Iteration 140100 (7.17286 iter/s, 13.9414s/100 iter), loss = 1.38543
I0802 11:12:39.861238 18636 solver.cpp:375]     Train net output #0: loss = 1.7424 (* 1 = 1.7424 loss)
I0802 11:12:39.861245 18636 sgd_solver.cpp:136] Iteration 140100, lr = 0.00124375, m = 0.9
I0802 11:12:53.858573 18636 solver.cpp:353] Iteration 140200 (7.14437 iter/s, 13.997s/100 iter), loss = 1.60482
I0802 11:12:53.858603 18636 solver.cpp:375]     Train net output #0: loss = 1.98419 (* 1 = 1.98419 loss)
I0802 11:12:53.858610 18636 sgd_solver.cpp:136] Iteration 140200, lr = 0.0012375, m = 0.9
I0802 11:13:07.967780 18636 solver.cpp:353] Iteration 140300 (7.08777 iter/s, 14.1088s/100 iter), loss = 1.33943
I0802 11:13:07.967806 18636 solver.cpp:375]     Train net output #0: loss = 1.58867 (* 1 = 1.58867 loss)
I0802 11:13:07.967811 18636 sgd_solver.cpp:136] Iteration 140300, lr = 0.00123125, m = 0.9
I0802 11:13:22.003746 18636 solver.cpp:353] Iteration 140400 (7.12475 iter/s, 14.0356s/100 iter), loss = 1.63441
I0802 11:13:22.003810 18636 solver.cpp:375]     Train net output #0: loss = 1.63779 (* 1 = 1.63779 loss)
I0802 11:13:22.003818 18636 sgd_solver.cpp:136] Iteration 140400, lr = 0.001225, m = 0.9
I0802 11:13:36.071707 18636 solver.cpp:353] Iteration 140500 (7.10855 iter/s, 14.0676s/100 iter), loss = 1.48672
I0802 11:13:36.071737 18636 solver.cpp:375]     Train net output #0: loss = 1.64292 (* 1 = 1.64292 loss)
I0802 11:13:36.071789 18636 sgd_solver.cpp:136] Iteration 140500, lr = 0.00121875, m = 0.9
I0802 11:13:50.267091 18636 solver.cpp:353] Iteration 140600 (7.04474 iter/s, 14.195s/100 iter), loss = 1.53328
I0802 11:13:50.267115 18636 solver.cpp:375]     Train net output #0: loss = 1.48452 (* 1 = 1.48452 loss)
I0802 11:13:50.267119 18636 sgd_solver.cpp:136] Iteration 140600, lr = 0.0012125, m = 0.9
I0802 11:14:04.349267 18636 solver.cpp:353] Iteration 140700 (7.10137 iter/s, 14.0818s/100 iter), loss = 1.40747
I0802 11:14:04.349341 18636 solver.cpp:375]     Train net output #0: loss = 1.08233 (* 1 = 1.08233 loss)
I0802 11:14:04.349349 18636 sgd_solver.cpp:136] Iteration 140700, lr = 0.00120625, m = 0.9
I0802 11:14:18.515189 18636 solver.cpp:353] Iteration 140800 (7.05939 iter/s, 14.1655s/100 iter), loss = 1.40008
I0802 11:14:18.515223 18636 solver.cpp:375]     Train net output #0: loss = 1.48653 (* 1 = 1.48653 loss)
I0802 11:14:18.515295 18636 sgd_solver.cpp:136] Iteration 140800, lr = 0.0012, m = 0.9
I0802 11:14:32.622336 18636 solver.cpp:353] Iteration 140900 (7.0888 iter/s, 14.1068s/100 iter), loss = 1.64201
I0802 11:14:32.622426 18636 solver.cpp:375]     Train net output #0: loss = 1.68974 (* 1 = 1.68974 loss)
I0802 11:14:32.622452 18636 sgd_solver.cpp:136] Iteration 140900, lr = 0.00119375, m = 0.9
I0802 11:14:46.501168 18636 solver.cpp:404] Sparsity after update:
I0802 11:14:46.515219 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:14:46.515236 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:14:46.515242 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:14:46.515244 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:14:46.515246 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:14:46.515249 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:14:46.515250 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:14:46.515252 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:14:46.515254 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:14:46.515256 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:14:46.515259 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:14:46.515260 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:14:46.515262 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:14:46.647114 18636 solver.cpp:353] Iteration 141000 (7.13043 iter/s, 14.0244s/100 iter), loss = 1.43087
I0802 11:14:46.647142 18636 solver.cpp:375]     Train net output #0: loss = 1.12432 (* 1 = 1.12432 loss)
I0802 11:14:46.647148 18636 sgd_solver.cpp:136] Iteration 141000, lr = 0.0011875, m = 0.9
I0802 11:15:00.610615 18636 solver.cpp:353] Iteration 141100 (7.16173 iter/s, 13.9631s/100 iter), loss = 1.58005
I0802 11:15:00.610709 18636 solver.cpp:375]     Train net output #0: loss = 2.3339 (* 1 = 2.3339 loss)
I0802 11:15:00.610728 18636 sgd_solver.cpp:136] Iteration 141100, lr = 0.00118125, m = 0.9
I0802 11:15:14.561875 18636 solver.cpp:353] Iteration 141200 (7.16801 iter/s, 13.9509s/100 iter), loss = 1.67332
I0802 11:15:14.561904 18636 solver.cpp:375]     Train net output #0: loss = 1.48681 (* 1 = 1.48681 loss)
I0802 11:15:14.561909 18636 sgd_solver.cpp:136] Iteration 141200, lr = 0.001175, m = 0.9
I0802 11:15:28.606899 18636 solver.cpp:353] Iteration 141300 (7.12016 iter/s, 14.0446s/100 iter), loss = 1.41926
I0802 11:15:28.607012 18636 solver.cpp:375]     Train net output #0: loss = 1.17212 (* 1 = 1.17212 loss)
I0802 11:15:28.607024 18636 sgd_solver.cpp:136] Iteration 141300, lr = 0.00116875, m = 0.9
I0802 11:15:42.522994 18636 solver.cpp:353] Iteration 141400 (7.18612 iter/s, 13.9157s/100 iter), loss = 1.39366
I0802 11:15:42.523028 18636 solver.cpp:375]     Train net output #0: loss = 1.49053 (* 1 = 1.49053 loss)
I0802 11:15:42.523036 18636 sgd_solver.cpp:136] Iteration 141400, lr = 0.0011625, m = 0.9
I0802 11:15:56.565964 18636 solver.cpp:353] Iteration 141500 (7.1212 iter/s, 14.0426s/100 iter), loss = 1.51274
I0802 11:15:56.566062 18636 solver.cpp:375]     Train net output #0: loss = 1.41114 (* 1 = 1.41114 loss)
I0802 11:15:56.566088 18636 sgd_solver.cpp:136] Iteration 141500, lr = 0.00115625, m = 0.9
I0802 11:16:10.634734 18636 solver.cpp:353] Iteration 141600 (7.10814 iter/s, 14.0684s/100 iter), loss = 1.60164
I0802 11:16:10.634852 18636 solver.cpp:375]     Train net output #0: loss = 1.64332 (* 1 = 1.64332 loss)
I0802 11:16:10.634876 18636 sgd_solver.cpp:136] Iteration 141600, lr = 0.00115, m = 0.9
I0802 11:16:24.594013 18636 solver.cpp:353] Iteration 141700 (7.16389 iter/s, 13.9589s/100 iter), loss = 1.39293
I0802 11:16:24.594040 18636 solver.cpp:375]     Train net output #0: loss = 1.40206 (* 1 = 1.40206 loss)
I0802 11:16:24.594045 18636 sgd_solver.cpp:136] Iteration 141700, lr = 0.00114375, m = 0.9
I0802 11:16:38.694725 18636 solver.cpp:353] Iteration 141800 (7.09204 iter/s, 14.1003s/100 iter), loss = 1.07753
I0802 11:16:38.694805 18636 solver.cpp:375]     Train net output #0: loss = 1.1988 (* 1 = 1.1988 loss)
I0802 11:16:38.694828 18636 sgd_solver.cpp:136] Iteration 141800, lr = 0.0011375, m = 0.9
I0802 11:16:52.749698 18636 solver.cpp:353] Iteration 141900 (7.11511 iter/s, 14.0546s/100 iter), loss = 1.57563
I0802 11:16:52.750000 18636 solver.cpp:375]     Train net output #0: loss = 1.17026 (* 1 = 1.17026 loss)
I0802 11:16:52.750110 18636 sgd_solver.cpp:136] Iteration 141900, lr = 0.00113125, m = 0.9
I0802 11:17:06.627187 18636 solver.cpp:404] Sparsity after update:
I0802 11:17:06.631189 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:17:06.631219 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:17:06.631235 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:17:06.631245 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:17:06.631254 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:17:06.631263 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:17:06.631273 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:17:06.631281 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:17:06.631290 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:17:06.631299 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:17:06.631309 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:17:06.631317 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:17:06.631326 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:17:06.631343 18636 solver.cpp:550] Iteration 142000, Testing net (#0)
I0802 11:17:26.642571 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589823
I0802 11:17:26.642675 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818996
I0802 11:17:26.642684 18636 solver.cpp:635]     Test net output #2: loss = 1.76149 (* 1 = 1.76149 loss)
I0802 11:17:26.642704 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0108s
I0802 11:17:26.794104 18636 solver.cpp:353] Iteration 142000 (2.93742 iter/s, 34.0435s/100 iter), loss = 1.42292
I0802 11:17:26.794129 18636 solver.cpp:375]     Train net output #0: loss = 1.63501 (* 1 = 1.63501 loss)
I0802 11:17:26.794136 18636 sgd_solver.cpp:136] Iteration 142000, lr = 0.001125, m = 0.9
I0802 11:17:40.761147 18636 solver.cpp:353] Iteration 142100 (7.15991 iter/s, 13.9667s/100 iter), loss = 1.28774
I0802 11:17:40.761174 18636 solver.cpp:375]     Train net output #0: loss = 1.18999 (* 1 = 1.18999 loss)
I0802 11:17:40.761180 18636 sgd_solver.cpp:136] Iteration 142100, lr = 0.00111875, m = 0.9
I0802 11:17:54.731523 18636 solver.cpp:353] Iteration 142200 (7.1582 iter/s, 13.97s/100 iter), loss = 1.47519
I0802 11:17:54.731554 18636 solver.cpp:375]     Train net output #0: loss = 1.56781 (* 1 = 1.56781 loss)
I0802 11:17:54.731560 18636 sgd_solver.cpp:136] Iteration 142200, lr = 0.0011125, m = 0.9
I0802 11:18:08.659237 18636 solver.cpp:353] Iteration 142300 (7.18013 iter/s, 13.9273s/100 iter), loss = 1.2544
I0802 11:18:08.659298 18636 solver.cpp:375]     Train net output #0: loss = 1.27399 (* 1 = 1.27399 loss)
I0802 11:18:08.659307 18636 sgd_solver.cpp:136] Iteration 142300, lr = 0.00110625, m = 0.9
I0802 11:18:22.675796 18636 solver.cpp:353] Iteration 142400 (7.13462 iter/s, 14.0162s/100 iter), loss = 1.24946
I0802 11:18:22.675886 18636 solver.cpp:375]     Train net output #0: loss = 1.47291 (* 1 = 1.47291 loss)
I0802 11:18:22.675912 18636 sgd_solver.cpp:136] Iteration 142400, lr = 0.0011, m = 0.9
I0802 11:18:36.760824 18636 solver.cpp:353] Iteration 142500 (7.09993 iter/s, 14.0846s/100 iter), loss = 1.69797
I0802 11:18:36.760848 18636 solver.cpp:375]     Train net output #0: loss = 1.6587 (* 1 = 1.6587 loss)
I0802 11:18:36.760854 18636 sgd_solver.cpp:136] Iteration 142500, lr = 0.00109375, m = 0.9
I0802 11:18:50.660125 18636 solver.cpp:353] Iteration 142600 (7.1948 iter/s, 13.8989s/100 iter), loss = 1.46242
I0802 11:18:50.660223 18636 solver.cpp:375]     Train net output #0: loss = 1.29453 (* 1 = 1.29453 loss)
I0802 11:18:50.660231 18636 sgd_solver.cpp:136] Iteration 142600, lr = 0.0010875, m = 0.9
I0802 11:19:04.674456 18636 solver.cpp:353] Iteration 142700 (7.13575 iter/s, 14.0139s/100 iter), loss = 1.19167
I0802 11:19:04.674487 18636 solver.cpp:375]     Train net output #0: loss = 0.94524 (* 1 = 0.94524 loss)
I0802 11:19:04.674491 18636 sgd_solver.cpp:136] Iteration 142700, lr = 0.00108125, m = 0.9
I0802 11:19:18.689563 18636 solver.cpp:353] Iteration 142800 (7.13536 iter/s, 14.0147s/100 iter), loss = 1.35245
I0802 11:19:18.689599 18636 solver.cpp:375]     Train net output #0: loss = 1.27591 (* 1 = 1.27591 loss)
I0802 11:19:18.689604 18636 sgd_solver.cpp:136] Iteration 142800, lr = 0.001075, m = 0.9
I0802 11:19:32.651149 18636 solver.cpp:353] Iteration 142900 (7.16271 iter/s, 13.9612s/100 iter), loss = 1.56554
I0802 11:19:32.651231 18636 solver.cpp:375]     Train net output #0: loss = 1.80321 (* 1 = 1.80321 loss)
I0802 11:19:32.651237 18636 sgd_solver.cpp:136] Iteration 142900, lr = 0.00106875, m = 0.9
I0802 11:19:46.591547 18636 solver.cpp:404] Sparsity after update:
I0802 11:19:46.605845 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:19:46.605864 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:19:46.605872 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:19:46.605875 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:19:46.605878 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:19:46.605882 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:19:46.605893 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:19:46.605901 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:19:46.605911 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:19:46.605918 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:19:46.605926 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:19:46.605942 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:19:46.605947 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:19:46.735455 18636 solver.cpp:353] Iteration 143000 (7.1003 iter/s, 14.0839s/100 iter), loss = 1.27104
I0802 11:19:46.735522 18636 solver.cpp:375]     Train net output #0: loss = 1.25462 (* 1 = 1.25462 loss)
I0802 11:19:46.735540 18636 sgd_solver.cpp:136] Iteration 143000, lr = 0.0010625, m = 0.9
I0802 11:20:00.723748 18636 solver.cpp:353] Iteration 143100 (7.14903 iter/s, 13.9879s/100 iter), loss = 1.34048
I0802 11:20:00.723778 18636 solver.cpp:375]     Train net output #0: loss = 0.970854 (* 1 = 0.970854 loss)
I0802 11:20:00.723784 18636 sgd_solver.cpp:136] Iteration 143100, lr = 0.00105625, m = 0.9
I0802 11:20:14.639871 18636 solver.cpp:353] Iteration 143200 (7.18611 iter/s, 13.9157s/100 iter), loss = 1.32331
I0802 11:20:14.639925 18636 solver.cpp:375]     Train net output #0: loss = 1.43876 (* 1 = 1.43876 loss)
I0802 11:20:14.639930 18636 sgd_solver.cpp:136] Iteration 143200, lr = 0.00105, m = 0.9
I0802 11:20:28.731055 18636 solver.cpp:353] Iteration 143300 (7.09683 iter/s, 14.0908s/100 iter), loss = 1.39758
I0802 11:20:28.731083 18636 solver.cpp:375]     Train net output #0: loss = 0.999909 (* 1 = 0.999909 loss)
I0802 11:20:28.731089 18636 sgd_solver.cpp:136] Iteration 143300, lr = 0.00104375, m = 0.9
I0802 11:20:42.604496 18636 solver.cpp:353] Iteration 143400 (7.20822 iter/s, 13.8731s/100 iter), loss = 1.38181
I0802 11:20:42.604521 18636 solver.cpp:375]     Train net output #0: loss = 1.55951 (* 1 = 1.55951 loss)
I0802 11:20:42.604526 18636 sgd_solver.cpp:136] Iteration 143400, lr = 0.0010375, m = 0.9
I0802 11:20:56.627651 18636 solver.cpp:353] Iteration 143500 (7.13126 iter/s, 14.0228s/100 iter), loss = 1.14685
I0802 11:20:56.627748 18636 solver.cpp:375]     Train net output #0: loss = 1.32042 (* 1 = 1.32042 loss)
I0802 11:20:56.627763 18636 sgd_solver.cpp:136] Iteration 143500, lr = 0.00103125, m = 0.9
I0802 11:21:10.641834 18636 solver.cpp:353] Iteration 143600 (7.13583 iter/s, 14.0138s/100 iter), loss = 1.71948
I0802 11:21:10.641861 18636 solver.cpp:375]     Train net output #0: loss = 1.37679 (* 1 = 1.37679 loss)
I0802 11:21:10.641866 18636 sgd_solver.cpp:136] Iteration 143600, lr = 0.001025, m = 0.9
I0802 11:21:24.634057 18636 solver.cpp:353] Iteration 143700 (7.14702 iter/s, 13.9918s/100 iter), loss = 1.32405
I0802 11:21:24.634081 18636 solver.cpp:375]     Train net output #0: loss = 1.62347 (* 1 = 1.62347 loss)
I0802 11:21:24.634088 18636 sgd_solver.cpp:136] Iteration 143700, lr = 0.00101875, m = 0.9
I0802 11:21:38.583900 18636 solver.cpp:353] Iteration 143800 (7.16874 iter/s, 13.9495s/100 iter), loss = 1.1563
I0802 11:21:38.584347 18636 solver.cpp:375]     Train net output #0: loss = 0.979246 (* 1 = 0.979246 loss)
I0802 11:21:38.584355 18636 sgd_solver.cpp:136] Iteration 143800, lr = 0.0010125, m = 0.9
I0802 11:21:52.650717 18636 solver.cpp:353] Iteration 143900 (7.10912 iter/s, 14.0664s/100 iter), loss = 1.6055
I0802 11:21:52.650745 18636 solver.cpp:375]     Train net output #0: loss = 1.12546 (* 1 = 1.12546 loss)
I0802 11:21:52.650753 18636 sgd_solver.cpp:136] Iteration 143900, lr = 0.00100625, m = 0.9
I0802 11:22:06.692282 18636 solver.cpp:404] Sparsity after update:
I0802 11:22:06.696590 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:22:06.696602 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:22:06.696611 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:22:06.696614 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:22:06.696617 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:22:06.696633 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:22:06.696650 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:22:06.696658 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:22:06.696667 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:22:06.696676 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:22:06.696684 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:22:06.696693 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:22:06.696702 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:22:06.696718 18636 solver.cpp:550] Iteration 144000, Testing net (#0)
I0802 11:22:17.183061 18619 data_reader.cpp:264] Starting prefetch of epoch 7
I0802 11:22:18.208210 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:22:26.156183 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591941
I0802 11:22:26.156208 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.819644
I0802 11:22:26.156215 18636 solver.cpp:635]     Test net output #2: loss = 1.78087 (* 1 = 1.78087 loss)
I0802 11:22:26.156296 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.459s
I0802 11:22:26.302522 18636 solver.cpp:353] Iteration 144000 (2.97169 iter/s, 33.6509s/100 iter), loss = 1.33317
I0802 11:22:26.302567 18636 solver.cpp:375]     Train net output #0: loss = 1.43983 (* 1 = 1.43983 loss)
I0802 11:22:26.302579 18636 sgd_solver.cpp:136] Iteration 144000, lr = 0.001, m = 0.9
I0802 11:22:40.279929 18636 solver.cpp:353] Iteration 144100 (7.1546 iter/s, 13.977s/100 iter), loss = 1.16617
I0802 11:22:40.279955 18636 solver.cpp:375]     Train net output #0: loss = 1.01862 (* 1 = 1.01862 loss)
I0802 11:22:40.279960 18636 sgd_solver.cpp:136] Iteration 144100, lr = 0.00099375, m = 0.9
I0802 11:22:54.261903 18636 solver.cpp:353] Iteration 144200 (7.15227 iter/s, 13.9816s/100 iter), loss = 1.58703
I0802 11:22:54.262033 18636 solver.cpp:375]     Train net output #0: loss = 1.37896 (* 1 = 1.37896 loss)
I0802 11:22:54.262040 18636 sgd_solver.cpp:136] Iteration 144200, lr = 0.0009875, m = 0.9
I0802 11:23:08.336942 18636 solver.cpp:353] Iteration 144300 (7.10497 iter/s, 14.0747s/100 iter), loss = 1.48206
I0802 11:23:08.336971 18636 solver.cpp:375]     Train net output #0: loss = 2.26298 (* 1 = 2.26298 loss)
I0802 11:23:08.336977 18636 sgd_solver.cpp:136] Iteration 144300, lr = 0.00098125, m = 0.9
I0802 11:23:22.520958 18636 solver.cpp:353] Iteration 144400 (7.05038 iter/s, 14.1836s/100 iter), loss = 1.3419
I0802 11:23:22.520987 18636 solver.cpp:375]     Train net output #0: loss = 1.48125 (* 1 = 1.48125 loss)
I0802 11:23:22.520992 18636 sgd_solver.cpp:136] Iteration 144400, lr = 0.000975, m = 0.9
I0802 11:23:36.527294 18636 solver.cpp:353] Iteration 144500 (7.13982 iter/s, 14.0059s/100 iter), loss = 1.0434
I0802 11:23:36.527369 18636 solver.cpp:375]     Train net output #0: loss = 0.98397 (* 1 = 0.98397 loss)
I0802 11:23:36.527375 18636 sgd_solver.cpp:136] Iteration 144500, lr = 0.00096875, m = 0.9
I0802 11:23:50.506899 18636 solver.cpp:353] Iteration 144600 (7.15348 iter/s, 13.9792s/100 iter), loss = 1.23236
I0802 11:23:50.506923 18636 solver.cpp:375]     Train net output #0: loss = 1.44325 (* 1 = 1.44325 loss)
I0802 11:23:50.506927 18636 sgd_solver.cpp:136] Iteration 144600, lr = 0.0009625, m = 0.9
I0802 11:24:04.517333 18636 solver.cpp:353] Iteration 144700 (7.13774 iter/s, 14.01s/100 iter), loss = 1.10314
I0802 11:24:04.517359 18636 solver.cpp:375]     Train net output #0: loss = 1.35401 (* 1 = 1.35401 loss)
I0802 11:24:04.517365 18636 sgd_solver.cpp:136] Iteration 144700, lr = 0.00095625, m = 0.9
I0802 11:24:18.490977 18636 solver.cpp:353] Iteration 144800 (7.15653 iter/s, 13.9733s/100 iter), loss = 1.31775
I0802 11:24:18.491063 18636 solver.cpp:375]     Train net output #0: loss = 1.46925 (* 1 = 1.46925 loss)
I0802 11:24:18.491070 18636 sgd_solver.cpp:136] Iteration 144800, lr = 0.00095, m = 0.9
I0802 11:24:32.738629 18636 solver.cpp:353] Iteration 144900 (7.01889 iter/s, 14.2473s/100 iter), loss = 1.6966
I0802 11:24:32.738656 18636 solver.cpp:375]     Train net output #0: loss = 1.74494 (* 1 = 1.74494 loss)
I0802 11:24:32.738661 18636 sgd_solver.cpp:136] Iteration 144900, lr = 0.00094375, m = 0.9
I0802 11:24:46.815779 18636 solver.cpp:404] Sparsity after update:
I0802 11:24:46.831048 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:24:46.831060 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:24:46.831068 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:24:46.831069 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:24:46.831071 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:24:46.831073 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:24:46.831075 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:24:46.831077 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:24:46.831079 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:24:46.831081 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:24:46.831084 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:24:46.831089 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:24:46.831091 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:24:46.960371 18636 solver.cpp:353] Iteration 145000 (7.03168 iter/s, 14.2214s/100 iter), loss = 1.12562
I0802 11:24:46.960398 18636 solver.cpp:375]     Train net output #0: loss = 1.27206 (* 1 = 1.27206 loss)
I0802 11:24:46.960404 18636 sgd_solver.cpp:136] Iteration 145000, lr = 0.0009375, m = 0.9
I0802 11:25:00.998283 18636 solver.cpp:353] Iteration 145100 (7.12376 iter/s, 14.0375s/100 iter), loss = 1.5004
I0802 11:25:00.998345 18636 solver.cpp:375]     Train net output #0: loss = 1.65358 (* 1 = 1.65358 loss)
I0802 11:25:00.998353 18636 sgd_solver.cpp:136] Iteration 145100, lr = 0.00093125, m = 0.9
I0802 11:25:15.250144 18636 solver.cpp:353] Iteration 145200 (7.01682 iter/s, 14.2515s/100 iter), loss = 1.31789
I0802 11:25:15.250174 18636 solver.cpp:375]     Train net output #0: loss = 1.8524 (* 1 = 1.8524 loss)
I0802 11:25:15.250178 18636 sgd_solver.cpp:136] Iteration 145200, lr = 0.000925, m = 0.9
I0802 11:25:29.329699 18636 solver.cpp:353] Iteration 145300 (7.10269 iter/s, 14.0792s/100 iter), loss = 1.72259
I0802 11:25:29.329728 18636 solver.cpp:375]     Train net output #0: loss = 2.01006 (* 1 = 2.01006 loss)
I0802 11:25:29.329735 18636 sgd_solver.cpp:136] Iteration 145300, lr = 0.00091875, m = 0.9
I0802 11:25:43.569835 18636 solver.cpp:353] Iteration 145400 (7.0226 iter/s, 14.2397s/100 iter), loss = 1.40516
I0802 11:25:43.569923 18636 solver.cpp:375]     Train net output #0: loss = 1.33604 (* 1 = 1.33604 loss)
I0802 11:25:43.569929 18636 sgd_solver.cpp:136] Iteration 145400, lr = 0.0009125, m = 0.9
I0802 11:25:57.459067 18636 solver.cpp:353] Iteration 145500 (7.20002 iter/s, 13.8888s/100 iter), loss = 1.25875
I0802 11:25:57.459092 18636 solver.cpp:375]     Train net output #0: loss = 1.158 (* 1 = 1.158 loss)
I0802 11:25:57.459096 18636 sgd_solver.cpp:136] Iteration 145500, lr = 0.00090625, m = 0.9
I0802 11:26:11.490809 18636 solver.cpp:353] Iteration 145600 (7.1269 iter/s, 14.0314s/100 iter), loss = 1.33435
I0802 11:26:11.490833 18636 solver.cpp:375]     Train net output #0: loss = 1.70921 (* 1 = 1.70921 loss)
I0802 11:26:11.490839 18636 sgd_solver.cpp:136] Iteration 145600, lr = 0.0009, m = 0.9
I0802 11:26:25.429002 18636 solver.cpp:353] Iteration 145700 (7.17473 iter/s, 13.9378s/100 iter), loss = 1.48368
I0802 11:26:25.429083 18636 solver.cpp:375]     Train net output #0: loss = 1.42845 (* 1 = 1.42845 loss)
I0802 11:26:25.429090 18636 sgd_solver.cpp:136] Iteration 145700, lr = 0.00089375, m = 0.9
I0802 11:26:39.423571 18636 solver.cpp:353] Iteration 145800 (7.14583 iter/s, 13.9942s/100 iter), loss = 1.40255
I0802 11:26:39.423604 18636 solver.cpp:375]     Train net output #0: loss = 1.49684 (* 1 = 1.49684 loss)
I0802 11:26:39.423610 18636 sgd_solver.cpp:136] Iteration 145800, lr = 0.0008875, m = 0.9
I0802 11:26:53.457383 18636 solver.cpp:353] Iteration 145900 (7.12585 iter/s, 14.0334s/100 iter), loss = 1.92962
I0802 11:26:53.457417 18636 solver.cpp:375]     Train net output #0: loss = 2.03531 (* 1 = 2.03531 loss)
I0802 11:26:53.457422 18636 sgd_solver.cpp:136] Iteration 145900, lr = 0.00088125, m = 0.9
I0802 11:27:07.243315 18636 solver.cpp:404] Sparsity after update:
I0802 11:27:07.248476 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:27:07.248654 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:27:07.248755 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:27:07.248852 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:27:07.248944 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:27:07.249039 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:27:07.249155 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:27:07.249228 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:27:07.249245 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:27:07.249260 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:27:07.249275 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:27:07.249290 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:27:07.249305 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:27:07.249337 18636 solver.cpp:550] Iteration 146000, Testing net (#0)
I0802 11:27:26.737860 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.595117
I0802 11:27:26.737885 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.82235
I0802 11:27:26.737890 18636 solver.cpp:635]     Test net output #2: loss = 1.75301 (* 1 = 1.75301 loss)
I0802 11:27:26.738116 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4882s
I0802 11:27:26.874523 18636 solver.cpp:353] Iteration 146000 (2.99256 iter/s, 33.4162s/100 iter), loss = 1.23914
I0802 11:27:26.874552 18636 solver.cpp:375]     Train net output #0: loss = 1.22793 (* 1 = 1.22793 loss)
I0802 11:27:26.874615 18636 sgd_solver.cpp:136] Iteration 146000, lr = 0.000875, m = 0.9
I0802 11:27:40.817167 18636 solver.cpp:353] Iteration 146100 (7.17244 iter/s, 13.9423s/100 iter), loss = 1.08719
I0802 11:27:40.817291 18636 solver.cpp:375]     Train net output #0: loss = 0.798414 (* 1 = 0.798414 loss)
I0802 11:27:40.817311 18636 sgd_solver.cpp:136] Iteration 146100, lr = 0.00086875, m = 0.9
I0802 11:27:54.739648 18636 solver.cpp:353] Iteration 146200 (7.18283 iter/s, 13.9221s/100 iter), loss = 1.11924
I0802 11:27:54.739681 18636 solver.cpp:375]     Train net output #0: loss = 1.3272 (* 1 = 1.3272 loss)
I0802 11:27:54.739687 18636 sgd_solver.cpp:136] Iteration 146200, lr = 0.0008625, m = 0.9
I0802 11:28:08.592671 18636 solver.cpp:353] Iteration 146300 (7.21884 iter/s, 13.8526s/100 iter), loss = 1.19014
I0802 11:28:08.592700 18636 solver.cpp:375]     Train net output #0: loss = 1.23571 (* 1 = 1.23571 loss)
I0802 11:28:08.592706 18636 sgd_solver.cpp:136] Iteration 146300, lr = 0.00085625, m = 0.9
I0802 11:28:22.627697 18636 solver.cpp:353] Iteration 146400 (7.12523 iter/s, 14.0346s/100 iter), loss = 1.62929
I0802 11:28:22.627758 18636 solver.cpp:375]     Train net output #0: loss = 1.70528 (* 1 = 1.70528 loss)
I0802 11:28:22.627763 18636 sgd_solver.cpp:136] Iteration 146400, lr = 0.00085, m = 0.9
I0802 11:28:36.517572 18636 solver.cpp:353] Iteration 146500 (7.19969 iter/s, 13.8895s/100 iter), loss = 1.18751
I0802 11:28:36.517666 18636 solver.cpp:375]     Train net output #0: loss = 1.11464 (* 1 = 1.11464 loss)
I0802 11:28:36.517688 18636 sgd_solver.cpp:136] Iteration 146500, lr = 0.00084375, m = 0.9
I0802 11:28:50.423141 18636 solver.cpp:353] Iteration 146600 (7.19156 iter/s, 13.9052s/100 iter), loss = 1.61013
I0802 11:28:50.423171 18636 solver.cpp:375]     Train net output #0: loss = 1.57835 (* 1 = 1.57835 loss)
I0802 11:28:50.423177 18636 sgd_solver.cpp:136] Iteration 146600, lr = 0.0008375, m = 0.9
I0802 11:29:04.421890 18636 solver.cpp:353] Iteration 146700 (7.14369 iter/s, 13.9984s/100 iter), loss = 1.38296
I0802 11:29:04.422013 18636 solver.cpp:375]     Train net output #0: loss = 1.6254 (* 1 = 1.6254 loss)
I0802 11:29:04.422032 18636 sgd_solver.cpp:136] Iteration 146700, lr = 0.00083125, m = 0.9
I0802 11:29:18.452179 18636 solver.cpp:353] Iteration 146800 (7.12763 iter/s, 14.0299s/100 iter), loss = 1.55365
I0802 11:29:18.452206 18636 solver.cpp:375]     Train net output #0: loss = 1.79012 (* 1 = 1.79012 loss)
I0802 11:29:18.452211 18636 sgd_solver.cpp:136] Iteration 146800, lr = 0.000825, m = 0.9
I0802 11:29:32.472455 18636 solver.cpp:353] Iteration 146900 (7.13273 iter/s, 14.0199s/100 iter), loss = 1.29596
I0802 11:29:32.472489 18636 solver.cpp:375]     Train net output #0: loss = 1.18621 (* 1 = 1.18621 loss)
I0802 11:29:32.472493 18636 sgd_solver.cpp:136] Iteration 146900, lr = 0.00081875, m = 0.9
I0802 11:29:46.382127 18636 solver.cpp:404] Sparsity after update:
I0802 11:29:46.396091 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:29:46.396191 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:29:46.396221 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:29:46.396239 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:29:46.396255 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:29:46.396267 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:29:46.396280 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:29:46.396291 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:29:46.396304 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:29:46.396327 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:29:46.396340 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:29:46.396353 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:29:46.396365 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:29:46.527338 18636 solver.cpp:353] Iteration 147000 (7.11516 iter/s, 14.0545s/100 iter), loss = 1.87244
I0802 11:29:46.527369 18636 solver.cpp:375]     Train net output #0: loss = 2.19166 (* 1 = 2.19166 loss)
I0802 11:29:46.527376 18636 sgd_solver.cpp:136] Iteration 147000, lr = 0.0008125, m = 0.9
I0802 11:30:00.581209 18636 solver.cpp:353] Iteration 147100 (7.11567 iter/s, 14.0535s/100 iter), loss = 1.19585
I0802 11:30:00.581265 18636 solver.cpp:375]     Train net output #0: loss = 0.910317 (* 1 = 0.910317 loss)
I0802 11:30:00.581287 18636 sgd_solver.cpp:136] Iteration 147100, lr = 0.00080625, m = 0.9
I0802 11:30:14.569136 18636 solver.cpp:353] Iteration 147200 (7.14922 iter/s, 13.9875s/100 iter), loss = 1.4624
I0802 11:30:14.569190 18636 solver.cpp:375]     Train net output #0: loss = 1.69846 (* 1 = 1.69846 loss)
I0802 11:30:14.569203 18636 sgd_solver.cpp:136] Iteration 147200, lr = 0.0008, m = 0.9
I0802 11:30:28.809895 18636 solver.cpp:353] Iteration 147300 (7.02229 iter/s, 14.2404s/100 iter), loss = 0.966283
I0802 11:30:28.809998 18636 solver.cpp:375]     Train net output #0: loss = 0.946633 (* 1 = 0.946633 loss)
I0802 11:30:28.810004 18636 sgd_solver.cpp:136] Iteration 147300, lr = 0.00079375, m = 0.9
I0802 11:30:42.891916 18636 solver.cpp:353] Iteration 147400 (7.10145 iter/s, 14.0816s/100 iter), loss = 1.37443
I0802 11:30:42.891942 18636 solver.cpp:375]     Train net output #0: loss = 1.41783 (* 1 = 1.41783 loss)
I0802 11:30:42.891947 18636 sgd_solver.cpp:136] Iteration 147400, lr = 0.0007875, m = 0.9
I0802 11:30:56.912236 18636 solver.cpp:353] Iteration 147500 (7.1327 iter/s, 14.0199s/100 iter), loss = 1.25536
I0802 11:30:56.912261 18636 solver.cpp:375]     Train net output #0: loss = 1.02847 (* 1 = 1.02847 loss)
I0802 11:30:56.912266 18636 sgd_solver.cpp:136] Iteration 147500, lr = 0.00078125, m = 0.9
I0802 11:31:10.857516 18636 solver.cpp:353] Iteration 147600 (7.17108 iter/s, 13.9449s/100 iter), loss = 1.08857
I0802 11:31:10.857591 18636 solver.cpp:375]     Train net output #0: loss = 1.26227 (* 1 = 1.26227 loss)
I0802 11:31:10.857597 18636 sgd_solver.cpp:136] Iteration 147600, lr = 0.000775, m = 0.9
I0802 11:31:24.962972 18636 solver.cpp:353] Iteration 147700 (7.08965 iter/s, 14.1051s/100 iter), loss = 1.41942
I0802 11:31:24.963001 18636 solver.cpp:375]     Train net output #0: loss = 1.4384 (* 1 = 1.4384 loss)
I0802 11:31:24.963006 18636 sgd_solver.cpp:136] Iteration 147700, lr = 0.00076875, m = 0.9
I0802 11:31:38.992924 18636 solver.cpp:353] Iteration 147800 (7.1278 iter/s, 14.0296s/100 iter), loss = 1.71926
I0802 11:31:38.992949 18636 solver.cpp:375]     Train net output #0: loss = 1.75389 (* 1 = 1.75389 loss)
I0802 11:31:38.992955 18636 sgd_solver.cpp:136] Iteration 147800, lr = 0.0007625, m = 0.9
I0802 11:31:53.295266 18636 solver.cpp:353] Iteration 147900 (6.99205 iter/s, 14.3019s/100 iter), loss = 1.47309
I0802 11:31:53.295341 18636 solver.cpp:375]     Train net output #0: loss = 1.71563 (* 1 = 1.71563 loss)
I0802 11:31:53.295347 18636 sgd_solver.cpp:136] Iteration 147900, lr = 0.00075625, m = 0.9
I0802 11:32:07.141373 18636 solver.cpp:404] Sparsity after update:
I0802 11:32:07.146383 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:32:07.146394 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:32:07.146400 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:32:07.146404 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:32:07.146406 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:32:07.146410 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:32:07.146414 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:32:07.146417 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:32:07.146421 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:32:07.146425 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:32:07.146428 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:32:07.146433 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:32:07.146436 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:32:07.146448 18636 solver.cpp:550] Iteration 148000, Testing net (#0)
I0802 11:32:26.618331 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.593235
I0802 11:32:26.618401 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.820644
I0802 11:32:26.618412 18636 solver.cpp:635]     Test net output #2: loss = 1.75509 (* 1 = 1.75509 loss)
I0802 11:32:26.618435 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4715s
I0802 11:32:26.763950 18636 solver.cpp:353] Iteration 148000 (2.98795 iter/s, 33.4678s/100 iter), loss = 1.11303
I0802 11:32:26.763983 18636 solver.cpp:375]     Train net output #0: loss = 1.28604 (* 1 = 1.28604 loss)
I0802 11:32:26.763986 18636 sgd_solver.cpp:136] Iteration 148000, lr = 0.00075, m = 0.9
I0802 11:32:40.697044 18636 solver.cpp:353] Iteration 148100 (7.17736 iter/s, 13.9327s/100 iter), loss = 1.39559
I0802 11:32:40.697070 18636 solver.cpp:375]     Train net output #0: loss = 1.40616 (* 1 = 1.40616 loss)
I0802 11:32:40.697077 18636 sgd_solver.cpp:136] Iteration 148100, lr = 0.00074375, m = 0.9
I0802 11:32:54.835325 18636 solver.cpp:353] Iteration 148200 (7.07319 iter/s, 14.1379s/100 iter), loss = 1.01646
I0802 11:32:54.835353 18636 solver.cpp:375]     Train net output #0: loss = 1.17068 (* 1 = 1.17068 loss)
I0802 11:32:54.835361 18636 sgd_solver.cpp:136] Iteration 148200, lr = 0.0007375, m = 0.9
I0802 11:33:08.928104 18636 solver.cpp:353] Iteration 148300 (7.09603 iter/s, 14.0924s/100 iter), loss = 1.19
I0802 11:33:08.928181 18636 solver.cpp:375]     Train net output #0: loss = 1.00703 (* 1 = 1.00703 loss)
I0802 11:33:08.928189 18636 sgd_solver.cpp:136] Iteration 148300, lr = 0.00073125, m = 0.9
I0802 11:33:23.158668 18636 solver.cpp:353] Iteration 148400 (7.02732 iter/s, 14.2302s/100 iter), loss = 1.38536
I0802 11:33:23.158695 18636 solver.cpp:375]     Train net output #0: loss = 1.424 (* 1 = 1.424 loss)
I0802 11:33:23.158701 18636 sgd_solver.cpp:136] Iteration 148400, lr = 0.000725, m = 0.9
I0802 11:33:37.064863 18636 solver.cpp:353] Iteration 148500 (7.19124 iter/s, 13.9058s/100 iter), loss = 1.09853
I0802 11:33:37.064895 18636 solver.cpp:375]     Train net output #0: loss = 1.05972 (* 1 = 1.05972 loss)
I0802 11:33:37.064903 18636 sgd_solver.cpp:136] Iteration 148500, lr = 0.00071875, m = 0.9
I0802 11:33:51.066584 18636 solver.cpp:353] Iteration 148600 (7.14218 iter/s, 14.0013s/100 iter), loss = 1.40854
I0802 11:33:51.066710 18636 solver.cpp:375]     Train net output #0: loss = 1.17097 (* 1 = 1.17097 loss)
I0802 11:33:51.066730 18636 sgd_solver.cpp:136] Iteration 148600, lr = 0.0007125, m = 0.9
I0802 11:34:05.269552 18636 solver.cpp:353] Iteration 148700 (7.04098 iter/s, 14.2026s/100 iter), loss = 1.28712
I0802 11:34:05.269580 18636 solver.cpp:375]     Train net output #0: loss = 1.39642 (* 1 = 1.39642 loss)
I0802 11:34:05.269587 18636 sgd_solver.cpp:136] Iteration 148700, lr = 0.00070625, m = 0.9
I0802 11:34:19.212249 18636 solver.cpp:353] Iteration 148800 (7.17241 iter/s, 13.9423s/100 iter), loss = 1.17114
I0802 11:34:19.212280 18636 solver.cpp:375]     Train net output #0: loss = 1.16087 (* 1 = 1.16087 loss)
I0802 11:34:19.212286 18636 sgd_solver.cpp:136] Iteration 148800, lr = 0.0007, m = 0.9
I0802 11:34:33.281287 18636 solver.cpp:353] Iteration 148900 (7.108 iter/s, 14.0686s/100 iter), loss = 1.17149
I0802 11:34:33.281350 18636 solver.cpp:375]     Train net output #0: loss = 1.08011 (* 1 = 1.08011 loss)
I0802 11:34:33.281358 18636 sgd_solver.cpp:136] Iteration 148900, lr = 0.00069375, m = 0.9
I0802 11:34:47.214671 18636 solver.cpp:404] Sparsity after update:
I0802 11:34:47.225177 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:34:47.225190 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:34:47.225199 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:34:47.225203 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:34:47.225205 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:34:47.225209 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:34:47.225214 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:34:47.225217 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:34:47.225221 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:34:47.225225 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:34:47.225229 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:34:47.225232 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:34:47.225235 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:34:47.364859 18636 solver.cpp:353] Iteration 149000 (7.10067 iter/s, 14.0832s/100 iter), loss = 1.41666
I0802 11:34:47.364886 18636 solver.cpp:375]     Train net output #0: loss = 1.25952 (* 1 = 1.25952 loss)
I0802 11:34:47.364890 18636 sgd_solver.cpp:136] Iteration 149000, lr = 0.0006875, m = 0.9
I0802 11:35:01.383285 18636 solver.cpp:353] Iteration 149100 (7.13367 iter/s, 14.018s/100 iter), loss = 1.4093
I0802 11:35:01.383311 18636 solver.cpp:375]     Train net output #0: loss = 1.63157 (* 1 = 1.63157 loss)
I0802 11:35:01.383317 18636 sgd_solver.cpp:136] Iteration 149100, lr = 0.00068125, m = 0.9
I0802 11:35:15.324658 18636 solver.cpp:353] Iteration 149200 (7.17309 iter/s, 13.941s/100 iter), loss = 1.44665
I0802 11:35:15.324746 18636 solver.cpp:375]     Train net output #0: loss = 1.48443 (* 1 = 1.48443 loss)
I0802 11:35:15.324753 18636 sgd_solver.cpp:136] Iteration 149200, lr = 0.000675, m = 0.9
I0802 11:35:29.406072 18636 solver.cpp:353] Iteration 149300 (7.10175 iter/s, 14.081s/100 iter), loss = 1.31102
I0802 11:35:29.406108 18636 solver.cpp:375]     Train net output #0: loss = 1.19287 (* 1 = 1.19287 loss)
I0802 11:35:29.406114 18636 sgd_solver.cpp:136] Iteration 149300, lr = 0.00066875, m = 0.9
I0802 11:35:43.369595 18636 solver.cpp:353] Iteration 149400 (7.16171 iter/s, 13.9631s/100 iter), loss = 1.42343
I0802 11:35:43.369622 18636 solver.cpp:375]     Train net output #0: loss = 1.49325 (* 1 = 1.49325 loss)
I0802 11:35:43.369627 18636 sgd_solver.cpp:136] Iteration 149400, lr = 0.0006625, m = 0.9
I0802 11:35:57.381333 18636 solver.cpp:353] Iteration 149500 (7.13707 iter/s, 14.0114s/100 iter), loss = 1.24056
I0802 11:35:57.381407 18636 solver.cpp:375]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0802 11:35:57.381414 18636 sgd_solver.cpp:136] Iteration 149500, lr = 0.00065625, m = 0.9
I0802 11:36:11.394445 18636 solver.cpp:353] Iteration 149600 (7.13637 iter/s, 14.0127s/100 iter), loss = 1.27946
I0802 11:36:11.394472 18636 solver.cpp:375]     Train net output #0: loss = 1.45157 (* 1 = 1.45157 loss)
I0802 11:36:11.394479 18636 sgd_solver.cpp:136] Iteration 149600, lr = 0.00065, m = 0.9
I0802 11:36:25.301125 18636 solver.cpp:353] Iteration 149700 (7.19099 iter/s, 13.9063s/100 iter), loss = 1.37463
I0802 11:36:25.301200 18636 solver.cpp:375]     Train net output #0: loss = 1.15878 (* 1 = 1.15878 loss)
I0802 11:36:25.301223 18636 sgd_solver.cpp:136] Iteration 149700, lr = 0.00064375, m = 0.9
I0802 11:36:39.298321 18636 solver.cpp:353] Iteration 149800 (7.14448 iter/s, 13.9968s/100 iter), loss = 1.14414
I0802 11:36:39.298400 18636 solver.cpp:375]     Train net output #0: loss = 1.24349 (* 1 = 1.24349 loss)
I0802 11:36:39.298408 18636 sgd_solver.cpp:136] Iteration 149800, lr = 0.0006375, m = 0.9
I0802 11:36:53.264767 18636 solver.cpp:353] Iteration 149900 (7.16021 iter/s, 13.9661s/100 iter), loss = 1.31889
I0802 11:36:53.264796 18636 solver.cpp:375]     Train net output #0: loss = 1.38855 (* 1 = 1.38855 loss)
I0802 11:36:53.264802 18636 sgd_solver.cpp:136] Iteration 149900, lr = 0.00063125, m = 0.9
I0802 11:37:07.049062 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_150000.caffemodel
I0802 11:37:07.139809 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_150000.solverstate
I0802 11:37:07.146023 18636 solver.cpp:404] Sparsity after update:
I0802 11:37:07.149183 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:37:07.149211 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:37:07.149230 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:37:07.149240 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:37:07.149248 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:37:07.149258 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:37:07.149269 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:37:07.149278 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:37:07.149287 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:37:07.149300 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:37:07.149308 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:37:07.149317 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:37:07.149325 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:37:07.149344 18636 solver.cpp:550] Iteration 150000, Testing net (#0)
I0802 11:37:20.965715 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:37:26.857408 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.594235
I0802 11:37:26.857434 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.820997
I0802 11:37:26.857439 18636 solver.cpp:635]     Test net output #2: loss = 1.76753 (* 1 = 1.76753 loss)
I0802 11:37:26.857460 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7076s
I0802 11:37:27.022351 18636 solver.cpp:353] Iteration 150000 (2.96238 iter/s, 33.7567s/100 iter), loss = 1.26078
I0802 11:37:27.022378 18636 solver.cpp:375]     Train net output #0: loss = 1.3744 (* 1 = 1.3744 loss)
I0802 11:37:27.022384 18636 sgd_solver.cpp:136] Iteration 150000, lr = 0.000625, m = 0.9
I0802 11:37:41.046640 18636 solver.cpp:353] Iteration 150100 (7.13069 iter/s, 14.0239s/100 iter), loss = 1.0329
I0802 11:37:41.046674 18636 solver.cpp:375]     Train net output #0: loss = 1.14736 (* 1 = 1.14736 loss)
I0802 11:37:41.046680 18636 sgd_solver.cpp:136] Iteration 150100, lr = 0.00061875, m = 0.9
I0802 11:37:55.126945 18636 solver.cpp:353] Iteration 150200 (7.10231 iter/s, 14.0799s/100 iter), loss = 1.23432
I0802 11:37:55.126999 18636 solver.cpp:375]     Train net output #0: loss = 1.31091 (* 1 = 1.31091 loss)
I0802 11:37:55.127005 18636 sgd_solver.cpp:136] Iteration 150200, lr = 0.0006125, m = 0.9
I0802 11:38:09.102627 18636 solver.cpp:353] Iteration 150300 (7.15548 iter/s, 13.9753s/100 iter), loss = 1.19774
I0802 11:38:09.102653 18636 solver.cpp:375]     Train net output #0: loss = 1.03457 (* 1 = 1.03457 loss)
I0802 11:38:09.102658 18636 sgd_solver.cpp:136] Iteration 150300, lr = 0.00060625, m = 0.9
I0802 11:38:22.994369 18636 solver.cpp:353] Iteration 150400 (7.19872 iter/s, 13.8914s/100 iter), loss = 1.35344
I0802 11:38:22.994405 18636 solver.cpp:375]     Train net output #0: loss = 1.35564 (* 1 = 1.35564 loss)
I0802 11:38:22.994410 18636 sgd_solver.cpp:136] Iteration 150400, lr = 0.0006, m = 0.9
I0802 11:38:36.867291 18636 solver.cpp:353] Iteration 150500 (7.20849 iter/s, 13.8725s/100 iter), loss = 1.26955
I0802 11:38:36.867394 18636 solver.cpp:375]     Train net output #0: loss = 1.23964 (* 1 = 1.23964 loss)
I0802 11:38:36.867413 18636 sgd_solver.cpp:136] Iteration 150500, lr = 0.00059375, m = 0.9
I0802 11:38:50.771713 18636 solver.cpp:353] Iteration 150600 (7.19215 iter/s, 13.904s/100 iter), loss = 1.16902
I0802 11:38:50.771739 18636 solver.cpp:375]     Train net output #0: loss = 1.25418 (* 1 = 1.25418 loss)
I0802 11:38:50.771742 18636 sgd_solver.cpp:136] Iteration 150600, lr = 0.0005875, m = 0.9
I0802 11:39:04.686683 18636 solver.cpp:353] Iteration 150700 (7.1867 iter/s, 13.9146s/100 iter), loss = 1.32402
I0802 11:39:04.686708 18636 solver.cpp:375]     Train net output #0: loss = 1.5675 (* 1 = 1.5675 loss)
I0802 11:39:04.686714 18636 sgd_solver.cpp:136] Iteration 150700, lr = 0.00058125, m = 0.9
I0802 11:39:18.669878 18636 solver.cpp:353] Iteration 150800 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.7505
I0802 11:39:18.669934 18636 solver.cpp:375]     Train net output #0: loss = 1.91647 (* 1 = 1.91647 loss)
I0802 11:39:18.669940 18636 sgd_solver.cpp:136] Iteration 150800, lr = 0.000575, m = 0.9
I0802 11:39:32.662202 18636 solver.cpp:353] Iteration 150900 (7.14697 iter/s, 13.9919s/100 iter), loss = 1.25603
I0802 11:39:32.662230 18636 solver.cpp:375]     Train net output #0: loss = 1.14988 (* 1 = 1.14988 loss)
I0802 11:39:32.662233 18636 sgd_solver.cpp:136] Iteration 150900, lr = 0.00056875, m = 0.9
I0802 11:39:46.469586 18636 solver.cpp:404] Sparsity after update:
I0802 11:39:46.484884 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:39:46.484897 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:39:46.484905 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:39:46.484906 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:39:46.484908 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:39:46.484910 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:39:46.484912 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:39:46.484915 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:39:46.484916 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:39:46.484918 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:39:46.484920 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:39:46.484921 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:39:46.484923 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:39:46.618747 18636 solver.cpp:353] Iteration 151000 (7.16529 iter/s, 13.9562s/100 iter), loss = 1.19327
I0802 11:39:46.618770 18636 solver.cpp:375]     Train net output #0: loss = 1.07802 (* 1 = 1.07802 loss)
I0802 11:39:46.618777 18636 sgd_solver.cpp:136] Iteration 151000, lr = 0.0005625, m = 0.9
I0802 11:40:00.544242 18636 solver.cpp:353] Iteration 151100 (7.18127 iter/s, 13.9251s/100 iter), loss = 1.24504
I0802 11:40:00.544318 18636 solver.cpp:375]     Train net output #0: loss = 1.28096 (* 1 = 1.28096 loss)
I0802 11:40:00.544325 18636 sgd_solver.cpp:136] Iteration 151100, lr = 0.00055625, m = 0.9
I0802 11:40:14.494585 18636 solver.cpp:353] Iteration 151200 (7.16848 iter/s, 13.95s/100 iter), loss = 1.36345
I0802 11:40:14.494616 18636 solver.cpp:375]     Train net output #0: loss = 1.22347 (* 1 = 1.22347 loss)
I0802 11:40:14.494621 18636 sgd_solver.cpp:136] Iteration 151200, lr = 0.00055, m = 0.9
I0802 11:40:28.753473 18636 solver.cpp:353] Iteration 151300 (7.01336 iter/s, 14.2585s/100 iter), loss = 1.25633
I0802 11:40:28.753502 18636 solver.cpp:375]     Train net output #0: loss = 1.48047 (* 1 = 1.48047 loss)
I0802 11:40:28.753509 18636 sgd_solver.cpp:136] Iteration 151300, lr = 0.00054375, m = 0.9
I0802 11:40:42.709946 18636 solver.cpp:353] Iteration 151400 (7.16533 iter/s, 13.9561s/100 iter), loss = 1.16135
I0802 11:40:42.710005 18636 solver.cpp:375]     Train net output #0: loss = 1.30551 (* 1 = 1.30551 loss)
I0802 11:40:42.710011 18636 sgd_solver.cpp:136] Iteration 151400, lr = 0.0005375, m = 0.9
I0802 11:40:56.981022 18636 solver.cpp:353] Iteration 151500 (7.00737 iter/s, 14.2707s/100 iter), loss = 1.83674
I0802 11:40:56.981047 18636 solver.cpp:375]     Train net output #0: loss = 2.25326 (* 1 = 2.25326 loss)
I0802 11:40:56.981052 18636 sgd_solver.cpp:136] Iteration 151500, lr = 0.00053125, m = 0.9
I0802 11:41:11.217921 18636 solver.cpp:353] Iteration 151600 (7.0242 iter/s, 14.2365s/100 iter), loss = 1.4707
I0802 11:41:11.218004 18636 solver.cpp:375]     Train net output #0: loss = 1.26735 (* 1 = 1.26735 loss)
I0802 11:41:11.218025 18636 sgd_solver.cpp:136] Iteration 151600, lr = 0.000525, m = 0.9
I0802 11:41:25.232522 18636 solver.cpp:353] Iteration 151700 (7.13561 iter/s, 14.0142s/100 iter), loss = 1.71721
I0802 11:41:25.232595 18636 solver.cpp:375]     Train net output #0: loss = 1.68313 (* 1 = 1.68313 loss)
I0802 11:41:25.232604 18636 sgd_solver.cpp:136] Iteration 151700, lr = 0.00051875, m = 0.9
I0802 11:41:39.224946 18636 solver.cpp:353] Iteration 151800 (7.14692 iter/s, 13.992s/100 iter), loss = 1.10707
I0802 11:41:39.225011 18636 solver.cpp:375]     Train net output #0: loss = 1.3282 (* 1 = 1.3282 loss)
I0802 11:41:39.225024 18636 sgd_solver.cpp:136] Iteration 151800, lr = 0.0005125, m = 0.9
I0802 11:41:53.321758 18636 solver.cpp:353] Iteration 151900 (7.094 iter/s, 14.0964s/100 iter), loss = 1.85981
I0802 11:41:53.321784 18636 solver.cpp:375]     Train net output #0: loss = 2.27163 (* 1 = 2.27163 loss)
I0802 11:41:53.321789 18636 sgd_solver.cpp:136] Iteration 151900, lr = 0.00050625, m = 0.9
I0802 11:42:07.253010 18636 solver.cpp:404] Sparsity after update:
I0802 11:42:07.257289 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:42:07.257324 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:42:07.257347 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:42:07.257356 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:42:07.257364 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:42:07.257372 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:42:07.257380 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:42:07.257386 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:42:07.257393 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:42:07.257401 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:42:07.257410 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:42:07.257416 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:42:07.257423 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:42:07.257447 18636 solver.cpp:550] Iteration 152000, Testing net (#0)
I0802 11:42:27.042915 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.597353
I0802 11:42:27.042939 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821409
I0802 11:42:27.042944 18636 solver.cpp:635]     Test net output #2: loss = 1.74317 (* 1 = 1.74317 loss)
I0802 11:42:27.044925 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7869s
I0802 11:42:27.180780 18636 solver.cpp:353] Iteration 152000 (2.9535 iter/s, 33.8581s/100 iter), loss = 1.35058
I0802 11:42:27.180809 18636 solver.cpp:375]     Train net output #0: loss = 1.24402 (* 1 = 1.24402 loss)
I0802 11:42:27.180825 18636 sgd_solver.cpp:136] Iteration 152000, lr = 0.0005, m = 0.9
I0802 11:42:41.190059 18636 solver.cpp:353] Iteration 152100 (7.13833 iter/s, 14.0089s/100 iter), loss = 1.67263
I0802 11:42:41.190124 18636 solver.cpp:375]     Train net output #0: loss = 1.91185 (* 1 = 1.91185 loss)
I0802 11:42:41.190130 18636 sgd_solver.cpp:136] Iteration 152100, lr = 0.00049375, m = 0.9
I0802 11:42:55.205901 18636 solver.cpp:353] Iteration 152200 (7.13498 iter/s, 14.0155s/100 iter), loss = 1.28579
I0802 11:42:55.205931 18636 solver.cpp:375]     Train net output #0: loss = 1.33586 (* 1 = 1.33586 loss)
I0802 11:42:55.205936 18636 sgd_solver.cpp:136] Iteration 152200, lr = 0.0004875, m = 0.9
I0802 11:43:09.198330 18636 solver.cpp:353] Iteration 152300 (7.14692 iter/s, 13.992s/100 iter), loss = 1.38182
I0802 11:43:09.198359 18636 solver.cpp:375]     Train net output #0: loss = 1.01972 (* 1 = 1.01972 loss)
I0802 11:43:09.198365 18636 sgd_solver.cpp:136] Iteration 152300, lr = 0.00048125, m = 0.9
I0802 11:43:23.076411 18636 solver.cpp:353] Iteration 152400 (7.20581 iter/s, 13.8777s/100 iter), loss = 1.67236
I0802 11:43:23.076514 18636 solver.cpp:375]     Train net output #0: loss = 1.6482 (* 1 = 1.6482 loss)
I0802 11:43:23.076522 18636 sgd_solver.cpp:136] Iteration 152400, lr = 0.000475, m = 0.9
I0802 11:43:37.198633 18636 solver.cpp:353] Iteration 152500 (7.08123 iter/s, 14.1218s/100 iter), loss = 1.42989
I0802 11:43:37.198685 18636 solver.cpp:375]     Train net output #0: loss = 1.5735 (* 1 = 1.5735 loss)
I0802 11:43:37.198698 18636 sgd_solver.cpp:136] Iteration 152500, lr = 0.00046875, m = 0.9
I0802 11:43:51.265012 18636 solver.cpp:353] Iteration 152600 (7.10935 iter/s, 14.066s/100 iter), loss = 1.33252
I0802 11:43:51.265038 18636 solver.cpp:375]     Train net output #0: loss = 1.52829 (* 1 = 1.52829 loss)
I0802 11:43:51.265043 18636 sgd_solver.cpp:136] Iteration 152600, lr = 0.0004625, m = 0.9
I0802 11:44:05.186854 18636 solver.cpp:353] Iteration 152700 (7.18316 iter/s, 13.9215s/100 iter), loss = 1.0193
I0802 11:44:05.186933 18636 solver.cpp:375]     Train net output #0: loss = 1.12443 (* 1 = 1.12443 loss)
I0802 11:44:05.186946 18636 sgd_solver.cpp:136] Iteration 152700, lr = 0.00045625, m = 0.9
I0802 11:44:19.285681 18636 solver.cpp:353] Iteration 152800 (7.09299 iter/s, 14.0984s/100 iter), loss = 1.1976
I0802 11:44:19.285711 18636 solver.cpp:375]     Train net output #0: loss = 1.18495 (* 1 = 1.18495 loss)
I0802 11:44:19.285714 18636 sgd_solver.cpp:136] Iteration 152800, lr = 0.00045, m = 0.9
I0802 11:44:33.188010 18636 solver.cpp:353] Iteration 152900 (7.19324 iter/s, 13.9019s/100 iter), loss = 1.27445
I0802 11:44:33.188035 18636 solver.cpp:375]     Train net output #0: loss = 1.40357 (* 1 = 1.40357 loss)
I0802 11:44:33.188041 18636 sgd_solver.cpp:136] Iteration 152900, lr = 0.00044375, m = 0.9
I0802 11:44:47.115128 18636 solver.cpp:404] Sparsity after update:
I0802 11:44:47.130409 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:44:47.130422 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:44:47.130431 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:44:47.130435 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:44:47.130439 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:44:47.130444 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:44:47.130446 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:44:47.130450 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:44:47.130452 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:44:47.130455 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:44:47.130458 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:44:47.130461 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:44:47.130465 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:44:47.260123 18636 solver.cpp:353] Iteration 153000 (7.10645 iter/s, 14.0717s/100 iter), loss = 1.91205
I0802 11:44:47.260149 18636 solver.cpp:375]     Train net output #0: loss = 1.75958 (* 1 = 1.75958 loss)
I0802 11:44:47.260154 18636 sgd_solver.cpp:136] Iteration 153000, lr = 0.0004375, m = 0.9
I0802 11:45:01.221174 18636 solver.cpp:353] Iteration 153100 (7.16298 iter/s, 13.9607s/100 iter), loss = 1.28431
I0802 11:45:01.221199 18636 solver.cpp:375]     Train net output #0: loss = 1.56884 (* 1 = 1.56884 loss)
I0802 11:45:01.221202 18636 sgd_solver.cpp:136] Iteration 153100, lr = 0.00043125, m = 0.9
I0802 11:45:15.268788 18636 solver.cpp:353] Iteration 153200 (7.11884 iter/s, 14.0472s/100 iter), loss = 1.34195
I0802 11:45:15.268826 18636 solver.cpp:375]     Train net output #0: loss = 1.3871 (* 1 = 1.3871 loss)
I0802 11:45:15.268833 18636 sgd_solver.cpp:136] Iteration 153200, lr = 0.000425, m = 0.9
I0802 11:45:29.236768 18636 solver.cpp:353] Iteration 153300 (7.15943 iter/s, 13.9676s/100 iter), loss = 1.4367
I0802 11:45:29.236866 18636 solver.cpp:375]     Train net output #0: loss = 1.38358 (* 1 = 1.38358 loss)
I0802 11:45:29.236879 18636 sgd_solver.cpp:136] Iteration 153300, lr = 0.00041875, m = 0.9
I0802 11:45:43.257155 18636 solver.cpp:353] Iteration 153400 (7.13267 iter/s, 14.02s/100 iter), loss = 1.73954
I0802 11:45:43.257251 18636 solver.cpp:375]     Train net output #0: loss = 1.71129 (* 1 = 1.71129 loss)
I0802 11:45:43.257270 18636 sgd_solver.cpp:136] Iteration 153400, lr = 0.0004125, m = 0.9
I0802 11:45:57.193217 18636 solver.cpp:353] Iteration 153500 (7.17583 iter/s, 13.9357s/100 iter), loss = 1.01902
I0802 11:45:57.193244 18636 solver.cpp:375]     Train net output #0: loss = 0.935565 (* 1 = 0.935565 loss)
I0802 11:45:57.193250 18636 sgd_solver.cpp:136] Iteration 153500, lr = 0.00040625, m = 0.9
I0802 11:46:11.113880 18636 solver.cpp:353] Iteration 153600 (7.18376 iter/s, 13.9203s/100 iter), loss = 1.18872
I0802 11:46:11.113961 18636 solver.cpp:375]     Train net output #0: loss = 1.11964 (* 1 = 1.11964 loss)
I0802 11:46:11.113975 18636 sgd_solver.cpp:136] Iteration 153600, lr = 0.0004, m = 0.9
I0802 11:46:25.109661 18636 solver.cpp:353] Iteration 153700 (7.14521 iter/s, 13.9954s/100 iter), loss = 1.56588
I0802 11:46:25.109685 18636 solver.cpp:375]     Train net output #0: loss = 1.38959 (* 1 = 1.38959 loss)
I0802 11:46:25.109689 18636 sgd_solver.cpp:136] Iteration 153700, lr = 0.00039375, m = 0.9
I0802 11:46:39.362329 18636 solver.cpp:353] Iteration 153800 (7.01643 iter/s, 14.2523s/100 iter), loss = 1.47752
I0802 11:46:39.362361 18636 solver.cpp:375]     Train net output #0: loss = 1.64974 (* 1 = 1.64974 loss)
I0802 11:46:39.362368 18636 sgd_solver.cpp:136] Iteration 153800, lr = 0.0003875, m = 0.9
I0802 11:46:53.441833 18636 solver.cpp:353] Iteration 153900 (7.10272 iter/s, 14.0791s/100 iter), loss = 1.33661
I0802 11:46:53.441910 18636 solver.cpp:375]     Train net output #0: loss = 1.43707 (* 1 = 1.43707 loss)
I0802 11:46:53.441916 18636 sgd_solver.cpp:136] Iteration 153900, lr = 0.00038125, m = 0.9
I0802 11:47:07.433465 18636 solver.cpp:404] Sparsity after update:
I0802 11:47:07.437940 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:47:07.437950 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:47:07.437958 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:47:07.437959 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:47:07.437961 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:47:07.437963 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:47:07.437965 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:47:07.437968 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:47:07.437973 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:47:07.437974 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:47:07.437976 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:47:07.437979 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:47:07.437983 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:47:07.437994 18636 solver.cpp:550] Iteration 154000, Testing net (#0)
I0802 11:47:27.376582 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.592588
I0802 11:47:27.376644 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818468
I0802 11:47:27.376651 18636 solver.cpp:635]     Test net output #2: loss = 1.77486 (* 1 = 1.77486 loss)
I0802 11:47:27.376670 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9381s
I0802 11:47:27.533879 18636 solver.cpp:353] Iteration 154000 (2.93332 iter/s, 34.0911s/100 iter), loss = 1.0654
I0802 11:47:27.533906 18636 solver.cpp:375]     Train net output #0: loss = 1.00879 (* 1 = 1.00879 loss)
I0802 11:47:27.533912 18636 sgd_solver.cpp:136] Iteration 154000, lr = 0.000375, m = 0.9
I0802 11:47:41.549482 18636 solver.cpp:353] Iteration 154100 (7.1351 iter/s, 14.0152s/100 iter), loss = 1.26634
I0802 11:47:41.549515 18636 solver.cpp:375]     Train net output #0: loss = 1.23883 (* 1 = 1.23883 loss)
I0802 11:47:41.549523 18636 sgd_solver.cpp:136] Iteration 154100, lr = 0.00036875, m = 0.9
I0802 11:47:55.457367 18636 solver.cpp:353] Iteration 154200 (7.19036 iter/s, 13.9075s/100 iter), loss = 1.25579
I0802 11:47:55.457393 18636 solver.cpp:375]     Train net output #0: loss = 1.3951 (* 1 = 1.3951 loss)
I0802 11:47:55.457398 18636 sgd_solver.cpp:136] Iteration 154200, lr = 0.0003625, m = 0.9
I0802 11:48:09.580948 18636 solver.cpp:353] Iteration 154300 (7.08056 iter/s, 14.1232s/100 iter), loss = 1.4149
I0802 11:48:09.581070 18636 solver.cpp:375]     Train net output #0: loss = 1.69923 (* 1 = 1.69923 loss)
I0802 11:48:09.581094 18636 sgd_solver.cpp:136] Iteration 154300, lr = 0.00035625, m = 0.9
I0802 11:48:23.704908 18636 solver.cpp:353] Iteration 154400 (7.08036 iter/s, 14.1236s/100 iter), loss = 1.16303
I0802 11:48:23.704944 18636 solver.cpp:375]     Train net output #0: loss = 1.24752 (* 1 = 1.24752 loss)
I0802 11:48:23.704951 18636 sgd_solver.cpp:136] Iteration 154400, lr = 0.00035, m = 0.9
I0802 11:48:37.664886 18636 solver.cpp:353] Iteration 154500 (7.16353 iter/s, 13.9596s/100 iter), loss = 1.20458
I0802 11:48:37.664952 18636 solver.cpp:375]     Train net output #0: loss = 1.29481 (* 1 = 1.29481 loss)
I0802 11:48:37.664965 18636 sgd_solver.cpp:136] Iteration 154500, lr = 0.00034375, m = 0.9
I0802 11:48:51.679968 18636 solver.cpp:353] Iteration 154600 (7.13537 iter/s, 14.0147s/100 iter), loss = 0.823556
I0802 11:48:51.680258 18636 solver.cpp:375]     Train net output #0: loss = 0.925412 (* 1 = 0.925412 loss)
I0802 11:48:51.680352 18636 sgd_solver.cpp:136] Iteration 154600, lr = 0.0003375, m = 0.9
I0802 11:49:05.727923 18636 solver.cpp:353] Iteration 154700 (7.11867 iter/s, 14.0476s/100 iter), loss = 1.58487
I0802 11:49:05.728034 18636 solver.cpp:375]     Train net output #0: loss = 1.19683 (* 1 = 1.19683 loss)
I0802 11:49:05.728057 18636 sgd_solver.cpp:136] Iteration 154700, lr = 0.00033125, m = 0.9
I0802 11:49:19.670145 18636 solver.cpp:353] Iteration 154800 (7.17266 iter/s, 13.9418s/100 iter), loss = 1.33698
I0802 11:49:19.670186 18636 solver.cpp:375]     Train net output #0: loss = 1.19788 (* 1 = 1.19788 loss)
I0802 11:49:19.670192 18636 sgd_solver.cpp:136] Iteration 154800, lr = 0.000325, m = 0.9
I0802 11:49:33.614943 18636 solver.cpp:353] Iteration 154900 (7.17133 iter/s, 13.9444s/100 iter), loss = 1.14985
I0802 11:49:33.615094 18636 solver.cpp:375]     Train net output #0: loss = 1.00716 (* 1 = 1.00716 loss)
I0802 11:49:33.615113 18636 sgd_solver.cpp:136] Iteration 154900, lr = 0.00031875, m = 0.9
I0802 11:49:47.714117 18636 solver.cpp:404] Sparsity after update:
I0802 11:49:47.725476 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:49:47.725699 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:49:47.725801 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:49:47.725896 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:49:47.725992 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:49:47.726090 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:49:47.726182 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:49:47.726276 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:49:47.726366 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:49:47.726454 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:49:47.726546 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:49:47.726639 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:49:47.726730 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:49:47.860724 18636 solver.cpp:353] Iteration 155000 (7.01982 iter/s, 14.2454s/100 iter), loss = 1.25328
I0802 11:49:47.860750 18636 solver.cpp:375]     Train net output #0: loss = 1.16173 (* 1 = 1.16173 loss)
I0802 11:49:47.860755 18636 sgd_solver.cpp:136] Iteration 155000, lr = 0.0003125, m = 0.9
I0802 11:50:01.813266 18636 solver.cpp:353] Iteration 155100 (7.16735 iter/s, 13.9522s/100 iter), loss = 1.10239
I0802 11:50:01.813297 18636 solver.cpp:375]     Train net output #0: loss = 1.23634 (* 1 = 1.23634 loss)
I0802 11:50:01.813302 18636 sgd_solver.cpp:136] Iteration 155100, lr = 0.00030625, m = 0.9
I0802 11:50:15.771095 18636 solver.cpp:353] Iteration 155200 (7.16463 iter/s, 13.9574s/100 iter), loss = 1.25036
I0802 11:50:15.771148 18636 solver.cpp:375]     Train net output #0: loss = 1.08132 (* 1 = 1.08132 loss)
I0802 11:50:15.771154 18636 sgd_solver.cpp:136] Iteration 155200, lr = 0.0003, m = 0.9
I0802 11:50:29.662369 18636 solver.cpp:353] Iteration 155300 (7.19896 iter/s, 13.8909s/100 iter), loss = 1.34848
I0802 11:50:29.662400 18636 solver.cpp:375]     Train net output #0: loss = 0.963143 (* 1 = 0.963143 loss)
I0802 11:50:29.662405 18636 sgd_solver.cpp:136] Iteration 155300, lr = 0.00029375, m = 0.9
I0802 11:50:43.673676 18636 solver.cpp:353] Iteration 155400 (7.13729 iter/s, 14.0109s/100 iter), loss = 1.19106
I0802 11:50:43.673729 18636 solver.cpp:375]     Train net output #0: loss = 0.902023 (* 1 = 0.902023 loss)
I0802 11:50:43.673743 18636 sgd_solver.cpp:136] Iteration 155400, lr = 0.0002875, m = 0.9
I0802 11:50:57.690989 18636 solver.cpp:353] Iteration 155500 (7.13423 iter/s, 14.0169s/100 iter), loss = 1.28041
I0802 11:50:57.691045 18636 solver.cpp:375]     Train net output #0: loss = 1.3928 (* 1 = 1.3928 loss)
I0802 11:50:57.691051 18636 sgd_solver.cpp:136] Iteration 155500, lr = 0.00028125, m = 0.9
I0802 11:51:11.626233 18636 solver.cpp:353] Iteration 155600 (7.17625 iter/s, 13.9349s/100 iter), loss = 1.41746
I0802 11:51:11.626360 18636 solver.cpp:375]     Train net output #0: loss = 1.30866 (* 1 = 1.30866 loss)
I0802 11:51:11.626389 18636 sgd_solver.cpp:136] Iteration 155600, lr = 0.000275, m = 0.9
I0802 11:51:25.703326 18636 solver.cpp:353] Iteration 155700 (7.10393 iter/s, 14.0767s/100 iter), loss = 1.52764
I0802 11:51:25.703410 18636 solver.cpp:375]     Train net output #0: loss = 1.31406 (* 1 = 1.31406 loss)
I0802 11:51:25.703431 18636 sgd_solver.cpp:136] Iteration 155700, lr = 0.00026875, m = 0.9
I0802 11:51:39.601037 18636 solver.cpp:353] Iteration 155800 (7.19563 iter/s, 13.8973s/100 iter), loss = 1.14127
I0802 11:51:39.601140 18636 solver.cpp:375]     Train net output #0: loss = 1.50405 (* 1 = 1.50405 loss)
I0802 11:51:39.601147 18636 sgd_solver.cpp:136] Iteration 155800, lr = 0.0002625, m = 0.9
I0802 11:51:53.537324 18636 solver.cpp:353] Iteration 155900 (7.17571 iter/s, 13.9359s/100 iter), loss = 1.23459
I0802 11:51:53.537349 18636 solver.cpp:375]     Train net output #0: loss = 1.19289 (* 1 = 1.19289 loss)
I0802 11:51:53.537355 18636 sgd_solver.cpp:136] Iteration 155900, lr = 0.00025625, m = 0.9
I0802 11:52:07.411674 18636 solver.cpp:404] Sparsity after update:
I0802 11:52:07.416996 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:52:07.417011 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:52:07.417017 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:52:07.417019 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:52:07.417021 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:52:07.417023 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:52:07.417026 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:52:07.417031 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:52:07.417032 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:52:07.417033 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:52:07.417035 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:52:07.417037 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:52:07.417039 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:52:07.417047 18636 solver.cpp:550] Iteration 156000, Testing net (#0)
I0802 11:52:24.151203 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:52:26.973140 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.595529
I0802 11:52:26.973165 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.82235
I0802 11:52:26.973170 18636 solver.cpp:635]     Test net output #2: loss = 1.75038 (* 1 = 1.75038 loss)
I0802 11:52:26.973191 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5556s
I0802 11:52:27.113400 18636 solver.cpp:353] Iteration 156000 (2.97839 iter/s, 33.5752s/100 iter), loss = 1.27678
I0802 11:52:27.113427 18636 solver.cpp:375]     Train net output #0: loss = 0.94104 (* 1 = 0.94104 loss)
I0802 11:52:27.113433 18636 sgd_solver.cpp:136] Iteration 156000, lr = 0.00025, m = 0.9
I0802 11:52:41.315587 18636 solver.cpp:353] Iteration 156100 (7.04137 iter/s, 14.2018s/100 iter), loss = 1.62884
I0802 11:52:41.315671 18636 solver.cpp:375]     Train net output #0: loss = 1.39114 (* 1 = 1.39114 loss)
I0802 11:52:41.315692 18636 sgd_solver.cpp:136] Iteration 156100, lr = 0.00024375, m = 0.9
I0802 11:52:55.253736 18636 solver.cpp:353] Iteration 156200 (7.17475 iter/s, 13.9378s/100 iter), loss = 1.38796
I0802 11:52:55.253818 18636 solver.cpp:375]     Train net output #0: loss = 1.42701 (* 1 = 1.42701 loss)
I0802 11:52:55.253825 18636 sgd_solver.cpp:136] Iteration 156200, lr = 0.0002375, m = 0.9
I0802 11:53:09.114647 18636 solver.cpp:353] Iteration 156300 (7.21473 iter/s, 13.8605s/100 iter), loss = 1.5004
I0802 11:53:09.114678 18636 solver.cpp:375]     Train net output #0: loss = 1.73752 (* 1 = 1.73752 loss)
I0802 11:53:09.114683 18636 sgd_solver.cpp:136] Iteration 156300, lr = 0.00023125, m = 0.9
I0802 11:53:23.116225 18636 solver.cpp:353] Iteration 156400 (7.14225 iter/s, 14.0012s/100 iter), loss = 1.18736
I0802 11:53:23.116250 18636 solver.cpp:375]     Train net output #0: loss = 1.01776 (* 1 = 1.01776 loss)
I0802 11:53:23.116255 18636 sgd_solver.cpp:136] Iteration 156400, lr = 0.000225, m = 0.9
I0802 11:53:37.208250 18636 solver.cpp:353] Iteration 156500 (7.09641 iter/s, 14.0916s/100 iter), loss = 0.975879
I0802 11:53:37.208335 18636 solver.cpp:375]     Train net output #0: loss = 1.0344 (* 1 = 1.0344 loss)
I0802 11:53:37.208343 18636 sgd_solver.cpp:136] Iteration 156500, lr = 0.00021875, m = 0.9
I0802 11:53:51.238888 18636 solver.cpp:353] Iteration 156600 (7.12746 iter/s, 14.0303s/100 iter), loss = 1.26513
I0802 11:53:51.238914 18636 solver.cpp:375]     Train net output #0: loss = 1.32872 (* 1 = 1.32872 loss)
I0802 11:53:51.238919 18636 sgd_solver.cpp:136] Iteration 156600, lr = 0.0002125, m = 0.9
I0802 11:54:05.412086 18636 solver.cpp:353] Iteration 156700 (7.05576 iter/s, 14.1728s/100 iter), loss = 1.12415
I0802 11:54:05.412272 18636 solver.cpp:375]     Train net output #0: loss = 0.967269 (* 1 = 0.967269 loss)
I0802 11:54:05.412356 18636 sgd_solver.cpp:136] Iteration 156700, lr = 0.00020625, m = 0.9
I0802 11:54:19.294850 18636 solver.cpp:353] Iteration 156800 (7.20338 iter/s, 13.8824s/100 iter), loss = 1.39266
I0802 11:54:19.294924 18636 solver.cpp:375]     Train net output #0: loss = 1.35531 (* 1 = 1.35531 loss)
I0802 11:54:19.294930 18636 sgd_solver.cpp:136] Iteration 156800, lr = 0.0002, m = 0.9
I0802 11:54:33.488267 18636 solver.cpp:353] Iteration 156900 (7.04571 iter/s, 14.193s/100 iter), loss = 1.12764
I0802 11:54:33.488296 18636 solver.cpp:375]     Train net output #0: loss = 1.06411 (* 1 = 1.06411 loss)
I0802 11:54:33.488302 18636 sgd_solver.cpp:136] Iteration 156900, lr = 0.00019375, m = 0.9
I0802 11:54:47.390472 18636 solver.cpp:404] Sparsity after update:
I0802 11:54:47.401659 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:54:47.401674 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:54:47.401682 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:54:47.401685 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:54:47.401690 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:54:47.401692 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:54:47.401695 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:54:47.401698 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:54:47.401701 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:54:47.401705 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:54:47.401707 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:54:47.401710 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:54:47.401713 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:54:47.531847 18636 solver.cpp:353] Iteration 157000 (7.12089 iter/s, 14.0432s/100 iter), loss = 1.12193
I0802 11:54:47.531877 18636 solver.cpp:375]     Train net output #0: loss = 0.972871 (* 1 = 0.972871 loss)
I0802 11:54:47.531883 18636 sgd_solver.cpp:136] Iteration 157000, lr = 0.0001875, m = 0.9
I0802 11:55:01.447368 18636 solver.cpp:353] Iteration 157100 (7.18642 iter/s, 13.9151s/100 iter), loss = 1.16635
I0802 11:55:01.447434 18636 solver.cpp:375]     Train net output #0: loss = 1.46873 (* 1 = 1.46873 loss)
I0802 11:55:01.447441 18636 sgd_solver.cpp:136] Iteration 157100, lr = 0.00018125, m = 0.9
I0802 11:55:15.485008 18636 solver.cpp:353] Iteration 157200 (7.1239 iter/s, 14.0373s/100 iter), loss = 1.63805
I0802 11:55:15.485033 18636 solver.cpp:375]     Train net output #0: loss = 1.83998 (* 1 = 1.83998 loss)
I0802 11:55:15.485036 18636 sgd_solver.cpp:136] Iteration 157200, lr = 0.000175, m = 0.9
I0802 11:55:29.492837 18636 solver.cpp:353] Iteration 157300 (7.13906 iter/s, 14.0074s/100 iter), loss = 1.67872
I0802 11:55:29.492866 18636 solver.cpp:375]     Train net output #0: loss = 1.64696 (* 1 = 1.64696 loss)
I0802 11:55:29.492871 18636 sgd_solver.cpp:136] Iteration 157300, lr = 0.00016875, m = 0.9
I0802 11:55:43.541795 18636 solver.cpp:353] Iteration 157400 (7.11816 iter/s, 14.0486s/100 iter), loss = 1.32172
I0802 11:55:43.541877 18636 solver.cpp:375]     Train net output #0: loss = 1.32011 (* 1 = 1.32011 loss)
I0802 11:55:43.541885 18636 sgd_solver.cpp:136] Iteration 157400, lr = 0.0001625, m = 0.9
I0802 11:55:57.552955 18636 solver.cpp:353] Iteration 157500 (7.13736 iter/s, 14.0108s/100 iter), loss = 1.257
I0802 11:55:57.552979 18636 solver.cpp:375]     Train net output #0: loss = 1.39085 (* 1 = 1.39085 loss)
I0802 11:55:57.552983 18636 sgd_solver.cpp:136] Iteration 157500, lr = 0.00015625, m = 0.9
I0802 11:56:11.829499 18636 solver.cpp:353] Iteration 157600 (7.00469 iter/s, 14.2762s/100 iter), loss = 1.35501
I0802 11:56:11.829527 18636 solver.cpp:375]     Train net output #0: loss = 1.12058 (* 1 = 1.12058 loss)
I0802 11:56:11.829535 18636 sgd_solver.cpp:136] Iteration 157600, lr = 0.00015, m = 0.9
I0802 11:56:25.794214 18636 solver.cpp:353] Iteration 157700 (7.16111 iter/s, 13.9643s/100 iter), loss = 1.38557
I0802 11:56:25.794368 18636 solver.cpp:375]     Train net output #0: loss = 1.68378 (* 1 = 1.68378 loss)
I0802 11:56:25.794389 18636 sgd_solver.cpp:136] Iteration 157700, lr = 0.00014375, m = 0.9
I0802 11:56:39.764595 18636 solver.cpp:353] Iteration 157800 (7.1582 iter/s, 13.97s/100 iter), loss = 1.37735
I0802 11:56:39.764623 18636 solver.cpp:375]     Train net output #0: loss = 1.51351 (* 1 = 1.51351 loss)
I0802 11:56:39.764629 18636 sgd_solver.cpp:136] Iteration 157800, lr = 0.0001375, m = 0.9
I0802 11:56:53.866894 18636 solver.cpp:353] Iteration 157900 (7.09124 iter/s, 14.1019s/100 iter), loss = 1.37591
I0802 11:56:53.866986 18636 solver.cpp:375]     Train net output #0: loss = 1.4839 (* 1 = 1.4839 loss)
I0802 11:56:53.867007 18636 sgd_solver.cpp:136] Iteration 157900, lr = 0.00013125, m = 0.9
I0802 11:57:07.756615 18636 solver.cpp:404] Sparsity after update:
I0802 11:57:07.761014 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:57:07.761025 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:57:07.761032 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:57:07.761034 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:57:07.761036 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:57:07.761039 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:57:07.761040 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:57:07.761042 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:57:07.761046 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:57:07.761049 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:57:07.761050 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:57:07.761052 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:57:07.761054 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:57:07.761062 18636 solver.cpp:550] Iteration 158000, Testing net (#0)
I0802 11:57:16.447721 18619 data_reader.cpp:264] Starting prefetch of epoch 8
I0802 11:57:27.807376 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.594941
I0802 11:57:27.807405 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821938
I0802 11:57:27.807413 18636 solver.cpp:635]     Test net output #2: loss = 1.75563 (* 1 = 1.75563 loss)
I0802 11:57:27.807433 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0458s
I0802 11:57:27.944092 18636 solver.cpp:353] Iteration 158000 (2.93459 iter/s, 34.0763s/100 iter), loss = 1.33139
I0802 11:57:27.944120 18636 solver.cpp:375]     Train net output #0: loss = 1.07038 (* 1 = 1.07038 loss)
I0802 11:57:27.944125 18636 sgd_solver.cpp:136] Iteration 158000, lr = 0.000125, m = 0.9
I0802 11:57:42.228689 18636 solver.cpp:353] Iteration 158100 (7.00075 iter/s, 14.2842s/100 iter), loss = 1.36206
I0802 11:57:42.228803 18636 solver.cpp:375]     Train net output #0: loss = 1.36122 (* 1 = 1.36122 loss)
I0802 11:57:42.228827 18636 sgd_solver.cpp:136] Iteration 158100, lr = 0.00011875, m = 0.9
I0802 11:57:56.353569 18636 solver.cpp:353] Iteration 158200 (7.0799 iter/s, 14.1245s/100 iter), loss = 1.36536
I0802 11:57:56.353600 18636 solver.cpp:375]     Train net output #0: loss = 1.18187 (* 1 = 1.18187 loss)
I0802 11:57:56.353607 18636 sgd_solver.cpp:136] Iteration 158200, lr = 0.0001125, m = 0.9
I0802 11:58:10.592788 18636 solver.cpp:353] Iteration 158300 (7.02305 iter/s, 14.2388s/100 iter), loss = 1.3406
I0802 11:58:10.592824 18636 solver.cpp:375]     Train net output #0: loss = 1.35916 (* 1 = 1.35916 loss)
I0802 11:58:10.592830 18636 sgd_solver.cpp:136] Iteration 158300, lr = 0.00010625, m = 0.9
I0802 11:58:24.893550 18636 solver.cpp:353] Iteration 158400 (6.99283 iter/s, 14.3004s/100 iter), loss = 1.50423
I0802 11:58:24.893628 18636 solver.cpp:375]     Train net output #0: loss = 1.46722 (* 1 = 1.46722 loss)
I0802 11:58:24.893635 18636 sgd_solver.cpp:136] Iteration 158400, lr = 9.99999e-05, m = 0.9
I0802 11:58:38.956511 18636 solver.cpp:353] Iteration 158500 (7.11108 iter/s, 14.0626s/100 iter), loss = 1.27294
I0802 11:58:38.956567 18636 solver.cpp:375]     Train net output #0: loss = 1.5219 (* 1 = 1.5219 loss)
I0802 11:58:38.956579 18636 sgd_solver.cpp:136] Iteration 158500, lr = 9.37498e-05, m = 0.9
I0802 11:58:53.005486 18636 solver.cpp:353] Iteration 158600 (7.11815 iter/s, 14.0486s/100 iter), loss = 1.11176
I0802 11:58:53.005511 18636 solver.cpp:375]     Train net output #0: loss = 1.04643 (* 1 = 1.04643 loss)
I0802 11:58:53.005517 18636 sgd_solver.cpp:136] Iteration 158600, lr = 8.75002e-05, m = 0.9
I0802 11:59:07.106804 18636 solver.cpp:353] Iteration 158700 (7.09173 iter/s, 14.1009s/100 iter), loss = 1.38624
I0802 11:59:07.106866 18636 solver.cpp:375]     Train net output #0: loss = 1.3043 (* 1 = 1.3043 loss)
I0802 11:59:07.106874 18636 sgd_solver.cpp:136] Iteration 158700, lr = 8.12501e-05, m = 0.9
I0802 11:59:21.038017 18636 solver.cpp:353] Iteration 158800 (7.17832 iter/s, 13.9308s/100 iter), loss = 1.36418
I0802 11:59:21.038043 18636 solver.cpp:375]     Train net output #0: loss = 1.16214 (* 1 = 1.16214 loss)
I0802 11:59:21.038048 18636 sgd_solver.cpp:136] Iteration 158800, lr = 7.49999e-05, m = 0.9
I0802 11:59:34.905232 18636 solver.cpp:353] Iteration 158900 (7.21145 iter/s, 13.8668s/100 iter), loss = 1.00751
I0802 11:59:34.905264 18636 solver.cpp:375]     Train net output #0: loss = 0.904927 (* 1 = 0.904927 loss)
I0802 11:59:34.905270 18636 sgd_solver.cpp:136] Iteration 158900, lr = 6.87498e-05, m = 0.9
I0802 11:59:49.045388 18636 solver.cpp:404] Sparsity after update:
I0802 11:59:49.055928 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:59:49.055959 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:59:49.055974 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:59:49.055984 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:59:49.055991 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:59:49.055999 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:59:49.056007 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:59:49.056015 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:59:49.056023 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:59:49.056031 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:59:49.056040 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:59:49.056047 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:59:49.056056 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:59:49.185381 18636 solver.cpp:353] Iteration 159000 (7.00292 iter/s, 14.2798s/100 iter), loss = 1.74865
I0802 11:59:49.185432 18636 solver.cpp:375]     Train net output #0: loss = 1.76277 (* 1 = 1.76277 loss)
I0802 11:59:49.185443 18636 sgd_solver.cpp:136] Iteration 159000, lr = 6.25002e-05, m = 0.9
I0802 12:00:03.209468 18636 solver.cpp:353] Iteration 159100 (7.13078 iter/s, 14.0237s/100 iter), loss = 1.39727
I0802 12:00:03.209493 18636 solver.cpp:375]     Train net output #0: loss = 1.46254 (* 1 = 1.46254 loss)
I0802 12:00:03.209497 18636 sgd_solver.cpp:136] Iteration 159100, lr = 5.62501e-05, m = 0.9
I0802 12:00:17.257881 18636 solver.cpp:353] Iteration 159200 (7.11844 iter/s, 14.048s/100 iter), loss = 1.61655
I0802 12:00:17.257906 18636 solver.cpp:375]     Train net output #0: loss = 1.93229 (* 1 = 1.93229 loss)
I0802 12:00:17.257910 18636 sgd_solver.cpp:136] Iteration 159200, lr = 5e-05, m = 0.9
I0802 12:00:31.229521 18636 solver.cpp:353] Iteration 159300 (7.15755 iter/s, 13.9713s/100 iter), loss = 1.33516
I0802 12:00:31.229586 18636 solver.cpp:375]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0802 12:00:31.229593 18636 sgd_solver.cpp:136] Iteration 159300, lr = 4.37498e-05, m = 0.9
I0802 12:00:45.408804 18636 solver.cpp:353] Iteration 159400 (7.05274 iter/s, 14.1789s/100 iter), loss = 1.49017
I0802 12:00:45.408841 18636 solver.cpp:375]     Train net output #0: loss = 1.52334 (* 1 = 1.52334 loss)
I0802 12:00:45.408848 18636 sgd_solver.cpp:136] Iteration 159400, lr = 3.75003e-05, m = 0.9
I0802 12:00:59.325413 18636 solver.cpp:353] Iteration 159500 (7.18586 iter/s, 13.9162s/100 iter), loss = 1.20673
I0802 12:00:59.325443 18636 solver.cpp:375]     Train net output #0: loss = 1.09974 (* 1 = 1.09974 loss)
I0802 12:00:59.325448 18636 sgd_solver.cpp:136] Iteration 159500, lr = 3.12501e-05, m = 0.9
I0802 12:01:13.241336 18636 solver.cpp:353] Iteration 159600 (7.18621 iter/s, 13.9155s/100 iter), loss = 1.39125
I0802 12:01:13.241448 18636 solver.cpp:375]     Train net output #0: loss = 1.4983 (* 1 = 1.4983 loss)
I0802 12:01:13.241456 18636 sgd_solver.cpp:136] Iteration 159600, lr = 2.5e-05, m = 0.9
I0802 12:01:27.237045 18636 solver.cpp:353] Iteration 159700 (7.14524 iter/s, 13.9953s/100 iter), loss = 1.25924
I0802 12:01:27.237071 18636 solver.cpp:375]     Train net output #0: loss = 1.36253 (* 1 = 1.36253 loss)
I0802 12:01:27.237076 18636 sgd_solver.cpp:136] Iteration 159700, lr = 1.87498e-05, m = 0.9
I0802 12:01:41.190138 18636 solver.cpp:353] Iteration 159800 (7.16707 iter/s, 13.9527s/100 iter), loss = 1.43359
I0802 12:01:41.190189 18636 solver.cpp:375]     Train net output #0: loss = 1.44849 (* 1 = 1.44849 loss)
I0802 12:01:41.190201 18636 sgd_solver.cpp:136] Iteration 159800, lr = 1.25003e-05, m = 0.9
I0802 12:01:55.238560 18636 solver.cpp:353] Iteration 159900 (7.11843 iter/s, 14.048s/100 iter), loss = 1.03472
I0802 12:01:55.238642 18636 solver.cpp:375]     Train net output #0: loss = 0.969054 (* 1 = 0.969054 loss)
I0802 12:01:55.238654 18636 sgd_solver.cpp:136] Iteration 159900, lr = 6.25014e-06, m = 0.9
I0802 12:02:09.065933 18636 solver.cpp:353] Iteration 159999 (7.15991 iter/s, 13.827s/99 iter), loss = 1.57142
I0802 12:02:09.065960 18636 solver.cpp:375]     Train net output #0: loss = 1.77526 (* 1 = 1.77526 loss)
I0802 12:02:09.065968 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_160000.caffemodel
I0802 12:02:09.096949 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_160000.solverstate
I0802 12:02:09.101287 18636 solver.cpp:404] Sparsity after update:
I0802 12:02:09.102345 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 12:02:09.102355 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 12:02:09.102361 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 12:02:09.102365 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 12:02:09.102366 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 12:02:09.102368 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 12:02:09.102371 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 12:02:09.102373 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 12:02:09.102375 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 12:02:09.102377 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 12:02:09.102380 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 12:02:09.102382 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 12:02:09.102385 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 12:02:09.164032 18636 solver.cpp:527] Iteration 160000, loss = 1.32036
I0802 12:02:09.164060 18636 solver.cpp:550] Iteration 160000, Testing net (#0)
I0802 12:02:29.389502 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.596764
I0802 12:02:29.389619 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821821
I0802 12:02:29.389629 18636 solver.cpp:635]     Test net output #2: loss = 1.75474 (* 1 = 1.75474 loss)
I0802 12:02:29.397680 18523 parallel.cpp:73] Root Solver performance on device 0: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397693 18523 parallel.cpp:78]      Solver performance on device 1: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397697 18523 parallel.cpp:78]      Solver performance on device 2: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397701 18523 parallel.cpp:81] Overall multi-GPU performance: 781.514 img/sec
I0802 12:02:29.948015 18523 caffe.cpp:247] Optimization Done in 7h 20m 36s
I0802 12:02:33.121881 19007 caffe.cpp:608] This is NVCaffe 0.16.3 started at Wed Aug  2 12:02:32 2017
I0802 12:02:33.127056 19007 caffe.cpp:611] CuDNN version: 6021
I0802 12:02:33.127079 19007 caffe.cpp:612] CuBLAS version: 8000
I0802 12:02:33.127089 19007 caffe.cpp:613] CUDA version: 8000
I0802 12:02:33.127099 19007 caffe.cpp:614] CUDA driver version: 8000
I0802 12:02:33.127123 19007 caffe.cpp:263] Not using GPU #2 for single-GPU function
I0802 12:02:33.127135 19007 caffe.cpp:263] Not using GPU #1 for single-GPU function
I0802 12:02:33.129153 19007 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0802 12:02:33.130995 19007 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0802 12:02:33.131027 19007 caffe.cpp:275] Use GPU with device ID 0
I0802 12:02:33.131908 19007 caffe.cpp:279] GPU device name: GeForce GTX 1080
I0802 12:02:33.176034 19007 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0802 12:02:33.176178 19007 net.cpp:104] Using FLOAT as default forward math type
I0802 12:02:33.176187 19007 net.cpp:110] Using FLOAT as default backward math type
I0802 12:02:33.176192 19007 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0802 12:02:33.176196 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:33.187621 19007 net.cpp:184] Created Layer data (0)
I0802 12:02:33.187634 19007 net.cpp:530] data -> data
I0802 12:02:33.187645 19007 net.cpp:530] data -> label
I0802 12:02:33.187667 19007 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 50
I0802 12:02:33.188064 19007 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 12:02:33.255205 19075 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 12:02:33.260469 19007 data_layer.cpp:184] (0) ReshapePrefetch 50, 3, 224, 224
I0802 12:02:33.260644 19007 data_layer.cpp:208] (0) Output data size: 50, 3, 224, 224
I0802 12:02:33.260679 19007 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 12:02:33.260776 19007 net.cpp:245] Setting up data
I0802 12:02:33.260813 19007 net.cpp:252] TEST Top shape for layer 0 'data' 50 3 224 224 (7526400)
I0802 12:02:33.260862 19007 net.cpp:252] TEST Top shape for layer 0 'data' 50 (50)
I0802 12:02:33.260890 19007 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0802 12:02:33.260920 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:33.260995 19007 net.cpp:184] Created Layer label_data_1_split (1)
I0802 12:02:33.261018 19007 net.cpp:561] label_data_1_split <- label
I0802 12:02:33.261046 19007 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0802 12:02:33.261082 19007 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0802 12:02:33.261142 19007 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0802 12:02:33.261171 19007 net.cpp:245] Setting up label_data_1_split
I0802 12:02:33.261175 19007 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0802 12:02:33.261178 19007 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0802 12:02:33.261181 19007 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0802 12:02:33.261183 19007 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0802 12:02:33.261188 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:33.261196 19007 net.cpp:184] Created Layer data/bias (2)
I0802 12:02:33.261199 19007 net.cpp:561] data/bias <- data
I0802 12:02:33.261201 19007 net.cpp:530] data/bias -> data/bias
I0802 12:02:33.262249 19076 data_layer.cpp:97] (0) Parser threads: 1
I0802 12:02:33.262259 19076 data_layer.cpp:99] (0) Transformer threads: 1
I0802 12:02:33.267942 19007 net.cpp:245] Setting up data/bias
I0802 12:02:33.267978 19007 net.cpp:252] TEST Top shape for layer 2 'data/bias' 50 3 224 224 (7526400)
I0802 12:02:33.267995 19007 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0802 12:02:33.268002 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:33.268049 19007 net.cpp:184] Created Layer conv1a (3)
I0802 12:02:33.268055 19007 net.cpp:561] conv1a <- data/bias
I0802 12:02:33.268059 19007 net.cpp:530] conv1a -> conv1a
I0802 12:02:34.033232 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 8.02G, req 0G)
I0802 12:02:34.033252 19007 net.cpp:245] Setting up conv1a
I0802 12:02:34.033257 19007 net.cpp:252] TEST Top shape for layer 3 'conv1a' 50 32 112 112 (20070400)
I0802 12:02:34.033265 19007 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0802 12:02:34.033270 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.033282 19007 net.cpp:184] Created Layer conv1a/bn (4)
I0802 12:02:34.033284 19007 net.cpp:561] conv1a/bn <- conv1a
I0802 12:02:34.033288 19007 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0802 12:02:34.033731 19007 net.cpp:245] Setting up conv1a/bn
I0802 12:02:34.033738 19007 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 50 32 112 112 (20070400)
I0802 12:02:34.033746 19007 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0802 12:02:34.033748 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.033752 19007 net.cpp:184] Created Layer conv1a/relu (5)
I0802 12:02:34.033756 19007 net.cpp:561] conv1a/relu <- conv1a
I0802 12:02:34.033757 19007 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0802 12:02:34.033767 19007 net.cpp:245] Setting up conv1a/relu
I0802 12:02:34.033771 19007 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 50 32 112 112 (20070400)
I0802 12:02:34.033774 19007 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0802 12:02:34.033776 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.033785 19007 net.cpp:184] Created Layer conv1b (6)
I0802 12:02:34.033787 19007 net.cpp:561] conv1b <- conv1a
I0802 12:02:34.033790 19007 net.cpp:530] conv1b -> conv1b
I0802 12:02:34.044070 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.93G, req 0G)
I0802 12:02:34.044080 19007 net.cpp:245] Setting up conv1b
I0802 12:02:34.044085 19007 net.cpp:252] TEST Top shape for layer 6 'conv1b' 50 32 112 112 (20070400)
I0802 12:02:34.044090 19007 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0802 12:02:34.044092 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.044102 19007 net.cpp:184] Created Layer conv1b/bn (7)
I0802 12:02:34.044106 19007 net.cpp:561] conv1b/bn <- conv1b
I0802 12:02:34.044107 19007 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0802 12:02:34.044528 19007 net.cpp:245] Setting up conv1b/bn
I0802 12:02:34.044535 19007 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 50 32 112 112 (20070400)
I0802 12:02:34.044540 19007 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0802 12:02:34.044543 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.044546 19007 net.cpp:184] Created Layer conv1b/relu (8)
I0802 12:02:34.044549 19007 net.cpp:561] conv1b/relu <- conv1b
I0802 12:02:34.044551 19007 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0802 12:02:34.044554 19007 net.cpp:245] Setting up conv1b/relu
I0802 12:02:34.044558 19007 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 50 32 112 112 (20070400)
I0802 12:02:34.044559 19007 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0802 12:02:34.044561 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.044566 19007 net.cpp:184] Created Layer pool1 (9)
I0802 12:02:34.044569 19007 net.cpp:561] pool1 <- conv1b
I0802 12:02:34.044572 19007 net.cpp:530] pool1 -> pool1
I0802 12:02:34.044615 19007 net.cpp:245] Setting up pool1
I0802 12:02:34.044620 19007 net.cpp:252] TEST Top shape for layer 9 'pool1' 50 32 56 56 (5017600)
I0802 12:02:34.044622 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0802 12:02:34.044625 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.044636 19007 net.cpp:184] Created Layer res2a_branch2a (10)
I0802 12:02:34.044639 19007 net.cpp:561] res2a_branch2a <- pool1
I0802 12:02:34.044641 19007 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0802 12:02:34.054517 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0802 12:02:34.054527 19007 net.cpp:245] Setting up res2a_branch2a
I0802 12:02:34.054532 19007 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 50 64 56 56 (10035200)
I0802 12:02:34.054538 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0802 12:02:34.054539 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.054549 19007 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0802 12:02:34.054551 19007 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0802 12:02:34.054554 19007 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0802 12:02:34.054963 19007 net.cpp:245] Setting up res2a_branch2a/bn
I0802 12:02:34.054970 19007 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 50 64 56 56 (10035200)
I0802 12:02:34.054975 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0802 12:02:34.054978 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.054981 19007 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0802 12:02:34.054983 19007 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0802 12:02:34.054986 19007 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0802 12:02:34.054989 19007 net.cpp:245] Setting up res2a_branch2a/relu
I0802 12:02:34.054991 19007 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 50 64 56 56 (10035200)
I0802 12:02:34.054993 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0802 12:02:34.054996 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.055001 19007 net.cpp:184] Created Layer res2a_branch2b (13)
I0802 12:02:34.055003 19007 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0802 12:02:34.055006 19007 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0802 12:02:34.060382 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.82G, req 0G)
I0802 12:02:34.060394 19007 net.cpp:245] Setting up res2a_branch2b
I0802 12:02:34.060397 19007 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 50 64 56 56 (10035200)
I0802 12:02:34.060410 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0802 12:02:34.060413 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.060417 19007 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0802 12:02:34.060420 19007 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0802 12:02:34.060423 19007 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0802 12:02:34.060837 19007 net.cpp:245] Setting up res2a_branch2b/bn
I0802 12:02:34.060844 19007 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 50 64 56 56 (10035200)
I0802 12:02:34.060850 19007 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0802 12:02:34.060853 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.060856 19007 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0802 12:02:34.060858 19007 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0802 12:02:34.060861 19007 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0802 12:02:34.060864 19007 net.cpp:245] Setting up res2a_branch2b/relu
I0802 12:02:34.060866 19007 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 50 64 56 56 (10035200)
I0802 12:02:34.060868 19007 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0802 12:02:34.060871 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.060874 19007 net.cpp:184] Created Layer pool2 (16)
I0802 12:02:34.060878 19007 net.cpp:561] pool2 <- res2a_branch2b
I0802 12:02:34.060880 19007 net.cpp:530] pool2 -> pool2
I0802 12:02:34.060909 19007 net.cpp:245] Setting up pool2
I0802 12:02:34.060914 19007 net.cpp:252] TEST Top shape for layer 16 'pool2' 50 64 28 28 (2508800)
I0802 12:02:34.060915 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0802 12:02:34.060917 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.060923 19007 net.cpp:184] Created Layer res3a_branch2a (17)
I0802 12:02:34.060925 19007 net.cpp:561] res3a_branch2a <- pool2
I0802 12:02:34.060927 19007 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0802 12:02:34.071063 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.79G, req 0G)
I0802 12:02:34.071074 19007 net.cpp:245] Setting up res3a_branch2a
I0802 12:02:34.071079 19007 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 50 128 28 28 (5017600)
I0802 12:02:34.071082 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0802 12:02:34.071085 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.071089 19007 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0802 12:02:34.071092 19007 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0802 12:02:34.071094 19007 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0802 12:02:34.071499 19007 net.cpp:245] Setting up res3a_branch2a/bn
I0802 12:02:34.071506 19007 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 50 128 28 28 (5017600)
I0802 12:02:34.071513 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0802 12:02:34.071516 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.071518 19007 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0802 12:02:34.071521 19007 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0802 12:02:34.071523 19007 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0802 12:02:34.071527 19007 net.cpp:245] Setting up res3a_branch2a/relu
I0802 12:02:34.071529 19007 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 50 128 28 28 (5017600)
I0802 12:02:34.071532 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0802 12:02:34.071533 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.071550 19007 net.cpp:184] Created Layer res3a_branch2b (20)
I0802 12:02:34.071553 19007 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0802 12:02:34.071555 19007 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0802 12:02:34.076125 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.77G, req 0G)
I0802 12:02:34.076136 19007 net.cpp:245] Setting up res3a_branch2b
I0802 12:02:34.076140 19007 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 50 128 28 28 (5017600)
I0802 12:02:34.076144 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0802 12:02:34.076148 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.076151 19007 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0802 12:02:34.076153 19007 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0802 12:02:34.076156 19007 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0802 12:02:34.076550 19007 net.cpp:245] Setting up res3a_branch2b/bn
I0802 12:02:34.076557 19007 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 50 128 28 28 (5017600)
I0802 12:02:34.076563 19007 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0802 12:02:34.076565 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.076568 19007 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0802 12:02:34.076570 19007 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0802 12:02:34.076573 19007 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0802 12:02:34.076576 19007 net.cpp:245] Setting up res3a_branch2b/relu
I0802 12:02:34.076580 19007 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 50 128 28 28 (5017600)
I0802 12:02:34.076581 19007 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0802 12:02:34.076583 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.076586 19007 net.cpp:184] Created Layer pool3 (23)
I0802 12:02:34.076588 19007 net.cpp:561] pool3 <- res3a_branch2b
I0802 12:02:34.076591 19007 net.cpp:530] pool3 -> pool3
I0802 12:02:34.076622 19007 net.cpp:245] Setting up pool3
I0802 12:02:34.076627 19007 net.cpp:252] TEST Top shape for layer 23 'pool3' 50 128 14 14 (1254400)
I0802 12:02:34.076628 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0802 12:02:34.076630 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.076637 19007 net.cpp:184] Created Layer res4a_branch2a (24)
I0802 12:02:34.076638 19007 net.cpp:561] res4a_branch2a <- pool3
I0802 12:02:34.076640 19007 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0802 12:02:34.090266 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.75G, req 0G)
I0802 12:02:34.090277 19007 net.cpp:245] Setting up res4a_branch2a
I0802 12:02:34.090281 19007 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 50 256 14 14 (2508800)
I0802 12:02:34.090286 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0802 12:02:34.090288 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.090292 19007 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0802 12:02:34.090296 19007 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0802 12:02:34.090298 19007 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0802 12:02:34.090694 19007 net.cpp:245] Setting up res4a_branch2a/bn
I0802 12:02:34.090701 19007 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 50 256 14 14 (2508800)
I0802 12:02:34.090706 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0802 12:02:34.090709 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.090713 19007 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0802 12:02:34.090723 19007 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0802 12:02:34.090726 19007 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0802 12:02:34.090730 19007 net.cpp:245] Setting up res4a_branch2a/relu
I0802 12:02:34.090734 19007 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 50 256 14 14 (2508800)
I0802 12:02:34.090736 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0802 12:02:34.090739 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.090745 19007 net.cpp:184] Created Layer res4a_branch2b (27)
I0802 12:02:34.090749 19007 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0802 12:02:34.090750 19007 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0802 12:02:34.097277 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.74G, req 0G)
I0802 12:02:34.097288 19007 net.cpp:245] Setting up res4a_branch2b
I0802 12:02:34.097292 19007 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 50 256 14 14 (2508800)
I0802 12:02:34.097296 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0802 12:02:34.097299 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.097303 19007 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0802 12:02:34.097306 19007 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0802 12:02:34.097308 19007 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0802 12:02:34.097704 19007 net.cpp:245] Setting up res4a_branch2b/bn
I0802 12:02:34.097712 19007 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 50 256 14 14 (2508800)
I0802 12:02:34.097718 19007 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0802 12:02:34.097719 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.097723 19007 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0802 12:02:34.097725 19007 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0802 12:02:34.097728 19007 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0802 12:02:34.097731 19007 net.cpp:245] Setting up res4a_branch2b/relu
I0802 12:02:34.097733 19007 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 50 256 14 14 (2508800)
I0802 12:02:34.097735 19007 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0802 12:02:34.097738 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.097740 19007 net.cpp:184] Created Layer pool4 (30)
I0802 12:02:34.097743 19007 net.cpp:561] pool4 <- res4a_branch2b
I0802 12:02:34.097745 19007 net.cpp:530] pool4 -> pool4
I0802 12:02:34.097774 19007 net.cpp:245] Setting up pool4
I0802 12:02:34.097780 19007 net.cpp:252] TEST Top shape for layer 30 'pool4' 50 256 7 7 (627200)
I0802 12:02:34.097784 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0802 12:02:34.097789 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.097798 19007 net.cpp:184] Created Layer res5a_branch2a (31)
I0802 12:02:34.097802 19007 net.cpp:561] res5a_branch2a <- pool4
I0802 12:02:34.097806 19007 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0802 12:02:34.130939 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.72G, req 0G)
I0802 12:02:34.130957 19007 net.cpp:245] Setting up res5a_branch2a
I0802 12:02:34.130964 19007 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 50 512 7 7 (1254400)
I0802 12:02:34.130973 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0802 12:02:34.130980 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.130993 19007 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0802 12:02:34.130998 19007 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0802 12:02:34.131012 19007 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0802 12:02:34.131463 19007 net.cpp:245] Setting up res5a_branch2a/bn
I0802 12:02:34.131470 19007 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 50 512 7 7 (1254400)
I0802 12:02:34.131479 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0802 12:02:34.131484 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.131489 19007 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0802 12:02:34.131494 19007 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0802 12:02:34.131497 19007 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0802 12:02:34.131503 19007 net.cpp:245] Setting up res5a_branch2a/relu
I0802 12:02:34.131508 19007 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 50 512 7 7 (1254400)
I0802 12:02:34.131512 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0802 12:02:34.131516 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.131526 19007 net.cpp:184] Created Layer res5a_branch2b (34)
I0802 12:02:34.131530 19007 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0802 12:02:34.131533 19007 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0802 12:02:34.147668 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 1  (limit 7.71G, req 0G)
I0802 12:02:34.147681 19007 net.cpp:245] Setting up res5a_branch2b
I0802 12:02:34.147688 19007 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 50 512 7 7 (1254400)
I0802 12:02:34.147698 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0802 12:02:34.147703 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.147712 19007 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0802 12:02:34.147716 19007 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0802 12:02:34.147720 19007 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0802 12:02:34.148134 19007 net.cpp:245] Setting up res5a_branch2b/bn
I0802 12:02:34.148142 19007 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 50 512 7 7 (1254400)
I0802 12:02:34.148151 19007 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0802 12:02:34.148154 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.148160 19007 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0802 12:02:34.148164 19007 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0802 12:02:34.148169 19007 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0802 12:02:34.148175 19007 net.cpp:245] Setting up res5a_branch2b/relu
I0802 12:02:34.148178 19007 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 50 512 7 7 (1254400)
I0802 12:02:34.148182 19007 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0802 12:02:34.148187 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.148193 19007 net.cpp:184] Created Layer pool5 (37)
I0802 12:02:34.148197 19007 net.cpp:561] pool5 <- res5a_branch2b
I0802 12:02:34.148202 19007 net.cpp:530] pool5 -> pool5
I0802 12:02:34.148221 19007 net.cpp:245] Setting up pool5
I0802 12:02:34.148226 19007 net.cpp:252] TEST Top shape for layer 37 'pool5' 50 512 1 1 (25600)
I0802 12:02:34.148231 19007 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0802 12:02:34.148234 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.148243 19007 net.cpp:184] Created Layer fc1000 (38)
I0802 12:02:34.148247 19007 net.cpp:561] fc1000 <- pool5
I0802 12:02:34.148252 19007 net.cpp:530] fc1000 -> fc1000
I0802 12:02:34.159090 19007 net.cpp:245] Setting up fc1000
I0802 12:02:34.159116 19007 net.cpp:252] TEST Top shape for layer 38 'fc1000' 50 1000 (50000)
I0802 12:02:34.159138 19007 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0802 12:02:34.159144 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.159152 19007 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0802 12:02:34.159165 19007 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0802 12:02:34.159173 19007 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0802 12:02:34.159179 19007 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0802 12:02:34.159185 19007 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0802 12:02:34.159238 19007 net.cpp:245] Setting up fc1000_fc1000_0_split
I0802 12:02:34.159245 19007 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0802 12:02:34.159250 19007 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0802 12:02:34.159255 19007 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0802 12:02:34.159260 19007 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0802 12:02:34.159263 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.159278 19007 net.cpp:184] Created Layer loss (40)
I0802 12:02:34.159283 19007 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0802 12:02:34.159289 19007 net.cpp:561] loss <- label_data_1_split_0
I0802 12:02:34.159294 19007 net.cpp:530] loss -> loss
I0802 12:02:34.159667 19007 net.cpp:245] Setting up loss
I0802 12:02:34.159674 19007 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0802 12:02:34.159678 19007 net.cpp:256]     with loss weight 1
I0802 12:02:34.159685 19007 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0802 12:02:34.159690 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.159701 19007 net.cpp:184] Created Layer accuracy/top1 (41)
I0802 12:02:34.159705 19007 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0802 12:02:34.159710 19007 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0802 12:02:34.159715 19007 net.cpp:530] accuracy/top1 -> accuracy/top1
I0802 12:02:34.159723 19007 net.cpp:245] Setting up accuracy/top1
I0802 12:02:34.159728 19007 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0802 12:02:34.159731 19007 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0802 12:02:34.159735 19007 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 12:02:34.159742 19007 net.cpp:184] Created Layer accuracy/top5 (42)
I0802 12:02:34.159746 19007 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0802 12:02:34.159750 19007 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0802 12:02:34.159755 19007 net.cpp:530] accuracy/top5 -> accuracy/top5
I0802 12:02:34.159762 19007 net.cpp:245] Setting up accuracy/top5
I0802 12:02:34.159766 19007 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0802 12:02:34.159770 19007 net.cpp:325] accuracy/top5 does not need backward computation.
I0802 12:02:34.159775 19007 net.cpp:325] accuracy/top1 does not need backward computation.
I0802 12:02:34.159778 19007 net.cpp:323] loss needs backward computation.
I0802 12:02:34.159782 19007 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0802 12:02:34.159786 19007 net.cpp:323] fc1000 needs backward computation.
I0802 12:02:34.159790 19007 net.cpp:323] pool5 needs backward computation.
I0802 12:02:34.159795 19007 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0802 12:02:34.159798 19007 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0802 12:02:34.159802 19007 net.cpp:323] res5a_branch2b needs backward computation.
I0802 12:02:34.159806 19007 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0802 12:02:34.159811 19007 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0802 12:02:34.159814 19007 net.cpp:323] res5a_branch2a needs backward computation.
I0802 12:02:34.159826 19007 net.cpp:323] pool4 needs backward computation.
I0802 12:02:34.159831 19007 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0802 12:02:34.159834 19007 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0802 12:02:34.159838 19007 net.cpp:323] res4a_branch2b needs backward computation.
I0802 12:02:34.159842 19007 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0802 12:02:34.159847 19007 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0802 12:02:34.159850 19007 net.cpp:323] res4a_branch2a needs backward computation.
I0802 12:02:34.159855 19007 net.cpp:323] pool3 needs backward computation.
I0802 12:02:34.159859 19007 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0802 12:02:34.159863 19007 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0802 12:02:34.159868 19007 net.cpp:323] res3a_branch2b needs backward computation.
I0802 12:02:34.159871 19007 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0802 12:02:34.159875 19007 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0802 12:02:34.159878 19007 net.cpp:323] res3a_branch2a needs backward computation.
I0802 12:02:34.159883 19007 net.cpp:323] pool2 needs backward computation.
I0802 12:02:34.159888 19007 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0802 12:02:34.159891 19007 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0802 12:02:34.159894 19007 net.cpp:323] res2a_branch2b needs backward computation.
I0802 12:02:34.159899 19007 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0802 12:02:34.159903 19007 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0802 12:02:34.159906 19007 net.cpp:323] res2a_branch2a needs backward computation.
I0802 12:02:34.159910 19007 net.cpp:323] pool1 needs backward computation.
I0802 12:02:34.159914 19007 net.cpp:323] conv1b/relu needs backward computation.
I0802 12:02:34.159919 19007 net.cpp:323] conv1b/bn needs backward computation.
I0802 12:02:34.159922 19007 net.cpp:323] conv1b needs backward computation.
I0802 12:02:34.159927 19007 net.cpp:323] conv1a/relu needs backward computation.
I0802 12:02:34.159931 19007 net.cpp:323] conv1a/bn needs backward computation.
I0802 12:02:34.159935 19007 net.cpp:323] conv1a needs backward computation.
I0802 12:02:34.159940 19007 net.cpp:325] data/bias does not need backward computation.
I0802 12:02:34.159945 19007 net.cpp:325] label_data_1_split does not need backward computation.
I0802 12:02:34.159948 19007 net.cpp:325] data does not need backward computation.
I0802 12:02:34.159951 19007 net.cpp:367] This network produces output accuracy/top1
I0802 12:02:34.159955 19007 net.cpp:367] This network produces output accuracy/top5
I0802 12:02:34.159960 19007 net.cpp:367] This network produces output loss
I0802 12:02:34.160001 19007 net.cpp:389] Top memory (TEST) required for data: 933273600 diff: 8
I0802 12:02:34.160006 19007 net.cpp:392] Bottom memory (TEST) required for data: 933273600 diff: 933273600
I0802 12:02:34.160008 19007 net.cpp:395] Shared (in-place) memory (TEST) by data: 622182400 diff: 622182400
I0802 12:02:34.160012 19007 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0802 12:02:34.160015 19007 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0802 12:02:34.160019 19007 net.cpp:407] Network initialization done.
I0802 12:02:34.165235 19007 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0802 12:02:34.165254 19007 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0802 12:02:34.165285 19007 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0802 12:02:34.165300 19007 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0802 12:02:34.165452 19007 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0802 12:02:34.165457 19007 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0802 12:02:34.165469 19007 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0802 12:02:34.165570 19007 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0802 12:02:34.165575 19007 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0802 12:02:34.165578 19007 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0802 12:02:34.165596 19007 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0802 12:02:34.165697 19007 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0802 12:02:34.165702 19007 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0802 12:02:34.165717 19007 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0802 12:02:34.165804 19007 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0802 12:02:34.165809 19007 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0802 12:02:34.165812 19007 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0802 12:02:34.165853 19007 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0802 12:02:34.165940 19007 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0802 12:02:34.165946 19007 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0802 12:02:34.165971 19007 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0802 12:02:34.166054 19007 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0802 12:02:34.166059 19007 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0802 12:02:34.166062 19007 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0802 12:02:34.166180 19007 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0802 12:02:34.166266 19007 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0802 12:02:34.166271 19007 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0802 12:02:34.166333 19007 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0802 12:02:34.166412 19007 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0802 12:02:34.166417 19007 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0802 12:02:34.166421 19007 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0802 12:02:34.166792 19007 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0802 12:02:34.166878 19007 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0802 12:02:34.166883 19007 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0802 12:02:34.167073 19007 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0802 12:02:34.167155 19007 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0802 12:02:34.167160 19007 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0802 12:02:34.167165 19007 net.cpp:1089] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0802 12:02:34.167312 19007 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0802 12:02:34.167387 19007 caffe.cpp:290] Running for 1000 iterations.
I0802 12:02:34.173645 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.68G, req 0G)
I0802 12:02:34.188040 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.52G, req 0G)
I0802 12:02:34.205229 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.33G, req 0G)
I0802 12:02:34.212772 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.25G, req 0G)
I0802 12:02:34.224277 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.15G, req 0G)
I0802 12:02:34.230121 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.11G, req 0G)
I0802 12:02:34.239127 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.06G, req 0G)
I0802 12:02:34.243639 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.04G, req 0G)
I0802 12:02:34.252681 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.02G, req 0G)
I0802 12:02:34.257211 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7G, req 0G)
I0802 12:02:34.260196 19007 caffe.cpp:313] Batch 0, accuracy/top1 = 0.48
I0802 12:02:34.260212 19007 caffe.cpp:313] Batch 0, accuracy/top5 = 0.74
I0802 12:02:34.260215 19007 caffe.cpp:313] Batch 0, loss = 2.08306
I0802 12:02:34.269107 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.74G/1 1  (limit 6.27G, req 0G)
I0802 12:02:34.290691 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 1.48G/2 6  (limit 5.53G, req 0G)
I0802 12:02:34.313999 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 1.48G/1 6  (limit 5.53G, req 0G)
I0802 12:02:34.325589 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 1.48G/2 6  (limit 5.53G, req 0G)
I0802 12:02:34.340417 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 1.48G/1 6  (limit 5.53G, req 0G)
I0802 12:02:34.346280 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 1.48G/2 6  (limit 5.53G, req 0G)
I0802 12:02:34.361093 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 1.48G/1 6  (limit 5.53G, req 0G)
I0802 12:02:34.367429 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 1.48G/2 6  (limit 5.53G, req 0G)
I0802 12:02:34.387917 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 1.48G/1 7  (limit 5.53G, req 0.05G)
I0802 12:02:34.395464 19007 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 1.48G/2 1  (limit 5.53G, req 0.05G)
I0802 12:02:34.396770 19007 caffe.cpp:313] Batch 1, accuracy/top1 = 0.64
I0802 12:02:34.396780 19007 caffe.cpp:313] Batch 1, accuracy/top5 = 0.8
I0802 12:02:34.396785 19007 caffe.cpp:313] Batch 1, loss = 1.79469
I0802 12:02:34.422222 19007 caffe.cpp:313] Batch 2, accuracy/top1 = 0.54
I0802 12:02:34.422250 19007 caffe.cpp:313] Batch 2, accuracy/top5 = 0.82
I0802 12:02:34.422255 19007 caffe.cpp:313] Batch 2, loss = 2.13542
I0802 12:02:34.422262 19007 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 12:02:34.480029 19007 caffe.cpp:313] Batch 3, accuracy/top1 = 0.66
I0802 12:02:34.480056 19007 caffe.cpp:313] Batch 3, accuracy/top5 = 0.8
I0802 12:02:34.480059 19007 caffe.cpp:313] Batch 3, loss = 1.33782
I0802 12:02:34.532438 19007 caffe.cpp:313] Batch 4, accuracy/top1 = 0.58
I0802 12:02:34.532459 19007 caffe.cpp:313] Batch 4, accuracy/top5 = 0.86
I0802 12:02:34.532464 19007 caffe.cpp:313] Batch 4, loss = 1.75425
I0802 12:02:34.585467 19007 caffe.cpp:313] Batch 5, accuracy/top1 = 0.64
I0802 12:02:34.585494 19007 caffe.cpp:313] Batch 5, accuracy/top5 = 0.84
I0802 12:02:34.585497 19007 caffe.cpp:313] Batch 5, loss = 1.37864
I0802 12:02:34.639055 19007 caffe.cpp:313] Batch 6, accuracy/top1 = 0.7
I0802 12:02:34.639081 19007 caffe.cpp:313] Batch 6, accuracy/top5 = 0.84
I0802 12:02:34.639086 19007 caffe.cpp:313] Batch 6, loss = 1.27628
I0802 12:02:34.692662 19007 caffe.cpp:313] Batch 7, accuracy/top1 = 0.58
I0802 12:02:34.692688 19007 caffe.cpp:313] Batch 7, accuracy/top5 = 0.82
I0802 12:02:34.692692 19007 caffe.cpp:313] Batch 7, loss = 1.7219
I0802 12:02:34.746094 19007 caffe.cpp:313] Batch 8, accuracy/top1 = 0.66
I0802 12:02:34.746122 19007 caffe.cpp:313] Batch 8, accuracy/top5 = 0.86
I0802 12:02:34.746126 19007 caffe.cpp:313] Batch 8, loss = 1.25939
I0802 12:02:34.798938 19007 caffe.cpp:313] Batch 9, accuracy/top1 = 0.56
I0802 12:02:34.798966 19007 caffe.cpp:313] Batch 9, accuracy/top5 = 0.82
I0802 12:02:34.798970 19007 caffe.cpp:313] Batch 9, loss = 1.53691
I0802 12:02:34.852681 19007 caffe.cpp:313] Batch 10, accuracy/top1 = 0.6
I0802 12:02:34.852710 19007 caffe.cpp:313] Batch 10, accuracy/top5 = 0.82
I0802 12:02:34.852715 19007 caffe.cpp:313] Batch 10, loss = 1.54522
I0802 12:02:34.907469 19007 caffe.cpp:313] Batch 11, accuracy/top1 = 0.66
I0802 12:02:34.907495 19007 caffe.cpp:313] Batch 11, accuracy/top5 = 0.86
I0802 12:02:34.907500 19007 caffe.cpp:313] Batch 11, loss = 1.27085
I0802 12:02:34.959484 19007 caffe.cpp:313] Batch 12, accuracy/top1 = 0.56
I0802 12:02:34.959509 19007 caffe.cpp:313] Batch 12, accuracy/top5 = 0.9
I0802 12:02:34.959512 19007 caffe.cpp:313] Batch 12, loss = 1.48166
I0802 12:02:35.010440 19007 caffe.cpp:313] Batch 13, accuracy/top1 = 0.68
I0802 12:02:35.010468 19007 caffe.cpp:313] Batch 13, accuracy/top5 = 0.8
I0802 12:02:35.010470 19007 caffe.cpp:313] Batch 13, loss = 1.54626
I0802 12:02:35.058239 19007 caffe.cpp:313] Batch 14, accuracy/top1 = 0.44
I0802 12:02:35.058255 19007 caffe.cpp:313] Batch 14, accuracy/top5 = 0.76
I0802 12:02:35.058259 19007 caffe.cpp:313] Batch 14, loss = 2.24706
I0802 12:02:35.107151 19007 caffe.cpp:313] Batch 15, accuracy/top1 = 0.6
I0802 12:02:35.107167 19007 caffe.cpp:313] Batch 15, accuracy/top5 = 0.78
I0802 12:02:35.107169 19007 caffe.cpp:313] Batch 15, loss = 2.28105
I0802 12:02:35.156550 19007 caffe.cpp:313] Batch 16, accuracy/top1 = 0.54
I0802 12:02:35.156576 19007 caffe.cpp:313] Batch 16, accuracy/top5 = 0.8
I0802 12:02:35.156579 19007 caffe.cpp:313] Batch 16, loss = 2.27823
I0802 12:02:35.206221 19007 caffe.cpp:313] Batch 17, accuracy/top1 = 0.58
I0802 12:02:35.206245 19007 caffe.cpp:313] Batch 17, accuracy/top5 = 0.78
I0802 12:02:35.206248 19007 caffe.cpp:313] Batch 17, loss = 1.99662
I0802 12:02:35.255779 19007 caffe.cpp:313] Batch 18, accuracy/top1 = 0.62
I0802 12:02:35.255802 19007 caffe.cpp:313] Batch 18, accuracy/top5 = 0.82
I0802 12:02:35.255805 19007 caffe.cpp:313] Batch 18, loss = 1.81265
I0802 12:02:35.304208 19007 caffe.cpp:313] Batch 19, accuracy/top1 = 0.58
I0802 12:02:35.304234 19007 caffe.cpp:313] Batch 19, accuracy/top5 = 0.86
I0802 12:02:35.304236 19007 caffe.cpp:313] Batch 19, loss = 1.68417
I0802 12:02:35.352993 19007 caffe.cpp:313] Batch 20, accuracy/top1 = 0.54
I0802 12:02:35.353018 19007 caffe.cpp:313] Batch 20, accuracy/top5 = 0.84
I0802 12:02:35.353021 19007 caffe.cpp:313] Batch 20, loss = 1.88562
I0802 12:02:35.401563 19007 caffe.cpp:313] Batch 21, accuracy/top1 = 0.62
I0802 12:02:35.401587 19007 caffe.cpp:313] Batch 21, accuracy/top5 = 0.82
I0802 12:02:35.401589 19007 caffe.cpp:313] Batch 21, loss = 1.77146
I0802 12:02:35.449936 19007 caffe.cpp:313] Batch 22, accuracy/top1 = 0.5
I0802 12:02:35.449960 19007 caffe.cpp:313] Batch 22, accuracy/top5 = 0.76
I0802 12:02:35.449964 19007 caffe.cpp:313] Batch 22, loss = 2.42757
I0802 12:02:35.499310 19007 caffe.cpp:313] Batch 23, accuracy/top1 = 0.62
I0802 12:02:35.499333 19007 caffe.cpp:313] Batch 23, accuracy/top5 = 0.9
I0802 12:02:35.499336 19007 caffe.cpp:313] Batch 23, loss = 1.2465
I0802 12:02:35.550689 19007 caffe.cpp:313] Batch 24, accuracy/top1 = 0.68
I0802 12:02:35.550710 19007 caffe.cpp:313] Batch 24, accuracy/top5 = 0.84
I0802 12:02:35.550714 19007 caffe.cpp:313] Batch 24, loss = 1.50355
I0802 12:02:35.599622 19007 caffe.cpp:313] Batch 25, accuracy/top1 = 0.68
I0802 12:02:35.599647 19007 caffe.cpp:313] Batch 25, accuracy/top5 = 0.86
I0802 12:02:35.599650 19007 caffe.cpp:313] Batch 25, loss = 1.41694
I0802 12:02:35.648833 19007 caffe.cpp:313] Batch 26, accuracy/top1 = 0.56
I0802 12:02:35.648859 19007 caffe.cpp:313] Batch 26, accuracy/top5 = 0.8
I0802 12:02:35.648862 19007 caffe.cpp:313] Batch 26, loss = 1.84046
I0802 12:02:35.696966 19007 caffe.cpp:313] Batch 27, accuracy/top1 = 0.38
I0802 12:02:35.696990 19007 caffe.cpp:313] Batch 27, accuracy/top5 = 0.68
I0802 12:02:35.696992 19007 caffe.cpp:313] Batch 27, loss = 2.7792
I0802 12:02:35.745900 19007 caffe.cpp:313] Batch 28, accuracy/top1 = 0.7
I0802 12:02:35.745925 19007 caffe.cpp:313] Batch 28, accuracy/top5 = 0.82
I0802 12:02:35.745929 19007 caffe.cpp:313] Batch 28, loss = 1.62463
I0802 12:02:35.796461 19007 caffe.cpp:313] Batch 29, accuracy/top1 = 0.58
I0802 12:02:35.796481 19007 caffe.cpp:313] Batch 29, accuracy/top5 = 0.8
I0802 12:02:35.796484 19007 caffe.cpp:313] Batch 29, loss = 2.10051
I0802 12:02:35.844511 19007 caffe.cpp:313] Batch 30, accuracy/top1 = 0.52
I0802 12:02:35.844535 19007 caffe.cpp:313] Batch 30, accuracy/top5 = 0.74
I0802 12:02:35.844538 19007 caffe.cpp:313] Batch 30, loss = 2.34312
I0802 12:02:35.892706 19007 caffe.cpp:313] Batch 31, accuracy/top1 = 0.62
I0802 12:02:35.892727 19007 caffe.cpp:313] Batch 31, accuracy/top5 = 0.8
I0802 12:02:35.892731 19007 caffe.cpp:313] Batch 31, loss = 1.66966
I0802 12:02:35.940793 19007 caffe.cpp:313] Batch 32, accuracy/top1 = 0.54
I0802 12:02:35.940820 19007 caffe.cpp:313] Batch 32, accuracy/top5 = 0.76
I0802 12:02:35.940824 19007 caffe.cpp:313] Batch 32, loss = 2.09589
I0802 12:02:35.989950 19007 caffe.cpp:313] Batch 33, accuracy/top1 = 0.58
I0802 12:02:35.989974 19007 caffe.cpp:313] Batch 33, accuracy/top5 = 0.8
I0802 12:02:35.989977 19007 caffe.cpp:313] Batch 33, loss = 1.82416
I0802 12:02:36.038074 19007 caffe.cpp:313] Batch 34, accuracy/top1 = 0.54
I0802 12:02:36.038099 19007 caffe.cpp:313] Batch 34, accuracy/top5 = 0.78
I0802 12:02:36.038101 19007 caffe.cpp:313] Batch 34, loss = 1.96792
I0802 12:02:36.087671 19007 caffe.cpp:313] Batch 35, accuracy/top1 = 0.66
I0802 12:02:36.087687 19007 caffe.cpp:313] Batch 35, accuracy/top5 = 0.88
I0802 12:02:36.087688 19007 caffe.cpp:313] Batch 35, loss = 1.48527
I0802 12:02:36.136032 19007 caffe.cpp:313] Batch 36, accuracy/top1 = 0.6
I0802 12:02:36.136059 19007 caffe.cpp:313] Batch 36, accuracy/top5 = 0.78
I0802 12:02:36.136061 19007 caffe.cpp:313] Batch 36, loss = 1.97302
I0802 12:02:36.185562 19007 caffe.cpp:313] Batch 37, accuracy/top1 = 0.62
I0802 12:02:36.185585 19007 caffe.cpp:313] Batch 37, accuracy/top5 = 0.86
I0802 12:02:36.185588 19007 caffe.cpp:313] Batch 37, loss = 1.43408
I0802 12:02:36.234073 19007 caffe.cpp:313] Batch 38, accuracy/top1 = 0.54
I0802 12:02:36.234098 19007 caffe.cpp:313] Batch 38, accuracy/top5 = 0.74
I0802 12:02:36.234102 19007 caffe.cpp:313] Batch 38, loss = 2.27925
I0802 12:02:36.281586 19007 caffe.cpp:313] Batch 39, accuracy/top1 = 0.56
I0802 12:02:36.281610 19007 caffe.cpp:313] Batch 39, accuracy/top5 = 0.82
I0802 12:02:36.281612 19007 caffe.cpp:313] Batch 39, loss = 1.86521
I0802 12:02:36.329556 19007 caffe.cpp:313] Batch 40, accuracy/top1 = 0.5
I0802 12:02:36.329578 19007 caffe.cpp:313] Batch 40, accuracy/top5 = 0.66
I0802 12:02:36.329581 19007 caffe.cpp:313] Batch 40, loss = 2.53768
I0802 12:02:36.377604 19007 caffe.cpp:313] Batch 41, accuracy/top1 = 0.54
I0802 12:02:36.377624 19007 caffe.cpp:313] Batch 41, accuracy/top5 = 0.82
I0802 12:02:36.377627 19007 caffe.cpp:313] Batch 41, loss = 1.68637
I0802 12:02:36.426169 19007 caffe.cpp:313] Batch 42, accuracy/top1 = 0.66
I0802 12:02:36.426194 19007 caffe.cpp:313] Batch 42, accuracy/top5 = 0.82
I0802 12:02:36.426198 19007 caffe.cpp:313] Batch 42, loss = 1.94782
I0802 12:02:36.474475 19007 caffe.cpp:313] Batch 43, accuracy/top1 = 0.6
I0802 12:02:36.474498 19007 caffe.cpp:313] Batch 43, accuracy/top5 = 0.86
I0802 12:02:36.474501 19007 caffe.cpp:313] Batch 43, loss = 1.34892
I0802 12:02:36.523488 19007 caffe.cpp:313] Batch 44, accuracy/top1 = 0.52
I0802 12:02:36.523516 19007 caffe.cpp:313] Batch 44, accuracy/top5 = 0.74
I0802 12:02:36.523521 19007 caffe.cpp:313] Batch 44, loss = 1.93144
I0802 12:02:36.573392 19007 caffe.cpp:313] Batch 45, accuracy/top1 = 0.6
I0802 12:02:36.573416 19007 caffe.cpp:313] Batch 45, accuracy/top5 = 0.8
I0802 12:02:36.573421 19007 caffe.cpp:313] Batch 45, loss = 1.92573
I0802 12:02:36.621590 19007 caffe.cpp:313] Batch 46, accuracy/top1 = 0.64
I0802 12:02:36.621615 19007 caffe.cpp:313] Batch 46, accuracy/top5 = 0.9
I0802 12:02:36.621619 19007 caffe.cpp:313] Batch 46, loss = 1.504
I0802 12:02:36.671133 19007 caffe.cpp:313] Batch 47, accuracy/top1 = 0.58
I0802 12:02:36.671155 19007 caffe.cpp:313] Batch 47, accuracy/top5 = 0.78
I0802 12:02:36.671159 19007 caffe.cpp:313] Batch 47, loss = 2.09043
I0802 12:02:36.719619 19007 caffe.cpp:313] Batch 48, accuracy/top1 = 0.58
I0802 12:02:36.719645 19007 caffe.cpp:313] Batch 48, accuracy/top5 = 0.84
I0802 12:02:36.719648 19007 caffe.cpp:313] Batch 48, loss = 1.62099
I0802 12:02:36.768149 19007 caffe.cpp:313] Batch 49, accuracy/top1 = 0.62
I0802 12:02:36.768173 19007 caffe.cpp:313] Batch 49, accuracy/top5 = 0.88
I0802 12:02:36.768177 19007 caffe.cpp:313] Batch 49, loss = 1.51925
I0802 12:02:36.817236 19007 caffe.cpp:313] Batch 50, accuracy/top1 = 0.64
I0802 12:02:36.817261 19007 caffe.cpp:313] Batch 50, accuracy/top5 = 0.8
I0802 12:02:36.817265 19007 caffe.cpp:313] Batch 50, loss = 1.85551
I0802 12:02:36.866019 19007 caffe.cpp:313] Batch 51, accuracy/top1 = 0.5
I0802 12:02:36.866044 19007 caffe.cpp:313] Batch 51, accuracy/top5 = 0.8
I0802 12:02:36.866047 19007 caffe.cpp:313] Batch 51, loss = 1.98697
I0802 12:02:36.914674 19007 caffe.cpp:313] Batch 52, accuracy/top1 = 0.6
I0802 12:02:36.914700 19007 caffe.cpp:313] Batch 52, accuracy/top5 = 0.82
I0802 12:02:36.914703 19007 caffe.cpp:313] Batch 52, loss = 1.87175
I0802 12:02:36.963742 19007 caffe.cpp:313] Batch 53, accuracy/top1 = 0.56
I0802 12:02:36.963766 19007 caffe.cpp:313] Batch 53, accuracy/top5 = 0.74
I0802 12:02:36.963769 19007 caffe.cpp:313] Batch 53, loss = 2.30613
I0802 12:02:37.012063 19007 caffe.cpp:313] Batch 54, accuracy/top1 = 0.66
I0802 12:02:37.012089 19007 caffe.cpp:313] Batch 54, accuracy/top5 = 0.9
I0802 12:02:37.012094 19007 caffe.cpp:313] Batch 54, loss = 1.19668
I0802 12:02:37.060112 19007 caffe.cpp:313] Batch 55, accuracy/top1 = 0.7
I0802 12:02:37.060137 19007 caffe.cpp:313] Batch 55, accuracy/top5 = 0.92
I0802 12:02:37.060140 19007 caffe.cpp:313] Batch 55, loss = 1.24716
I0802 12:02:37.107478 19007 caffe.cpp:313] Batch 56, accuracy/top1 = 0.68
I0802 12:02:37.107493 19007 caffe.cpp:313] Batch 56, accuracy/top5 = 0.84
I0802 12:02:37.107497 19007 caffe.cpp:313] Batch 56, loss = 1.35253
I0802 12:02:37.155721 19007 caffe.cpp:313] Batch 57, accuracy/top1 = 0.6
I0802 12:02:37.155747 19007 caffe.cpp:313] Batch 57, accuracy/top5 = 0.84
I0802 12:02:37.155751 19007 caffe.cpp:313] Batch 57, loss = 1.9228
I0802 12:02:37.204968 19007 caffe.cpp:313] Batch 58, accuracy/top1 = 0.64
I0802 12:02:37.204994 19007 caffe.cpp:313] Batch 58, accuracy/top5 = 0.9
I0802 12:02:37.204998 19007 caffe.cpp:313] Batch 58, loss = 1.49268
I0802 12:02:37.254166 19007 caffe.cpp:313] Batch 59, accuracy/top1 = 0.72
I0802 12:02:37.254191 19007 caffe.cpp:313] Batch 59, accuracy/top5 = 0.86
I0802 12:02:37.254195 19007 caffe.cpp:313] Batch 59, loss = 1.25905
I0802 12:02:37.303151 19007 caffe.cpp:313] Batch 60, accuracy/top1 = 0.68
I0802 12:02:37.303175 19007 caffe.cpp:313] Batch 60, accuracy/top5 = 0.88
I0802 12:02:37.303179 19007 caffe.cpp:313] Batch 60, loss = 1.43217
I0802 12:02:37.351336 19007 caffe.cpp:313] Batch 61, accuracy/top1 = 0.58
I0802 12:02:37.351361 19007 caffe.cpp:313] Batch 61, accuracy/top5 = 0.84
I0802 12:02:37.351364 19007 caffe.cpp:313] Batch 61, loss = 1.83932
I0802 12:02:37.400533 19007 caffe.cpp:313] Batch 62, accuracy/top1 = 0.6
I0802 12:02:37.400558 19007 caffe.cpp:313] Batch 62, accuracy/top5 = 0.86
I0802 12:02:37.400563 19007 caffe.cpp:313] Batch 62, loss = 1.49572
I0802 12:02:37.450021 19007 caffe.cpp:313] Batch 63, accuracy/top1 = 0.6
I0802 12:02:37.450044 19007 caffe.cpp:313] Batch 63, accuracy/top5 = 0.8
I0802 12:02:37.450048 19007 caffe.cpp:313] Batch 63, loss = 1.62196
I0802 12:02:37.500789 19007 caffe.cpp:313] Batch 64, accuracy/top1 = 0.48
I0802 12:02:37.500809 19007 caffe.cpp:313] Batch 64, accuracy/top5 = 0.74
I0802 12:02:37.500813 19007 caffe.cpp:313] Batch 64, loss = 2.24431
I0802 12:02:37.548874 19007 caffe.cpp:313] Batch 65, accuracy/top1 = 0.6
I0802 12:02:37.548909 19007 caffe.cpp:313] Batch 65, accuracy/top5 = 0.78
I0802 12:02:37.548913 19007 caffe.cpp:313] Batch 65, loss = 1.86484
I0802 12:02:37.598049 19007 caffe.cpp:313] Batch 66, accuracy/top1 = 0.64
I0802 12:02:37.598073 19007 caffe.cpp:313] Batch 66, accuracy/top5 = 0.84
I0802 12:02:37.598076 19007 caffe.cpp:313] Batch 66, loss = 1.39344
I0802 12:02:37.648221 19007 caffe.cpp:313] Batch 67, accuracy/top1 = 0.6
I0802 12:02:37.648247 19007 caffe.cpp:313] Batch 67, accuracy/top5 = 0.8
I0802 12:02:37.648249 19007 caffe.cpp:313] Batch 67, loss = 1.69163
I0802 12:02:37.696733 19007 caffe.cpp:313] Batch 68, accuracy/top1 = 0.58
I0802 12:02:37.696758 19007 caffe.cpp:313] Batch 68, accuracy/top5 = 0.88
I0802 12:02:37.696761 19007 caffe.cpp:313] Batch 68, loss = 1.29659
I0802 12:02:37.746974 19007 caffe.cpp:313] Batch 69, accuracy/top1 = 0.58
I0802 12:02:37.746999 19007 caffe.cpp:313] Batch 69, accuracy/top5 = 0.82
I0802 12:02:37.747002 19007 caffe.cpp:313] Batch 69, loss = 1.74572
I0802 12:02:37.796573 19007 caffe.cpp:313] Batch 70, accuracy/top1 = 0.44
I0802 12:02:37.796597 19007 caffe.cpp:313] Batch 70, accuracy/top5 = 0.76
I0802 12:02:37.796600 19007 caffe.cpp:313] Batch 70, loss = 2.28009
I0802 12:02:37.846308 19007 caffe.cpp:313] Batch 71, accuracy/top1 = 0.46
I0802 12:02:37.846331 19007 caffe.cpp:313] Batch 71, accuracy/top5 = 0.78
I0802 12:02:37.846334 19007 caffe.cpp:313] Batch 71, loss = 2.31916
I0802 12:02:37.894876 19007 caffe.cpp:313] Batch 72, accuracy/top1 = 0.6
I0802 12:02:37.894896 19007 caffe.cpp:313] Batch 72, accuracy/top5 = 0.78
I0802 12:02:37.894899 19007 caffe.cpp:313] Batch 72, loss = 1.63979
I0802 12:02:37.943322 19007 caffe.cpp:313] Batch 73, accuracy/top1 = 0.6
I0802 12:02:37.943347 19007 caffe.cpp:313] Batch 73, accuracy/top5 = 0.86
I0802 12:02:37.943351 19007 caffe.cpp:313] Batch 73, loss = 1.57596
I0802 12:02:37.992146 19007 caffe.cpp:313] Batch 74, accuracy/top1 = 0.62
I0802 12:02:37.992171 19007 caffe.cpp:313] Batch 74, accuracy/top5 = 0.84
I0802 12:02:37.992173 19007 caffe.cpp:313] Batch 74, loss = 1.54949
I0802 12:02:38.041117 19007 caffe.cpp:313] Batch 75, accuracy/top1 = 0.6
I0802 12:02:38.041136 19007 caffe.cpp:313] Batch 75, accuracy/top5 = 0.8
I0802 12:02:38.041139 19007 caffe.cpp:313] Batch 75, loss = 1.69514
I0802 12:02:38.089486 19007 caffe.cpp:313] Batch 76, accuracy/top1 = 0.56
I0802 12:02:38.089500 19007 caffe.cpp:313] Batch 76, accuracy/top5 = 0.78
I0802 12:02:38.089504 19007 caffe.cpp:313] Batch 76, loss = 1.93026
I0802 12:02:38.137950 19007 caffe.cpp:313] Batch 77, accuracy/top1 = 0.56
I0802 12:02:38.137974 19007 caffe.cpp:313] Batch 77, accuracy/top5 = 0.86
I0802 12:02:38.137976 19007 caffe.cpp:313] Batch 77, loss = 1.79296
I0802 12:02:38.185744 19007 caffe.cpp:313] Batch 78, accuracy/top1 = 0.5
I0802 12:02:38.185767 19007 caffe.cpp:313] Batch 78, accuracy/top5 = 0.82
I0802 12:02:38.185771 19007 caffe.cpp:313] Batch 78, loss = 2.22618
I0802 12:02:38.234896 19007 caffe.cpp:313] Batch 79, accuracy/top1 = 0.68
I0802 12:02:38.234923 19007 caffe.cpp:313] Batch 79, accuracy/top5 = 0.84
I0802 12:02:38.234926 19007 caffe.cpp:313] Batch 79, loss = 1.6567
I0802 12:02:38.284019 19007 caffe.cpp:313] Batch 80, accuracy/top1 = 0.52
I0802 12:02:38.284044 19007 caffe.cpp:313] Batch 80, accuracy/top5 = 0.74
I0802 12:02:38.284046 19007 caffe.cpp:313] Batch 80, loss = 2.40439
I0802 12:02:38.332746 19007 caffe.cpp:313] Batch 81, accuracy/top1 = 0.66
I0802 12:02:38.332772 19007 caffe.cpp:313] Batch 81, accuracy/top5 = 0.86
I0802 12:02:38.332774 19007 caffe.cpp:313] Batch 81, loss = 1.45451
I0802 12:02:38.381901 19007 caffe.cpp:313] Batch 82, accuracy/top1 = 0.58
I0802 12:02:38.381927 19007 caffe.cpp:313] Batch 82, accuracy/top5 = 0.82
I0802 12:02:38.381929 19007 caffe.cpp:313] Batch 82, loss = 1.93233
I0802 12:02:38.429967 19007 caffe.cpp:313] Batch 83, accuracy/top1 = 0.56
I0802 12:02:38.429987 19007 caffe.cpp:313] Batch 83, accuracy/top5 = 0.78
I0802 12:02:38.429991 19007 caffe.cpp:313] Batch 83, loss = 2.23246
I0802 12:02:38.479207 19007 caffe.cpp:313] Batch 84, accuracy/top1 = 0.58
I0802 12:02:38.479228 19007 caffe.cpp:313] Batch 84, accuracy/top5 = 0.82
I0802 12:02:38.479230 19007 caffe.cpp:313] Batch 84, loss = 1.80883
I0802 12:02:38.530117 19007 caffe.cpp:313] Batch 85, accuracy/top1 = 0.66
I0802 12:02:38.530140 19007 caffe.cpp:313] Batch 85, accuracy/top5 = 0.86
I0802 12:02:38.530144 19007 caffe.cpp:313] Batch 85, loss = 1.4343
I0802 12:02:38.579504 19007 caffe.cpp:313] Batch 86, accuracy/top1 = 0.52
I0802 12:02:38.579527 19007 caffe.cpp:313] Batch 86, accuracy/top5 = 0.72
I0802 12:02:38.579531 19007 caffe.cpp:313] Batch 86, loss = 2.13814
I0802 12:02:38.627960 19007 caffe.cpp:313] Batch 87, accuracy/top1 = 0.64
I0802 12:02:38.627985 19007 caffe.cpp:313] Batch 87, accuracy/top5 = 0.78
I0802 12:02:38.627990 19007 caffe.cpp:313] Batch 87, loss = 1.70318
I0802 12:02:38.678129 19007 caffe.cpp:313] Batch 88, accuracy/top1 = 0.64
I0802 12:02:38.678154 19007 caffe.cpp:313] Batch 88, accuracy/top5 = 0.82
I0802 12:02:38.678158 19007 caffe.cpp:313] Batch 88, loss = 1.4371
I0802 12:02:38.727473 19007 caffe.cpp:313] Batch 89, accuracy/top1 = 0.64
I0802 12:02:38.727499 19007 caffe.cpp:313] Batch 89, accuracy/top5 = 0.82
I0802 12:02:38.727502 19007 caffe.cpp:313] Batch 89, loss = 2.10206
I0802 12:02:38.777230 19007 caffe.cpp:313] Batch 90, accuracy/top1 = 0.7
I0802 12:02:38.777254 19007 caffe.cpp:313] Batch 90, accuracy/top5 = 0.9
I0802 12:02:38.777258 19007 caffe.cpp:313] Batch 90, loss = 1.19605
I0802 12:02:38.826617 19007 caffe.cpp:313] Batch 91, accuracy/top1 = 0.6
I0802 12:02:38.826642 19007 caffe.cpp:313] Batch 91, accuracy/top5 = 0.76
I0802 12:02:38.826647 19007 caffe.cpp:313] Batch 91, loss = 2.07775
I0802 12:02:38.876286 19007 caffe.cpp:313] Batch 92, accuracy/top1 = 0.52
I0802 12:02:38.876312 19007 caffe.cpp:313] Batch 92, accuracy/top5 = 0.76
I0802 12:02:38.876315 19007 caffe.cpp:313] Batch 92, loss = 2.33067
I0802 12:02:38.925313 19007 caffe.cpp:313] Batch 93, accuracy/top1 = 0.62
I0802 12:02:38.925338 19007 caffe.cpp:313] Batch 93, accuracy/top5 = 0.86
I0802 12:02:38.925343 19007 caffe.cpp:313] Batch 93, loss = 1.67737
I0802 12:02:38.975131 19007 caffe.cpp:313] Batch 94, accuracy/top1 = 0.7
I0802 12:02:38.975155 19007 caffe.cpp:313] Batch 94, accuracy/top5 = 0.92
I0802 12:02:38.975160 19007 caffe.cpp:313] Batch 94, loss = 1.06617
I0802 12:02:39.024824 19007 caffe.cpp:313] Batch 95, accuracy/top1 = 0.56
I0802 12:02:39.024849 19007 caffe.cpp:313] Batch 95, accuracy/top5 = 0.82
I0802 12:02:39.024853 19007 caffe.cpp:313] Batch 95, loss = 1.82089
I0802 12:02:39.073002 19007 caffe.cpp:313] Batch 96, accuracy/top1 = 0.46
I0802 12:02:39.073019 19007 caffe.cpp:313] Batch 96, accuracy/top5 = 0.8
I0802 12:02:39.073022 19007 caffe.cpp:313] Batch 96, loss = 2.09965
I0802 12:02:39.122509 19007 caffe.cpp:313] Batch 97, accuracy/top1 = 0.6
I0802 12:02:39.122534 19007 caffe.cpp:313] Batch 97, accuracy/top5 = 0.8
I0802 12:02:39.122539 19007 caffe.cpp:313] Batch 97, loss = 1.65297
I0802 12:02:39.172204 19007 caffe.cpp:313] Batch 98, accuracy/top1 = 0.5
I0802 12:02:39.172230 19007 caffe.cpp:313] Batch 98, accuracy/top5 = 0.8
I0802 12:02:39.172233 19007 caffe.cpp:313] Batch 98, loss = 2.15305
I0802 12:02:39.222139 19007 caffe.cpp:313] Batch 99, accuracy/top1 = 0.52
I0802 12:02:39.222165 19007 caffe.cpp:313] Batch 99, accuracy/top5 = 0.78
I0802 12:02:39.222170 19007 caffe.cpp:313] Batch 99, loss = 1.92869
I0802 12:02:39.271126 19007 caffe.cpp:313] Batch 100, accuracy/top1 = 0.72
I0802 12:02:39.271152 19007 caffe.cpp:313] Batch 100, accuracy/top5 = 0.82
I0802 12:02:39.271155 19007 caffe.cpp:313] Batch 100, loss = 1.3043
I0802 12:02:39.319902 19007 caffe.cpp:313] Batch 101, accuracy/top1 = 0.64
I0802 12:02:39.319929 19007 caffe.cpp:313] Batch 101, accuracy/top5 = 0.84
I0802 12:02:39.319933 19007 caffe.cpp:313] Batch 101, loss = 1.80198
I0802 12:02:39.368623 19007 caffe.cpp:313] Batch 102, accuracy/top1 = 0.44
I0802 12:02:39.368649 19007 caffe.cpp:313] Batch 102, accuracy/top5 = 0.72
I0802 12:02:39.368652 19007 caffe.cpp:313] Batch 102, loss = 2.72763
I0802 12:02:39.418382 19007 caffe.cpp:313] Batch 103, accuracy/top1 = 0.68
I0802 12:02:39.418409 19007 caffe.cpp:313] Batch 103, accuracy/top5 = 0.86
I0802 12:02:39.418413 19007 caffe.cpp:313] Batch 103, loss = 1.27439
I0802 12:02:39.467711 19007 caffe.cpp:313] Batch 104, accuracy/top1 = 0.66
I0802 12:02:39.467736 19007 caffe.cpp:313] Batch 104, accuracy/top5 = 0.8
I0802 12:02:39.467741 19007 caffe.cpp:313] Batch 104, loss = 1.55821
I0802 12:02:39.517012 19007 caffe.cpp:313] Batch 105, accuracy/top1 = 0.56
I0802 12:02:39.517040 19007 caffe.cpp:313] Batch 105, accuracy/top5 = 0.74
I0802 12:02:39.517043 19007 caffe.cpp:313] Batch 105, loss = 1.99358
I0802 12:02:39.566654 19007 caffe.cpp:313] Batch 106, accuracy/top1 = 0.54
I0802 12:02:39.566678 19007 caffe.cpp:313] Batch 106, accuracy/top5 = 0.84
I0802 12:02:39.566681 19007 caffe.cpp:313] Batch 106, loss = 1.77485
I0802 12:02:39.615541 19007 caffe.cpp:313] Batch 107, accuracy/top1 = 0.5
I0802 12:02:39.615566 19007 caffe.cpp:313] Batch 107, accuracy/top5 = 0.74
I0802 12:02:39.615571 19007 caffe.cpp:313] Batch 107, loss = 1.95695
I0802 12:02:39.664696 19007 caffe.cpp:313] Batch 108, accuracy/top1 = 0.6
I0802 12:02:39.664722 19007 caffe.cpp:313] Batch 108, accuracy/top5 = 0.84
I0802 12:02:39.664726 19007 caffe.cpp:313] Batch 108, loss = 1.46321
I0802 12:02:39.714876 19007 caffe.cpp:313] Batch 109, accuracy/top1 = 0.66
I0802 12:02:39.714902 19007 caffe.cpp:313] Batch 109, accuracy/top5 = 0.82
I0802 12:02:39.714906 19007 caffe.cpp:313] Batch 109, loss = 1.54227
I0802 12:02:39.764423 19007 caffe.cpp:313] Batch 110, accuracy/top1 = 0.56
I0802 12:02:39.764449 19007 caffe.cpp:313] Batch 110, accuracy/top5 = 0.8
I0802 12:02:39.764453 19007 caffe.cpp:313] Batch 110, loss = 1.86915
I0802 12:02:39.814815 19007 caffe.cpp:313] Batch 111, accuracy/top1 = 0.48
I0802 12:02:39.814841 19007 caffe.cpp:313] Batch 111, accuracy/top5 = 0.84
I0802 12:02:39.814846 19007 caffe.cpp:313] Batch 111, loss = 1.97748
I0802 12:02:39.863862 19007 caffe.cpp:313] Batch 112, accuracy/top1 = 0.6
I0802 12:02:39.863889 19007 caffe.cpp:313] Batch 112, accuracy/top5 = 0.8
I0802 12:02:39.863893 19007 caffe.cpp:313] Batch 112, loss = 1.9834
I0802 12:02:39.914347 19007 caffe.cpp:313] Batch 113, accuracy/top1 = 0.64
I0802 12:02:39.914372 19007 caffe.cpp:313] Batch 113, accuracy/top5 = 0.88
I0802 12:02:39.914376 19007 caffe.cpp:313] Batch 113, loss = 1.32312
I0802 12:02:39.962824 19007 caffe.cpp:313] Batch 114, accuracy/top1 = 0.62
I0802 12:02:39.962846 19007 caffe.cpp:313] Batch 114, accuracy/top5 = 0.84
I0802 12:02:39.962849 19007 caffe.cpp:313] Batch 114, loss = 1.79044
I0802 12:02:40.011040 19007 caffe.cpp:313] Batch 115, accuracy/top1 = 0.62
I0802 12:02:40.011065 19007 caffe.cpp:313] Batch 115, accuracy/top5 = 0.8
I0802 12:02:40.011070 19007 caffe.cpp:313] Batch 115, loss = 1.80787
I0802 12:02:40.061300 19007 caffe.cpp:313] Batch 116, accuracy/top1 = 0.56
I0802 12:02:40.061324 19007 caffe.cpp:313] Batch 116, accuracy/top5 = 0.76
I0802 12:02:40.061328 19007 caffe.cpp:313] Batch 116, loss = 1.94776
I0802 12:02:40.110636 19007 caffe.cpp:313] Batch 117, accuracy/top1 = 0.58
I0802 12:02:40.110651 19007 caffe.cpp:313] Batch 117, accuracy/top5 = 0.82
I0802 12:02:40.110656 19007 caffe.cpp:313] Batch 117, loss = 2.04822
I0802 12:02:40.160171 19007 caffe.cpp:313] Batch 118, accuracy/top1 = 0.42
I0802 12:02:40.160195 19007 caffe.cpp:313] Batch 118, accuracy/top5 = 0.72
I0802 12:02:40.160199 19007 caffe.cpp:313] Batch 118, loss = 2.79974
I0802 12:02:40.210049 19007 caffe.cpp:313] Batch 119, accuracy/top1 = 0.72
I0802 12:02:40.210075 19007 caffe.cpp:313] Batch 119, accuracy/top5 = 0.88
I0802 12:02:40.210079 19007 caffe.cpp:313] Batch 119, loss = 1.4217
I0802 12:02:40.258535 19007 caffe.cpp:313] Batch 120, accuracy/top1 = 0.5
I0802 12:02:40.258559 19007 caffe.cpp:313] Batch 120, accuracy/top5 = 0.86
I0802 12:02:40.258563 19007 caffe.cpp:313] Batch 120, loss = 1.84642
I0802 12:02:40.307389 19007 caffe.cpp:313] Batch 121, accuracy/top1 = 0.56
I0802 12:02:40.307415 19007 caffe.cpp:313] Batch 121, accuracy/top5 = 0.82
I0802 12:02:40.307418 19007 caffe.cpp:313] Batch 121, loss = 1.55135
I0802 12:02:40.355978 19007 caffe.cpp:313] Batch 122, accuracy/top1 = 0.52
I0802 12:02:40.356003 19007 caffe.cpp:313] Batch 122, accuracy/top5 = 0.82
I0802 12:02:40.356006 19007 caffe.cpp:313] Batch 122, loss = 2.50584
I0802 12:02:40.404139 19007 caffe.cpp:313] Batch 123, accuracy/top1 = 0.52
I0802 12:02:40.404165 19007 caffe.cpp:313] Batch 123, accuracy/top5 = 0.88
I0802 12:02:40.404191 19007 caffe.cpp:313] Batch 123, loss = 1.95735
I0802 12:02:40.453894 19007 caffe.cpp:313] Batch 124, accuracy/top1 = 0.58
I0802 12:02:40.453919 19007 caffe.cpp:313] Batch 124, accuracy/top5 = 0.74
I0802 12:02:40.453923 19007 caffe.cpp:313] Batch 124, loss = 2.075
I0802 12:02:40.502784 19007 caffe.cpp:313] Batch 125, accuracy/top1 = 0.56
I0802 12:02:40.502801 19007 caffe.cpp:313] Batch 125, accuracy/top5 = 0.8
I0802 12:02:40.502805 19007 caffe.cpp:313] Batch 125, loss = 1.587
I0802 12:02:40.552642 19007 caffe.cpp:313] Batch 126, accuracy/top1 = 0.54
I0802 12:02:40.552662 19007 caffe.cpp:313] Batch 126, accuracy/top5 = 0.86
I0802 12:02:40.552665 19007 caffe.cpp:313] Batch 126, loss = 1.67448
I0802 12:02:40.601817 19007 caffe.cpp:313] Batch 127, accuracy/top1 = 0.52
I0802 12:02:40.601840 19007 caffe.cpp:313] Batch 127, accuracy/top5 = 0.86
I0802 12:02:40.601842 19007 caffe.cpp:313] Batch 127, loss = 1.74104
I0802 12:02:40.651993 19007 caffe.cpp:313] Batch 128, accuracy/top1 = 0.62
I0802 12:02:40.652014 19007 caffe.cpp:313] Batch 128, accuracy/top5 = 0.86
I0802 12:02:40.652017 19007 caffe.cpp:313] Batch 128, loss = 1.67633
I0802 12:02:40.701120 19007 caffe.cpp:313] Batch 129, accuracy/top1 = 0.6
I0802 12:02:40.701143 19007 caffe.cpp:313] Batch 129, accuracy/top5 = 0.82
I0802 12:02:40.701146 19007 caffe.cpp:313] Batch 129, loss = 1.32629
I0802 12:02:40.750322 19007 caffe.cpp:313] Batch 130, accuracy/top1 = 0.68
I0802 12:02:40.750347 19007 caffe.cpp:313] Batch 130, accuracy/top5 = 0.88
I0802 12:02:40.750350 19007 caffe.cpp:313] Batch 130, loss = 1.45687
I0802 12:02:40.798532 19007 caffe.cpp:313] Batch 131, accuracy/top1 = 0.6
I0802 12:02:40.798557 19007 caffe.cpp:313] Batch 131, accuracy/top5 = 0.9
I0802 12:02:40.798560 19007 caffe.cpp:313] Batch 131, loss = 1.45498
I0802 12:02:40.846236 19007 caffe.cpp:313] Batch 132, accuracy/top1 = 0.62
I0802 12:02:40.846261 19007 caffe.cpp:313] Batch 132, accuracy/top5 = 0.82
I0802 12:02:40.846263 19007 caffe.cpp:313] Batch 132, loss = 1.74703
I0802 12:02:40.895689 19007 caffe.cpp:313] Batch 133, accuracy/top1 = 0.56
I0802 12:02:40.895712 19007 caffe.cpp:313] Batch 133, accuracy/top5 = 0.78
I0802 12:02:40.895715 19007 caffe.cpp:313] Batch 133, loss = 2.0118
I0802 12:02:40.943775 19007 caffe.cpp:313] Batch 134, accuracy/top1 = 0.6
I0802 12:02:40.943799 19007 caffe.cpp:313] Batch 134, accuracy/top5 = 0.84
I0802 12:02:40.943802 19007 caffe.cpp:313] Batch 134, loss = 1.68077
I0802 12:02:40.992182 19007 caffe.cpp:313] Batch 135, accuracy/top1 = 0.58
I0802 12:02:40.992207 19007 caffe.cpp:313] Batch 135, accuracy/top5 = 0.8
I0802 12:02:40.992209 19007 caffe.cpp:313] Batch 135, loss = 1.91908
I0802 12:02:41.041736 19007 caffe.cpp:313] Batch 136, accuracy/top1 = 0.52
I0802 12:02:41.041754 19007 caffe.cpp:313] Batch 136, accuracy/top5 = 0.84
I0802 12:02:41.041757 19007 caffe.cpp:313] Batch 136, loss = 2.07286
I0802 12:02:41.090978 19007 caffe.cpp:313] Batch 137, accuracy/top1 = 0.62
I0802 12:02:41.090993 19007 caffe.cpp:313] Batch 137, accuracy/top5 = 0.86
I0802 12:02:41.090996 19007 caffe.cpp:313] Batch 137, loss = 1.29688
I0802 12:02:41.140417 19007 caffe.cpp:313] Batch 138, accuracy/top1 = 0.7
I0802 12:02:41.140444 19007 caffe.cpp:313] Batch 138, accuracy/top5 = 0.92
I0802 12:02:41.140446 19007 caffe.cpp:313] Batch 138, loss = 1.15756
I0802 12:02:41.189070 19007 caffe.cpp:313] Batch 139, accuracy/top1 = 0.64
I0802 12:02:41.189095 19007 caffe.cpp:313] Batch 139, accuracy/top5 = 0.8
I0802 12:02:41.189097 19007 caffe.cpp:313] Batch 139, loss = 1.9711
I0802 12:02:41.237954 19007 caffe.cpp:313] Batch 140, accuracy/top1 = 0.62
I0802 12:02:41.237979 19007 caffe.cpp:313] Batch 140, accuracy/top5 = 0.8
I0802 12:02:41.237982 19007 caffe.cpp:313] Batch 140, loss = 1.80751
I0802 12:02:41.287888 19007 caffe.cpp:313] Batch 141, accuracy/top1 = 0.58
I0802 12:02:41.287911 19007 caffe.cpp:313] Batch 141, accuracy/top5 = 0.9
I0802 12:02:41.287914 19007 caffe.cpp:313] Batch 141, loss = 1.45532
I0802 12:02:41.337968 19007 caffe.cpp:313] Batch 142, accuracy/top1 = 0.62
I0802 12:02:41.337994 19007 caffe.cpp:313] Batch 142, accuracy/top5 = 0.84
I0802 12:02:41.338014 19007 caffe.cpp:313] Batch 142, loss = 1.92709
I0802 12:02:41.387812 19007 caffe.cpp:313] Batch 143, accuracy/top1 = 0.64
I0802 12:02:41.387837 19007 caffe.cpp:313] Batch 143, accuracy/top5 = 0.82
I0802 12:02:41.387840 19007 caffe.cpp:313] Batch 143, loss = 1.91649
I0802 12:02:41.436192 19007 caffe.cpp:313] Batch 144, accuracy/top1 = 0.64
I0802 12:02:41.436218 19007 caffe.cpp:313] Batch 144, accuracy/top5 = 0.9
I0802 12:02:41.436221 19007 caffe.cpp:313] Batch 144, loss = 1.51875
I0802 12:02:41.485090 19007 caffe.cpp:313] Batch 145, accuracy/top1 = 0.74
I0802 12:02:41.485113 19007 caffe.cpp:313] Batch 145, accuracy/top5 = 0.82
I0802 12:02:41.485116 19007 caffe.cpp:313] Batch 145, loss = 1.67173
I0802 12:02:41.534499 19007 caffe.cpp:313] Batch 146, accuracy/top1 = 0.66
I0802 12:02:41.534521 19007 caffe.cpp:313] Batch 146, accuracy/top5 = 0.92
I0802 12:02:41.534524 19007 caffe.cpp:313] Batch 146, loss = 1.21963
I0802 12:02:41.584549 19007 caffe.cpp:313] Batch 147, accuracy/top1 = 0.56
I0802 12:02:41.584573 19007 caffe.cpp:313] Batch 147, accuracy/top5 = 0.9
I0802 12:02:41.584576 19007 caffe.cpp:313] Batch 147, loss = 1.62034
I0802 12:02:41.632973 19007 caffe.cpp:313] Batch 148, accuracy/top1 = 0.58
I0802 12:02:41.632997 19007 caffe.cpp:313] Batch 148, accuracy/top5 = 0.82
I0802 12:02:41.633000 19007 caffe.cpp:313] Batch 148, loss = 1.95491
I0802 12:02:41.682097 19007 caffe.cpp:313] Batch 149, accuracy/top1 = 0.58
I0802 12:02:41.682121 19007 caffe.cpp:313] Batch 149, accuracy/top5 = 0.82
I0802 12:02:41.682123 19007 caffe.cpp:313] Batch 149, loss = 1.50625
I0802 12:02:41.730459 19007 caffe.cpp:313] Batch 150, accuracy/top1 = 0.62
I0802 12:02:41.730484 19007 caffe.cpp:313] Batch 150, accuracy/top5 = 0.78
I0802 12:02:41.730487 19007 caffe.cpp:313] Batch 150, loss = 1.81206
I0802 12:02:41.779968 19007 caffe.cpp:313] Batch 151, accuracy/top1 = 0.66
I0802 12:02:41.779992 19007 caffe.cpp:313] Batch 151, accuracy/top5 = 0.86
I0802 12:02:41.779995 19007 caffe.cpp:313] Batch 151, loss = 1.45063
I0802 12:02:41.827469 19007 caffe.cpp:313] Batch 152, accuracy/top1 = 0.64
I0802 12:02:41.827494 19007 caffe.cpp:313] Batch 152, accuracy/top5 = 0.8
I0802 12:02:41.827497 19007 caffe.cpp:313] Batch 152, loss = 1.80833
I0802 12:02:41.876133 19007 caffe.cpp:313] Batch 153, accuracy/top1 = 0.6
I0802 12:02:41.876157 19007 caffe.cpp:313] Batch 153, accuracy/top5 = 0.82
I0802 12:02:41.876159 19007 caffe.cpp:313] Batch 153, loss = 1.86929
I0802 12:02:41.925017 19007 caffe.cpp:313] Batch 154, accuracy/top1 = 0.66
I0802 12:02:41.925041 19007 caffe.cpp:313] Batch 154, accuracy/top5 = 0.84
I0802 12:02:41.925045 19007 caffe.cpp:313] Batch 154, loss = 1.42243
I0802 12:02:41.973922 19007 caffe.cpp:313] Batch 155, accuracy/top1 = 0.48
I0802 12:02:41.973942 19007 caffe.cpp:313] Batch 155, accuracy/top5 = 0.8
I0802 12:02:41.973944 19007 caffe.cpp:313] Batch 155, loss = 1.86458
I0802 12:02:42.022511 19007 caffe.cpp:313] Batch 156, accuracy/top1 = 0.6
I0802 12:02:42.022536 19007 caffe.cpp:313] Batch 156, accuracy/top5 = 0.76
I0802 12:02:42.022539 19007 caffe.cpp:313] Batch 156, loss = 1.96093
I0802 12:02:42.071329 19007 caffe.cpp:313] Batch 157, accuracy/top1 = 0.52
I0802 12:02:42.071346 19007 caffe.cpp:313] Batch 157, accuracy/top5 = 0.88
I0802 12:02:42.071349 19007 caffe.cpp:313] Batch 157, loss = 1.37507
I0802 12:02:42.121129 19007 caffe.cpp:313] Batch 158, accuracy/top1 = 0.68
I0802 12:02:42.121155 19007 caffe.cpp:313] Batch 158, accuracy/top5 = 0.86
I0802 12:02:42.121158 19007 caffe.cpp:313] Batch 158, loss = 1.34169
I0802 12:02:42.170974 19007 caffe.cpp:313] Batch 159, accuracy/top1 = 0.6
I0802 12:02:42.171000 19007 caffe.cpp:313] Batch 159, accuracy/top5 = 0.82
I0802 12:02:42.171002 19007 caffe.cpp:313] Batch 159, loss = 1.85417
I0802 12:02:42.220366 19007 caffe.cpp:313] Batch 160, accuracy/top1 = 0.72
I0802 12:02:42.220392 19007 caffe.cpp:313] Batch 160, accuracy/top5 = 0.84
I0802 12:02:42.220396 19007 caffe.cpp:313] Batch 160, loss = 1.47636
I0802 12:02:42.270112 19007 caffe.cpp:313] Batch 161, accuracy/top1 = 0.58
I0802 12:02:42.270153 19007 caffe.cpp:313] Batch 161, accuracy/top5 = 0.86
I0802 12:02:42.270157 19007 caffe.cpp:313] Batch 161, loss = 2.08457
I0802 12:02:42.319591 19007 caffe.cpp:313] Batch 162, accuracy/top1 = 0.52
I0802 12:02:42.319617 19007 caffe.cpp:313] Batch 162, accuracy/top5 = 0.88
I0802 12:02:42.319619 19007 caffe.cpp:313] Batch 162, loss = 1.79797
I0802 12:02:42.368793 19007 caffe.cpp:313] Batch 163, accuracy/top1 = 0.62
I0802 12:02:42.368822 19007 caffe.cpp:313] Batch 163, accuracy/top5 = 0.84
I0802 12:02:42.368826 19007 caffe.cpp:313] Batch 163, loss = 1.73521
I0802 12:02:42.418946 19007 caffe.cpp:313] Batch 164, accuracy/top1 = 0.7
I0802 12:02:42.418972 19007 caffe.cpp:313] Batch 164, accuracy/top5 = 0.82
I0802 12:02:42.418974 19007 caffe.cpp:313] Batch 164, loss = 1.6212
I0802 12:02:42.468641 19007 caffe.cpp:313] Batch 165, accuracy/top1 = 0.7
I0802 12:02:42.468664 19007 caffe.cpp:313] Batch 165, accuracy/top5 = 0.92
I0802 12:02:42.468667 19007 caffe.cpp:313] Batch 165, loss = 1.09156
I0802 12:02:42.518024 19007 caffe.cpp:313] Batch 166, accuracy/top1 = 0.52
I0802 12:02:42.518054 19007 caffe.cpp:313] Batch 166, accuracy/top5 = 0.8
I0802 12:02:42.518056 19007 caffe.cpp:313] Batch 166, loss = 2.265
I0802 12:02:42.567595 19007 caffe.cpp:313] Batch 167, accuracy/top1 = 0.48
I0802 12:02:42.567617 19007 caffe.cpp:313] Batch 167, accuracy/top5 = 0.8
I0802 12:02:42.567620 19007 caffe.cpp:313] Batch 167, loss = 1.93879
I0802 12:02:42.616482 19007 caffe.cpp:313] Batch 168, accuracy/top1 = 0.64
I0802 12:02:42.616508 19007 caffe.cpp:313] Batch 168, accuracy/top5 = 0.86
I0802 12:02:42.616511 19007 caffe.cpp:313] Batch 168, loss = 1.4054
I0802 12:02:42.665974 19007 caffe.cpp:313] Batch 169, accuracy/top1 = 0.68
I0802 12:02:42.665998 19007 caffe.cpp:313] Batch 169, accuracy/top5 = 0.9
I0802 12:02:42.666002 19007 caffe.cpp:313] Batch 169, loss = 1.27599
I0802 12:02:42.714861 19007 caffe.cpp:313] Batch 170, accuracy/top1 = 0.66
I0802 12:02:42.714882 19007 caffe.cpp:313] Batch 170, accuracy/top5 = 0.76
I0802 12:02:42.714886 19007 caffe.cpp:313] Batch 170, loss = 1.79912
I0802 12:02:42.763082 19007 caffe.cpp:313] Batch 171, accuracy/top1 = 0.5
I0802 12:02:42.763101 19007 caffe.cpp:313] Batch 171, accuracy/top5 = 0.76
I0802 12:02:42.763105 19007 caffe.cpp:313] Batch 171, loss = 2.1085
I0802 12:02:42.812858 19007 caffe.cpp:313] Batch 172, accuracy/top1 = 0.64
I0802 12:02:42.812882 19007 caffe.cpp:313] Batch 172, accuracy/top5 = 0.84
I0802 12:02:42.812885 19007 caffe.cpp:313] Batch 172, loss = 1.80618
I0802 12:02:42.862210 19007 caffe.cpp:313] Batch 173, accuracy/top1 = 0.62
I0802 12:02:42.862233 19007 caffe.cpp:313] Batch 173, accuracy/top5 = 0.84
I0802 12:02:42.862237 19007 caffe.cpp:313] Batch 173, loss = 1.82738
I0802 12:02:42.910275 19007 caffe.cpp:313] Batch 174, accuracy/top1 = 0.6
I0802 12:02:42.910300 19007 caffe.cpp:313] Batch 174, accuracy/top5 = 0.82
I0802 12:02:42.910303 19007 caffe.cpp:313] Batch 174, loss = 1.68955
I0802 12:02:42.959146 19007 caffe.cpp:313] Batch 175, accuracy/top1 = 0.62
I0802 12:02:42.959169 19007 caffe.cpp:313] Batch 175, accuracy/top5 = 0.76
I0802 12:02:42.959172 19007 caffe.cpp:313] Batch 175, loss = 1.95648
I0802 12:02:43.007355 19007 caffe.cpp:313] Batch 176, accuracy/top1 = 0.54
I0802 12:02:43.007380 19007 caffe.cpp:313] Batch 176, accuracy/top5 = 0.76
I0802 12:02:43.007383 19007 caffe.cpp:313] Batch 176, loss = 2.06726
I0802 12:02:43.055749 19007 caffe.cpp:313] Batch 177, accuracy/top1 = 0.62
I0802 12:02:43.055773 19007 caffe.cpp:313] Batch 177, accuracy/top5 = 0.78
I0802 12:02:43.055776 19007 caffe.cpp:313] Batch 177, loss = 1.73416
I0802 12:02:43.104691 19007 caffe.cpp:313] Batch 178, accuracy/top1 = 0.52
I0802 12:02:43.104706 19007 caffe.cpp:313] Batch 178, accuracy/top5 = 0.9
I0802 12:02:43.104708 19007 caffe.cpp:313] Batch 178, loss = 1.65619
I0802 12:02:43.155637 19007 caffe.cpp:313] Batch 179, accuracy/top1 = 0.64
I0802 12:02:43.155663 19007 caffe.cpp:313] Batch 179, accuracy/top5 = 0.86
I0802 12:02:43.155666 19007 caffe.cpp:313] Batch 179, loss = 1.57572
I0802 12:02:43.204010 19007 caffe.cpp:313] Batch 180, accuracy/top1 = 0.46
I0802 12:02:43.204033 19007 caffe.cpp:313] Batch 180, accuracy/top5 = 0.82
I0802 12:02:43.204036 19007 caffe.cpp:313] Batch 180, loss = 1.84173
I0802 12:02:43.253188 19007 caffe.cpp:313] Batch 181, accuracy/top1 = 0.6
I0802 12:02:43.253213 19007 caffe.cpp:313] Batch 181, accuracy/top5 = 0.68
I0802 12:02:43.253216 19007 caffe.cpp:313] Batch 181, loss = 2.17349
I0802 12:02:43.302217 19007 caffe.cpp:313] Batch 182, accuracy/top1 = 0.56
I0802 12:02:43.302242 19007 caffe.cpp:313] Batch 182, accuracy/top5 = 0.82
I0802 12:02:43.302245 19007 caffe.cpp:313] Batch 182, loss = 2.12902
I0802 12:02:43.351394 19007 caffe.cpp:313] Batch 183, accuracy/top1 = 0.58
I0802 12:02:43.351419 19007 caffe.cpp:313] Batch 183, accuracy/top5 = 0.8
I0802 12:02:43.351423 19007 caffe.cpp:313] Batch 183, loss = 2.02826
I0802 12:02:43.399019 19007 caffe.cpp:313] Batch 184, accuracy/top1 = 0.66
I0802 12:02:43.399044 19007 caffe.cpp:313] Batch 184, accuracy/top5 = 0.8
I0802 12:02:43.399047 19007 caffe.cpp:313] Batch 184, loss = 1.72596
I0802 12:02:43.447767 19007 caffe.cpp:313] Batch 185, accuracy/top1 = 0.5
I0802 12:02:43.447793 19007 caffe.cpp:313] Batch 185, accuracy/top5 = 0.78
I0802 12:02:43.447796 19007 caffe.cpp:313] Batch 185, loss = 2.1112
I0802 12:02:43.496803 19007 caffe.cpp:313] Batch 186, accuracy/top1 = 0.42
I0802 12:02:43.496829 19007 caffe.cpp:313] Batch 186, accuracy/top5 = 0.86
I0802 12:02:43.496832 19007 caffe.cpp:313] Batch 186, loss = 1.7067
I0802 12:02:43.547475 19007 caffe.cpp:313] Batch 187, accuracy/top1 = 0.58
I0802 12:02:43.547498 19007 caffe.cpp:313] Batch 187, accuracy/top5 = 0.86
I0802 12:02:43.547502 19007 caffe.cpp:313] Batch 187, loss = 1.57741
I0802 12:02:43.595546 19007 caffe.cpp:313] Batch 188, accuracy/top1 = 0.58
I0802 12:02:43.595571 19007 caffe.cpp:313] Batch 188, accuracy/top5 = 0.82
I0802 12:02:43.595574 19007 caffe.cpp:313] Batch 188, loss = 1.57777
I0802 12:02:43.644686 19007 caffe.cpp:313] Batch 189, accuracy/top1 = 0.56
I0802 12:02:43.644711 19007 caffe.cpp:313] Batch 189, accuracy/top5 = 0.8
I0802 12:02:43.644713 19007 caffe.cpp:313] Batch 189, loss = 1.7511
I0802 12:02:43.693532 19007 caffe.cpp:313] Batch 190, accuracy/top1 = 0.56
I0802 12:02:43.693557 19007 caffe.cpp:313] Batch 190, accuracy/top5 = 0.9
I0802 12:02:43.693560 19007 caffe.cpp:313] Batch 190, loss = 1.58842
I0802 12:02:43.742410 19007 caffe.cpp:313] Batch 191, accuracy/top1 = 0.52
I0802 12:02:43.742436 19007 caffe.cpp:313] Batch 191, accuracy/top5 = 0.72
I0802 12:02:43.742439 19007 caffe.cpp:313] Batch 191, loss = 2.355
I0802 12:02:43.791177 19007 caffe.cpp:313] Batch 192, accuracy/top1 = 0.48
I0802 12:02:43.791201 19007 caffe.cpp:313] Batch 192, accuracy/top5 = 0.8
I0802 12:02:43.791204 19007 caffe.cpp:313] Batch 192, loss = 1.89059
I0802 12:02:43.840389 19007 caffe.cpp:313] Batch 193, accuracy/top1 = 0.56
I0802 12:02:43.840414 19007 caffe.cpp:313] Batch 193, accuracy/top5 = 0.8
I0802 12:02:43.840416 19007 caffe.cpp:313] Batch 193, loss = 1.91757
I0802 12:02:43.888957 19007 caffe.cpp:313] Batch 194, accuracy/top1 = 0.7
I0802 12:02:43.888981 19007 caffe.cpp:313] Batch 194, accuracy/top5 = 0.86
I0802 12:02:43.888984 19007 caffe.cpp:313] Batch 194, loss = 1.55494
I0802 12:02:43.937620 19007 caffe.cpp:313] Batch 195, accuracy/top1 = 0.6
I0802 12:02:43.937644 19007 caffe.cpp:313] Batch 195, accuracy/top5 = 0.82
I0802 12:02:43.937647 19007 caffe.cpp:313] Batch 195, loss = 1.65333
I0802 12:02:43.987035 19007 caffe.cpp:313] Batch 196, accuracy/top1 = 0.7
I0802 12:02:43.987053 19007 caffe.cpp:313] Batch 196, accuracy/top5 = 0.94
I0802 12:02:43.987056 19007 caffe.cpp:313] Batch 196, loss = 1.08107
I0802 12:02:44.036054 19007 caffe.cpp:313] Batch 197, accuracy/top1 = 0.72
I0802 12:02:44.036077 19007 caffe.cpp:313] Batch 197, accuracy/top5 = 0.88
I0802 12:02:44.036080 19007 caffe.cpp:313] Batch 197, loss = 1.27839
I0802 12:02:44.085841 19007 caffe.cpp:313] Batch 198, accuracy/top1 = 0.58
I0802 12:02:44.085856 19007 caffe.cpp:313] Batch 198, accuracy/top5 = 0.82
I0802 12:02:44.085860 19007 caffe.cpp:313] Batch 198, loss = 1.9179
I0802 12:02:44.134238 19007 caffe.cpp:313] Batch 199, accuracy/top1 = 0.74
I0802 12:02:44.134263 19007 caffe.cpp:313] Batch 199, accuracy/top5 = 0.86
I0802 12:02:44.134265 19007 caffe.cpp:313] Batch 199, loss = 1.21153
I0802 12:02:44.183260 19007 caffe.cpp:313] Batch 200, accuracy/top1 = 0.6
I0802 12:02:44.183285 19007 caffe.cpp:313] Batch 200, accuracy/top5 = 0.78
I0802 12:02:44.183289 19007 caffe.cpp:313] Batch 200, loss = 1.83875
I0802 12:02:44.232841 19007 caffe.cpp:313] Batch 201, accuracy/top1 = 0.52
I0802 12:02:44.232864 19007 caffe.cpp:313] Batch 201, accuracy/top5 = 0.76
I0802 12:02:44.232867 19007 caffe.cpp:313] Batch 201, loss = 2.12888
I0802 12:02:44.282296 19007 caffe.cpp:313] Batch 202, accuracy/top1 = 0.52
I0802 12:02:44.282320 19007 caffe.cpp:313] Batch 202, accuracy/top5 = 0.84
I0802 12:02:44.282322 19007 caffe.cpp:313] Batch 202, loss = 1.69478
I0802 12:02:44.330750 19007 caffe.cpp:313] Batch 203, accuracy/top1 = 0.66
I0802 12:02:44.330775 19007 caffe.cpp:313] Batch 203, accuracy/top5 = 0.82
I0802 12:02:44.330778 19007 caffe.cpp:313] Batch 203, loss = 1.52623
I0802 12:02:44.379287 19007 caffe.cpp:313] Batch 204, accuracy/top1 = 0.72
I0802 12:02:44.379312 19007 caffe.cpp:313] Batch 204, accuracy/top5 = 0.88
I0802 12:02:44.379314 19007 caffe.cpp:313] Batch 204, loss = 1.31034
I0802 12:02:44.427525 19007 caffe.cpp:313] Batch 205, accuracy/top1 = 0.54
I0802 12:02:44.427549 19007 caffe.cpp:313] Batch 205, accuracy/top5 = 0.84
I0802 12:02:44.427552 19007 caffe.cpp:313] Batch 205, loss = 1.80559
I0802 12:02:44.476356 19007 caffe.cpp:313] Batch 206, accuracy/top1 = 0.62
I0802 12:02:44.476380 19007 caffe.cpp:313] Batch 206, accuracy/top5 = 0.94
I0802 12:02:44.476383 19007 caffe.cpp:313] Batch 206, loss = 1.39639
I0802 12:02:44.525128 19007 caffe.cpp:313] Batch 207, accuracy/top1 = 0.7
I0802 12:02:44.525151 19007 caffe.cpp:313] Batch 207, accuracy/top5 = 0.82
I0802 12:02:44.525154 19007 caffe.cpp:313] Batch 207, loss = 1.44335
I0802 12:02:44.573637 19007 caffe.cpp:313] Batch 208, accuracy/top1 = 0.52
I0802 12:02:44.573658 19007 caffe.cpp:313] Batch 208, accuracy/top5 = 0.74
I0802 12:02:44.573662 19007 caffe.cpp:313] Batch 208, loss = 2.28752
I0802 12:02:44.621863 19007 caffe.cpp:313] Batch 209, accuracy/top1 = 0.56
I0802 12:02:44.621889 19007 caffe.cpp:313] Batch 209, accuracy/top5 = 0.82
I0802 12:02:44.621892 19007 caffe.cpp:313] Batch 209, loss = 1.6375
I0802 12:02:44.671345 19007 caffe.cpp:313] Batch 210, accuracy/top1 = 0.46
I0802 12:02:44.671370 19007 caffe.cpp:313] Batch 210, accuracy/top5 = 0.76
I0802 12:02:44.671375 19007 caffe.cpp:313] Batch 210, loss = 2.38501
I0802 12:02:44.720329 19007 caffe.cpp:313] Batch 211, accuracy/top1 = 0.58
I0802 12:02:44.720352 19007 caffe.cpp:313] Batch 211, accuracy/top5 = 0.84
I0802 12:02:44.720355 19007 caffe.cpp:313] Batch 211, loss = 1.8146
I0802 12:02:44.769798 19007 caffe.cpp:313] Batch 212, accuracy/top1 = 0.66
I0802 12:02:44.769822 19007 caffe.cpp:313] Batch 212, accuracy/top5 = 0.88
I0802 12:02:44.769825 19007 caffe.cpp:313] Batch 212, loss = 1.70793
I0802 12:02:44.818950 19007 caffe.cpp:313] Batch 213, accuracy/top1 = 0.72
I0802 12:02:44.818974 19007 caffe.cpp:313] Batch 213, accuracy/top5 = 0.86
I0802 12:02:44.818976 19007 caffe.cpp:313] Batch 213, loss = 1.45445
I0802 12:02:44.868700 19007 caffe.cpp:313] Batch 214, accuracy/top1 = 0.56
I0802 12:02:44.868722 19007 caffe.cpp:313] Batch 214, accuracy/top5 = 0.88
I0802 12:02:44.868726 19007 caffe.cpp:313] Batch 214, loss = 1.88148
I0802 12:02:44.915485 19007 caffe.cpp:313] Batch 215, accuracy/top1 = 0.52
I0802 12:02:44.915508 19007 caffe.cpp:313] Batch 215, accuracy/top5 = 0.74
I0802 12:02:44.915510 19007 caffe.cpp:313] Batch 215, loss = 1.94511
I0802 12:02:44.964045 19007 caffe.cpp:313] Batch 216, accuracy/top1 = 0.66
I0802 12:02:44.964067 19007 caffe.cpp:313] Batch 216, accuracy/top5 = 0.9
I0802 12:02:44.964071 19007 caffe.cpp:313] Batch 216, loss = 1.23734
I0802 12:02:45.012742 19007 caffe.cpp:313] Batch 217, accuracy/top1 = 0.66
I0802 12:02:45.012768 19007 caffe.cpp:313] Batch 217, accuracy/top5 = 0.84
I0802 12:02:45.012786 19007 caffe.cpp:313] Batch 217, loss = 1.48705
I0802 12:02:45.060868 19007 caffe.cpp:313] Batch 218, accuracy/top1 = 0.64
I0802 12:02:45.060886 19007 caffe.cpp:313] Batch 218, accuracy/top5 = 0.86
I0802 12:02:45.060889 19007 caffe.cpp:313] Batch 218, loss = 1.6068
I0802 12:02:45.109848 19007 caffe.cpp:313] Batch 219, accuracy/top1 = 0.6
I0802 12:02:45.109875 19007 caffe.cpp:313] Batch 219, accuracy/top5 = 0.88
I0802 12:02:45.109879 19007 caffe.cpp:313] Batch 219, loss = 1.46568
I0802 12:02:45.158517 19007 caffe.cpp:313] Batch 220, accuracy/top1 = 0.44
I0802 12:02:45.158542 19007 caffe.cpp:313] Batch 220, accuracy/top5 = 0.68
I0802 12:02:45.158545 19007 caffe.cpp:313] Batch 220, loss = 2.38441
I0802 12:02:45.207104 19007 caffe.cpp:313] Batch 221, accuracy/top1 = 0.72
I0802 12:02:45.207129 19007 caffe.cpp:313] Batch 221, accuracy/top5 = 0.9
I0802 12:02:45.207132 19007 caffe.cpp:313] Batch 221, loss = 1.51172
I0802 12:02:45.255823 19007 caffe.cpp:313] Batch 222, accuracy/top1 = 0.66
I0802 12:02:45.255848 19007 caffe.cpp:313] Batch 222, accuracy/top5 = 0.82
I0802 12:02:45.255851 19007 caffe.cpp:313] Batch 222, loss = 2.03978
I0802 12:02:45.304010 19007 caffe.cpp:313] Batch 223, accuracy/top1 = 0.6
I0802 12:02:45.304035 19007 caffe.cpp:313] Batch 223, accuracy/top5 = 0.82
I0802 12:02:45.304039 19007 caffe.cpp:313] Batch 223, loss = 1.58264
I0802 12:02:45.353381 19007 caffe.cpp:313] Batch 224, accuracy/top1 = 0.5
I0802 12:02:45.353405 19007 caffe.cpp:313] Batch 224, accuracy/top5 = 0.84
I0802 12:02:45.353408 19007 caffe.cpp:313] Batch 224, loss = 1.90804
I0802 12:02:45.401072 19007 caffe.cpp:313] Batch 225, accuracy/top1 = 0.74
I0802 12:02:45.401098 19007 caffe.cpp:313] Batch 225, accuracy/top5 = 0.9
I0802 12:02:45.401101 19007 caffe.cpp:313] Batch 225, loss = 1.17724
I0802 12:02:45.450186 19007 caffe.cpp:313] Batch 226, accuracy/top1 = 0.56
I0802 12:02:45.450212 19007 caffe.cpp:313] Batch 226, accuracy/top5 = 0.88
I0802 12:02:45.450214 19007 caffe.cpp:313] Batch 226, loss = 1.50759
I0802 12:02:45.499617 19007 caffe.cpp:313] Batch 227, accuracy/top1 = 0.56
I0802 12:02:45.499642 19007 caffe.cpp:313] Batch 227, accuracy/top5 = 0.88
I0802 12:02:45.499645 19007 caffe.cpp:313] Batch 227, loss = 1.39466
I0802 12:02:45.548871 19007 caffe.cpp:313] Batch 228, accuracy/top1 = 0.66
I0802 12:02:45.548892 19007 caffe.cpp:313] Batch 228, accuracy/top5 = 0.82
I0802 12:02:45.548897 19007 caffe.cpp:313] Batch 228, loss = 1.29593
I0802 12:02:45.597837 19007 caffe.cpp:313] Batch 229, accuracy/top1 = 0.64
I0802 12:02:45.597862 19007 caffe.cpp:313] Batch 229, accuracy/top5 = 0.9
I0802 12:02:45.597865 19007 caffe.cpp:313] Batch 229, loss = 1.31681
I0802 12:02:45.647023 19007 caffe.cpp:313] Batch 230, accuracy/top1 = 0.8
I0802 12:02:45.647047 19007 caffe.cpp:313] Batch 230, accuracy/top5 = 0.92
I0802 12:02:45.647052 19007 caffe.cpp:313] Batch 230, loss = 1.05487
I0802 12:02:45.695823 19007 caffe.cpp:313] Batch 231, accuracy/top1 = 0.56
I0802 12:02:45.695847 19007 caffe.cpp:313] Batch 231, accuracy/top5 = 0.76
I0802 12:02:45.695852 19007 caffe.cpp:313] Batch 231, loss = 2.13718
I0802 12:02:45.744454 19007 caffe.cpp:313] Batch 232, accuracy/top1 = 0.6
I0802 12:02:45.744478 19007 caffe.cpp:313] Batch 232, accuracy/top5 = 0.78
I0802 12:02:45.744482 19007 caffe.cpp:313] Batch 232, loss = 1.60271
I0802 12:02:45.793154 19007 caffe.cpp:313] Batch 233, accuracy/top1 = 0.58
I0802 12:02:45.793179 19007 caffe.cpp:313] Batch 233, accuracy/top5 = 0.84
I0802 12:02:45.793181 19007 caffe.cpp:313] Batch 233, loss = 1.66158
I0802 12:02:45.841814 19007 caffe.cpp:313] Batch 234, accuracy/top1 = 0.6
I0802 12:02:45.841837 19007 caffe.cpp:313] Batch 234, accuracy/top5 = 0.78
I0802 12:02:45.841841 19007 caffe.cpp:313] Batch 234, loss = 2.03301
I0802 12:02:45.891150 19007 caffe.cpp:313] Batch 235, accuracy/top1 = 0.64
I0802 12:02:45.891173 19007 caffe.cpp:313] Batch 235, accuracy/top5 = 0.9
I0802 12:02:45.891176 19007 caffe.cpp:313] Batch 235, loss = 1.32437
I0802 12:02:45.939649 19007 caffe.cpp:313] Batch 236, accuracy/top1 = 0.58
I0802 12:02:45.939692 19007 caffe.cpp:313] Batch 236, accuracy/top5 = 0.74
I0802 12:02:45.939695 19007 caffe.cpp:313] Batch 236, loss = 2.13669
I0802 12:02:45.988983 19007 caffe.cpp:313] Batch 237, accuracy/top1 = 0.62
I0802 12:02:45.989007 19007 caffe.cpp:313] Batch 237, accuracy/top5 = 0.9
I0802 12:02:45.989011 19007 caffe.cpp:313] Batch 237, loss = 1.28534
I0802 12:02:46.038211 19007 caffe.cpp:313] Batch 238, accuracy/top1 = 0.64
I0802 12:02:46.038234 19007 caffe.cpp:313] Batch 238, accuracy/top5 = 0.84
I0802 12:02:46.038238 19007 caffe.cpp:313] Batch 238, loss = 1.56251
I0802 12:02:46.088169 19007 caffe.cpp:313] Batch 239, accuracy/top1 = 0.58
I0802 12:02:46.088186 19007 caffe.cpp:313] Batch 239, accuracy/top5 = 0.9
I0802 12:02:46.088189 19007 caffe.cpp:313] Batch 239, loss = 1.3009
I0802 12:02:46.137655 19007 caffe.cpp:313] Batch 240, accuracy/top1 = 0.6
I0802 12:02:46.137681 19007 caffe.cpp:313] Batch 240, accuracy/top5 = 0.84
I0802 12:02:46.137684 19007 caffe.cpp:313] Batch 240, loss = 1.55116
I0802 12:02:46.187088 19007 caffe.cpp:313] Batch 241, accuracy/top1 = 0.62
I0802 12:02:46.187110 19007 caffe.cpp:313] Batch 241, accuracy/top5 = 0.82
I0802 12:02:46.187114 19007 caffe.cpp:313] Batch 241, loss = 1.7811
I0802 12:02:46.237326 19007 caffe.cpp:313] Batch 242, accuracy/top1 = 0.7
I0802 12:02:46.237350 19007 caffe.cpp:313] Batch 242, accuracy/top5 = 0.82
I0802 12:02:46.237354 19007 caffe.cpp:313] Batch 242, loss = 1.32651
I0802 12:02:46.286962 19007 caffe.cpp:313] Batch 243, accuracy/top1 = 0.54
I0802 12:02:46.286985 19007 caffe.cpp:313] Batch 243, accuracy/top5 = 0.78
I0802 12:02:46.286988 19007 caffe.cpp:313] Batch 243, loss = 1.74717
I0802 12:02:46.336334 19007 caffe.cpp:313] Batch 244, accuracy/top1 = 0.52
I0802 12:02:46.336359 19007 caffe.cpp:313] Batch 244, accuracy/top5 = 0.78
I0802 12:02:46.336361 19007 caffe.cpp:313] Batch 244, loss = 2.07075
I0802 12:02:46.385594 19007 caffe.cpp:313] Batch 245, accuracy/top1 = 0.44
I0802 12:02:46.385617 19007 caffe.cpp:313] Batch 245, accuracy/top5 = 0.68
I0802 12:02:46.385620 19007 caffe.cpp:313] Batch 245, loss = 2.6527
I0802 12:02:46.434602 19007 caffe.cpp:313] Batch 246, accuracy/top1 = 0.56
I0802 12:02:46.434626 19007 caffe.cpp:313] Batch 246, accuracy/top5 = 0.76
I0802 12:02:46.434629 19007 caffe.cpp:313] Batch 246, loss = 1.97099
I0802 12:02:46.484993 19007 caffe.cpp:313] Batch 247, accuracy/top1 = 0.5
I0802 12:02:46.485018 19007 caffe.cpp:313] Batch 247, accuracy/top5 = 0.78
I0802 12:02:46.485021 19007 caffe.cpp:313] Batch 247, loss = 2.21717
I0802 12:02:46.534570 19007 caffe.cpp:313] Batch 248, accuracy/top1 = 0.52
I0802 12:02:46.534592 19007 caffe.cpp:313] Batch 248, accuracy/top5 = 0.76
I0802 12:02:46.534595 19007 caffe.cpp:313] Batch 248, loss = 2.22791
I0802 12:02:46.584477 19007 caffe.cpp:313] Batch 249, accuracy/top1 = 0.54
I0802 12:02:46.584502 19007 caffe.cpp:313] Batch 249, accuracy/top5 = 0.72
I0802 12:02:46.584506 19007 caffe.cpp:313] Batch 249, loss = 2.03959
I0802 12:02:46.634685 19007 caffe.cpp:313] Batch 250, accuracy/top1 = 0.72
I0802 12:02:46.634711 19007 caffe.cpp:313] Batch 250, accuracy/top5 = 0.9
I0802 12:02:46.634713 19007 caffe.cpp:313] Batch 250, loss = 1.34769
I0802 12:02:46.684120 19007 caffe.cpp:313] Batch 251, accuracy/top1 = 0.52
I0802 12:02:46.684145 19007 caffe.cpp:313] Batch 251, accuracy/top5 = 0.84
I0802 12:02:46.684149 19007 caffe.cpp:313] Batch 251, loss = 1.59114
I0802 12:02:46.733623 19007 caffe.cpp:313] Batch 252, accuracy/top1 = 0.58
I0802 12:02:46.733647 19007 caffe.cpp:313] Batch 252, accuracy/top5 = 0.72
I0802 12:02:46.733651 19007 caffe.cpp:313] Batch 252, loss = 2.29325
I0802 12:02:46.782975 19007 caffe.cpp:313] Batch 253, accuracy/top1 = 0.58
I0802 12:02:46.783000 19007 caffe.cpp:313] Batch 253, accuracy/top5 = 0.78
I0802 12:02:46.783004 19007 caffe.cpp:313] Batch 253, loss = 2.10315
I0802 12:02:46.832404 19007 caffe.cpp:313] Batch 254, accuracy/top1 = 0.56
I0802 12:02:46.832429 19007 caffe.cpp:313] Batch 254, accuracy/top5 = 0.8
I0802 12:02:46.832433 19007 caffe.cpp:313] Batch 254, loss = 1.87571
I0802 12:02:46.881726 19007 caffe.cpp:313] Batch 255, accuracy/top1 = 0.48
I0802 12:02:46.881749 19007 caffe.cpp:313] Batch 255, accuracy/top5 = 0.78
I0802 12:02:46.881752 19007 caffe.cpp:313] Batch 255, loss = 2.16482
I0802 12:02:46.931169 19007 caffe.cpp:313] Batch 256, accuracy/top1 = 0.6
I0802 12:02:46.931191 19007 caffe.cpp:313] Batch 256, accuracy/top5 = 0.88
I0802 12:02:46.931195 19007 caffe.cpp:313] Batch 256, loss = 1.81442
I0802 12:02:46.981133 19007 caffe.cpp:313] Batch 257, accuracy/top1 = 0.54
I0802 12:02:46.981154 19007 caffe.cpp:313] Batch 257, accuracy/top5 = 0.78
I0802 12:02:46.981158 19007 caffe.cpp:313] Batch 257, loss = 2.08359
I0802 12:02:47.029844 19007 caffe.cpp:313] Batch 258, accuracy/top1 = 0.66
I0802 12:02:47.029865 19007 caffe.cpp:313] Batch 258, accuracy/top5 = 0.78
I0802 12:02:47.029868 19007 caffe.cpp:313] Batch 258, loss = 2.01016
I0802 12:02:47.077455 19007 caffe.cpp:313] Batch 259, accuracy/top1 = 0.42
I0802 12:02:47.077476 19007 caffe.cpp:313] Batch 259, accuracy/top5 = 0.74
I0802 12:02:47.077481 19007 caffe.cpp:313] Batch 259, loss = 2.21482
I0802 12:02:47.126137 19007 caffe.cpp:313] Batch 260, accuracy/top1 = 0.62
I0802 12:02:47.126161 19007 caffe.cpp:313] Batch 260, accuracy/top5 = 0.8
I0802 12:02:47.126164 19007 caffe.cpp:313] Batch 260, loss = 1.72879
I0802 12:02:47.175848 19007 caffe.cpp:313] Batch 261, accuracy/top1 = 0.6
I0802 12:02:47.175873 19007 caffe.cpp:313] Batch 261, accuracy/top5 = 0.84
I0802 12:02:47.175878 19007 caffe.cpp:313] Batch 261, loss = 1.66116
I0802 12:02:47.224673 19007 caffe.cpp:313] Batch 262, accuracy/top1 = 0.54
I0802 12:02:47.224696 19007 caffe.cpp:313] Batch 262, accuracy/top5 = 0.86
I0802 12:02:47.224700 19007 caffe.cpp:313] Batch 262, loss = 2.01336
I0802 12:02:47.273937 19007 caffe.cpp:313] Batch 263, accuracy/top1 = 0.68
I0802 12:02:47.273962 19007 caffe.cpp:313] Batch 263, accuracy/top5 = 0.84
I0802 12:02:47.273964 19007 caffe.cpp:313] Batch 263, loss = 1.56542
I0802 12:02:47.323799 19007 caffe.cpp:313] Batch 264, accuracy/top1 = 0.6
I0802 12:02:47.323824 19007 caffe.cpp:313] Batch 264, accuracy/top5 = 0.82
I0802 12:02:47.323827 19007 caffe.cpp:313] Batch 264, loss = 1.74189
I0802 12:02:47.371909 19007 caffe.cpp:313] Batch 265, accuracy/top1 = 0.68
I0802 12:02:47.371933 19007 caffe.cpp:313] Batch 265, accuracy/top5 = 0.86
I0802 12:02:47.371937 19007 caffe.cpp:313] Batch 265, loss = 1.43621
I0802 12:02:47.421085 19007 caffe.cpp:313] Batch 266, accuracy/top1 = 0.64
I0802 12:02:47.421109 19007 caffe.cpp:313] Batch 266, accuracy/top5 = 0.78
I0802 12:02:47.421111 19007 caffe.cpp:313] Batch 266, loss = 1.92148
I0802 12:02:47.469854 19007 caffe.cpp:313] Batch 267, accuracy/top1 = 0.68
I0802 12:02:47.469879 19007 caffe.cpp:313] Batch 267, accuracy/top5 = 0.86
I0802 12:02:47.469882 19007 caffe.cpp:313] Batch 267, loss = 1.58868
I0802 12:02:47.519544 19007 caffe.cpp:313] Batch 268, accuracy/top1 = 0.6
I0802 12:02:47.519559 19007 caffe.cpp:313] Batch 268, accuracy/top5 = 0.8
I0802 12:02:47.519562 19007 caffe.cpp:313] Batch 268, loss = 1.80611
I0802 12:02:47.569522 19007 caffe.cpp:313] Batch 269, accuracy/top1 = 0.64
I0802 12:02:47.569546 19007 caffe.cpp:313] Batch 269, accuracy/top5 = 0.9
I0802 12:02:47.569550 19007 caffe.cpp:313] Batch 269, loss = 1.51054
I0802 12:02:47.619078 19007 caffe.cpp:313] Batch 270, accuracy/top1 = 0.52
I0802 12:02:47.619102 19007 caffe.cpp:313] Batch 270, accuracy/top5 = 0.76
I0802 12:02:47.619105 19007 caffe.cpp:313] Batch 270, loss = 2.25024
I0802 12:02:47.668531 19007 caffe.cpp:313] Batch 271, accuracy/top1 = 0.52
I0802 12:02:47.668555 19007 caffe.cpp:313] Batch 271, accuracy/top5 = 0.82
I0802 12:02:47.668558 19007 caffe.cpp:313] Batch 271, loss = 2.45084
I0802 12:02:47.717792 19007 caffe.cpp:313] Batch 272, accuracy/top1 = 0.6
I0802 12:02:47.717816 19007 caffe.cpp:313] Batch 272, accuracy/top5 = 0.78
I0802 12:02:47.717819 19007 caffe.cpp:313] Batch 272, loss = 2.11345
I0802 12:02:47.766527 19007 caffe.cpp:313] Batch 273, accuracy/top1 = 0.62
I0802 12:02:47.766553 19007 caffe.cpp:313] Batch 273, accuracy/top5 = 0.9
I0802 12:02:47.766574 19007 caffe.cpp:313] Batch 273, loss = 1.47104
I0802 12:02:47.815755 19007 caffe.cpp:313] Batch 274, accuracy/top1 = 0.54
I0802 12:02:47.815778 19007 caffe.cpp:313] Batch 274, accuracy/top5 = 0.8
I0802 12:02:47.815783 19007 caffe.cpp:313] Batch 274, loss = 1.98844
I0802 12:02:47.864753 19007 caffe.cpp:313] Batch 275, accuracy/top1 = 0.6
I0802 12:02:47.864778 19007 caffe.cpp:313] Batch 275, accuracy/top5 = 0.84
I0802 12:02:47.864780 19007 caffe.cpp:313] Batch 275, loss = 1.77911
I0802 12:02:47.914429 19007 caffe.cpp:313] Batch 276, accuracy/top1 = 0.66
I0802 12:02:47.914453 19007 caffe.cpp:313] Batch 276, accuracy/top5 = 0.86
I0802 12:02:47.914456 19007 caffe.cpp:313] Batch 276, loss = 1.51161
I0802 12:02:47.964047 19007 caffe.cpp:313] Batch 277, accuracy/top1 = 0.64
I0802 12:02:47.964072 19007 caffe.cpp:313] Batch 277, accuracy/top5 = 0.84
I0802 12:02:47.964076 19007 caffe.cpp:313] Batch 277, loss = 1.39117
I0802 12:02:48.013320 19007 caffe.cpp:313] Batch 278, accuracy/top1 = 0.48
I0802 12:02:48.013345 19007 caffe.cpp:313] Batch 278, accuracy/top5 = 0.76
I0802 12:02:48.013347 19007 caffe.cpp:313] Batch 278, loss = 2.42655
I0802 12:02:48.062660 19007 caffe.cpp:313] Batch 279, accuracy/top1 = 0.62
I0802 12:02:48.062680 19007 caffe.cpp:313] Batch 279, accuracy/top5 = 0.82
I0802 12:02:48.062682 19007 caffe.cpp:313] Batch 279, loss = 1.75666
I0802 12:02:48.112006 19007 caffe.cpp:313] Batch 280, accuracy/top1 = 0.58
I0802 12:02:48.112022 19007 caffe.cpp:313] Batch 280, accuracy/top5 = 0.82
I0802 12:02:48.112026 19007 caffe.cpp:313] Batch 280, loss = 1.72413
I0802 12:02:48.161571 19007 caffe.cpp:313] Batch 281, accuracy/top1 = 0.52
I0802 12:02:48.161599 19007 caffe.cpp:313] Batch 281, accuracy/top5 = 0.86
I0802 12:02:48.161602 19007 caffe.cpp:313] Batch 281, loss = 2.11309
I0802 12:02:48.210300 19007 caffe.cpp:313] Batch 282, accuracy/top1 = 0.62
I0802 12:02:48.210324 19007 caffe.cpp:313] Batch 282, accuracy/top5 = 0.84
I0802 12:02:48.210327 19007 caffe.cpp:313] Batch 282, loss = 1.57654
I0802 12:02:48.258060 19007 caffe.cpp:313] Batch 283, accuracy/top1 = 0.54
I0802 12:02:48.258086 19007 caffe.cpp:313] Batch 283, accuracy/top5 = 0.78
I0802 12:02:48.258090 19007 caffe.cpp:313] Batch 283, loss = 2.03512
I0802 12:02:48.307243 19007 caffe.cpp:313] Batch 284, accuracy/top1 = 0.54
I0802 12:02:48.307267 19007 caffe.cpp:313] Batch 284, accuracy/top5 = 0.72
I0802 12:02:48.307271 19007 caffe.cpp:313] Batch 284, loss = 2.09251
I0802 12:02:48.355726 19007 caffe.cpp:313] Batch 285, accuracy/top1 = 0.64
I0802 12:02:48.355751 19007 caffe.cpp:313] Batch 285, accuracy/top5 = 0.86
I0802 12:02:48.355754 19007 caffe.cpp:313] Batch 285, loss = 1.45518
I0802 12:02:48.403949 19007 caffe.cpp:313] Batch 286, accuracy/top1 = 0.58
I0802 12:02:48.403971 19007 caffe.cpp:313] Batch 286, accuracy/top5 = 0.72
I0802 12:02:48.403975 19007 caffe.cpp:313] Batch 286, loss = 1.92722
I0802 12:02:48.452442 19007 caffe.cpp:313] Batch 287, accuracy/top1 = 0.52
I0802 12:02:48.452466 19007 caffe.cpp:313] Batch 287, accuracy/top5 = 0.7
I0802 12:02:48.452468 19007 caffe.cpp:313] Batch 287, loss = 2.13802
I0802 12:02:48.501015 19007 caffe.cpp:313] Batch 288, accuracy/top1 = 0.54
I0802 12:02:48.501040 19007 caffe.cpp:313] Batch 288, accuracy/top5 = 0.8
I0802 12:02:48.501044 19007 caffe.cpp:313] Batch 288, loss = 2.24281
I0802 12:02:48.550880 19007 caffe.cpp:313] Batch 289, accuracy/top1 = 0.56
I0802 12:02:48.550902 19007 caffe.cpp:313] Batch 289, accuracy/top5 = 0.88
I0802 12:02:48.550905 19007 caffe.cpp:313] Batch 289, loss = 1.50731
I0802 12:02:48.599782 19007 caffe.cpp:313] Batch 290, accuracy/top1 = 0.52
I0802 12:02:48.599807 19007 caffe.cpp:313] Batch 290, accuracy/top5 = 0.74
I0802 12:02:48.599809 19007 caffe.cpp:313] Batch 290, loss = 1.93197
I0802 12:02:48.648687 19007 caffe.cpp:313] Batch 291, accuracy/top1 = 0.56
I0802 12:02:48.648713 19007 caffe.cpp:313] Batch 291, accuracy/top5 = 0.72
I0802 12:02:48.648716 19007 caffe.cpp:313] Batch 291, loss = 2.2122
I0802 12:02:48.697404 19007 caffe.cpp:313] Batch 292, accuracy/top1 = 0.56
I0802 12:02:48.697428 19007 caffe.cpp:313] Batch 292, accuracy/top5 = 0.84
I0802 12:02:48.697448 19007 caffe.cpp:313] Batch 292, loss = 1.63225
I0802 12:02:48.746922 19007 caffe.cpp:313] Batch 293, accuracy/top1 = 0.68
I0802 12:02:48.746945 19007 caffe.cpp:313] Batch 293, accuracy/top5 = 0.82
I0802 12:02:48.746948 19007 caffe.cpp:313] Batch 293, loss = 1.57164
I0802 12:02:48.795019 19007 caffe.cpp:313] Batch 294, accuracy/top1 = 0.74
I0802 12:02:48.795042 19007 caffe.cpp:313] Batch 294, accuracy/top5 = 0.94
I0802 12:02:48.795045 19007 caffe.cpp:313] Batch 294, loss = 0.849408
I0802 12:02:48.844257 19007 caffe.cpp:313] Batch 295, accuracy/top1 = 0.54
I0802 12:02:48.844282 19007 caffe.cpp:313] Batch 295, accuracy/top5 = 0.78
I0802 12:02:48.844285 19007 caffe.cpp:313] Batch 295, loss = 1.86732
I0802 12:02:48.892904 19007 caffe.cpp:313] Batch 296, accuracy/top1 = 0.64
I0802 12:02:48.892927 19007 caffe.cpp:313] Batch 296, accuracy/top5 = 0.9
I0802 12:02:48.892930 19007 caffe.cpp:313] Batch 296, loss = 1.23382
I0802 12:02:48.941637 19007 caffe.cpp:313] Batch 297, accuracy/top1 = 0.72
I0802 12:02:48.941661 19007 caffe.cpp:313] Batch 297, accuracy/top5 = 0.92
I0802 12:02:48.941664 19007 caffe.cpp:313] Batch 297, loss = 1.25276
I0802 12:02:48.990468 19007 caffe.cpp:313] Batch 298, accuracy/top1 = 0.56
I0802 12:02:48.990492 19007 caffe.cpp:313] Batch 298, accuracy/top5 = 0.76
I0802 12:02:48.990495 19007 caffe.cpp:313] Batch 298, loss = 2.11606
I0802 12:02:49.039101 19007 caffe.cpp:313] Batch 299, accuracy/top1 = 0.48
I0802 12:02:49.039126 19007 caffe.cpp:313] Batch 299, accuracy/top5 = 0.78
I0802 12:02:49.039129 19007 caffe.cpp:313] Batch 299, loss = 2.00278
I0802 12:02:49.087299 19007 caffe.cpp:313] Batch 300, accuracy/top1 = 0.48
I0802 12:02:49.087321 19007 caffe.cpp:313] Batch 300, accuracy/top5 = 0.8
I0802 12:02:49.087323 19007 caffe.cpp:313] Batch 300, loss = 2.1318
I0802 12:02:49.136065 19007 caffe.cpp:313] Batch 301, accuracy/top1 = 0.54
I0802 12:02:49.136086 19007 caffe.cpp:313] Batch 301, accuracy/top5 = 0.78
I0802 12:02:49.136090 19007 caffe.cpp:313] Batch 301, loss = 2.60862
I0802 12:02:49.184370 19007 caffe.cpp:313] Batch 302, accuracy/top1 = 0.58
I0802 12:02:49.184392 19007 caffe.cpp:313] Batch 302, accuracy/top5 = 0.86
I0802 12:02:49.184396 19007 caffe.cpp:313] Batch 302, loss = 1.60066
I0802 12:02:49.232981 19007 caffe.cpp:313] Batch 303, accuracy/top1 = 0.6
I0802 12:02:49.233006 19007 caffe.cpp:313] Batch 303, accuracy/top5 = 0.86
I0802 12:02:49.233009 19007 caffe.cpp:313] Batch 303, loss = 1.55619
I0802 12:02:49.280838 19007 caffe.cpp:313] Batch 304, accuracy/top1 = 0.64
I0802 12:02:49.280861 19007 caffe.cpp:313] Batch 304, accuracy/top5 = 0.84
I0802 12:02:49.280864 19007 caffe.cpp:313] Batch 304, loss = 1.54904
I0802 12:02:49.330711 19007 caffe.cpp:313] Batch 305, accuracy/top1 = 0.56
I0802 12:02:49.330736 19007 caffe.cpp:313] Batch 305, accuracy/top5 = 0.9
I0802 12:02:49.330739 19007 caffe.cpp:313] Batch 305, loss = 1.44641
I0802 12:02:49.379083 19007 caffe.cpp:313] Batch 306, accuracy/top1 = 0.66
I0802 12:02:49.379109 19007 caffe.cpp:313] Batch 306, accuracy/top5 = 0.82
I0802 12:02:49.379112 19007 caffe.cpp:313] Batch 306, loss = 1.61917
I0802 12:02:49.427623 19007 caffe.cpp:313] Batch 307, accuracy/top1 = 0.58
I0802 12:02:49.427649 19007 caffe.cpp:313] Batch 307, accuracy/top5 = 0.82
I0802 12:02:49.427651 19007 caffe.cpp:313] Batch 307, loss = 1.81883
I0802 12:02:49.475957 19007 caffe.cpp:313] Batch 308, accuracy/top1 = 0.7
I0802 12:02:49.475982 19007 caffe.cpp:313] Batch 308, accuracy/top5 = 0.86
I0802 12:02:49.475986 19007 caffe.cpp:313] Batch 308, loss = 1.37315
I0802 12:02:49.525952 19007 caffe.cpp:313] Batch 309, accuracy/top1 = 0.62
I0802 12:02:49.525977 19007 caffe.cpp:313] Batch 309, accuracy/top5 = 0.8
I0802 12:02:49.525980 19007 caffe.cpp:313] Batch 309, loss = 1.82272
I0802 12:02:49.576052 19007 caffe.cpp:313] Batch 310, accuracy/top1 = 0.7
I0802 12:02:49.576076 19007 caffe.cpp:313] Batch 310, accuracy/top5 = 0.88
I0802 12:02:49.576078 19007 caffe.cpp:313] Batch 310, loss = 1.2064
I0802 12:02:49.624320 19007 caffe.cpp:313] Batch 311, accuracy/top1 = 0.56
I0802 12:02:49.624361 19007 caffe.cpp:313] Batch 311, accuracy/top5 = 0.76
I0802 12:02:49.624364 19007 caffe.cpp:313] Batch 311, loss = 2.28477
I0802 12:02:49.673593 19007 caffe.cpp:313] Batch 312, accuracy/top1 = 0.66
I0802 12:02:49.673616 19007 caffe.cpp:313] Batch 312, accuracy/top5 = 0.82
I0802 12:02:49.673620 19007 caffe.cpp:313] Batch 312, loss = 1.84511
I0802 12:02:49.722447 19007 caffe.cpp:313] Batch 313, accuracy/top1 = 0.66
I0802 12:02:49.722472 19007 caffe.cpp:313] Batch 313, accuracy/top5 = 0.9
I0802 12:02:49.722476 19007 caffe.cpp:313] Batch 313, loss = 1.57502
I0802 12:02:49.771234 19007 caffe.cpp:313] Batch 314, accuracy/top1 = 0.74
I0802 12:02:49.771258 19007 caffe.cpp:313] Batch 314, accuracy/top5 = 0.9
I0802 12:02:49.771261 19007 caffe.cpp:313] Batch 314, loss = 1.07406
I0802 12:02:49.819983 19007 caffe.cpp:313] Batch 315, accuracy/top1 = 0.62
I0802 12:02:49.820008 19007 caffe.cpp:313] Batch 315, accuracy/top5 = 0.84
I0802 12:02:49.820010 19007 caffe.cpp:313] Batch 315, loss = 1.47089
I0802 12:02:49.868211 19007 caffe.cpp:313] Batch 316, accuracy/top1 = 0.58
I0802 12:02:49.868235 19007 caffe.cpp:313] Batch 316, accuracy/top5 = 0.76
I0802 12:02:49.868238 19007 caffe.cpp:313] Batch 316, loss = 2.33225
I0802 12:02:49.916944 19007 caffe.cpp:313] Batch 317, accuracy/top1 = 0.62
I0802 12:02:49.916967 19007 caffe.cpp:313] Batch 317, accuracy/top5 = 0.84
I0802 12:02:49.916971 19007 caffe.cpp:313] Batch 317, loss = 1.58635
I0802 12:02:49.965286 19007 caffe.cpp:313] Batch 318, accuracy/top1 = 0.68
I0802 12:02:49.965311 19007 caffe.cpp:313] Batch 318, accuracy/top5 = 0.84
I0802 12:02:49.965313 19007 caffe.cpp:313] Batch 318, loss = 1.55904
I0802 12:02:50.013504 19007 caffe.cpp:313] Batch 319, accuracy/top1 = 0.54
I0802 12:02:50.013530 19007 caffe.cpp:313] Batch 319, accuracy/top5 = 0.88
I0802 12:02:50.013532 19007 caffe.cpp:313] Batch 319, loss = 1.9407
I0802 12:02:50.061501 19007 caffe.cpp:313] Batch 320, accuracy/top1 = 0.52
I0802 12:02:50.061520 19007 caffe.cpp:313] Batch 320, accuracy/top5 = 0.74
I0802 12:02:50.061523 19007 caffe.cpp:313] Batch 320, loss = 2.01558
I0802 12:02:50.110932 19007 caffe.cpp:313] Batch 321, accuracy/top1 = 0.54
I0802 12:02:50.110957 19007 caffe.cpp:313] Batch 321, accuracy/top5 = 0.8
I0802 12:02:50.110961 19007 caffe.cpp:313] Batch 321, loss = 2.16407
I0802 12:02:50.159267 19007 caffe.cpp:313] Batch 322, accuracy/top1 = 0.56
I0802 12:02:50.159293 19007 caffe.cpp:313] Batch 322, accuracy/top5 = 0.92
I0802 12:02:50.159296 19007 caffe.cpp:313] Batch 322, loss = 1.32003
I0802 12:02:50.208521 19007 caffe.cpp:313] Batch 323, accuracy/top1 = 0.6
I0802 12:02:50.208545 19007 caffe.cpp:313] Batch 323, accuracy/top5 = 0.78
I0802 12:02:50.208549 19007 caffe.cpp:313] Batch 323, loss = 2.04028
I0802 12:02:50.256798 19007 caffe.cpp:313] Batch 324, accuracy/top1 = 0.5
I0802 12:02:50.256824 19007 caffe.cpp:313] Batch 324, accuracy/top5 = 0.76
I0802 12:02:50.256827 19007 caffe.cpp:313] Batch 324, loss = 2.19491
I0802 12:02:50.305876 19007 caffe.cpp:313] Batch 325, accuracy/top1 = 0.58
I0802 12:02:50.305901 19007 caffe.cpp:313] Batch 325, accuracy/top5 = 0.8
I0802 12:02:50.305903 19007 caffe.cpp:313] Batch 325, loss = 1.68716
I0802 12:02:50.354409 19007 caffe.cpp:313] Batch 326, accuracy/top1 = 0.54
I0802 12:02:50.354434 19007 caffe.cpp:313] Batch 326, accuracy/top5 = 0.78
I0802 12:02:50.354437 19007 caffe.cpp:313] Batch 326, loss = 1.90214
I0802 12:02:50.403087 19007 caffe.cpp:313] Batch 327, accuracy/top1 = 0.52
I0802 12:02:50.403110 19007 caffe.cpp:313] Batch 327, accuracy/top5 = 0.8
I0802 12:02:50.403113 19007 caffe.cpp:313] Batch 327, loss = 1.9078
I0802 12:02:50.451468 19007 caffe.cpp:313] Batch 328, accuracy/top1 = 0.52
I0802 12:02:50.451493 19007 caffe.cpp:313] Batch 328, accuracy/top5 = 0.88
I0802 12:02:50.451496 19007 caffe.cpp:313] Batch 328, loss = 1.63706
I0802 12:02:50.499629 19007 caffe.cpp:313] Batch 329, accuracy/top1 = 0.54
I0802 12:02:50.499652 19007 caffe.cpp:313] Batch 329, accuracy/top5 = 0.88
I0802 12:02:50.499655 19007 caffe.cpp:313] Batch 329, loss = 1.83792
I0802 12:02:50.546779 19007 caffe.cpp:313] Batch 330, accuracy/top1 = 0.62
I0802 12:02:50.546815 19007 caffe.cpp:313] Batch 330, accuracy/top5 = 0.84
I0802 12:02:50.546819 19007 caffe.cpp:313] Batch 330, loss = 1.76578
I0802 12:02:50.596402 19007 caffe.cpp:313] Batch 331, accuracy/top1 = 0.58
I0802 12:02:50.596426 19007 caffe.cpp:313] Batch 331, accuracy/top5 = 0.82
I0802 12:02:50.596429 19007 caffe.cpp:313] Batch 331, loss = 1.82098
I0802 12:02:50.645110 19007 caffe.cpp:313] Batch 332, accuracy/top1 = 0.62
I0802 12:02:50.645134 19007 caffe.cpp:313] Batch 332, accuracy/top5 = 0.88
I0802 12:02:50.645138 19007 caffe.cpp:313] Batch 332, loss = 1.58096
I0802 12:02:50.698099 19007 caffe.cpp:313] Batch 333, accuracy/top1 = 0.54
I0802 12:02:50.698124 19007 caffe.cpp:313] Batch 333, accuracy/top5 = 0.86
I0802 12:02:50.698127 19007 caffe.cpp:313] Batch 333, loss = 2.00314
I0802 12:02:50.746086 19007 caffe.cpp:313] Batch 334, accuracy/top1 = 0.74
I0802 12:02:50.746110 19007 caffe.cpp:313] Batch 334, accuracy/top5 = 0.94
I0802 12:02:50.746114 19007 caffe.cpp:313] Batch 334, loss = 0.993699
I0802 12:02:50.800215 19007 caffe.cpp:313] Batch 335, accuracy/top1 = 0.54
I0802 12:02:50.800240 19007 caffe.cpp:313] Batch 335, accuracy/top5 = 0.72
I0802 12:02:50.800242 19007 caffe.cpp:313] Batch 335, loss = 2.07129
I0802 12:02:50.850113 19007 caffe.cpp:313] Batch 336, accuracy/top1 = 0.64
I0802 12:02:50.850137 19007 caffe.cpp:313] Batch 336, accuracy/top5 = 0.86
I0802 12:02:50.850142 19007 caffe.cpp:313] Batch 336, loss = 1.32889
I0802 12:02:50.903810 19007 caffe.cpp:313] Batch 337, accuracy/top1 = 0.66
I0802 12:02:50.903836 19007 caffe.cpp:313] Batch 337, accuracy/top5 = 0.84
I0802 12:02:50.903838 19007 caffe.cpp:313] Batch 337, loss = 1.53184
I0802 12:02:50.951737 19007 caffe.cpp:313] Batch 338, accuracy/top1 = 0.66
I0802 12:02:50.951762 19007 caffe.cpp:313] Batch 338, accuracy/top5 = 0.82
I0802 12:02:50.951766 19007 caffe.cpp:313] Batch 338, loss = 1.64923
I0802 12:02:51.004070 19007 caffe.cpp:313] Batch 339, accuracy/top1 = 0.58
I0802 12:02:51.004094 19007 caffe.cpp:313] Batch 339, accuracy/top5 = 0.84
I0802 12:02:51.004097 19007 caffe.cpp:313] Batch 339, loss = 1.81061
I0802 12:02:51.051906 19007 caffe.cpp:313] Batch 340, accuracy/top1 = 0.54
I0802 12:02:51.051923 19007 caffe.cpp:313] Batch 340, accuracy/top5 = 0.74
I0802 12:02:51.051926 19007 caffe.cpp:313] Batch 340, loss = 2.22016
I0802 12:02:51.100797 19007 caffe.cpp:313] Batch 341, accuracy/top1 = 0.54
I0802 12:02:51.100812 19007 caffe.cpp:313] Batch 341, accuracy/top5 = 0.74
I0802 12:02:51.100817 19007 caffe.cpp:313] Batch 341, loss = 2.06637
I0802 12:02:51.149565 19007 caffe.cpp:313] Batch 342, accuracy/top1 = 0.64
I0802 12:02:51.149591 19007 caffe.cpp:313] Batch 342, accuracy/top5 = 0.84
I0802 12:02:51.149595 19007 caffe.cpp:313] Batch 342, loss = 1.6181
I0802 12:02:51.199268 19007 caffe.cpp:313] Batch 343, accuracy/top1 = 0.58
I0802 12:02:51.199290 19007 caffe.cpp:313] Batch 343, accuracy/top5 = 0.72
I0802 12:02:51.199292 19007 caffe.cpp:313] Batch 343, loss = 1.97466
I0802 12:02:51.248849 19007 caffe.cpp:313] Batch 344, accuracy/top1 = 0.58
I0802 12:02:51.248870 19007 caffe.cpp:313] Batch 344, accuracy/top5 = 0.88
I0802 12:02:51.248873 19007 caffe.cpp:313] Batch 344, loss = 1.3949
I0802 12:02:51.298362 19007 caffe.cpp:313] Batch 345, accuracy/top1 = 0.6
I0802 12:02:51.298385 19007 caffe.cpp:313] Batch 345, accuracy/top5 = 0.88
I0802 12:02:51.298388 19007 caffe.cpp:313] Batch 345, loss = 1.62302
I0802 12:02:51.347524 19007 caffe.cpp:313] Batch 346, accuracy/top1 = 0.42
I0802 12:02:51.347550 19007 caffe.cpp:313] Batch 346, accuracy/top5 = 0.66
I0802 12:02:51.347553 19007 caffe.cpp:313] Batch 346, loss = 2.80184
I0802 12:02:51.396437 19007 caffe.cpp:313] Batch 347, accuracy/top1 = 0.64
I0802 12:02:51.396461 19007 caffe.cpp:313] Batch 347, accuracy/top5 = 0.86
I0802 12:02:51.396464 19007 caffe.cpp:313] Batch 347, loss = 1.43645
I0802 12:02:51.446184 19007 caffe.cpp:313] Batch 348, accuracy/top1 = 0.72
I0802 12:02:51.446209 19007 caffe.cpp:313] Batch 348, accuracy/top5 = 0.86
I0802 12:02:51.446228 19007 caffe.cpp:313] Batch 348, loss = 1.07407
I0802 12:02:51.495259 19007 caffe.cpp:313] Batch 349, accuracy/top1 = 0.58
I0802 12:02:51.495281 19007 caffe.cpp:313] Batch 349, accuracy/top5 = 0.78
I0802 12:02:51.495285 19007 caffe.cpp:313] Batch 349, loss = 2.25778
I0802 12:02:51.544498 19007 caffe.cpp:313] Batch 350, accuracy/top1 = 0.62
I0802 12:02:51.544520 19007 caffe.cpp:313] Batch 350, accuracy/top5 = 0.8
I0802 12:02:51.544524 19007 caffe.cpp:313] Batch 350, loss = 1.60309
I0802 12:02:51.592510 19007 caffe.cpp:313] Batch 351, accuracy/top1 = 0.6
I0802 12:02:51.592535 19007 caffe.cpp:313] Batch 351, accuracy/top5 = 0.84
I0802 12:02:51.592540 19007 caffe.cpp:313] Batch 351, loss = 1.45213
I0802 12:02:51.645870 19007 caffe.cpp:313] Batch 352, accuracy/top1 = 0.54
I0802 12:02:51.645891 19007 caffe.cpp:313] Batch 352, accuracy/top5 = 0.66
I0802 12:02:51.645896 19007 caffe.cpp:313] Batch 352, loss = 2.8044
I0802 12:02:51.694830 19007 caffe.cpp:313] Batch 353, accuracy/top1 = 0.52
I0802 12:02:51.694854 19007 caffe.cpp:313] Batch 353, accuracy/top5 = 0.84
I0802 12:02:51.694859 19007 caffe.cpp:313] Batch 353, loss = 1.88443
I0802 12:02:51.744490 19007 caffe.cpp:313] Batch 354, accuracy/top1 = 0.46
I0802 12:02:51.744516 19007 caffe.cpp:313] Batch 354, accuracy/top5 = 0.78
I0802 12:02:51.744520 19007 caffe.cpp:313] Batch 354, loss = 2.21265
I0802 12:02:51.793828 19007 caffe.cpp:313] Batch 355, accuracy/top1 = 0.62
I0802 12:02:51.793853 19007 caffe.cpp:313] Batch 355, accuracy/top5 = 0.8
I0802 12:02:51.793856 19007 caffe.cpp:313] Batch 355, loss = 1.8599
I0802 12:02:51.843435 19007 caffe.cpp:313] Batch 356, accuracy/top1 = 0.66
I0802 12:02:51.843459 19007 caffe.cpp:313] Batch 356, accuracy/top5 = 0.78
I0802 12:02:51.843464 19007 caffe.cpp:313] Batch 356, loss = 1.92227
I0802 12:02:51.892534 19007 caffe.cpp:313] Batch 357, accuracy/top1 = 0.66
I0802 12:02:51.892560 19007 caffe.cpp:313] Batch 357, accuracy/top5 = 0.9
I0802 12:02:51.892563 19007 caffe.cpp:313] Batch 357, loss = 1.35062
I0802 12:02:51.940321 19007 caffe.cpp:313] Batch 358, accuracy/top1 = 0.52
I0802 12:02:51.940348 19007 caffe.cpp:313] Batch 358, accuracy/top5 = 0.76
I0802 12:02:51.940352 19007 caffe.cpp:313] Batch 358, loss = 2.15571
I0802 12:02:51.989895 19007 caffe.cpp:313] Batch 359, accuracy/top1 = 0.52
I0802 12:02:51.989922 19007 caffe.cpp:313] Batch 359, accuracy/top5 = 0.84
I0802 12:02:51.989926 19007 caffe.cpp:313] Batch 359, loss = 2.09896
I0802 12:02:52.037559 19007 caffe.cpp:313] Batch 360, accuracy/top1 = 0.74
I0802 12:02:52.037585 19007 caffe.cpp:313] Batch 360, accuracy/top5 = 0.84
I0802 12:02:52.037588 19007 caffe.cpp:313] Batch 360, loss = 1.55788
I0802 12:02:52.085575 19007 caffe.cpp:313] Batch 361, accuracy/top1 = 0.58
I0802 12:02:52.085592 19007 caffe.cpp:313] Batch 361, accuracy/top5 = 0.82
I0802 12:02:52.085595 19007 caffe.cpp:313] Batch 361, loss = 1.65088
I0802 12:02:52.135318 19007 caffe.cpp:313] Batch 362, accuracy/top1 = 0.56
I0802 12:02:52.135345 19007 caffe.cpp:313] Batch 362, accuracy/top5 = 0.74
I0802 12:02:52.135350 19007 caffe.cpp:313] Batch 362, loss = 2.24696
I0802 12:02:52.184437 19007 caffe.cpp:313] Batch 363, accuracy/top1 = 0.7
I0802 12:02:52.184460 19007 caffe.cpp:313] Batch 363, accuracy/top5 = 0.82
I0802 12:02:52.184464 19007 caffe.cpp:313] Batch 363, loss = 1.69583
I0802 12:02:52.234482 19007 caffe.cpp:313] Batch 364, accuracy/top1 = 0.6
I0802 12:02:52.234506 19007 caffe.cpp:313] Batch 364, accuracy/top5 = 0.76
I0802 12:02:52.234510 19007 caffe.cpp:313] Batch 364, loss = 1.54469
I0802 12:02:52.284601 19007 caffe.cpp:313] Batch 365, accuracy/top1 = 0.56
I0802 12:02:52.284627 19007 caffe.cpp:313] Batch 365, accuracy/top5 = 0.8
I0802 12:02:52.284631 19007 caffe.cpp:313] Batch 365, loss = 1.81588
I0802 12:02:52.334311 19007 caffe.cpp:313] Batch 366, accuracy/top1 = 0.52
I0802 12:02:52.334336 19007 caffe.cpp:313] Batch 366, accuracy/top5 = 0.8
I0802 12:02:52.334339 19007 caffe.cpp:313] Batch 366, loss = 1.84471
I0802 12:02:52.383587 19007 caffe.cpp:313] Batch 367, accuracy/top1 = 0.6
I0802 12:02:52.383611 19007 caffe.cpp:313] Batch 367, accuracy/top5 = 0.82
I0802 12:02:52.383635 19007 caffe.cpp:313] Batch 367, loss = 1.72578
I0802 12:02:52.432148 19007 caffe.cpp:313] Batch 368, accuracy/top1 = 0.54
I0802 12:02:52.432173 19007 caffe.cpp:313] Batch 368, accuracy/top5 = 0.82
I0802 12:02:52.432178 19007 caffe.cpp:313] Batch 368, loss = 1.97415
I0802 12:02:52.480207 19007 caffe.cpp:313] Batch 369, accuracy/top1 = 0.68
I0802 12:02:52.480232 19007 caffe.cpp:313] Batch 369, accuracy/top5 = 0.88
I0802 12:02:52.480237 19007 caffe.cpp:313] Batch 369, loss = 1.33325
I0802 12:02:52.527386 19007 caffe.cpp:313] Batch 370, accuracy/top1 = 0.66
I0802 12:02:52.527410 19007 caffe.cpp:313] Batch 370, accuracy/top5 = 0.8
I0802 12:02:52.527413 19007 caffe.cpp:313] Batch 370, loss = 1.68123
I0802 12:02:52.576688 19007 caffe.cpp:313] Batch 371, accuracy/top1 = 0.62
I0802 12:02:52.576709 19007 caffe.cpp:313] Batch 371, accuracy/top5 = 0.82
I0802 12:02:52.576714 19007 caffe.cpp:313] Batch 371, loss = 1.5856
I0802 12:02:52.626081 19007 caffe.cpp:313] Batch 372, accuracy/top1 = 0.64
I0802 12:02:52.626106 19007 caffe.cpp:313] Batch 372, accuracy/top5 = 0.86
I0802 12:02:52.626111 19007 caffe.cpp:313] Batch 372, loss = 1.68476
I0802 12:02:52.674674 19007 caffe.cpp:313] Batch 373, accuracy/top1 = 0.52
I0802 12:02:52.674700 19007 caffe.cpp:313] Batch 373, accuracy/top5 = 0.76
I0802 12:02:52.674703 19007 caffe.cpp:313] Batch 373, loss = 2.86414
I0802 12:02:52.723871 19007 caffe.cpp:313] Batch 374, accuracy/top1 = 0.56
I0802 12:02:52.723897 19007 caffe.cpp:313] Batch 374, accuracy/top5 = 0.86
I0802 12:02:52.723901 19007 caffe.cpp:313] Batch 374, loss = 1.63887
I0802 12:02:52.773157 19007 caffe.cpp:313] Batch 375, accuracy/top1 = 0.72
I0802 12:02:52.773183 19007 caffe.cpp:313] Batch 375, accuracy/top5 = 0.9
I0802 12:02:52.773187 19007 caffe.cpp:313] Batch 375, loss = 1.2628
I0802 12:02:52.822319 19007 caffe.cpp:313] Batch 376, accuracy/top1 = 0.58
I0802 12:02:52.822345 19007 caffe.cpp:313] Batch 376, accuracy/top5 = 0.88
I0802 12:02:52.822350 19007 caffe.cpp:313] Batch 376, loss = 1.51278
I0802 12:02:52.872210 19007 caffe.cpp:313] Batch 377, accuracy/top1 = 0.64
I0802 12:02:52.872236 19007 caffe.cpp:313] Batch 377, accuracy/top5 = 0.84
I0802 12:02:52.872241 19007 caffe.cpp:313] Batch 377, loss = 1.6261
I0802 12:02:52.921805 19007 caffe.cpp:313] Batch 378, accuracy/top1 = 0.62
I0802 12:02:52.921830 19007 caffe.cpp:313] Batch 378, accuracy/top5 = 0.86
I0802 12:02:52.921834 19007 caffe.cpp:313] Batch 378, loss = 1.52616
I0802 12:02:52.969673 19007 caffe.cpp:313] Batch 379, accuracy/top1 = 0.74
I0802 12:02:52.969698 19007 caffe.cpp:313] Batch 379, accuracy/top5 = 0.92
I0802 12:02:52.969702 19007 caffe.cpp:313] Batch 379, loss = 1.22628
I0802 12:02:53.018024 19007 caffe.cpp:313] Batch 380, accuracy/top1 = 0.62
I0802 12:02:53.018049 19007 caffe.cpp:313] Batch 380, accuracy/top5 = 0.84
I0802 12:02:53.018054 19007 caffe.cpp:313] Batch 380, loss = 1.67002
I0802 12:02:53.067070 19007 caffe.cpp:313] Batch 381, accuracy/top1 = 0.52
I0802 12:02:53.067090 19007 caffe.cpp:313] Batch 381, accuracy/top5 = 0.76
I0802 12:02:53.067093 19007 caffe.cpp:313] Batch 381, loss = 2.25204
I0802 12:02:53.116827 19007 caffe.cpp:313] Batch 382, accuracy/top1 = 0.6
I0802 12:02:53.116852 19007 caffe.cpp:313] Batch 382, accuracy/top5 = 0.76
I0802 12:02:53.116858 19007 caffe.cpp:313] Batch 382, loss = 1.97841
I0802 12:02:53.166026 19007 caffe.cpp:313] Batch 383, accuracy/top1 = 0.72
I0802 12:02:53.166052 19007 caffe.cpp:313] Batch 383, accuracy/top5 = 0.9
I0802 12:02:53.166056 19007 caffe.cpp:313] Batch 383, loss = 1.30752
I0802 12:02:53.214190 19007 caffe.cpp:313] Batch 384, accuracy/top1 = 0.68
I0802 12:02:53.214215 19007 caffe.cpp:313] Batch 384, accuracy/top5 = 0.84
I0802 12:02:53.214218 19007 caffe.cpp:313] Batch 384, loss = 1.52144
I0802 12:02:53.263828 19007 caffe.cpp:313] Batch 385, accuracy/top1 = 0.66
I0802 12:02:53.263854 19007 caffe.cpp:313] Batch 385, accuracy/top5 = 0.82
I0802 12:02:53.263859 19007 caffe.cpp:313] Batch 385, loss = 1.54508
I0802 12:02:53.312273 19007 caffe.cpp:313] Batch 386, accuracy/top1 = 0.64
I0802 12:02:53.312307 19007 caffe.cpp:313] Batch 386, accuracy/top5 = 0.86
I0802 12:02:53.312312 19007 caffe.cpp:313] Batch 386, loss = 1.51969
I0802 12:02:53.360266 19007 caffe.cpp:313] Batch 387, accuracy/top1 = 0.62
I0802 12:02:53.360291 19007 caffe.cpp:313] Batch 387, accuracy/top5 = 0.78
I0802 12:02:53.360294 19007 caffe.cpp:313] Batch 387, loss = 1.90697
I0802 12:02:53.408558 19007 caffe.cpp:313] Batch 388, accuracy/top1 = 0.54
I0802 12:02:53.408579 19007 caffe.cpp:313] Batch 388, accuracy/top5 = 0.8
I0802 12:02:53.408583 19007 caffe.cpp:313] Batch 388, loss = 1.65163
I0802 12:02:53.456776 19007 caffe.cpp:313] Batch 389, accuracy/top1 = 0.54
I0802 12:02:53.456800 19007 caffe.cpp:313] Batch 389, accuracy/top5 = 0.74
I0802 12:02:53.456805 19007 caffe.cpp:313] Batch 389, loss = 2.33192
I0802 12:02:53.505504 19007 caffe.cpp:313] Batch 390, accuracy/top1 = 0.66
I0802 12:02:53.505530 19007 caffe.cpp:313] Batch 390, accuracy/top5 = 0.9
I0802 12:02:53.505534 19007 caffe.cpp:313] Batch 390, loss = 1.48736
I0802 12:02:53.555107 19007 caffe.cpp:313] Batch 391, accuracy/top1 = 0.58
I0802 12:02:53.555129 19007 caffe.cpp:313] Batch 391, accuracy/top5 = 0.8
I0802 12:02:53.555133 19007 caffe.cpp:313] Batch 391, loss = 1.8151
I0802 12:02:53.603889 19007 caffe.cpp:313] Batch 392, accuracy/top1 = 0.54
I0802 12:02:53.603915 19007 caffe.cpp:313] Batch 392, accuracy/top5 = 0.82
I0802 12:02:53.603919 19007 caffe.cpp:313] Batch 392, loss = 1.51666
I0802 12:02:53.653038 19007 caffe.cpp:313] Batch 393, accuracy/top1 = 0.54
I0802 12:02:53.653064 19007 caffe.cpp:313] Batch 393, accuracy/top5 = 0.74
I0802 12:02:53.653069 19007 caffe.cpp:313] Batch 393, loss = 2.35762
I0802 12:02:53.701782 19007 caffe.cpp:313] Batch 394, accuracy/top1 = 0.58
I0802 12:02:53.701807 19007 caffe.cpp:313] Batch 394, accuracy/top5 = 0.84
I0802 12:02:53.701810 19007 caffe.cpp:313] Batch 394, loss = 1.52745
I0802 12:02:53.750579 19007 caffe.cpp:313] Batch 395, accuracy/top1 = 0.76
I0802 12:02:53.750605 19007 caffe.cpp:313] Batch 395, accuracy/top5 = 0.88
I0802 12:02:53.750610 19007 caffe.cpp:313] Batch 395, loss = 1.15449
I0802 12:02:53.799252 19007 caffe.cpp:313] Batch 396, accuracy/top1 = 0.56
I0802 12:02:53.799275 19007 caffe.cpp:313] Batch 396, accuracy/top5 = 0.72
I0802 12:02:53.799279 19007 caffe.cpp:313] Batch 396, loss = 2.09869
I0802 12:02:53.849316 19007 caffe.cpp:313] Batch 397, accuracy/top1 = 0.52
I0802 12:02:53.849342 19007 caffe.cpp:313] Batch 397, accuracy/top5 = 0.74
I0802 12:02:53.849346 19007 caffe.cpp:313] Batch 397, loss = 2.32758
I0802 12:02:53.896936 19007 caffe.cpp:313] Batch 398, accuracy/top1 = 0.62
I0802 12:02:53.896960 19007 caffe.cpp:313] Batch 398, accuracy/top5 = 0.84
I0802 12:02:53.896965 19007 caffe.cpp:313] Batch 398, loss = 1.85355
I0802 12:02:53.944432 19007 caffe.cpp:313] Batch 399, accuracy/top1 = 0.58
I0802 12:02:53.944458 19007 caffe.cpp:313] Batch 399, accuracy/top5 = 0.78
I0802 12:02:53.944461 19007 caffe.cpp:313] Batch 399, loss = 1.66908
I0802 12:02:53.993971 19007 caffe.cpp:313] Batch 400, accuracy/top1 = 0.54
I0802 12:02:53.993995 19007 caffe.cpp:313] Batch 400, accuracy/top5 = 0.7
I0802 12:02:53.994000 19007 caffe.cpp:313] Batch 400, loss = 2.11508
I0802 12:02:54.042475 19007 caffe.cpp:313] Batch 401, accuracy/top1 = 0.58
I0802 12:02:54.042493 19007 caffe.cpp:313] Batch 401, accuracy/top5 = 0.8
I0802 12:02:54.042497 19007 caffe.cpp:313] Batch 401, loss = 1.66493
I0802 12:02:54.091012 19007 caffe.cpp:313] Batch 402, accuracy/top1 = 0.64
I0802 12:02:54.091027 19007 caffe.cpp:313] Batch 402, accuracy/top5 = 0.74
I0802 12:02:54.091032 19007 caffe.cpp:313] Batch 402, loss = 2.10582
I0802 12:02:54.140480 19007 caffe.cpp:313] Batch 403, accuracy/top1 = 0.56
I0802 12:02:54.140501 19007 caffe.cpp:313] Batch 403, accuracy/top5 = 0.8
I0802 12:02:54.140504 19007 caffe.cpp:313] Batch 403, loss = 1.87339
I0802 12:02:54.189960 19007 caffe.cpp:313] Batch 404, accuracy/top1 = 0.66
I0802 12:02:54.189985 19007 caffe.cpp:313] Batch 404, accuracy/top5 = 0.88
I0802 12:02:54.189990 19007 caffe.cpp:313] Batch 404, loss = 1.5537
I0802 12:02:54.238569 19007 caffe.cpp:313] Batch 405, accuracy/top1 = 0.64
I0802 12:02:54.238595 19007 caffe.cpp:313] Batch 405, accuracy/top5 = 0.84
I0802 12:02:54.238598 19007 caffe.cpp:313] Batch 405, loss = 1.56253
I0802 12:02:54.286806 19007 caffe.cpp:313] Batch 406, accuracy/top1 = 0.62
I0802 12:02:54.286831 19007 caffe.cpp:313] Batch 406, accuracy/top5 = 0.9
I0802 12:02:54.286836 19007 caffe.cpp:313] Batch 406, loss = 1.42857
I0802 12:02:54.335438 19007 caffe.cpp:313] Batch 407, accuracy/top1 = 0.66
I0802 12:02:54.335464 19007 caffe.cpp:313] Batch 407, accuracy/top5 = 0.88
I0802 12:02:54.335467 19007 caffe.cpp:313] Batch 407, loss = 1.40202
I0802 12:02:54.383368 19007 caffe.cpp:313] Batch 408, accuracy/top1 = 0.44
I0802 12:02:54.383394 19007 caffe.cpp:313] Batch 408, accuracy/top5 = 0.78
I0802 12:02:54.383397 19007 caffe.cpp:313] Batch 408, loss = 2.3988
I0802 12:02:54.431970 19007 caffe.cpp:313] Batch 409, accuracy/top1 = 0.54
I0802 12:02:54.431995 19007 caffe.cpp:313] Batch 409, accuracy/top5 = 0.8
I0802 12:02:54.431999 19007 caffe.cpp:313] Batch 409, loss = 2.09888
I0802 12:02:54.480538 19007 caffe.cpp:313] Batch 410, accuracy/top1 = 0.56
I0802 12:02:54.480564 19007 caffe.cpp:313] Batch 410, accuracy/top5 = 0.76
I0802 12:02:54.480568 19007 caffe.cpp:313] Batch 410, loss = 1.87967
I0802 12:02:54.528869 19007 caffe.cpp:313] Batch 411, accuracy/top1 = 0.66
I0802 12:02:54.528893 19007 caffe.cpp:313] Batch 411, accuracy/top5 = 0.8
I0802 12:02:54.528898 19007 caffe.cpp:313] Batch 411, loss = 1.76948
I0802 12:02:54.578091 19007 caffe.cpp:313] Batch 412, accuracy/top1 = 0.72
I0802 12:02:54.578114 19007 caffe.cpp:313] Batch 412, accuracy/top5 = 0.9
I0802 12:02:54.578119 19007 caffe.cpp:313] Batch 412, loss = 1.22005
I0802 12:02:54.627022 19007 caffe.cpp:313] Batch 413, accuracy/top1 = 0.64
I0802 12:02:54.627048 19007 caffe.cpp:313] Batch 413, accuracy/top5 = 0.88
I0802 12:02:54.627051 19007 caffe.cpp:313] Batch 413, loss = 1.64983
I0802 12:02:54.676396 19007 caffe.cpp:313] Batch 414, accuracy/top1 = 0.54
I0802 12:02:54.676421 19007 caffe.cpp:313] Batch 414, accuracy/top5 = 0.84
I0802 12:02:54.676425 19007 caffe.cpp:313] Batch 414, loss = 1.81816
I0802 12:02:54.724939 19007 caffe.cpp:313] Batch 415, accuracy/top1 = 0.6
I0802 12:02:54.724963 19007 caffe.cpp:313] Batch 415, accuracy/top5 = 0.88
I0802 12:02:54.724967 19007 caffe.cpp:313] Batch 415, loss = 1.68627
I0802 12:02:54.773108 19007 caffe.cpp:313] Batch 416, accuracy/top1 = 0.5
I0802 12:02:54.773133 19007 caffe.cpp:313] Batch 416, accuracy/top5 = 0.84
I0802 12:02:54.773138 19007 caffe.cpp:313] Batch 416, loss = 1.88575
I0802 12:02:54.822032 19007 caffe.cpp:313] Batch 417, accuracy/top1 = 0.54
I0802 12:02:54.822058 19007 caffe.cpp:313] Batch 417, accuracy/top5 = 0.82
I0802 12:02:54.822062 19007 caffe.cpp:313] Batch 417, loss = 1.90519
I0802 12:02:54.871456 19007 caffe.cpp:313] Batch 418, accuracy/top1 = 0.54
I0802 12:02:54.871482 19007 caffe.cpp:313] Batch 418, accuracy/top5 = 0.88
I0802 12:02:54.871486 19007 caffe.cpp:313] Batch 418, loss = 1.31849
I0802 12:02:54.920709 19007 caffe.cpp:313] Batch 419, accuracy/top1 = 0.58
I0802 12:02:54.920735 19007 caffe.cpp:313] Batch 419, accuracy/top5 = 0.8
I0802 12:02:54.920740 19007 caffe.cpp:313] Batch 419, loss = 1.99784
I0802 12:02:54.969764 19007 caffe.cpp:313] Batch 420, accuracy/top1 = 0.56
I0802 12:02:54.969790 19007 caffe.cpp:313] Batch 420, accuracy/top5 = 0.8
I0802 12:02:54.969794 19007 caffe.cpp:313] Batch 420, loss = 1.7797
I0802 12:02:55.018121 19007 caffe.cpp:313] Batch 421, accuracy/top1 = 0.64
I0802 12:02:55.018148 19007 caffe.cpp:313] Batch 421, accuracy/top5 = 0.82
I0802 12:02:55.018152 19007 caffe.cpp:313] Batch 421, loss = 1.46583
I0802 12:02:55.066714 19007 caffe.cpp:313] Batch 422, accuracy/top1 = 0.62
I0802 12:02:55.066732 19007 caffe.cpp:313] Batch 422, accuracy/top5 = 0.78
I0802 12:02:55.066737 19007 caffe.cpp:313] Batch 422, loss = 1.6885
I0802 12:02:55.115973 19007 caffe.cpp:313] Batch 423, accuracy/top1 = 0.52
I0802 12:02:55.116000 19007 caffe.cpp:313] Batch 423, accuracy/top5 = 0.76
I0802 12:02:55.116025 19007 caffe.cpp:313] Batch 423, loss = 2.13298
I0802 12:02:55.164597 19007 caffe.cpp:313] Batch 424, accuracy/top1 = 0.68
I0802 12:02:55.164623 19007 caffe.cpp:313] Batch 424, accuracy/top5 = 0.88
I0802 12:02:55.164628 19007 caffe.cpp:313] Batch 424, loss = 1.23479
I0802 12:02:55.213361 19007 caffe.cpp:313] Batch 425, accuracy/top1 = 0.6
I0802 12:02:55.213387 19007 caffe.cpp:313] Batch 425, accuracy/top5 = 0.78
I0802 12:02:55.213392 19007 caffe.cpp:313] Batch 425, loss = 1.83005
I0802 12:02:55.263044 19007 caffe.cpp:313] Batch 426, accuracy/top1 = 0.5
I0802 12:02:55.263070 19007 caffe.cpp:313] Batch 426, accuracy/top5 = 0.82
I0802 12:02:55.263074 19007 caffe.cpp:313] Batch 426, loss = 1.7698
I0802 12:02:55.310995 19007 caffe.cpp:313] Batch 427, accuracy/top1 = 0.58
I0802 12:02:55.311022 19007 caffe.cpp:313] Batch 427, accuracy/top5 = 0.82
I0802 12:02:55.311025 19007 caffe.cpp:313] Batch 427, loss = 2.08235
I0802 12:02:55.359354 19007 caffe.cpp:313] Batch 428, accuracy/top1 = 0.72
I0802 12:02:55.359380 19007 caffe.cpp:313] Batch 428, accuracy/top5 = 0.84
I0802 12:02:55.359385 19007 caffe.cpp:313] Batch 428, loss = 1.32823
I0802 12:02:55.407335 19007 caffe.cpp:313] Batch 429, accuracy/top1 = 0.6
I0802 12:02:55.407358 19007 caffe.cpp:313] Batch 429, accuracy/top5 = 0.86
I0802 12:02:55.407363 19007 caffe.cpp:313] Batch 429, loss = 1.29466
I0802 12:02:55.456395 19007 caffe.cpp:313] Batch 430, accuracy/top1 = 0.52
I0802 12:02:55.456416 19007 caffe.cpp:313] Batch 430, accuracy/top5 = 0.9
I0802 12:02:55.456420 19007 caffe.cpp:313] Batch 430, loss = 1.53437
I0802 12:02:55.505389 19007 caffe.cpp:313] Batch 431, accuracy/top1 = 0.7
I0802 12:02:55.505409 19007 caffe.cpp:313] Batch 431, accuracy/top5 = 0.86
I0802 12:02:55.505414 19007 caffe.cpp:313] Batch 431, loss = 1.79506
I0802 12:02:55.554594 19007 caffe.cpp:313] Batch 432, accuracy/top1 = 0.58
I0802 12:02:55.554618 19007 caffe.cpp:313] Batch 432, accuracy/top5 = 0.82
I0802 12:02:55.554621 19007 caffe.cpp:313] Batch 432, loss = 2.05552
I0802 12:02:55.603832 19007 caffe.cpp:313] Batch 433, accuracy/top1 = 0.68
I0802 12:02:55.603854 19007 caffe.cpp:313] Batch 433, accuracy/top5 = 0.9
I0802 12:02:55.603858 19007 caffe.cpp:313] Batch 433, loss = 1.34393
I0802 12:02:55.652819 19007 caffe.cpp:313] Batch 434, accuracy/top1 = 0.56
I0802 12:02:55.652843 19007 caffe.cpp:313] Batch 434, accuracy/top5 = 0.78
I0802 12:02:55.652846 19007 caffe.cpp:313] Batch 434, loss = 2.13607
I0802 12:02:55.701756 19007 caffe.cpp:313] Batch 435, accuracy/top1 = 0.64
I0802 12:02:55.701781 19007 caffe.cpp:313] Batch 435, accuracy/top5 = 0.86
I0802 12:02:55.701783 19007 caffe.cpp:313] Batch 435, loss = 1.52152
I0802 12:02:55.750587 19007 caffe.cpp:313] Batch 436, accuracy/top1 = 0.46
I0802 12:02:55.750612 19007 caffe.cpp:313] Batch 436, accuracy/top5 = 0.78
I0802 12:02:55.750615 19007 caffe.cpp:313] Batch 436, loss = 2.21965
I0802 12:02:55.799326 19007 caffe.cpp:313] Batch 437, accuracy/top1 = 0.6
I0802 12:02:55.799351 19007 caffe.cpp:313] Batch 437, accuracy/top5 = 0.8
I0802 12:02:55.799355 19007 caffe.cpp:313] Batch 437, loss = 1.71079
I0802 12:02:55.849416 19007 caffe.cpp:313] Batch 438, accuracy/top1 = 0.66
I0802 12:02:55.849442 19007 caffe.cpp:313] Batch 438, accuracy/top5 = 0.8
I0802 12:02:55.849444 19007 caffe.cpp:313] Batch 438, loss = 1.7438
I0802 12:02:55.897930 19007 caffe.cpp:313] Batch 439, accuracy/top1 = 0.66
I0802 12:02:55.897954 19007 caffe.cpp:313] Batch 439, accuracy/top5 = 0.86
I0802 12:02:55.897958 19007 caffe.cpp:313] Batch 439, loss = 2.12006
I0802 12:02:55.946400 19007 caffe.cpp:313] Batch 440, accuracy/top1 = 0.6
I0802 12:02:55.946424 19007 caffe.cpp:313] Batch 440, accuracy/top5 = 0.76
I0802 12:02:55.946429 19007 caffe.cpp:313] Batch 440, loss = 1.77046
I0802 12:02:55.994218 19007 caffe.cpp:313] Batch 441, accuracy/top1 = 0.52
I0802 12:02:55.994243 19007 caffe.cpp:313] Batch 441, accuracy/top5 = 0.88
I0802 12:02:55.994246 19007 caffe.cpp:313] Batch 441, loss = 1.72956
I0802 12:02:56.044653 19007 caffe.cpp:313] Batch 442, accuracy/top1 = 0.6
I0802 12:02:56.044694 19007 caffe.cpp:313] Batch 442, accuracy/top5 = 0.82
I0802 12:02:56.044698 19007 caffe.cpp:313] Batch 442, loss = 1.68545
I0802 12:02:56.093662 19007 caffe.cpp:313] Batch 443, accuracy/top1 = 0.7
I0802 12:02:56.093675 19007 caffe.cpp:313] Batch 443, accuracy/top5 = 0.84
I0802 12:02:56.093678 19007 caffe.cpp:313] Batch 443, loss = 1.51347
I0802 12:02:56.142961 19007 caffe.cpp:313] Batch 444, accuracy/top1 = 0.68
I0802 12:02:56.142987 19007 caffe.cpp:313] Batch 444, accuracy/top5 = 0.82
I0802 12:02:56.142989 19007 caffe.cpp:313] Batch 444, loss = 1.26407
I0802 12:02:56.192816 19007 caffe.cpp:313] Batch 445, accuracy/top1 = 0.7
I0802 12:02:56.192842 19007 caffe.cpp:313] Batch 445, accuracy/top5 = 0.88
I0802 12:02:56.192847 19007 caffe.cpp:313] Batch 445, loss = 1.31432
I0802 12:02:56.243042 19007 caffe.cpp:313] Batch 446, accuracy/top1 = 0.58
I0802 12:02:56.243067 19007 caffe.cpp:313] Batch 446, accuracy/top5 = 0.88
I0802 12:02:56.243069 19007 caffe.cpp:313] Batch 446, loss = 1.39282
I0802 12:02:56.292186 19007 caffe.cpp:313] Batch 447, accuracy/top1 = 0.6
I0802 12:02:56.292210 19007 caffe.cpp:313] Batch 447, accuracy/top5 = 0.78
I0802 12:02:56.292213 19007 caffe.cpp:313] Batch 447, loss = 1.63914
I0802 12:02:56.342346 19007 caffe.cpp:313] Batch 448, accuracy/top1 = 0.7
I0802 12:02:56.342371 19007 caffe.cpp:313] Batch 448, accuracy/top5 = 0.84
I0802 12:02:56.342375 19007 caffe.cpp:313] Batch 448, loss = 1.29677
I0802 12:02:56.391742 19007 caffe.cpp:313] Batch 449, accuracy/top1 = 0.6
I0802 12:02:56.391767 19007 caffe.cpp:313] Batch 449, accuracy/top5 = 0.8
I0802 12:02:56.391770 19007 caffe.cpp:313] Batch 449, loss = 2.12126
I0802 12:02:56.441203 19007 caffe.cpp:313] Batch 450, accuracy/top1 = 0.58
I0802 12:02:56.441228 19007 caffe.cpp:313] Batch 450, accuracy/top5 = 0.8
I0802 12:02:56.441231 19007 caffe.cpp:313] Batch 450, loss = 1.93721
I0802 12:02:56.489626 19007 caffe.cpp:313] Batch 451, accuracy/top1 = 0.62
I0802 12:02:56.489651 19007 caffe.cpp:313] Batch 451, accuracy/top5 = 0.78
I0802 12:02:56.489655 19007 caffe.cpp:313] Batch 451, loss = 1.75536
I0802 12:02:56.539252 19007 caffe.cpp:313] Batch 452, accuracy/top1 = 0.62
I0802 12:02:56.539276 19007 caffe.cpp:313] Batch 452, accuracy/top5 = 0.86
I0802 12:02:56.539279 19007 caffe.cpp:313] Batch 452, loss = 1.35373
I0802 12:02:56.588687 19007 caffe.cpp:313] Batch 453, accuracy/top1 = 0.54
I0802 12:02:56.588709 19007 caffe.cpp:313] Batch 453, accuracy/top5 = 0.82
I0802 12:02:56.588713 19007 caffe.cpp:313] Batch 453, loss = 1.91954
I0802 12:02:56.639469 19007 caffe.cpp:313] Batch 454, accuracy/top1 = 0.52
I0802 12:02:56.639493 19007 caffe.cpp:313] Batch 454, accuracy/top5 = 0.76
I0802 12:02:56.639497 19007 caffe.cpp:313] Batch 454, loss = 2.1304
I0802 12:02:56.689031 19007 caffe.cpp:313] Batch 455, accuracy/top1 = 0.7
I0802 12:02:56.689054 19007 caffe.cpp:313] Batch 455, accuracy/top5 = 0.88
I0802 12:02:56.689057 19007 caffe.cpp:313] Batch 455, loss = 1.38161
I0802 12:02:56.737987 19007 caffe.cpp:313] Batch 456, accuracy/top1 = 0.56
I0802 12:02:56.738011 19007 caffe.cpp:313] Batch 456, accuracy/top5 = 0.84
I0802 12:02:56.738015 19007 caffe.cpp:313] Batch 456, loss = 2.10023
I0802 12:02:56.787106 19007 caffe.cpp:313] Batch 457, accuracy/top1 = 0.58
I0802 12:02:56.787130 19007 caffe.cpp:313] Batch 457, accuracy/top5 = 0.78
I0802 12:02:56.787133 19007 caffe.cpp:313] Batch 457, loss = 2.04515
I0802 12:02:56.836066 19007 caffe.cpp:313] Batch 458, accuracy/top1 = 0.48
I0802 12:02:56.836091 19007 caffe.cpp:313] Batch 458, accuracy/top5 = 0.74
I0802 12:02:56.836093 19007 caffe.cpp:313] Batch 458, loss = 2.44298
I0802 12:02:56.885089 19007 caffe.cpp:313] Batch 459, accuracy/top1 = 0.82
I0802 12:02:56.885116 19007 caffe.cpp:313] Batch 459, accuracy/top5 = 0.96
I0802 12:02:56.885119 19007 caffe.cpp:313] Batch 459, loss = 0.81645
I0802 12:02:56.933425 19007 caffe.cpp:313] Batch 460, accuracy/top1 = 0.54
I0802 12:02:56.933449 19007 caffe.cpp:313] Batch 460, accuracy/top5 = 0.8
I0802 12:02:56.933454 19007 caffe.cpp:313] Batch 460, loss = 1.67975
I0802 12:02:56.982064 19007 caffe.cpp:313] Batch 461, accuracy/top1 = 0.68
I0802 12:02:56.982105 19007 caffe.cpp:313] Batch 461, accuracy/top5 = 0.84
I0802 12:02:56.982108 19007 caffe.cpp:313] Batch 461, loss = 1.52004
I0802 12:02:57.032335 19007 caffe.cpp:313] Batch 462, accuracy/top1 = 0.7
I0802 12:02:57.032358 19007 caffe.cpp:313] Batch 462, accuracy/top5 = 0.8
I0802 12:02:57.032361 19007 caffe.cpp:313] Batch 462, loss = 1.28878
I0802 12:02:57.082492 19007 caffe.cpp:313] Batch 463, accuracy/top1 = 0.56
I0802 12:02:57.082509 19007 caffe.cpp:313] Batch 463, accuracy/top5 = 0.76
I0802 12:02:57.082511 19007 caffe.cpp:313] Batch 463, loss = 1.80364
I0802 12:02:57.132619 19007 caffe.cpp:313] Batch 464, accuracy/top1 = 0.62
I0802 12:02:57.132644 19007 caffe.cpp:313] Batch 464, accuracy/top5 = 0.8
I0802 12:02:57.132647 19007 caffe.cpp:313] Batch 464, loss = 1.9586
I0802 12:02:57.181902 19007 caffe.cpp:313] Batch 465, accuracy/top1 = 0.54
I0802 12:02:57.181928 19007 caffe.cpp:313] Batch 465, accuracy/top5 = 0.86
I0802 12:02:57.181931 19007 caffe.cpp:313] Batch 465, loss = 1.62386
I0802 12:02:57.231261 19007 caffe.cpp:313] Batch 466, accuracy/top1 = 0.68
I0802 12:02:57.231284 19007 caffe.cpp:313] Batch 466, accuracy/top5 = 0.84
I0802 12:02:57.231288 19007 caffe.cpp:313] Batch 466, loss = 1.75204
I0802 12:02:57.279279 19007 caffe.cpp:313] Batch 467, accuracy/top1 = 0.54
I0802 12:02:57.279304 19007 caffe.cpp:313] Batch 467, accuracy/top5 = 0.88
I0802 12:02:57.279309 19007 caffe.cpp:313] Batch 467, loss = 1.4815
I0802 12:02:57.328999 19007 caffe.cpp:313] Batch 468, accuracy/top1 = 0.58
I0802 12:02:57.329025 19007 caffe.cpp:313] Batch 468, accuracy/top5 = 0.8
I0802 12:02:57.329028 19007 caffe.cpp:313] Batch 468, loss = 1.77904
I0802 12:02:57.378456 19007 caffe.cpp:313] Batch 469, accuracy/top1 = 0.54
I0802 12:02:57.378482 19007 caffe.cpp:313] Batch 469, accuracy/top5 = 0.84
I0802 12:02:57.378485 19007 caffe.cpp:313] Batch 469, loss = 1.75219
I0802 12:02:57.427781 19007 caffe.cpp:313] Batch 470, accuracy/top1 = 0.58
I0802 12:02:57.427806 19007 caffe.cpp:313] Batch 470, accuracy/top5 = 0.82
I0802 12:02:57.427809 19007 caffe.cpp:313] Batch 470, loss = 1.78891
I0802 12:02:57.476953 19007 caffe.cpp:313] Batch 471, accuracy/top1 = 0.62
I0802 12:02:57.476977 19007 caffe.cpp:313] Batch 471, accuracy/top5 = 0.82
I0802 12:02:57.476980 19007 caffe.cpp:313] Batch 471, loss = 1.40096
I0802 12:02:57.526077 19007 caffe.cpp:313] Batch 472, accuracy/top1 = 0.66
I0802 12:02:57.526100 19007 caffe.cpp:313] Batch 472, accuracy/top5 = 0.88
I0802 12:02:57.526103 19007 caffe.cpp:313] Batch 472, loss = 1.26698
I0802 12:02:57.576295 19007 caffe.cpp:313] Batch 473, accuracy/top1 = 0.54
I0802 12:02:57.576316 19007 caffe.cpp:313] Batch 473, accuracy/top5 = 0.8
I0802 12:02:57.576319 19007 caffe.cpp:313] Batch 473, loss = 1.8716
I0802 12:02:57.626000 19007 caffe.cpp:313] Batch 474, accuracy/top1 = 0.66
I0802 12:02:57.626022 19007 caffe.cpp:313] Batch 474, accuracy/top5 = 0.84
I0802 12:02:57.626025 19007 caffe.cpp:313] Batch 474, loss = 1.4451
I0802 12:02:57.675415 19007 caffe.cpp:313] Batch 475, accuracy/top1 = 0.6
I0802 12:02:57.675436 19007 caffe.cpp:313] Batch 475, accuracy/top5 = 0.88
I0802 12:02:57.675439 19007 caffe.cpp:313] Batch 475, loss = 1.52479
I0802 12:02:57.724400 19007 caffe.cpp:313] Batch 476, accuracy/top1 = 0.56
I0802 12:02:57.724423 19007 caffe.cpp:313] Batch 476, accuracy/top5 = 0.82
I0802 12:02:57.724427 19007 caffe.cpp:313] Batch 476, loss = 1.78289
I0802 12:02:57.771854 19007 caffe.cpp:313] Batch 477, accuracy/top1 = 0.56
I0802 12:02:57.771879 19007 caffe.cpp:313] Batch 477, accuracy/top5 = 0.82
I0802 12:02:57.771883 19007 caffe.cpp:313] Batch 477, loss = 1.6204
I0802 12:02:57.821813 19007 caffe.cpp:313] Batch 478, accuracy/top1 = 0.54
I0802 12:02:57.821837 19007 caffe.cpp:313] Batch 478, accuracy/top5 = 0.78
I0802 12:02:57.821841 19007 caffe.cpp:313] Batch 478, loss = 2.00037
I0802 12:02:57.870934 19007 caffe.cpp:313] Batch 479, accuracy/top1 = 0.56
I0802 12:02:57.870960 19007 caffe.cpp:313] Batch 479, accuracy/top5 = 0.72
I0802 12:02:57.870964 19007 caffe.cpp:313] Batch 479, loss = 2.04112
I0802 12:02:57.919872 19007 caffe.cpp:313] Batch 480, accuracy/top1 = 0.62
I0802 12:02:57.919894 19007 caffe.cpp:313] Batch 480, accuracy/top5 = 0.78
I0802 12:02:57.919898 19007 caffe.cpp:313] Batch 480, loss = 1.65334
I0802 12:02:57.968928 19007 caffe.cpp:313] Batch 481, accuracy/top1 = 0.52
I0802 12:02:57.968953 19007 caffe.cpp:313] Batch 481, accuracy/top5 = 0.86
I0802 12:02:57.968956 19007 caffe.cpp:313] Batch 481, loss = 1.8539
I0802 12:02:58.017252 19007 caffe.cpp:313] Batch 482, accuracy/top1 = 0.6
I0802 12:02:58.017276 19007 caffe.cpp:313] Batch 482, accuracy/top5 = 0.74
I0802 12:02:58.017278 19007 caffe.cpp:313] Batch 482, loss = 1.9579
I0802 12:02:58.066269 19007 caffe.cpp:313] Batch 483, accuracy/top1 = 0.64
I0802 12:02:58.066288 19007 caffe.cpp:313] Batch 483, accuracy/top5 = 0.8
I0802 12:02:58.066292 19007 caffe.cpp:313] Batch 483, loss = 1.57919
I0802 12:02:58.115423 19007 caffe.cpp:313] Batch 484, accuracy/top1 = 0.58
I0802 12:02:58.115448 19007 caffe.cpp:313] Batch 484, accuracy/top5 = 0.8
I0802 12:02:58.115452 19007 caffe.cpp:313] Batch 484, loss = 1.9196
I0802 12:02:58.165370 19007 caffe.cpp:313] Batch 485, accuracy/top1 = 0.66
I0802 12:02:58.165395 19007 caffe.cpp:313] Batch 485, accuracy/top5 = 0.78
I0802 12:02:58.165398 19007 caffe.cpp:313] Batch 485, loss = 1.62467
I0802 12:02:58.214645 19007 caffe.cpp:313] Batch 486, accuracy/top1 = 0.72
I0802 12:02:58.214665 19007 caffe.cpp:313] Batch 486, accuracy/top5 = 0.96
I0802 12:02:58.214668 19007 caffe.cpp:313] Batch 486, loss = 0.858501
I0802 12:02:58.262506 19007 caffe.cpp:313] Batch 487, accuracy/top1 = 0.56
I0802 12:02:58.262531 19007 caffe.cpp:313] Batch 487, accuracy/top5 = 0.78
I0802 12:02:58.262534 19007 caffe.cpp:313] Batch 487, loss = 2.01826
I0802 12:02:58.311211 19007 caffe.cpp:313] Batch 488, accuracy/top1 = 0.68
I0802 12:02:58.311235 19007 caffe.cpp:313] Batch 488, accuracy/top5 = 0.84
I0802 12:02:58.311239 19007 caffe.cpp:313] Batch 488, loss = 1.58892
I0802 12:02:58.359696 19007 caffe.cpp:313] Batch 489, accuracy/top1 = 0.7
I0802 12:02:58.359721 19007 caffe.cpp:313] Batch 489, accuracy/top5 = 0.84
I0802 12:02:58.359724 19007 caffe.cpp:313] Batch 489, loss = 1.3484
I0802 12:02:58.409643 19007 caffe.cpp:313] Batch 490, accuracy/top1 = 0.54
I0802 12:02:58.409667 19007 caffe.cpp:313] Batch 490, accuracy/top5 = 0.78
I0802 12:02:58.409670 19007 caffe.cpp:313] Batch 490, loss = 1.72702
I0802 12:02:58.459002 19007 caffe.cpp:313] Batch 491, accuracy/top1 = 0.62
I0802 12:02:58.459028 19007 caffe.cpp:313] Batch 491, accuracy/top5 = 0.84
I0802 12:02:58.459030 19007 caffe.cpp:313] Batch 491, loss = 1.64778
I0802 12:02:58.507616 19007 caffe.cpp:313] Batch 492, accuracy/top1 = 0.58
I0802 12:02:58.507640 19007 caffe.cpp:313] Batch 492, accuracy/top5 = 0.86
I0802 12:02:58.507643 19007 caffe.cpp:313] Batch 492, loss = 1.89323
I0802 12:02:58.557178 19007 caffe.cpp:313] Batch 493, accuracy/top1 = 0.64
I0802 12:02:58.557200 19007 caffe.cpp:313] Batch 493, accuracy/top5 = 0.82
I0802 12:02:58.557204 19007 caffe.cpp:313] Batch 493, loss = 1.69139
I0802 12:02:58.607306 19007 caffe.cpp:313] Batch 494, accuracy/top1 = 0.56
I0802 12:02:58.607331 19007 caffe.cpp:313] Batch 494, accuracy/top5 = 0.78
I0802 12:02:58.607333 19007 caffe.cpp:313] Batch 494, loss = 2.06061
I0802 12:02:58.656507 19007 caffe.cpp:313] Batch 495, accuracy/top1 = 0.66
I0802 12:02:58.656533 19007 caffe.cpp:313] Batch 495, accuracy/top5 = 0.9
I0802 12:02:58.656535 19007 caffe.cpp:313] Batch 495, loss = 1.38868
I0802 12:02:58.704676 19007 caffe.cpp:313] Batch 496, accuracy/top1 = 0.66
I0802 12:02:58.704700 19007 caffe.cpp:313] Batch 496, accuracy/top5 = 0.86
I0802 12:02:58.704704 19007 caffe.cpp:313] Batch 496, loss = 1.55538
I0802 12:02:58.752799 19007 caffe.cpp:313] Batch 497, accuracy/top1 = 0.54
I0802 12:02:58.752827 19007 caffe.cpp:313] Batch 497, accuracy/top5 = 0.72
I0802 12:02:58.752830 19007 caffe.cpp:313] Batch 497, loss = 2.15635
I0802 12:02:58.801378 19007 caffe.cpp:313] Batch 498, accuracy/top1 = 0.66
I0802 12:02:58.801401 19007 caffe.cpp:313] Batch 498, accuracy/top5 = 0.92
I0802 12:02:58.801422 19007 caffe.cpp:313] Batch 498, loss = 1.22811
I0802 12:02:58.850172 19007 caffe.cpp:313] Batch 499, accuracy/top1 = 0.56
I0802 12:02:58.850198 19007 caffe.cpp:313] Batch 499, accuracy/top5 = 0.82
I0802 12:02:58.850200 19007 caffe.cpp:313] Batch 499, loss = 1.77486
I0802 12:02:58.898037 19007 caffe.cpp:313] Batch 500, accuracy/top1 = 0.64
I0802 12:02:58.898062 19007 caffe.cpp:313] Batch 500, accuracy/top5 = 0.84
I0802 12:02:58.898066 19007 caffe.cpp:313] Batch 500, loss = 1.96773
I0802 12:02:58.947331 19007 caffe.cpp:313] Batch 501, accuracy/top1 = 0.64
I0802 12:02:58.947355 19007 caffe.cpp:313] Batch 501, accuracy/top5 = 0.82
I0802 12:02:58.947357 19007 caffe.cpp:313] Batch 501, loss = 1.61117
I0802 12:02:58.995719 19007 caffe.cpp:313] Batch 502, accuracy/top1 = 0.48
I0802 12:02:58.995744 19007 caffe.cpp:313] Batch 502, accuracy/top5 = 0.82
I0802 12:02:58.995748 19007 caffe.cpp:313] Batch 502, loss = 2.01513
I0802 12:02:59.044137 19007 caffe.cpp:313] Batch 503, accuracy/top1 = 0.62
I0802 12:02:59.044162 19007 caffe.cpp:313] Batch 503, accuracy/top5 = 0.86
I0802 12:02:59.044164 19007 caffe.cpp:313] Batch 503, loss = 1.53794
I0802 12:02:59.091825 19007 caffe.cpp:313] Batch 504, accuracy/top1 = 0.7
I0802 12:02:59.091840 19007 caffe.cpp:313] Batch 504, accuracy/top5 = 0.84
I0802 12:02:59.091842 19007 caffe.cpp:313] Batch 504, loss = 1.33607
I0802 12:02:59.141278 19007 caffe.cpp:313] Batch 505, accuracy/top1 = 0.6
I0802 12:02:59.141304 19007 caffe.cpp:313] Batch 505, accuracy/top5 = 0.82
I0802 12:02:59.141307 19007 caffe.cpp:313] Batch 505, loss = 1.91495
I0802 12:02:59.190119 19007 caffe.cpp:313] Batch 506, accuracy/top1 = 0.7
I0802 12:02:59.190142 19007 caffe.cpp:313] Batch 506, accuracy/top5 = 0.92
I0802 12:02:59.190146 19007 caffe.cpp:313] Batch 506, loss = 1.39886
I0802 12:02:59.239017 19007 caffe.cpp:313] Batch 507, accuracy/top1 = 0.48
I0802 12:02:59.239042 19007 caffe.cpp:313] Batch 507, accuracy/top5 = 0.72
I0802 12:02:59.239044 19007 caffe.cpp:313] Batch 507, loss = 2.3753
I0802 12:02:59.287371 19007 caffe.cpp:313] Batch 508, accuracy/top1 = 0.6
I0802 12:02:59.287396 19007 caffe.cpp:313] Batch 508, accuracy/top5 = 0.86
I0802 12:02:59.287400 19007 caffe.cpp:313] Batch 508, loss = 1.95256
I0802 12:02:59.336908 19007 caffe.cpp:313] Batch 509, accuracy/top1 = 0.6
I0802 12:02:59.336933 19007 caffe.cpp:313] Batch 509, accuracy/top5 = 0.84
I0802 12:02:59.336936 19007 caffe.cpp:313] Batch 509, loss = 1.80637
I0802 12:02:59.385882 19007 caffe.cpp:313] Batch 510, accuracy/top1 = 0.48
I0802 12:02:59.385906 19007 caffe.cpp:313] Batch 510, accuracy/top5 = 0.8
I0802 12:02:59.385910 19007 caffe.cpp:313] Batch 510, loss = 1.84897
I0802 12:02:59.433424 19007 caffe.cpp:313] Batch 511, accuracy/top1 = 0.64
I0802 12:02:59.433449 19007 caffe.cpp:313] Batch 511, accuracy/top5 = 0.86
I0802 12:02:59.433451 19007 caffe.cpp:313] Batch 511, loss = 1.59738
I0802 12:02:59.481240 19007 caffe.cpp:313] Batch 512, accuracy/top1 = 0.62
I0802 12:02:59.481256 19007 caffe.cpp:313] Batch 512, accuracy/top5 = 0.82
I0802 12:02:59.481258 19007 caffe.cpp:313] Batch 512, loss = 1.47875
I0802 12:02:59.529969 19007 caffe.cpp:313] Batch 513, accuracy/top1 = 0.58
I0802 12:02:59.529990 19007 caffe.cpp:313] Batch 513, accuracy/top5 = 0.76
I0802 12:02:59.529994 19007 caffe.cpp:313] Batch 513, loss = 2.07721
I0802 12:02:59.579797 19007 caffe.cpp:313] Batch 514, accuracy/top1 = 0.52
I0802 12:02:59.579821 19007 caffe.cpp:313] Batch 514, accuracy/top5 = 0.82
I0802 12:02:59.579824 19007 caffe.cpp:313] Batch 514, loss = 1.8828
I0802 12:02:59.628439 19007 caffe.cpp:313] Batch 515, accuracy/top1 = 0.62
I0802 12:02:59.628463 19007 caffe.cpp:313] Batch 515, accuracy/top5 = 0.82
I0802 12:02:59.628466 19007 caffe.cpp:313] Batch 515, loss = 1.68505
I0802 12:02:59.676452 19007 caffe.cpp:313] Batch 516, accuracy/top1 = 0.54
I0802 12:02:59.676478 19007 caffe.cpp:313] Batch 516, accuracy/top5 = 0.76
I0802 12:02:59.676481 19007 caffe.cpp:313] Batch 516, loss = 2.10817
I0802 12:02:59.724637 19007 caffe.cpp:313] Batch 517, accuracy/top1 = 0.64
I0802 12:02:59.724673 19007 caffe.cpp:313] Batch 517, accuracy/top5 = 0.86
I0802 12:02:59.724676 19007 caffe.cpp:313] Batch 517, loss = 1.44306
I0802 12:02:59.773793 19007 caffe.cpp:313] Batch 518, accuracy/top1 = 0.6
I0802 12:02:59.773813 19007 caffe.cpp:313] Batch 518, accuracy/top5 = 0.84
I0802 12:02:59.773816 19007 caffe.cpp:313] Batch 518, loss = 1.72918
I0802 12:02:59.821579 19007 caffe.cpp:313] Batch 519, accuracy/top1 = 0.64
I0802 12:02:59.821601 19007 caffe.cpp:313] Batch 519, accuracy/top5 = 0.84
I0802 12:02:59.821604 19007 caffe.cpp:313] Batch 519, loss = 1.59786
I0802 12:02:59.870267 19007 caffe.cpp:313] Batch 520, accuracy/top1 = 0.5
I0802 12:02:59.870291 19007 caffe.cpp:313] Batch 520, accuracy/top5 = 0.76
I0802 12:02:59.870295 19007 caffe.cpp:313] Batch 520, loss = 2.29202
I0802 12:02:59.918469 19007 caffe.cpp:313] Batch 521, accuracy/top1 = 0.6
I0802 12:02:59.918494 19007 caffe.cpp:313] Batch 521, accuracy/top5 = 0.82
I0802 12:02:59.918498 19007 caffe.cpp:313] Batch 521, loss = 1.61588
I0802 12:02:59.967650 19007 caffe.cpp:313] Batch 522, accuracy/top1 = 0.62
I0802 12:02:59.967675 19007 caffe.cpp:313] Batch 522, accuracy/top5 = 0.86
I0802 12:02:59.967679 19007 caffe.cpp:313] Batch 522, loss = 1.5559
I0802 12:03:00.016721 19007 caffe.cpp:313] Batch 523, accuracy/top1 = 0.62
I0802 12:03:00.016746 19007 caffe.cpp:313] Batch 523, accuracy/top5 = 0.86
I0802 12:03:00.016748 19007 caffe.cpp:313] Batch 523, loss = 1.44056
I0802 12:03:00.065546 19007 caffe.cpp:313] Batch 524, accuracy/top1 = 0.54
I0802 12:03:00.065564 19007 caffe.cpp:313] Batch 524, accuracy/top5 = 0.8
I0802 12:03:00.065567 19007 caffe.cpp:313] Batch 524, loss = 1.77445
I0802 12:03:00.113975 19007 caffe.cpp:313] Batch 525, accuracy/top1 = 0.66
I0802 12:03:00.114007 19007 caffe.cpp:313] Batch 525, accuracy/top5 = 0.82
I0802 12:03:00.114012 19007 caffe.cpp:313] Batch 525, loss = 1.83365
I0802 12:03:00.162519 19007 caffe.cpp:313] Batch 526, accuracy/top1 = 0.52
I0802 12:03:00.162544 19007 caffe.cpp:313] Batch 526, accuracy/top5 = 0.74
I0802 12:03:00.162547 19007 caffe.cpp:313] Batch 526, loss = 2.45505
I0802 12:03:00.211089 19007 caffe.cpp:313] Batch 527, accuracy/top1 = 0.58
I0802 12:03:00.211108 19007 caffe.cpp:313] Batch 527, accuracy/top5 = 0.8
I0802 12:03:00.211112 19007 caffe.cpp:313] Batch 527, loss = 1.66482
I0802 12:03:00.259994 19007 caffe.cpp:313] Batch 528, accuracy/top1 = 0.6
I0802 12:03:00.260018 19007 caffe.cpp:313] Batch 528, accuracy/top5 = 0.84
I0802 12:03:00.260021 19007 caffe.cpp:313] Batch 528, loss = 1.7682
I0802 12:03:00.308390 19007 caffe.cpp:313] Batch 529, accuracy/top1 = 0.52
I0802 12:03:00.308414 19007 caffe.cpp:313] Batch 529, accuracy/top5 = 0.86
I0802 12:03:00.308418 19007 caffe.cpp:313] Batch 529, loss = 1.60936
I0802 12:03:00.356539 19007 caffe.cpp:313] Batch 530, accuracy/top1 = 0.5
I0802 12:03:00.356564 19007 caffe.cpp:313] Batch 530, accuracy/top5 = 0.8
I0802 12:03:00.356567 19007 caffe.cpp:313] Batch 530, loss = 1.79417
I0802 12:03:00.406165 19007 caffe.cpp:313] Batch 531, accuracy/top1 = 0.56
I0802 12:03:00.406189 19007 caffe.cpp:313] Batch 531, accuracy/top5 = 0.82
I0802 12:03:00.406193 19007 caffe.cpp:313] Batch 531, loss = 1.58152
I0802 12:03:00.455924 19007 caffe.cpp:313] Batch 532, accuracy/top1 = 0.72
I0802 12:03:00.455948 19007 caffe.cpp:313] Batch 532, accuracy/top5 = 0.92
I0802 12:03:00.455951 19007 caffe.cpp:313] Batch 532, loss = 1.18698
I0802 12:03:00.504573 19007 caffe.cpp:313] Batch 533, accuracy/top1 = 0.5
I0802 12:03:00.504588 19007 caffe.cpp:313] Batch 533, accuracy/top5 = 0.76
I0802 12:03:00.504592 19007 caffe.cpp:313] Batch 533, loss = 2.37969
I0802 12:03:00.553455 19007 caffe.cpp:313] Batch 534, accuracy/top1 = 0.64
I0802 12:03:00.553490 19007 caffe.cpp:313] Batch 534, accuracy/top5 = 0.86
I0802 12:03:00.553493 19007 caffe.cpp:313] Batch 534, loss = 1.30105
I0802 12:03:00.601258 19007 caffe.cpp:313] Batch 535, accuracy/top1 = 0.66
I0802 12:03:00.601284 19007 caffe.cpp:313] Batch 535, accuracy/top5 = 0.84
I0802 12:03:00.601286 19007 caffe.cpp:313] Batch 535, loss = 1.70907
I0802 12:03:00.649786 19007 caffe.cpp:313] Batch 536, accuracy/top1 = 0.78
I0802 12:03:00.649827 19007 caffe.cpp:313] Batch 536, accuracy/top5 = 0.92
I0802 12:03:00.649830 19007 caffe.cpp:313] Batch 536, loss = 0.961232
I0802 12:03:00.698791 19007 caffe.cpp:313] Batch 537, accuracy/top1 = 0.66
I0802 12:03:00.698814 19007 caffe.cpp:313] Batch 537, accuracy/top5 = 0.86
I0802 12:03:00.698817 19007 caffe.cpp:313] Batch 537, loss = 1.4182
I0802 12:03:00.748474 19007 caffe.cpp:313] Batch 538, accuracy/top1 = 0.52
I0802 12:03:00.748499 19007 caffe.cpp:313] Batch 538, accuracy/top5 = 0.8
I0802 12:03:00.748502 19007 caffe.cpp:313] Batch 538, loss = 1.78414
I0802 12:03:00.797927 19007 caffe.cpp:313] Batch 539, accuracy/top1 = 0.46
I0802 12:03:00.797951 19007 caffe.cpp:313] Batch 539, accuracy/top5 = 0.74
I0802 12:03:00.797955 19007 caffe.cpp:313] Batch 539, loss = 2.02771
I0802 12:03:00.846139 19007 caffe.cpp:313] Batch 540, accuracy/top1 = 0.62
I0802 12:03:00.846163 19007 caffe.cpp:313] Batch 540, accuracy/top5 = 0.86
I0802 12:03:00.846166 19007 caffe.cpp:313] Batch 540, loss = 1.56206
I0802 12:03:00.894708 19007 caffe.cpp:313] Batch 541, accuracy/top1 = 0.6
I0802 12:03:00.894733 19007 caffe.cpp:313] Batch 541, accuracy/top5 = 0.82
I0802 12:03:00.894737 19007 caffe.cpp:313] Batch 541, loss = 1.73526
I0802 12:03:00.942993 19007 caffe.cpp:313] Batch 542, accuracy/top1 = 0.6
I0802 12:03:00.943017 19007 caffe.cpp:313] Batch 542, accuracy/top5 = 0.84
I0802 12:03:00.943020 19007 caffe.cpp:313] Batch 542, loss = 1.76439
I0802 12:03:00.991937 19007 caffe.cpp:313] Batch 543, accuracy/top1 = 0.66
I0802 12:03:00.991961 19007 caffe.cpp:313] Batch 543, accuracy/top5 = 0.82
I0802 12:03:00.991964 19007 caffe.cpp:313] Batch 543, loss = 1.59595
I0802 12:03:01.040237 19007 caffe.cpp:313] Batch 544, accuracy/top1 = 0.78
I0802 12:03:01.040256 19007 caffe.cpp:313] Batch 544, accuracy/top5 = 0.86
I0802 12:03:01.040258 19007 caffe.cpp:313] Batch 544, loss = 1.26117
I0802 12:03:01.089819 19007 caffe.cpp:313] Batch 545, accuracy/top1 = 0.54
I0802 12:03:01.089834 19007 caffe.cpp:313] Batch 545, accuracy/top5 = 0.76
I0802 12:03:01.089838 19007 caffe.cpp:313] Batch 545, loss = 1.76466
I0802 12:03:01.137940 19007 caffe.cpp:313] Batch 546, accuracy/top1 = 0.64
I0802 12:03:01.137967 19007 caffe.cpp:313] Batch 546, accuracy/top5 = 0.84
I0802 12:03:01.137970 19007 caffe.cpp:313] Batch 546, loss = 1.77732
I0802 12:03:01.187093 19007 caffe.cpp:313] Batch 547, accuracy/top1 = 0.46
I0802 12:03:01.187117 19007 caffe.cpp:313] Batch 547, accuracy/top5 = 0.74
I0802 12:03:01.187120 19007 caffe.cpp:313] Batch 547, loss = 1.93826
I0802 12:03:01.235468 19007 caffe.cpp:313] Batch 548, accuracy/top1 = 0.58
I0802 12:03:01.235493 19007 caffe.cpp:313] Batch 548, accuracy/top5 = 0.76
I0802 12:03:01.235496 19007 caffe.cpp:313] Batch 548, loss = 1.91175
I0802 12:03:01.284728 19007 caffe.cpp:313] Batch 549, accuracy/top1 = 0.56
I0802 12:03:01.284751 19007 caffe.cpp:313] Batch 549, accuracy/top5 = 0.8
I0802 12:03:01.284755 19007 caffe.cpp:313] Batch 549, loss = 2.1147
I0802 12:03:01.333173 19007 caffe.cpp:313] Batch 550, accuracy/top1 = 0.56
I0802 12:03:01.333197 19007 caffe.cpp:313] Batch 550, accuracy/top5 = 0.82
I0802 12:03:01.333200 19007 caffe.cpp:313] Batch 550, loss = 1.90822
I0802 12:03:01.382472 19007 caffe.cpp:313] Batch 551, accuracy/top1 = 0.66
I0802 12:03:01.382498 19007 caffe.cpp:313] Batch 551, accuracy/top5 = 0.84
I0802 12:03:01.382500 19007 caffe.cpp:313] Batch 551, loss = 1.45303
I0802 12:03:01.430992 19007 caffe.cpp:313] Batch 552, accuracy/top1 = 0.62
I0802 12:03:01.431017 19007 caffe.cpp:313] Batch 552, accuracy/top5 = 0.86
I0802 12:03:01.431020 19007 caffe.cpp:313] Batch 552, loss = 1.44176
I0802 12:03:01.480031 19007 caffe.cpp:313] Batch 553, accuracy/top1 = 0.58
I0802 12:03:01.480056 19007 caffe.cpp:313] Batch 553, accuracy/top5 = 0.82
I0802 12:03:01.480058 19007 caffe.cpp:313] Batch 553, loss = 1.55959
I0802 12:03:01.528486 19007 caffe.cpp:313] Batch 554, accuracy/top1 = 0.54
I0802 12:03:01.528512 19007 caffe.cpp:313] Batch 554, accuracy/top5 = 0.88
I0802 12:03:01.528515 19007 caffe.cpp:313] Batch 554, loss = 1.65312
I0802 12:03:01.578353 19007 caffe.cpp:313] Batch 555, accuracy/top1 = 0.76
I0802 12:03:01.578377 19007 caffe.cpp:313] Batch 555, accuracy/top5 = 0.94
I0802 12:03:01.578380 19007 caffe.cpp:313] Batch 555, loss = 0.935241
I0802 12:03:01.627308 19007 caffe.cpp:313] Batch 556, accuracy/top1 = 0.64
I0802 12:03:01.627334 19007 caffe.cpp:313] Batch 556, accuracy/top5 = 0.84
I0802 12:03:01.627337 19007 caffe.cpp:313] Batch 556, loss = 1.76493
I0802 12:03:01.676239 19007 caffe.cpp:313] Batch 557, accuracy/top1 = 0.56
I0802 12:03:01.676265 19007 caffe.cpp:313] Batch 557, accuracy/top5 = 0.82
I0802 12:03:01.676268 19007 caffe.cpp:313] Batch 557, loss = 1.67098
I0802 12:03:01.724661 19007 caffe.cpp:313] Batch 558, accuracy/top1 = 0.58
I0802 12:03:01.724685 19007 caffe.cpp:313] Batch 558, accuracy/top5 = 0.78
I0802 12:03:01.724689 19007 caffe.cpp:313] Batch 558, loss = 1.88623
I0802 12:03:01.773957 19007 caffe.cpp:313] Batch 559, accuracy/top1 = 0.66
I0802 12:03:01.773980 19007 caffe.cpp:313] Batch 559, accuracy/top5 = 0.8
I0802 12:03:01.773983 19007 caffe.cpp:313] Batch 559, loss = 1.54064
I0802 12:03:01.821919 19007 caffe.cpp:313] Batch 560, accuracy/top1 = 0.56
I0802 12:03:01.821943 19007 caffe.cpp:313] Batch 560, accuracy/top5 = 0.76
I0802 12:03:01.821946 19007 caffe.cpp:313] Batch 560, loss = 2.01002
I0802 12:03:01.870368 19007 caffe.cpp:313] Batch 561, accuracy/top1 = 0.64
I0802 12:03:01.870389 19007 caffe.cpp:313] Batch 561, accuracy/top5 = 0.74
I0802 12:03:01.870393 19007 caffe.cpp:313] Batch 561, loss = 2.1679
I0802 12:03:01.918748 19007 caffe.cpp:313] Batch 562, accuracy/top1 = 0.6
I0802 12:03:01.918771 19007 caffe.cpp:313] Batch 562, accuracy/top5 = 0.8
I0802 12:03:01.918774 19007 caffe.cpp:313] Batch 562, loss = 1.68896
I0802 12:03:01.967170 19007 caffe.cpp:313] Batch 563, accuracy/top1 = 0.58
I0802 12:03:01.967191 19007 caffe.cpp:313] Batch 563, accuracy/top5 = 0.8
I0802 12:03:01.967195 19007 caffe.cpp:313] Batch 563, loss = 1.78428
I0802 12:03:02.016253 19007 caffe.cpp:313] Batch 564, accuracy/top1 = 0.66
I0802 12:03:02.016280 19007 caffe.cpp:313] Batch 564, accuracy/top5 = 0.84
I0802 12:03:02.016283 19007 caffe.cpp:313] Batch 564, loss = 1.66211
I0802 12:03:02.065343 19007 caffe.cpp:313] Batch 565, accuracy/top1 = 0.54
I0802 12:03:02.065362 19007 caffe.cpp:313] Batch 565, accuracy/top5 = 0.86
I0802 12:03:02.065366 19007 caffe.cpp:313] Batch 565, loss = 1.66275
I0802 12:03:02.114089 19007 caffe.cpp:313] Batch 566, accuracy/top1 = 0.54
I0802 12:03:02.114125 19007 caffe.cpp:313] Batch 566, accuracy/top5 = 0.74
I0802 12:03:02.114130 19007 caffe.cpp:313] Batch 566, loss = 2.14474
I0802 12:03:02.162998 19007 caffe.cpp:313] Batch 567, accuracy/top1 = 0.54
I0802 12:03:02.163022 19007 caffe.cpp:313] Batch 567, accuracy/top5 = 0.86
I0802 12:03:02.163025 19007 caffe.cpp:313] Batch 567, loss = 1.92269
I0802 12:03:02.212062 19007 caffe.cpp:313] Batch 568, accuracy/top1 = 0.52
I0802 12:03:02.212085 19007 caffe.cpp:313] Batch 568, accuracy/top5 = 0.74
I0802 12:03:02.212088 19007 caffe.cpp:313] Batch 568, loss = 2.10358
I0802 12:03:02.260370 19007 caffe.cpp:313] Batch 569, accuracy/top1 = 0.42
I0802 12:03:02.260390 19007 caffe.cpp:313] Batch 569, accuracy/top5 = 0.68
I0802 12:03:02.260392 19007 caffe.cpp:313] Batch 569, loss = 2.65442
I0802 12:03:02.309197 19007 caffe.cpp:313] Batch 570, accuracy/top1 = 0.58
I0802 12:03:02.309222 19007 caffe.cpp:313] Batch 570, accuracy/top5 = 0.78
I0802 12:03:02.309226 19007 caffe.cpp:313] Batch 570, loss = 1.61825
I0802 12:03:02.357121 19007 caffe.cpp:313] Batch 571, accuracy/top1 = 0.5
I0802 12:03:02.357146 19007 caffe.cpp:313] Batch 571, accuracy/top5 = 0.74
I0802 12:03:02.357148 19007 caffe.cpp:313] Batch 571, loss = 2.21277
I0802 12:03:02.406230 19007 caffe.cpp:313] Batch 572, accuracy/top1 = 0.62
I0802 12:03:02.406255 19007 caffe.cpp:313] Batch 572, accuracy/top5 = 0.82
I0802 12:03:02.406257 19007 caffe.cpp:313] Batch 572, loss = 1.70969
I0802 12:03:02.455088 19007 caffe.cpp:313] Batch 573, accuracy/top1 = 0.64
I0802 12:03:02.455113 19007 caffe.cpp:313] Batch 573, accuracy/top5 = 0.86
I0802 12:03:02.455130 19007 caffe.cpp:313] Batch 573, loss = 1.60296
I0802 12:03:02.503914 19007 caffe.cpp:313] Batch 574, accuracy/top1 = 0.58
I0802 12:03:02.503938 19007 caffe.cpp:313] Batch 574, accuracy/top5 = 0.74
I0802 12:03:02.503942 19007 caffe.cpp:313] Batch 574, loss = 2.20218
I0802 12:03:02.552829 19007 caffe.cpp:313] Batch 575, accuracy/top1 = 0.6
I0802 12:03:02.552853 19007 caffe.cpp:313] Batch 575, accuracy/top5 = 0.8
I0802 12:03:02.552856 19007 caffe.cpp:313] Batch 575, loss = 1.92368
I0802 12:03:02.601287 19007 caffe.cpp:313] Batch 576, accuracy/top1 = 0.6
I0802 12:03:02.601312 19007 caffe.cpp:313] Batch 576, accuracy/top5 = 0.86
I0802 12:03:02.601315 19007 caffe.cpp:313] Batch 576, loss = 1.58933
I0802 12:03:02.649408 19007 caffe.cpp:313] Batch 577, accuracy/top1 = 0.58
I0802 12:03:02.649435 19007 caffe.cpp:313] Batch 577, accuracy/top5 = 0.86
I0802 12:03:02.649437 19007 caffe.cpp:313] Batch 577, loss = 1.39727
I0802 12:03:02.698489 19007 caffe.cpp:313] Batch 578, accuracy/top1 = 0.56
I0802 12:03:02.698514 19007 caffe.cpp:313] Batch 578, accuracy/top5 = 0.76
I0802 12:03:02.698518 19007 caffe.cpp:313] Batch 578, loss = 1.92123
I0802 12:03:02.746525 19007 caffe.cpp:313] Batch 579, accuracy/top1 = 0.6
I0802 12:03:02.746552 19007 caffe.cpp:313] Batch 579, accuracy/top5 = 0.76
I0802 12:03:02.746556 19007 caffe.cpp:313] Batch 579, loss = 1.90972
I0802 12:03:02.795011 19007 caffe.cpp:313] Batch 580, accuracy/top1 = 0.56
I0802 12:03:02.795035 19007 caffe.cpp:313] Batch 580, accuracy/top5 = 0.8
I0802 12:03:02.795038 19007 caffe.cpp:313] Batch 580, loss = 1.93016
I0802 12:03:02.844501 19007 caffe.cpp:313] Batch 581, accuracy/top1 = 0.58
I0802 12:03:02.844525 19007 caffe.cpp:313] Batch 581, accuracy/top5 = 0.88
I0802 12:03:02.844528 19007 caffe.cpp:313] Batch 581, loss = 1.54429
I0802 12:03:02.893194 19007 caffe.cpp:313] Batch 582, accuracy/top1 = 0.56
I0802 12:03:02.893219 19007 caffe.cpp:313] Batch 582, accuracy/top5 = 0.8
I0802 12:03:02.893223 19007 caffe.cpp:313] Batch 582, loss = 1.53792
I0802 12:03:02.941956 19007 caffe.cpp:313] Batch 583, accuracy/top1 = 0.56
I0802 12:03:02.941979 19007 caffe.cpp:313] Batch 583, accuracy/top5 = 0.86
I0802 12:03:02.941982 19007 caffe.cpp:313] Batch 583, loss = 1.83646
I0802 12:03:02.990612 19007 caffe.cpp:313] Batch 584, accuracy/top1 = 0.66
I0802 12:03:02.990635 19007 caffe.cpp:313] Batch 584, accuracy/top5 = 0.84
I0802 12:03:02.990639 19007 caffe.cpp:313] Batch 584, loss = 1.34309
I0802 12:03:03.040374 19007 caffe.cpp:313] Batch 585, accuracy/top1 = 0.66
I0802 12:03:03.040398 19007 caffe.cpp:313] Batch 585, accuracy/top5 = 0.9
I0802 12:03:03.040401 19007 caffe.cpp:313] Batch 585, loss = 1.1375
I0802 12:03:03.088551 19007 caffe.cpp:313] Batch 586, accuracy/top1 = 0.64
I0802 12:03:03.088565 19007 caffe.cpp:313] Batch 586, accuracy/top5 = 0.84
I0802 12:03:03.088568 19007 caffe.cpp:313] Batch 586, loss = 1.5787
I0802 12:03:03.136234 19007 caffe.cpp:313] Batch 587, accuracy/top1 = 0.68
I0802 12:03:03.136354 19007 caffe.cpp:313] Batch 587, accuracy/top5 = 0.9
I0802 12:03:03.136359 19007 caffe.cpp:313] Batch 587, loss = 1.11287
I0802 12:03:03.184600 19007 caffe.cpp:313] Batch 588, accuracy/top1 = 0.62
I0802 12:03:03.184625 19007 caffe.cpp:313] Batch 588, accuracy/top5 = 0.88
I0802 12:03:03.184628 19007 caffe.cpp:313] Batch 588, loss = 1.55497
I0802 12:03:03.233384 19007 caffe.cpp:313] Batch 589, accuracy/top1 = 0.64
I0802 12:03:03.233408 19007 caffe.cpp:313] Batch 589, accuracy/top5 = 0.92
I0802 12:03:03.233412 19007 caffe.cpp:313] Batch 589, loss = 1.47928
I0802 12:03:03.282814 19007 caffe.cpp:313] Batch 590, accuracy/top1 = 0.6
I0802 12:03:03.282840 19007 caffe.cpp:313] Batch 590, accuracy/top5 = 0.82
I0802 12:03:03.282842 19007 caffe.cpp:313] Batch 590, loss = 1.92741
I0802 12:03:03.331707 19007 caffe.cpp:313] Batch 591, accuracy/top1 = 0.64
I0802 12:03:03.331730 19007 caffe.cpp:313] Batch 591, accuracy/top5 = 0.84
I0802 12:03:03.331733 19007 caffe.cpp:313] Batch 591, loss = 1.44617
I0802 12:03:03.381067 19007 caffe.cpp:313] Batch 592, accuracy/top1 = 0.66
I0802 12:03:03.381091 19007 caffe.cpp:313] Batch 592, accuracy/top5 = 0.88
I0802 12:03:03.381094 19007 caffe.cpp:313] Batch 592, loss = 1.40987
I0802 12:03:03.430680 19007 caffe.cpp:313] Batch 593, accuracy/top1 = 0.56
I0802 12:03:03.430704 19007 caffe.cpp:313] Batch 593, accuracy/top5 = 0.76
I0802 12:03:03.430707 19007 caffe.cpp:313] Batch 593, loss = 1.83204
I0802 12:03:03.479215 19007 caffe.cpp:313] Batch 594, accuracy/top1 = 0.58
I0802 12:03:03.479241 19007 caffe.cpp:313] Batch 594, accuracy/top5 = 0.86
I0802 12:03:03.479244 19007 caffe.cpp:313] Batch 594, loss = 1.53224
I0802 12:03:03.527678 19007 caffe.cpp:313] Batch 595, accuracy/top1 = 0.66
I0802 12:03:03.527693 19007 caffe.cpp:313] Batch 595, accuracy/top5 = 0.86
I0802 12:03:03.527695 19007 caffe.cpp:313] Batch 595, loss = 1.41989
I0802 12:03:03.577006 19007 caffe.cpp:313] Batch 596, accuracy/top1 = 0.48
I0802 12:03:03.577031 19007 caffe.cpp:313] Batch 596, accuracy/top5 = 0.74
I0802 12:03:03.577034 19007 caffe.cpp:313] Batch 596, loss = 2.24488
I0802 12:03:03.625790 19007 caffe.cpp:313] Batch 597, accuracy/top1 = 0.64
I0802 12:03:03.625815 19007 caffe.cpp:313] Batch 597, accuracy/top5 = 0.9
I0802 12:03:03.625818 19007 caffe.cpp:313] Batch 597, loss = 1.16163
I0802 12:03:03.674664 19007 caffe.cpp:313] Batch 598, accuracy/top1 = 0.48
I0802 12:03:03.674688 19007 caffe.cpp:313] Batch 598, accuracy/top5 = 0.8
I0802 12:03:03.674691 19007 caffe.cpp:313] Batch 598, loss = 1.88416
I0802 12:03:03.723975 19007 caffe.cpp:313] Batch 599, accuracy/top1 = 0.54
I0802 12:03:03.723999 19007 caffe.cpp:313] Batch 599, accuracy/top5 = 0.82
I0802 12:03:03.724002 19007 caffe.cpp:313] Batch 599, loss = 1.73499
I0802 12:03:03.772152 19007 caffe.cpp:313] Batch 600, accuracy/top1 = 0.56
I0802 12:03:03.772177 19007 caffe.cpp:313] Batch 600, accuracy/top5 = 0.8
I0802 12:03:03.772181 19007 caffe.cpp:313] Batch 600, loss = 1.94999
I0802 12:03:03.821444 19007 caffe.cpp:313] Batch 601, accuracy/top1 = 0.54
I0802 12:03:03.821470 19007 caffe.cpp:313] Batch 601, accuracy/top5 = 0.9
I0802 12:03:03.821472 19007 caffe.cpp:313] Batch 601, loss = 1.33712
I0802 12:03:03.871053 19007 caffe.cpp:313] Batch 602, accuracy/top1 = 0.48
I0802 12:03:03.871078 19007 caffe.cpp:313] Batch 602, accuracy/top5 = 0.74
I0802 12:03:03.871081 19007 caffe.cpp:313] Batch 602, loss = 2.39278
I0802 12:03:03.920473 19007 caffe.cpp:313] Batch 603, accuracy/top1 = 0.76
I0802 12:03:03.920498 19007 caffe.cpp:313] Batch 603, accuracy/top5 = 0.84
I0802 12:03:03.920501 19007 caffe.cpp:313] Batch 603, loss = 1.17811
I0802 12:03:03.968956 19007 caffe.cpp:313] Batch 604, accuracy/top1 = 0.8
I0802 12:03:03.968976 19007 caffe.cpp:313] Batch 604, accuracy/top5 = 0.98
I0802 12:03:03.968979 19007 caffe.cpp:313] Batch 604, loss = 0.758797
I0802 12:03:04.016907 19007 caffe.cpp:313] Batch 605, accuracy/top1 = 0.56
I0802 12:03:04.016927 19007 caffe.cpp:313] Batch 605, accuracy/top5 = 0.74
I0802 12:03:04.016930 19007 caffe.cpp:313] Batch 605, loss = 2.00708
I0802 12:03:04.065706 19007 caffe.cpp:313] Batch 606, accuracy/top1 = 0.54
I0802 12:03:04.065740 19007 caffe.cpp:313] Batch 606, accuracy/top5 = 0.8
I0802 12:03:04.065743 19007 caffe.cpp:313] Batch 606, loss = 1.96231
I0802 12:03:04.114195 19007 caffe.cpp:313] Batch 607, accuracy/top1 = 0.56
I0802 12:03:04.114219 19007 caffe.cpp:313] Batch 607, accuracy/top5 = 0.84
I0802 12:03:04.114223 19007 caffe.cpp:313] Batch 607, loss = 1.70609
I0802 12:03:04.163096 19007 caffe.cpp:313] Batch 608, accuracy/top1 = 0.58
I0802 12:03:04.163121 19007 caffe.cpp:313] Batch 608, accuracy/top5 = 0.84
I0802 12:03:04.163125 19007 caffe.cpp:313] Batch 608, loss = 1.7216
I0802 12:03:04.212288 19007 caffe.cpp:313] Batch 609, accuracy/top1 = 0.6
I0802 12:03:04.212313 19007 caffe.cpp:313] Batch 609, accuracy/top5 = 0.86
I0802 12:03:04.212316 19007 caffe.cpp:313] Batch 609, loss = 1.62581
I0802 12:03:04.261174 19007 caffe.cpp:313] Batch 610, accuracy/top1 = 0.7
I0802 12:03:04.261198 19007 caffe.cpp:313] Batch 610, accuracy/top5 = 0.88
I0802 12:03:04.261203 19007 caffe.cpp:313] Batch 610, loss = 1.75464
I0802 12:03:04.310173 19007 caffe.cpp:313] Batch 611, accuracy/top1 = 0.54
I0802 12:03:04.310194 19007 caffe.cpp:313] Batch 611, accuracy/top5 = 0.8
I0802 12:03:04.310196 19007 caffe.cpp:313] Batch 611, loss = 1.7437
I0802 12:03:04.358227 19007 caffe.cpp:313] Batch 612, accuracy/top1 = 0.68
I0802 12:03:04.358252 19007 caffe.cpp:313] Batch 612, accuracy/top5 = 0.8
I0802 12:03:04.358255 19007 caffe.cpp:313] Batch 612, loss = 1.45363
I0802 12:03:04.405982 19007 caffe.cpp:313] Batch 613, accuracy/top1 = 0.52
I0802 12:03:04.406005 19007 caffe.cpp:313] Batch 613, accuracy/top5 = 0.72
I0802 12:03:04.406008 19007 caffe.cpp:313] Batch 613, loss = 2.09759
I0802 12:03:04.455760 19007 caffe.cpp:313] Batch 614, accuracy/top1 = 0.48
I0802 12:03:04.455785 19007 caffe.cpp:313] Batch 614, accuracy/top5 = 0.78
I0802 12:03:04.455788 19007 caffe.cpp:313] Batch 614, loss = 2.23958
I0802 12:03:04.505172 19007 caffe.cpp:313] Batch 615, accuracy/top1 = 0.56
I0802 12:03:04.505189 19007 caffe.cpp:313] Batch 615, accuracy/top5 = 0.82
I0802 12:03:04.505192 19007 caffe.cpp:313] Batch 615, loss = 1.80194
I0802 12:03:04.554350 19007 caffe.cpp:313] Batch 616, accuracy/top1 = 0.64
I0802 12:03:04.554373 19007 caffe.cpp:313] Batch 616, accuracy/top5 = 0.84
I0802 12:03:04.554375 19007 caffe.cpp:313] Batch 616, loss = 1.66075
I0802 12:03:04.603205 19007 caffe.cpp:313] Batch 617, accuracy/top1 = 0.58
I0802 12:03:04.603230 19007 caffe.cpp:313] Batch 617, accuracy/top5 = 0.82
I0802 12:03:04.603233 19007 caffe.cpp:313] Batch 617, loss = 1.85357
I0802 12:03:04.651087 19007 caffe.cpp:313] Batch 618, accuracy/top1 = 0.5
I0802 12:03:04.651111 19007 caffe.cpp:313] Batch 618, accuracy/top5 = 0.78
I0802 12:03:04.651114 19007 caffe.cpp:313] Batch 618, loss = 2.3964
I0802 12:03:04.699452 19007 caffe.cpp:313] Batch 619, accuracy/top1 = 0.72
I0802 12:03:04.699477 19007 caffe.cpp:313] Batch 619, accuracy/top5 = 0.82
I0802 12:03:04.699481 19007 caffe.cpp:313] Batch 619, loss = 1.20537
I0802 12:03:04.748723 19007 caffe.cpp:313] Batch 620, accuracy/top1 = 0.54
I0802 12:03:04.748747 19007 caffe.cpp:313] Batch 620, accuracy/top5 = 0.84
I0802 12:03:04.748750 19007 caffe.cpp:313] Batch 620, loss = 1.5918
I0802 12:03:04.797644 19007 caffe.cpp:313] Batch 621, accuracy/top1 = 0.66
I0802 12:03:04.797669 19007 caffe.cpp:313] Batch 621, accuracy/top5 = 0.76
I0802 12:03:04.797672 19007 caffe.cpp:313] Batch 621, loss = 1.96879
I0802 12:03:04.846098 19007 caffe.cpp:313] Batch 622, accuracy/top1 = 0.62
I0802 12:03:04.846122 19007 caffe.cpp:313] Batch 622, accuracy/top5 = 0.76
I0802 12:03:04.846127 19007 caffe.cpp:313] Batch 622, loss = 2.00086
I0802 12:03:04.894467 19007 caffe.cpp:313] Batch 623, accuracy/top1 = 0.52
I0802 12:03:04.894492 19007 caffe.cpp:313] Batch 623, accuracy/top5 = 0.82
I0802 12:03:04.894495 19007 caffe.cpp:313] Batch 623, loss = 2.0016
I0802 12:03:04.943261 19007 caffe.cpp:313] Batch 624, accuracy/top1 = 0.6
I0802 12:03:04.943286 19007 caffe.cpp:313] Batch 624, accuracy/top5 = 0.88
I0802 12:03:04.943289 19007 caffe.cpp:313] Batch 624, loss = 1.664
I0802 12:03:04.992699 19007 caffe.cpp:313] Batch 625, accuracy/top1 = 0.62
I0802 12:03:04.992723 19007 caffe.cpp:313] Batch 625, accuracy/top5 = 0.8
I0802 12:03:04.992727 19007 caffe.cpp:313] Batch 625, loss = 2.2001
I0802 12:03:05.041656 19007 caffe.cpp:313] Batch 626, accuracy/top1 = 0.38
I0802 12:03:05.041674 19007 caffe.cpp:313] Batch 626, accuracy/top5 = 0.68
I0802 12:03:05.041677 19007 caffe.cpp:313] Batch 626, loss = 2.64491
I0802 12:03:05.090581 19007 caffe.cpp:313] Batch 627, accuracy/top1 = 0.48
I0802 12:03:05.090595 19007 caffe.cpp:313] Batch 627, accuracy/top5 = 0.72
I0802 12:03:05.090598 19007 caffe.cpp:313] Batch 627, loss = 2.37123
I0802 12:03:05.139238 19007 caffe.cpp:313] Batch 628, accuracy/top1 = 0.62
I0802 12:03:05.139266 19007 caffe.cpp:313] Batch 628, accuracy/top5 = 0.88
I0802 12:03:05.139268 19007 caffe.cpp:313] Batch 628, loss = 1.6617
I0802 12:03:05.188329 19007 caffe.cpp:313] Batch 629, accuracy/top1 = 0.56
I0802 12:03:05.188354 19007 caffe.cpp:313] Batch 629, accuracy/top5 = 0.78
I0802 12:03:05.188356 19007 caffe.cpp:313] Batch 629, loss = 2.0131
I0802 12:03:05.237762 19007 caffe.cpp:313] Batch 630, accuracy/top1 = 0.56
I0802 12:03:05.237787 19007 caffe.cpp:313] Batch 630, accuracy/top5 = 0.76
I0802 12:03:05.237790 19007 caffe.cpp:313] Batch 630, loss = 2.17117
I0802 12:03:05.285779 19007 caffe.cpp:313] Batch 631, accuracy/top1 = 0.68
I0802 12:03:05.285804 19007 caffe.cpp:313] Batch 631, accuracy/top5 = 0.9
I0802 12:03:05.285806 19007 caffe.cpp:313] Batch 631, loss = 1.09543
I0802 12:03:05.335619 19007 caffe.cpp:313] Batch 632, accuracy/top1 = 0.56
I0802 12:03:05.335644 19007 caffe.cpp:313] Batch 632, accuracy/top5 = 0.84
I0802 12:03:05.335647 19007 caffe.cpp:313] Batch 632, loss = 1.5919
I0802 12:03:05.384001 19007 caffe.cpp:313] Batch 633, accuracy/top1 = 0.54
I0802 12:03:05.384024 19007 caffe.cpp:313] Batch 633, accuracy/top5 = 0.72
I0802 12:03:05.384027 19007 caffe.cpp:313] Batch 633, loss = 2.19327
I0802 12:03:05.432539 19007 caffe.cpp:313] Batch 634, accuracy/top1 = 0.58
I0802 12:03:05.432564 19007 caffe.cpp:313] Batch 634, accuracy/top5 = 0.78
I0802 12:03:05.432567 19007 caffe.cpp:313] Batch 634, loss = 2.00944
I0802 12:03:05.482017 19007 caffe.cpp:313] Batch 635, accuracy/top1 = 0.64
I0802 12:03:05.482040 19007 caffe.cpp:313] Batch 635, accuracy/top5 = 0.82
I0802 12:03:05.482043 19007 caffe.cpp:313] Batch 635, loss = 1.69001
I0802 12:03:05.530848 19007 caffe.cpp:313] Batch 636, accuracy/top1 = 0.56
I0802 12:03:05.530864 19007 caffe.cpp:313] Batch 636, accuracy/top5 = 0.78
I0802 12:03:05.530866 19007 caffe.cpp:313] Batch 636, loss = 2.13284
I0802 12:03:05.579936 19007 caffe.cpp:313] Batch 637, accuracy/top1 = 0.68
I0802 12:03:05.579957 19007 caffe.cpp:313] Batch 637, accuracy/top5 = 0.88
I0802 12:03:05.579960 19007 caffe.cpp:313] Batch 637, loss = 1.29505
I0802 12:03:05.629071 19007 caffe.cpp:313] Batch 638, accuracy/top1 = 0.6
I0802 12:03:05.629097 19007 caffe.cpp:313] Batch 638, accuracy/top5 = 0.86
I0802 12:03:05.629101 19007 caffe.cpp:313] Batch 638, loss = 1.56822
I0802 12:03:05.677736 19007 caffe.cpp:313] Batch 639, accuracy/top1 = 0.62
I0802 12:03:05.677762 19007 caffe.cpp:313] Batch 639, accuracy/top5 = 0.82
I0802 12:03:05.677764 19007 caffe.cpp:313] Batch 639, loss = 1.84549
I0802 12:03:05.726789 19007 caffe.cpp:313] Batch 640, accuracy/top1 = 0.5
I0802 12:03:05.726815 19007 caffe.cpp:313] Batch 640, accuracy/top5 = 0.84
I0802 12:03:05.726819 19007 caffe.cpp:313] Batch 640, loss = 1.78554
I0802 12:03:05.776410 19007 caffe.cpp:313] Batch 641, accuracy/top1 = 0.6
I0802 12:03:05.776435 19007 caffe.cpp:313] Batch 641, accuracy/top5 = 0.78
I0802 12:03:05.776438 19007 caffe.cpp:313] Batch 641, loss = 1.75609
I0802 12:03:05.825242 19007 caffe.cpp:313] Batch 642, accuracy/top1 = 0.58
I0802 12:03:05.825265 19007 caffe.cpp:313] Batch 642, accuracy/top5 = 0.74
I0802 12:03:05.825268 19007 caffe.cpp:313] Batch 642, loss = 1.9759
I0802 12:03:05.874760 19007 caffe.cpp:313] Batch 643, accuracy/top1 = 0.5
I0802 12:03:05.874785 19007 caffe.cpp:313] Batch 643, accuracy/top5 = 0.86
I0802 12:03:05.874804 19007 caffe.cpp:313] Batch 643, loss = 1.71064
I0802 12:03:05.922950 19007 caffe.cpp:313] Batch 644, accuracy/top1 = 0.56
I0802 12:03:05.922974 19007 caffe.cpp:313] Batch 644, accuracy/top5 = 0.76
I0802 12:03:05.922978 19007 caffe.cpp:313] Batch 644, loss = 1.93534
I0802 12:03:05.971721 19007 caffe.cpp:313] Batch 645, accuracy/top1 = 0.66
I0802 12:03:05.971746 19007 caffe.cpp:313] Batch 645, accuracy/top5 = 0.84
I0802 12:03:05.971750 19007 caffe.cpp:313] Batch 645, loss = 1.56164
I0802 12:03:06.020715 19007 caffe.cpp:313] Batch 646, accuracy/top1 = 0.62
I0802 12:03:06.020741 19007 caffe.cpp:313] Batch 646, accuracy/top5 = 0.9
I0802 12:03:06.020745 19007 caffe.cpp:313] Batch 646, loss = 1.55938
I0802 12:03:06.069092 19007 caffe.cpp:313] Batch 647, accuracy/top1 = 0.62
I0802 12:03:06.069111 19007 caffe.cpp:313] Batch 647, accuracy/top5 = 0.76
I0802 12:03:06.069114 19007 caffe.cpp:313] Batch 647, loss = 2.10771
I0802 12:03:06.118314 19007 caffe.cpp:313] Batch 648, accuracy/top1 = 0.62
I0802 12:03:06.118335 19007 caffe.cpp:313] Batch 648, accuracy/top5 = 0.84
I0802 12:03:06.118338 19007 caffe.cpp:313] Batch 648, loss = 1.37519
I0802 12:03:06.166630 19007 caffe.cpp:313] Batch 649, accuracy/top1 = 0.62
I0802 12:03:06.166652 19007 caffe.cpp:313] Batch 649, accuracy/top5 = 0.8
I0802 12:03:06.166656 19007 caffe.cpp:313] Batch 649, loss = 1.87674
I0802 12:03:06.214972 19007 caffe.cpp:313] Batch 650, accuracy/top1 = 0.64
I0802 12:03:06.214995 19007 caffe.cpp:313] Batch 650, accuracy/top5 = 0.8
I0802 12:03:06.214998 19007 caffe.cpp:313] Batch 650, loss = 1.52025
I0802 12:03:06.264498 19007 caffe.cpp:313] Batch 651, accuracy/top1 = 0.48
I0802 12:03:06.264523 19007 caffe.cpp:313] Batch 651, accuracy/top5 = 0.74
I0802 12:03:06.264525 19007 caffe.cpp:313] Batch 651, loss = 2.32915
I0802 12:03:06.312685 19007 caffe.cpp:313] Batch 652, accuracy/top1 = 0.48
I0802 12:03:06.312705 19007 caffe.cpp:313] Batch 652, accuracy/top5 = 0.7
I0802 12:03:06.312708 19007 caffe.cpp:313] Batch 652, loss = 2.51818
I0802 12:03:06.361987 19007 caffe.cpp:313] Batch 653, accuracy/top1 = 0.48
I0802 12:03:06.362012 19007 caffe.cpp:313] Batch 653, accuracy/top5 = 0.74
I0802 12:03:06.362015 19007 caffe.cpp:313] Batch 653, loss = 2.16683
I0802 12:03:06.410063 19007 caffe.cpp:313] Batch 654, accuracy/top1 = 0.6
I0802 12:03:06.410087 19007 caffe.cpp:313] Batch 654, accuracy/top5 = 0.84
I0802 12:03:06.410090 19007 caffe.cpp:313] Batch 654, loss = 1.84156
I0802 12:03:06.459414 19007 caffe.cpp:313] Batch 655, accuracy/top1 = 0.66
I0802 12:03:06.459439 19007 caffe.cpp:313] Batch 655, accuracy/top5 = 0.92
I0802 12:03:06.459441 19007 caffe.cpp:313] Batch 655, loss = 1.04952
I0802 12:03:06.507810 19007 caffe.cpp:313] Batch 656, accuracy/top1 = 0.62
I0802 12:03:06.507835 19007 caffe.cpp:313] Batch 656, accuracy/top5 = 0.9
I0802 12:03:06.507838 19007 caffe.cpp:313] Batch 656, loss = 1.4226
I0802 12:03:06.556938 19007 caffe.cpp:313] Batch 657, accuracy/top1 = 0.6
I0802 12:03:06.556959 19007 caffe.cpp:313] Batch 657, accuracy/top5 = 0.78
I0802 12:03:06.556962 19007 caffe.cpp:313] Batch 657, loss = 1.6431
I0802 12:03:06.605373 19007 caffe.cpp:313] Batch 658, accuracy/top1 = 0.56
I0802 12:03:06.605398 19007 caffe.cpp:313] Batch 658, accuracy/top5 = 0.76
I0802 12:03:06.605401 19007 caffe.cpp:313] Batch 658, loss = 1.97475
I0802 12:03:06.654222 19007 caffe.cpp:313] Batch 659, accuracy/top1 = 0.52
I0802 12:03:06.654247 19007 caffe.cpp:313] Batch 659, accuracy/top5 = 0.76
I0802 12:03:06.654250 19007 caffe.cpp:313] Batch 659, loss = 2.00913
I0802 12:03:06.701472 19007 caffe.cpp:313] Batch 660, accuracy/top1 = 0.64
I0802 12:03:06.701496 19007 caffe.cpp:313] Batch 660, accuracy/top5 = 0.78
I0802 12:03:06.701499 19007 caffe.cpp:313] Batch 660, loss = 1.69454
I0802 12:03:06.749546 19007 caffe.cpp:313] Batch 661, accuracy/top1 = 0.66
I0802 12:03:06.749572 19007 caffe.cpp:313] Batch 661, accuracy/top5 = 0.78
I0802 12:03:06.749574 19007 caffe.cpp:313] Batch 661, loss = 1.56822
I0802 12:03:06.798306 19007 caffe.cpp:313] Batch 662, accuracy/top1 = 0.56
I0802 12:03:06.798349 19007 caffe.cpp:313] Batch 662, accuracy/top5 = 0.74
I0802 12:03:06.798352 19007 caffe.cpp:313] Batch 662, loss = 2.07111
I0802 12:03:06.847239 19007 caffe.cpp:313] Batch 663, accuracy/top1 = 0.64
I0802 12:03:06.847263 19007 caffe.cpp:313] Batch 663, accuracy/top5 = 0.78
I0802 12:03:06.847266 19007 caffe.cpp:313] Batch 663, loss = 2.1112
I0802 12:03:06.895676 19007 caffe.cpp:313] Batch 664, accuracy/top1 = 0.54
I0802 12:03:06.895701 19007 caffe.cpp:313] Batch 664, accuracy/top5 = 0.8
I0802 12:03:06.895704 19007 caffe.cpp:313] Batch 664, loss = 1.88944
I0802 12:03:06.944100 19007 caffe.cpp:313] Batch 665, accuracy/top1 = 0.58
I0802 12:03:06.944125 19007 caffe.cpp:313] Batch 665, accuracy/top5 = 0.82
I0802 12:03:06.944128 19007 caffe.cpp:313] Batch 665, loss = 1.7374
I0802 12:03:06.993317 19007 caffe.cpp:313] Batch 666, accuracy/top1 = 0.6
I0802 12:03:06.993345 19007 caffe.cpp:313] Batch 666, accuracy/top5 = 0.84
I0802 12:03:06.993347 19007 caffe.cpp:313] Batch 666, loss = 1.64458
I0802 12:03:07.043182 19007 caffe.cpp:313] Batch 667, accuracy/top1 = 0.52
I0802 12:03:07.043207 19007 caffe.cpp:313] Batch 667, accuracy/top5 = 0.86
I0802 12:03:07.043210 19007 caffe.cpp:313] Batch 667, loss = 1.70073
I0802 12:03:07.092324 19007 caffe.cpp:313] Batch 668, accuracy/top1 = 0.54
I0802 12:03:07.092339 19007 caffe.cpp:313] Batch 668, accuracy/top5 = 0.78
I0802 12:03:07.092342 19007 caffe.cpp:313] Batch 668, loss = 1.93483
I0802 12:03:07.141248 19007 caffe.cpp:313] Batch 669, accuracy/top1 = 0.64
I0802 12:03:07.141274 19007 caffe.cpp:313] Batch 669, accuracy/top5 = 0.9
I0802 12:03:07.141278 19007 caffe.cpp:313] Batch 669, loss = 1.38738
I0802 12:03:07.190043 19007 caffe.cpp:313] Batch 670, accuracy/top1 = 0.64
I0802 12:03:07.190068 19007 caffe.cpp:313] Batch 670, accuracy/top5 = 0.82
I0802 12:03:07.190071 19007 caffe.cpp:313] Batch 670, loss = 1.46499
I0802 12:03:07.238430 19007 caffe.cpp:313] Batch 671, accuracy/top1 = 0.52
I0802 12:03:07.238456 19007 caffe.cpp:313] Batch 671, accuracy/top5 = 0.84
I0802 12:03:07.238457 19007 caffe.cpp:313] Batch 671, loss = 1.70876
I0802 12:03:07.287439 19007 caffe.cpp:313] Batch 672, accuracy/top1 = 0.54
I0802 12:03:07.287464 19007 caffe.cpp:313] Batch 672, accuracy/top5 = 0.84
I0802 12:03:07.287467 19007 caffe.cpp:313] Batch 672, loss = 1.70263
I0802 12:03:07.336066 19007 caffe.cpp:313] Batch 673, accuracy/top1 = 0.68
I0802 12:03:07.336091 19007 caffe.cpp:313] Batch 673, accuracy/top5 = 0.86
I0802 12:03:07.336093 19007 caffe.cpp:313] Batch 673, loss = 1.46479
I0802 12:03:07.385123 19007 caffe.cpp:313] Batch 674, accuracy/top1 = 0.74
I0802 12:03:07.385148 19007 caffe.cpp:313] Batch 674, accuracy/top5 = 0.9
I0802 12:03:07.385151 19007 caffe.cpp:313] Batch 674, loss = 1.07986
I0802 12:03:07.434352 19007 caffe.cpp:313] Batch 675, accuracy/top1 = 0.66
I0802 12:03:07.434376 19007 caffe.cpp:313] Batch 675, accuracy/top5 = 0.84
I0802 12:03:07.434379 19007 caffe.cpp:313] Batch 675, loss = 1.7276
I0802 12:03:07.482496 19007 caffe.cpp:313] Batch 676, accuracy/top1 = 0.5
I0802 12:03:07.482519 19007 caffe.cpp:313] Batch 676, accuracy/top5 = 0.72
I0802 12:03:07.482522 19007 caffe.cpp:313] Batch 676, loss = 2.03566
I0802 12:03:07.531275 19007 caffe.cpp:313] Batch 677, accuracy/top1 = 0.58
I0802 12:03:07.531299 19007 caffe.cpp:313] Batch 677, accuracy/top5 = 0.84
I0802 12:03:07.531302 19007 caffe.cpp:313] Batch 677, loss = 1.37622
I0802 12:03:07.581166 19007 caffe.cpp:313] Batch 678, accuracy/top1 = 0.56
I0802 12:03:07.581189 19007 caffe.cpp:313] Batch 678, accuracy/top5 = 0.84
I0802 12:03:07.581192 19007 caffe.cpp:313] Batch 678, loss = 1.94013
I0802 12:03:07.629118 19007 caffe.cpp:313] Batch 679, accuracy/top1 = 0.64
I0802 12:03:07.629142 19007 caffe.cpp:313] Batch 679, accuracy/top5 = 0.84
I0802 12:03:07.629145 19007 caffe.cpp:313] Batch 679, loss = 1.50508
I0802 12:03:07.677968 19007 caffe.cpp:313] Batch 680, accuracy/top1 = 0.68
I0802 12:03:07.677995 19007 caffe.cpp:313] Batch 680, accuracy/top5 = 0.9
I0802 12:03:07.677999 19007 caffe.cpp:313] Batch 680, loss = 1.38106
I0802 12:03:07.727237 19007 caffe.cpp:313] Batch 681, accuracy/top1 = 0.66
I0802 12:03:07.727279 19007 caffe.cpp:313] Batch 681, accuracy/top5 = 0.88
I0802 12:03:07.727283 19007 caffe.cpp:313] Batch 681, loss = 1.45887
I0802 12:03:07.775542 19007 caffe.cpp:313] Batch 682, accuracy/top1 = 0.5
I0802 12:03:07.775568 19007 caffe.cpp:313] Batch 682, accuracy/top5 = 0.8
I0802 12:03:07.775571 19007 caffe.cpp:313] Batch 682, loss = 2.07101
I0802 12:03:07.824584 19007 caffe.cpp:313] Batch 683, accuracy/top1 = 0.5
I0802 12:03:07.824609 19007 caffe.cpp:313] Batch 683, accuracy/top5 = 0.72
I0802 12:03:07.824612 19007 caffe.cpp:313] Batch 683, loss = 2.36304
I0802 12:03:07.873738 19007 caffe.cpp:313] Batch 684, accuracy/top1 = 0.64
I0802 12:03:07.873762 19007 caffe.cpp:313] Batch 684, accuracy/top5 = 0.84
I0802 12:03:07.873765 19007 caffe.cpp:313] Batch 684, loss = 2.00452
I0802 12:03:07.922965 19007 caffe.cpp:313] Batch 685, accuracy/top1 = 0.62
I0802 12:03:07.922989 19007 caffe.cpp:313] Batch 685, accuracy/top5 = 0.78
I0802 12:03:07.922992 19007 caffe.cpp:313] Batch 685, loss = 1.93958
I0802 12:03:07.971982 19007 caffe.cpp:313] Batch 686, accuracy/top1 = 0.54
I0802 12:03:07.972007 19007 caffe.cpp:313] Batch 686, accuracy/top5 = 0.68
I0802 12:03:07.972009 19007 caffe.cpp:313] Batch 686, loss = 1.92229
I0802 12:03:08.020279 19007 caffe.cpp:313] Batch 687, accuracy/top1 = 0.62
I0802 12:03:08.020303 19007 caffe.cpp:313] Batch 687, accuracy/top5 = 0.8
I0802 12:03:08.020306 19007 caffe.cpp:313] Batch 687, loss = 2.09542
I0802 12:03:08.068644 19007 caffe.cpp:313] Batch 688, accuracy/top1 = 0.64
I0802 12:03:08.068663 19007 caffe.cpp:313] Batch 688, accuracy/top5 = 0.8
I0802 12:03:08.068666 19007 caffe.cpp:313] Batch 688, loss = 1.92585
I0802 12:03:08.116668 19007 caffe.cpp:313] Batch 689, accuracy/top1 = 0.58
I0802 12:03:08.116693 19007 caffe.cpp:313] Batch 689, accuracy/top5 = 0.74
I0802 12:03:08.116696 19007 caffe.cpp:313] Batch 689, loss = 1.99007
I0802 12:03:08.165382 19007 caffe.cpp:313] Batch 690, accuracy/top1 = 0.54
I0802 12:03:08.165406 19007 caffe.cpp:313] Batch 690, accuracy/top5 = 0.88
I0802 12:03:08.165410 19007 caffe.cpp:313] Batch 690, loss = 1.7097
I0802 12:03:08.214094 19007 caffe.cpp:313] Batch 691, accuracy/top1 = 0.56
I0802 12:03:08.214114 19007 caffe.cpp:313] Batch 691, accuracy/top5 = 0.86
I0802 12:03:08.214118 19007 caffe.cpp:313] Batch 691, loss = 1.75898
I0802 12:03:08.262840 19007 caffe.cpp:313] Batch 692, accuracy/top1 = 0.5
I0802 12:03:08.262859 19007 caffe.cpp:313] Batch 692, accuracy/top5 = 0.78
I0802 12:03:08.262862 19007 caffe.cpp:313] Batch 692, loss = 2.14987
I0802 12:03:08.311619 19007 caffe.cpp:313] Batch 693, accuracy/top1 = 0.6
I0802 12:03:08.311640 19007 caffe.cpp:313] Batch 693, accuracy/top5 = 0.8
I0802 12:03:08.311643 19007 caffe.cpp:313] Batch 693, loss = 1.89701
I0802 12:03:08.360554 19007 caffe.cpp:313] Batch 694, accuracy/top1 = 0.56
I0802 12:03:08.360577 19007 caffe.cpp:313] Batch 694, accuracy/top5 = 0.86
I0802 12:03:08.360580 19007 caffe.cpp:313] Batch 694, loss = 1.5349
I0802 12:03:08.409566 19007 caffe.cpp:313] Batch 695, accuracy/top1 = 0.62
I0802 12:03:08.409591 19007 caffe.cpp:313] Batch 695, accuracy/top5 = 0.82
I0802 12:03:08.409595 19007 caffe.cpp:313] Batch 695, loss = 1.50486
I0802 12:03:08.458295 19007 caffe.cpp:313] Batch 696, accuracy/top1 = 0.46
I0802 12:03:08.458319 19007 caffe.cpp:313] Batch 696, accuracy/top5 = 0.78
I0802 12:03:08.458323 19007 caffe.cpp:313] Batch 696, loss = 1.9217
I0802 12:03:08.507133 19007 caffe.cpp:313] Batch 697, accuracy/top1 = 0.68
I0802 12:03:08.507158 19007 caffe.cpp:313] Batch 697, accuracy/top5 = 0.9
I0802 12:03:08.507160 19007 caffe.cpp:313] Batch 697, loss = 1.40065
I0802 12:03:08.556473 19007 caffe.cpp:313] Batch 698, accuracy/top1 = 0.6
I0802 12:03:08.556495 19007 caffe.cpp:313] Batch 698, accuracy/top5 = 0.82
I0802 12:03:08.556499 19007 caffe.cpp:313] Batch 698, loss = 2.06728
I0802 12:03:08.604743 19007 caffe.cpp:313] Batch 699, accuracy/top1 = 0.74
I0802 12:03:08.604766 19007 caffe.cpp:313] Batch 699, accuracy/top5 = 0.88
I0802 12:03:08.604769 19007 caffe.cpp:313] Batch 699, loss = 1.20624
I0802 12:03:08.652637 19007 caffe.cpp:313] Batch 700, accuracy/top1 = 0.6
I0802 12:03:08.652662 19007 caffe.cpp:313] Batch 700, accuracy/top5 = 0.78
I0802 12:03:08.652665 19007 caffe.cpp:313] Batch 700, loss = 2.10395
I0802 12:03:08.700244 19007 caffe.cpp:313] Batch 701, accuracy/top1 = 0.46
I0802 12:03:08.700269 19007 caffe.cpp:313] Batch 701, accuracy/top5 = 0.72
I0802 12:03:08.700273 19007 caffe.cpp:313] Batch 701, loss = 2.19627
I0802 12:03:08.748679 19007 caffe.cpp:313] Batch 702, accuracy/top1 = 0.52
I0802 12:03:08.748704 19007 caffe.cpp:313] Batch 702, accuracy/top5 = 0.76
I0802 12:03:08.748708 19007 caffe.cpp:313] Batch 702, loss = 2.24469
I0802 12:03:08.797616 19007 caffe.cpp:313] Batch 703, accuracy/top1 = 0.68
I0802 12:03:08.797641 19007 caffe.cpp:313] Batch 703, accuracy/top5 = 0.94
I0802 12:03:08.797644 19007 caffe.cpp:313] Batch 703, loss = 1.14435
I0802 12:03:08.846063 19007 caffe.cpp:313] Batch 704, accuracy/top1 = 0.64
I0802 12:03:08.846089 19007 caffe.cpp:313] Batch 704, accuracy/top5 = 0.84
I0802 12:03:08.846092 19007 caffe.cpp:313] Batch 704, loss = 1.67837
I0802 12:03:08.894971 19007 caffe.cpp:313] Batch 705, accuracy/top1 = 0.6
I0802 12:03:08.894996 19007 caffe.cpp:313] Batch 705, accuracy/top5 = 0.88
I0802 12:03:08.895000 19007 caffe.cpp:313] Batch 705, loss = 1.32997
I0802 12:03:08.944011 19007 caffe.cpp:313] Batch 706, accuracy/top1 = 0.6
I0802 12:03:08.944036 19007 caffe.cpp:313] Batch 706, accuracy/top5 = 0.84
I0802 12:03:08.944041 19007 caffe.cpp:313] Batch 706, loss = 1.526
I0802 12:03:08.993069 19007 caffe.cpp:313] Batch 707, accuracy/top1 = 0.64
I0802 12:03:08.993093 19007 caffe.cpp:313] Batch 707, accuracy/top5 = 0.8
I0802 12:03:08.993096 19007 caffe.cpp:313] Batch 707, loss = 1.63166
I0802 12:03:09.041676 19007 caffe.cpp:313] Batch 708, accuracy/top1 = 0.54
I0802 12:03:09.041694 19007 caffe.cpp:313] Batch 708, accuracy/top5 = 0.9
I0802 12:03:09.041697 19007 caffe.cpp:313] Batch 708, loss = 1.37688
I0802 12:03:09.090737 19007 caffe.cpp:313] Batch 709, accuracy/top1 = 0.6
I0802 12:03:09.090754 19007 caffe.cpp:313] Batch 709, accuracy/top5 = 0.78
I0802 12:03:09.090756 19007 caffe.cpp:313] Batch 709, loss = 1.95822
I0802 12:03:09.138430 19007 caffe.cpp:313] Batch 710, accuracy/top1 = 0.56
I0802 12:03:09.138456 19007 caffe.cpp:313] Batch 710, accuracy/top5 = 0.76
I0802 12:03:09.138459 19007 caffe.cpp:313] Batch 710, loss = 2.11152
I0802 12:03:09.187448 19007 caffe.cpp:313] Batch 711, accuracy/top1 = 0.58
I0802 12:03:09.187472 19007 caffe.cpp:313] Batch 711, accuracy/top5 = 0.8
I0802 12:03:09.187475 19007 caffe.cpp:313] Batch 711, loss = 1.81934
I0802 12:03:09.236986 19007 caffe.cpp:313] Batch 712, accuracy/top1 = 0.6
I0802 12:03:09.237011 19007 caffe.cpp:313] Batch 712, accuracy/top5 = 0.8
I0802 12:03:09.237015 19007 caffe.cpp:313] Batch 712, loss = 1.92343
I0802 12:03:09.286013 19007 caffe.cpp:313] Batch 713, accuracy/top1 = 0.48
I0802 12:03:09.286038 19007 caffe.cpp:313] Batch 713, accuracy/top5 = 0.74
I0802 12:03:09.286042 19007 caffe.cpp:313] Batch 713, loss = 2.45005
I0802 12:03:09.334499 19007 caffe.cpp:313] Batch 714, accuracy/top1 = 0.62
I0802 12:03:09.334524 19007 caffe.cpp:313] Batch 714, accuracy/top5 = 0.84
I0802 12:03:09.334528 19007 caffe.cpp:313] Batch 714, loss = 1.5191
I0802 12:03:09.384024 19007 caffe.cpp:313] Batch 715, accuracy/top1 = 0.54
I0802 12:03:09.384049 19007 caffe.cpp:313] Batch 715, accuracy/top5 = 0.8
I0802 12:03:09.384052 19007 caffe.cpp:313] Batch 715, loss = 2.10038
I0802 12:03:09.433251 19007 caffe.cpp:313] Batch 716, accuracy/top1 = 0.68
I0802 12:03:09.433276 19007 caffe.cpp:313] Batch 716, accuracy/top5 = 0.76
I0802 12:03:09.433279 19007 caffe.cpp:313] Batch 716, loss = 2.05515
I0802 12:03:09.482847 19007 caffe.cpp:313] Batch 717, accuracy/top1 = 0.74
I0802 12:03:09.482872 19007 caffe.cpp:313] Batch 717, accuracy/top5 = 0.82
I0802 12:03:09.482875 19007 caffe.cpp:313] Batch 717, loss = 1.59976
I0802 12:03:09.531111 19007 caffe.cpp:313] Batch 718, accuracy/top1 = 0.44
I0802 12:03:09.531136 19007 caffe.cpp:313] Batch 718, accuracy/top5 = 0.7
I0802 12:03:09.531154 19007 caffe.cpp:313] Batch 718, loss = 2.74614
I0802 12:03:09.579859 19007 caffe.cpp:313] Batch 719, accuracy/top1 = 0.72
I0802 12:03:09.579879 19007 caffe.cpp:313] Batch 719, accuracy/top5 = 0.86
I0802 12:03:09.579883 19007 caffe.cpp:313] Batch 719, loss = 1.61147
I0802 12:03:09.628315 19007 caffe.cpp:313] Batch 720, accuracy/top1 = 0.56
I0802 12:03:09.628340 19007 caffe.cpp:313] Batch 720, accuracy/top5 = 0.82
I0802 12:03:09.628343 19007 caffe.cpp:313] Batch 720, loss = 1.64677
I0802 12:03:09.677052 19007 caffe.cpp:313] Batch 721, accuracy/top1 = 0.62
I0802 12:03:09.677076 19007 caffe.cpp:313] Batch 721, accuracy/top5 = 0.82
I0802 12:03:09.677079 19007 caffe.cpp:313] Batch 721, loss = 1.86241
I0802 12:03:09.725677 19007 caffe.cpp:313] Batch 722, accuracy/top1 = 0.6
I0802 12:03:09.725702 19007 caffe.cpp:313] Batch 722, accuracy/top5 = 0.74
I0802 12:03:09.725704 19007 caffe.cpp:313] Batch 722, loss = 2.00576
I0802 12:03:09.774658 19007 caffe.cpp:313] Batch 723, accuracy/top1 = 0.5
I0802 12:03:09.774683 19007 caffe.cpp:313] Batch 723, accuracy/top5 = 0.84
I0802 12:03:09.774688 19007 caffe.cpp:313] Batch 723, loss = 2.04203
I0802 12:03:09.822497 19007 caffe.cpp:313] Batch 724, accuracy/top1 = 0.62
I0802 12:03:09.822522 19007 caffe.cpp:313] Batch 724, accuracy/top5 = 0.9
I0802 12:03:09.822525 19007 caffe.cpp:313] Batch 724, loss = 1.34764
I0802 12:03:09.871536 19007 caffe.cpp:313] Batch 725, accuracy/top1 = 0.68
I0802 12:03:09.871558 19007 caffe.cpp:313] Batch 725, accuracy/top5 = 0.92
I0802 12:03:09.871562 19007 caffe.cpp:313] Batch 725, loss = 1.38426
I0802 12:03:09.920176 19007 caffe.cpp:313] Batch 726, accuracy/top1 = 0.62
I0802 12:03:09.920199 19007 caffe.cpp:313] Batch 726, accuracy/top5 = 0.86
I0802 12:03:09.920203 19007 caffe.cpp:313] Batch 726, loss = 1.58127
I0802 12:03:09.968235 19007 caffe.cpp:313] Batch 727, accuracy/top1 = 0.6
I0802 12:03:09.968260 19007 caffe.cpp:313] Batch 727, accuracy/top5 = 0.82
I0802 12:03:09.968262 19007 caffe.cpp:313] Batch 727, loss = 1.74912
I0802 12:03:10.017179 19007 caffe.cpp:313] Batch 728, accuracy/top1 = 0.7
I0802 12:03:10.017204 19007 caffe.cpp:313] Batch 728, accuracy/top5 = 0.84
I0802 12:03:10.017206 19007 caffe.cpp:313] Batch 728, loss = 1.42076
I0802 12:03:10.065008 19007 caffe.cpp:313] Batch 729, accuracy/top1 = 0.7
I0802 12:03:10.065026 19007 caffe.cpp:313] Batch 729, accuracy/top5 = 0.86
I0802 12:03:10.065029 19007 caffe.cpp:313] Batch 729, loss = 1.28838
I0802 12:03:10.113420 19007 caffe.cpp:313] Batch 730, accuracy/top1 = 0.52
I0802 12:03:10.113445 19007 caffe.cpp:313] Batch 730, accuracy/top5 = 0.72
I0802 12:03:10.113448 19007 caffe.cpp:313] Batch 730, loss = 2.29111
I0802 12:03:10.161494 19007 caffe.cpp:313] Batch 731, accuracy/top1 = 0.5
I0802 12:03:10.161519 19007 caffe.cpp:313] Batch 731, accuracy/top5 = 0.78
I0802 12:03:10.161521 19007 caffe.cpp:313] Batch 731, loss = 2.06104
I0802 12:03:10.210050 19007 caffe.cpp:313] Batch 732, accuracy/top1 = 0.68
I0802 12:03:10.210077 19007 caffe.cpp:313] Batch 732, accuracy/top5 = 0.86
I0802 12:03:10.210080 19007 caffe.cpp:313] Batch 732, loss = 1.48807
I0802 12:03:10.259061 19007 caffe.cpp:313] Batch 733, accuracy/top1 = 0.48
I0802 12:03:10.259085 19007 caffe.cpp:313] Batch 733, accuracy/top5 = 0.84
I0802 12:03:10.259088 19007 caffe.cpp:313] Batch 733, loss = 1.94386
I0802 12:03:10.307688 19007 caffe.cpp:313] Batch 734, accuracy/top1 = 0.58
I0802 12:03:10.307713 19007 caffe.cpp:313] Batch 734, accuracy/top5 = 0.88
I0802 12:03:10.307715 19007 caffe.cpp:313] Batch 734, loss = 1.56954
I0802 12:03:10.357270 19007 caffe.cpp:313] Batch 735, accuracy/top1 = 0.56
I0802 12:03:10.357288 19007 caffe.cpp:313] Batch 735, accuracy/top5 = 0.8
I0802 12:03:10.357291 19007 caffe.cpp:313] Batch 735, loss = 1.71011
I0802 12:03:10.406393 19007 caffe.cpp:313] Batch 736, accuracy/top1 = 0.62
I0802 12:03:10.406419 19007 caffe.cpp:313] Batch 736, accuracy/top5 = 0.88
I0802 12:03:10.406424 19007 caffe.cpp:313] Batch 736, loss = 1.47407
I0802 12:03:10.454695 19007 caffe.cpp:313] Batch 737, accuracy/top1 = 0.72
I0802 12:03:10.454717 19007 caffe.cpp:313] Batch 737, accuracy/top5 = 0.82
I0802 12:03:10.454730 19007 caffe.cpp:313] Batch 737, loss = 1.41118
I0802 12:03:10.503680 19007 caffe.cpp:313] Batch 738, accuracy/top1 = 0.66
I0802 12:03:10.503705 19007 caffe.cpp:313] Batch 738, accuracy/top5 = 0.82
I0802 12:03:10.503707 19007 caffe.cpp:313] Batch 738, loss = 1.51712
I0802 12:03:10.552129 19007 caffe.cpp:313] Batch 739, accuracy/top1 = 0.62
I0802 12:03:10.552151 19007 caffe.cpp:313] Batch 739, accuracy/top5 = 0.82
I0802 12:03:10.552155 19007 caffe.cpp:313] Batch 739, loss = 1.67409
I0802 12:03:10.601001 19007 caffe.cpp:313] Batch 740, accuracy/top1 = 0.7
I0802 12:03:10.601025 19007 caffe.cpp:313] Batch 740, accuracy/top5 = 0.88
I0802 12:03:10.601029 19007 caffe.cpp:313] Batch 740, loss = 1.41178
I0802 12:03:10.648778 19007 caffe.cpp:313] Batch 741, accuracy/top1 = 0.64
I0802 12:03:10.648803 19007 caffe.cpp:313] Batch 741, accuracy/top5 = 0.84
I0802 12:03:10.648807 19007 caffe.cpp:313] Batch 741, loss = 1.63708
I0802 12:03:10.697674 19007 caffe.cpp:313] Batch 742, accuracy/top1 = 0.64
I0802 12:03:10.697698 19007 caffe.cpp:313] Batch 742, accuracy/top5 = 0.86
I0802 12:03:10.697701 19007 caffe.cpp:313] Batch 742, loss = 1.52832
I0802 12:03:10.746160 19007 caffe.cpp:313] Batch 743, accuracy/top1 = 0.6
I0802 12:03:10.746186 19007 caffe.cpp:313] Batch 743, accuracy/top5 = 0.78
I0802 12:03:10.746188 19007 caffe.cpp:313] Batch 743, loss = 2.10593
I0802 12:03:10.794744 19007 caffe.cpp:313] Batch 744, accuracy/top1 = 0.52
I0802 12:03:10.794770 19007 caffe.cpp:313] Batch 744, accuracy/top5 = 0.76
I0802 12:03:10.794773 19007 caffe.cpp:313] Batch 744, loss = 2.19801
I0802 12:03:10.843964 19007 caffe.cpp:313] Batch 745, accuracy/top1 = 0.64
I0802 12:03:10.843987 19007 caffe.cpp:313] Batch 745, accuracy/top5 = 0.84
I0802 12:03:10.843991 19007 caffe.cpp:313] Batch 745, loss = 1.48403
I0802 12:03:10.892542 19007 caffe.cpp:313] Batch 746, accuracy/top1 = 0.58
I0802 12:03:10.892568 19007 caffe.cpp:313] Batch 746, accuracy/top5 = 0.82
I0802 12:03:10.892571 19007 caffe.cpp:313] Batch 746, loss = 2.1497
I0802 12:03:10.941505 19007 caffe.cpp:313] Batch 747, accuracy/top1 = 0.62
I0802 12:03:10.941530 19007 caffe.cpp:313] Batch 747, accuracy/top5 = 0.88
I0802 12:03:10.941534 19007 caffe.cpp:313] Batch 747, loss = 1.61805
I0802 12:03:10.990136 19007 caffe.cpp:313] Batch 748, accuracy/top1 = 0.66
I0802 12:03:10.990162 19007 caffe.cpp:313] Batch 748, accuracy/top5 = 0.82
I0802 12:03:10.990165 19007 caffe.cpp:313] Batch 748, loss = 1.49169
I0802 12:03:11.038895 19007 caffe.cpp:313] Batch 749, accuracy/top1 = 0.76
I0802 12:03:11.038919 19007 caffe.cpp:313] Batch 749, accuracy/top5 = 0.92
I0802 12:03:11.038923 19007 caffe.cpp:313] Batch 749, loss = 1.03803
I0802 12:03:11.088095 19007 caffe.cpp:313] Batch 750, accuracy/top1 = 0.64
I0802 12:03:11.088111 19007 caffe.cpp:313] Batch 750, accuracy/top5 = 0.86
I0802 12:03:11.088114 19007 caffe.cpp:313] Batch 750, loss = 1.25774
I0802 12:03:11.136313 19007 caffe.cpp:313] Batch 751, accuracy/top1 = 0.64
I0802 12:03:11.136339 19007 caffe.cpp:313] Batch 751, accuracy/top5 = 0.78
I0802 12:03:11.136343 19007 caffe.cpp:313] Batch 751, loss = 1.57377
I0802 12:03:11.184062 19007 caffe.cpp:313] Batch 752, accuracy/top1 = 0.66
I0802 12:03:11.184085 19007 caffe.cpp:313] Batch 752, accuracy/top5 = 0.84
I0802 12:03:11.184088 19007 caffe.cpp:313] Batch 752, loss = 1.40454
I0802 12:03:11.233712 19007 caffe.cpp:313] Batch 753, accuracy/top1 = 0.52
I0802 12:03:11.233736 19007 caffe.cpp:313] Batch 753, accuracy/top5 = 0.8
I0802 12:03:11.233739 19007 caffe.cpp:313] Batch 753, loss = 2.12769
I0802 12:03:11.281985 19007 caffe.cpp:313] Batch 754, accuracy/top1 = 0.62
I0802 12:03:11.282008 19007 caffe.cpp:313] Batch 754, accuracy/top5 = 0.82
I0802 12:03:11.282011 19007 caffe.cpp:313] Batch 754, loss = 1.66165
I0802 12:03:11.329988 19007 caffe.cpp:313] Batch 755, accuracy/top1 = 0.56
I0802 12:03:11.330011 19007 caffe.cpp:313] Batch 755, accuracy/top5 = 0.74
I0802 12:03:11.330014 19007 caffe.cpp:313] Batch 755, loss = 2.43797
I0802 12:03:11.378566 19007 caffe.cpp:313] Batch 756, accuracy/top1 = 0.62
I0802 12:03:11.378605 19007 caffe.cpp:313] Batch 756, accuracy/top5 = 0.78
I0802 12:03:11.378609 19007 caffe.cpp:313] Batch 756, loss = 1.57999
I0802 12:03:11.427055 19007 caffe.cpp:313] Batch 757, accuracy/top1 = 0.6
I0802 12:03:11.427080 19007 caffe.cpp:313] Batch 757, accuracy/top5 = 0.88
I0802 12:03:11.427084 19007 caffe.cpp:313] Batch 757, loss = 1.52694
I0802 12:03:11.476032 19007 caffe.cpp:313] Batch 758, accuracy/top1 = 0.7
I0802 12:03:11.476058 19007 caffe.cpp:313] Batch 758, accuracy/top5 = 0.84
I0802 12:03:11.476061 19007 caffe.cpp:313] Batch 758, loss = 1.33894
I0802 12:03:11.524735 19007 caffe.cpp:313] Batch 759, accuracy/top1 = 0.66
I0802 12:03:11.524750 19007 caffe.cpp:313] Batch 759, accuracy/top5 = 0.82
I0802 12:03:11.524755 19007 caffe.cpp:313] Batch 759, loss = 1.82554
I0802 12:03:11.574085 19007 caffe.cpp:313] Batch 760, accuracy/top1 = 0.72
I0802 12:03:11.574110 19007 caffe.cpp:313] Batch 760, accuracy/top5 = 0.88
I0802 12:03:11.574113 19007 caffe.cpp:313] Batch 760, loss = 1.4925
I0802 12:03:11.622037 19007 caffe.cpp:313] Batch 761, accuracy/top1 = 0.52
I0802 12:03:11.622062 19007 caffe.cpp:313] Batch 761, accuracy/top5 = 0.82
I0802 12:03:11.622066 19007 caffe.cpp:313] Batch 761, loss = 2.04447
I0802 12:03:11.670331 19007 caffe.cpp:313] Batch 762, accuracy/top1 = 0.64
I0802 12:03:11.670356 19007 caffe.cpp:313] Batch 762, accuracy/top5 = 0.8
I0802 12:03:11.670359 19007 caffe.cpp:313] Batch 762, loss = 1.61839
I0802 12:03:11.718139 19007 caffe.cpp:313] Batch 763, accuracy/top1 = 0.6
I0802 12:03:11.718163 19007 caffe.cpp:313] Batch 763, accuracy/top5 = 0.8
I0802 12:03:11.718166 19007 caffe.cpp:313] Batch 763, loss = 1.79786
I0802 12:03:11.767594 19007 caffe.cpp:313] Batch 764, accuracy/top1 = 0.34
I0802 12:03:11.767619 19007 caffe.cpp:313] Batch 764, accuracy/top5 = 0.68
I0802 12:03:11.767622 19007 caffe.cpp:313] Batch 764, loss = 2.78701
I0802 12:03:11.816365 19007 caffe.cpp:313] Batch 765, accuracy/top1 = 0.62
I0802 12:03:11.816390 19007 caffe.cpp:313] Batch 765, accuracy/top5 = 0.88
I0802 12:03:11.816392 19007 caffe.cpp:313] Batch 765, loss = 1.6386
I0802 12:03:11.865294 19007 caffe.cpp:313] Batch 766, accuracy/top1 = 0.58
I0802 12:03:11.865319 19007 caffe.cpp:313] Batch 766, accuracy/top5 = 0.78
I0802 12:03:11.865321 19007 caffe.cpp:313] Batch 766, loss = 2.0381
I0802 12:03:11.914615 19007 caffe.cpp:313] Batch 767, accuracy/top1 = 0.52
I0802 12:03:11.914644 19007 caffe.cpp:313] Batch 767, accuracy/top5 = 0.78
I0802 12:03:11.914647 19007 caffe.cpp:313] Batch 767, loss = 1.72129
I0802 12:03:11.963088 19007 caffe.cpp:313] Batch 768, accuracy/top1 = 0.6
I0802 12:03:11.963114 19007 caffe.cpp:313] Batch 768, accuracy/top5 = 0.82
I0802 12:03:11.963117 19007 caffe.cpp:313] Batch 768, loss = 1.65384
I0802 12:03:12.012161 19007 caffe.cpp:313] Batch 769, accuracy/top1 = 0.58
I0802 12:03:12.012187 19007 caffe.cpp:313] Batch 769, accuracy/top5 = 0.8
I0802 12:03:12.012189 19007 caffe.cpp:313] Batch 769, loss = 1.82522
I0802 12:03:12.060590 19007 caffe.cpp:313] Batch 770, accuracy/top1 = 0.64
I0802 12:03:12.060607 19007 caffe.cpp:313] Batch 770, accuracy/top5 = 0.82
I0802 12:03:12.060611 19007 caffe.cpp:313] Batch 770, loss = 1.73769
I0802 12:03:12.109361 19007 caffe.cpp:313] Batch 771, accuracy/top1 = 0.6
I0802 12:03:12.109395 19007 caffe.cpp:313] Batch 771, accuracy/top5 = 0.78
I0802 12:03:12.109398 19007 caffe.cpp:313] Batch 771, loss = 1.93807
I0802 12:03:12.158108 19007 caffe.cpp:313] Batch 772, accuracy/top1 = 0.52
I0802 12:03:12.158133 19007 caffe.cpp:313] Batch 772, accuracy/top5 = 0.86
I0802 12:03:12.158136 19007 caffe.cpp:313] Batch 772, loss = 2.14149
I0802 12:03:12.206284 19007 caffe.cpp:313] Batch 773, accuracy/top1 = 0.58
I0802 12:03:12.206310 19007 caffe.cpp:313] Batch 773, accuracy/top5 = 0.76
I0802 12:03:12.206312 19007 caffe.cpp:313] Batch 773, loss = 2.12863
I0802 12:03:12.255118 19007 caffe.cpp:313] Batch 774, accuracy/top1 = 0.64
I0802 12:03:12.255142 19007 caffe.cpp:313] Batch 774, accuracy/top5 = 0.84
I0802 12:03:12.255146 19007 caffe.cpp:313] Batch 774, loss = 1.53262
I0802 12:03:12.304083 19007 caffe.cpp:313] Batch 775, accuracy/top1 = 0.62
I0802 12:03:12.304108 19007 caffe.cpp:313] Batch 775, accuracy/top5 = 0.92
I0802 12:03:12.304111 19007 caffe.cpp:313] Batch 775, loss = 1.48376
I0802 12:03:12.352907 19007 caffe.cpp:313] Batch 776, accuracy/top1 = 0.72
I0802 12:03:12.352932 19007 caffe.cpp:313] Batch 776, accuracy/top5 = 0.84
I0802 12:03:12.352936 19007 caffe.cpp:313] Batch 776, loss = 1.65672
I0802 12:03:12.402575 19007 caffe.cpp:313] Batch 777, accuracy/top1 = 0.56
I0802 12:03:12.402595 19007 caffe.cpp:313] Batch 777, accuracy/top5 = 0.94
I0802 12:03:12.402597 19007 caffe.cpp:313] Batch 777, loss = 1.42738
I0802 12:03:12.451575 19007 caffe.cpp:313] Batch 778, accuracy/top1 = 0.66
I0802 12:03:12.451601 19007 caffe.cpp:313] Batch 778, accuracy/top5 = 0.86
I0802 12:03:12.451604 19007 caffe.cpp:313] Batch 778, loss = 1.41397
I0802 12:03:12.499497 19007 caffe.cpp:313] Batch 779, accuracy/top1 = 0.66
I0802 12:03:12.499518 19007 caffe.cpp:313] Batch 779, accuracy/top5 = 0.78
I0802 12:03:12.499521 19007 caffe.cpp:313] Batch 779, loss = 2.08169
I0802 12:03:12.548574 19007 caffe.cpp:313] Batch 780, accuracy/top1 = 0.56
I0802 12:03:12.548599 19007 caffe.cpp:313] Batch 780, accuracy/top5 = 0.9
I0802 12:03:12.548604 19007 caffe.cpp:313] Batch 780, loss = 1.38794
I0802 12:03:12.597318 19007 caffe.cpp:313] Batch 781, accuracy/top1 = 0.68
I0802 12:03:12.597342 19007 caffe.cpp:313] Batch 781, accuracy/top5 = 0.88
I0802 12:03:12.597345 19007 caffe.cpp:313] Batch 781, loss = 1.59126
I0802 12:03:12.645555 19007 caffe.cpp:313] Batch 782, accuracy/top1 = 0.7
I0802 12:03:12.645581 19007 caffe.cpp:313] Batch 782, accuracy/top5 = 0.9
I0802 12:03:12.645584 19007 caffe.cpp:313] Batch 782, loss = 1.16465
I0802 12:03:12.694372 19007 caffe.cpp:313] Batch 783, accuracy/top1 = 0.62
I0802 12:03:12.694397 19007 caffe.cpp:313] Batch 783, accuracy/top5 = 0.9
I0802 12:03:12.694401 19007 caffe.cpp:313] Batch 783, loss = 1.39944
I0802 12:03:12.743794 19007 caffe.cpp:313] Batch 784, accuracy/top1 = 0.54
I0802 12:03:12.743819 19007 caffe.cpp:313] Batch 784, accuracy/top5 = 0.88
I0802 12:03:12.743824 19007 caffe.cpp:313] Batch 784, loss = 1.55164
I0802 12:03:12.792923 19007 caffe.cpp:313] Batch 785, accuracy/top1 = 0.56
I0802 12:03:12.792949 19007 caffe.cpp:313] Batch 785, accuracy/top5 = 0.82
I0802 12:03:12.792953 19007 caffe.cpp:313] Batch 785, loss = 2.00696
I0802 12:03:12.841564 19007 caffe.cpp:313] Batch 786, accuracy/top1 = 0.7
I0802 12:03:12.841590 19007 caffe.cpp:313] Batch 786, accuracy/top5 = 0.94
I0802 12:03:12.841594 19007 caffe.cpp:313] Batch 786, loss = 0.881359
I0802 12:03:12.890969 19007 caffe.cpp:313] Batch 787, accuracy/top1 = 0.52
I0802 12:03:12.890995 19007 caffe.cpp:313] Batch 787, accuracy/top5 = 0.88
I0802 12:03:12.890998 19007 caffe.cpp:313] Batch 787, loss = 1.51811
I0802 12:03:12.939973 19007 caffe.cpp:313] Batch 788, accuracy/top1 = 0.6
I0802 12:03:12.939999 19007 caffe.cpp:313] Batch 788, accuracy/top5 = 0.78
I0802 12:03:12.940004 19007 caffe.cpp:313] Batch 788, loss = 2.07752
I0802 12:03:12.988864 19007 caffe.cpp:313] Batch 789, accuracy/top1 = 0.68
I0802 12:03:12.988890 19007 caffe.cpp:313] Batch 789, accuracy/top5 = 0.88
I0802 12:03:12.988894 19007 caffe.cpp:313] Batch 789, loss = 1.28501
I0802 12:03:13.037055 19007 caffe.cpp:313] Batch 790, accuracy/top1 = 0.7
I0802 12:03:13.037080 19007 caffe.cpp:313] Batch 790, accuracy/top5 = 0.9
I0802 12:03:13.037084 19007 caffe.cpp:313] Batch 790, loss = 1.30251
I0802 12:03:13.086084 19007 caffe.cpp:313] Batch 791, accuracy/top1 = 0.58
I0802 12:03:13.086102 19007 caffe.cpp:313] Batch 791, accuracy/top5 = 0.82
I0802 12:03:13.086107 19007 caffe.cpp:313] Batch 791, loss = 1.86367
I0802 12:03:13.133154 19007 caffe.cpp:313] Batch 792, accuracy/top1 = 0.5
I0802 12:03:13.133179 19007 caffe.cpp:313] Batch 792, accuracy/top5 = 0.9
I0802 12:03:13.133184 19007 caffe.cpp:313] Batch 792, loss = 1.87493
I0802 12:03:13.182431 19007 caffe.cpp:313] Batch 793, accuracy/top1 = 0.58
I0802 12:03:13.182457 19007 caffe.cpp:313] Batch 793, accuracy/top5 = 0.7
I0802 12:03:13.182479 19007 caffe.cpp:313] Batch 793, loss = 2.20043
I0802 12:03:13.232606 19007 caffe.cpp:313] Batch 794, accuracy/top1 = 0.56
I0802 12:03:13.232631 19007 caffe.cpp:313] Batch 794, accuracy/top5 = 0.78
I0802 12:03:13.232635 19007 caffe.cpp:313] Batch 794, loss = 1.79286
I0802 12:03:13.281514 19007 caffe.cpp:313] Batch 795, accuracy/top1 = 0.62
I0802 12:03:13.281540 19007 caffe.cpp:313] Batch 795, accuracy/top5 = 0.78
I0802 12:03:13.281544 19007 caffe.cpp:313] Batch 795, loss = 1.90192
I0802 12:03:13.330965 19007 caffe.cpp:313] Batch 796, accuracy/top1 = 0.6
I0802 12:03:13.330991 19007 caffe.cpp:313] Batch 796, accuracy/top5 = 0.78
I0802 12:03:13.330996 19007 caffe.cpp:313] Batch 796, loss = 1.83537
I0802 12:03:13.380209 19007 caffe.cpp:313] Batch 797, accuracy/top1 = 0.56
I0802 12:03:13.380236 19007 caffe.cpp:313] Batch 797, accuracy/top5 = 0.78
I0802 12:03:13.380240 19007 caffe.cpp:313] Batch 797, loss = 1.92795
I0802 12:03:13.430621 19007 caffe.cpp:313] Batch 798, accuracy/top1 = 0.6
I0802 12:03:13.430646 19007 caffe.cpp:313] Batch 798, accuracy/top5 = 0.84
I0802 12:03:13.430651 19007 caffe.cpp:313] Batch 798, loss = 1.86095
I0802 12:03:13.479933 19007 caffe.cpp:313] Batch 799, accuracy/top1 = 0.6
I0802 12:03:13.479957 19007 caffe.cpp:313] Batch 799, accuracy/top5 = 0.78
I0802 12:03:13.479962 19007 caffe.cpp:313] Batch 799, loss = 1.67197
I0802 12:03:13.529281 19007 caffe.cpp:313] Batch 800, accuracy/top1 = 0.5
I0802 12:03:13.529305 19007 caffe.cpp:313] Batch 800, accuracy/top5 = 0.72
I0802 12:03:13.529309 19007 caffe.cpp:313] Batch 800, loss = 2.75989
I0802 12:03:13.579067 19007 caffe.cpp:313] Batch 801, accuracy/top1 = 0.56
I0802 12:03:13.579092 19007 caffe.cpp:313] Batch 801, accuracy/top5 = 0.84
I0802 12:03:13.579097 19007 caffe.cpp:313] Batch 801, loss = 1.80588
I0802 12:03:13.627346 19007 caffe.cpp:313] Batch 802, accuracy/top1 = 0.62
I0802 12:03:13.627369 19007 caffe.cpp:313] Batch 802, accuracy/top5 = 0.82
I0802 12:03:13.627373 19007 caffe.cpp:313] Batch 802, loss = 1.68478
I0802 12:03:13.676287 19007 caffe.cpp:313] Batch 803, accuracy/top1 = 0.62
I0802 12:03:13.676313 19007 caffe.cpp:313] Batch 803, accuracy/top5 = 0.84
I0802 12:03:13.676317 19007 caffe.cpp:313] Batch 803, loss = 1.53506
I0802 12:03:13.725595 19007 caffe.cpp:313] Batch 804, accuracy/top1 = 0.56
I0802 12:03:13.725620 19007 caffe.cpp:313] Batch 804, accuracy/top5 = 0.9
I0802 12:03:13.725623 19007 caffe.cpp:313] Batch 804, loss = 1.63416
I0802 12:03:13.774803 19007 caffe.cpp:313] Batch 805, accuracy/top1 = 0.6
I0802 12:03:13.774827 19007 caffe.cpp:313] Batch 805, accuracy/top5 = 0.84
I0802 12:03:13.774832 19007 caffe.cpp:313] Batch 805, loss = 1.827
I0802 12:03:13.824069 19007 caffe.cpp:313] Batch 806, accuracy/top1 = 0.66
I0802 12:03:13.824093 19007 caffe.cpp:313] Batch 806, accuracy/top5 = 0.88
I0802 12:03:13.824097 19007 caffe.cpp:313] Batch 806, loss = 1.3355
I0802 12:03:13.873466 19007 caffe.cpp:313] Batch 807, accuracy/top1 = 0.58
I0802 12:03:13.873489 19007 caffe.cpp:313] Batch 807, accuracy/top5 = 0.82
I0802 12:03:13.873493 19007 caffe.cpp:313] Batch 807, loss = 1.84658
I0802 12:03:13.922876 19007 caffe.cpp:313] Batch 808, accuracy/top1 = 0.64
I0802 12:03:13.922900 19007 caffe.cpp:313] Batch 808, accuracy/top5 = 0.84
I0802 12:03:13.922904 19007 caffe.cpp:313] Batch 808, loss = 1.92598
I0802 12:03:13.973037 19007 caffe.cpp:313] Batch 809, accuracy/top1 = 0.54
I0802 12:03:13.973062 19007 caffe.cpp:313] Batch 809, accuracy/top5 = 0.74
I0802 12:03:13.973067 19007 caffe.cpp:313] Batch 809, loss = 2.50251
I0802 12:03:14.022589 19007 caffe.cpp:313] Batch 810, accuracy/top1 = 0.56
I0802 12:03:14.022620 19007 caffe.cpp:313] Batch 810, accuracy/top5 = 0.8
I0802 12:03:14.022624 19007 caffe.cpp:313] Batch 810, loss = 1.92873
I0802 12:03:14.071310 19007 caffe.cpp:313] Batch 811, accuracy/top1 = 0.54
I0802 12:03:14.071326 19007 caffe.cpp:313] Batch 811, accuracy/top5 = 0.84
I0802 12:03:14.071331 19007 caffe.cpp:313] Batch 811, loss = 2.09279
I0802 12:03:14.119587 19007 caffe.cpp:313] Batch 812, accuracy/top1 = 0.62
I0802 12:03:14.119630 19007 caffe.cpp:313] Batch 812, accuracy/top5 = 0.86
I0802 12:03:14.119634 19007 caffe.cpp:313] Batch 812, loss = 1.76911
I0802 12:03:14.167529 19007 caffe.cpp:313] Batch 813, accuracy/top1 = 0.58
I0802 12:03:14.167556 19007 caffe.cpp:313] Batch 813, accuracy/top5 = 0.84
I0802 12:03:14.167559 19007 caffe.cpp:313] Batch 813, loss = 1.88082
I0802 12:03:14.217236 19007 caffe.cpp:313] Batch 814, accuracy/top1 = 0.46
I0802 12:03:14.217262 19007 caffe.cpp:313] Batch 814, accuracy/top5 = 0.68
I0802 12:03:14.217265 19007 caffe.cpp:313] Batch 814, loss = 2.58489
I0802 12:03:14.266083 19007 caffe.cpp:313] Batch 815, accuracy/top1 = 0.6
I0802 12:03:14.266108 19007 caffe.cpp:313] Batch 815, accuracy/top5 = 0.88
I0802 12:03:14.266113 19007 caffe.cpp:313] Batch 815, loss = 1.44024
I0802 12:03:14.316109 19007 caffe.cpp:313] Batch 816, accuracy/top1 = 0.56
I0802 12:03:14.316135 19007 caffe.cpp:313] Batch 816, accuracy/top5 = 0.76
I0802 12:03:14.316139 19007 caffe.cpp:313] Batch 816, loss = 2.12703
I0802 12:03:14.364658 19007 caffe.cpp:313] Batch 817, accuracy/top1 = 0.6
I0802 12:03:14.364684 19007 caffe.cpp:313] Batch 817, accuracy/top5 = 0.82
I0802 12:03:14.364688 19007 caffe.cpp:313] Batch 817, loss = 1.60135
I0802 12:03:14.414937 19007 caffe.cpp:313] Batch 818, accuracy/top1 = 0.66
I0802 12:03:14.414958 19007 caffe.cpp:313] Batch 818, accuracy/top5 = 0.9
I0802 12:03:14.414961 19007 caffe.cpp:313] Batch 818, loss = 1.30311
I0802 12:03:14.463126 19007 caffe.cpp:313] Batch 819, accuracy/top1 = 0.68
I0802 12:03:14.463151 19007 caffe.cpp:313] Batch 819, accuracy/top5 = 0.82
I0802 12:03:14.463155 19007 caffe.cpp:313] Batch 819, loss = 1.646
I0802 12:03:14.511425 19007 caffe.cpp:313] Batch 820, accuracy/top1 = 0.48
I0802 12:03:14.511451 19007 caffe.cpp:313] Batch 820, accuracy/top5 = 0.86
I0802 12:03:14.511456 19007 caffe.cpp:313] Batch 820, loss = 2.20263
I0802 12:03:14.559522 19007 caffe.cpp:313] Batch 821, accuracy/top1 = 0.64
I0802 12:03:14.559545 19007 caffe.cpp:313] Batch 821, accuracy/top5 = 0.84
I0802 12:03:14.559550 19007 caffe.cpp:313] Batch 821, loss = 1.69091
I0802 12:03:14.608634 19007 caffe.cpp:313] Batch 822, accuracy/top1 = 0.62
I0802 12:03:14.608655 19007 caffe.cpp:313] Batch 822, accuracy/top5 = 0.84
I0802 12:03:14.608659 19007 caffe.cpp:313] Batch 822, loss = 1.91591
I0802 12:03:14.657265 19007 caffe.cpp:313] Batch 823, accuracy/top1 = 0.66
I0802 12:03:14.657287 19007 caffe.cpp:313] Batch 823, accuracy/top5 = 0.88
I0802 12:03:14.657291 19007 caffe.cpp:313] Batch 823, loss = 1.55427
I0802 12:03:14.705513 19007 caffe.cpp:313] Batch 824, accuracy/top1 = 0.58
I0802 12:03:14.705535 19007 caffe.cpp:313] Batch 824, accuracy/top5 = 0.8
I0802 12:03:14.705538 19007 caffe.cpp:313] Batch 824, loss = 1.76483
I0802 12:03:14.754976 19007 caffe.cpp:313] Batch 825, accuracy/top1 = 0.68
I0802 12:03:14.755000 19007 caffe.cpp:313] Batch 825, accuracy/top5 = 0.8
I0802 12:03:14.755003 19007 caffe.cpp:313] Batch 825, loss = 1.43563
I0802 12:03:14.803763 19007 caffe.cpp:313] Batch 826, accuracy/top1 = 0.66
I0802 12:03:14.803787 19007 caffe.cpp:313] Batch 826, accuracy/top5 = 0.84
I0802 12:03:14.803791 19007 caffe.cpp:313] Batch 826, loss = 1.65162
I0802 12:03:14.853204 19007 caffe.cpp:313] Batch 827, accuracy/top1 = 0.66
I0802 12:03:14.853229 19007 caffe.cpp:313] Batch 827, accuracy/top5 = 0.9
I0802 12:03:14.853231 19007 caffe.cpp:313] Batch 827, loss = 1.31343
I0802 12:03:14.902916 19007 caffe.cpp:313] Batch 828, accuracy/top1 = 0.56
I0802 12:03:14.902940 19007 caffe.cpp:313] Batch 828, accuracy/top5 = 0.78
I0802 12:03:14.902943 19007 caffe.cpp:313] Batch 828, loss = 2.0015
I0802 12:03:14.951315 19007 caffe.cpp:313] Batch 829, accuracy/top1 = 0.5
I0802 12:03:14.951341 19007 caffe.cpp:313] Batch 829, accuracy/top5 = 0.74
I0802 12:03:14.951344 19007 caffe.cpp:313] Batch 829, loss = 2.53497
I0802 12:03:15.001171 19007 caffe.cpp:313] Batch 830, accuracy/top1 = 0.64
I0802 12:03:15.001196 19007 caffe.cpp:313] Batch 830, accuracy/top5 = 0.88
I0802 12:03:15.001199 19007 caffe.cpp:313] Batch 830, loss = 1.48249
I0802 12:03:15.050513 19007 caffe.cpp:313] Batch 831, accuracy/top1 = 0.6
I0802 12:03:15.050542 19007 caffe.cpp:313] Batch 831, accuracy/top5 = 0.84
I0802 12:03:15.050546 19007 caffe.cpp:313] Batch 831, loss = 1.53143
I0802 12:03:15.100837 19007 caffe.cpp:313] Batch 832, accuracy/top1 = 0.56
I0802 12:03:15.100852 19007 caffe.cpp:313] Batch 832, accuracy/top5 = 0.84
I0802 12:03:15.100855 19007 caffe.cpp:313] Batch 832, loss = 1.7228
I0802 12:03:15.150759 19007 caffe.cpp:313] Batch 833, accuracy/top1 = 0.6
I0802 12:03:15.150784 19007 caffe.cpp:313] Batch 833, accuracy/top5 = 0.82
I0802 12:03:15.150787 19007 caffe.cpp:313] Batch 833, loss = 1.63519
I0802 12:03:15.199280 19007 caffe.cpp:313] Batch 834, accuracy/top1 = 0.58
I0802 12:03:15.199306 19007 caffe.cpp:313] Batch 834, accuracy/top5 = 0.82
I0802 12:03:15.199308 19007 caffe.cpp:313] Batch 834, loss = 1.99648
I0802 12:03:15.248651 19007 caffe.cpp:313] Batch 835, accuracy/top1 = 0.54
I0802 12:03:15.248675 19007 caffe.cpp:313] Batch 835, accuracy/top5 = 0.8
I0802 12:03:15.248678 19007 caffe.cpp:313] Batch 835, loss = 1.91577
I0802 12:03:15.297037 19007 caffe.cpp:313] Batch 836, accuracy/top1 = 0.64
I0802 12:03:15.297062 19007 caffe.cpp:313] Batch 836, accuracy/top5 = 0.82
I0802 12:03:15.297066 19007 caffe.cpp:313] Batch 836, loss = 1.63121
I0802 12:03:15.346632 19007 caffe.cpp:313] Batch 837, accuracy/top1 = 0.68
I0802 12:03:15.346657 19007 caffe.cpp:313] Batch 837, accuracy/top5 = 0.98
I0802 12:03:15.346659 19007 caffe.cpp:313] Batch 837, loss = 1.19174
I0802 12:03:15.395730 19007 caffe.cpp:313] Batch 838, accuracy/top1 = 0.54
I0802 12:03:15.395754 19007 caffe.cpp:313] Batch 838, accuracy/top5 = 0.8
I0802 12:03:15.395757 19007 caffe.cpp:313] Batch 838, loss = 1.89885
I0802 12:03:15.443549 19007 caffe.cpp:313] Batch 839, accuracy/top1 = 0.6
I0802 12:03:15.443573 19007 caffe.cpp:313] Batch 839, accuracy/top5 = 0.78
I0802 12:03:15.443577 19007 caffe.cpp:313] Batch 839, loss = 1.85144
I0802 12:03:15.492924 19007 caffe.cpp:313] Batch 840, accuracy/top1 = 0.64
I0802 12:03:15.492949 19007 caffe.cpp:313] Batch 840, accuracy/top5 = 0.8
I0802 12:03:15.492951 19007 caffe.cpp:313] Batch 840, loss = 1.69496
I0802 12:03:15.542044 19007 caffe.cpp:313] Batch 841, accuracy/top1 = 0.62
I0802 12:03:15.542068 19007 caffe.cpp:313] Batch 841, accuracy/top5 = 0.82
I0802 12:03:15.542070 19007 caffe.cpp:313] Batch 841, loss = 1.71232
I0802 12:03:15.591370 19007 caffe.cpp:313] Batch 842, accuracy/top1 = 0.6
I0802 12:03:15.591394 19007 caffe.cpp:313] Batch 842, accuracy/top5 = 0.86
I0802 12:03:15.591398 19007 caffe.cpp:313] Batch 842, loss = 1.524
I0802 12:03:15.639430 19007 caffe.cpp:313] Batch 843, accuracy/top1 = 0.6
I0802 12:03:15.639454 19007 caffe.cpp:313] Batch 843, accuracy/top5 = 0.88
I0802 12:03:15.639457 19007 caffe.cpp:313] Batch 843, loss = 1.64134
I0802 12:03:15.687407 19007 caffe.cpp:313] Batch 844, accuracy/top1 = 0.74
I0802 12:03:15.687433 19007 caffe.cpp:313] Batch 844, accuracy/top5 = 0.94
I0802 12:03:15.687435 19007 caffe.cpp:313] Batch 844, loss = 1.22458
I0802 12:03:15.736255 19007 caffe.cpp:313] Batch 845, accuracy/top1 = 0.68
I0802 12:03:15.736279 19007 caffe.cpp:313] Batch 845, accuracy/top5 = 0.88
I0802 12:03:15.736282 19007 caffe.cpp:313] Batch 845, loss = 1.67445
I0802 12:03:15.785531 19007 caffe.cpp:313] Batch 846, accuracy/top1 = 0.62
I0802 12:03:15.785558 19007 caffe.cpp:313] Batch 846, accuracy/top5 = 0.86
I0802 12:03:15.785562 19007 caffe.cpp:313] Batch 846, loss = 1.814
I0802 12:03:15.835281 19007 caffe.cpp:313] Batch 847, accuracy/top1 = 0.54
I0802 12:03:15.835305 19007 caffe.cpp:313] Batch 847, accuracy/top5 = 0.72
I0802 12:03:15.835309 19007 caffe.cpp:313] Batch 847, loss = 2.37415
I0802 12:03:15.884891 19007 caffe.cpp:313] Batch 848, accuracy/top1 = 0.6
I0802 12:03:15.884915 19007 caffe.cpp:313] Batch 848, accuracy/top5 = 0.86
I0802 12:03:15.884918 19007 caffe.cpp:313] Batch 848, loss = 1.93164
I0802 12:03:15.933918 19007 caffe.cpp:313] Batch 849, accuracy/top1 = 0.62
I0802 12:03:15.933941 19007 caffe.cpp:313] Batch 849, accuracy/top5 = 0.88
I0802 12:03:15.933944 19007 caffe.cpp:313] Batch 849, loss = 1.4167
I0802 12:03:15.983005 19007 caffe.cpp:313] Batch 850, accuracy/top1 = 0.68
I0802 12:03:15.983029 19007 caffe.cpp:313] Batch 850, accuracy/top5 = 0.82
I0802 12:03:15.983032 19007 caffe.cpp:313] Batch 850, loss = 1.59136
I0802 12:03:16.032086 19007 caffe.cpp:313] Batch 851, accuracy/top1 = 0.52
I0802 12:03:16.032109 19007 caffe.cpp:313] Batch 851, accuracy/top5 = 0.84
I0802 12:03:16.032114 19007 caffe.cpp:313] Batch 851, loss = 1.92348
I0802 12:03:16.081363 19007 caffe.cpp:313] Batch 852, accuracy/top1 = 0.6
I0802 12:03:16.081379 19007 caffe.cpp:313] Batch 852, accuracy/top5 = 0.86
I0802 12:03:16.081382 19007 caffe.cpp:313] Batch 852, loss = 1.60073
I0802 12:03:16.131749 19007 caffe.cpp:313] Batch 853, accuracy/top1 = 0.72
I0802 12:03:16.131772 19007 caffe.cpp:313] Batch 853, accuracy/top5 = 0.88
I0802 12:03:16.131775 19007 caffe.cpp:313] Batch 853, loss = 1.45063
I0802 12:03:16.180824 19007 caffe.cpp:313] Batch 854, accuracy/top1 = 0.68
I0802 12:03:16.180850 19007 caffe.cpp:313] Batch 854, accuracy/top5 = 0.86
I0802 12:03:16.180852 19007 caffe.cpp:313] Batch 854, loss = 1.57396
I0802 12:03:16.229928 19007 caffe.cpp:313] Batch 855, accuracy/top1 = 0.48
I0802 12:03:16.229953 19007 caffe.cpp:313] Batch 855, accuracy/top5 = 0.78
I0802 12:03:16.229955 19007 caffe.cpp:313] Batch 855, loss = 2.25727
I0802 12:03:16.280128 19007 caffe.cpp:313] Batch 856, accuracy/top1 = 0.46
I0802 12:03:16.280151 19007 caffe.cpp:313] Batch 856, accuracy/top5 = 0.82
I0802 12:03:16.280154 19007 caffe.cpp:313] Batch 856, loss = 2.09333
I0802 12:03:16.328542 19007 caffe.cpp:313] Batch 857, accuracy/top1 = 0.64
I0802 12:03:16.328567 19007 caffe.cpp:313] Batch 857, accuracy/top5 = 0.9
I0802 12:03:16.328569 19007 caffe.cpp:313] Batch 857, loss = 1.44747
I0802 12:03:16.376380 19007 caffe.cpp:313] Batch 858, accuracy/top1 = 0.62
I0802 12:03:16.376408 19007 caffe.cpp:313] Batch 858, accuracy/top5 = 0.9
I0802 12:03:16.376411 19007 caffe.cpp:313] Batch 858, loss = 1.33668
I0802 12:03:16.425864 19007 caffe.cpp:313] Batch 859, accuracy/top1 = 0.62
I0802 12:03:16.425889 19007 caffe.cpp:313] Batch 859, accuracy/top5 = 0.8
I0802 12:03:16.425891 19007 caffe.cpp:313] Batch 859, loss = 1.69508
I0802 12:03:16.476145 19007 caffe.cpp:313] Batch 860, accuracy/top1 = 0.64
I0802 12:03:16.476167 19007 caffe.cpp:313] Batch 860, accuracy/top5 = 0.76
I0802 12:03:16.476171 19007 caffe.cpp:313] Batch 860, loss = 1.82889
I0802 12:03:16.524953 19007 caffe.cpp:313] Batch 861, accuracy/top1 = 0.7
I0802 12:03:16.524969 19007 caffe.cpp:313] Batch 861, accuracy/top5 = 0.8
I0802 12:03:16.524972 19007 caffe.cpp:313] Batch 861, loss = 1.44922
I0802 12:03:16.574462 19007 caffe.cpp:313] Batch 862, accuracy/top1 = 0.48
I0802 12:03:16.574486 19007 caffe.cpp:313] Batch 862, accuracy/top5 = 0.84
I0802 12:03:16.574489 19007 caffe.cpp:313] Batch 862, loss = 1.81904
I0802 12:03:16.622576 19007 caffe.cpp:313] Batch 863, accuracy/top1 = 0.64
I0802 12:03:16.622601 19007 caffe.cpp:313] Batch 863, accuracy/top5 = 0.76
I0802 12:03:16.622604 19007 caffe.cpp:313] Batch 863, loss = 1.61194
I0802 12:03:16.670413 19007 caffe.cpp:313] Batch 864, accuracy/top1 = 0.68
I0802 12:03:16.670439 19007 caffe.cpp:313] Batch 864, accuracy/top5 = 0.9
I0802 12:03:16.670441 19007 caffe.cpp:313] Batch 864, loss = 1.49764
I0802 12:03:16.720301 19007 caffe.cpp:313] Batch 865, accuracy/top1 = 0.56
I0802 12:03:16.720322 19007 caffe.cpp:313] Batch 865, accuracy/top5 = 0.84
I0802 12:03:16.720325 19007 caffe.cpp:313] Batch 865, loss = 1.82244
I0802 12:03:16.768601 19007 caffe.cpp:313] Batch 866, accuracy/top1 = 0.7
I0802 12:03:16.768623 19007 caffe.cpp:313] Batch 866, accuracy/top5 = 0.86
I0802 12:03:16.768626 19007 caffe.cpp:313] Batch 866, loss = 1.37756
I0802 12:03:16.819111 19007 caffe.cpp:313] Batch 867, accuracy/top1 = 0.58
I0802 12:03:16.819133 19007 caffe.cpp:313] Batch 867, accuracy/top5 = 0.78
I0802 12:03:16.819135 19007 caffe.cpp:313] Batch 867, loss = 2.04739
I0802 12:03:16.869067 19007 caffe.cpp:313] Batch 868, accuracy/top1 = 0.64
I0802 12:03:16.869092 19007 caffe.cpp:313] Batch 868, accuracy/top5 = 0.8
I0802 12:03:16.869110 19007 caffe.cpp:313] Batch 868, loss = 1.7956
I0802 12:03:16.917095 19007 caffe.cpp:313] Batch 869, accuracy/top1 = 0.52
I0802 12:03:16.917119 19007 caffe.cpp:313] Batch 869, accuracy/top5 = 0.88
I0802 12:03:16.917122 19007 caffe.cpp:313] Batch 869, loss = 1.74823
I0802 12:03:16.965618 19007 caffe.cpp:313] Batch 870, accuracy/top1 = 0.46
I0802 12:03:16.965642 19007 caffe.cpp:313] Batch 870, accuracy/top5 = 0.74
I0802 12:03:16.965646 19007 caffe.cpp:313] Batch 870, loss = 2.13352
I0802 12:03:17.015933 19007 caffe.cpp:313] Batch 871, accuracy/top1 = 0.66
I0802 12:03:17.015959 19007 caffe.cpp:313] Batch 871, accuracy/top5 = 0.9
I0802 12:03:17.015962 19007 caffe.cpp:313] Batch 871, loss = 1.24916
I0802 12:03:17.064240 19007 caffe.cpp:313] Batch 872, accuracy/top1 = 0.56
I0802 12:03:17.064260 19007 caffe.cpp:313] Batch 872, accuracy/top5 = 0.76
I0802 12:03:17.064262 19007 caffe.cpp:313] Batch 872, loss = 1.90427
I0802 12:03:17.113740 19007 caffe.cpp:313] Batch 873, accuracy/top1 = 0.64
I0802 12:03:17.113766 19007 caffe.cpp:313] Batch 873, accuracy/top5 = 0.84
I0802 12:03:17.113770 19007 caffe.cpp:313] Batch 873, loss = 1.6687
I0802 12:03:17.163139 19007 caffe.cpp:313] Batch 874, accuracy/top1 = 0.68
I0802 12:03:17.163166 19007 caffe.cpp:313] Batch 874, accuracy/top5 = 0.86
I0802 12:03:17.163168 19007 caffe.cpp:313] Batch 874, loss = 1.55746
I0802 12:03:17.213088 19007 caffe.cpp:313] Batch 875, accuracy/top1 = 0.78
I0802 12:03:17.213111 19007 caffe.cpp:313] Batch 875, accuracy/top5 = 0.92
I0802 12:03:17.213114 19007 caffe.cpp:313] Batch 875, loss = 1.12675
I0802 12:03:17.262042 19007 caffe.cpp:313] Batch 876, accuracy/top1 = 0.68
I0802 12:03:17.262068 19007 caffe.cpp:313] Batch 876, accuracy/top5 = 0.88
I0802 12:03:17.262070 19007 caffe.cpp:313] Batch 876, loss = 1.53235
I0802 12:03:17.312270 19007 caffe.cpp:313] Batch 877, accuracy/top1 = 0.68
I0802 12:03:17.312294 19007 caffe.cpp:313] Batch 877, accuracy/top5 = 0.88
I0802 12:03:17.312297 19007 caffe.cpp:313] Batch 877, loss = 1.6647
I0802 12:03:17.360401 19007 caffe.cpp:313] Batch 878, accuracy/top1 = 0.5
I0802 12:03:17.360427 19007 caffe.cpp:313] Batch 878, accuracy/top5 = 0.72
I0802 12:03:17.360430 19007 caffe.cpp:313] Batch 878, loss = 2.23058
I0802 12:03:17.410485 19007 caffe.cpp:313] Batch 879, accuracy/top1 = 0.68
I0802 12:03:17.410509 19007 caffe.cpp:313] Batch 879, accuracy/top5 = 0.86
I0802 12:03:17.410513 19007 caffe.cpp:313] Batch 879, loss = 1.24299
I0802 12:03:17.459363 19007 caffe.cpp:313] Batch 880, accuracy/top1 = 0.58
I0802 12:03:17.459388 19007 caffe.cpp:313] Batch 880, accuracy/top5 = 0.86
I0802 12:03:17.459391 19007 caffe.cpp:313] Batch 880, loss = 1.3114
I0802 12:03:17.508731 19007 caffe.cpp:313] Batch 881, accuracy/top1 = 0.58
I0802 12:03:17.508747 19007 caffe.cpp:313] Batch 881, accuracy/top5 = 0.8
I0802 12:03:17.508750 19007 caffe.cpp:313] Batch 881, loss = 1.64956
I0802 12:03:17.558578 19007 caffe.cpp:313] Batch 882, accuracy/top1 = 0.62
I0802 12:03:17.558600 19007 caffe.cpp:313] Batch 882, accuracy/top5 = 0.84
I0802 12:03:17.558604 19007 caffe.cpp:313] Batch 882, loss = 1.62047
I0802 12:03:17.608325 19007 caffe.cpp:313] Batch 883, accuracy/top1 = 0.64
I0802 12:03:17.608350 19007 caffe.cpp:313] Batch 883, accuracy/top5 = 0.82
I0802 12:03:17.608352 19007 caffe.cpp:313] Batch 883, loss = 1.76154
I0802 12:03:17.657304 19007 caffe.cpp:313] Batch 884, accuracy/top1 = 0.44
I0802 12:03:17.657327 19007 caffe.cpp:313] Batch 884, accuracy/top5 = 0.7
I0802 12:03:17.657331 19007 caffe.cpp:313] Batch 884, loss = 2.42162
I0802 12:03:17.706068 19007 caffe.cpp:313] Batch 885, accuracy/top1 = 0.64
I0802 12:03:17.706092 19007 caffe.cpp:313] Batch 885, accuracy/top5 = 0.84
I0802 12:03:17.706095 19007 caffe.cpp:313] Batch 885, loss = 1.55119
I0802 12:03:17.754669 19007 caffe.cpp:313] Batch 886, accuracy/top1 = 0.6
I0802 12:03:17.754694 19007 caffe.cpp:313] Batch 886, accuracy/top5 = 0.74
I0802 12:03:17.754698 19007 caffe.cpp:313] Batch 886, loss = 1.82211
I0802 12:03:17.804051 19007 caffe.cpp:313] Batch 887, accuracy/top1 = 0.6
I0802 12:03:17.804093 19007 caffe.cpp:313] Batch 887, accuracy/top5 = 0.76
I0802 12:03:17.804097 19007 caffe.cpp:313] Batch 887, loss = 1.84007
I0802 12:03:17.853983 19007 caffe.cpp:313] Batch 888, accuracy/top1 = 0.54
I0802 12:03:17.854008 19007 caffe.cpp:313] Batch 888, accuracy/top5 = 0.76
I0802 12:03:17.854012 19007 caffe.cpp:313] Batch 888, loss = 2.04496
I0802 12:03:17.903658 19007 caffe.cpp:313] Batch 889, accuracy/top1 = 0.7
I0802 12:03:17.903682 19007 caffe.cpp:313] Batch 889, accuracy/top5 = 0.86
I0802 12:03:17.903687 19007 caffe.cpp:313] Batch 889, loss = 1.50197
I0802 12:03:17.951833 19007 caffe.cpp:313] Batch 890, accuracy/top1 = 0.5
I0802 12:03:17.951858 19007 caffe.cpp:313] Batch 890, accuracy/top5 = 0.8
I0802 12:03:17.951860 19007 caffe.cpp:313] Batch 890, loss = 2.34948
I0802 12:03:18.001919 19007 caffe.cpp:313] Batch 891, accuracy/top1 = 0.68
I0802 12:03:18.001945 19007 caffe.cpp:313] Batch 891, accuracy/top5 = 0.86
I0802 12:03:18.001947 19007 caffe.cpp:313] Batch 891, loss = 1.6438
I0802 12:03:18.050705 19007 caffe.cpp:313] Batch 892, accuracy/top1 = 0.52
I0802 12:03:18.050722 19007 caffe.cpp:313] Batch 892, accuracy/top5 = 0.88
I0802 12:03:18.050725 19007 caffe.cpp:313] Batch 892, loss = 1.65332
I0802 12:03:18.100256 19007 caffe.cpp:313] Batch 893, accuracy/top1 = 0.6
I0802 12:03:18.100270 19007 caffe.cpp:313] Batch 893, accuracy/top5 = 0.86
I0802 12:03:18.100273 19007 caffe.cpp:313] Batch 893, loss = 1.61371
I0802 12:03:18.150419 19007 caffe.cpp:313] Batch 894, accuracy/top1 = 0.54
I0802 12:03:18.150444 19007 caffe.cpp:313] Batch 894, accuracy/top5 = 0.78
I0802 12:03:18.150449 19007 caffe.cpp:313] Batch 894, loss = 2.05828
I0802 12:03:18.200458 19007 caffe.cpp:313] Batch 895, accuracy/top1 = 0.78
I0802 12:03:18.200482 19007 caffe.cpp:313] Batch 895, accuracy/top5 = 0.9
I0802 12:03:18.200485 19007 caffe.cpp:313] Batch 895, loss = 1.00513
I0802 12:03:18.249177 19007 caffe.cpp:313] Batch 896, accuracy/top1 = 0.48
I0802 12:03:18.249202 19007 caffe.cpp:313] Batch 896, accuracy/top5 = 0.72
I0802 12:03:18.249205 19007 caffe.cpp:313] Batch 896, loss = 2.0659
I0802 12:03:18.298207 19007 caffe.cpp:313] Batch 897, accuracy/top1 = 0.48
I0802 12:03:18.298233 19007 caffe.cpp:313] Batch 897, accuracy/top5 = 0.82
I0802 12:03:18.298235 19007 caffe.cpp:313] Batch 897, loss = 1.92336
I0802 12:03:18.347839 19007 caffe.cpp:313] Batch 898, accuracy/top1 = 0.64
I0802 12:03:18.347862 19007 caffe.cpp:313] Batch 898, accuracy/top5 = 0.88
I0802 12:03:18.347864 19007 caffe.cpp:313] Batch 898, loss = 1.55376
I0802 12:03:18.397066 19007 caffe.cpp:313] Batch 899, accuracy/top1 = 0.64
I0802 12:03:18.397092 19007 caffe.cpp:313] Batch 899, accuracy/top5 = 0.86
I0802 12:03:18.397095 19007 caffe.cpp:313] Batch 899, loss = 1.57788
I0802 12:03:18.446838 19007 caffe.cpp:313] Batch 900, accuracy/top1 = 0.74
I0802 12:03:18.446862 19007 caffe.cpp:313] Batch 900, accuracy/top5 = 0.92
I0802 12:03:18.446866 19007 caffe.cpp:313] Batch 900, loss = 1.11723
I0802 12:03:18.496528 19007 caffe.cpp:313] Batch 901, accuracy/top1 = 0.54
I0802 12:03:18.496549 19007 caffe.cpp:313] Batch 901, accuracy/top5 = 0.7
I0802 12:03:18.496552 19007 caffe.cpp:313] Batch 901, loss = 2.00055
I0802 12:03:18.546038 19007 caffe.cpp:313] Batch 902, accuracy/top1 = 0.56
I0802 12:03:18.546062 19007 caffe.cpp:313] Batch 902, accuracy/top5 = 0.76
I0802 12:03:18.546066 19007 caffe.cpp:313] Batch 902, loss = 1.80218
I0802 12:03:18.595489 19007 caffe.cpp:313] Batch 903, accuracy/top1 = 0.6
I0802 12:03:18.595512 19007 caffe.cpp:313] Batch 903, accuracy/top5 = 0.86
I0802 12:03:18.595516 19007 caffe.cpp:313] Batch 903, loss = 1.3531
I0802 12:03:18.644340 19007 caffe.cpp:313] Batch 904, accuracy/top1 = 0.68
I0802 12:03:18.644364 19007 caffe.cpp:313] Batch 904, accuracy/top5 = 0.88
I0802 12:03:18.644367 19007 caffe.cpp:313] Batch 904, loss = 1.24495
I0802 12:03:18.692888 19007 caffe.cpp:313] Batch 905, accuracy/top1 = 0.64
I0802 12:03:18.692914 19007 caffe.cpp:313] Batch 905, accuracy/top5 = 0.84
I0802 12:03:18.692916 19007 caffe.cpp:313] Batch 905, loss = 1.49953
I0802 12:03:18.740790 19007 caffe.cpp:313] Batch 906, accuracy/top1 = 0.66
I0802 12:03:18.740833 19007 caffe.cpp:313] Batch 906, accuracy/top5 = 0.82
I0802 12:03:18.740838 19007 caffe.cpp:313] Batch 906, loss = 1.56358
I0802 12:03:18.789896 19007 caffe.cpp:313] Batch 907, accuracy/top1 = 0.54
I0802 12:03:18.789921 19007 caffe.cpp:313] Batch 907, accuracy/top5 = 0.84
I0802 12:03:18.789925 19007 caffe.cpp:313] Batch 907, loss = 1.85031
I0802 12:03:18.839747 19007 caffe.cpp:313] Batch 908, accuracy/top1 = 0.52
I0802 12:03:18.839768 19007 caffe.cpp:313] Batch 908, accuracy/top5 = 0.84
I0802 12:03:18.839771 19007 caffe.cpp:313] Batch 908, loss = 1.80106
I0802 12:03:18.889428 19007 caffe.cpp:313] Batch 909, accuracy/top1 = 0.64
I0802 12:03:18.889449 19007 caffe.cpp:313] Batch 909, accuracy/top5 = 0.84
I0802 12:03:18.889452 19007 caffe.cpp:313] Batch 909, loss = 1.30783
I0802 12:03:18.937144 19007 caffe.cpp:313] Batch 910, accuracy/top1 = 0.5
I0802 12:03:18.937163 19007 caffe.cpp:313] Batch 910, accuracy/top5 = 0.82
I0802 12:03:18.937166 19007 caffe.cpp:313] Batch 910, loss = 2.05376
I0802 12:03:18.984853 19007 caffe.cpp:313] Batch 911, accuracy/top1 = 0.6
I0802 12:03:18.984879 19007 caffe.cpp:313] Batch 911, accuracy/top5 = 0.8
I0802 12:03:18.984881 19007 caffe.cpp:313] Batch 911, loss = 1.78889
I0802 12:03:19.032778 19007 caffe.cpp:313] Batch 912, accuracy/top1 = 0.6
I0802 12:03:19.032802 19007 caffe.cpp:313] Batch 912, accuracy/top5 = 0.84
I0802 12:03:19.032805 19007 caffe.cpp:313] Batch 912, loss = 1.65451
I0802 12:03:19.080657 19007 caffe.cpp:313] Batch 913, accuracy/top1 = 0.56
I0802 12:03:19.080672 19007 caffe.cpp:313] Batch 913, accuracy/top5 = 0.78
I0802 12:03:19.080675 19007 caffe.cpp:313] Batch 913, loss = 1.7977
I0802 12:03:19.130342 19007 caffe.cpp:313] Batch 914, accuracy/top1 = 0.54
I0802 12:03:19.130367 19007 caffe.cpp:313] Batch 914, accuracy/top5 = 0.8
I0802 12:03:19.130370 19007 caffe.cpp:313] Batch 914, loss = 2.20143
I0802 12:03:19.179227 19007 caffe.cpp:313] Batch 915, accuracy/top1 = 0.6
I0802 12:03:19.179252 19007 caffe.cpp:313] Batch 915, accuracy/top5 = 0.8
I0802 12:03:19.179255 19007 caffe.cpp:313] Batch 915, loss = 1.54346
I0802 12:03:19.228088 19007 caffe.cpp:313] Batch 916, accuracy/top1 = 0.72
I0802 12:03:19.228114 19007 caffe.cpp:313] Batch 916, accuracy/top5 = 0.88
I0802 12:03:19.228117 19007 caffe.cpp:313] Batch 916, loss = 1.32072
I0802 12:03:19.277521 19007 caffe.cpp:313] Batch 917, accuracy/top1 = 0.72
I0802 12:03:19.277546 19007 caffe.cpp:313] Batch 917, accuracy/top5 = 0.84
I0802 12:03:19.277549 19007 caffe.cpp:313] Batch 917, loss = 1.49084
I0802 12:03:19.327328 19007 caffe.cpp:313] Batch 918, accuracy/top1 = 0.6
I0802 12:03:19.327353 19007 caffe.cpp:313] Batch 918, accuracy/top5 = 0.78
I0802 12:03:19.327356 19007 caffe.cpp:313] Batch 918, loss = 1.81876
I0802 12:03:19.376466 19007 caffe.cpp:313] Batch 919, accuracy/top1 = 0.56
I0802 12:03:19.376492 19007 caffe.cpp:313] Batch 919, accuracy/top5 = 0.76
I0802 12:03:19.376497 19007 caffe.cpp:313] Batch 919, loss = 2.34012
I0802 12:03:19.425297 19007 caffe.cpp:313] Batch 920, accuracy/top1 = 0.62
I0802 12:03:19.425323 19007 caffe.cpp:313] Batch 920, accuracy/top5 = 0.82
I0802 12:03:19.425326 19007 caffe.cpp:313] Batch 920, loss = 1.82101
I0802 12:03:19.475867 19007 caffe.cpp:313] Batch 921, accuracy/top1 = 0.54
I0802 12:03:19.475893 19007 caffe.cpp:313] Batch 921, accuracy/top5 = 0.84
I0802 12:03:19.475895 19007 caffe.cpp:313] Batch 921, loss = 1.64093
I0802 12:03:19.524354 19007 caffe.cpp:313] Batch 922, accuracy/top1 = 0.68
I0802 12:03:19.524379 19007 caffe.cpp:313] Batch 922, accuracy/top5 = 0.88
I0802 12:03:19.524382 19007 caffe.cpp:313] Batch 922, loss = 1.20972
I0802 12:03:19.573999 19007 caffe.cpp:313] Batch 923, accuracy/top1 = 0.68
I0802 12:03:19.574021 19007 caffe.cpp:313] Batch 923, accuracy/top5 = 0.82
I0802 12:03:19.574024 19007 caffe.cpp:313] Batch 923, loss = 1.83827
I0802 12:03:19.623672 19007 caffe.cpp:313] Batch 924, accuracy/top1 = 0.66
I0802 12:03:19.623697 19007 caffe.cpp:313] Batch 924, accuracy/top5 = 0.88
I0802 12:03:19.623700 19007 caffe.cpp:313] Batch 924, loss = 1.27296
I0802 12:03:19.672602 19007 caffe.cpp:313] Batch 925, accuracy/top1 = 0.48
I0802 12:03:19.672626 19007 caffe.cpp:313] Batch 925, accuracy/top5 = 0.78
I0802 12:03:19.672629 19007 caffe.cpp:313] Batch 925, loss = 1.9615
I0802 12:03:19.721688 19007 caffe.cpp:313] Batch 926, accuracy/top1 = 0.58
I0802 12:03:19.721714 19007 caffe.cpp:313] Batch 926, accuracy/top5 = 0.76
I0802 12:03:19.721716 19007 caffe.cpp:313] Batch 926, loss = 1.90353
I0802 12:03:19.769074 19007 caffe.cpp:313] Batch 927, accuracy/top1 = 0.54
I0802 12:03:19.769101 19007 caffe.cpp:313] Batch 927, accuracy/top5 = 0.74
I0802 12:03:19.769104 19007 caffe.cpp:313] Batch 927, loss = 2.0955
I0802 12:03:19.816715 19007 caffe.cpp:313] Batch 928, accuracy/top1 = 0.7
I0802 12:03:19.816740 19007 caffe.cpp:313] Batch 928, accuracy/top5 = 0.9
I0802 12:03:19.816742 19007 caffe.cpp:313] Batch 928, loss = 1.25835
I0802 12:03:19.865203 19007 caffe.cpp:313] Batch 929, accuracy/top1 = 0.58
I0802 12:03:19.865227 19007 caffe.cpp:313] Batch 929, accuracy/top5 = 0.82
I0802 12:03:19.865231 19007 caffe.cpp:313] Batch 929, loss = 1.6839
I0802 12:03:19.913543 19007 caffe.cpp:313] Batch 930, accuracy/top1 = 0.62
I0802 12:03:19.913568 19007 caffe.cpp:313] Batch 930, accuracy/top5 = 0.76
I0802 12:03:19.913571 19007 caffe.cpp:313] Batch 930, loss = 1.80931
I0802 12:03:19.962308 19007 caffe.cpp:313] Batch 931, accuracy/top1 = 0.58
I0802 12:03:19.962334 19007 caffe.cpp:313] Batch 931, accuracy/top5 = 0.84
I0802 12:03:19.962337 19007 caffe.cpp:313] Batch 931, loss = 2.07813
I0802 12:03:20.010761 19007 caffe.cpp:313] Batch 932, accuracy/top1 = 0.64
I0802 12:03:20.010787 19007 caffe.cpp:313] Batch 932, accuracy/top5 = 0.82
I0802 12:03:20.010789 19007 caffe.cpp:313] Batch 932, loss = 1.5075
I0802 12:03:20.059562 19007 caffe.cpp:313] Batch 933, accuracy/top1 = 0.58
I0802 12:03:20.059587 19007 caffe.cpp:313] Batch 933, accuracy/top5 = 0.8
I0802 12:03:20.059590 19007 caffe.cpp:313] Batch 933, loss = 2.1957
I0802 12:03:20.108610 19007 caffe.cpp:313] Batch 934, accuracy/top1 = 0.58
I0802 12:03:20.108624 19007 caffe.cpp:313] Batch 934, accuracy/top5 = 0.8
I0802 12:03:20.108628 19007 caffe.cpp:313] Batch 934, loss = 1.69134
I0802 12:03:20.156461 19007 caffe.cpp:313] Batch 935, accuracy/top1 = 0.6
I0802 12:03:20.156486 19007 caffe.cpp:313] Batch 935, accuracy/top5 = 0.78
I0802 12:03:20.156489 19007 caffe.cpp:313] Batch 935, loss = 2.19298
I0802 12:03:20.204085 19007 caffe.cpp:313] Batch 936, accuracy/top1 = 0.66
I0802 12:03:20.204110 19007 caffe.cpp:313] Batch 936, accuracy/top5 = 0.9
I0802 12:03:20.204114 19007 caffe.cpp:313] Batch 936, loss = 1.63122
I0802 12:03:20.253170 19007 caffe.cpp:313] Batch 937, accuracy/top1 = 0.62
I0802 12:03:20.253193 19007 caffe.cpp:313] Batch 937, accuracy/top5 = 0.9
I0802 12:03:20.253196 19007 caffe.cpp:313] Batch 937, loss = 1.59726
I0802 12:03:20.300902 19007 caffe.cpp:313] Batch 938, accuracy/top1 = 0.52
I0802 12:03:20.300926 19007 caffe.cpp:313] Batch 938, accuracy/top5 = 0.86
I0802 12:03:20.300930 19007 caffe.cpp:313] Batch 938, loss = 1.9431
I0802 12:03:20.348582 19007 caffe.cpp:313] Batch 939, accuracy/top1 = 0.6
I0802 12:03:20.348606 19007 caffe.cpp:313] Batch 939, accuracy/top5 = 0.86
I0802 12:03:20.348610 19007 caffe.cpp:313] Batch 939, loss = 1.69169
I0802 12:03:20.396481 19007 caffe.cpp:313] Batch 940, accuracy/top1 = 0.58
I0802 12:03:20.396504 19007 caffe.cpp:313] Batch 940, accuracy/top5 = 0.88
I0802 12:03:20.396507 19007 caffe.cpp:313] Batch 940, loss = 1.73594
I0802 12:03:20.444772 19007 caffe.cpp:313] Batch 941, accuracy/top1 = 0.64
I0802 12:03:20.444797 19007 caffe.cpp:313] Batch 941, accuracy/top5 = 0.8
I0802 12:03:20.444800 19007 caffe.cpp:313] Batch 941, loss = 1.73409
I0802 12:03:20.492741 19007 caffe.cpp:313] Batch 942, accuracy/top1 = 0.5
I0802 12:03:20.492766 19007 caffe.cpp:313] Batch 942, accuracy/top5 = 0.82
I0802 12:03:20.492769 19007 caffe.cpp:313] Batch 942, loss = 1.90237
I0802 12:03:20.540400 19007 caffe.cpp:313] Batch 943, accuracy/top1 = 0.64
I0802 12:03:20.540421 19007 caffe.cpp:313] Batch 943, accuracy/top5 = 0.88
I0802 12:03:20.540436 19007 caffe.cpp:313] Batch 943, loss = 1.50369
I0802 12:03:20.588847 19007 caffe.cpp:313] Batch 944, accuracy/top1 = 0.64
I0802 12:03:20.588874 19007 caffe.cpp:313] Batch 944, accuracy/top5 = 0.88
I0802 12:03:20.588877 19007 caffe.cpp:313] Batch 944, loss = 1.54512
I0802 12:03:20.637614 19007 caffe.cpp:313] Batch 945, accuracy/top1 = 0.56
I0802 12:03:20.637637 19007 caffe.cpp:313] Batch 945, accuracy/top5 = 0.76
I0802 12:03:20.637640 19007 caffe.cpp:313] Batch 945, loss = 2.1567
I0802 12:03:20.685947 19007 caffe.cpp:313] Batch 946, accuracy/top1 = 0.54
I0802 12:03:20.685973 19007 caffe.cpp:313] Batch 946, accuracy/top5 = 0.82
I0802 12:03:20.685976 19007 caffe.cpp:313] Batch 946, loss = 1.97176
I0802 12:03:20.735735 19007 caffe.cpp:313] Batch 947, accuracy/top1 = 0.6
I0802 12:03:20.735759 19007 caffe.cpp:313] Batch 947, accuracy/top5 = 0.9
I0802 12:03:20.735764 19007 caffe.cpp:313] Batch 947, loss = 1.26992
I0802 12:03:20.784620 19007 caffe.cpp:313] Batch 948, accuracy/top1 = 0.56
I0802 12:03:20.784644 19007 caffe.cpp:313] Batch 948, accuracy/top5 = 0.76
I0802 12:03:20.784648 19007 caffe.cpp:313] Batch 948, loss = 1.90732
I0802 12:03:20.832304 19007 caffe.cpp:313] Batch 949, accuracy/top1 = 0.8
I0802 12:03:20.832329 19007 caffe.cpp:313] Batch 949, accuracy/top5 = 0.9
I0802 12:03:20.832332 19007 caffe.cpp:313] Batch 949, loss = 1.01669
I0802 12:03:20.879843 19007 caffe.cpp:313] Batch 950, accuracy/top1 = 0.6
I0802 12:03:20.879868 19007 caffe.cpp:313] Batch 950, accuracy/top5 = 0.78
I0802 12:03:20.879870 19007 caffe.cpp:313] Batch 950, loss = 2.16113
I0802 12:03:20.929147 19007 caffe.cpp:313] Batch 951, accuracy/top1 = 0.76
I0802 12:03:20.929172 19007 caffe.cpp:313] Batch 951, accuracy/top5 = 0.92
I0802 12:03:20.929175 19007 caffe.cpp:313] Batch 951, loss = 1.2078
I0802 12:03:20.977581 19007 caffe.cpp:313] Batch 952, accuracy/top1 = 0.58
I0802 12:03:20.977602 19007 caffe.cpp:313] Batch 952, accuracy/top5 = 0.84
I0802 12:03:20.977604 19007 caffe.cpp:313] Batch 952, loss = 2.06616
I0802 12:03:21.026150 19007 caffe.cpp:313] Batch 953, accuracy/top1 = 0.52
I0802 12:03:21.026171 19007 caffe.cpp:313] Batch 953, accuracy/top5 = 0.78
I0802 12:03:21.026175 19007 caffe.cpp:313] Batch 953, loss = 2.11225
I0802 12:03:21.074851 19007 caffe.cpp:313] Batch 954, accuracy/top1 = 0.56
I0802 12:03:21.074873 19007 caffe.cpp:313] Batch 954, accuracy/top5 = 0.74
I0802 12:03:21.074877 19007 caffe.cpp:313] Batch 954, loss = 2.2005
I0802 12:03:21.123715 19007 caffe.cpp:313] Batch 955, accuracy/top1 = 0.58
I0802 12:03:21.123741 19007 caffe.cpp:313] Batch 955, accuracy/top5 = 0.74
I0802 12:03:21.123745 19007 caffe.cpp:313] Batch 955, loss = 1.88596
I0802 12:03:21.172330 19007 caffe.cpp:313] Batch 956, accuracy/top1 = 0.66
I0802 12:03:21.172356 19007 caffe.cpp:313] Batch 956, accuracy/top5 = 0.9
I0802 12:03:21.172361 19007 caffe.cpp:313] Batch 956, loss = 1.63602
I0802 12:03:21.221498 19007 caffe.cpp:313] Batch 957, accuracy/top1 = 0.56
I0802 12:03:21.221524 19007 caffe.cpp:313] Batch 957, accuracy/top5 = 0.78
I0802 12:03:21.221529 19007 caffe.cpp:313] Batch 957, loss = 2.00282
I0802 12:03:21.270162 19007 caffe.cpp:313] Batch 958, accuracy/top1 = 0.68
I0802 12:03:21.270189 19007 caffe.cpp:313] Batch 958, accuracy/top5 = 0.86
I0802 12:03:21.270192 19007 caffe.cpp:313] Batch 958, loss = 1.84062
I0802 12:03:21.318508 19007 caffe.cpp:313] Batch 959, accuracy/top1 = 0.52
I0802 12:03:21.318534 19007 caffe.cpp:313] Batch 959, accuracy/top5 = 0.76
I0802 12:03:21.318538 19007 caffe.cpp:313] Batch 959, loss = 2.00042
I0802 12:03:21.365963 19007 caffe.cpp:313] Batch 960, accuracy/top1 = 0.64
I0802 12:03:21.365988 19007 caffe.cpp:313] Batch 960, accuracy/top5 = 0.8
I0802 12:03:21.365993 19007 caffe.cpp:313] Batch 960, loss = 1.74654
I0802 12:03:21.413869 19007 caffe.cpp:313] Batch 961, accuracy/top1 = 0.58
I0802 12:03:21.413894 19007 caffe.cpp:313] Batch 961, accuracy/top5 = 0.78
I0802 12:03:21.413898 19007 caffe.cpp:313] Batch 961, loss = 2.45377
I0802 12:03:21.462067 19007 caffe.cpp:313] Batch 962, accuracy/top1 = 0.66
I0802 12:03:21.462092 19007 caffe.cpp:313] Batch 962, accuracy/top5 = 0.94
I0802 12:03:21.462115 19007 caffe.cpp:313] Batch 962, loss = 1.43281
I0802 12:03:21.510349 19007 caffe.cpp:313] Batch 963, accuracy/top1 = 0.38
I0802 12:03:21.510373 19007 caffe.cpp:313] Batch 963, accuracy/top5 = 0.78
I0802 12:03:21.510378 19007 caffe.cpp:313] Batch 963, loss = 2.33604
I0802 12:03:21.558892 19007 caffe.cpp:313] Batch 964, accuracy/top1 = 0.6
I0802 12:03:21.558924 19007 caffe.cpp:313] Batch 964, accuracy/top5 = 0.72
I0802 12:03:21.558929 19007 caffe.cpp:313] Batch 964, loss = 1.88224
I0802 12:03:21.607285 19007 caffe.cpp:313] Batch 965, accuracy/top1 = 0.56
I0802 12:03:21.607309 19007 caffe.cpp:313] Batch 965, accuracy/top5 = 0.82
I0802 12:03:21.607313 19007 caffe.cpp:313] Batch 965, loss = 1.91161
I0802 12:03:21.655500 19007 caffe.cpp:313] Batch 966, accuracy/top1 = 0.52
I0802 12:03:21.655526 19007 caffe.cpp:313] Batch 966, accuracy/top5 = 0.82
I0802 12:03:21.655530 19007 caffe.cpp:313] Batch 966, loss = 2.22686
I0802 12:03:21.704582 19007 caffe.cpp:313] Batch 967, accuracy/top1 = 0.52
I0802 12:03:21.704607 19007 caffe.cpp:313] Batch 967, accuracy/top5 = 0.84
I0802 12:03:21.704610 19007 caffe.cpp:313] Batch 967, loss = 2.02465
I0802 12:03:21.754734 19007 caffe.cpp:313] Batch 968, accuracy/top1 = 0.52
I0802 12:03:21.754758 19007 caffe.cpp:313] Batch 968, accuracy/top5 = 0.82
I0802 12:03:21.754762 19007 caffe.cpp:313] Batch 968, loss = 2.1641
I0802 12:03:21.804857 19007 caffe.cpp:313] Batch 969, accuracy/top1 = 0.48
I0802 12:03:21.804882 19007 caffe.cpp:313] Batch 969, accuracy/top5 = 0.82
I0802 12:03:21.804885 19007 caffe.cpp:313] Batch 969, loss = 1.72103
I0802 12:03:21.854403 19007 caffe.cpp:313] Batch 970, accuracy/top1 = 0.64
I0802 12:03:21.854429 19007 caffe.cpp:313] Batch 970, accuracy/top5 = 0.84
I0802 12:03:21.854432 19007 caffe.cpp:313] Batch 970, loss = 1.55538
I0802 12:03:21.903599 19007 caffe.cpp:313] Batch 971, accuracy/top1 = 0.64
I0802 12:03:21.903622 19007 caffe.cpp:313] Batch 971, accuracy/top5 = 0.86
I0802 12:03:21.903626 19007 caffe.cpp:313] Batch 971, loss = 1.38755
I0802 12:03:21.952353 19007 caffe.cpp:313] Batch 972, accuracy/top1 = 0.78
I0802 12:03:21.952378 19007 caffe.cpp:313] Batch 972, accuracy/top5 = 0.84
I0802 12:03:21.952383 19007 caffe.cpp:313] Batch 972, loss = 1.1968
I0802 12:03:22.003150 19007 caffe.cpp:313] Batch 973, accuracy/top1 = 0.46
I0802 12:03:22.003175 19007 caffe.cpp:313] Batch 973, accuracy/top5 = 0.7
I0802 12:03:22.003178 19007 caffe.cpp:313] Batch 973, loss = 2.59824
I0802 12:03:22.051542 19007 caffe.cpp:313] Batch 974, accuracy/top1 = 0.52
I0802 12:03:22.051561 19007 caffe.cpp:313] Batch 974, accuracy/top5 = 0.78
I0802 12:03:22.051566 19007 caffe.cpp:313] Batch 974, loss = 2.04455
I0802 12:03:22.100723 19007 caffe.cpp:313] Batch 975, accuracy/top1 = 0.66
I0802 12:03:22.100739 19007 caffe.cpp:313] Batch 975, accuracy/top5 = 0.8
I0802 12:03:22.100742 19007 caffe.cpp:313] Batch 975, loss = 1.77437
I0802 12:03:22.150003 19007 caffe.cpp:313] Batch 976, accuracy/top1 = 0.5
I0802 12:03:22.150029 19007 caffe.cpp:313] Batch 976, accuracy/top5 = 0.88
I0802 12:03:22.150033 19007 caffe.cpp:313] Batch 976, loss = 1.71725
I0802 12:03:22.199208 19007 caffe.cpp:313] Batch 977, accuracy/top1 = 0.56
I0802 12:03:22.199232 19007 caffe.cpp:313] Batch 977, accuracy/top5 = 0.84
I0802 12:03:22.199236 19007 caffe.cpp:313] Batch 977, loss = 1.68693
I0802 12:03:22.248725 19007 caffe.cpp:313] Batch 978, accuracy/top1 = 0.5
I0802 12:03:22.248749 19007 caffe.cpp:313] Batch 978, accuracy/top5 = 0.76
I0802 12:03:22.248754 19007 caffe.cpp:313] Batch 978, loss = 2.12808
I0802 12:03:22.298776 19007 caffe.cpp:313] Batch 979, accuracy/top1 = 0.62
I0802 12:03:22.298801 19007 caffe.cpp:313] Batch 979, accuracy/top5 = 0.8
I0802 12:03:22.298805 19007 caffe.cpp:313] Batch 979, loss = 1.69024
I0802 12:03:22.347398 19007 caffe.cpp:313] Batch 980, accuracy/top1 = 0.5
I0802 12:03:22.347421 19007 caffe.cpp:313] Batch 980, accuracy/top5 = 0.74
I0802 12:03:22.347426 19007 caffe.cpp:313] Batch 980, loss = 1.99879
I0802 12:03:22.397047 19007 caffe.cpp:313] Batch 981, accuracy/top1 = 0.64
I0802 12:03:22.397085 19007 caffe.cpp:313] Batch 981, accuracy/top5 = 0.86
I0802 12:03:22.397090 19007 caffe.cpp:313] Batch 981, loss = 1.67975
I0802 12:03:22.446125 19007 caffe.cpp:313] Batch 982, accuracy/top1 = 0.48
I0802 12:03:22.446149 19007 caffe.cpp:313] Batch 982, accuracy/top5 = 0.74
I0802 12:03:22.446154 19007 caffe.cpp:313] Batch 982, loss = 2.65207
I0802 12:03:22.495426 19007 caffe.cpp:313] Batch 983, accuracy/top1 = 0.54
I0802 12:03:22.495451 19007 caffe.cpp:313] Batch 983, accuracy/top5 = 0.8
I0802 12:03:22.495455 19007 caffe.cpp:313] Batch 983, loss = 2.45842
I0802 12:03:22.545027 19007 caffe.cpp:313] Batch 984, accuracy/top1 = 0.62
I0802 12:03:22.545047 19007 caffe.cpp:313] Batch 984, accuracy/top5 = 0.86
I0802 12:03:22.545050 19007 caffe.cpp:313] Batch 984, loss = 1.39978
I0802 12:03:22.594288 19007 caffe.cpp:313] Batch 985, accuracy/top1 = 0.52
I0802 12:03:22.594311 19007 caffe.cpp:313] Batch 985, accuracy/top5 = 0.86
I0802 12:03:22.594316 19007 caffe.cpp:313] Batch 985, loss = 1.75421
I0802 12:03:22.643373 19007 caffe.cpp:313] Batch 986, accuracy/top1 = 0.6
I0802 12:03:22.643396 19007 caffe.cpp:313] Batch 986, accuracy/top5 = 0.78
I0802 12:03:22.643401 19007 caffe.cpp:313] Batch 986, loss = 2.08141
I0802 12:03:22.691733 19007 caffe.cpp:313] Batch 987, accuracy/top1 = 0.5
I0802 12:03:22.691758 19007 caffe.cpp:313] Batch 987, accuracy/top5 = 0.78
I0802 12:03:22.691762 19007 caffe.cpp:313] Batch 987, loss = 1.83135
I0802 12:03:22.739959 19007 caffe.cpp:313] Batch 988, accuracy/top1 = 0.6
I0802 12:03:22.739984 19007 caffe.cpp:313] Batch 988, accuracy/top5 = 0.82
I0802 12:03:22.739989 19007 caffe.cpp:313] Batch 988, loss = 1.66665
I0802 12:03:22.789882 19007 caffe.cpp:313] Batch 989, accuracy/top1 = 0.52
I0802 12:03:22.789906 19007 caffe.cpp:313] Batch 989, accuracy/top5 = 0.76
I0802 12:03:22.789911 19007 caffe.cpp:313] Batch 989, loss = 2.18724
I0802 12:03:22.839094 19007 caffe.cpp:313] Batch 990, accuracy/top1 = 0.62
I0802 12:03:22.839119 19007 caffe.cpp:313] Batch 990, accuracy/top5 = 0.9
I0802 12:03:22.839123 19007 caffe.cpp:313] Batch 990, loss = 1.28243
I0802 12:03:22.889243 19007 caffe.cpp:313] Batch 991, accuracy/top1 = 0.68
I0802 12:03:22.889271 19007 caffe.cpp:313] Batch 991, accuracy/top5 = 0.86
I0802 12:03:22.889274 19007 caffe.cpp:313] Batch 991, loss = 1.53013
I0802 12:03:22.938478 19007 caffe.cpp:313] Batch 992, accuracy/top1 = 0.64
I0802 12:03:22.938503 19007 caffe.cpp:313] Batch 992, accuracy/top5 = 0.9
I0802 12:03:22.938508 19007 caffe.cpp:313] Batch 992, loss = 1.35603
I0802 12:03:22.988273 19007 caffe.cpp:313] Batch 993, accuracy/top1 = 0.66
I0802 12:03:22.988299 19007 caffe.cpp:313] Batch 993, accuracy/top5 = 0.92
I0802 12:03:22.988303 19007 caffe.cpp:313] Batch 993, loss = 1.26432
I0802 12:03:23.036726 19007 caffe.cpp:313] Batch 994, accuracy/top1 = 0.68
I0802 12:03:23.036751 19007 caffe.cpp:313] Batch 994, accuracy/top5 = 0.9
I0802 12:03:23.036756 19007 caffe.cpp:313] Batch 994, loss = 1.27395
I0802 12:03:23.085938 19007 caffe.cpp:313] Batch 995, accuracy/top1 = 0.64
I0802 12:03:23.085957 19007 caffe.cpp:313] Batch 995, accuracy/top5 = 0.86
I0802 12:03:23.085960 19007 caffe.cpp:313] Batch 995, loss = 1.37753
I0802 12:03:23.135418 19007 caffe.cpp:313] Batch 996, accuracy/top1 = 0.62
I0802 12:03:23.135439 19007 caffe.cpp:313] Batch 996, accuracy/top5 = 0.82
I0802 12:03:23.135443 19007 caffe.cpp:313] Batch 996, loss = 1.57471
I0802 12:03:23.184274 19007 caffe.cpp:313] Batch 997, accuracy/top1 = 0.54
I0802 12:03:23.184300 19007 caffe.cpp:313] Batch 997, accuracy/top5 = 0.86
I0802 12:03:23.184307 19007 caffe.cpp:313] Batch 997, loss = 1.73758
I0802 12:03:23.204339 19075 data_reader.cpp:264] Starting prefetch of epoch 1
I0802 12:03:23.231444 19007 caffe.cpp:313] Batch 998, accuracy/top1 = 0.52
I0802 12:03:23.231469 19007 caffe.cpp:313] Batch 998, accuracy/top5 = 0.86
I0802 12:03:23.231472 19007 caffe.cpp:313] Batch 998, loss = 1.79927
I0802 12:03:23.279410 19007 caffe.cpp:313] Batch 999, accuracy/top1 = 0.68
I0802 12:03:23.279435 19007 caffe.cpp:313] Batch 999, accuracy/top5 = 0.84
I0802 12:03:23.279455 19007 caffe.cpp:313] Batch 999, loss = 1.57432
I0802 12:03:23.279458 19007 caffe.cpp:318] Loss: 1.75275
I0802 12:03:23.279466 19007 caffe.cpp:330] accuracy/top1 = 0.59644
I0802 12:03:23.279470 19007 caffe.cpp:330] accuracy/top5 = 0.822162
I0802 12:03:23.279475 19007 caffe.cpp:330] loss = 1.75275 (* 1 = 1.75275 loss)
./train_imagenet_classification.sh: line 79: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/train-log_2017-08-01_15-21-31.txt/run.sh: Not a directory
