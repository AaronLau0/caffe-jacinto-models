I0817 10:57:50.166539 14586 caffe.cpp:608] This is NVCaffe 0.16.3 started at Thu Aug 17 10:57:49 2017
I0817 10:57:50.166674 14586 caffe.cpp:611] CuDNN version: 6021
I0817 10:57:50.166679 14586 caffe.cpp:612] CuBLAS version: 8000
I0817 10:57:50.166682 14586 caffe.cpp:613] CUDA version: 8000
I0817 10:57:50.166684 14586 caffe.cpp:614] CUDA driver version: 8000
I0817 10:57:50.166692 14586 caffe.cpp:263] Not using GPU #2 for single-GPU function
I0817 10:57:50.166698 14586 caffe.cpp:263] Not using GPU #1 for single-GPU function
I0817 10:57:50.167306 14586 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0817 10:57:50.167898 14586 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0817 10:57:50.167906 14586 caffe.cpp:275] Use GPU with device ID 0
I0817 10:57:50.168280 14586 caffe.cpp:279] GPU device name: GeForce GTX 1080
I0817 10:57:50.169555 14586 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
quantize: true
I0817 10:57:50.169690 14586 net.cpp:104] Using FLOAT as default forward math type
I0817 10:57:50.169697 14586 net.cpp:110] Using FLOAT as default backward math type
I0817 10:57:50.169700 14586 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0817 10:57:50.169704 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.169755 14586 net.cpp:184] Created Layer data (0)
I0817 10:57:50.169760 14586 net.cpp:530] data -> data
I0817 10:57:50.169771 14586 net.cpp:530] data -> label
I0817 10:57:50.169791 14586 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 50
I0817 10:57:50.170094 14586 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0817 10:57:50.178534 14619 db_lmdb.cpp:24] Opened lmdb ./data/ilsvrc12_val_lmdb
I0817 10:57:50.179951 14586 data_layer.cpp:185] (0) ReshapePrefetch 50, 3, 224, 224
I0817 10:57:50.179986 14586 data_layer.cpp:209] (0) Output data size: 50, 3, 224, 224
I0817 10:57:50.179991 14586 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0817 10:57:50.180012 14586 net.cpp:245] Setting up data
I0817 10:57:50.180022 14586 net.cpp:252] TEST Top shape for layer 0 'data' 50 3 224 224 (7526400)
I0817 10:57:50.180027 14586 net.cpp:252] TEST Top shape for layer 0 'data' 50 (50)
I0817 10:57:50.180032 14586 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0817 10:57:50.180037 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.180047 14586 net.cpp:184] Created Layer label_data_1_split (1)
I0817 10:57:50.180052 14586 net.cpp:561] label_data_1_split <- label
I0817 10:57:50.180058 14586 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0817 10:57:50.180063 14586 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0817 10:57:50.180074 14586 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0817 10:57:50.180104 14586 net.cpp:245] Setting up label_data_1_split
I0817 10:57:50.180107 14586 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0817 10:57:50.180109 14586 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0817 10:57:50.180112 14586 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0817 10:57:50.180114 14586 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0817 10:57:50.180116 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.180125 14586 net.cpp:184] Created Layer data/bias (2)
I0817 10:57:50.180128 14586 net.cpp:561] data/bias <- data
I0817 10:57:50.180142 14586 net.cpp:530] data/bias -> data/bias
I0817 10:57:50.181164 14620 data_layer.cpp:97] (0) Parser threads: 1
I0817 10:57:50.181174 14620 data_layer.cpp:99] (0) Transformer threads: 1
I0817 10:57:50.186360 14586 net.cpp:245] Setting up data/bias
I0817 10:57:50.186398 14586 net.cpp:252] TEST Top shape for layer 2 'data/bias' 50 3 224 224 (7526400)
I0817 10:57:50.186414 14586 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0817 10:57:50.186420 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.186444 14586 net.cpp:184] Created Layer conv1a (3)
I0817 10:57:50.186450 14586 net.cpp:561] conv1a <- data/bias
I0817 10:57:50.186455 14586 net.cpp:530] conv1a -> conv1a
I0817 10:57:50.480576 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 8.02G, req 0G)
I0817 10:57:50.480595 14586 net.cpp:245] Setting up conv1a
I0817 10:57:50.480602 14586 net.cpp:252] TEST Top shape for layer 3 'conv1a' 50 32 112 112 (20070400)
I0817 10:57:50.480610 14586 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0817 10:57:50.480614 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.480626 14586 net.cpp:184] Created Layer conv1a/bn (4)
I0817 10:57:50.480630 14586 net.cpp:561] conv1a/bn <- conv1a
I0817 10:57:50.480633 14586 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0817 10:57:50.481076 14586 net.cpp:245] Setting up conv1a/bn
I0817 10:57:50.481082 14586 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 50 32 112 112 (20070400)
I0817 10:57:50.481091 14586 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0817 10:57:50.481092 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.481097 14586 net.cpp:184] Created Layer conv1a/relu (5)
I0817 10:57:50.481099 14586 net.cpp:561] conv1a/relu <- conv1a
I0817 10:57:50.481102 14586 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0817 10:57:50.481112 14586 net.cpp:245] Setting up conv1a/relu
I0817 10:57:50.481115 14586 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 50 32 112 112 (20070400)
I0817 10:57:50.481117 14586 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0817 10:57:50.481122 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.481133 14586 net.cpp:184] Created Layer conv1b (6)
I0817 10:57:50.481137 14586 net.cpp:561] conv1b <- conv1a
I0817 10:57:50.481139 14586 net.cpp:530] conv1b -> conv1b
I0817 10:57:50.490617 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.93G, req 0G)
I0817 10:57:50.490627 14586 net.cpp:245] Setting up conv1b
I0817 10:57:50.490630 14586 net.cpp:252] TEST Top shape for layer 6 'conv1b' 50 32 112 112 (20070400)
I0817 10:57:50.490635 14586 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0817 10:57:50.490638 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.490643 14586 net.cpp:184] Created Layer conv1b/bn (7)
I0817 10:57:50.490645 14586 net.cpp:561] conv1b/bn <- conv1b
I0817 10:57:50.490648 14586 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0817 10:57:50.491063 14586 net.cpp:245] Setting up conv1b/bn
I0817 10:57:50.491071 14586 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 50 32 112 112 (20070400)
I0817 10:57:50.491077 14586 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0817 10:57:50.491080 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.491082 14586 net.cpp:184] Created Layer conv1b/relu (8)
I0817 10:57:50.491086 14586 net.cpp:561] conv1b/relu <- conv1b
I0817 10:57:50.491087 14586 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0817 10:57:50.491091 14586 net.cpp:245] Setting up conv1b/relu
I0817 10:57:50.491093 14586 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 50 32 112 112 (20070400)
I0817 10:57:50.491096 14586 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0817 10:57:50.491097 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.491103 14586 net.cpp:184] Created Layer pool1 (9)
I0817 10:57:50.491106 14586 net.cpp:561] pool1 <- conv1b
I0817 10:57:50.491107 14586 net.cpp:530] pool1 -> pool1
I0817 10:57:50.491154 14586 net.cpp:245] Setting up pool1
I0817 10:57:50.491160 14586 net.cpp:252] TEST Top shape for layer 9 'pool1' 50 32 56 56 (5017600)
I0817 10:57:50.491163 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0817 10:57:50.491164 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.491170 14586 net.cpp:184] Created Layer res2a_branch2a (10)
I0817 10:57:50.491173 14586 net.cpp:561] res2a_branch2a <- pool1
I0817 10:57:50.491175 14586 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0817 10:57:50.500325 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0817 10:57:50.500336 14586 net.cpp:245] Setting up res2a_branch2a
I0817 10:57:50.500340 14586 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 50 64 56 56 (10035200)
I0817 10:57:50.500345 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0817 10:57:50.500349 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.500352 14586 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0817 10:57:50.500355 14586 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0817 10:57:50.500357 14586 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0817 10:57:50.500772 14586 net.cpp:245] Setting up res2a_branch2a/bn
I0817 10:57:50.500779 14586 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 50 64 56 56 (10035200)
I0817 10:57:50.500784 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0817 10:57:50.500787 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.500793 14586 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0817 10:57:50.500797 14586 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0817 10:57:50.500798 14586 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0817 10:57:50.500802 14586 net.cpp:245] Setting up res2a_branch2a/relu
I0817 10:57:50.500804 14586 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 50 64 56 56 (10035200)
I0817 10:57:50.500807 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0817 10:57:50.500808 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.500823 14586 net.cpp:184] Created Layer res2a_branch2b (13)
I0817 10:57:50.500825 14586 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0817 10:57:50.500828 14586 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0817 10:57:50.505569 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.82G, req 0G)
I0817 10:57:50.505589 14586 net.cpp:245] Setting up res2a_branch2b
I0817 10:57:50.505595 14586 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 50 64 56 56 (10035200)
I0817 10:57:50.505615 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0817 10:57:50.505623 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.505640 14586 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0817 10:57:50.505645 14586 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0817 10:57:50.505648 14586 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0817 10:57:50.506122 14586 net.cpp:245] Setting up res2a_branch2b/bn
I0817 10:57:50.506132 14586 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 50 64 56 56 (10035200)
I0817 10:57:50.506142 14586 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0817 10:57:50.506146 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.506152 14586 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0817 10:57:50.506156 14586 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0817 10:57:50.506160 14586 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0817 10:57:50.506168 14586 net.cpp:245] Setting up res2a_branch2b/relu
I0817 10:57:50.506175 14586 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 50 64 56 56 (10035200)
I0817 10:57:50.506177 14586 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0817 10:57:50.506181 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.506189 14586 net.cpp:184] Created Layer pool2 (16)
I0817 10:57:50.506193 14586 net.cpp:561] pool2 <- res2a_branch2b
I0817 10:57:50.506196 14586 net.cpp:530] pool2 -> pool2
I0817 10:57:50.506229 14586 net.cpp:245] Setting up pool2
I0817 10:57:50.506234 14586 net.cpp:252] TEST Top shape for layer 16 'pool2' 50 64 28 28 (2508800)
I0817 10:57:50.506239 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0817 10:57:50.506244 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.506253 14586 net.cpp:184] Created Layer res3a_branch2a (17)
I0817 10:57:50.506258 14586 net.cpp:561] res3a_branch2a <- pool2
I0817 10:57:50.506261 14586 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0817 10:57:50.533380 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.79G, req 0G)
I0817 10:57:50.533401 14586 net.cpp:245] Setting up res3a_branch2a
I0817 10:57:50.533407 14586 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 50 128 28 28 (5017600)
I0817 10:57:50.533417 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0817 10:57:50.533422 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.533432 14586 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0817 10:57:50.533437 14586 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0817 10:57:50.533442 14586 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0817 10:57:50.533995 14586 net.cpp:245] Setting up res3a_branch2a/bn
I0817 10:57:50.534008 14586 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 50 128 28 28 (5017600)
I0817 10:57:50.534018 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0817 10:57:50.534023 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.534027 14586 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0817 10:57:50.534030 14586 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0817 10:57:50.534034 14586 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0817 10:57:50.534039 14586 net.cpp:245] Setting up res3a_branch2a/relu
I0817 10:57:50.534044 14586 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 50 128 28 28 (5017600)
I0817 10:57:50.534049 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0817 10:57:50.534052 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.534076 14586 net.cpp:184] Created Layer res3a_branch2b (20)
I0817 10:57:50.534082 14586 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0817 10:57:50.534088 14586 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0817 10:57:50.538180 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.77G, req 0G)
I0817 10:57:50.538192 14586 net.cpp:245] Setting up res3a_branch2b
I0817 10:57:50.538195 14586 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 50 128 28 28 (5017600)
I0817 10:57:50.538200 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0817 10:57:50.538203 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.538208 14586 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0817 10:57:50.538210 14586 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0817 10:57:50.538213 14586 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0817 10:57:50.538612 14586 net.cpp:245] Setting up res3a_branch2b/bn
I0817 10:57:50.538619 14586 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 50 128 28 28 (5017600)
I0817 10:57:50.538625 14586 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0817 10:57:50.538627 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.538630 14586 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0817 10:57:50.538632 14586 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0817 10:57:50.538635 14586 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0817 10:57:50.538638 14586 net.cpp:245] Setting up res3a_branch2b/relu
I0817 10:57:50.538641 14586 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 50 128 28 28 (5017600)
I0817 10:57:50.538643 14586 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0817 10:57:50.538645 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.538650 14586 net.cpp:184] Created Layer pool3 (23)
I0817 10:57:50.538651 14586 net.cpp:561] pool3 <- res3a_branch2b
I0817 10:57:50.538653 14586 net.cpp:530] pool3 -> pool3
I0817 10:57:50.538687 14586 net.cpp:245] Setting up pool3
I0817 10:57:50.538691 14586 net.cpp:252] TEST Top shape for layer 23 'pool3' 50 128 14 14 (1254400)
I0817 10:57:50.538694 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0817 10:57:50.538697 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.538707 14586 net.cpp:184] Created Layer res4a_branch2a (24)
I0817 10:57:50.538710 14586 net.cpp:561] res4a_branch2a <- pool3
I0817 10:57:50.538713 14586 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0817 10:57:50.552230 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.75G, req 0G)
I0817 10:57:50.552248 14586 net.cpp:245] Setting up res4a_branch2a
I0817 10:57:50.552253 14586 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 50 256 14 14 (2508800)
I0817 10:57:50.552258 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0817 10:57:50.552263 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.552268 14586 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0817 10:57:50.552271 14586 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0817 10:57:50.552274 14586 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0817 10:57:50.552709 14586 net.cpp:245] Setting up res4a_branch2a/bn
I0817 10:57:50.552716 14586 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 50 256 14 14 (2508800)
I0817 10:57:50.552722 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0817 10:57:50.552724 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.552739 14586 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0817 10:57:50.552742 14586 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0817 10:57:50.552744 14586 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0817 10:57:50.552748 14586 net.cpp:245] Setting up res4a_branch2a/relu
I0817 10:57:50.552752 14586 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 50 256 14 14 (2508800)
I0817 10:57:50.552753 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0817 10:57:50.552755 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.552762 14586 net.cpp:184] Created Layer res4a_branch2b (27)
I0817 10:57:50.552765 14586 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0817 10:57:50.552767 14586 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0817 10:57:50.558807 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.74G, req 0G)
I0817 10:57:50.558817 14586 net.cpp:245] Setting up res4a_branch2b
I0817 10:57:50.558822 14586 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 50 256 14 14 (2508800)
I0817 10:57:50.558826 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0817 10:57:50.558830 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.558835 14586 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0817 10:57:50.558837 14586 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0817 10:57:50.558840 14586 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0817 10:57:50.559240 14586 net.cpp:245] Setting up res4a_branch2b/bn
I0817 10:57:50.559299 14586 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 50 256 14 14 (2508800)
I0817 10:57:50.559306 14586 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0817 10:57:50.559309 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.559312 14586 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0817 10:57:50.559315 14586 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0817 10:57:50.559317 14586 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0817 10:57:50.559320 14586 net.cpp:245] Setting up res4a_branch2b/relu
I0817 10:57:50.559324 14586 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 50 256 14 14 (2508800)
I0817 10:57:50.559325 14586 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0817 10:57:50.559327 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.559331 14586 net.cpp:184] Created Layer pool4 (30)
I0817 10:57:50.559334 14586 net.cpp:561] pool4 <- res4a_branch2b
I0817 10:57:50.559336 14586 net.cpp:530] pool4 -> pool4
I0817 10:57:50.559368 14586 net.cpp:245] Setting up pool4
I0817 10:57:50.559372 14586 net.cpp:252] TEST Top shape for layer 30 'pool4' 50 256 7 7 (627200)
I0817 10:57:50.559376 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0817 10:57:50.559377 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.559382 14586 net.cpp:184] Created Layer res5a_branch2a (31)
I0817 10:57:50.559386 14586 net.cpp:561] res5a_branch2a <- pool4
I0817 10:57:50.559388 14586 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0817 10:57:50.592303 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.72G, req 0G)
I0817 10:57:50.592319 14586 net.cpp:245] Setting up res5a_branch2a
I0817 10:57:50.592324 14586 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 50 512 7 7 (1254400)
I0817 10:57:50.592330 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0817 10:57:50.592334 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.592344 14586 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0817 10:57:50.592346 14586 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0817 10:57:50.592365 14586 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0817 10:57:50.592803 14586 net.cpp:245] Setting up res5a_branch2a/bn
I0817 10:57:50.592809 14586 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 50 512 7 7 (1254400)
I0817 10:57:50.592815 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0817 10:57:50.592818 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.592821 14586 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0817 10:57:50.592823 14586 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0817 10:57:50.592825 14586 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0817 10:57:50.592829 14586 net.cpp:245] Setting up res5a_branch2a/relu
I0817 10:57:50.592831 14586 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 50 512 7 7 (1254400)
I0817 10:57:50.592833 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0817 10:57:50.592836 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.592842 14586 net.cpp:184] Created Layer res5a_branch2b (34)
I0817 10:57:50.592844 14586 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0817 10:57:50.592846 14586 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0817 10:57:50.608578 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 1  (limit 7.71G, req 0G)
I0817 10:57:50.608595 14586 net.cpp:245] Setting up res5a_branch2b
I0817 10:57:50.608600 14586 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 50 512 7 7 (1254400)
I0817 10:57:50.608610 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0817 10:57:50.608613 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.608621 14586 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0817 10:57:50.608624 14586 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0817 10:57:50.608628 14586 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0817 10:57:50.609069 14586 net.cpp:245] Setting up res5a_branch2b/bn
I0817 10:57:50.609076 14586 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 50 512 7 7 (1254400)
I0817 10:57:50.609082 14586 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0817 10:57:50.609086 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.609088 14586 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0817 10:57:50.609091 14586 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0817 10:57:50.609093 14586 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0817 10:57:50.609097 14586 net.cpp:245] Setting up res5a_branch2b/relu
I0817 10:57:50.609099 14586 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 50 512 7 7 (1254400)
I0817 10:57:50.609102 14586 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0817 10:57:50.609104 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.609108 14586 net.cpp:184] Created Layer pool5 (37)
I0817 10:57:50.609110 14586 net.cpp:561] pool5 <- res5a_branch2b
I0817 10:57:50.609112 14586 net.cpp:530] pool5 -> pool5
I0817 10:57:50.609130 14586 net.cpp:245] Setting up pool5
I0817 10:57:50.609134 14586 net.cpp:252] TEST Top shape for layer 37 'pool5' 50 512 1 1 (25600)
I0817 10:57:50.609136 14586 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0817 10:57:50.609138 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.609143 14586 net.cpp:184] Created Layer fc1000 (38)
I0817 10:57:50.609146 14586 net.cpp:561] fc1000 <- pool5
I0817 10:57:50.609148 14586 net.cpp:530] fc1000 -> fc1000
I0817 10:57:50.619825 14586 net.cpp:245] Setting up fc1000
I0817 10:57:50.619835 14586 net.cpp:252] TEST Top shape for layer 38 'fc1000' 50 1000 (50000)
I0817 10:57:50.619848 14586 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0817 10:57:50.619851 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.619855 14586 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0817 10:57:50.619858 14586 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0817 10:57:50.619861 14586 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0817 10:57:50.619864 14586 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0817 10:57:50.619868 14586 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0817 10:57:50.619902 14586 net.cpp:245] Setting up fc1000_fc1000_0_split
I0817 10:57:50.619906 14586 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0817 10:57:50.619910 14586 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0817 10:57:50.619911 14586 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0817 10:57:50.619913 14586 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0817 10:57:50.619916 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.619925 14586 net.cpp:184] Created Layer loss (40)
I0817 10:57:50.619927 14586 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0817 10:57:50.619930 14586 net.cpp:561] loss <- label_data_1_split_0
I0817 10:57:50.619933 14586 net.cpp:530] loss -> loss
I0817 10:57:50.620051 14586 net.cpp:245] Setting up loss
I0817 10:57:50.620057 14586 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0817 10:57:50.620060 14586 net.cpp:256]     with loss weight 1
I0817 10:57:50.620065 14586 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0817 10:57:50.620067 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.620076 14586 net.cpp:184] Created Layer accuracy/top1 (41)
I0817 10:57:50.620079 14586 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0817 10:57:50.620081 14586 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0817 10:57:50.620085 14586 net.cpp:530] accuracy/top1 -> accuracy/top1
I0817 10:57:50.620090 14586 net.cpp:245] Setting up accuracy/top1
I0817 10:57:50.620093 14586 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0817 10:57:50.620096 14586 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0817 10:57:50.620098 14586 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0817 10:57:50.620105 14586 net.cpp:184] Created Layer accuracy/top5 (42)
I0817 10:57:50.620108 14586 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0817 10:57:50.620110 14586 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0817 10:57:50.620113 14586 net.cpp:530] accuracy/top5 -> accuracy/top5
I0817 10:57:50.620117 14586 net.cpp:245] Setting up accuracy/top5
I0817 10:57:50.620121 14586 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0817 10:57:50.620122 14586 net.cpp:325] accuracy/top5 does not need backward computation.
I0817 10:57:50.620126 14586 net.cpp:325] accuracy/top1 does not need backward computation.
I0817 10:57:50.620127 14586 net.cpp:323] loss needs backward computation.
I0817 10:57:50.620133 14586 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0817 10:57:50.620137 14586 net.cpp:323] fc1000 needs backward computation.
I0817 10:57:50.620139 14586 net.cpp:323] pool5 needs backward computation.
I0817 10:57:50.620141 14586 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0817 10:57:50.620143 14586 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0817 10:57:50.620146 14586 net.cpp:323] res5a_branch2b needs backward computation.
I0817 10:57:50.620147 14586 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0817 10:57:50.620149 14586 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0817 10:57:50.620151 14586 net.cpp:323] res5a_branch2a needs backward computation.
I0817 10:57:50.620159 14586 net.cpp:323] pool4 needs backward computation.
I0817 10:57:50.620162 14586 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0817 10:57:50.620163 14586 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0817 10:57:50.620165 14586 net.cpp:323] res4a_branch2b needs backward computation.
I0817 10:57:50.620167 14586 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0817 10:57:50.620169 14586 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0817 10:57:50.620170 14586 net.cpp:323] res4a_branch2a needs backward computation.
I0817 10:57:50.620172 14586 net.cpp:323] pool3 needs backward computation.
I0817 10:57:50.620174 14586 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0817 10:57:50.620177 14586 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0817 10:57:50.620178 14586 net.cpp:323] res3a_branch2b needs backward computation.
I0817 10:57:50.620180 14586 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0817 10:57:50.620182 14586 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0817 10:57:50.620184 14586 net.cpp:323] res3a_branch2a needs backward computation.
I0817 10:57:50.620185 14586 net.cpp:323] pool2 needs backward computation.
I0817 10:57:50.620187 14586 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0817 10:57:50.620189 14586 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0817 10:57:50.620192 14586 net.cpp:323] res2a_branch2b needs backward computation.
I0817 10:57:50.620193 14586 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0817 10:57:50.620195 14586 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0817 10:57:50.620196 14586 net.cpp:323] res2a_branch2a needs backward computation.
I0817 10:57:50.620198 14586 net.cpp:323] pool1 needs backward computation.
I0817 10:57:50.620200 14586 net.cpp:323] conv1b/relu needs backward computation.
I0817 10:57:50.620203 14586 net.cpp:323] conv1b/bn needs backward computation.
I0817 10:57:50.620205 14586 net.cpp:323] conv1b needs backward computation.
I0817 10:57:50.620208 14586 net.cpp:323] conv1a/relu needs backward computation.
I0817 10:57:50.620209 14586 net.cpp:323] conv1a/bn needs backward computation.
I0817 10:57:50.620211 14586 net.cpp:323] conv1a needs backward computation.
I0817 10:57:50.620213 14586 net.cpp:325] data/bias does not need backward computation.
I0817 10:57:50.620218 14586 net.cpp:325] label_data_1_split does not need backward computation.
I0817 10:57:50.620221 14586 net.cpp:325] data does not need backward computation.
I0817 10:57:50.620224 14586 net.cpp:367] This network produces output accuracy/top1
I0817 10:57:50.620229 14586 net.cpp:367] This network produces output accuracy/top5
I0817 10:57:50.620231 14586 net.cpp:367] This network produces output loss
I0817 10:57:50.620263 14586 net.cpp:389] Top memory (TEST) required for data: 933273600 diff: 8
I0817 10:57:50.620267 14586 net.cpp:392] Bottom memory (TEST) required for data: 933273600 diff: 933273600
I0817 10:57:50.620270 14586 net.cpp:395] Shared (in-place) memory (TEST) by data: 622182400 diff: 622182400
I0817 10:57:50.620273 14586 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0817 10:57:50.620276 14586 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0817 10:57:50.620280 14586 net.cpp:407] Network initialization done.
I0817 10:57:50.624609 14586 net.cpp:1095] Copying source layer data Type:Data #blobs=0
I0817 10:57:50.624630 14586 net.cpp:1095] Copying source layer data/bias Type:Bias #blobs=1
I0817 10:57:50.624663 14586 net.cpp:1095] Copying source layer conv1a Type:Convolution #blobs=2
I0817 10:57:50.624678 14586 net.cpp:1095] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0817 10:57:50.624826 14586 net.cpp:1095] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0817 10:57:50.624831 14586 net.cpp:1095] Copying source layer conv1b Type:Convolution #blobs=2
I0817 10:57:50.624843 14586 net.cpp:1095] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0817 10:57:50.624948 14586 net.cpp:1095] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0817 10:57:50.624953 14586 net.cpp:1095] Copying source layer pool1 Type:Pooling #blobs=0
I0817 10:57:50.624956 14586 net.cpp:1095] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0817 10:57:50.624974 14586 net.cpp:1095] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625066 14586 net.cpp:1095] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0817 10:57:50.625072 14586 net.cpp:1095] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0817 10:57:50.625087 14586 net.cpp:1095] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625175 14586 net.cpp:1095] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0817 10:57:50.625180 14586 net.cpp:1095] Copying source layer pool2 Type:Pooling #blobs=0
I0817 10:57:50.625183 14586 net.cpp:1095] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0817 10:57:50.625222 14586 net.cpp:1095] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625308 14586 net.cpp:1095] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0817 10:57:50.625313 14586 net.cpp:1095] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0817 10:57:50.625337 14586 net.cpp:1095] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625417 14586 net.cpp:1095] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0817 10:57:50.625422 14586 net.cpp:1095] Copying source layer pool3 Type:Pooling #blobs=0
I0817 10:57:50.625425 14586 net.cpp:1095] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0817 10:57:50.625540 14586 net.cpp:1095] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625622 14586 net.cpp:1095] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0817 10:57:50.625627 14586 net.cpp:1095] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0817 10:57:50.625685 14586 net.cpp:1095] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0817 10:57:50.625766 14586 net.cpp:1095] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0817 10:57:50.625771 14586 net.cpp:1095] Copying source layer pool4 Type:Pooling #blobs=0
I0817 10:57:50.625774 14586 net.cpp:1095] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0817 10:57:50.626142 14586 net.cpp:1095] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0817 10:57:50.626229 14586 net.cpp:1095] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0817 10:57:50.626233 14586 net.cpp:1095] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0817 10:57:50.626410 14586 net.cpp:1095] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0817 10:57:50.626488 14586 net.cpp:1095] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0817 10:57:50.626492 14586 net.cpp:1095] Copying source layer pool5 Type:Pooling #blobs=0
I0817 10:57:50.626497 14586 net.cpp:1095] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0817 10:57:50.626602 14586 net.cpp:1095] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0817 10:57:50.626646 14586 caffe.cpp:290] Running for 1000 iterations.
I0817 10:57:50.632796 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.68G, req 0G)
I0817 10:57:50.646978 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.52G, req 0G)
I0817 10:57:50.663513 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.33G, req 0G)
I0817 10:57:50.670653 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.25G, req 0G)
I0817 10:57:50.682188 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.15G, req 0G)
I0817 10:57:50.687273 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.11G, req 0G)
I0817 10:57:50.696476 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.06G, req 0G)
I0817 10:57:50.700922 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.04G, req 0G)
I0817 10:57:50.709882 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.02G, req 0G)
I0817 10:57:50.714414 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 1  (limit 7G, req 0G)
I0817 10:57:50.749246 14586 caffe.cpp:313] Batch 0, accuracy/top1 = 0.56
I0817 10:57:50.749270 14586 caffe.cpp:313] Batch 0, accuracy/top5 = 0.8
I0817 10:57:50.749274 14586 caffe.cpp:313] Batch 0, loss = 1.76059
I0817 10:57:50.749276 14586 net.cpp:1620] Adding quantization params at infer/iter index: 1
I0817 10:57:50.757930 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.74G/1 1  (limit 6.25G, req 0G)
I0817 10:57:50.777915 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0817 10:57:50.802887 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0817 10:57:50.815687 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0817 10:57:50.830795 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0817 10:57:50.836982 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0817 10:57:50.850697 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0817 10:57:50.855952 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0817 10:57:50.876296 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 1.48G/1 7  (limit 5.51G, req 0.05G)
I0817 10:57:50.882169 14586 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 1.48G/2 1  (limit 5.51G, req 0.05G)
I0817 10:57:50.916241 14586 caffe.cpp:313] Batch 1, accuracy/top1 = 0.6
I0817 10:57:50.916267 14586 caffe.cpp:313] Batch 1, accuracy/top5 = 0.78
I0817 10:57:50.916272 14586 caffe.cpp:313] Batch 1, loss = 1.89292
I0817 10:57:50.979591 14586 caffe.cpp:313] Batch 2, accuracy/top1 = 0.54
I0817 10:57:50.979614 14586 caffe.cpp:313] Batch 2, accuracy/top5 = 0.76
I0817 10:57:50.979617 14586 caffe.cpp:313] Batch 2, loss = 2.22387
I0817 10:57:51.043289 14586 caffe.cpp:313] Batch 3, accuracy/top1 = 0.66
I0817 10:57:51.043308 14586 caffe.cpp:313] Batch 3, accuracy/top5 = 0.78
I0817 10:57:51.043310 14586 caffe.cpp:313] Batch 3, loss = 1.55652
I0817 10:57:51.106704 14586 caffe.cpp:313] Batch 4, accuracy/top1 = 0.58
I0817 10:57:51.106727 14586 caffe.cpp:313] Batch 4, accuracy/top5 = 0.8
I0817 10:57:51.106730 14586 caffe.cpp:313] Batch 4, loss = 1.84934
I0817 10:57:51.170087 14586 caffe.cpp:313] Batch 5, accuracy/top1 = 0.62
I0817 10:57:51.170110 14586 caffe.cpp:313] Batch 5, accuracy/top5 = 0.82
I0817 10:57:51.170114 14586 caffe.cpp:313] Batch 5, loss = 1.49525
I0817 10:57:51.233534 14586 caffe.cpp:313] Batch 6, accuracy/top1 = 0.68
I0817 10:57:51.233557 14586 caffe.cpp:313] Batch 6, accuracy/top5 = 0.84
I0817 10:57:51.233561 14586 caffe.cpp:313] Batch 6, loss = 1.49569
I0817 10:57:51.296880 14586 caffe.cpp:313] Batch 7, accuracy/top1 = 0.6
I0817 10:57:51.296902 14586 caffe.cpp:313] Batch 7, accuracy/top5 = 0.88
I0817 10:57:51.296905 14586 caffe.cpp:313] Batch 7, loss = 1.64795
I0817 10:57:51.360206 14586 caffe.cpp:313] Batch 8, accuracy/top1 = 0.68
I0817 10:57:51.360229 14586 caffe.cpp:313] Batch 8, accuracy/top5 = 0.86
I0817 10:57:51.360231 14586 caffe.cpp:313] Batch 8, loss = 1.40594
I0817 10:57:51.423601 14586 caffe.cpp:313] Batch 9, accuracy/top1 = 0.54
I0817 10:57:51.423624 14586 caffe.cpp:313] Batch 9, accuracy/top5 = 0.88
I0817 10:57:51.423627 14586 caffe.cpp:313] Batch 9, loss = 1.76956
I0817 10:57:51.486692 14586 caffe.cpp:313] Batch 10, accuracy/top1 = 0.56
I0817 10:57:51.486714 14586 caffe.cpp:313] Batch 10, accuracy/top5 = 0.9
I0817 10:57:51.486717 14586 caffe.cpp:313] Batch 10, loss = 1.49453
I0817 10:57:51.549417 14586 caffe.cpp:313] Batch 11, accuracy/top1 = 0.56
I0817 10:57:51.549435 14586 caffe.cpp:313] Batch 11, accuracy/top5 = 0.84
I0817 10:57:51.549438 14586 caffe.cpp:313] Batch 11, loss = 1.46103
I0817 10:57:51.612306 14586 caffe.cpp:313] Batch 12, accuracy/top1 = 0.62
I0817 10:57:51.612326 14586 caffe.cpp:313] Batch 12, accuracy/top5 = 0.92
I0817 10:57:51.612329 14586 caffe.cpp:313] Batch 12, loss = 1.52319
I0817 10:57:51.675375 14586 caffe.cpp:313] Batch 13, accuracy/top1 = 0.6
I0817 10:57:51.675396 14586 caffe.cpp:313] Batch 13, accuracy/top5 = 0.84
I0817 10:57:51.675400 14586 caffe.cpp:313] Batch 13, loss = 1.43364
I0817 10:57:51.738251 14586 caffe.cpp:313] Batch 14, accuracy/top1 = 0.4
I0817 10:57:51.738273 14586 caffe.cpp:313] Batch 14, accuracy/top5 = 0.82
I0817 10:57:51.738276 14586 caffe.cpp:313] Batch 14, loss = 2.19524
I0817 10:57:51.800796 14586 caffe.cpp:313] Batch 15, accuracy/top1 = 0.54
I0817 10:57:51.800817 14586 caffe.cpp:313] Batch 15, accuracy/top5 = 0.64
I0817 10:57:51.800820 14586 caffe.cpp:313] Batch 15, loss = 2.49439
I0817 10:57:51.863694 14586 caffe.cpp:313] Batch 16, accuracy/top1 = 0.46
I0817 10:57:51.863718 14586 caffe.cpp:313] Batch 16, accuracy/top5 = 0.84
I0817 10:57:51.863720 14586 caffe.cpp:313] Batch 16, loss = 2.05766
I0817 10:57:51.926304 14586 caffe.cpp:313] Batch 17, accuracy/top1 = 0.54
I0817 10:57:51.926326 14586 caffe.cpp:313] Batch 17, accuracy/top5 = 0.78
I0817 10:57:51.926329 14586 caffe.cpp:313] Batch 17, loss = 2.0313
I0817 10:57:51.989045 14586 caffe.cpp:313] Batch 18, accuracy/top1 = 0.62
I0817 10:57:51.989068 14586 caffe.cpp:313] Batch 18, accuracy/top5 = 0.88
I0817 10:57:51.989071 14586 caffe.cpp:313] Batch 18, loss = 1.68275
I0817 10:57:52.051730 14586 caffe.cpp:313] Batch 19, accuracy/top1 = 0.58
I0817 10:57:52.051749 14586 caffe.cpp:313] Batch 19, accuracy/top5 = 0.9
I0817 10:57:52.051753 14586 caffe.cpp:313] Batch 19, loss = 1.4788
I0817 10:57:52.114521 14586 caffe.cpp:313] Batch 20, accuracy/top1 = 0.58
I0817 10:57:52.114543 14586 caffe.cpp:313] Batch 20, accuracy/top5 = 0.78
I0817 10:57:52.114545 14586 caffe.cpp:313] Batch 20, loss = 1.73114
I0817 10:57:52.177261 14586 caffe.cpp:313] Batch 21, accuracy/top1 = 0.6
I0817 10:57:52.177283 14586 caffe.cpp:313] Batch 21, accuracy/top5 = 0.76
I0817 10:57:52.177285 14586 caffe.cpp:313] Batch 21, loss = 1.83138
I0817 10:57:52.240026 14586 caffe.cpp:313] Batch 22, accuracy/top1 = 0.5
I0817 10:57:52.240048 14586 caffe.cpp:313] Batch 22, accuracy/top5 = 0.8
I0817 10:57:52.240051 14586 caffe.cpp:313] Batch 22, loss = 2.14195
I0817 10:57:52.302752 14586 caffe.cpp:313] Batch 23, accuracy/top1 = 0.62
I0817 10:57:52.302774 14586 caffe.cpp:313] Batch 23, accuracy/top5 = 0.78
I0817 10:57:52.302778 14586 caffe.cpp:313] Batch 23, loss = 1.92474
I0817 10:57:52.365460 14586 caffe.cpp:313] Batch 24, accuracy/top1 = 0.62
I0817 10:57:52.365483 14586 caffe.cpp:313] Batch 24, accuracy/top5 = 0.9
I0817 10:57:52.365485 14586 caffe.cpp:313] Batch 24, loss = 1.46839
I0817 10:57:52.428242 14586 caffe.cpp:313] Batch 25, accuracy/top1 = 0.58
I0817 10:57:52.428264 14586 caffe.cpp:313] Batch 25, accuracy/top5 = 0.84
I0817 10:57:52.428267 14586 caffe.cpp:313] Batch 25, loss = 1.70408
I0817 10:57:52.490773 14586 caffe.cpp:313] Batch 26, accuracy/top1 = 0.5
I0817 10:57:52.490795 14586 caffe.cpp:313] Batch 26, accuracy/top5 = 0.84
I0817 10:57:52.490798 14586 caffe.cpp:313] Batch 26, loss = 1.88408
I0817 10:57:52.553411 14586 caffe.cpp:313] Batch 27, accuracy/top1 = 0.4
I0817 10:57:52.553428 14586 caffe.cpp:313] Batch 27, accuracy/top5 = 0.58
I0817 10:57:52.553431 14586 caffe.cpp:313] Batch 27, loss = 2.77319
I0817 10:57:52.616106 14586 caffe.cpp:313] Batch 28, accuracy/top1 = 0.62
I0817 10:57:52.616127 14586 caffe.cpp:313] Batch 28, accuracy/top5 = 0.8
I0817 10:57:52.616132 14586 caffe.cpp:313] Batch 28, loss = 1.56521
I0817 10:57:52.678856 14586 caffe.cpp:313] Batch 29, accuracy/top1 = 0.52
I0817 10:57:52.678877 14586 caffe.cpp:313] Batch 29, accuracy/top5 = 0.74
I0817 10:57:52.678880 14586 caffe.cpp:313] Batch 29, loss = 2.18478
I0817 10:57:52.741576 14586 caffe.cpp:313] Batch 30, accuracy/top1 = 0.56
I0817 10:57:52.741597 14586 caffe.cpp:313] Batch 30, accuracy/top5 = 0.78
I0817 10:57:52.741600 14586 caffe.cpp:313] Batch 30, loss = 2.1273
I0817 10:57:52.804214 14586 caffe.cpp:313] Batch 31, accuracy/top1 = 0.6
I0817 10:57:52.804235 14586 caffe.cpp:313] Batch 31, accuracy/top5 = 0.82
I0817 10:57:52.804239 14586 caffe.cpp:313] Batch 31, loss = 1.83202
I0817 10:57:52.867027 14586 caffe.cpp:313] Batch 32, accuracy/top1 = 0.56
I0817 10:57:52.867048 14586 caffe.cpp:313] Batch 32, accuracy/top5 = 0.78
I0817 10:57:52.867050 14586 caffe.cpp:313] Batch 32, loss = 2.07202
I0817 10:57:52.929792 14586 caffe.cpp:313] Batch 33, accuracy/top1 = 0.6
I0817 10:57:52.929814 14586 caffe.cpp:313] Batch 33, accuracy/top5 = 0.8
I0817 10:57:52.929817 14586 caffe.cpp:313] Batch 33, loss = 1.77043
I0817 10:57:52.992394 14586 caffe.cpp:313] Batch 34, accuracy/top1 = 0.48
I0817 10:57:52.992416 14586 caffe.cpp:313] Batch 34, accuracy/top5 = 0.84
I0817 10:57:52.992419 14586 caffe.cpp:313] Batch 34, loss = 1.94878
I0817 10:57:53.055146 14586 caffe.cpp:313] Batch 35, accuracy/top1 = 0.68
I0817 10:57:53.055166 14586 caffe.cpp:313] Batch 35, accuracy/top5 = 0.8
I0817 10:57:53.055169 14586 caffe.cpp:313] Batch 35, loss = 1.58228
I0817 10:57:53.117908 14586 caffe.cpp:313] Batch 36, accuracy/top1 = 0.56
I0817 10:57:53.117929 14586 caffe.cpp:313] Batch 36, accuracy/top5 = 0.72
I0817 10:57:53.117933 14586 caffe.cpp:313] Batch 36, loss = 2.00805
I0817 10:57:53.180560 14586 caffe.cpp:313] Batch 37, accuracy/top1 = 0.66
I0817 10:57:53.180583 14586 caffe.cpp:313] Batch 37, accuracy/top5 = 0.84
I0817 10:57:53.180585 14586 caffe.cpp:313] Batch 37, loss = 1.54862
I0817 10:57:53.243149 14586 caffe.cpp:313] Batch 38, accuracy/top1 = 0.46
I0817 10:57:53.243170 14586 caffe.cpp:313] Batch 38, accuracy/top5 = 0.72
I0817 10:57:53.243173 14586 caffe.cpp:313] Batch 38, loss = 2.7449
I0817 10:57:53.305663 14586 caffe.cpp:313] Batch 39, accuracy/top1 = 0.62
I0817 10:57:53.305685 14586 caffe.cpp:313] Batch 39, accuracy/top5 = 0.82
I0817 10:57:53.305688 14586 caffe.cpp:313] Batch 39, loss = 1.74577
I0817 10:57:53.368383 14586 caffe.cpp:313] Batch 40, accuracy/top1 = 0.5
I0817 10:57:53.368404 14586 caffe.cpp:313] Batch 40, accuracy/top5 = 0.76
I0817 10:57:53.368407 14586 caffe.cpp:313] Batch 40, loss = 2.37991
I0817 10:57:53.431022 14586 caffe.cpp:313] Batch 41, accuracy/top1 = 0.6
I0817 10:57:53.431044 14586 caffe.cpp:313] Batch 41, accuracy/top5 = 0.86
I0817 10:57:53.431047 14586 caffe.cpp:313] Batch 41, loss = 1.54302
I0817 10:57:53.493621 14586 caffe.cpp:313] Batch 42, accuracy/top1 = 0.58
I0817 10:57:53.493643 14586 caffe.cpp:313] Batch 42, accuracy/top5 = 0.8
I0817 10:57:53.493646 14586 caffe.cpp:313] Batch 42, loss = 1.94869
I0817 10:57:53.556147 14586 caffe.cpp:313] Batch 43, accuracy/top1 = 0.56
I0817 10:57:53.556169 14586 caffe.cpp:313] Batch 43, accuracy/top5 = 0.88
I0817 10:57:53.556172 14586 caffe.cpp:313] Batch 43, loss = 1.43864
I0817 10:57:53.618865 14586 caffe.cpp:313] Batch 44, accuracy/top1 = 0.52
I0817 10:57:53.618887 14586 caffe.cpp:313] Batch 44, accuracy/top5 = 0.8
I0817 10:57:53.618891 14586 caffe.cpp:313] Batch 44, loss = 1.75962
I0817 10:57:53.681476 14586 caffe.cpp:313] Batch 45, accuracy/top1 = 0.64
I0817 10:57:53.681498 14586 caffe.cpp:313] Batch 45, accuracy/top5 = 0.78
I0817 10:57:53.681500 14586 caffe.cpp:313] Batch 45, loss = 2.19617
I0817 10:57:53.744374 14586 caffe.cpp:313] Batch 46, accuracy/top1 = 0.68
I0817 10:57:53.744392 14586 caffe.cpp:313] Batch 46, accuracy/top5 = 0.86
I0817 10:57:53.744395 14586 caffe.cpp:313] Batch 46, loss = 1.47133
I0817 10:57:53.807435 14586 caffe.cpp:313] Batch 47, accuracy/top1 = 0.54
I0817 10:57:53.807459 14586 caffe.cpp:313] Batch 47, accuracy/top5 = 0.82
I0817 10:57:53.807466 14586 caffe.cpp:313] Batch 47, loss = 2.07006
I0817 10:57:53.870391 14586 caffe.cpp:313] Batch 48, accuracy/top1 = 0.56
I0817 10:57:53.870411 14586 caffe.cpp:313] Batch 48, accuracy/top5 = 0.8
I0817 10:57:53.870414 14586 caffe.cpp:313] Batch 48, loss = 1.9907
I0817 10:57:53.932920 14586 caffe.cpp:313] Batch 49, accuracy/top1 = 0.6
I0817 10:57:53.932941 14586 caffe.cpp:313] Batch 49, accuracy/top5 = 0.84
I0817 10:57:53.932945 14586 caffe.cpp:313] Batch 49, loss = 1.58422
I0817 10:57:53.995560 14586 caffe.cpp:313] Batch 50, accuracy/top1 = 0.56
I0817 10:57:53.995581 14586 caffe.cpp:313] Batch 50, accuracy/top5 = 0.8
I0817 10:57:53.995584 14586 caffe.cpp:313] Batch 50, loss = 1.98026
I0817 10:57:54.058305 14586 caffe.cpp:313] Batch 51, accuracy/top1 = 0.62
I0817 10:57:54.058324 14586 caffe.cpp:313] Batch 51, accuracy/top5 = 0.76
I0817 10:57:54.058327 14586 caffe.cpp:313] Batch 51, loss = 1.97373
I0817 10:57:54.120982 14586 caffe.cpp:313] Batch 52, accuracy/top1 = 0.58
I0817 10:57:54.121003 14586 caffe.cpp:313] Batch 52, accuracy/top5 = 0.8
I0817 10:57:54.121006 14586 caffe.cpp:313] Batch 52, loss = 1.80765
I0817 10:57:54.183593 14586 caffe.cpp:313] Batch 53, accuracy/top1 = 0.52
I0817 10:57:54.183614 14586 caffe.cpp:313] Batch 53, accuracy/top5 = 0.74
I0817 10:57:54.183616 14586 caffe.cpp:313] Batch 53, loss = 2.31881
I0817 10:57:54.246362 14586 caffe.cpp:313] Batch 54, accuracy/top1 = 0.66
I0817 10:57:54.246383 14586 caffe.cpp:313] Batch 54, accuracy/top5 = 0.9
I0817 10:57:54.246387 14586 caffe.cpp:313] Batch 54, loss = 1.30271
I0817 10:57:54.308897 14586 caffe.cpp:313] Batch 55, accuracy/top1 = 0.52
I0817 10:57:54.308918 14586 caffe.cpp:313] Batch 55, accuracy/top5 = 0.86
I0817 10:57:54.308920 14586 caffe.cpp:313] Batch 55, loss = 1.58272
I0817 10:57:54.371451 14586 caffe.cpp:313] Batch 56, accuracy/top1 = 0.6
I0817 10:57:54.371474 14586 caffe.cpp:313] Batch 56, accuracy/top5 = 0.92
I0817 10:57:54.371476 14586 caffe.cpp:313] Batch 56, loss = 1.26041
I0817 10:57:54.433982 14586 caffe.cpp:313] Batch 57, accuracy/top1 = 0.62
I0817 10:57:54.434003 14586 caffe.cpp:313] Batch 57, accuracy/top5 = 0.82
I0817 10:57:54.434006 14586 caffe.cpp:313] Batch 57, loss = 1.94489
I0817 10:57:54.496585 14586 caffe.cpp:313] Batch 58, accuracy/top1 = 0.68
I0817 10:57:54.496608 14586 caffe.cpp:313] Batch 58, accuracy/top5 = 0.88
I0817 10:57:54.496611 14586 caffe.cpp:313] Batch 58, loss = 1.41544
I0817 10:57:54.559353 14586 caffe.cpp:313] Batch 59, accuracy/top1 = 0.72
I0817 10:57:54.559375 14586 caffe.cpp:313] Batch 59, accuracy/top5 = 0.86
I0817 10:57:54.559377 14586 caffe.cpp:313] Batch 59, loss = 1.2853
I0817 10:57:54.622099 14586 caffe.cpp:313] Batch 60, accuracy/top1 = 0.68
I0817 10:57:54.622120 14586 caffe.cpp:313] Batch 60, accuracy/top5 = 0.88
I0817 10:57:54.622123 14586 caffe.cpp:313] Batch 60, loss = 1.45283
I0817 10:57:54.684844 14586 caffe.cpp:313] Batch 61, accuracy/top1 = 0.56
I0817 10:57:54.684865 14586 caffe.cpp:313] Batch 61, accuracy/top5 = 0.86
I0817 10:57:54.684867 14586 caffe.cpp:313] Batch 61, loss = 1.86753
I0817 10:57:54.747694 14586 caffe.cpp:313] Batch 62, accuracy/top1 = 0.52
I0817 10:57:54.747715 14586 caffe.cpp:313] Batch 62, accuracy/top5 = 0.88
I0817 10:57:54.747719 14586 caffe.cpp:313] Batch 62, loss = 1.44831
I0817 10:57:54.810582 14586 caffe.cpp:313] Batch 63, accuracy/top1 = 0.6
I0817 10:57:54.810602 14586 caffe.cpp:313] Batch 63, accuracy/top5 = 0.78
I0817 10:57:54.810606 14586 caffe.cpp:313] Batch 63, loss = 1.7154
I0817 10:57:54.873379 14586 caffe.cpp:313] Batch 64, accuracy/top1 = 0.52
I0817 10:57:54.873400 14586 caffe.cpp:313] Batch 64, accuracy/top5 = 0.74
I0817 10:57:54.873404 14586 caffe.cpp:313] Batch 64, loss = 1.95209
I0817 10:57:54.935953 14586 caffe.cpp:313] Batch 65, accuracy/top1 = 0.54
I0817 10:57:54.935976 14586 caffe.cpp:313] Batch 65, accuracy/top5 = 0.76
I0817 10:57:54.935978 14586 caffe.cpp:313] Batch 65, loss = 1.97649
I0817 10:57:54.998503 14586 caffe.cpp:313] Batch 66, accuracy/top1 = 0.66
I0817 10:57:54.998524 14586 caffe.cpp:313] Batch 66, accuracy/top5 = 0.78
I0817 10:57:54.998528 14586 caffe.cpp:313] Batch 66, loss = 1.56599
I0817 10:57:55.061188 14586 caffe.cpp:313] Batch 67, accuracy/top1 = 0.54
I0817 10:57:55.061209 14586 caffe.cpp:313] Batch 67, accuracy/top5 = 0.8
I0817 10:57:55.061213 14586 caffe.cpp:313] Batch 67, loss = 1.86031
I0817 10:57:55.123952 14586 caffe.cpp:313] Batch 68, accuracy/top1 = 0.66
I0817 10:57:55.123972 14586 caffe.cpp:313] Batch 68, accuracy/top5 = 0.88
I0817 10:57:55.123975 14586 caffe.cpp:313] Batch 68, loss = 1.33767
I0817 10:57:55.186655 14586 caffe.cpp:313] Batch 69, accuracy/top1 = 0.58
I0817 10:57:55.186677 14586 caffe.cpp:313] Batch 69, accuracy/top5 = 0.78
I0817 10:57:55.186681 14586 caffe.cpp:313] Batch 69, loss = 1.8876
I0817 10:57:55.249305 14586 caffe.cpp:313] Batch 70, accuracy/top1 = 0.46
I0817 10:57:55.249326 14586 caffe.cpp:313] Batch 70, accuracy/top5 = 0.72
I0817 10:57:55.249330 14586 caffe.cpp:313] Batch 70, loss = 2.24997
I0817 10:57:55.311908 14586 caffe.cpp:313] Batch 71, accuracy/top1 = 0.46
I0817 10:57:55.311928 14586 caffe.cpp:313] Batch 71, accuracy/top5 = 0.76
I0817 10:57:55.311931 14586 caffe.cpp:313] Batch 71, loss = 2.31639
I0817 10:57:55.374552 14586 caffe.cpp:313] Batch 72, accuracy/top1 = 0.62
I0817 10:57:55.374574 14586 caffe.cpp:313] Batch 72, accuracy/top5 = 0.82
I0817 10:57:55.374577 14586 caffe.cpp:313] Batch 72, loss = 1.55839
I0817 10:57:55.437122 14586 caffe.cpp:313] Batch 73, accuracy/top1 = 0.62
I0817 10:57:55.437144 14586 caffe.cpp:313] Batch 73, accuracy/top5 = 0.86
I0817 10:57:55.437147 14586 caffe.cpp:313] Batch 73, loss = 1.60004
I0817 10:57:55.499799 14586 caffe.cpp:313] Batch 74, accuracy/top1 = 0.58
I0817 10:57:55.499821 14586 caffe.cpp:313] Batch 74, accuracy/top5 = 0.84
I0817 10:57:55.499825 14586 caffe.cpp:313] Batch 74, loss = 1.65913
I0817 10:57:55.562505 14586 caffe.cpp:313] Batch 75, accuracy/top1 = 0.6
I0817 10:57:55.562527 14586 caffe.cpp:313] Batch 75, accuracy/top5 = 0.78
I0817 10:57:55.562530 14586 caffe.cpp:313] Batch 75, loss = 1.85807
I0817 10:57:55.625185 14586 caffe.cpp:313] Batch 76, accuracy/top1 = 0.6
I0817 10:57:55.625207 14586 caffe.cpp:313] Batch 76, accuracy/top5 = 0.72
I0817 10:57:55.625211 14586 caffe.cpp:313] Batch 76, loss = 1.92032
I0817 10:57:55.687929 14586 caffe.cpp:313] Batch 77, accuracy/top1 = 0.6
I0817 10:57:55.687949 14586 caffe.cpp:313] Batch 77, accuracy/top5 = 0.88
I0817 10:57:55.687952 14586 caffe.cpp:313] Batch 77, loss = 1.56644
I0817 10:57:55.750633 14586 caffe.cpp:313] Batch 78, accuracy/top1 = 0.54
I0817 10:57:55.750653 14586 caffe.cpp:313] Batch 78, accuracy/top5 = 0.74
I0817 10:57:55.750656 14586 caffe.cpp:313] Batch 78, loss = 2.17431
I0817 10:57:55.813415 14586 caffe.cpp:313] Batch 79, accuracy/top1 = 0.74
I0817 10:57:55.813438 14586 caffe.cpp:313] Batch 79, accuracy/top5 = 0.88
I0817 10:57:55.813442 14586 caffe.cpp:313] Batch 79, loss = 1.28216
I0817 10:57:55.876536 14586 caffe.cpp:313] Batch 80, accuracy/top1 = 0.42
I0817 10:57:55.876556 14586 caffe.cpp:313] Batch 80, accuracy/top5 = 0.72
I0817 10:57:55.876560 14586 caffe.cpp:313] Batch 80, loss = 2.35615
I0817 10:57:55.939347 14586 caffe.cpp:313] Batch 81, accuracy/top1 = 0.68
I0817 10:57:55.939368 14586 caffe.cpp:313] Batch 81, accuracy/top5 = 0.82
I0817 10:57:55.939371 14586 caffe.cpp:313] Batch 81, loss = 1.6862
I0817 10:57:56.002151 14586 caffe.cpp:313] Batch 82, accuracy/top1 = 0.58
I0817 10:57:56.002174 14586 caffe.cpp:313] Batch 82, accuracy/top5 = 0.76
I0817 10:57:56.002178 14586 caffe.cpp:313] Batch 82, loss = 1.79458
I0817 10:57:56.064882 14586 caffe.cpp:313] Batch 83, accuracy/top1 = 0.58
I0817 10:57:56.064903 14586 caffe.cpp:313] Batch 83, accuracy/top5 = 0.72
I0817 10:57:56.064908 14586 caffe.cpp:313] Batch 83, loss = 2.27786
I0817 10:57:56.127538 14586 caffe.cpp:313] Batch 84, accuracy/top1 = 0.62
I0817 10:57:56.127562 14586 caffe.cpp:313] Batch 84, accuracy/top5 = 0.72
I0817 10:57:56.127565 14586 caffe.cpp:313] Batch 84, loss = 1.94173
I0817 10:57:56.190114 14586 caffe.cpp:313] Batch 85, accuracy/top1 = 0.72
I0817 10:57:56.190135 14586 caffe.cpp:313] Batch 85, accuracy/top5 = 0.92
I0817 10:57:56.190140 14586 caffe.cpp:313] Batch 85, loss = 1.1818
I0817 10:57:56.252650 14586 caffe.cpp:313] Batch 86, accuracy/top1 = 0.52
I0817 10:57:56.252671 14586 caffe.cpp:313] Batch 86, accuracy/top5 = 0.68
I0817 10:57:56.252673 14586 caffe.cpp:313] Batch 86, loss = 2.04404
I0817 10:57:56.315187 14586 caffe.cpp:313] Batch 87, accuracy/top1 = 0.62
I0817 10:57:56.315210 14586 caffe.cpp:313] Batch 87, accuracy/top5 = 0.8
I0817 10:57:56.315214 14586 caffe.cpp:313] Batch 87, loss = 1.69167
I0817 10:57:56.377946 14586 caffe.cpp:313] Batch 88, accuracy/top1 = 0.68
I0817 10:57:56.377969 14586 caffe.cpp:313] Batch 88, accuracy/top5 = 0.84
I0817 10:57:56.377972 14586 caffe.cpp:313] Batch 88, loss = 1.47968
I0817 10:57:56.440668 14586 caffe.cpp:313] Batch 89, accuracy/top1 = 0.56
I0817 10:57:56.440690 14586 caffe.cpp:313] Batch 89, accuracy/top5 = 0.78
I0817 10:57:56.440695 14586 caffe.cpp:313] Batch 89, loss = 2.03301
I0817 10:57:56.503404 14586 caffe.cpp:313] Batch 90, accuracy/top1 = 0.66
I0817 10:57:56.503427 14586 caffe.cpp:313] Batch 90, accuracy/top5 = 0.88
I0817 10:57:56.503430 14586 caffe.cpp:313] Batch 90, loss = 1.2904
I0817 10:57:56.566108 14586 caffe.cpp:313] Batch 91, accuracy/top1 = 0.62
I0817 10:57:56.566129 14586 caffe.cpp:313] Batch 91, accuracy/top5 = 0.74
I0817 10:57:56.566133 14586 caffe.cpp:313] Batch 91, loss = 2.06707
I0817 10:57:56.629509 14586 caffe.cpp:313] Batch 92, accuracy/top1 = 0.58
I0817 10:57:56.629528 14586 caffe.cpp:313] Batch 92, accuracy/top5 = 0.74
I0817 10:57:56.629531 14586 caffe.cpp:313] Batch 92, loss = 2.2136
I0817 10:57:56.692783 14586 caffe.cpp:313] Batch 93, accuracy/top1 = 0.6
I0817 10:57:56.692806 14586 caffe.cpp:313] Batch 93, accuracy/top5 = 0.88
I0817 10:57:56.692809 14586 caffe.cpp:313] Batch 93, loss = 1.80411
I0817 10:57:56.755609 14586 caffe.cpp:313] Batch 94, accuracy/top1 = 0.7
I0817 10:57:56.755632 14586 caffe.cpp:313] Batch 94, accuracy/top5 = 0.9
I0817 10:57:56.755635 14586 caffe.cpp:313] Batch 94, loss = 1.20374
I0817 10:57:56.818567 14586 caffe.cpp:313] Batch 95, accuracy/top1 = 0.52
I0817 10:57:56.818589 14586 caffe.cpp:313] Batch 95, accuracy/top5 = 0.76
I0817 10:57:56.818594 14586 caffe.cpp:313] Batch 95, loss = 1.99482
I0817 10:57:56.881438 14586 caffe.cpp:313] Batch 96, accuracy/top1 = 0.5
I0817 10:57:56.881460 14586 caffe.cpp:313] Batch 96, accuracy/top5 = 0.7
I0817 10:57:56.881465 14586 caffe.cpp:313] Batch 96, loss = 2.16252
I0817 10:57:56.944123 14586 caffe.cpp:313] Batch 97, accuracy/top1 = 0.64
I0817 10:57:56.944145 14586 caffe.cpp:313] Batch 97, accuracy/top5 = 0.82
I0817 10:57:56.944150 14586 caffe.cpp:313] Batch 97, loss = 1.58355
I0817 10:57:57.006845 14586 caffe.cpp:313] Batch 98, accuracy/top1 = 0.56
I0817 10:57:57.006868 14586 caffe.cpp:313] Batch 98, accuracy/top5 = 0.9
I0817 10:57:57.006872 14586 caffe.cpp:313] Batch 98, loss = 1.75274
I0817 10:57:57.069597 14586 caffe.cpp:313] Batch 99, accuracy/top1 = 0.6
I0817 10:57:57.069617 14586 caffe.cpp:313] Batch 99, accuracy/top5 = 0.82
I0817 10:57:57.069622 14586 caffe.cpp:313] Batch 99, loss = 1.73168
I0817 10:57:57.132164 14586 caffe.cpp:313] Batch 100, accuracy/top1 = 0.64
I0817 10:57:57.132187 14586 caffe.cpp:313] Batch 100, accuracy/top5 = 0.82
I0817 10:57:57.132191 14586 caffe.cpp:313] Batch 100, loss = 1.41638
I0817 10:57:57.194962 14586 caffe.cpp:313] Batch 101, accuracy/top1 = 0.68
I0817 10:57:57.194984 14586 caffe.cpp:313] Batch 101, accuracy/top5 = 0.84
I0817 10:57:57.194988 14586 caffe.cpp:313] Batch 101, loss = 1.54682
I0817 10:57:57.257711 14586 caffe.cpp:313] Batch 102, accuracy/top1 = 0.54
I0817 10:57:57.257733 14586 caffe.cpp:313] Batch 102, accuracy/top5 = 0.74
I0817 10:57:57.257738 14586 caffe.cpp:313] Batch 102, loss = 2.64861
I0817 10:57:57.320371 14586 caffe.cpp:313] Batch 103, accuracy/top1 = 0.72
I0817 10:57:57.320394 14586 caffe.cpp:313] Batch 103, accuracy/top5 = 0.9
I0817 10:57:57.320397 14586 caffe.cpp:313] Batch 103, loss = 1.32351
I0817 10:57:57.383038 14586 caffe.cpp:313] Batch 104, accuracy/top1 = 0.58
I0817 10:57:57.383060 14586 caffe.cpp:313] Batch 104, accuracy/top5 = 0.82
I0817 10:57:57.383064 14586 caffe.cpp:313] Batch 104, loss = 1.70292
I0817 10:57:57.445639 14586 caffe.cpp:313] Batch 105, accuracy/top1 = 0.62
I0817 10:57:57.445662 14586 caffe.cpp:313] Batch 105, accuracy/top5 = 0.72
I0817 10:57:57.445665 14586 caffe.cpp:313] Batch 105, loss = 1.93917
I0817 10:57:57.508272 14586 caffe.cpp:313] Batch 106, accuracy/top1 = 0.54
I0817 10:57:57.508294 14586 caffe.cpp:313] Batch 106, accuracy/top5 = 0.82
I0817 10:57:57.508298 14586 caffe.cpp:313] Batch 106, loss = 1.83209
I0817 10:57:57.570838 14586 caffe.cpp:313] Batch 107, accuracy/top1 = 0.48
I0817 10:57:57.570860 14586 caffe.cpp:313] Batch 107, accuracy/top5 = 0.72
I0817 10:57:57.570864 14586 caffe.cpp:313] Batch 107, loss = 2.02659
I0817 10:57:57.633514 14586 caffe.cpp:313] Batch 108, accuracy/top1 = 0.56
I0817 10:57:57.633538 14586 caffe.cpp:313] Batch 108, accuracy/top5 = 0.86
I0817 10:57:57.633543 14586 caffe.cpp:313] Batch 108, loss = 1.51517
I0817 10:57:57.696262 14586 caffe.cpp:313] Batch 109, accuracy/top1 = 0.68
I0817 10:57:57.696285 14586 caffe.cpp:313] Batch 109, accuracy/top5 = 0.76
I0817 10:57:57.696290 14586 caffe.cpp:313] Batch 109, loss = 1.38229
I0817 10:57:57.759160 14586 caffe.cpp:313] Batch 110, accuracy/top1 = 0.56
I0817 10:57:57.759182 14586 caffe.cpp:313] Batch 110, accuracy/top5 = 0.74
I0817 10:57:57.759186 14586 caffe.cpp:313] Batch 110, loss = 2.2348
I0817 10:57:57.822077 14586 caffe.cpp:313] Batch 111, accuracy/top1 = 0.48
I0817 10:57:57.822098 14586 caffe.cpp:313] Batch 111, accuracy/top5 = 0.8
I0817 10:57:57.822101 14586 caffe.cpp:313] Batch 111, loss = 2.02209
I0817 10:57:57.884855 14586 caffe.cpp:313] Batch 112, accuracy/top1 = 0.6
I0817 10:57:57.884876 14586 caffe.cpp:313] Batch 112, accuracy/top5 = 0.7
I0817 10:57:57.884879 14586 caffe.cpp:313] Batch 112, loss = 2.04168
I0817 10:57:57.947598 14586 caffe.cpp:313] Batch 113, accuracy/top1 = 0.6
I0817 10:57:57.947620 14586 caffe.cpp:313] Batch 113, accuracy/top5 = 0.84
I0817 10:57:57.947624 14586 caffe.cpp:313] Batch 113, loss = 1.37556
I0817 10:57:58.010315 14586 caffe.cpp:313] Batch 114, accuracy/top1 = 0.58
I0817 10:57:58.010335 14586 caffe.cpp:313] Batch 114, accuracy/top5 = 0.8
I0817 10:57:58.010339 14586 caffe.cpp:313] Batch 114, loss = 1.74078
I0817 10:57:58.073732 14586 caffe.cpp:313] Batch 115, accuracy/top1 = 0.56
I0817 10:57:58.073753 14586 caffe.cpp:313] Batch 115, accuracy/top5 = 0.82
I0817 10:57:58.073758 14586 caffe.cpp:313] Batch 115, loss = 1.91175
I0817 10:57:58.137236 14586 caffe.cpp:313] Batch 116, accuracy/top1 = 0.52
I0817 10:57:58.137259 14586 caffe.cpp:313] Batch 116, accuracy/top5 = 0.76
I0817 10:57:58.137262 14586 caffe.cpp:313] Batch 116, loss = 1.94746
I0817 10:57:58.199870 14586 caffe.cpp:313] Batch 117, accuracy/top1 = 0.48
I0817 10:57:58.199893 14586 caffe.cpp:313] Batch 117, accuracy/top5 = 0.84
I0817 10:57:58.199898 14586 caffe.cpp:313] Batch 117, loss = 2.14356
I0817 10:57:58.262686 14586 caffe.cpp:313] Batch 118, accuracy/top1 = 0.44
I0817 10:57:58.262707 14586 caffe.cpp:313] Batch 118, accuracy/top5 = 0.74
I0817 10:57:58.262712 14586 caffe.cpp:313] Batch 118, loss = 2.75622
I0817 10:57:58.325318 14586 caffe.cpp:313] Batch 119, accuracy/top1 = 0.62
I0817 10:57:58.325340 14586 caffe.cpp:313] Batch 119, accuracy/top5 = 0.88
I0817 10:57:58.325345 14586 caffe.cpp:313] Batch 119, loss = 1.50651
I0817 10:57:58.388072 14586 caffe.cpp:313] Batch 120, accuracy/top1 = 0.56
I0817 10:57:58.388094 14586 caffe.cpp:313] Batch 120, accuracy/top5 = 0.8
I0817 10:57:58.388098 14586 caffe.cpp:313] Batch 120, loss = 1.96157
I0817 10:57:58.450742 14586 caffe.cpp:313] Batch 121, accuracy/top1 = 0.6
I0817 10:57:58.450764 14586 caffe.cpp:313] Batch 121, accuracy/top5 = 0.82
I0817 10:57:58.450768 14586 caffe.cpp:313] Batch 121, loss = 1.74989
I0817 10:57:58.513425 14586 caffe.cpp:313] Batch 122, accuracy/top1 = 0.56
I0817 10:57:58.513448 14586 caffe.cpp:313] Batch 122, accuracy/top5 = 0.76
I0817 10:57:58.513453 14586 caffe.cpp:313] Batch 122, loss = 2.48693
I0817 10:57:58.576114 14586 caffe.cpp:313] Batch 123, accuracy/top1 = 0.56
I0817 10:57:58.576139 14586 caffe.cpp:313] Batch 123, accuracy/top5 = 0.76
I0817 10:57:58.576160 14586 caffe.cpp:313] Batch 123, loss = 2.07288
I0817 10:57:58.638845 14586 caffe.cpp:313] Batch 124, accuracy/top1 = 0.6
I0817 10:57:58.638864 14586 caffe.cpp:313] Batch 124, accuracy/top5 = 0.8
I0817 10:57:58.638867 14586 caffe.cpp:313] Batch 124, loss = 1.80008
I0817 10:57:58.701387 14586 caffe.cpp:313] Batch 125, accuracy/top1 = 0.6
I0817 10:57:58.701409 14586 caffe.cpp:313] Batch 125, accuracy/top5 = 0.9
I0817 10:57:58.701414 14586 caffe.cpp:313] Batch 125, loss = 1.49647
I0817 10:57:58.764155 14586 caffe.cpp:313] Batch 126, accuracy/top1 = 0.46
I0817 10:57:58.764178 14586 caffe.cpp:313] Batch 126, accuracy/top5 = 0.82
I0817 10:57:58.764183 14586 caffe.cpp:313] Batch 126, loss = 1.90199
I0817 10:57:58.827327 14586 caffe.cpp:313] Batch 127, accuracy/top1 = 0.48
I0817 10:57:58.827345 14586 caffe.cpp:313] Batch 127, accuracy/top5 = 0.8
I0817 10:57:58.827349 14586 caffe.cpp:313] Batch 127, loss = 2.13003
I0817 10:57:58.890012 14586 caffe.cpp:313] Batch 128, accuracy/top1 = 0.66
I0817 10:57:58.890033 14586 caffe.cpp:313] Batch 128, accuracy/top5 = 0.8
I0817 10:57:58.890038 14586 caffe.cpp:313] Batch 128, loss = 1.56317
I0817 10:57:58.952783 14586 caffe.cpp:313] Batch 129, accuracy/top1 = 0.52
I0817 10:57:58.952805 14586 caffe.cpp:313] Batch 129, accuracy/top5 = 0.82
I0817 10:57:58.952810 14586 caffe.cpp:313] Batch 129, loss = 1.70511
I0817 10:57:59.015434 14586 caffe.cpp:313] Batch 130, accuracy/top1 = 0.56
I0817 10:57:59.015456 14586 caffe.cpp:313] Batch 130, accuracy/top5 = 0.86
I0817 10:57:59.015460 14586 caffe.cpp:313] Batch 130, loss = 1.63818
I0817 10:57:59.078198 14586 caffe.cpp:313] Batch 131, accuracy/top1 = 0.62
I0817 10:57:59.078219 14586 caffe.cpp:313] Batch 131, accuracy/top5 = 0.86
I0817 10:57:59.078223 14586 caffe.cpp:313] Batch 131, loss = 1.4631
I0817 10:57:59.140825 14586 caffe.cpp:313] Batch 132, accuracy/top1 = 0.7
I0817 10:57:59.140848 14586 caffe.cpp:313] Batch 132, accuracy/top5 = 0.82
I0817 10:57:59.140852 14586 caffe.cpp:313] Batch 132, loss = 1.89883
I0817 10:57:59.203533 14586 caffe.cpp:313] Batch 133, accuracy/top1 = 0.56
I0817 10:57:59.203557 14586 caffe.cpp:313] Batch 133, accuracy/top5 = 0.8
I0817 10:57:59.203560 14586 caffe.cpp:313] Batch 133, loss = 2.06515
I0817 10:57:59.266214 14586 caffe.cpp:313] Batch 134, accuracy/top1 = 0.7
I0817 10:57:59.266237 14586 caffe.cpp:313] Batch 134, accuracy/top5 = 0.86
I0817 10:57:59.266242 14586 caffe.cpp:313] Batch 134, loss = 1.46174
I0817 10:57:59.329000 14586 caffe.cpp:313] Batch 135, accuracy/top1 = 0.5
I0817 10:57:59.329021 14586 caffe.cpp:313] Batch 135, accuracy/top5 = 0.84
I0817 10:57:59.329025 14586 caffe.cpp:313] Batch 135, loss = 1.81297
I0817 10:57:59.391571 14586 caffe.cpp:313] Batch 136, accuracy/top1 = 0.5
I0817 10:57:59.391593 14586 caffe.cpp:313] Batch 136, accuracy/top5 = 0.72
I0817 10:57:59.391597 14586 caffe.cpp:313] Batch 136, loss = 2.18077
I0817 10:57:59.454111 14586 caffe.cpp:313] Batch 137, accuracy/top1 = 0.56
I0817 10:57:59.454134 14586 caffe.cpp:313] Batch 137, accuracy/top5 = 0.88
I0817 10:57:59.454138 14586 caffe.cpp:313] Batch 137, loss = 1.4792
I0817 10:57:59.516649 14586 caffe.cpp:313] Batch 138, accuracy/top1 = 0.64
I0817 10:57:59.516672 14586 caffe.cpp:313] Batch 138, accuracy/top5 = 0.84
I0817 10:57:59.516676 14586 caffe.cpp:313] Batch 138, loss = 1.55811
I0817 10:57:59.579275 14586 caffe.cpp:313] Batch 139, accuracy/top1 = 0.62
I0817 10:57:59.579298 14586 caffe.cpp:313] Batch 139, accuracy/top5 = 0.74
I0817 10:57:59.579301 14586 caffe.cpp:313] Batch 139, loss = 2.11356
I0817 10:57:59.642007 14586 caffe.cpp:313] Batch 140, accuracy/top1 = 0.58
I0817 10:57:59.642030 14586 caffe.cpp:313] Batch 140, accuracy/top5 = 0.76
I0817 10:57:59.642033 14586 caffe.cpp:313] Batch 140, loss = 2.06228
I0817 10:57:59.704699 14586 caffe.cpp:313] Batch 141, accuracy/top1 = 0.6
I0817 10:57:59.704721 14586 caffe.cpp:313] Batch 141, accuracy/top5 = 0.88
I0817 10:57:59.704725 14586 caffe.cpp:313] Batch 141, loss = 1.44511
I0817 10:57:59.767439 14586 caffe.cpp:313] Batch 142, accuracy/top1 = 0.58
I0817 10:57:59.767474 14586 caffe.cpp:313] Batch 142, accuracy/top5 = 0.8
I0817 10:57:59.767478 14586 caffe.cpp:313] Batch 142, loss = 1.94373
I0817 10:57:59.830643 14586 caffe.cpp:313] Batch 143, accuracy/top1 = 0.52
I0817 10:57:59.830668 14586 caffe.cpp:313] Batch 143, accuracy/top5 = 0.74
I0817 10:57:59.830672 14586 caffe.cpp:313] Batch 143, loss = 2.16175
I0817 10:57:59.893448 14586 caffe.cpp:313] Batch 144, accuracy/top1 = 0.56
I0817 10:57:59.893471 14586 caffe.cpp:313] Batch 144, accuracy/top5 = 0.82
I0817 10:57:59.893474 14586 caffe.cpp:313] Batch 144, loss = 1.81736
I0817 10:57:59.956032 14586 caffe.cpp:313] Batch 145, accuracy/top1 = 0.68
I0817 10:57:59.956053 14586 caffe.cpp:313] Batch 145, accuracy/top5 = 0.88
I0817 10:57:59.956058 14586 caffe.cpp:313] Batch 145, loss = 1.56382
I0817 10:58:00.018630 14586 caffe.cpp:313] Batch 146, accuracy/top1 = 0.64
I0817 10:58:00.018652 14586 caffe.cpp:313] Batch 146, accuracy/top5 = 0.86
I0817 10:58:00.018656 14586 caffe.cpp:313] Batch 146, loss = 1.42823
I0817 10:58:00.081171 14586 caffe.cpp:313] Batch 147, accuracy/top1 = 0.62
I0817 10:58:00.081192 14586 caffe.cpp:313] Batch 147, accuracy/top5 = 0.92
I0817 10:58:00.081195 14586 caffe.cpp:313] Batch 147, loss = 1.39673
I0817 10:58:00.144297 14586 caffe.cpp:313] Batch 148, accuracy/top1 = 0.52
I0817 10:58:00.144318 14586 caffe.cpp:313] Batch 148, accuracy/top5 = 0.82
I0817 10:58:00.144322 14586 caffe.cpp:313] Batch 148, loss = 2.05899
I0817 10:58:00.206985 14586 caffe.cpp:313] Batch 149, accuracy/top1 = 0.62
I0817 10:58:00.207006 14586 caffe.cpp:313] Batch 149, accuracy/top5 = 0.88
I0817 10:58:00.207010 14586 caffe.cpp:313] Batch 149, loss = 1.37888
I0817 10:58:00.269794 14586 caffe.cpp:313] Batch 150, accuracy/top1 = 0.58
I0817 10:58:00.269816 14586 caffe.cpp:313] Batch 150, accuracy/top5 = 0.8
I0817 10:58:00.269820 14586 caffe.cpp:313] Batch 150, loss = 1.91818
I0817 10:58:00.332412 14586 caffe.cpp:313] Batch 151, accuracy/top1 = 0.6
I0817 10:58:00.332434 14586 caffe.cpp:313] Batch 151, accuracy/top5 = 0.84
I0817 10:58:00.332438 14586 caffe.cpp:313] Batch 151, loss = 1.51594
I0817 10:58:00.395045 14586 caffe.cpp:313] Batch 152, accuracy/top1 = 0.56
I0817 10:58:00.395066 14586 caffe.cpp:313] Batch 152, accuracy/top5 = 0.8
I0817 10:58:00.395071 14586 caffe.cpp:313] Batch 152, loss = 1.85548
I0817 10:58:00.457640 14586 caffe.cpp:313] Batch 153, accuracy/top1 = 0.52
I0817 10:58:00.457662 14586 caffe.cpp:313] Batch 153, accuracy/top5 = 0.82
I0817 10:58:00.457666 14586 caffe.cpp:313] Batch 153, loss = 2.18714
I0817 10:58:00.520334 14586 caffe.cpp:313] Batch 154, accuracy/top1 = 0.62
I0817 10:58:00.520356 14586 caffe.cpp:313] Batch 154, accuracy/top5 = 0.82
I0817 10:58:00.520360 14586 caffe.cpp:313] Batch 154, loss = 1.4433
I0817 10:58:00.582932 14586 caffe.cpp:313] Batch 155, accuracy/top1 = 0.58
I0817 10:58:00.582954 14586 caffe.cpp:313] Batch 155, accuracy/top5 = 0.8
I0817 10:58:00.582958 14586 caffe.cpp:313] Batch 155, loss = 1.70884
I0817 10:58:00.645548 14586 caffe.cpp:313] Batch 156, accuracy/top1 = 0.68
I0817 10:58:00.645571 14586 caffe.cpp:313] Batch 156, accuracy/top5 = 0.84
I0817 10:58:00.645576 14586 caffe.cpp:313] Batch 156, loss = 1.84108
I0817 10:58:00.708426 14586 caffe.cpp:313] Batch 157, accuracy/top1 = 0.58
I0817 10:58:00.708448 14586 caffe.cpp:313] Batch 157, accuracy/top5 = 0.84
I0817 10:58:00.708452 14586 caffe.cpp:313] Batch 157, loss = 1.60762
I0817 10:58:00.771106 14586 caffe.cpp:313] Batch 158, accuracy/top1 = 0.68
I0817 10:58:00.771127 14586 caffe.cpp:313] Batch 158, accuracy/top5 = 0.84
I0817 10:58:00.771131 14586 caffe.cpp:313] Batch 158, loss = 1.56315
I0817 10:58:00.834374 14586 caffe.cpp:313] Batch 159, accuracy/top1 = 0.58
I0817 10:58:00.834393 14586 caffe.cpp:313] Batch 159, accuracy/top5 = 0.78
I0817 10:58:00.834396 14586 caffe.cpp:313] Batch 159, loss = 1.99483
I0817 10:58:00.897104 14586 caffe.cpp:313] Batch 160, accuracy/top1 = 0.68
I0817 10:58:00.897126 14586 caffe.cpp:313] Batch 160, accuracy/top5 = 0.84
I0817 10:58:00.897130 14586 caffe.cpp:313] Batch 160, loss = 1.67234
I0817 10:58:00.959772 14586 caffe.cpp:313] Batch 161, accuracy/top1 = 0.62
I0817 10:58:00.959808 14586 caffe.cpp:313] Batch 161, accuracy/top5 = 0.78
I0817 10:58:00.959812 14586 caffe.cpp:313] Batch 161, loss = 2.05324
I0817 10:58:01.022431 14586 caffe.cpp:313] Batch 162, accuracy/top1 = 0.54
I0817 10:58:01.022449 14586 caffe.cpp:313] Batch 162, accuracy/top5 = 0.84
I0817 10:58:01.022454 14586 caffe.cpp:313] Batch 162, loss = 1.76707
I0817 10:58:01.085216 14586 caffe.cpp:313] Batch 163, accuracy/top1 = 0.64
I0817 10:58:01.085238 14586 caffe.cpp:313] Batch 163, accuracy/top5 = 0.84
I0817 10:58:01.085242 14586 caffe.cpp:313] Batch 163, loss = 1.64564
I0817 10:58:01.147927 14586 caffe.cpp:313] Batch 164, accuracy/top1 = 0.66
I0817 10:58:01.147949 14586 caffe.cpp:313] Batch 164, accuracy/top5 = 0.8
I0817 10:58:01.147953 14586 caffe.cpp:313] Batch 164, loss = 1.56335
I0817 10:58:01.210594 14586 caffe.cpp:313] Batch 165, accuracy/top1 = 0.66
I0817 10:58:01.210616 14586 caffe.cpp:313] Batch 165, accuracy/top5 = 0.86
I0817 10:58:01.210620 14586 caffe.cpp:313] Batch 165, loss = 1.1788
I0817 10:58:01.273208 14586 caffe.cpp:313] Batch 166, accuracy/top1 = 0.42
I0817 10:58:01.273231 14586 caffe.cpp:313] Batch 166, accuracy/top5 = 0.82
I0817 10:58:01.273234 14586 caffe.cpp:313] Batch 166, loss = 2.04778
I0817 10:58:01.335878 14586 caffe.cpp:313] Batch 167, accuracy/top1 = 0.58
I0817 10:58:01.335901 14586 caffe.cpp:313] Batch 167, accuracy/top5 = 0.8
I0817 10:58:01.335906 14586 caffe.cpp:313] Batch 167, loss = 1.55265
I0817 10:58:01.398377 14586 caffe.cpp:313] Batch 168, accuracy/top1 = 0.68
I0817 10:58:01.398399 14586 caffe.cpp:313] Batch 168, accuracy/top5 = 0.9
I0817 10:58:01.398403 14586 caffe.cpp:313] Batch 168, loss = 1.36179
I0817 10:58:01.461006 14586 caffe.cpp:313] Batch 169, accuracy/top1 = 0.72
I0817 10:58:01.461028 14586 caffe.cpp:313] Batch 169, accuracy/top5 = 0.86
I0817 10:58:01.461032 14586 caffe.cpp:313] Batch 169, loss = 1.33113
I0817 10:58:01.523690 14586 caffe.cpp:313] Batch 170, accuracy/top1 = 0.58
I0817 10:58:01.523713 14586 caffe.cpp:313] Batch 170, accuracy/top5 = 0.76
I0817 10:58:01.523717 14586 caffe.cpp:313] Batch 170, loss = 1.84724
I0817 10:58:01.586421 14586 caffe.cpp:313] Batch 171, accuracy/top1 = 0.56
I0817 10:58:01.586444 14586 caffe.cpp:313] Batch 171, accuracy/top5 = 0.88
I0817 10:58:01.586448 14586 caffe.cpp:313] Batch 171, loss = 1.8214
I0817 10:58:01.649055 14586 caffe.cpp:313] Batch 172, accuracy/top1 = 0.68
I0817 10:58:01.649076 14586 caffe.cpp:313] Batch 172, accuracy/top5 = 0.88
I0817 10:58:01.649080 14586 caffe.cpp:313] Batch 172, loss = 1.59137
I0817 10:58:01.711681 14586 caffe.cpp:313] Batch 173, accuracy/top1 = 0.6
I0817 10:58:01.711702 14586 caffe.cpp:313] Batch 173, accuracy/top5 = 0.8
I0817 10:58:01.711706 14586 caffe.cpp:313] Batch 173, loss = 1.89474
I0817 10:58:01.774436 14586 caffe.cpp:313] Batch 174, accuracy/top1 = 0.68
I0817 10:58:01.774457 14586 caffe.cpp:313] Batch 174, accuracy/top5 = 0.78
I0817 10:58:01.774461 14586 caffe.cpp:313] Batch 174, loss = 1.81483
I0817 10:58:01.837893 14586 caffe.cpp:313] Batch 175, accuracy/top1 = 0.6
I0817 10:58:01.837914 14586 caffe.cpp:313] Batch 175, accuracy/top5 = 0.78
I0817 10:58:01.837918 14586 caffe.cpp:313] Batch 175, loss = 1.95247
I0817 10:58:01.901087 14586 caffe.cpp:313] Batch 176, accuracy/top1 = 0.5
I0817 10:58:01.901109 14586 caffe.cpp:313] Batch 176, accuracy/top5 = 0.76
I0817 10:58:01.901113 14586 caffe.cpp:313] Batch 176, loss = 2.14348
I0817 10:58:01.963793 14586 caffe.cpp:313] Batch 177, accuracy/top1 = 0.54
I0817 10:58:01.963815 14586 caffe.cpp:313] Batch 177, accuracy/top5 = 0.76
I0817 10:58:01.963819 14586 caffe.cpp:313] Batch 177, loss = 1.94652
I0817 10:58:02.026535 14586 caffe.cpp:313] Batch 178, accuracy/top1 = 0.52
I0817 10:58:02.026553 14586 caffe.cpp:313] Batch 178, accuracy/top5 = 0.84
I0817 10:58:02.026557 14586 caffe.cpp:313] Batch 178, loss = 1.80856
I0817 10:58:02.089201 14586 caffe.cpp:313] Batch 179, accuracy/top1 = 0.62
I0817 10:58:02.089224 14586 caffe.cpp:313] Batch 179, accuracy/top5 = 0.86
I0817 10:58:02.089228 14586 caffe.cpp:313] Batch 179, loss = 1.6656
I0817 10:58:02.151921 14586 caffe.cpp:313] Batch 180, accuracy/top1 = 0.62
I0817 10:58:02.151942 14586 caffe.cpp:313] Batch 180, accuracy/top5 = 0.8
I0817 10:58:02.151947 14586 caffe.cpp:313] Batch 180, loss = 1.89718
I0817 10:58:02.214615 14586 caffe.cpp:313] Batch 181, accuracy/top1 = 0.52
I0817 10:58:02.214638 14586 caffe.cpp:313] Batch 181, accuracy/top5 = 0.72
I0817 10:58:02.214643 14586 caffe.cpp:313] Batch 181, loss = 2.07226
I0817 10:58:02.277458 14586 caffe.cpp:313] Batch 182, accuracy/top1 = 0.52
I0817 10:58:02.277478 14586 caffe.cpp:313] Batch 182, accuracy/top5 = 0.8
I0817 10:58:02.277482 14586 caffe.cpp:313] Batch 182, loss = 2.22678
I0817 10:58:02.340342 14586 caffe.cpp:313] Batch 183, accuracy/top1 = 0.48
I0817 10:58:02.340363 14586 caffe.cpp:313] Batch 183, accuracy/top5 = 0.74
I0817 10:58:02.340368 14586 caffe.cpp:313] Batch 183, loss = 2.1848
I0817 10:58:02.403136 14586 caffe.cpp:313] Batch 184, accuracy/top1 = 0.64
I0817 10:58:02.403157 14586 caffe.cpp:313] Batch 184, accuracy/top5 = 0.88
I0817 10:58:02.403162 14586 caffe.cpp:313] Batch 184, loss = 1.69824
I0817 10:58:02.465687 14586 caffe.cpp:313] Batch 185, accuracy/top1 = 0.56
I0817 10:58:02.465708 14586 caffe.cpp:313] Batch 185, accuracy/top5 = 0.76
I0817 10:58:02.465713 14586 caffe.cpp:313] Batch 185, loss = 1.93168
I0817 10:58:02.528369 14586 caffe.cpp:313] Batch 186, accuracy/top1 = 0.54
I0817 10:58:02.528393 14586 caffe.cpp:313] Batch 186, accuracy/top5 = 0.82
I0817 10:58:02.528396 14586 caffe.cpp:313] Batch 186, loss = 1.57362
I0817 10:58:02.591014 14586 caffe.cpp:313] Batch 187, accuracy/top1 = 0.58
I0817 10:58:02.591037 14586 caffe.cpp:313] Batch 187, accuracy/top5 = 0.8
I0817 10:58:02.591040 14586 caffe.cpp:313] Batch 187, loss = 1.79742
I0817 10:58:02.653678 14586 caffe.cpp:313] Batch 188, accuracy/top1 = 0.62
I0817 10:58:02.653699 14586 caffe.cpp:313] Batch 188, accuracy/top5 = 0.76
I0817 10:58:02.653703 14586 caffe.cpp:313] Batch 188, loss = 1.59224
I0817 10:58:02.716238 14586 caffe.cpp:313] Batch 189, accuracy/top1 = 0.58
I0817 10:58:02.716256 14586 caffe.cpp:313] Batch 189, accuracy/top5 = 0.78
I0817 10:58:02.716260 14586 caffe.cpp:313] Batch 189, loss = 1.98888
I0817 10:58:02.778870 14586 caffe.cpp:313] Batch 190, accuracy/top1 = 0.6
I0817 10:58:02.778892 14586 caffe.cpp:313] Batch 190, accuracy/top5 = 0.86
I0817 10:58:02.778897 14586 caffe.cpp:313] Batch 190, loss = 1.49972
I0817 10:58:02.842000 14586 caffe.cpp:313] Batch 191, accuracy/top1 = 0.48
I0817 10:58:02.842017 14586 caffe.cpp:313] Batch 191, accuracy/top5 = 0.76
I0817 10:58:02.842021 14586 caffe.cpp:313] Batch 191, loss = 2.29793
I0817 10:58:02.904749 14586 caffe.cpp:313] Batch 192, accuracy/top1 = 0.54
I0817 10:58:02.904772 14586 caffe.cpp:313] Batch 192, accuracy/top5 = 0.8
I0817 10:58:02.904775 14586 caffe.cpp:313] Batch 192, loss = 1.90314
I0817 10:58:02.967314 14586 caffe.cpp:313] Batch 193, accuracy/top1 = 0.56
I0817 10:58:02.967336 14586 caffe.cpp:313] Batch 193, accuracy/top5 = 0.84
I0817 10:58:02.967340 14586 caffe.cpp:313] Batch 193, loss = 1.75635
I0817 10:58:03.029983 14586 caffe.cpp:313] Batch 194, accuracy/top1 = 0.6
I0817 10:58:03.030002 14586 caffe.cpp:313] Batch 194, accuracy/top5 = 0.92
I0817 10:58:03.030006 14586 caffe.cpp:313] Batch 194, loss = 1.59329
I0817 10:58:03.092579 14586 caffe.cpp:313] Batch 195, accuracy/top1 = 0.62
I0817 10:58:03.092602 14586 caffe.cpp:313] Batch 195, accuracy/top5 = 0.8
I0817 10:58:03.092605 14586 caffe.cpp:313] Batch 195, loss = 1.66721
I0817 10:58:03.155165 14586 caffe.cpp:313] Batch 196, accuracy/top1 = 0.7
I0817 10:58:03.155187 14586 caffe.cpp:313] Batch 196, accuracy/top5 = 0.84
I0817 10:58:03.155191 14586 caffe.cpp:313] Batch 196, loss = 1.23476
I0817 10:58:03.217680 14586 caffe.cpp:313] Batch 197, accuracy/top1 = 0.66
I0817 10:58:03.217701 14586 caffe.cpp:313] Batch 197, accuracy/top5 = 0.88
I0817 10:58:03.217705 14586 caffe.cpp:313] Batch 197, loss = 1.54326
I0817 10:58:03.280421 14586 caffe.cpp:313] Batch 198, accuracy/top1 = 0.62
I0817 10:58:03.280442 14586 caffe.cpp:313] Batch 198, accuracy/top5 = 0.84
I0817 10:58:03.280464 14586 caffe.cpp:313] Batch 198, loss = 1.78899
I0817 10:58:03.343202 14586 caffe.cpp:313] Batch 199, accuracy/top1 = 0.7
I0817 10:58:03.343225 14586 caffe.cpp:313] Batch 199, accuracy/top5 = 0.82
I0817 10:58:03.343230 14586 caffe.cpp:313] Batch 199, loss = 1.32199
I0817 10:58:03.405717 14586 caffe.cpp:313] Batch 200, accuracy/top1 = 0.64
I0817 10:58:03.405740 14586 caffe.cpp:313] Batch 200, accuracy/top5 = 0.82
I0817 10:58:03.405743 14586 caffe.cpp:313] Batch 200, loss = 1.71636
I0817 10:58:03.468343 14586 caffe.cpp:313] Batch 201, accuracy/top1 = 0.46
I0817 10:58:03.468365 14586 caffe.cpp:313] Batch 201, accuracy/top5 = 0.72
I0817 10:58:03.468369 14586 caffe.cpp:313] Batch 201, loss = 2.13017
I0817 10:58:03.532161 14586 caffe.cpp:313] Batch 202, accuracy/top1 = 0.48
I0817 10:58:03.532184 14586 caffe.cpp:313] Batch 202, accuracy/top5 = 0.86
I0817 10:58:03.532188 14586 caffe.cpp:313] Batch 202, loss = 1.95993
I0817 10:58:03.597218 14586 caffe.cpp:313] Batch 203, accuracy/top1 = 0.64
I0817 10:58:03.597241 14586 caffe.cpp:313] Batch 203, accuracy/top5 = 0.8
I0817 10:58:03.597245 14586 caffe.cpp:313] Batch 203, loss = 1.69303
I0817 10:58:03.662339 14586 caffe.cpp:313] Batch 204, accuracy/top1 = 0.7
I0817 10:58:03.662362 14586 caffe.cpp:313] Batch 204, accuracy/top5 = 0.86
I0817 10:58:03.662366 14586 caffe.cpp:313] Batch 204, loss = 1.38816
I0817 10:58:03.727290 14586 caffe.cpp:313] Batch 205, accuracy/top1 = 0.6
I0817 10:58:03.727313 14586 caffe.cpp:313] Batch 205, accuracy/top5 = 0.86
I0817 10:58:03.727318 14586 caffe.cpp:313] Batch 205, loss = 1.62723
I0817 10:58:03.792264 14586 caffe.cpp:313] Batch 206, accuracy/top1 = 0.52
I0817 10:58:03.792287 14586 caffe.cpp:313] Batch 206, accuracy/top5 = 0.84
I0817 10:58:03.792291 14586 caffe.cpp:313] Batch 206, loss = 1.67004
I0817 10:58:03.855684 14586 caffe.cpp:313] Batch 207, accuracy/top1 = 0.54
I0817 10:58:03.855701 14586 caffe.cpp:313] Batch 207, accuracy/top5 = 0.82
I0817 10:58:03.855705 14586 caffe.cpp:313] Batch 207, loss = 1.87749
I0817 10:58:03.918193 14586 caffe.cpp:313] Batch 208, accuracy/top1 = 0.56
I0817 10:58:03.918215 14586 caffe.cpp:313] Batch 208, accuracy/top5 = 0.7
I0817 10:58:03.918218 14586 caffe.cpp:313] Batch 208, loss = 2.28529
I0817 10:58:03.980708 14586 caffe.cpp:313] Batch 209, accuracy/top1 = 0.62
I0817 10:58:03.980731 14586 caffe.cpp:313] Batch 209, accuracy/top5 = 0.88
I0817 10:58:03.980736 14586 caffe.cpp:313] Batch 209, loss = 1.52869
I0817 10:58:04.043272 14586 caffe.cpp:313] Batch 210, accuracy/top1 = 0.42
I0817 10:58:04.043289 14586 caffe.cpp:313] Batch 210, accuracy/top5 = 0.68
I0817 10:58:04.043293 14586 caffe.cpp:313] Batch 210, loss = 2.98014
I0817 10:58:04.105875 14586 caffe.cpp:313] Batch 211, accuracy/top1 = 0.6
I0817 10:58:04.105897 14586 caffe.cpp:313] Batch 211, accuracy/top5 = 0.86
I0817 10:58:04.105901 14586 caffe.cpp:313] Batch 211, loss = 1.7596
I0817 10:58:04.168510 14586 caffe.cpp:313] Batch 212, accuracy/top1 = 0.6
I0817 10:58:04.168534 14586 caffe.cpp:313] Batch 212, accuracy/top5 = 0.8
I0817 10:58:04.168536 14586 caffe.cpp:313] Batch 212, loss = 1.67117
I0817 10:58:04.231225 14586 caffe.cpp:313] Batch 213, accuracy/top1 = 0.68
I0817 10:58:04.231247 14586 caffe.cpp:313] Batch 213, accuracy/top5 = 0.84
I0817 10:58:04.231251 14586 caffe.cpp:313] Batch 213, loss = 1.73366
I0817 10:58:04.293900 14586 caffe.cpp:313] Batch 214, accuracy/top1 = 0.52
I0817 10:58:04.293922 14586 caffe.cpp:313] Batch 214, accuracy/top5 = 0.86
I0817 10:58:04.293926 14586 caffe.cpp:313] Batch 214, loss = 1.90302
I0817 10:58:04.356633 14586 caffe.cpp:313] Batch 215, accuracy/top1 = 0.46
I0817 10:58:04.356652 14586 caffe.cpp:313] Batch 215, accuracy/top5 = 0.76
I0817 10:58:04.356657 14586 caffe.cpp:313] Batch 215, loss = 2.05142
I0817 10:58:04.419385 14586 caffe.cpp:313] Batch 216, accuracy/top1 = 0.68
I0817 10:58:04.419405 14586 caffe.cpp:313] Batch 216, accuracy/top5 = 0.9
I0817 10:58:04.419409 14586 caffe.cpp:313] Batch 216, loss = 1.34544
I0817 10:58:04.482869 14586 caffe.cpp:313] Batch 217, accuracy/top1 = 0.58
I0817 10:58:04.482903 14586 caffe.cpp:313] Batch 217, accuracy/top5 = 0.82
I0817 10:58:04.482908 14586 caffe.cpp:313] Batch 217, loss = 1.68961
I0817 10:58:04.545661 14586 caffe.cpp:313] Batch 218, accuracy/top1 = 0.62
I0817 10:58:04.545684 14586 caffe.cpp:313] Batch 218, accuracy/top5 = 0.82
I0817 10:58:04.545688 14586 caffe.cpp:313] Batch 218, loss = 1.7744
I0817 10:58:04.608343 14586 caffe.cpp:313] Batch 219, accuracy/top1 = 0.68
I0817 10:58:04.608366 14586 caffe.cpp:313] Batch 219, accuracy/top5 = 0.86
I0817 10:58:04.608369 14586 caffe.cpp:313] Batch 219, loss = 1.48242
I0817 10:58:04.670861 14586 caffe.cpp:313] Batch 220, accuracy/top1 = 0.5
I0817 10:58:04.670883 14586 caffe.cpp:313] Batch 220, accuracy/top5 = 0.74
I0817 10:58:04.670887 14586 caffe.cpp:313] Batch 220, loss = 2.21341
I0817 10:58:04.733466 14586 caffe.cpp:313] Batch 221, accuracy/top1 = 0.64
I0817 10:58:04.733484 14586 caffe.cpp:313] Batch 221, accuracy/top5 = 0.88
I0817 10:58:04.733489 14586 caffe.cpp:313] Batch 221, loss = 1.49062
I0817 10:58:04.796252 14586 caffe.cpp:313] Batch 222, accuracy/top1 = 0.64
I0817 10:58:04.796273 14586 caffe.cpp:313] Batch 222, accuracy/top5 = 0.78
I0817 10:58:04.796277 14586 caffe.cpp:313] Batch 222, loss = 2.05984
I0817 10:58:04.859333 14586 caffe.cpp:313] Batch 223, accuracy/top1 = 0.54
I0817 10:58:04.859349 14586 caffe.cpp:313] Batch 223, accuracy/top5 = 0.82
I0817 10:58:04.859354 14586 caffe.cpp:313] Batch 223, loss = 1.94483
I0817 10:58:04.921967 14586 caffe.cpp:313] Batch 224, accuracy/top1 = 0.46
I0817 10:58:04.921989 14586 caffe.cpp:313] Batch 224, accuracy/top5 = 0.76
I0817 10:58:04.921993 14586 caffe.cpp:313] Batch 224, loss = 2.27245
I0817 10:58:04.984697 14586 caffe.cpp:313] Batch 225, accuracy/top1 = 0.7
I0817 10:58:04.984720 14586 caffe.cpp:313] Batch 225, accuracy/top5 = 0.84
I0817 10:58:04.984724 14586 caffe.cpp:313] Batch 225, loss = 1.53834
I0817 10:58:05.047430 14586 caffe.cpp:313] Batch 226, accuracy/top1 = 0.62
I0817 10:58:05.047448 14586 caffe.cpp:313] Batch 226, accuracy/top5 = 0.86
I0817 10:58:05.047452 14586 caffe.cpp:313] Batch 226, loss = 1.6627
I0817 10:58:05.110153 14586 caffe.cpp:313] Batch 227, accuracy/top1 = 0.62
I0817 10:58:05.110177 14586 caffe.cpp:313] Batch 227, accuracy/top5 = 0.88
I0817 10:58:05.110180 14586 caffe.cpp:313] Batch 227, loss = 1.47746
I0817 10:58:05.172847 14586 caffe.cpp:313] Batch 228, accuracy/top1 = 0.62
I0817 10:58:05.172868 14586 caffe.cpp:313] Batch 228, accuracy/top5 = 0.82
I0817 10:58:05.172873 14586 caffe.cpp:313] Batch 228, loss = 1.50591
I0817 10:58:05.235534 14586 caffe.cpp:313] Batch 229, accuracy/top1 = 0.62
I0817 10:58:05.235556 14586 caffe.cpp:313] Batch 229, accuracy/top5 = 0.82
I0817 10:58:05.235560 14586 caffe.cpp:313] Batch 229, loss = 1.49238
I0817 10:58:05.298282 14586 caffe.cpp:313] Batch 230, accuracy/top1 = 0.72
I0817 10:58:05.298305 14586 caffe.cpp:313] Batch 230, accuracy/top5 = 0.92
I0817 10:58:05.298308 14586 caffe.cpp:313] Batch 230, loss = 1.20117
I0817 10:58:05.360996 14586 caffe.cpp:313] Batch 231, accuracy/top1 = 0.48
I0817 10:58:05.361019 14586 caffe.cpp:313] Batch 231, accuracy/top5 = 0.76
I0817 10:58:05.361022 14586 caffe.cpp:313] Batch 231, loss = 2.26207
I0817 10:58:05.423673 14586 caffe.cpp:313] Batch 232, accuracy/top1 = 0.54
I0817 10:58:05.423696 14586 caffe.cpp:313] Batch 232, accuracy/top5 = 0.76
I0817 10:58:05.423701 14586 caffe.cpp:313] Batch 232, loss = 2.12355
I0817 10:58:05.486347 14586 caffe.cpp:313] Batch 233, accuracy/top1 = 0.62
I0817 10:58:05.486371 14586 caffe.cpp:313] Batch 233, accuracy/top5 = 0.86
I0817 10:58:05.486376 14586 caffe.cpp:313] Batch 233, loss = 1.6159
I0817 10:58:05.549089 14586 caffe.cpp:313] Batch 234, accuracy/top1 = 0.54
I0817 10:58:05.549111 14586 caffe.cpp:313] Batch 234, accuracy/top5 = 0.8
I0817 10:58:05.549115 14586 caffe.cpp:313] Batch 234, loss = 1.90732
I0817 10:58:05.611856 14586 caffe.cpp:313] Batch 235, accuracy/top1 = 0.56
I0817 10:58:05.611881 14586 caffe.cpp:313] Batch 235, accuracy/top5 = 0.84
I0817 10:58:05.611884 14586 caffe.cpp:313] Batch 235, loss = 1.63012
I0817 10:58:05.674657 14586 caffe.cpp:313] Batch 236, accuracy/top1 = 0.56
I0817 10:58:05.674679 14586 caffe.cpp:313] Batch 236, accuracy/top5 = 0.78
I0817 10:58:05.674685 14586 caffe.cpp:313] Batch 236, loss = 2.06833
I0817 10:58:05.737502 14586 caffe.cpp:313] Batch 237, accuracy/top1 = 0.62
I0817 10:58:05.737525 14586 caffe.cpp:313] Batch 237, accuracy/top5 = 0.9
I0817 10:58:05.737529 14586 caffe.cpp:313] Batch 237, loss = 1.32638
I0817 10:58:05.800124 14586 caffe.cpp:313] Batch 238, accuracy/top1 = 0.6
I0817 10:58:05.800149 14586 caffe.cpp:313] Batch 238, accuracy/top5 = 0.88
I0817 10:58:05.800153 14586 caffe.cpp:313] Batch 238, loss = 1.76464
I0817 10:58:05.863075 14586 caffe.cpp:313] Batch 239, accuracy/top1 = 0.66
I0817 10:58:05.863095 14586 caffe.cpp:313] Batch 239, accuracy/top5 = 0.86
I0817 10:58:05.863098 14586 caffe.cpp:313] Batch 239, loss = 1.26473
I0817 10:58:05.925864 14586 caffe.cpp:313] Batch 240, accuracy/top1 = 0.52
I0817 10:58:05.925885 14586 caffe.cpp:313] Batch 240, accuracy/top5 = 0.82
I0817 10:58:05.925890 14586 caffe.cpp:313] Batch 240, loss = 1.60567
I0817 10:58:05.988605 14586 caffe.cpp:313] Batch 241, accuracy/top1 = 0.46
I0817 10:58:05.988627 14586 caffe.cpp:313] Batch 241, accuracy/top5 = 0.72
I0817 10:58:05.988631 14586 caffe.cpp:313] Batch 241, loss = 2.34283
I0817 10:58:06.051347 14586 caffe.cpp:313] Batch 242, accuracy/top1 = 0.62
I0817 10:58:06.051367 14586 caffe.cpp:313] Batch 242, accuracy/top5 = 0.86
I0817 10:58:06.051371 14586 caffe.cpp:313] Batch 242, loss = 1.59151
I0817 10:58:06.113965 14586 caffe.cpp:313] Batch 243, accuracy/top1 = 0.46
I0817 10:58:06.113986 14586 caffe.cpp:313] Batch 243, accuracy/top5 = 0.78
I0817 10:58:06.113991 14586 caffe.cpp:313] Batch 243, loss = 1.79035
I0817 10:58:06.176581 14586 caffe.cpp:313] Batch 244, accuracy/top1 = 0.5
I0817 10:58:06.176604 14586 caffe.cpp:313] Batch 244, accuracy/top5 = 0.78
I0817 10:58:06.176607 14586 caffe.cpp:313] Batch 244, loss = 2.10096
I0817 10:58:06.239315 14586 caffe.cpp:313] Batch 245, accuracy/top1 = 0.44
I0817 10:58:06.239337 14586 caffe.cpp:313] Batch 245, accuracy/top5 = 0.64
I0817 10:58:06.239341 14586 caffe.cpp:313] Batch 245, loss = 2.51529
I0817 10:58:06.302108 14586 caffe.cpp:313] Batch 246, accuracy/top1 = 0.54
I0817 10:58:06.302129 14586 caffe.cpp:313] Batch 246, accuracy/top5 = 0.8
I0817 10:58:06.302134 14586 caffe.cpp:313] Batch 246, loss = 2.06284
I0817 10:58:06.364820 14586 caffe.cpp:313] Batch 247, accuracy/top1 = 0.42
I0817 10:58:06.364842 14586 caffe.cpp:313] Batch 247, accuracy/top5 = 0.68
I0817 10:58:06.364846 14586 caffe.cpp:313] Batch 247, loss = 2.33254
I0817 10:58:06.427544 14586 caffe.cpp:313] Batch 248, accuracy/top1 = 0.54
I0817 10:58:06.427567 14586 caffe.cpp:313] Batch 248, accuracy/top5 = 0.66
I0817 10:58:06.427572 14586 caffe.cpp:313] Batch 248, loss = 2.35005
I0817 10:58:06.490276 14586 caffe.cpp:313] Batch 249, accuracy/top1 = 0.5
I0817 10:58:06.490294 14586 caffe.cpp:313] Batch 249, accuracy/top5 = 0.76
I0817 10:58:06.490298 14586 caffe.cpp:313] Batch 249, loss = 2.03351
I0817 10:58:06.553200 14586 caffe.cpp:313] Batch 250, accuracy/top1 = 0.66
I0817 10:58:06.553218 14586 caffe.cpp:313] Batch 250, accuracy/top5 = 0.94
I0817 10:58:06.553222 14586 caffe.cpp:313] Batch 250, loss = 1.26529
I0817 10:58:06.616050 14586 caffe.cpp:313] Batch 251, accuracy/top1 = 0.6
I0817 10:58:06.616071 14586 caffe.cpp:313] Batch 251, accuracy/top5 = 0.8
I0817 10:58:06.616075 14586 caffe.cpp:313] Batch 251, loss = 1.60513
I0817 10:58:06.678741 14586 caffe.cpp:313] Batch 252, accuracy/top1 = 0.54
I0817 10:58:06.678766 14586 caffe.cpp:313] Batch 252, accuracy/top5 = 0.7
I0817 10:58:06.678769 14586 caffe.cpp:313] Batch 252, loss = 2.48661
I0817 10:58:06.741683 14586 caffe.cpp:313] Batch 253, accuracy/top1 = 0.54
I0817 10:58:06.741701 14586 caffe.cpp:313] Batch 253, accuracy/top5 = 0.82
I0817 10:58:06.741705 14586 caffe.cpp:313] Batch 253, loss = 1.79506
I0817 10:58:06.804250 14586 caffe.cpp:313] Batch 254, accuracy/top1 = 0.58
I0817 10:58:06.804271 14586 caffe.cpp:313] Batch 254, accuracy/top5 = 0.76
I0817 10:58:06.804275 14586 caffe.cpp:313] Batch 254, loss = 1.97716
I0817 10:58:06.867089 14586 caffe.cpp:313] Batch 255, accuracy/top1 = 0.54
I0817 10:58:06.867110 14586 caffe.cpp:313] Batch 255, accuracy/top5 = 0.78
I0817 10:58:06.867115 14586 caffe.cpp:313] Batch 255, loss = 2.36197
I0817 10:58:06.929690 14586 caffe.cpp:313] Batch 256, accuracy/top1 = 0.6
I0817 10:58:06.929713 14586 caffe.cpp:313] Batch 256, accuracy/top5 = 0.84
I0817 10:58:06.929718 14586 caffe.cpp:313] Batch 256, loss = 1.54749
I0817 10:58:06.992321 14586 caffe.cpp:313] Batch 257, accuracy/top1 = 0.56
I0817 10:58:06.992343 14586 caffe.cpp:313] Batch 257, accuracy/top5 = 0.8
I0817 10:58:06.992347 14586 caffe.cpp:313] Batch 257, loss = 1.98515
I0817 10:58:07.055172 14586 caffe.cpp:313] Batch 258, accuracy/top1 = 0.58
I0817 10:58:07.055191 14586 caffe.cpp:313] Batch 258, accuracy/top5 = 0.78
I0817 10:58:07.055194 14586 caffe.cpp:313] Batch 258, loss = 2.26442
I0817 10:58:07.117868 14586 caffe.cpp:313] Batch 259, accuracy/top1 = 0.5
I0817 10:58:07.117892 14586 caffe.cpp:313] Batch 259, accuracy/top5 = 0.86
I0817 10:58:07.117895 14586 caffe.cpp:313] Batch 259, loss = 1.97115
I0817 10:58:07.180627 14586 caffe.cpp:313] Batch 260, accuracy/top1 = 0.56
I0817 10:58:07.180649 14586 caffe.cpp:313] Batch 260, accuracy/top5 = 0.78
I0817 10:58:07.180654 14586 caffe.cpp:313] Batch 260, loss = 1.71798
I0817 10:58:07.243331 14586 caffe.cpp:313] Batch 261, accuracy/top1 = 0.56
I0817 10:58:07.243352 14586 caffe.cpp:313] Batch 261, accuracy/top5 = 0.76
I0817 10:58:07.243356 14586 caffe.cpp:313] Batch 261, loss = 1.82607
I0817 10:58:07.305910 14586 caffe.cpp:313] Batch 262, accuracy/top1 = 0.52
I0817 10:58:07.305932 14586 caffe.cpp:313] Batch 262, accuracy/top5 = 0.76
I0817 10:58:07.305936 14586 caffe.cpp:313] Batch 262, loss = 1.96789
I0817 10:58:07.368585 14586 caffe.cpp:313] Batch 263, accuracy/top1 = 0.62
I0817 10:58:07.368607 14586 caffe.cpp:313] Batch 263, accuracy/top5 = 0.82
I0817 10:58:07.368612 14586 caffe.cpp:313] Batch 263, loss = 1.80793
I0817 10:58:07.431290 14586 caffe.cpp:313] Batch 264, accuracy/top1 = 0.56
I0817 10:58:07.431313 14586 caffe.cpp:313] Batch 264, accuracy/top5 = 0.82
I0817 10:58:07.431318 14586 caffe.cpp:313] Batch 264, loss = 1.86878
I0817 10:58:07.494016 14586 caffe.cpp:313] Batch 265, accuracy/top1 = 0.66
I0817 10:58:07.494040 14586 caffe.cpp:313] Batch 265, accuracy/top5 = 0.84
I0817 10:58:07.494043 14586 caffe.cpp:313] Batch 265, loss = 1.42142
I0817 10:58:07.556614 14586 caffe.cpp:313] Batch 266, accuracy/top1 = 0.64
I0817 10:58:07.556637 14586 caffe.cpp:313] Batch 266, accuracy/top5 = 0.78
I0817 10:58:07.556640 14586 caffe.cpp:313] Batch 266, loss = 1.69376
I0817 10:58:07.619361 14586 caffe.cpp:313] Batch 267, accuracy/top1 = 0.56
I0817 10:58:07.619384 14586 caffe.cpp:313] Batch 267, accuracy/top5 = 0.88
I0817 10:58:07.619387 14586 caffe.cpp:313] Batch 267, loss = 1.64015
I0817 10:58:07.682073 14586 caffe.cpp:313] Batch 268, accuracy/top1 = 0.6
I0817 10:58:07.682096 14586 caffe.cpp:313] Batch 268, accuracy/top5 = 0.82
I0817 10:58:07.682101 14586 caffe.cpp:313] Batch 268, loss = 1.76973
I0817 10:58:07.745007 14586 caffe.cpp:313] Batch 269, accuracy/top1 = 0.66
I0817 10:58:07.745030 14586 caffe.cpp:313] Batch 269, accuracy/top5 = 0.84
I0817 10:58:07.745034 14586 caffe.cpp:313] Batch 269, loss = 1.69788
I0817 10:58:07.807749 14586 caffe.cpp:313] Batch 270, accuracy/top1 = 0.56
I0817 10:58:07.807771 14586 caffe.cpp:313] Batch 270, accuracy/top5 = 0.78
I0817 10:58:07.807775 14586 caffe.cpp:313] Batch 270, loss = 1.99432
I0817 10:58:07.870638 14586 caffe.cpp:313] Batch 271, accuracy/top1 = 0.58
I0817 10:58:07.870661 14586 caffe.cpp:313] Batch 271, accuracy/top5 = 0.78
I0817 10:58:07.870664 14586 caffe.cpp:313] Batch 271, loss = 2.2456
I0817 10:58:07.933384 14586 caffe.cpp:313] Batch 272, accuracy/top1 = 0.56
I0817 10:58:07.933406 14586 caffe.cpp:313] Batch 272, accuracy/top5 = 0.8
I0817 10:58:07.933409 14586 caffe.cpp:313] Batch 272, loss = 1.82373
I0817 10:58:07.996179 14586 caffe.cpp:313] Batch 273, accuracy/top1 = 0.58
I0817 10:58:07.996201 14586 caffe.cpp:313] Batch 273, accuracy/top5 = 0.88
I0817 10:58:07.996222 14586 caffe.cpp:313] Batch 273, loss = 1.44508
I0817 10:58:08.058887 14586 caffe.cpp:313] Batch 274, accuracy/top1 = 0.56
I0817 10:58:08.058907 14586 caffe.cpp:313] Batch 274, accuracy/top5 = 0.86
I0817 10:58:08.058912 14586 caffe.cpp:313] Batch 274, loss = 1.85531
I0817 10:58:08.121588 14586 caffe.cpp:313] Batch 275, accuracy/top1 = 0.62
I0817 10:58:08.121611 14586 caffe.cpp:313] Batch 275, accuracy/top5 = 0.82
I0817 10:58:08.121615 14586 caffe.cpp:313] Batch 275, loss = 1.67349
I0817 10:58:08.184303 14586 caffe.cpp:313] Batch 276, accuracy/top1 = 0.66
I0817 10:58:08.184325 14586 caffe.cpp:313] Batch 276, accuracy/top5 = 0.82
I0817 10:58:08.184329 14586 caffe.cpp:313] Batch 276, loss = 1.61744
I0817 10:58:08.247027 14586 caffe.cpp:313] Batch 277, accuracy/top1 = 0.56
I0817 10:58:08.247051 14586 caffe.cpp:313] Batch 277, accuracy/top5 = 0.76
I0817 10:58:08.247054 14586 caffe.cpp:313] Batch 277, loss = 1.86262
I0817 10:58:08.309700 14586 caffe.cpp:313] Batch 278, accuracy/top1 = 0.46
I0817 10:58:08.309723 14586 caffe.cpp:313] Batch 278, accuracy/top5 = 0.76
I0817 10:58:08.309727 14586 caffe.cpp:313] Batch 278, loss = 2.39255
I0817 10:58:08.372252 14586 caffe.cpp:313] Batch 279, accuracy/top1 = 0.56
I0817 10:58:08.372274 14586 caffe.cpp:313] Batch 279, accuracy/top5 = 0.76
I0817 10:58:08.372278 14586 caffe.cpp:313] Batch 279, loss = 2.37236
I0817 10:58:08.434864 14586 caffe.cpp:313] Batch 280, accuracy/top1 = 0.56
I0817 10:58:08.434885 14586 caffe.cpp:313] Batch 280, accuracy/top5 = 0.88
I0817 10:58:08.434890 14586 caffe.cpp:313] Batch 280, loss = 1.75514
I0817 10:58:08.497557 14586 caffe.cpp:313] Batch 281, accuracy/top1 = 0.64
I0817 10:58:08.497581 14586 caffe.cpp:313] Batch 281, accuracy/top5 = 0.84
I0817 10:58:08.497584 14586 caffe.cpp:313] Batch 281, loss = 1.89763
I0817 10:58:08.560328 14586 caffe.cpp:313] Batch 282, accuracy/top1 = 0.58
I0817 10:58:08.560349 14586 caffe.cpp:313] Batch 282, accuracy/top5 = 0.8
I0817 10:58:08.560353 14586 caffe.cpp:313] Batch 282, loss = 1.66016
I0817 10:58:08.623054 14586 caffe.cpp:313] Batch 283, accuracy/top1 = 0.52
I0817 10:58:08.623075 14586 caffe.cpp:313] Batch 283, accuracy/top5 = 0.78
I0817 10:58:08.623078 14586 caffe.cpp:313] Batch 283, loss = 2.06996
I0817 10:58:08.686431 14586 caffe.cpp:313] Batch 284, accuracy/top1 = 0.56
I0817 10:58:08.686450 14586 caffe.cpp:313] Batch 284, accuracy/top5 = 0.78
I0817 10:58:08.686455 14586 caffe.cpp:313] Batch 284, loss = 1.97785
I0817 10:58:08.749987 14586 caffe.cpp:313] Batch 285, accuracy/top1 = 0.64
I0817 10:58:08.750008 14586 caffe.cpp:313] Batch 285, accuracy/top5 = 0.84
I0817 10:58:08.750012 14586 caffe.cpp:313] Batch 285, loss = 1.44595
I0817 10:58:08.813221 14586 caffe.cpp:313] Batch 286, accuracy/top1 = 0.64
I0817 10:58:08.813241 14586 caffe.cpp:313] Batch 286, accuracy/top5 = 0.84
I0817 10:58:08.813246 14586 caffe.cpp:313] Batch 286, loss = 1.40205
I0817 10:58:08.876662 14586 caffe.cpp:313] Batch 287, accuracy/top1 = 0.54
I0817 10:58:08.876684 14586 caffe.cpp:313] Batch 287, accuracy/top5 = 0.76
I0817 10:58:08.876688 14586 caffe.cpp:313] Batch 287, loss = 2.12217
I0817 10:58:08.939350 14586 caffe.cpp:313] Batch 288, accuracy/top1 = 0.58
I0817 10:58:08.939373 14586 caffe.cpp:313] Batch 288, accuracy/top5 = 0.84
I0817 10:58:08.939378 14586 caffe.cpp:313] Batch 288, loss = 2.04259
I0817 10:58:09.002043 14586 caffe.cpp:313] Batch 289, accuracy/top1 = 0.58
I0817 10:58:09.002065 14586 caffe.cpp:313] Batch 289, accuracy/top5 = 0.88
I0817 10:58:09.002069 14586 caffe.cpp:313] Batch 289, loss = 1.35913
I0817 10:58:09.064745 14586 caffe.cpp:313] Batch 290, accuracy/top1 = 0.62
I0817 10:58:09.064765 14586 caffe.cpp:313] Batch 290, accuracy/top5 = 0.78
I0817 10:58:09.064769 14586 caffe.cpp:313] Batch 290, loss = 2.06299
I0817 10:58:09.127435 14586 caffe.cpp:313] Batch 291, accuracy/top1 = 0.56
I0817 10:58:09.127459 14586 caffe.cpp:313] Batch 291, accuracy/top5 = 0.78
I0817 10:58:09.127462 14586 caffe.cpp:313] Batch 291, loss = 2.07777
I0817 10:58:09.190038 14586 caffe.cpp:313] Batch 292, accuracy/top1 = 0.58
I0817 10:58:09.190075 14586 caffe.cpp:313] Batch 292, accuracy/top5 = 0.82
I0817 10:58:09.190080 14586 caffe.cpp:313] Batch 292, loss = 1.67249
I0817 10:58:09.252661 14586 caffe.cpp:313] Batch 293, accuracy/top1 = 0.74
I0817 10:58:09.252683 14586 caffe.cpp:313] Batch 293, accuracy/top5 = 0.82
I0817 10:58:09.252687 14586 caffe.cpp:313] Batch 293, loss = 1.4071
I0817 10:58:09.315310 14586 caffe.cpp:313] Batch 294, accuracy/top1 = 0.68
I0817 10:58:09.315332 14586 caffe.cpp:313] Batch 294, accuracy/top5 = 0.92
I0817 10:58:09.315337 14586 caffe.cpp:313] Batch 294, loss = 1.01465
I0817 10:58:09.378080 14586 caffe.cpp:313] Batch 295, accuracy/top1 = 0.5
I0817 10:58:09.378103 14586 caffe.cpp:313] Batch 295, accuracy/top5 = 0.74
I0817 10:58:09.378108 14586 caffe.cpp:313] Batch 295, loss = 2.04932
I0817 10:58:09.440768 14586 caffe.cpp:313] Batch 296, accuracy/top1 = 0.62
I0817 10:58:09.440790 14586 caffe.cpp:313] Batch 296, accuracy/top5 = 0.86
I0817 10:58:09.440794 14586 caffe.cpp:313] Batch 296, loss = 1.44275
I0817 10:58:09.503500 14586 caffe.cpp:313] Batch 297, accuracy/top1 = 0.66
I0817 10:58:09.503523 14586 caffe.cpp:313] Batch 297, accuracy/top5 = 0.82
I0817 10:58:09.503527 14586 caffe.cpp:313] Batch 297, loss = 1.43874
I0817 10:58:09.566134 14586 caffe.cpp:313] Batch 298, accuracy/top1 = 0.52
I0817 10:58:09.566157 14586 caffe.cpp:313] Batch 298, accuracy/top5 = 0.84
I0817 10:58:09.566161 14586 caffe.cpp:313] Batch 298, loss = 1.95869
I0817 10:58:09.628835 14586 caffe.cpp:313] Batch 299, accuracy/top1 = 0.58
I0817 10:58:09.628859 14586 caffe.cpp:313] Batch 299, accuracy/top5 = 0.72
I0817 10:58:09.628862 14586 caffe.cpp:313] Batch 299, loss = 2.07586
I0817 10:58:09.691658 14586 caffe.cpp:313] Batch 300, accuracy/top1 = 0.48
I0817 10:58:09.691680 14586 caffe.cpp:313] Batch 300, accuracy/top5 = 0.68
I0817 10:58:09.691684 14586 caffe.cpp:313] Batch 300, loss = 2.2139
I0817 10:58:09.754464 14586 caffe.cpp:313] Batch 301, accuracy/top1 = 0.52
I0817 10:58:09.754487 14586 caffe.cpp:313] Batch 301, accuracy/top5 = 0.76
I0817 10:58:09.754490 14586 caffe.cpp:313] Batch 301, loss = 2.29234
I0817 10:58:09.817008 14586 caffe.cpp:313] Batch 302, accuracy/top1 = 0.7
I0817 10:58:09.817025 14586 caffe.cpp:313] Batch 302, accuracy/top5 = 0.86
I0817 10:58:09.817029 14586 caffe.cpp:313] Batch 302, loss = 1.58396
I0817 10:58:09.880022 14586 caffe.cpp:313] Batch 303, accuracy/top1 = 0.54
I0817 10:58:09.880041 14586 caffe.cpp:313] Batch 303, accuracy/top5 = 0.86
I0817 10:58:09.880045 14586 caffe.cpp:313] Batch 303, loss = 1.61727
I0817 10:58:09.942729 14586 caffe.cpp:313] Batch 304, accuracy/top1 = 0.6
I0817 10:58:09.942751 14586 caffe.cpp:313] Batch 304, accuracy/top5 = 0.84
I0817 10:58:09.942755 14586 caffe.cpp:313] Batch 304, loss = 1.52109
I0817 10:58:10.005496 14586 caffe.cpp:313] Batch 305, accuracy/top1 = 0.7
I0817 10:58:10.005518 14586 caffe.cpp:313] Batch 305, accuracy/top5 = 0.88
I0817 10:58:10.005522 14586 caffe.cpp:313] Batch 305, loss = 1.22257
I0817 10:58:10.068300 14586 caffe.cpp:313] Batch 306, accuracy/top1 = 0.64
I0817 10:58:10.068321 14586 caffe.cpp:313] Batch 306, accuracy/top5 = 0.86
I0817 10:58:10.068325 14586 caffe.cpp:313] Batch 306, loss = 1.4936
I0817 10:58:10.131053 14586 caffe.cpp:313] Batch 307, accuracy/top1 = 0.62
I0817 10:58:10.131075 14586 caffe.cpp:313] Batch 307, accuracy/top5 = 0.82
I0817 10:58:10.131079 14586 caffe.cpp:313] Batch 307, loss = 1.81389
I0817 10:58:10.193823 14586 caffe.cpp:313] Batch 308, accuracy/top1 = 0.72
I0817 10:58:10.193845 14586 caffe.cpp:313] Batch 308, accuracy/top5 = 0.86
I0817 10:58:10.193850 14586 caffe.cpp:313] Batch 308, loss = 1.43404
I0817 10:58:10.256613 14586 caffe.cpp:313] Batch 309, accuracy/top1 = 0.52
I0817 10:58:10.256635 14586 caffe.cpp:313] Batch 309, accuracy/top5 = 0.78
I0817 10:58:10.256639 14586 caffe.cpp:313] Batch 309, loss = 2.0551
I0817 10:58:10.319392 14586 caffe.cpp:313] Batch 310, accuracy/top1 = 0.64
I0817 10:58:10.319412 14586 caffe.cpp:313] Batch 310, accuracy/top5 = 0.9
I0817 10:58:10.319416 14586 caffe.cpp:313] Batch 310, loss = 1.30838
I0817 10:58:10.382149 14586 caffe.cpp:313] Batch 311, accuracy/top1 = 0.52
I0817 10:58:10.382172 14586 caffe.cpp:313] Batch 311, accuracy/top5 = 0.76
I0817 10:58:10.382176 14586 caffe.cpp:313] Batch 311, loss = 2.40503
I0817 10:58:10.444835 14586 caffe.cpp:313] Batch 312, accuracy/top1 = 0.64
I0817 10:58:10.444857 14586 caffe.cpp:313] Batch 312, accuracy/top5 = 0.8
I0817 10:58:10.444861 14586 caffe.cpp:313] Batch 312, loss = 1.8671
I0817 10:58:10.507457 14586 caffe.cpp:313] Batch 313, accuracy/top1 = 0.68
I0817 10:58:10.507479 14586 caffe.cpp:313] Batch 313, accuracy/top5 = 0.88
I0817 10:58:10.507483 14586 caffe.cpp:313] Batch 313, loss = 1.62735
I0817 10:58:10.570188 14586 caffe.cpp:313] Batch 314, accuracy/top1 = 0.66
I0817 10:58:10.570211 14586 caffe.cpp:313] Batch 314, accuracy/top5 = 0.86
I0817 10:58:10.570215 14586 caffe.cpp:313] Batch 314, loss = 1.36887
I0817 10:58:10.632910 14586 caffe.cpp:313] Batch 315, accuracy/top1 = 0.6
I0817 10:58:10.632932 14586 caffe.cpp:313] Batch 315, accuracy/top5 = 0.78
I0817 10:58:10.632936 14586 caffe.cpp:313] Batch 315, loss = 1.84653
I0817 10:58:10.695653 14586 caffe.cpp:313] Batch 316, accuracy/top1 = 0.48
I0817 10:58:10.695675 14586 caffe.cpp:313] Batch 316, accuracy/top5 = 0.74
I0817 10:58:10.695679 14586 caffe.cpp:313] Batch 316, loss = 2.25582
I0817 10:58:10.758530 14586 caffe.cpp:313] Batch 317, accuracy/top1 = 0.58
I0817 10:58:10.758550 14586 caffe.cpp:313] Batch 317, accuracy/top5 = 0.8
I0817 10:58:10.758554 14586 caffe.cpp:313] Batch 317, loss = 1.80937
I0817 10:58:10.821616 14586 caffe.cpp:313] Batch 318, accuracy/top1 = 0.64
I0817 10:58:10.821640 14586 caffe.cpp:313] Batch 318, accuracy/top5 = 0.84
I0817 10:58:10.821643 14586 caffe.cpp:313] Batch 318, loss = 1.57829
I0817 10:58:10.884580 14586 caffe.cpp:313] Batch 319, accuracy/top1 = 0.56
I0817 10:58:10.884601 14586 caffe.cpp:313] Batch 319, accuracy/top5 = 0.82
I0817 10:58:10.884605 14586 caffe.cpp:313] Batch 319, loss = 1.78256
I0817 10:58:10.947325 14586 caffe.cpp:313] Batch 320, accuracy/top1 = 0.54
I0817 10:58:10.947347 14586 caffe.cpp:313] Batch 320, accuracy/top5 = 0.74
I0817 10:58:10.947351 14586 caffe.cpp:313] Batch 320, loss = 2.19136
I0817 10:58:11.009865 14586 caffe.cpp:313] Batch 321, accuracy/top1 = 0.62
I0817 10:58:11.009883 14586 caffe.cpp:313] Batch 321, accuracy/top5 = 0.8
I0817 10:58:11.009887 14586 caffe.cpp:313] Batch 321, loss = 1.92429
I0817 10:58:11.072578 14586 caffe.cpp:313] Batch 322, accuracy/top1 = 0.6
I0817 10:58:11.072600 14586 caffe.cpp:313] Batch 322, accuracy/top5 = 0.94
I0817 10:58:11.072604 14586 caffe.cpp:313] Batch 322, loss = 1.17425
I0817 10:58:11.135313 14586 caffe.cpp:313] Batch 323, accuracy/top1 = 0.6
I0817 10:58:11.135334 14586 caffe.cpp:313] Batch 323, accuracy/top5 = 0.8
I0817 10:58:11.135339 14586 caffe.cpp:313] Batch 323, loss = 1.97181
I0817 10:58:11.197995 14586 caffe.cpp:313] Batch 324, accuracy/top1 = 0.5
I0817 10:58:11.198017 14586 caffe.cpp:313] Batch 324, accuracy/top5 = 0.7
I0817 10:58:11.198021 14586 caffe.cpp:313] Batch 324, loss = 2.10905
I0817 10:58:11.260745 14586 caffe.cpp:313] Batch 325, accuracy/top1 = 0.56
I0817 10:58:11.260766 14586 caffe.cpp:313] Batch 325, accuracy/top5 = 0.74
I0817 10:58:11.260769 14586 caffe.cpp:313] Batch 325, loss = 2.00012
I0817 10:58:11.323245 14586 caffe.cpp:313] Batch 326, accuracy/top1 = 0.58
I0817 10:58:11.323267 14586 caffe.cpp:313] Batch 326, accuracy/top5 = 0.84
I0817 10:58:11.323271 14586 caffe.cpp:313] Batch 326, loss = 1.96719
I0817 10:58:11.385921 14586 caffe.cpp:313] Batch 327, accuracy/top1 = 0.58
I0817 10:58:11.385944 14586 caffe.cpp:313] Batch 327, accuracy/top5 = 0.7
I0817 10:58:11.385948 14586 caffe.cpp:313] Batch 327, loss = 2.11381
I0817 10:58:11.448624 14586 caffe.cpp:313] Batch 328, accuracy/top1 = 0.44
I0817 10:58:11.448647 14586 caffe.cpp:313] Batch 328, accuracy/top5 = 0.82
I0817 10:58:11.448650 14586 caffe.cpp:313] Batch 328, loss = 2.02692
I0817 10:58:11.511348 14586 caffe.cpp:313] Batch 329, accuracy/top1 = 0.58
I0817 10:58:11.511370 14586 caffe.cpp:313] Batch 329, accuracy/top5 = 0.82
I0817 10:58:11.511391 14586 caffe.cpp:313] Batch 329, loss = 1.74828
I0817 10:58:11.574162 14586 caffe.cpp:313] Batch 330, accuracy/top1 = 0.56
I0817 10:58:11.574183 14586 caffe.cpp:313] Batch 330, accuracy/top5 = 0.84
I0817 10:58:11.574187 14586 caffe.cpp:313] Batch 330, loss = 1.8365
I0817 10:58:11.636987 14586 caffe.cpp:313] Batch 331, accuracy/top1 = 0.48
I0817 10:58:11.637011 14586 caffe.cpp:313] Batch 331, accuracy/top5 = 0.78
I0817 10:58:11.637014 14586 caffe.cpp:313] Batch 331, loss = 2.08876
I0817 10:58:11.699697 14586 caffe.cpp:313] Batch 332, accuracy/top1 = 0.6
I0817 10:58:11.699720 14586 caffe.cpp:313] Batch 332, accuracy/top5 = 0.84
I0817 10:58:11.699724 14586 caffe.cpp:313] Batch 332, loss = 1.63103
I0817 10:58:11.762538 14586 caffe.cpp:313] Batch 333, accuracy/top1 = 0.5
I0817 10:58:11.762560 14586 caffe.cpp:313] Batch 333, accuracy/top5 = 0.82
I0817 10:58:11.762564 14586 caffe.cpp:313] Batch 333, loss = 1.7452
I0817 10:58:11.825505 14586 caffe.cpp:313] Batch 334, accuracy/top1 = 0.7
I0817 10:58:11.825541 14586 caffe.cpp:313] Batch 334, accuracy/top5 = 0.92
I0817 10:58:11.825547 14586 caffe.cpp:313] Batch 334, loss = 1.30991
I0817 10:58:11.888463 14586 caffe.cpp:313] Batch 335, accuracy/top1 = 0.5
I0817 10:58:11.888484 14586 caffe.cpp:313] Batch 335, accuracy/top5 = 0.78
I0817 10:58:11.888489 14586 caffe.cpp:313] Batch 335, loss = 2.15712
I0817 10:58:11.951125 14586 caffe.cpp:313] Batch 336, accuracy/top1 = 0.72
I0817 10:58:11.951148 14586 caffe.cpp:313] Batch 336, accuracy/top5 = 0.88
I0817 10:58:11.951151 14586 caffe.cpp:313] Batch 336, loss = 1.33304
I0817 10:58:12.013702 14586 caffe.cpp:313] Batch 337, accuracy/top1 = 0.72
I0817 10:58:12.013725 14586 caffe.cpp:313] Batch 337, accuracy/top5 = 0.88
I0817 10:58:12.013730 14586 caffe.cpp:313] Batch 337, loss = 1.386
I0817 10:58:12.076406 14586 caffe.cpp:313] Batch 338, accuracy/top1 = 0.62
I0817 10:58:12.076426 14586 caffe.cpp:313] Batch 338, accuracy/top5 = 0.78
I0817 10:58:12.076431 14586 caffe.cpp:313] Batch 338, loss = 1.71656
I0817 10:58:12.138983 14586 caffe.cpp:313] Batch 339, accuracy/top1 = 0.52
I0817 10:58:12.139005 14586 caffe.cpp:313] Batch 339, accuracy/top5 = 0.84
I0817 10:58:12.139009 14586 caffe.cpp:313] Batch 339, loss = 1.8881
I0817 10:58:12.201581 14586 caffe.cpp:313] Batch 340, accuracy/top1 = 0.48
I0817 10:58:12.201603 14586 caffe.cpp:313] Batch 340, accuracy/top5 = 0.82
I0817 10:58:12.201607 14586 caffe.cpp:313] Batch 340, loss = 2.27282
I0817 10:58:12.264327 14586 caffe.cpp:313] Batch 341, accuracy/top1 = 0.6
I0817 10:58:12.264348 14586 caffe.cpp:313] Batch 341, accuracy/top5 = 0.74
I0817 10:58:12.264353 14586 caffe.cpp:313] Batch 341, loss = 1.69482
I0817 10:58:12.327095 14586 caffe.cpp:313] Batch 342, accuracy/top1 = 0.6
I0817 10:58:12.327118 14586 caffe.cpp:313] Batch 342, accuracy/top5 = 0.84
I0817 10:58:12.327122 14586 caffe.cpp:313] Batch 342, loss = 1.62344
I0817 10:58:12.389679 14586 caffe.cpp:313] Batch 343, accuracy/top1 = 0.54
I0817 10:58:12.389701 14586 caffe.cpp:313] Batch 343, accuracy/top5 = 0.8
I0817 10:58:12.389705 14586 caffe.cpp:313] Batch 343, loss = 1.76622
I0817 10:58:12.452280 14586 caffe.cpp:313] Batch 344, accuracy/top1 = 0.6
I0817 10:58:12.452302 14586 caffe.cpp:313] Batch 344, accuracy/top5 = 0.84
I0817 10:58:12.452306 14586 caffe.cpp:313] Batch 344, loss = 1.47115
I0817 10:58:12.515055 14586 caffe.cpp:313] Batch 345, accuracy/top1 = 0.58
I0817 10:58:12.515079 14586 caffe.cpp:313] Batch 345, accuracy/top5 = 0.88
I0817 10:58:12.515082 14586 caffe.cpp:313] Batch 345, loss = 1.65578
I0817 10:58:12.577872 14586 caffe.cpp:313] Batch 346, accuracy/top1 = 0.48
I0817 10:58:12.577895 14586 caffe.cpp:313] Batch 346, accuracy/top5 = 0.72
I0817 10:58:12.577899 14586 caffe.cpp:313] Batch 346, loss = 2.23447
I0817 10:58:12.640589 14586 caffe.cpp:313] Batch 347, accuracy/top1 = 0.54
I0817 10:58:12.640612 14586 caffe.cpp:313] Batch 347, accuracy/top5 = 0.88
I0817 10:58:12.640616 14586 caffe.cpp:313] Batch 347, loss = 1.59444
I0817 10:58:12.703331 14586 caffe.cpp:313] Batch 348, accuracy/top1 = 0.66
I0817 10:58:12.703352 14586 caffe.cpp:313] Batch 348, accuracy/top5 = 0.84
I0817 10:58:12.703373 14586 caffe.cpp:313] Batch 348, loss = 1.41879
I0817 10:58:12.766034 14586 caffe.cpp:313] Batch 349, accuracy/top1 = 0.5
I0817 10:58:12.766057 14586 caffe.cpp:313] Batch 349, accuracy/top5 = 0.82
I0817 10:58:12.766060 14586 caffe.cpp:313] Batch 349, loss = 2.1617
I0817 10:58:12.829007 14586 caffe.cpp:313] Batch 350, accuracy/top1 = 0.68
I0817 10:58:12.829027 14586 caffe.cpp:313] Batch 350, accuracy/top5 = 0.8
I0817 10:58:12.829031 14586 caffe.cpp:313] Batch 350, loss = 1.49721
I0817 10:58:12.892062 14586 caffe.cpp:313] Batch 351, accuracy/top1 = 0.64
I0817 10:58:12.892082 14586 caffe.cpp:313] Batch 351, accuracy/top5 = 0.78
I0817 10:58:12.892087 14586 caffe.cpp:313] Batch 351, loss = 1.60202
I0817 10:58:12.954933 14586 caffe.cpp:313] Batch 352, accuracy/top1 = 0.6
I0817 10:58:12.954952 14586 caffe.cpp:313] Batch 352, accuracy/top5 = 0.74
I0817 10:58:12.954957 14586 caffe.cpp:313] Batch 352, loss = 2.37324
I0817 10:58:13.018626 14586 caffe.cpp:313] Batch 353, accuracy/top1 = 0.6
I0817 10:58:13.018648 14586 caffe.cpp:313] Batch 353, accuracy/top5 = 0.78
I0817 10:58:13.018652 14586 caffe.cpp:313] Batch 353, loss = 1.97939
I0817 10:58:13.081252 14586 caffe.cpp:313] Batch 354, accuracy/top1 = 0.54
I0817 10:58:13.081274 14586 caffe.cpp:313] Batch 354, accuracy/top5 = 0.76
I0817 10:58:13.081279 14586 caffe.cpp:313] Batch 354, loss = 2.40583
I0817 10:58:13.143972 14586 caffe.cpp:313] Batch 355, accuracy/top1 = 0.56
I0817 10:58:13.143996 14586 caffe.cpp:313] Batch 355, accuracy/top5 = 0.78
I0817 10:58:13.143999 14586 caffe.cpp:313] Batch 355, loss = 1.90712
I0817 10:58:13.206617 14586 caffe.cpp:313] Batch 356, accuracy/top1 = 0.56
I0817 10:58:13.206640 14586 caffe.cpp:313] Batch 356, accuracy/top5 = 0.78
I0817 10:58:13.206645 14586 caffe.cpp:313] Batch 356, loss = 1.80684
I0817 10:58:13.269284 14586 caffe.cpp:313] Batch 357, accuracy/top1 = 0.64
I0817 10:58:13.269306 14586 caffe.cpp:313] Batch 357, accuracy/top5 = 0.88
I0817 10:58:13.269311 14586 caffe.cpp:313] Batch 357, loss = 1.50174
I0817 10:58:13.331918 14586 caffe.cpp:313] Batch 358, accuracy/top1 = 0.5
I0817 10:58:13.331940 14586 caffe.cpp:313] Batch 358, accuracy/top5 = 0.76
I0817 10:58:13.331944 14586 caffe.cpp:313] Batch 358, loss = 2.27703
I0817 10:58:13.394660 14586 caffe.cpp:313] Batch 359, accuracy/top1 = 0.48
I0817 10:58:13.394682 14586 caffe.cpp:313] Batch 359, accuracy/top5 = 0.84
I0817 10:58:13.394686 14586 caffe.cpp:313] Batch 359, loss = 2.24128
I0817 10:58:13.457229 14586 caffe.cpp:313] Batch 360, accuracy/top1 = 0.66
I0817 10:58:13.457252 14586 caffe.cpp:313] Batch 360, accuracy/top5 = 0.86
I0817 10:58:13.457255 14586 caffe.cpp:313] Batch 360, loss = 1.90759
I0817 10:58:13.519726 14586 caffe.cpp:313] Batch 361, accuracy/top1 = 0.56
I0817 10:58:13.519749 14586 caffe.cpp:313] Batch 361, accuracy/top5 = 0.86
I0817 10:58:13.519753 14586 caffe.cpp:313] Batch 361, loss = 1.59288
I0817 10:58:13.582239 14586 caffe.cpp:313] Batch 362, accuracy/top1 = 0.58
I0817 10:58:13.582260 14586 caffe.cpp:313] Batch 362, accuracy/top5 = 0.74
I0817 10:58:13.582264 14586 caffe.cpp:313] Batch 362, loss = 2.04033
I0817 10:58:13.645076 14586 caffe.cpp:313] Batch 363, accuracy/top1 = 0.56
I0817 10:58:13.645098 14586 caffe.cpp:313] Batch 363, accuracy/top5 = 0.82
I0817 10:58:13.645102 14586 caffe.cpp:313] Batch 363, loss = 1.95665
I0817 10:58:13.707733 14586 caffe.cpp:313] Batch 364, accuracy/top1 = 0.6
I0817 10:58:13.707756 14586 caffe.cpp:313] Batch 364, accuracy/top5 = 0.82
I0817 10:58:13.707761 14586 caffe.cpp:313] Batch 364, loss = 1.55344
I0817 10:58:13.770548 14586 caffe.cpp:313] Batch 365, accuracy/top1 = 0.66
I0817 10:58:13.770571 14586 caffe.cpp:313] Batch 365, accuracy/top5 = 0.82
I0817 10:58:13.770575 14586 caffe.cpp:313] Batch 365, loss = 1.59383
I0817 10:58:13.833577 14586 caffe.cpp:313] Batch 366, accuracy/top1 = 0.48
I0817 10:58:13.833595 14586 caffe.cpp:313] Batch 366, accuracy/top5 = 0.78
I0817 10:58:13.833600 14586 caffe.cpp:313] Batch 366, loss = 1.99148
I0817 10:58:13.896281 14586 caffe.cpp:313] Batch 367, accuracy/top1 = 0.6
I0817 10:58:13.896315 14586 caffe.cpp:313] Batch 367, accuracy/top5 = 0.82
I0817 10:58:13.896319 14586 caffe.cpp:313] Batch 367, loss = 1.67384
I0817 10:58:13.959026 14586 caffe.cpp:313] Batch 368, accuracy/top1 = 0.52
I0817 10:58:13.959048 14586 caffe.cpp:313] Batch 368, accuracy/top5 = 0.84
I0817 10:58:13.959053 14586 caffe.cpp:313] Batch 368, loss = 1.79547
I0817 10:58:14.021697 14586 caffe.cpp:313] Batch 369, accuracy/top1 = 0.66
I0817 10:58:14.021716 14586 caffe.cpp:313] Batch 369, accuracy/top5 = 0.88
I0817 10:58:14.021720 14586 caffe.cpp:313] Batch 369, loss = 1.45645
I0817 10:58:14.084373 14586 caffe.cpp:313] Batch 370, accuracy/top1 = 0.7
I0817 10:58:14.084396 14586 caffe.cpp:313] Batch 370, accuracy/top5 = 0.8
I0817 10:58:14.084400 14586 caffe.cpp:313] Batch 370, loss = 1.59143
I0817 10:58:14.147035 14586 caffe.cpp:313] Batch 371, accuracy/top1 = 0.68
I0817 10:58:14.147058 14586 caffe.cpp:313] Batch 371, accuracy/top5 = 0.8
I0817 10:58:14.147061 14586 caffe.cpp:313] Batch 371, loss = 1.69905
I0817 10:58:14.209573 14586 caffe.cpp:313] Batch 372, accuracy/top1 = 0.72
I0817 10:58:14.209595 14586 caffe.cpp:313] Batch 372, accuracy/top5 = 0.9
I0817 10:58:14.209599 14586 caffe.cpp:313] Batch 372, loss = 1.38197
I0817 10:58:14.272274 14586 caffe.cpp:313] Batch 373, accuracy/top1 = 0.46
I0817 10:58:14.272297 14586 caffe.cpp:313] Batch 373, accuracy/top5 = 0.76
I0817 10:58:14.272301 14586 caffe.cpp:313] Batch 373, loss = 2.46941
I0817 10:58:14.334951 14586 caffe.cpp:313] Batch 374, accuracy/top1 = 0.62
I0817 10:58:14.334974 14586 caffe.cpp:313] Batch 374, accuracy/top5 = 0.76
I0817 10:58:14.334977 14586 caffe.cpp:313] Batch 374, loss = 1.72137
I0817 10:58:14.397652 14586 caffe.cpp:313] Batch 375, accuracy/top1 = 0.68
I0817 10:58:14.397673 14586 caffe.cpp:313] Batch 375, accuracy/top5 = 0.94
I0817 10:58:14.397678 14586 caffe.cpp:313] Batch 375, loss = 1.17112
I0817 10:58:14.460444 14586 caffe.cpp:313] Batch 376, accuracy/top1 = 0.56
I0817 10:58:14.460467 14586 caffe.cpp:313] Batch 376, accuracy/top5 = 0.86
I0817 10:58:14.460471 14586 caffe.cpp:313] Batch 376, loss = 1.55789
I0817 10:58:14.523129 14586 caffe.cpp:313] Batch 377, accuracy/top1 = 0.48
I0817 10:58:14.523152 14586 caffe.cpp:313] Batch 377, accuracy/top5 = 0.78
I0817 10:58:14.523156 14586 caffe.cpp:313] Batch 377, loss = 1.90143
I0817 10:58:14.585697 14586 caffe.cpp:313] Batch 378, accuracy/top1 = 0.66
I0817 10:58:14.585719 14586 caffe.cpp:313] Batch 378, accuracy/top5 = 0.86
I0817 10:58:14.585723 14586 caffe.cpp:313] Batch 378, loss = 1.51374
I0817 10:58:14.648233 14586 caffe.cpp:313] Batch 379, accuracy/top1 = 0.68
I0817 10:58:14.648255 14586 caffe.cpp:313] Batch 379, accuracy/top5 = 0.9
I0817 10:58:14.648259 14586 caffe.cpp:313] Batch 379, loss = 1.35905
I0817 10:58:14.710813 14586 caffe.cpp:313] Batch 380, accuracy/top1 = 0.6
I0817 10:58:14.710835 14586 caffe.cpp:313] Batch 380, accuracy/top5 = 0.84
I0817 10:58:14.710839 14586 caffe.cpp:313] Batch 380, loss = 1.61545
I0817 10:58:14.773533 14586 caffe.cpp:313] Batch 381, accuracy/top1 = 0.42
I0817 10:58:14.773556 14586 caffe.cpp:313] Batch 381, accuracy/top5 = 0.74
I0817 10:58:14.773561 14586 caffe.cpp:313] Batch 381, loss = 2.46216
I0817 10:58:14.836607 14586 caffe.cpp:313] Batch 382, accuracy/top1 = 0.58
I0817 10:58:14.836627 14586 caffe.cpp:313] Batch 382, accuracy/top5 = 0.7
I0817 10:58:14.836630 14586 caffe.cpp:313] Batch 382, loss = 2.13146
I0817 10:58:14.899473 14586 caffe.cpp:313] Batch 383, accuracy/top1 = 0.64
I0817 10:58:14.899492 14586 caffe.cpp:313] Batch 383, accuracy/top5 = 0.86
I0817 10:58:14.899497 14586 caffe.cpp:313] Batch 383, loss = 1.62703
I0817 10:58:14.962366 14586 caffe.cpp:313] Batch 384, accuracy/top1 = 0.64
I0817 10:58:14.962388 14586 caffe.cpp:313] Batch 384, accuracy/top5 = 0.84
I0817 10:58:14.962393 14586 caffe.cpp:313] Batch 384, loss = 1.66705
I0817 10:58:15.025156 14586 caffe.cpp:313] Batch 385, accuracy/top1 = 0.6
I0817 10:58:15.025174 14586 caffe.cpp:313] Batch 385, accuracy/top5 = 0.82
I0817 10:58:15.025178 14586 caffe.cpp:313] Batch 385, loss = 1.57569
I0817 10:58:15.087860 14586 caffe.cpp:313] Batch 386, accuracy/top1 = 0.62
I0817 10:58:15.087882 14586 caffe.cpp:313] Batch 386, accuracy/top5 = 0.86
I0817 10:58:15.087885 14586 caffe.cpp:313] Batch 386, loss = 1.69903
I0817 10:58:15.150576 14586 caffe.cpp:313] Batch 387, accuracy/top1 = 0.54
I0817 10:58:15.150599 14586 caffe.cpp:313] Batch 387, accuracy/top5 = 0.78
I0817 10:58:15.150602 14586 caffe.cpp:313] Batch 387, loss = 1.68459
I0817 10:58:15.213342 14586 caffe.cpp:313] Batch 388, accuracy/top1 = 0.54
I0817 10:58:15.213364 14586 caffe.cpp:313] Batch 388, accuracy/top5 = 0.84
I0817 10:58:15.213369 14586 caffe.cpp:313] Batch 388, loss = 1.58311
I0817 10:58:15.275969 14586 caffe.cpp:313] Batch 389, accuracy/top1 = 0.52
I0817 10:58:15.275992 14586 caffe.cpp:313] Batch 389, accuracy/top5 = 0.74
I0817 10:58:15.275995 14586 caffe.cpp:313] Batch 389, loss = 2.12611
I0817 10:58:15.338548 14586 caffe.cpp:313] Batch 390, accuracy/top1 = 0.62
I0817 10:58:15.338572 14586 caffe.cpp:313] Batch 390, accuracy/top5 = 0.92
I0817 10:58:15.338575 14586 caffe.cpp:313] Batch 390, loss = 1.51823
I0817 10:58:15.401067 14586 caffe.cpp:313] Batch 391, accuracy/top1 = 0.58
I0817 10:58:15.401089 14586 caffe.cpp:313] Batch 391, accuracy/top5 = 0.82
I0817 10:58:15.401093 14586 caffe.cpp:313] Batch 391, loss = 1.81176
I0817 10:58:15.463722 14586 caffe.cpp:313] Batch 392, accuracy/top1 = 0.5
I0817 10:58:15.463744 14586 caffe.cpp:313] Batch 392, accuracy/top5 = 0.9
I0817 10:58:15.463748 14586 caffe.cpp:313] Batch 392, loss = 1.59182
I0817 10:58:15.526273 14586 caffe.cpp:313] Batch 393, accuracy/top1 = 0.52
I0817 10:58:15.526295 14586 caffe.cpp:313] Batch 393, accuracy/top5 = 0.72
I0817 10:58:15.526299 14586 caffe.cpp:313] Batch 393, loss = 2.20562
I0817 10:58:15.588874 14586 caffe.cpp:313] Batch 394, accuracy/top1 = 0.64
I0817 10:58:15.588896 14586 caffe.cpp:313] Batch 394, accuracy/top5 = 0.9
I0817 10:58:15.588901 14586 caffe.cpp:313] Batch 394, loss = 1.38045
I0817 10:58:15.651337 14586 caffe.cpp:313] Batch 395, accuracy/top1 = 0.74
I0817 10:58:15.651360 14586 caffe.cpp:313] Batch 395, accuracy/top5 = 0.88
I0817 10:58:15.651365 14586 caffe.cpp:313] Batch 395, loss = 1.52942
I0817 10:58:15.713937 14586 caffe.cpp:313] Batch 396, accuracy/top1 = 0.56
I0817 10:58:15.713960 14586 caffe.cpp:313] Batch 396, accuracy/top5 = 0.82
I0817 10:58:15.713964 14586 caffe.cpp:313] Batch 396, loss = 1.91394
I0817 10:58:15.776602 14586 caffe.cpp:313] Batch 397, accuracy/top1 = 0.52
I0817 10:58:15.776624 14586 caffe.cpp:313] Batch 397, accuracy/top5 = 0.78
I0817 10:58:15.776628 14586 caffe.cpp:313] Batch 397, loss = 2.40765
I0817 10:58:15.839665 14586 caffe.cpp:313] Batch 398, accuracy/top1 = 0.66
I0817 10:58:15.839684 14586 caffe.cpp:313] Batch 398, accuracy/top5 = 0.82
I0817 10:58:15.839687 14586 caffe.cpp:313] Batch 398, loss = 1.80101
I0817 10:58:15.902326 14586 caffe.cpp:313] Batch 399, accuracy/top1 = 0.62
I0817 10:58:15.902348 14586 caffe.cpp:313] Batch 399, accuracy/top5 = 0.82
I0817 10:58:15.902353 14586 caffe.cpp:313] Batch 399, loss = 1.71398
I0817 10:58:15.964879 14586 caffe.cpp:313] Batch 400, accuracy/top1 = 0.52
I0817 10:58:15.964901 14586 caffe.cpp:313] Batch 400, accuracy/top5 = 0.74
I0817 10:58:15.964905 14586 caffe.cpp:313] Batch 400, loss = 2.10752
I0817 10:58:16.027473 14586 caffe.cpp:313] Batch 401, accuracy/top1 = 0.58
I0817 10:58:16.027493 14586 caffe.cpp:313] Batch 401, accuracy/top5 = 0.9
I0817 10:58:16.027498 14586 caffe.cpp:313] Batch 401, loss = 1.56755
I0817 10:58:16.090203 14586 caffe.cpp:313] Batch 402, accuracy/top1 = 0.62
I0817 10:58:16.090224 14586 caffe.cpp:313] Batch 402, accuracy/top5 = 0.74
I0817 10:58:16.090229 14586 caffe.cpp:313] Batch 402, loss = 1.9469
I0817 10:58:16.152832 14586 caffe.cpp:313] Batch 403, accuracy/top1 = 0.54
I0817 10:58:16.152853 14586 caffe.cpp:313] Batch 403, accuracy/top5 = 0.82
I0817 10:58:16.152858 14586 caffe.cpp:313] Batch 403, loss = 1.91725
I0817 10:58:16.215512 14586 caffe.cpp:313] Batch 404, accuracy/top1 = 0.72
I0817 10:58:16.215533 14586 caffe.cpp:313] Batch 404, accuracy/top5 = 0.88
I0817 10:58:16.215555 14586 caffe.cpp:313] Batch 404, loss = 1.38111
I0817 10:58:16.278195 14586 caffe.cpp:313] Batch 405, accuracy/top1 = 0.64
I0817 10:58:16.278218 14586 caffe.cpp:313] Batch 405, accuracy/top5 = 0.84
I0817 10:58:16.278221 14586 caffe.cpp:313] Batch 405, loss = 1.78734
I0817 10:58:16.340906 14586 caffe.cpp:313] Batch 406, accuracy/top1 = 0.64
I0817 10:58:16.340929 14586 caffe.cpp:313] Batch 406, accuracy/top5 = 0.88
I0817 10:58:16.340932 14586 caffe.cpp:313] Batch 406, loss = 1.58687
I0817 10:58:16.403610 14586 caffe.cpp:313] Batch 407, accuracy/top1 = 0.7
I0817 10:58:16.403633 14586 caffe.cpp:313] Batch 407, accuracy/top5 = 0.88
I0817 10:58:16.403636 14586 caffe.cpp:313] Batch 407, loss = 1.19757
I0817 10:58:16.466231 14586 caffe.cpp:313] Batch 408, accuracy/top1 = 0.5
I0817 10:58:16.466253 14586 caffe.cpp:313] Batch 408, accuracy/top5 = 0.76
I0817 10:58:16.466256 14586 caffe.cpp:313] Batch 408, loss = 2.20845
I0817 10:58:16.528952 14586 caffe.cpp:313] Batch 409, accuracy/top1 = 0.5
I0817 10:58:16.528975 14586 caffe.cpp:313] Batch 409, accuracy/top5 = 0.84
I0817 10:58:16.528978 14586 caffe.cpp:313] Batch 409, loss = 1.94125
I0817 10:58:16.591687 14586 caffe.cpp:313] Batch 410, accuracy/top1 = 0.64
I0817 10:58:16.591711 14586 caffe.cpp:313] Batch 410, accuracy/top5 = 0.78
I0817 10:58:16.591714 14586 caffe.cpp:313] Batch 410, loss = 1.88615
I0817 10:58:16.654420 14586 caffe.cpp:313] Batch 411, accuracy/top1 = 0.62
I0817 10:58:16.654443 14586 caffe.cpp:313] Batch 411, accuracy/top5 = 0.84
I0817 10:58:16.654448 14586 caffe.cpp:313] Batch 411, loss = 1.65261
I0817 10:58:16.716946 14586 caffe.cpp:313] Batch 412, accuracy/top1 = 0.64
I0817 10:58:16.716969 14586 caffe.cpp:313] Batch 412, accuracy/top5 = 0.86
I0817 10:58:16.716972 14586 caffe.cpp:313] Batch 412, loss = 1.40815
I0817 10:58:16.779587 14586 caffe.cpp:313] Batch 413, accuracy/top1 = 0.56
I0817 10:58:16.779609 14586 caffe.cpp:313] Batch 413, accuracy/top5 = 0.78
I0817 10:58:16.779613 14586 caffe.cpp:313] Batch 413, loss = 2.02461
I0817 10:58:16.842766 14586 caffe.cpp:313] Batch 414, accuracy/top1 = 0.56
I0817 10:58:16.842783 14586 caffe.cpp:313] Batch 414, accuracy/top5 = 0.78
I0817 10:58:16.842787 14586 caffe.cpp:313] Batch 414, loss = 1.93394
I0817 10:58:16.905385 14586 caffe.cpp:313] Batch 415, accuracy/top1 = 0.62
I0817 10:58:16.905402 14586 caffe.cpp:313] Batch 415, accuracy/top5 = 0.8
I0817 10:58:16.905406 14586 caffe.cpp:313] Batch 415, loss = 1.63926
I0817 10:58:16.968083 14586 caffe.cpp:313] Batch 416, accuracy/top1 = 0.5
I0817 10:58:16.968106 14586 caffe.cpp:313] Batch 416, accuracy/top5 = 0.82
I0817 10:58:16.968111 14586 caffe.cpp:313] Batch 416, loss = 2.20563
I0817 10:58:17.030831 14586 caffe.cpp:313] Batch 417, accuracy/top1 = 0.58
I0817 10:58:17.030849 14586 caffe.cpp:313] Batch 417, accuracy/top5 = 0.8
I0817 10:58:17.030854 14586 caffe.cpp:313] Batch 417, loss = 1.86891
I0817 10:58:17.093542 14586 caffe.cpp:313] Batch 418, accuracy/top1 = 0.48
I0817 10:58:17.093565 14586 caffe.cpp:313] Batch 418, accuracy/top5 = 0.86
I0817 10:58:17.093569 14586 caffe.cpp:313] Batch 418, loss = 1.63302
I0817 10:58:17.156282 14586 caffe.cpp:313] Batch 419, accuracy/top1 = 0.54
I0817 10:58:17.156302 14586 caffe.cpp:313] Batch 419, accuracy/top5 = 0.78
I0817 10:58:17.156306 14586 caffe.cpp:313] Batch 419, loss = 1.98433
I0817 10:58:17.219076 14586 caffe.cpp:313] Batch 420, accuracy/top1 = 0.56
I0817 10:58:17.219096 14586 caffe.cpp:313] Batch 420, accuracy/top5 = 0.84
I0817 10:58:17.219100 14586 caffe.cpp:313] Batch 420, loss = 1.79187
I0817 10:58:17.281790 14586 caffe.cpp:313] Batch 421, accuracy/top1 = 0.66
I0817 10:58:17.281811 14586 caffe.cpp:313] Batch 421, accuracy/top5 = 0.82
I0817 10:58:17.281816 14586 caffe.cpp:313] Batch 421, loss = 1.72961
I0817 10:58:17.344396 14586 caffe.cpp:313] Batch 422, accuracy/top1 = 0.58
I0817 10:58:17.344419 14586 caffe.cpp:313] Batch 422, accuracy/top5 = 0.78
I0817 10:58:17.344422 14586 caffe.cpp:313] Batch 422, loss = 1.87048
I0817 10:58:17.406930 14586 caffe.cpp:313] Batch 423, accuracy/top1 = 0.6
I0817 10:58:17.406952 14586 caffe.cpp:313] Batch 423, accuracy/top5 = 0.74
I0817 10:58:17.406975 14586 caffe.cpp:313] Batch 423, loss = 2.22354
I0817 10:58:17.469669 14586 caffe.cpp:313] Batch 424, accuracy/top1 = 0.62
I0817 10:58:17.469691 14586 caffe.cpp:313] Batch 424, accuracy/top5 = 0.9
I0817 10:58:17.469696 14586 caffe.cpp:313] Batch 424, loss = 1.28437
I0817 10:58:17.532356 14586 caffe.cpp:313] Batch 425, accuracy/top1 = 0.66
I0817 10:58:17.532378 14586 caffe.cpp:313] Batch 425, accuracy/top5 = 0.86
I0817 10:58:17.532382 14586 caffe.cpp:313] Batch 425, loss = 1.86003
I0817 10:58:17.595079 14586 caffe.cpp:313] Batch 426, accuracy/top1 = 0.54
I0817 10:58:17.595101 14586 caffe.cpp:313] Batch 426, accuracy/top5 = 0.76
I0817 10:58:17.595105 14586 caffe.cpp:313] Batch 426, loss = 1.92858
I0817 10:58:17.657624 14586 caffe.cpp:313] Batch 427, accuracy/top1 = 0.6
I0817 10:58:17.657647 14586 caffe.cpp:313] Batch 427, accuracy/top5 = 0.82
I0817 10:58:17.657651 14586 caffe.cpp:313] Batch 427, loss = 1.69056
I0817 10:58:17.720294 14586 caffe.cpp:313] Batch 428, accuracy/top1 = 0.66
I0817 10:58:17.720317 14586 caffe.cpp:313] Batch 428, accuracy/top5 = 0.86
I0817 10:58:17.720320 14586 caffe.cpp:313] Batch 428, loss = 1.372
I0817 10:58:17.783032 14586 caffe.cpp:313] Batch 429, accuracy/top1 = 0.64
I0817 10:58:17.783056 14586 caffe.cpp:313] Batch 429, accuracy/top5 = 0.86
I0817 10:58:17.783059 14586 caffe.cpp:313] Batch 429, loss = 1.45442
I0817 10:58:17.846195 14586 caffe.cpp:313] Batch 430, accuracy/top1 = 0.54
I0817 10:58:17.846213 14586 caffe.cpp:313] Batch 430, accuracy/top5 = 0.86
I0817 10:58:17.846217 14586 caffe.cpp:313] Batch 430, loss = 1.49924
I0817 10:58:17.908921 14586 caffe.cpp:313] Batch 431, accuracy/top1 = 0.6
I0817 10:58:17.908941 14586 caffe.cpp:313] Batch 431, accuracy/top5 = 0.84
I0817 10:58:17.908946 14586 caffe.cpp:313] Batch 431, loss = 1.92214
I0817 10:58:17.971575 14586 caffe.cpp:313] Batch 432, accuracy/top1 = 0.54
I0817 10:58:17.971597 14586 caffe.cpp:313] Batch 432, accuracy/top5 = 0.74
I0817 10:58:17.971601 14586 caffe.cpp:313] Batch 432, loss = 2.32511
I0817 10:58:18.034270 14586 caffe.cpp:313] Batch 433, accuracy/top1 = 0.56
I0817 10:58:18.034289 14586 caffe.cpp:313] Batch 433, accuracy/top5 = 0.88
I0817 10:58:18.034293 14586 caffe.cpp:313] Batch 433, loss = 1.55602
I0817 10:58:18.097024 14586 caffe.cpp:313] Batch 434, accuracy/top1 = 0.44
I0817 10:58:18.097046 14586 caffe.cpp:313] Batch 434, accuracy/top5 = 0.8
I0817 10:58:18.097051 14586 caffe.cpp:313] Batch 434, loss = 2.22084
I0817 10:58:18.159704 14586 caffe.cpp:313] Batch 435, accuracy/top1 = 0.64
I0817 10:58:18.159726 14586 caffe.cpp:313] Batch 435, accuracy/top5 = 0.88
I0817 10:58:18.159730 14586 caffe.cpp:313] Batch 435, loss = 1.50534
I0817 10:58:18.222415 14586 caffe.cpp:313] Batch 436, accuracy/top1 = 0.58
I0817 10:58:18.222439 14586 caffe.cpp:313] Batch 436, accuracy/top5 = 0.8
I0817 10:58:18.222442 14586 caffe.cpp:313] Batch 436, loss = 1.9984
I0817 10:58:18.285095 14586 caffe.cpp:313] Batch 437, accuracy/top1 = 0.48
I0817 10:58:18.285117 14586 caffe.cpp:313] Batch 437, accuracy/top5 = 0.7
I0817 10:58:18.285121 14586 caffe.cpp:313] Batch 437, loss = 2.15024
I0817 10:58:18.347853 14586 caffe.cpp:313] Batch 438, accuracy/top1 = 0.58
I0817 10:58:18.347877 14586 caffe.cpp:313] Batch 438, accuracy/top5 = 0.8
I0817 10:58:18.347880 14586 caffe.cpp:313] Batch 438, loss = 1.78893
I0817 10:58:18.410636 14586 caffe.cpp:313] Batch 439, accuracy/top1 = 0.64
I0817 10:58:18.410658 14586 caffe.cpp:313] Batch 439, accuracy/top5 = 0.82
I0817 10:58:18.410662 14586 caffe.cpp:313] Batch 439, loss = 2.13394
I0817 10:58:18.473273 14586 caffe.cpp:313] Batch 440, accuracy/top1 = 0.52
I0817 10:58:18.473295 14586 caffe.cpp:313] Batch 440, accuracy/top5 = 0.74
I0817 10:58:18.473299 14586 caffe.cpp:313] Batch 440, loss = 1.74012
I0817 10:58:18.535835 14586 caffe.cpp:313] Batch 441, accuracy/top1 = 0.52
I0817 10:58:18.535856 14586 caffe.cpp:313] Batch 441, accuracy/top5 = 0.88
I0817 10:58:18.535861 14586 caffe.cpp:313] Batch 441, loss = 1.60023
I0817 10:58:18.598573 14586 caffe.cpp:313] Batch 442, accuracy/top1 = 0.6
I0817 10:58:18.598610 14586 caffe.cpp:313] Batch 442, accuracy/top5 = 0.9
I0817 10:58:18.598615 14586 caffe.cpp:313] Batch 442, loss = 1.64609
I0817 10:58:18.661372 14586 caffe.cpp:313] Batch 443, accuracy/top1 = 0.68
I0817 10:58:18.661394 14586 caffe.cpp:313] Batch 443, accuracy/top5 = 0.8
I0817 10:58:18.661398 14586 caffe.cpp:313] Batch 443, loss = 1.48518
I0817 10:58:18.724097 14586 caffe.cpp:313] Batch 444, accuracy/top1 = 0.68
I0817 10:58:18.724118 14586 caffe.cpp:313] Batch 444, accuracy/top5 = 0.84
I0817 10:58:18.724123 14586 caffe.cpp:313] Batch 444, loss = 1.27999
I0817 10:58:18.786743 14586 caffe.cpp:313] Batch 445, accuracy/top1 = 0.6
I0817 10:58:18.786765 14586 caffe.cpp:313] Batch 445, accuracy/top5 = 0.86
I0817 10:58:18.786769 14586 caffe.cpp:313] Batch 445, loss = 1.69574
I0817 10:58:18.849824 14586 caffe.cpp:313] Batch 446, accuracy/top1 = 0.6
I0817 10:58:18.849841 14586 caffe.cpp:313] Batch 446, accuracy/top5 = 0.86
I0817 10:58:18.849845 14586 caffe.cpp:313] Batch 446, loss = 1.45465
I0817 10:58:18.912554 14586 caffe.cpp:313] Batch 447, accuracy/top1 = 0.6
I0817 10:58:18.912576 14586 caffe.cpp:313] Batch 447, accuracy/top5 = 0.82
I0817 10:58:18.912580 14586 caffe.cpp:313] Batch 447, loss = 1.67553
I0817 10:58:18.975240 14586 caffe.cpp:313] Batch 448, accuracy/top1 = 0.56
I0817 10:58:18.975260 14586 caffe.cpp:313] Batch 448, accuracy/top5 = 0.8
I0817 10:58:18.975265 14586 caffe.cpp:313] Batch 448, loss = 1.51133
I0817 10:58:19.037999 14586 caffe.cpp:313] Batch 449, accuracy/top1 = 0.54
I0817 10:58:19.038017 14586 caffe.cpp:313] Batch 449, accuracy/top5 = 0.8
I0817 10:58:19.038022 14586 caffe.cpp:313] Batch 449, loss = 2.03282
I0817 10:58:19.100725 14586 caffe.cpp:313] Batch 450, accuracy/top1 = 0.58
I0817 10:58:19.100749 14586 caffe.cpp:313] Batch 450, accuracy/top5 = 0.8
I0817 10:58:19.100752 14586 caffe.cpp:313] Batch 450, loss = 1.74968
I0817 10:58:19.163367 14586 caffe.cpp:313] Batch 451, accuracy/top1 = 0.56
I0817 10:58:19.163389 14586 caffe.cpp:313] Batch 451, accuracy/top5 = 0.84
I0817 10:58:19.163393 14586 caffe.cpp:313] Batch 451, loss = 1.7026
I0817 10:58:19.226065 14586 caffe.cpp:313] Batch 452, accuracy/top1 = 0.62
I0817 10:58:19.226089 14586 caffe.cpp:313] Batch 452, accuracy/top5 = 0.84
I0817 10:58:19.226092 14586 caffe.cpp:313] Batch 452, loss = 1.44832
I0817 10:58:19.288889 14586 caffe.cpp:313] Batch 453, accuracy/top1 = 0.6
I0817 10:58:19.288909 14586 caffe.cpp:313] Batch 453, accuracy/top5 = 0.84
I0817 10:58:19.288913 14586 caffe.cpp:313] Batch 453, loss = 1.67717
I0817 10:58:19.351614 14586 caffe.cpp:313] Batch 454, accuracy/top1 = 0.54
I0817 10:58:19.351634 14586 caffe.cpp:313] Batch 454, accuracy/top5 = 0.82
I0817 10:58:19.351637 14586 caffe.cpp:313] Batch 454, loss = 2.14393
I0817 10:58:19.414415 14586 caffe.cpp:313] Batch 455, accuracy/top1 = 0.54
I0817 10:58:19.414436 14586 caffe.cpp:313] Batch 455, accuracy/top5 = 0.8
I0817 10:58:19.414440 14586 caffe.cpp:313] Batch 455, loss = 1.81812
I0817 10:58:19.477030 14586 caffe.cpp:313] Batch 456, accuracy/top1 = 0.58
I0817 10:58:19.477052 14586 caffe.cpp:313] Batch 456, accuracy/top5 = 0.86
I0817 10:58:19.477056 14586 caffe.cpp:313] Batch 456, loss = 1.968
I0817 10:58:19.539768 14586 caffe.cpp:313] Batch 457, accuracy/top1 = 0.48
I0817 10:58:19.539791 14586 caffe.cpp:313] Batch 457, accuracy/top5 = 0.7
I0817 10:58:19.539795 14586 caffe.cpp:313] Batch 457, loss = 2.03943
I0817 10:58:19.602282 14586 caffe.cpp:313] Batch 458, accuracy/top1 = 0.52
I0817 10:58:19.602304 14586 caffe.cpp:313] Batch 458, accuracy/top5 = 0.7
I0817 10:58:19.602308 14586 caffe.cpp:313] Batch 458, loss = 2.23806
I0817 10:58:19.665029 14586 caffe.cpp:313] Batch 459, accuracy/top1 = 0.64
I0817 10:58:19.665050 14586 caffe.cpp:313] Batch 459, accuracy/top5 = 0.86
I0817 10:58:19.665055 14586 caffe.cpp:313] Batch 459, loss = 1.29553
I0817 10:58:19.727862 14586 caffe.cpp:313] Batch 460, accuracy/top1 = 0.64
I0817 10:58:19.727885 14586 caffe.cpp:313] Batch 460, accuracy/top5 = 0.78
I0817 10:58:19.727890 14586 caffe.cpp:313] Batch 460, loss = 1.75856
I0817 10:58:19.790606 14586 caffe.cpp:313] Batch 461, accuracy/top1 = 0.66
I0817 10:58:19.790628 14586 caffe.cpp:313] Batch 461, accuracy/top5 = 0.9
I0817 10:58:19.790632 14586 caffe.cpp:313] Batch 461, loss = 1.41554
I0817 10:58:19.854233 14586 caffe.cpp:313] Batch 462, accuracy/top1 = 0.66
I0817 10:58:19.854250 14586 caffe.cpp:313] Batch 462, accuracy/top5 = 0.84
I0817 10:58:19.854254 14586 caffe.cpp:313] Batch 462, loss = 1.44045
I0817 10:58:19.916965 14586 caffe.cpp:313] Batch 463, accuracy/top1 = 0.56
I0817 10:58:19.916987 14586 caffe.cpp:313] Batch 463, accuracy/top5 = 0.7
I0817 10:58:19.916991 14586 caffe.cpp:313] Batch 463, loss = 1.9855
I0817 10:58:19.979729 14586 caffe.cpp:313] Batch 464, accuracy/top1 = 0.5
I0817 10:58:19.979751 14586 caffe.cpp:313] Batch 464, accuracy/top5 = 0.84
I0817 10:58:19.979755 14586 caffe.cpp:313] Batch 464, loss = 1.81637
I0817 10:58:20.042587 14586 caffe.cpp:313] Batch 465, accuracy/top1 = 0.58
I0817 10:58:20.042604 14586 caffe.cpp:313] Batch 465, accuracy/top5 = 0.84
I0817 10:58:20.042608 14586 caffe.cpp:313] Batch 465, loss = 1.60198
I0817 10:58:20.105366 14586 caffe.cpp:313] Batch 466, accuracy/top1 = 0.58
I0817 10:58:20.105389 14586 caffe.cpp:313] Batch 466, accuracy/top5 = 0.82
I0817 10:58:20.105393 14586 caffe.cpp:313] Batch 466, loss = 1.79263
I0817 10:58:20.168038 14586 caffe.cpp:313] Batch 467, accuracy/top1 = 0.7
I0817 10:58:20.168145 14586 caffe.cpp:313] Batch 467, accuracy/top5 = 0.9
I0817 10:58:20.168151 14586 caffe.cpp:313] Batch 467, loss = 1.46586
I0817 10:58:20.230851 14586 caffe.cpp:313] Batch 468, accuracy/top1 = 0.56
I0817 10:58:20.230875 14586 caffe.cpp:313] Batch 468, accuracy/top5 = 0.78
I0817 10:58:20.230878 14586 caffe.cpp:313] Batch 468, loss = 1.85395
I0817 10:58:20.293727 14586 caffe.cpp:313] Batch 469, accuracy/top1 = 0.54
I0817 10:58:20.293751 14586 caffe.cpp:313] Batch 469, accuracy/top5 = 0.84
I0817 10:58:20.293754 14586 caffe.cpp:313] Batch 469, loss = 1.63964
I0817 10:58:20.356356 14586 caffe.cpp:313] Batch 470, accuracy/top1 = 0.58
I0817 10:58:20.356379 14586 caffe.cpp:313] Batch 470, accuracy/top5 = 0.82
I0817 10:58:20.356382 14586 caffe.cpp:313] Batch 470, loss = 1.6709
I0817 10:58:20.418951 14586 caffe.cpp:313] Batch 471, accuracy/top1 = 0.66
I0817 10:58:20.418973 14586 caffe.cpp:313] Batch 471, accuracy/top5 = 0.88
I0817 10:58:20.418977 14586 caffe.cpp:313] Batch 471, loss = 1.38115
I0817 10:58:20.481564 14586 caffe.cpp:313] Batch 472, accuracy/top1 = 0.62
I0817 10:58:20.481585 14586 caffe.cpp:313] Batch 472, accuracy/top5 = 0.82
I0817 10:58:20.481588 14586 caffe.cpp:313] Batch 472, loss = 1.5708
I0817 10:58:20.544406 14586 caffe.cpp:313] Batch 473, accuracy/top1 = 0.66
I0817 10:58:20.544430 14586 caffe.cpp:313] Batch 473, accuracy/top5 = 0.84
I0817 10:58:20.544433 14586 caffe.cpp:313] Batch 473, loss = 1.71834
I0817 10:58:20.607041 14586 caffe.cpp:313] Batch 474, accuracy/top1 = 0.62
I0817 10:58:20.607064 14586 caffe.cpp:313] Batch 474, accuracy/top5 = 0.82
I0817 10:58:20.607069 14586 caffe.cpp:313] Batch 474, loss = 1.6987
I0817 10:58:20.669664 14586 caffe.cpp:313] Batch 475, accuracy/top1 = 0.58
I0817 10:58:20.669687 14586 caffe.cpp:313] Batch 475, accuracy/top5 = 0.82
I0817 10:58:20.669690 14586 caffe.cpp:313] Batch 475, loss = 1.84431
I0817 10:58:20.732285 14586 caffe.cpp:313] Batch 476, accuracy/top1 = 0.56
I0817 10:58:20.732307 14586 caffe.cpp:313] Batch 476, accuracy/top5 = 0.8
I0817 10:58:20.732311 14586 caffe.cpp:313] Batch 476, loss = 1.9123
I0817 10:58:20.795166 14586 caffe.cpp:313] Batch 477, accuracy/top1 = 0.46
I0817 10:58:20.795188 14586 caffe.cpp:313] Batch 477, accuracy/top5 = 0.8
I0817 10:58:20.795192 14586 caffe.cpp:313] Batch 477, loss = 1.81698
I0817 10:58:20.858440 14586 caffe.cpp:313] Batch 478, accuracy/top1 = 0.58
I0817 10:58:20.858458 14586 caffe.cpp:313] Batch 478, accuracy/top5 = 0.84
I0817 10:58:20.858461 14586 caffe.cpp:313] Batch 478, loss = 1.69877
I0817 10:58:20.921171 14586 caffe.cpp:313] Batch 479, accuracy/top1 = 0.56
I0817 10:58:20.921193 14586 caffe.cpp:313] Batch 479, accuracy/top5 = 0.76
I0817 10:58:20.921197 14586 caffe.cpp:313] Batch 479, loss = 2.08901
I0817 10:58:20.984048 14586 caffe.cpp:313] Batch 480, accuracy/top1 = 0.64
I0817 10:58:20.984066 14586 caffe.cpp:313] Batch 480, accuracy/top5 = 0.84
I0817 10:58:20.984071 14586 caffe.cpp:313] Batch 480, loss = 1.53824
I0817 10:58:21.046792 14586 caffe.cpp:313] Batch 481, accuracy/top1 = 0.58
I0817 10:58:21.046811 14586 caffe.cpp:313] Batch 481, accuracy/top5 = 0.8
I0817 10:58:21.046815 14586 caffe.cpp:313] Batch 481, loss = 1.92409
I0817 10:58:21.109576 14586 caffe.cpp:313] Batch 482, accuracy/top1 = 0.48
I0817 10:58:21.109598 14586 caffe.cpp:313] Batch 482, accuracy/top5 = 0.72
I0817 10:58:21.109603 14586 caffe.cpp:313] Batch 482, loss = 2.3611
I0817 10:58:21.172348 14586 caffe.cpp:313] Batch 483, accuracy/top1 = 0.58
I0817 10:58:21.172370 14586 caffe.cpp:313] Batch 483, accuracy/top5 = 0.86
I0817 10:58:21.172374 14586 caffe.cpp:313] Batch 483, loss = 1.51483
I0817 10:58:21.235055 14586 caffe.cpp:313] Batch 484, accuracy/top1 = 0.54
I0817 10:58:21.235079 14586 caffe.cpp:313] Batch 484, accuracy/top5 = 0.76
I0817 10:58:21.235082 14586 caffe.cpp:313] Batch 484, loss = 2.32078
I0817 10:58:21.297693 14586 caffe.cpp:313] Batch 485, accuracy/top1 = 0.72
I0817 10:58:21.297715 14586 caffe.cpp:313] Batch 485, accuracy/top5 = 0.76
I0817 10:58:21.297719 14586 caffe.cpp:313] Batch 485, loss = 1.68464
I0817 10:58:21.360342 14586 caffe.cpp:313] Batch 486, accuracy/top1 = 0.64
I0817 10:58:21.360378 14586 caffe.cpp:313] Batch 486, accuracy/top5 = 0.88
I0817 10:58:21.360383 14586 caffe.cpp:313] Batch 486, loss = 1.18143
I0817 10:58:21.423173 14586 caffe.cpp:313] Batch 487, accuracy/top1 = 0.56
I0817 10:58:21.423193 14586 caffe.cpp:313] Batch 487, accuracy/top5 = 0.72
I0817 10:58:21.423197 14586 caffe.cpp:313] Batch 487, loss = 2.31629
I0817 10:58:21.485894 14586 caffe.cpp:313] Batch 488, accuracy/top1 = 0.48
I0817 10:58:21.485913 14586 caffe.cpp:313] Batch 488, accuracy/top5 = 0.82
I0817 10:58:21.485916 14586 caffe.cpp:313] Batch 488, loss = 1.96422
I0817 10:58:21.549299 14586 caffe.cpp:313] Batch 489, accuracy/top1 = 0.56
I0817 10:58:21.549319 14586 caffe.cpp:313] Batch 489, accuracy/top5 = 0.82
I0817 10:58:21.549324 14586 caffe.cpp:313] Batch 489, loss = 1.74685
I0817 10:58:21.612484 14586 caffe.cpp:313] Batch 490, accuracy/top1 = 0.58
I0817 10:58:21.612506 14586 caffe.cpp:313] Batch 490, accuracy/top5 = 0.84
I0817 10:58:21.612510 14586 caffe.cpp:313] Batch 490, loss = 1.68557
I0817 10:58:21.675119 14586 caffe.cpp:313] Batch 491, accuracy/top1 = 0.6
I0817 10:58:21.675142 14586 caffe.cpp:313] Batch 491, accuracy/top5 = 0.84
I0817 10:58:21.675145 14586 caffe.cpp:313] Batch 491, loss = 1.7429
I0817 10:58:21.737762 14586 caffe.cpp:313] Batch 492, accuracy/top1 = 0.56
I0817 10:58:21.737784 14586 caffe.cpp:313] Batch 492, accuracy/top5 = 0.7
I0817 10:58:21.737788 14586 caffe.cpp:313] Batch 492, loss = 2.27191
I0817 10:58:21.800472 14586 caffe.cpp:313] Batch 493, accuracy/top1 = 0.56
I0817 10:58:21.800494 14586 caffe.cpp:313] Batch 493, accuracy/top5 = 0.82
I0817 10:58:21.800498 14586 caffe.cpp:313] Batch 493, loss = 1.85382
I0817 10:58:21.863617 14586 caffe.cpp:313] Batch 494, accuracy/top1 = 0.54
I0817 10:58:21.863634 14586 caffe.cpp:313] Batch 494, accuracy/top5 = 0.76
I0817 10:58:21.863638 14586 caffe.cpp:313] Batch 494, loss = 1.88968
I0817 10:58:21.926190 14586 caffe.cpp:313] Batch 495, accuracy/top1 = 0.66
I0817 10:58:21.926213 14586 caffe.cpp:313] Batch 495, accuracy/top5 = 0.88
I0817 10:58:21.926216 14586 caffe.cpp:313] Batch 495, loss = 1.42837
I0817 10:58:21.988831 14586 caffe.cpp:313] Batch 496, accuracy/top1 = 0.56
I0817 10:58:21.988854 14586 caffe.cpp:313] Batch 496, accuracy/top5 = 0.82
I0817 10:58:21.988858 14586 caffe.cpp:313] Batch 496, loss = 1.8436
I0817 10:58:22.051542 14586 caffe.cpp:313] Batch 497, accuracy/top1 = 0.56
I0817 10:58:22.051560 14586 caffe.cpp:313] Batch 497, accuracy/top5 = 0.74
I0817 10:58:22.051564 14586 caffe.cpp:313] Batch 497, loss = 1.95493
I0817 10:58:22.114318 14586 caffe.cpp:313] Batch 498, accuracy/top1 = 0.68
I0817 10:58:22.114341 14586 caffe.cpp:313] Batch 498, accuracy/top5 = 0.86
I0817 10:58:22.114346 14586 caffe.cpp:313] Batch 498, loss = 1.2727
I0817 10:58:22.177089 14586 caffe.cpp:313] Batch 499, accuracy/top1 = 0.56
I0817 10:58:22.177110 14586 caffe.cpp:313] Batch 499, accuracy/top5 = 0.78
I0817 10:58:22.177114 14586 caffe.cpp:313] Batch 499, loss = 1.77856
I0817 10:58:22.239699 14586 caffe.cpp:313] Batch 500, accuracy/top1 = 0.58
I0817 10:58:22.239722 14586 caffe.cpp:313] Batch 500, accuracy/top5 = 0.8
I0817 10:58:22.239727 14586 caffe.cpp:313] Batch 500, loss = 1.98417
I0817 10:58:22.302407 14586 caffe.cpp:313] Batch 501, accuracy/top1 = 0.54
I0817 10:58:22.302428 14586 caffe.cpp:313] Batch 501, accuracy/top5 = 0.76
I0817 10:58:22.302431 14586 caffe.cpp:313] Batch 501, loss = 1.95916
I0817 10:58:22.365170 14586 caffe.cpp:313] Batch 502, accuracy/top1 = 0.38
I0817 10:58:22.365192 14586 caffe.cpp:313] Batch 502, accuracy/top5 = 0.74
I0817 10:58:22.365196 14586 caffe.cpp:313] Batch 502, loss = 2.38848
I0817 10:58:22.427901 14586 caffe.cpp:313] Batch 503, accuracy/top1 = 0.6
I0817 10:58:22.427923 14586 caffe.cpp:313] Batch 503, accuracy/top5 = 0.78
I0817 10:58:22.427927 14586 caffe.cpp:313] Batch 503, loss = 1.91557
I0817 10:58:22.490602 14586 caffe.cpp:313] Batch 504, accuracy/top1 = 0.62
I0817 10:58:22.490623 14586 caffe.cpp:313] Batch 504, accuracy/top5 = 0.88
I0817 10:58:22.490628 14586 caffe.cpp:313] Batch 504, loss = 1.38235
I0817 10:58:22.553316 14586 caffe.cpp:313] Batch 505, accuracy/top1 = 0.58
I0817 10:58:22.553339 14586 caffe.cpp:313] Batch 505, accuracy/top5 = 0.88
I0817 10:58:22.553342 14586 caffe.cpp:313] Batch 505, loss = 1.8062
I0817 10:58:22.615986 14586 caffe.cpp:313] Batch 506, accuracy/top1 = 0.66
I0817 10:58:22.616008 14586 caffe.cpp:313] Batch 506, accuracy/top5 = 0.86
I0817 10:58:22.616013 14586 caffe.cpp:313] Batch 506, loss = 1.33164
I0817 10:58:22.678632 14586 caffe.cpp:313] Batch 507, accuracy/top1 = 0.48
I0817 10:58:22.678655 14586 caffe.cpp:313] Batch 507, accuracy/top5 = 0.78
I0817 10:58:22.678659 14586 caffe.cpp:313] Batch 507, loss = 2.28912
I0817 10:58:22.741204 14586 caffe.cpp:313] Batch 508, accuracy/top1 = 0.64
I0817 10:58:22.741225 14586 caffe.cpp:313] Batch 508, accuracy/top5 = 0.9
I0817 10:58:22.741230 14586 caffe.cpp:313] Batch 508, loss = 1.81346
I0817 10:58:22.803983 14586 caffe.cpp:313] Batch 509, accuracy/top1 = 0.54
I0817 10:58:22.804004 14586 caffe.cpp:313] Batch 509, accuracy/top5 = 0.82
I0817 10:58:22.804008 14586 caffe.cpp:313] Batch 509, loss = 1.7712
I0817 10:58:22.867058 14586 caffe.cpp:313] Batch 510, accuracy/top1 = 0.54
I0817 10:58:22.867075 14586 caffe.cpp:313] Batch 510, accuracy/top5 = 0.78
I0817 10:58:22.867079 14586 caffe.cpp:313] Batch 510, loss = 1.87499
I0817 10:58:22.929795 14586 caffe.cpp:313] Batch 511, accuracy/top1 = 0.62
I0817 10:58:22.929816 14586 caffe.cpp:313] Batch 511, accuracy/top5 = 0.86
I0817 10:58:22.929819 14586 caffe.cpp:313] Batch 511, loss = 1.72642
I0817 10:58:22.992604 14586 caffe.cpp:313] Batch 512, accuracy/top1 = 0.66
I0817 10:58:22.992620 14586 caffe.cpp:313] Batch 512, accuracy/top5 = 0.86
I0817 10:58:22.992624 14586 caffe.cpp:313] Batch 512, loss = 1.43488
I0817 10:58:23.055330 14586 caffe.cpp:313] Batch 513, accuracy/top1 = 0.54
I0817 10:58:23.055348 14586 caffe.cpp:313] Batch 513, accuracy/top5 = 0.78
I0817 10:58:23.055351 14586 caffe.cpp:313] Batch 513, loss = 2.01205
I0817 10:58:23.117918 14586 caffe.cpp:313] Batch 514, accuracy/top1 = 0.54
I0817 10:58:23.117940 14586 caffe.cpp:313] Batch 514, accuracy/top5 = 0.8
I0817 10:58:23.117944 14586 caffe.cpp:313] Batch 514, loss = 1.85805
I0817 10:58:23.180717 14586 caffe.cpp:313] Batch 515, accuracy/top1 = 0.54
I0817 10:58:23.180739 14586 caffe.cpp:313] Batch 515, accuracy/top5 = 0.76
I0817 10:58:23.180743 14586 caffe.cpp:313] Batch 515, loss = 1.96289
I0817 10:58:23.243371 14586 caffe.cpp:313] Batch 516, accuracy/top1 = 0.62
I0817 10:58:23.243392 14586 caffe.cpp:313] Batch 516, accuracy/top5 = 0.82
I0817 10:58:23.243396 14586 caffe.cpp:313] Batch 516, loss = 2.08052
I0817 10:58:23.306107 14586 caffe.cpp:313] Batch 517, accuracy/top1 = 0.64
I0817 10:58:23.306128 14586 caffe.cpp:313] Batch 517, accuracy/top5 = 0.84
I0817 10:58:23.306133 14586 caffe.cpp:313] Batch 517, loss = 1.43032
I0817 10:58:23.368860 14586 caffe.cpp:313] Batch 518, accuracy/top1 = 0.66
I0817 10:58:23.368880 14586 caffe.cpp:313] Batch 518, accuracy/top5 = 0.82
I0817 10:58:23.368885 14586 caffe.cpp:313] Batch 518, loss = 1.79119
I0817 10:58:23.431547 14586 caffe.cpp:313] Batch 519, accuracy/top1 = 0.62
I0817 10:58:23.431569 14586 caffe.cpp:313] Batch 519, accuracy/top5 = 0.82
I0817 10:58:23.431573 14586 caffe.cpp:313] Batch 519, loss = 1.7433
I0817 10:58:23.494299 14586 caffe.cpp:313] Batch 520, accuracy/top1 = 0.54
I0817 10:58:23.494323 14586 caffe.cpp:313] Batch 520, accuracy/top5 = 0.76
I0817 10:58:23.494325 14586 caffe.cpp:313] Batch 520, loss = 2.112
I0817 10:58:23.557088 14586 caffe.cpp:313] Batch 521, accuracy/top1 = 0.56
I0817 10:58:23.557108 14586 caffe.cpp:313] Batch 521, accuracy/top5 = 0.84
I0817 10:58:23.557112 14586 caffe.cpp:313] Batch 521, loss = 1.74338
I0817 10:58:23.620127 14586 caffe.cpp:313] Batch 522, accuracy/top1 = 0.56
I0817 10:58:23.620152 14586 caffe.cpp:313] Batch 522, accuracy/top5 = 0.92
I0817 10:58:23.620157 14586 caffe.cpp:313] Batch 522, loss = 1.53932
I0817 10:58:23.683351 14586 caffe.cpp:313] Batch 523, accuracy/top1 = 0.62
I0817 10:58:23.683372 14586 caffe.cpp:313] Batch 523, accuracy/top5 = 0.88
I0817 10:58:23.683392 14586 caffe.cpp:313] Batch 523, loss = 1.4266
I0817 10:58:23.746096 14586 caffe.cpp:313] Batch 524, accuracy/top1 = 0.56
I0817 10:58:23.746119 14586 caffe.cpp:313] Batch 524, accuracy/top5 = 0.8
I0817 10:58:23.746122 14586 caffe.cpp:313] Batch 524, loss = 1.6986
I0817 10:58:23.808715 14586 caffe.cpp:313] Batch 525, accuracy/top1 = 0.64
I0817 10:58:23.808737 14586 caffe.cpp:313] Batch 525, accuracy/top5 = 0.82
I0817 10:58:23.808742 14586 caffe.cpp:313] Batch 525, loss = 1.75775
I0817 10:58:23.872192 14586 caffe.cpp:313] Batch 526, accuracy/top1 = 0.44
I0817 10:58:23.872210 14586 caffe.cpp:313] Batch 526, accuracy/top5 = 0.74
I0817 10:58:23.872213 14586 caffe.cpp:313] Batch 526, loss = 2.574
I0817 10:58:23.934784 14586 caffe.cpp:313] Batch 527, accuracy/top1 = 0.56
I0817 10:58:23.934806 14586 caffe.cpp:313] Batch 527, accuracy/top5 = 0.82
I0817 10:58:23.934810 14586 caffe.cpp:313] Batch 527, loss = 1.71257
I0817 10:58:23.997488 14586 caffe.cpp:313] Batch 528, accuracy/top1 = 0.68
I0817 10:58:23.997509 14586 caffe.cpp:313] Batch 528, accuracy/top5 = 0.84
I0817 10:58:23.997514 14586 caffe.cpp:313] Batch 528, loss = 1.5722
I0817 10:58:24.060210 14586 caffe.cpp:313] Batch 529, accuracy/top1 = 0.52
I0817 10:58:24.060232 14586 caffe.cpp:313] Batch 529, accuracy/top5 = 0.82
I0817 10:58:24.060236 14586 caffe.cpp:313] Batch 529, loss = 1.81266
I0817 10:58:24.122915 14586 caffe.cpp:313] Batch 530, accuracy/top1 = 0.58
I0817 10:58:24.122937 14586 caffe.cpp:313] Batch 530, accuracy/top5 = 0.82
I0817 10:58:24.122941 14586 caffe.cpp:313] Batch 530, loss = 1.72799
I0817 10:58:24.185570 14586 caffe.cpp:313] Batch 531, accuracy/top1 = 0.52
I0817 10:58:24.185591 14586 caffe.cpp:313] Batch 531, accuracy/top5 = 0.82
I0817 10:58:24.185595 14586 caffe.cpp:313] Batch 531, loss = 1.86934
I0817 10:58:24.248253 14586 caffe.cpp:313] Batch 532, accuracy/top1 = 0.56
I0817 10:58:24.248275 14586 caffe.cpp:313] Batch 532, accuracy/top5 = 0.9
I0817 10:58:24.248280 14586 caffe.cpp:313] Batch 532, loss = 1.50367
I0817 10:58:24.310909 14586 caffe.cpp:313] Batch 533, accuracy/top1 = 0.52
I0817 10:58:24.310930 14586 caffe.cpp:313] Batch 533, accuracy/top5 = 0.7
I0817 10:58:24.310933 14586 caffe.cpp:313] Batch 533, loss = 2.27857
I0817 10:58:24.373678 14586 caffe.cpp:313] Batch 534, accuracy/top1 = 0.64
I0817 10:58:24.373699 14586 caffe.cpp:313] Batch 534, accuracy/top5 = 0.76
I0817 10:58:24.373703 14586 caffe.cpp:313] Batch 534, loss = 1.57798
I0817 10:58:24.436399 14586 caffe.cpp:313] Batch 535, accuracy/top1 = 0.52
I0817 10:58:24.436421 14586 caffe.cpp:313] Batch 535, accuracy/top5 = 0.84
I0817 10:58:24.436425 14586 caffe.cpp:313] Batch 535, loss = 1.59736
I0817 10:58:24.499126 14586 caffe.cpp:313] Batch 536, accuracy/top1 = 0.66
I0817 10:58:24.499147 14586 caffe.cpp:313] Batch 536, accuracy/top5 = 0.86
I0817 10:58:24.499151 14586 caffe.cpp:313] Batch 536, loss = 1.2885
I0817 10:58:24.561915 14586 caffe.cpp:313] Batch 537, accuracy/top1 = 0.62
I0817 10:58:24.561936 14586 caffe.cpp:313] Batch 537, accuracy/top5 = 0.88
I0817 10:58:24.561940 14586 caffe.cpp:313] Batch 537, loss = 1.44175
I0817 10:58:24.624584 14586 caffe.cpp:313] Batch 538, accuracy/top1 = 0.54
I0817 10:58:24.624605 14586 caffe.cpp:313] Batch 538, accuracy/top5 = 0.8
I0817 10:58:24.624609 14586 caffe.cpp:313] Batch 538, loss = 1.79878
I0817 10:58:24.687273 14586 caffe.cpp:313] Batch 539, accuracy/top1 = 0.38
I0817 10:58:24.687295 14586 caffe.cpp:313] Batch 539, accuracy/top5 = 0.74
I0817 10:58:24.687299 14586 caffe.cpp:313] Batch 539, loss = 2.3626
I0817 10:58:24.750063 14586 caffe.cpp:313] Batch 540, accuracy/top1 = 0.56
I0817 10:58:24.750085 14586 caffe.cpp:313] Batch 540, accuracy/top5 = 0.76
I0817 10:58:24.750089 14586 caffe.cpp:313] Batch 540, loss = 1.89251
I0817 10:58:24.812841 14586 caffe.cpp:313] Batch 541, accuracy/top1 = 0.6
I0817 10:58:24.812863 14586 caffe.cpp:313] Batch 541, accuracy/top5 = 0.8
I0817 10:58:24.812867 14586 caffe.cpp:313] Batch 541, loss = 1.77949
I0817 10:58:24.875604 14586 caffe.cpp:313] Batch 542, accuracy/top1 = 0.6
I0817 10:58:24.875635 14586 caffe.cpp:313] Batch 542, accuracy/top5 = 0.78
I0817 10:58:24.875640 14586 caffe.cpp:313] Batch 542, loss = 1.98425
I0817 10:58:24.938215 14586 caffe.cpp:313] Batch 543, accuracy/top1 = 0.66
I0817 10:58:24.938237 14586 caffe.cpp:313] Batch 543, accuracy/top5 = 0.9
I0817 10:58:24.938241 14586 caffe.cpp:313] Batch 543, loss = 1.45344
I0817 10:58:25.000707 14586 caffe.cpp:313] Batch 544, accuracy/top1 = 0.74
I0817 10:58:25.000730 14586 caffe.cpp:313] Batch 544, accuracy/top5 = 0.84
I0817 10:58:25.000733 14586 caffe.cpp:313] Batch 544, loss = 1.48295
I0817 10:58:25.063432 14586 caffe.cpp:313] Batch 545, accuracy/top1 = 0.54
I0817 10:58:25.063453 14586 caffe.cpp:313] Batch 545, accuracy/top5 = 0.82
I0817 10:58:25.063458 14586 caffe.cpp:313] Batch 545, loss = 1.72931
I0817 10:58:25.126291 14586 caffe.cpp:313] Batch 546, accuracy/top1 = 0.68
I0817 10:58:25.126314 14586 caffe.cpp:313] Batch 546, accuracy/top5 = 0.88
I0817 10:58:25.126317 14586 caffe.cpp:313] Batch 546, loss = 1.70154
I0817 10:58:25.189069 14586 caffe.cpp:313] Batch 547, accuracy/top1 = 0.54
I0817 10:58:25.189092 14586 caffe.cpp:313] Batch 547, accuracy/top5 = 0.84
I0817 10:58:25.189096 14586 caffe.cpp:313] Batch 547, loss = 1.64711
I0817 10:58:25.251801 14586 caffe.cpp:313] Batch 548, accuracy/top1 = 0.56
I0817 10:58:25.251824 14586 caffe.cpp:313] Batch 548, accuracy/top5 = 0.76
I0817 10:58:25.251828 14586 caffe.cpp:313] Batch 548, loss = 2.20654
I0817 10:58:25.314677 14586 caffe.cpp:313] Batch 549, accuracy/top1 = 0.62
I0817 10:58:25.314699 14586 caffe.cpp:313] Batch 549, accuracy/top5 = 0.74
I0817 10:58:25.314703 14586 caffe.cpp:313] Batch 549, loss = 2.04438
I0817 10:58:25.377370 14586 caffe.cpp:313] Batch 550, accuracy/top1 = 0.54
I0817 10:58:25.377393 14586 caffe.cpp:313] Batch 550, accuracy/top5 = 0.82
I0817 10:58:25.377396 14586 caffe.cpp:313] Batch 550, loss = 1.79407
I0817 10:58:25.440105 14586 caffe.cpp:313] Batch 551, accuracy/top1 = 0.68
I0817 10:58:25.440127 14586 caffe.cpp:313] Batch 551, accuracy/top5 = 0.84
I0817 10:58:25.440135 14586 caffe.cpp:313] Batch 551, loss = 1.44803
I0817 10:58:25.502746 14586 caffe.cpp:313] Batch 552, accuracy/top1 = 0.64
I0817 10:58:25.502769 14586 caffe.cpp:313] Batch 552, accuracy/top5 = 0.8
I0817 10:58:25.502774 14586 caffe.cpp:313] Batch 552, loss = 1.60829
I0817 10:58:25.565397 14586 caffe.cpp:313] Batch 553, accuracy/top1 = 0.6
I0817 10:58:25.565419 14586 caffe.cpp:313] Batch 553, accuracy/top5 = 0.84
I0817 10:58:25.565423 14586 caffe.cpp:313] Batch 553, loss = 1.60118
I0817 10:58:25.628259 14586 caffe.cpp:313] Batch 554, accuracy/top1 = 0.6
I0817 10:58:25.628283 14586 caffe.cpp:313] Batch 554, accuracy/top5 = 0.86
I0817 10:58:25.628286 14586 caffe.cpp:313] Batch 554, loss = 1.76207
I0817 10:58:25.690973 14586 caffe.cpp:313] Batch 555, accuracy/top1 = 0.62
I0817 10:58:25.690991 14586 caffe.cpp:313] Batch 555, accuracy/top5 = 0.94
I0817 10:58:25.690995 14586 caffe.cpp:313] Batch 555, loss = 1.30685
I0817 10:58:25.753751 14586 caffe.cpp:313] Batch 556, accuracy/top1 = 0.58
I0817 10:58:25.753772 14586 caffe.cpp:313] Batch 556, accuracy/top5 = 0.78
I0817 10:58:25.753774 14586 caffe.cpp:313] Batch 556, loss = 1.7394
I0817 10:58:25.816949 14586 caffe.cpp:313] Batch 557, accuracy/top1 = 0.54
I0817 10:58:25.816967 14586 caffe.cpp:313] Batch 557, accuracy/top5 = 0.86
I0817 10:58:25.816970 14586 caffe.cpp:313] Batch 557, loss = 1.77948
I0817 10:58:25.879963 14586 caffe.cpp:313] Batch 558, accuracy/top1 = 0.46
I0817 10:58:25.879984 14586 caffe.cpp:313] Batch 558, accuracy/top5 = 0.76
I0817 10:58:25.879988 14586 caffe.cpp:313] Batch 558, loss = 2.18957
I0817 10:58:25.942772 14586 caffe.cpp:313] Batch 559, accuracy/top1 = 0.6
I0817 10:58:25.942795 14586 caffe.cpp:313] Batch 559, accuracy/top5 = 0.8
I0817 10:58:25.942798 14586 caffe.cpp:313] Batch 559, loss = 1.78758
I0817 10:58:26.005395 14586 caffe.cpp:313] Batch 560, accuracy/top1 = 0.66
I0817 10:58:26.005417 14586 caffe.cpp:313] Batch 560, accuracy/top5 = 0.82
I0817 10:58:26.005421 14586 caffe.cpp:313] Batch 560, loss = 1.75887
I0817 10:58:26.068178 14586 caffe.cpp:313] Batch 561, accuracy/top1 = 0.6
I0817 10:58:26.068213 14586 caffe.cpp:313] Batch 561, accuracy/top5 = 0.74
I0817 10:58:26.068218 14586 caffe.cpp:313] Batch 561, loss = 1.9914
I0817 10:58:26.130949 14586 caffe.cpp:313] Batch 562, accuracy/top1 = 0.56
I0817 10:58:26.130971 14586 caffe.cpp:313] Batch 562, accuracy/top5 = 0.82
I0817 10:58:26.130975 14586 caffe.cpp:313] Batch 562, loss = 1.73365
I0817 10:58:26.193610 14586 caffe.cpp:313] Batch 563, accuracy/top1 = 0.62
I0817 10:58:26.193634 14586 caffe.cpp:313] Batch 563, accuracy/top5 = 0.82
I0817 10:58:26.193637 14586 caffe.cpp:313] Batch 563, loss = 1.83974
I0817 10:58:26.256202 14586 caffe.cpp:313] Batch 564, accuracy/top1 = 0.64
I0817 10:58:26.256224 14586 caffe.cpp:313] Batch 564, accuracy/top5 = 0.84
I0817 10:58:26.256228 14586 caffe.cpp:313] Batch 564, loss = 1.69459
I0817 10:58:26.318850 14586 caffe.cpp:313] Batch 565, accuracy/top1 = 0.58
I0817 10:58:26.318872 14586 caffe.cpp:313] Batch 565, accuracy/top5 = 0.88
I0817 10:58:26.318876 14586 caffe.cpp:313] Batch 565, loss = 1.53811
I0817 10:58:26.381618 14586 caffe.cpp:313] Batch 566, accuracy/top1 = 0.6
I0817 10:58:26.381640 14586 caffe.cpp:313] Batch 566, accuracy/top5 = 0.76
I0817 10:58:26.381644 14586 caffe.cpp:313] Batch 566, loss = 1.94914
I0817 10:58:26.444398 14586 caffe.cpp:313] Batch 567, accuracy/top1 = 0.52
I0817 10:58:26.444420 14586 caffe.cpp:313] Batch 567, accuracy/top5 = 0.78
I0817 10:58:26.444424 14586 caffe.cpp:313] Batch 567, loss = 1.8808
I0817 10:58:26.507176 14586 caffe.cpp:313] Batch 568, accuracy/top1 = 0.48
I0817 10:58:26.507199 14586 caffe.cpp:313] Batch 568, accuracy/top5 = 0.7
I0817 10:58:26.507203 14586 caffe.cpp:313] Batch 568, loss = 2.00517
I0817 10:58:26.569856 14586 caffe.cpp:313] Batch 569, accuracy/top1 = 0.44
I0817 10:58:26.569878 14586 caffe.cpp:313] Batch 569, accuracy/top5 = 0.72
I0817 10:58:26.569882 14586 caffe.cpp:313] Batch 569, loss = 2.67274
I0817 10:58:26.632623 14586 caffe.cpp:313] Batch 570, accuracy/top1 = 0.66
I0817 10:58:26.632647 14586 caffe.cpp:313] Batch 570, accuracy/top5 = 0.82
I0817 10:58:26.632652 14586 caffe.cpp:313] Batch 570, loss = 1.63267
I0817 10:58:26.695475 14586 caffe.cpp:313] Batch 571, accuracy/top1 = 0.48
I0817 10:58:26.695497 14586 caffe.cpp:313] Batch 571, accuracy/top5 = 0.66
I0817 10:58:26.695502 14586 caffe.cpp:313] Batch 571, loss = 2.45995
I0817 10:58:26.758198 14586 caffe.cpp:313] Batch 572, accuracy/top1 = 0.46
I0817 10:58:26.758219 14586 caffe.cpp:313] Batch 572, accuracy/top5 = 0.84
I0817 10:58:26.758224 14586 caffe.cpp:313] Batch 572, loss = 1.84296
I0817 10:58:26.820838 14586 caffe.cpp:313] Batch 573, accuracy/top1 = 0.64
I0817 10:58:26.820860 14586 caffe.cpp:313] Batch 573, accuracy/top5 = 0.84
I0817 10:58:26.820864 14586 caffe.cpp:313] Batch 573, loss = 1.93866
I0817 10:58:26.883728 14586 caffe.cpp:313] Batch 574, accuracy/top1 = 0.56
I0817 10:58:26.883750 14586 caffe.cpp:313] Batch 574, accuracy/top5 = 0.76
I0817 10:58:26.883754 14586 caffe.cpp:313] Batch 574, loss = 2.12251
I0817 10:58:26.946369 14586 caffe.cpp:313] Batch 575, accuracy/top1 = 0.54
I0817 10:58:26.946391 14586 caffe.cpp:313] Batch 575, accuracy/top5 = 0.76
I0817 10:58:26.946395 14586 caffe.cpp:313] Batch 575, loss = 1.97651
I0817 10:58:27.009021 14586 caffe.cpp:313] Batch 576, accuracy/top1 = 0.74
I0817 10:58:27.009043 14586 caffe.cpp:313] Batch 576, accuracy/top5 = 0.88
I0817 10:58:27.009047 14586 caffe.cpp:313] Batch 576, loss = 1.15774
I0817 10:58:27.072412 14586 caffe.cpp:313] Batch 577, accuracy/top1 = 0.56
I0817 10:58:27.072430 14586 caffe.cpp:313] Batch 577, accuracy/top5 = 0.84
I0817 10:58:27.072434 14586 caffe.cpp:313] Batch 577, loss = 1.65472
I0817 10:58:27.135685 14586 caffe.cpp:313] Batch 578, accuracy/top1 = 0.6
I0817 10:58:27.135709 14586 caffe.cpp:313] Batch 578, accuracy/top5 = 0.8
I0817 10:58:27.135712 14586 caffe.cpp:313] Batch 578, loss = 1.96098
I0817 10:58:27.198290 14586 caffe.cpp:313] Batch 579, accuracy/top1 = 0.66
I0817 10:58:27.198312 14586 caffe.cpp:313] Batch 579, accuracy/top5 = 0.78
I0817 10:58:27.198315 14586 caffe.cpp:313] Batch 579, loss = 2.02181
I0817 10:58:27.261080 14586 caffe.cpp:313] Batch 580, accuracy/top1 = 0.66
I0817 10:58:27.261103 14586 caffe.cpp:313] Batch 580, accuracy/top5 = 0.88
I0817 10:58:27.261107 14586 caffe.cpp:313] Batch 580, loss = 1.58029
I0817 10:58:27.323753 14586 caffe.cpp:313] Batch 581, accuracy/top1 = 0.58
I0817 10:58:27.323776 14586 caffe.cpp:313] Batch 581, accuracy/top5 = 0.86
I0817 10:58:27.323779 14586 caffe.cpp:313] Batch 581, loss = 1.83409
I0817 10:58:27.386438 14586 caffe.cpp:313] Batch 582, accuracy/top1 = 0.58
I0817 10:58:27.386461 14586 caffe.cpp:313] Batch 582, accuracy/top5 = 0.84
I0817 10:58:27.386464 14586 caffe.cpp:313] Batch 582, loss = 1.52987
I0817 10:58:27.449024 14586 caffe.cpp:313] Batch 583, accuracy/top1 = 0.68
I0817 10:58:27.449046 14586 caffe.cpp:313] Batch 583, accuracy/top5 = 0.82
I0817 10:58:27.449050 14586 caffe.cpp:313] Batch 583, loss = 1.65678
I0817 10:58:27.511745 14586 caffe.cpp:313] Batch 584, accuracy/top1 = 0.6
I0817 10:58:27.511766 14586 caffe.cpp:313] Batch 584, accuracy/top5 = 0.9
I0817 10:58:27.511771 14586 caffe.cpp:313] Batch 584, loss = 1.27142
I0817 10:58:27.574322 14586 caffe.cpp:313] Batch 585, accuracy/top1 = 0.68
I0817 10:58:27.574344 14586 caffe.cpp:313] Batch 585, accuracy/top5 = 0.86
I0817 10:58:27.574348 14586 caffe.cpp:313] Batch 585, loss = 1.41057
I0817 10:58:27.636916 14586 caffe.cpp:313] Batch 586, accuracy/top1 = 0.56
I0817 10:58:27.636939 14586 caffe.cpp:313] Batch 586, accuracy/top5 = 0.82
I0817 10:58:27.636942 14586 caffe.cpp:313] Batch 586, loss = 1.73486
I0817 10:58:27.699549 14586 caffe.cpp:313] Batch 587, accuracy/top1 = 0.64
I0817 10:58:27.699571 14586 caffe.cpp:313] Batch 587, accuracy/top5 = 0.82
I0817 10:58:27.699574 14586 caffe.cpp:313] Batch 587, loss = 1.35506
I0817 10:58:27.762437 14586 caffe.cpp:313] Batch 588, accuracy/top1 = 0.66
I0817 10:58:27.762460 14586 caffe.cpp:313] Batch 588, accuracy/top5 = 0.86
I0817 10:58:27.762465 14586 caffe.cpp:313] Batch 588, loss = 1.44068
I0817 10:58:27.825074 14586 caffe.cpp:313] Batch 589, accuracy/top1 = 0.62
I0817 10:58:27.825095 14586 caffe.cpp:313] Batch 589, accuracy/top5 = 0.84
I0817 10:58:27.825099 14586 caffe.cpp:313] Batch 589, loss = 1.79632
I0817 10:58:27.888123 14586 caffe.cpp:313] Batch 590, accuracy/top1 = 0.6
I0817 10:58:27.888146 14586 caffe.cpp:313] Batch 590, accuracy/top5 = 0.8
I0817 10:58:27.888150 14586 caffe.cpp:313] Batch 590, loss = 1.97084
I0817 10:58:27.951061 14586 caffe.cpp:313] Batch 591, accuracy/top1 = 0.6
I0817 10:58:27.951082 14586 caffe.cpp:313] Batch 591, accuracy/top5 = 0.76
I0817 10:58:27.951086 14586 caffe.cpp:313] Batch 591, loss = 1.69853
I0817 10:58:28.013923 14586 caffe.cpp:313] Batch 592, accuracy/top1 = 0.62
I0817 10:58:28.013947 14586 caffe.cpp:313] Batch 592, accuracy/top5 = 0.84
I0817 10:58:28.013949 14586 caffe.cpp:313] Batch 592, loss = 1.55484
I0817 10:58:28.076783 14586 caffe.cpp:313] Batch 593, accuracy/top1 = 0.48
I0817 10:58:28.076807 14586 caffe.cpp:313] Batch 593, accuracy/top5 = 0.76
I0817 10:58:28.076810 14586 caffe.cpp:313] Batch 593, loss = 2.31587
I0817 10:58:28.139503 14586 caffe.cpp:313] Batch 594, accuracy/top1 = 0.54
I0817 10:58:28.139524 14586 caffe.cpp:313] Batch 594, accuracy/top5 = 0.82
I0817 10:58:28.139529 14586 caffe.cpp:313] Batch 594, loss = 1.85398
I0817 10:58:28.202270 14586 caffe.cpp:313] Batch 595, accuracy/top1 = 0.68
I0817 10:58:28.202291 14586 caffe.cpp:313] Batch 595, accuracy/top5 = 0.9
I0817 10:58:28.202296 14586 caffe.cpp:313] Batch 595, loss = 1.51907
I0817 10:58:28.265072 14586 caffe.cpp:313] Batch 596, accuracy/top1 = 0.54
I0817 10:58:28.265095 14586 caffe.cpp:313] Batch 596, accuracy/top5 = 0.7
I0817 10:58:28.265100 14586 caffe.cpp:313] Batch 596, loss = 2.31156
I0817 10:58:28.327881 14586 caffe.cpp:313] Batch 597, accuracy/top1 = 0.72
I0817 10:58:28.327904 14586 caffe.cpp:313] Batch 597, accuracy/top5 = 0.88
I0817 10:58:28.327908 14586 caffe.cpp:313] Batch 597, loss = 1.22793
I0817 10:58:28.390630 14586 caffe.cpp:313] Batch 598, accuracy/top1 = 0.44
I0817 10:58:28.390653 14586 caffe.cpp:313] Batch 598, accuracy/top5 = 0.76
I0817 10:58:28.390674 14586 caffe.cpp:313] Batch 598, loss = 2.27008
I0817 10:58:28.453425 14586 caffe.cpp:313] Batch 599, accuracy/top1 = 0.6
I0817 10:58:28.453447 14586 caffe.cpp:313] Batch 599, accuracy/top5 = 0.76
I0817 10:58:28.453451 14586 caffe.cpp:313] Batch 599, loss = 1.9677
I0817 10:58:28.516160 14586 caffe.cpp:313] Batch 600, accuracy/top1 = 0.6
I0817 10:58:28.516183 14586 caffe.cpp:313] Batch 600, accuracy/top5 = 0.78
I0817 10:58:28.516187 14586 caffe.cpp:313] Batch 600, loss = 1.82956
I0817 10:58:28.578964 14586 caffe.cpp:313] Batch 601, accuracy/top1 = 0.56
I0817 10:58:28.578987 14586 caffe.cpp:313] Batch 601, accuracy/top5 = 0.9
I0817 10:58:28.578991 14586 caffe.cpp:313] Batch 601, loss = 1.47878
I0817 10:58:28.641772 14586 caffe.cpp:313] Batch 602, accuracy/top1 = 0.5
I0817 10:58:28.641794 14586 caffe.cpp:313] Batch 602, accuracy/top5 = 0.76
I0817 10:58:28.641798 14586 caffe.cpp:313] Batch 602, loss = 2.27757
I0817 10:58:28.704658 14586 caffe.cpp:313] Batch 603, accuracy/top1 = 0.66
I0817 10:58:28.704679 14586 caffe.cpp:313] Batch 603, accuracy/top5 = 0.8
I0817 10:58:28.704684 14586 caffe.cpp:313] Batch 603, loss = 1.3641
I0817 10:58:28.767469 14586 caffe.cpp:313] Batch 604, accuracy/top1 = 0.74
I0817 10:58:28.767490 14586 caffe.cpp:313] Batch 604, accuracy/top5 = 0.96
I0817 10:58:28.767494 14586 caffe.cpp:313] Batch 604, loss = 0.990387
I0817 10:58:28.830351 14586 caffe.cpp:313] Batch 605, accuracy/top1 = 0.52
I0817 10:58:28.830370 14586 caffe.cpp:313] Batch 605, accuracy/top5 = 0.7
I0817 10:58:28.830374 14586 caffe.cpp:313] Batch 605, loss = 2.18136
I0817 10:58:28.893249 14586 caffe.cpp:313] Batch 606, accuracy/top1 = 0.62
I0817 10:58:28.893270 14586 caffe.cpp:313] Batch 606, accuracy/top5 = 0.84
I0817 10:58:28.893273 14586 caffe.cpp:313] Batch 606, loss = 1.80077
I0817 10:58:28.955920 14586 caffe.cpp:313] Batch 607, accuracy/top1 = 0.52
I0817 10:58:28.955943 14586 caffe.cpp:313] Batch 607, accuracy/top5 = 0.78
I0817 10:58:28.955946 14586 caffe.cpp:313] Batch 607, loss = 1.8709
I0817 10:58:29.018703 14586 caffe.cpp:313] Batch 608, accuracy/top1 = 0.6
I0817 10:58:29.018725 14586 caffe.cpp:313] Batch 608, accuracy/top5 = 0.82
I0817 10:58:29.018729 14586 caffe.cpp:313] Batch 608, loss = 1.63041
I0817 10:58:29.081651 14586 caffe.cpp:313] Batch 609, accuracy/top1 = 0.62
I0817 10:58:29.081668 14586 caffe.cpp:313] Batch 609, accuracy/top5 = 0.8
I0817 10:58:29.081672 14586 caffe.cpp:313] Batch 609, loss = 1.9754
I0817 10:58:29.144412 14586 caffe.cpp:313] Batch 610, accuracy/top1 = 0.54
I0817 10:58:29.144434 14586 caffe.cpp:313] Batch 610, accuracy/top5 = 0.74
I0817 10:58:29.144438 14586 caffe.cpp:313] Batch 610, loss = 2.01296
I0817 10:58:29.207161 14586 caffe.cpp:313] Batch 611, accuracy/top1 = 0.64
I0817 10:58:29.207182 14586 caffe.cpp:313] Batch 611, accuracy/top5 = 0.8
I0817 10:58:29.207186 14586 caffe.cpp:313] Batch 611, loss = 1.7056
I0817 10:58:29.269942 14586 caffe.cpp:313] Batch 612, accuracy/top1 = 0.64
I0817 10:58:29.269965 14586 caffe.cpp:313] Batch 612, accuracy/top5 = 0.82
I0817 10:58:29.269969 14586 caffe.cpp:313] Batch 612, loss = 1.46691
I0817 10:58:29.332542 14586 caffe.cpp:313] Batch 613, accuracy/top1 = 0.58
I0817 10:58:29.332564 14586 caffe.cpp:313] Batch 613, accuracy/top5 = 0.76
I0817 10:58:29.332568 14586 caffe.cpp:313] Batch 613, loss = 2.11951
I0817 10:58:29.395156 14586 caffe.cpp:313] Batch 614, accuracy/top1 = 0.44
I0817 10:58:29.395179 14586 caffe.cpp:313] Batch 614, accuracy/top5 = 0.78
I0817 10:58:29.395182 14586 caffe.cpp:313] Batch 614, loss = 2.1755
I0817 10:58:29.457801 14586 caffe.cpp:313] Batch 615, accuracy/top1 = 0.42
I0817 10:58:29.457823 14586 caffe.cpp:313] Batch 615, accuracy/top5 = 0.78
I0817 10:58:29.457828 14586 caffe.cpp:313] Batch 615, loss = 2.21821
I0817 10:58:29.520546 14586 caffe.cpp:313] Batch 616, accuracy/top1 = 0.58
I0817 10:58:29.520570 14586 caffe.cpp:313] Batch 616, accuracy/top5 = 0.86
I0817 10:58:29.520573 14586 caffe.cpp:313] Batch 616, loss = 1.85001
I0817 10:58:29.583236 14586 caffe.cpp:313] Batch 617, accuracy/top1 = 0.58
I0817 10:58:29.583272 14586 caffe.cpp:313] Batch 617, accuracy/top5 = 0.78
I0817 10:58:29.583277 14586 caffe.cpp:313] Batch 617, loss = 1.93651
I0817 10:58:29.645922 14586 caffe.cpp:313] Batch 618, accuracy/top1 = 0.5
I0817 10:58:29.645946 14586 caffe.cpp:313] Batch 618, accuracy/top5 = 0.82
I0817 10:58:29.645951 14586 caffe.cpp:313] Batch 618, loss = 2.00655
I0817 10:58:29.708658 14586 caffe.cpp:313] Batch 619, accuracy/top1 = 0.7
I0817 10:58:29.708680 14586 caffe.cpp:313] Batch 619, accuracy/top5 = 0.84
I0817 10:58:29.708684 14586 caffe.cpp:313] Batch 619, loss = 1.29993
I0817 10:58:29.771409 14586 caffe.cpp:313] Batch 620, accuracy/top1 = 0.5
I0817 10:58:29.771431 14586 caffe.cpp:313] Batch 620, accuracy/top5 = 0.78
I0817 10:58:29.771435 14586 caffe.cpp:313] Batch 620, loss = 1.83845
I0817 10:58:29.834281 14586 caffe.cpp:313] Batch 621, accuracy/top1 = 0.56
I0817 10:58:29.834306 14586 caffe.cpp:313] Batch 621, accuracy/top5 = 0.84
I0817 10:58:29.834309 14586 caffe.cpp:313] Batch 621, loss = 1.89689
I0817 10:58:29.897140 14586 caffe.cpp:313] Batch 622, accuracy/top1 = 0.56
I0817 10:58:29.897161 14586 caffe.cpp:313] Batch 622, accuracy/top5 = 0.78
I0817 10:58:29.897164 14586 caffe.cpp:313] Batch 622, loss = 2.06681
I0817 10:58:29.959921 14586 caffe.cpp:313] Batch 623, accuracy/top1 = 0.52
I0817 10:58:29.959940 14586 caffe.cpp:313] Batch 623, accuracy/top5 = 0.82
I0817 10:58:29.959944 14586 caffe.cpp:313] Batch 623, loss = 1.98496
I0817 10:58:30.023025 14586 caffe.cpp:313] Batch 624, accuracy/top1 = 0.58
I0817 10:58:30.023043 14586 caffe.cpp:313] Batch 624, accuracy/top5 = 0.82
I0817 10:58:30.023047 14586 caffe.cpp:313] Batch 624, loss = 1.80896
I0817 10:58:30.085819 14586 caffe.cpp:313] Batch 625, accuracy/top1 = 0.5
I0817 10:58:30.085841 14586 caffe.cpp:313] Batch 625, accuracy/top5 = 0.78
I0817 10:58:30.085845 14586 caffe.cpp:313] Batch 625, loss = 2.3652
I0817 10:58:30.148617 14586 caffe.cpp:313] Batch 626, accuracy/top1 = 0.38
I0817 10:58:30.148638 14586 caffe.cpp:313] Batch 626, accuracy/top5 = 0.68
I0817 10:58:30.148643 14586 caffe.cpp:313] Batch 626, loss = 2.80917
I0817 10:58:30.211367 14586 caffe.cpp:313] Batch 627, accuracy/top1 = 0.46
I0817 10:58:30.211390 14586 caffe.cpp:313] Batch 627, accuracy/top5 = 0.78
I0817 10:58:30.211393 14586 caffe.cpp:313] Batch 627, loss = 2.26262
I0817 10:58:30.274076 14586 caffe.cpp:313] Batch 628, accuracy/top1 = 0.54
I0817 10:58:30.274099 14586 caffe.cpp:313] Batch 628, accuracy/top5 = 0.84
I0817 10:58:30.274103 14586 caffe.cpp:313] Batch 628, loss = 2.05987
I0817 10:58:30.336906 14586 caffe.cpp:313] Batch 629, accuracy/top1 = 0.56
I0817 10:58:30.336928 14586 caffe.cpp:313] Batch 629, accuracy/top5 = 0.72
I0817 10:58:30.336932 14586 caffe.cpp:313] Batch 629, loss = 2.06524
I0817 10:58:30.399657 14586 caffe.cpp:313] Batch 630, accuracy/top1 = 0.42
I0817 10:58:30.399679 14586 caffe.cpp:313] Batch 630, accuracy/top5 = 0.64
I0817 10:58:30.399683 14586 caffe.cpp:313] Batch 630, loss = 2.49964
I0817 10:58:30.462502 14586 caffe.cpp:313] Batch 631, accuracy/top1 = 0.7
I0817 10:58:30.462524 14586 caffe.cpp:313] Batch 631, accuracy/top5 = 0.88
I0817 10:58:30.462528 14586 caffe.cpp:313] Batch 631, loss = 1.25411
I0817 10:58:30.525362 14586 caffe.cpp:313] Batch 632, accuracy/top1 = 0.56
I0817 10:58:30.525385 14586 caffe.cpp:313] Batch 632, accuracy/top5 = 0.88
I0817 10:58:30.525389 14586 caffe.cpp:313] Batch 632, loss = 1.607
I0817 10:58:30.588162 14586 caffe.cpp:313] Batch 633, accuracy/top1 = 0.62
I0817 10:58:30.588186 14586 caffe.cpp:313] Batch 633, accuracy/top5 = 0.72
I0817 10:58:30.588189 14586 caffe.cpp:313] Batch 633, loss = 2.03886
I0817 10:58:30.650934 14586 caffe.cpp:313] Batch 634, accuracy/top1 = 0.58
I0817 10:58:30.650956 14586 caffe.cpp:313] Batch 634, accuracy/top5 = 0.72
I0817 10:58:30.650960 14586 caffe.cpp:313] Batch 634, loss = 2.28378
I0817 10:58:30.713716 14586 caffe.cpp:313] Batch 635, accuracy/top1 = 0.6
I0817 10:58:30.713738 14586 caffe.cpp:313] Batch 635, accuracy/top5 = 0.8
I0817 10:58:30.713742 14586 caffe.cpp:313] Batch 635, loss = 1.85911
I0817 10:58:30.776679 14586 caffe.cpp:313] Batch 636, accuracy/top1 = 0.56
I0817 10:58:30.776713 14586 caffe.cpp:313] Batch 636, accuracy/top5 = 0.78
I0817 10:58:30.776718 14586 caffe.cpp:313] Batch 636, loss = 2.09445
I0817 10:58:30.839733 14586 caffe.cpp:313] Batch 637, accuracy/top1 = 0.54
I0817 10:58:30.839753 14586 caffe.cpp:313] Batch 637, accuracy/top5 = 0.88
I0817 10:58:30.839757 14586 caffe.cpp:313] Batch 637, loss = 1.55365
I0817 10:58:30.902585 14586 caffe.cpp:313] Batch 638, accuracy/top1 = 0.58
I0817 10:58:30.902606 14586 caffe.cpp:313] Batch 638, accuracy/top5 = 0.82
I0817 10:58:30.902609 14586 caffe.cpp:313] Batch 638, loss = 1.69698
I0817 10:58:30.965324 14586 caffe.cpp:313] Batch 639, accuracy/top1 = 0.56
I0817 10:58:30.965345 14586 caffe.cpp:313] Batch 639, accuracy/top5 = 0.84
I0817 10:58:30.965349 14586 caffe.cpp:313] Batch 639, loss = 1.66447
I0817 10:58:31.028105 14586 caffe.cpp:313] Batch 640, accuracy/top1 = 0.52
I0817 10:58:31.028122 14586 caffe.cpp:313] Batch 640, accuracy/top5 = 0.82
I0817 10:58:31.028126 14586 caffe.cpp:313] Batch 640, loss = 1.86724
I0817 10:58:31.090746 14586 caffe.cpp:313] Batch 641, accuracy/top1 = 0.52
I0817 10:58:31.090768 14586 caffe.cpp:313] Batch 641, accuracy/top5 = 0.84
I0817 10:58:31.090771 14586 caffe.cpp:313] Batch 641, loss = 1.69844
I0817 10:58:31.154160 14586 caffe.cpp:313] Batch 642, accuracy/top1 = 0.64
I0817 10:58:31.154182 14586 caffe.cpp:313] Batch 642, accuracy/top5 = 0.78
I0817 10:58:31.154186 14586 caffe.cpp:313] Batch 642, loss = 1.85336
I0817 10:58:31.216852 14586 caffe.cpp:313] Batch 643, accuracy/top1 = 0.52
I0817 10:58:31.216874 14586 caffe.cpp:313] Batch 643, accuracy/top5 = 0.82
I0817 10:58:31.216878 14586 caffe.cpp:313] Batch 643, loss = 1.6813
I0817 10:58:31.279614 14586 caffe.cpp:313] Batch 644, accuracy/top1 = 0.54
I0817 10:58:31.279635 14586 caffe.cpp:313] Batch 644, accuracy/top5 = 0.72
I0817 10:58:31.279639 14586 caffe.cpp:313] Batch 644, loss = 1.99881
I0817 10:58:31.342324 14586 caffe.cpp:313] Batch 645, accuracy/top1 = 0.52
I0817 10:58:31.342346 14586 caffe.cpp:313] Batch 645, accuracy/top5 = 0.86
I0817 10:58:31.342350 14586 caffe.cpp:313] Batch 645, loss = 1.66467
I0817 10:58:31.405009 14586 caffe.cpp:313] Batch 646, accuracy/top1 = 0.6
I0817 10:58:31.405030 14586 caffe.cpp:313] Batch 646, accuracy/top5 = 0.86
I0817 10:58:31.405035 14586 caffe.cpp:313] Batch 646, loss = 1.54219
I0817 10:58:31.467686 14586 caffe.cpp:313] Batch 647, accuracy/top1 = 0.5
I0817 10:58:31.467710 14586 caffe.cpp:313] Batch 647, accuracy/top5 = 0.76
I0817 10:58:31.467713 14586 caffe.cpp:313] Batch 647, loss = 2.23332
I0817 10:58:31.530344 14586 caffe.cpp:313] Batch 648, accuracy/top1 = 0.6
I0817 10:58:31.530366 14586 caffe.cpp:313] Batch 648, accuracy/top5 = 0.82
I0817 10:58:31.530370 14586 caffe.cpp:313] Batch 648, loss = 1.4735
I0817 10:58:31.593092 14586 caffe.cpp:313] Batch 649, accuracy/top1 = 0.62
I0817 10:58:31.593116 14586 caffe.cpp:313] Batch 649, accuracy/top5 = 0.76
I0817 10:58:31.593119 14586 caffe.cpp:313] Batch 649, loss = 1.81963
I0817 10:58:31.655910 14586 caffe.cpp:313] Batch 650, accuracy/top1 = 0.56
I0817 10:58:31.655932 14586 caffe.cpp:313] Batch 650, accuracy/top5 = 0.74
I0817 10:58:31.655936 14586 caffe.cpp:313] Batch 650, loss = 1.67131
I0817 10:58:31.718688 14586 caffe.cpp:313] Batch 651, accuracy/top1 = 0.5
I0817 10:58:31.718711 14586 caffe.cpp:313] Batch 651, accuracy/top5 = 0.7
I0817 10:58:31.718715 14586 caffe.cpp:313] Batch 651, loss = 2.3341
I0817 10:58:31.781533 14586 caffe.cpp:313] Batch 652, accuracy/top1 = 0.54
I0817 10:58:31.781556 14586 caffe.cpp:313] Batch 652, accuracy/top5 = 0.74
I0817 10:58:31.781560 14586 caffe.cpp:313] Batch 652, loss = 2.18483
I0817 10:58:31.844959 14586 caffe.cpp:313] Batch 653, accuracy/top1 = 0.34
I0817 10:58:31.844983 14586 caffe.cpp:313] Batch 653, accuracy/top5 = 0.78
I0817 10:58:31.844987 14586 caffe.cpp:313] Batch 653, loss = 2.13586
I0817 10:58:31.907620 14586 caffe.cpp:313] Batch 654, accuracy/top1 = 0.54
I0817 10:58:31.907642 14586 caffe.cpp:313] Batch 654, accuracy/top5 = 0.86
I0817 10:58:31.907647 14586 caffe.cpp:313] Batch 654, loss = 1.87914
I0817 10:58:31.970286 14586 caffe.cpp:313] Batch 655, accuracy/top1 = 0.66
I0817 10:58:31.970309 14586 caffe.cpp:313] Batch 655, accuracy/top5 = 0.82
I0817 10:58:31.970312 14586 caffe.cpp:313] Batch 655, loss = 1.42597
I0817 10:58:32.032920 14586 caffe.cpp:313] Batch 656, accuracy/top1 = 0.62
I0817 10:58:32.032938 14586 caffe.cpp:313] Batch 656, accuracy/top5 = 0.9
I0817 10:58:32.032943 14586 caffe.cpp:313] Batch 656, loss = 1.51146
I0817 10:58:32.095767 14586 caffe.cpp:313] Batch 657, accuracy/top1 = 0.6
I0817 10:58:32.095787 14586 caffe.cpp:313] Batch 657, accuracy/top5 = 0.74
I0817 10:58:32.095790 14586 caffe.cpp:313] Batch 657, loss = 1.83087
I0817 10:58:32.158501 14586 caffe.cpp:313] Batch 658, accuracy/top1 = 0.48
I0817 10:58:32.158520 14586 caffe.cpp:313] Batch 658, accuracy/top5 = 0.78
I0817 10:58:32.158524 14586 caffe.cpp:313] Batch 658, loss = 1.93068
I0817 10:58:32.221310 14586 caffe.cpp:313] Batch 659, accuracy/top1 = 0.54
I0817 10:58:32.221333 14586 caffe.cpp:313] Batch 659, accuracy/top5 = 0.76
I0817 10:58:32.221336 14586 caffe.cpp:313] Batch 659, loss = 2.0243
I0817 10:58:32.284039 14586 caffe.cpp:313] Batch 660, accuracy/top1 = 0.7
I0817 10:58:32.284060 14586 caffe.cpp:313] Batch 660, accuracy/top5 = 0.78
I0817 10:58:32.284065 14586 caffe.cpp:313] Batch 660, loss = 1.59293
I0817 10:58:32.346666 14586 caffe.cpp:313] Batch 661, accuracy/top1 = 0.62
I0817 10:58:32.346689 14586 caffe.cpp:313] Batch 661, accuracy/top5 = 0.84
I0817 10:58:32.346693 14586 caffe.cpp:313] Batch 661, loss = 1.53237
I0817 10:58:32.409291 14586 caffe.cpp:313] Batch 662, accuracy/top1 = 0.48
I0817 10:58:32.409314 14586 caffe.cpp:313] Batch 662, accuracy/top5 = 0.74
I0817 10:58:32.409318 14586 caffe.cpp:313] Batch 662, loss = 2.05245
I0817 10:58:32.471837 14586 caffe.cpp:313] Batch 663, accuracy/top1 = 0.64
I0817 10:58:32.471858 14586 caffe.cpp:313] Batch 663, accuracy/top5 = 0.74
I0817 10:58:32.471863 14586 caffe.cpp:313] Batch 663, loss = 2.09809
I0817 10:58:32.534518 14586 caffe.cpp:313] Batch 664, accuracy/top1 = 0.5
I0817 10:58:32.534540 14586 caffe.cpp:313] Batch 664, accuracy/top5 = 0.8
I0817 10:58:32.534544 14586 caffe.cpp:313] Batch 664, loss = 1.95157
I0817 10:58:32.597240 14586 caffe.cpp:313] Batch 665, accuracy/top1 = 0.54
I0817 10:58:32.597262 14586 caffe.cpp:313] Batch 665, accuracy/top5 = 0.72
I0817 10:58:32.597266 14586 caffe.cpp:313] Batch 665, loss = 1.92019
I0817 10:58:32.660065 14586 caffe.cpp:313] Batch 666, accuracy/top1 = 0.62
I0817 10:58:32.660086 14586 caffe.cpp:313] Batch 666, accuracy/top5 = 0.82
I0817 10:58:32.660090 14586 caffe.cpp:313] Batch 666, loss = 1.70118
I0817 10:58:32.722771 14586 caffe.cpp:313] Batch 667, accuracy/top1 = 0.6
I0817 10:58:32.722795 14586 caffe.cpp:313] Batch 667, accuracy/top5 = 0.8
I0817 10:58:32.722800 14586 caffe.cpp:313] Batch 667, loss = 1.85198
I0817 10:58:32.785503 14586 caffe.cpp:313] Batch 668, accuracy/top1 = 0.52
I0817 10:58:32.785526 14586 caffe.cpp:313] Batch 668, accuracy/top5 = 0.76
I0817 10:58:32.785529 14586 caffe.cpp:313] Batch 668, loss = 2.01692
I0817 10:58:32.848457 14586 caffe.cpp:313] Batch 669, accuracy/top1 = 0.7
I0817 10:58:32.848475 14586 caffe.cpp:313] Batch 669, accuracy/top5 = 0.92
I0817 10:58:32.848479 14586 caffe.cpp:313] Batch 669, loss = 1.19673
I0817 10:58:32.911316 14586 caffe.cpp:313] Batch 670, accuracy/top1 = 0.6
I0817 10:58:32.911339 14586 caffe.cpp:313] Batch 670, accuracy/top5 = 0.78
I0817 10:58:32.911343 14586 caffe.cpp:313] Batch 670, loss = 1.87735
I0817 10:58:32.974017 14586 caffe.cpp:313] Batch 671, accuracy/top1 = 0.62
I0817 10:58:32.974040 14586 caffe.cpp:313] Batch 671, accuracy/top5 = 0.82
I0817 10:58:32.974043 14586 caffe.cpp:313] Batch 671, loss = 1.64302
I0817 10:58:33.036844 14586 caffe.cpp:313] Batch 672, accuracy/top1 = 0.48
I0817 10:58:33.036861 14586 caffe.cpp:313] Batch 672, accuracy/top5 = 0.86
I0817 10:58:33.036865 14586 caffe.cpp:313] Batch 672, loss = 2.0517
I0817 10:58:33.099575 14586 caffe.cpp:313] Batch 673, accuracy/top1 = 0.68
I0817 10:58:33.099597 14586 caffe.cpp:313] Batch 673, accuracy/top5 = 0.86
I0817 10:58:33.099618 14586 caffe.cpp:313] Batch 673, loss = 1.29738
I0817 10:58:33.162446 14586 caffe.cpp:313] Batch 674, accuracy/top1 = 0.7
I0817 10:58:33.162464 14586 caffe.cpp:313] Batch 674, accuracy/top5 = 0.92
I0817 10:58:33.162467 14586 caffe.cpp:313] Batch 674, loss = 1.09455
I0817 10:58:33.225029 14586 caffe.cpp:313] Batch 675, accuracy/top1 = 0.56
I0817 10:58:33.225051 14586 caffe.cpp:313] Batch 675, accuracy/top5 = 0.74
I0817 10:58:33.225055 14586 caffe.cpp:313] Batch 675, loss = 1.99795
I0817 10:58:33.287672 14586 caffe.cpp:313] Batch 676, accuracy/top1 = 0.48
I0817 10:58:33.287694 14586 caffe.cpp:313] Batch 676, accuracy/top5 = 0.78
I0817 10:58:33.287698 14586 caffe.cpp:313] Batch 676, loss = 1.86177
I0817 10:58:33.350322 14586 caffe.cpp:313] Batch 677, accuracy/top1 = 0.6
I0817 10:58:33.350345 14586 caffe.cpp:313] Batch 677, accuracy/top5 = 0.86
I0817 10:58:33.350349 14586 caffe.cpp:313] Batch 677, loss = 1.55427
I0817 10:58:33.413034 14586 caffe.cpp:313] Batch 678, accuracy/top1 = 0.5
I0817 10:58:33.413056 14586 caffe.cpp:313] Batch 678, accuracy/top5 = 0.82
I0817 10:58:33.413060 14586 caffe.cpp:313] Batch 678, loss = 2.00256
I0817 10:58:33.475847 14586 caffe.cpp:313] Batch 679, accuracy/top1 = 0.66
I0817 10:58:33.475870 14586 caffe.cpp:313] Batch 679, accuracy/top5 = 0.82
I0817 10:58:33.475874 14586 caffe.cpp:313] Batch 679, loss = 1.60097
I0817 10:58:33.538413 14586 caffe.cpp:313] Batch 680, accuracy/top1 = 0.58
I0817 10:58:33.538435 14586 caffe.cpp:313] Batch 680, accuracy/top5 = 0.88
I0817 10:58:33.538439 14586 caffe.cpp:313] Batch 680, loss = 1.47023
I0817 10:58:33.601060 14586 caffe.cpp:313] Batch 681, accuracy/top1 = 0.66
I0817 10:58:33.601083 14586 caffe.cpp:313] Batch 681, accuracy/top5 = 0.88
I0817 10:58:33.601086 14586 caffe.cpp:313] Batch 681, loss = 1.52075
I0817 10:58:33.663825 14586 caffe.cpp:313] Batch 682, accuracy/top1 = 0.54
I0817 10:58:33.663847 14586 caffe.cpp:313] Batch 682, accuracy/top5 = 0.84
I0817 10:58:33.663851 14586 caffe.cpp:313] Batch 682, loss = 1.95123
I0817 10:58:33.726523 14586 caffe.cpp:313] Batch 683, accuracy/top1 = 0.5
I0817 10:58:33.726546 14586 caffe.cpp:313] Batch 683, accuracy/top5 = 0.8
I0817 10:58:33.726549 14586 caffe.cpp:313] Batch 683, loss = 2.19013
I0817 10:58:33.789193 14586 caffe.cpp:313] Batch 684, accuracy/top1 = 0.52
I0817 10:58:33.789216 14586 caffe.cpp:313] Batch 684, accuracy/top5 = 0.76
I0817 10:58:33.789221 14586 caffe.cpp:313] Batch 684, loss = 2.00688
I0817 10:58:33.852056 14586 caffe.cpp:313] Batch 685, accuracy/top1 = 0.56
I0817 10:58:33.852074 14586 caffe.cpp:313] Batch 685, accuracy/top5 = 0.86
I0817 10:58:33.852078 14586 caffe.cpp:313] Batch 685, loss = 2.01172
I0817 10:58:33.914927 14586 caffe.cpp:313] Batch 686, accuracy/top1 = 0.5
I0817 10:58:33.914947 14586 caffe.cpp:313] Batch 686, accuracy/top5 = 0.72
I0817 10:58:33.914952 14586 caffe.cpp:313] Batch 686, loss = 2.05612
I0817 10:58:33.977780 14586 caffe.cpp:313] Batch 687, accuracy/top1 = 0.5
I0817 10:58:33.977803 14586 caffe.cpp:313] Batch 687, accuracy/top5 = 0.8
I0817 10:58:33.977807 14586 caffe.cpp:313] Batch 687, loss = 2.37729
I0817 10:58:34.040442 14586 caffe.cpp:313] Batch 688, accuracy/top1 = 0.56
I0817 10:58:34.040462 14586 caffe.cpp:313] Batch 688, accuracy/top5 = 0.86
I0817 10:58:34.040465 14586 caffe.cpp:313] Batch 688, loss = 1.78014
I0817 10:58:34.103332 14586 caffe.cpp:313] Batch 689, accuracy/top1 = 0.58
I0817 10:58:34.103353 14586 caffe.cpp:313] Batch 689, accuracy/top5 = 0.82
I0817 10:58:34.103358 14586 caffe.cpp:313] Batch 689, loss = 1.70153
I0817 10:58:34.165987 14586 caffe.cpp:313] Batch 690, accuracy/top1 = 0.48
I0817 10:58:34.166009 14586 caffe.cpp:313] Batch 690, accuracy/top5 = 0.76
I0817 10:58:34.166013 14586 caffe.cpp:313] Batch 690, loss = 1.99547
I0817 10:58:34.228726 14586 caffe.cpp:313] Batch 691, accuracy/top1 = 0.6
I0817 10:58:34.228746 14586 caffe.cpp:313] Batch 691, accuracy/top5 = 0.76
I0817 10:58:34.228751 14586 caffe.cpp:313] Batch 691, loss = 1.88191
I0817 10:58:34.291612 14586 caffe.cpp:313] Batch 692, accuracy/top1 = 0.58
I0817 10:58:34.291646 14586 caffe.cpp:313] Batch 692, accuracy/top5 = 0.78
I0817 10:58:34.291651 14586 caffe.cpp:313] Batch 692, loss = 2.05025
I0817 10:58:34.354424 14586 caffe.cpp:313] Batch 693, accuracy/top1 = 0.7
I0817 10:58:34.354447 14586 caffe.cpp:313] Batch 693, accuracy/top5 = 0.82
I0817 10:58:34.354451 14586 caffe.cpp:313] Batch 693, loss = 1.71301
I0817 10:58:34.417052 14586 caffe.cpp:313] Batch 694, accuracy/top1 = 0.56
I0817 10:58:34.417073 14586 caffe.cpp:313] Batch 694, accuracy/top5 = 0.78
I0817 10:58:34.417076 14586 caffe.cpp:313] Batch 694, loss = 1.75564
I0817 10:58:34.479686 14586 caffe.cpp:313] Batch 695, accuracy/top1 = 0.6
I0817 10:58:34.479709 14586 caffe.cpp:313] Batch 695, accuracy/top5 = 0.78
I0817 10:58:34.479713 14586 caffe.cpp:313] Batch 695, loss = 1.689
I0817 10:58:34.542397 14586 caffe.cpp:313] Batch 696, accuracy/top1 = 0.42
I0817 10:58:34.542418 14586 caffe.cpp:313] Batch 696, accuracy/top5 = 0.8
I0817 10:58:34.542423 14586 caffe.cpp:313] Batch 696, loss = 1.96428
I0817 10:58:34.605077 14586 caffe.cpp:313] Batch 697, accuracy/top1 = 0.68
I0817 10:58:34.605098 14586 caffe.cpp:313] Batch 697, accuracy/top5 = 0.88
I0817 10:58:34.605103 14586 caffe.cpp:313] Batch 697, loss = 1.36302
I0817 10:58:34.667510 14586 caffe.cpp:313] Batch 698, accuracy/top1 = 0.44
I0817 10:58:34.667531 14586 caffe.cpp:313] Batch 698, accuracy/top5 = 0.78
I0817 10:58:34.667536 14586 caffe.cpp:313] Batch 698, loss = 2.13963
I0817 10:58:34.730137 14586 caffe.cpp:313] Batch 699, accuracy/top1 = 0.72
I0817 10:58:34.730160 14586 caffe.cpp:313] Batch 699, accuracy/top5 = 0.88
I0817 10:58:34.730165 14586 caffe.cpp:313] Batch 699, loss = 1.27854
I0817 10:58:34.792860 14586 caffe.cpp:313] Batch 700, accuracy/top1 = 0.58
I0817 10:58:34.792883 14586 caffe.cpp:313] Batch 700, accuracy/top5 = 0.82
I0817 10:58:34.792887 14586 caffe.cpp:313] Batch 700, loss = 2.04326
I0817 10:58:34.856243 14586 caffe.cpp:313] Batch 701, accuracy/top1 = 0.48
I0817 10:58:34.856263 14586 caffe.cpp:313] Batch 701, accuracy/top5 = 0.68
I0817 10:58:34.856267 14586 caffe.cpp:313] Batch 701, loss = 2.43107
I0817 10:58:34.919039 14586 caffe.cpp:313] Batch 702, accuracy/top1 = 0.56
I0817 10:58:34.919061 14586 caffe.cpp:313] Batch 702, accuracy/top5 = 0.74
I0817 10:58:34.919065 14586 caffe.cpp:313] Batch 702, loss = 2.17195
I0817 10:58:34.981719 14586 caffe.cpp:313] Batch 703, accuracy/top1 = 0.64
I0817 10:58:34.981740 14586 caffe.cpp:313] Batch 703, accuracy/top5 = 0.9
I0817 10:58:34.981745 14586 caffe.cpp:313] Batch 703, loss = 1.36532
I0817 10:58:35.044517 14586 caffe.cpp:313] Batch 704, accuracy/top1 = 0.58
I0817 10:58:35.044535 14586 caffe.cpp:313] Batch 704, accuracy/top5 = 0.78
I0817 10:58:35.044539 14586 caffe.cpp:313] Batch 704, loss = 2.11531
I0817 10:58:35.107224 14586 caffe.cpp:313] Batch 705, accuracy/top1 = 0.68
I0817 10:58:35.107246 14586 caffe.cpp:313] Batch 705, accuracy/top5 = 0.82
I0817 10:58:35.107250 14586 caffe.cpp:313] Batch 705, loss = 1.36943
I0817 10:58:35.169973 14586 caffe.cpp:313] Batch 706, accuracy/top1 = 0.56
I0817 10:58:35.169991 14586 caffe.cpp:313] Batch 706, accuracy/top5 = 0.88
I0817 10:58:35.169996 14586 caffe.cpp:313] Batch 706, loss = 1.77899
I0817 10:58:35.232743 14586 caffe.cpp:313] Batch 707, accuracy/top1 = 0.62
I0817 10:58:35.232765 14586 caffe.cpp:313] Batch 707, accuracy/top5 = 0.84
I0817 10:58:35.232769 14586 caffe.cpp:313] Batch 707, loss = 1.56782
I0817 10:58:35.295473 14586 caffe.cpp:313] Batch 708, accuracy/top1 = 0.56
I0817 10:58:35.295496 14586 caffe.cpp:313] Batch 708, accuracy/top5 = 0.84
I0817 10:58:35.295500 14586 caffe.cpp:313] Batch 708, loss = 1.56141
I0817 10:58:35.358129 14586 caffe.cpp:313] Batch 709, accuracy/top1 = 0.58
I0817 10:58:35.358152 14586 caffe.cpp:313] Batch 709, accuracy/top5 = 0.82
I0817 10:58:35.358156 14586 caffe.cpp:313] Batch 709, loss = 2.02267
I0817 10:58:35.420898 14586 caffe.cpp:313] Batch 710, accuracy/top1 = 0.58
I0817 10:58:35.420922 14586 caffe.cpp:313] Batch 710, accuracy/top5 = 0.72
I0817 10:58:35.420925 14586 caffe.cpp:313] Batch 710, loss = 2.05953
I0817 10:58:35.483537 14586 caffe.cpp:313] Batch 711, accuracy/top1 = 0.56
I0817 10:58:35.483573 14586 caffe.cpp:313] Batch 711, accuracy/top5 = 0.8
I0817 10:58:35.483577 14586 caffe.cpp:313] Batch 711, loss = 1.89681
I0817 10:58:35.546306 14586 caffe.cpp:313] Batch 712, accuracy/top1 = 0.58
I0817 10:58:35.546329 14586 caffe.cpp:313] Batch 712, accuracy/top5 = 0.78
I0817 10:58:35.546332 14586 caffe.cpp:313] Batch 712, loss = 1.80079
I0817 10:58:35.608928 14586 caffe.cpp:313] Batch 713, accuracy/top1 = 0.46
I0817 10:58:35.608950 14586 caffe.cpp:313] Batch 713, accuracy/top5 = 0.72
I0817 10:58:35.608954 14586 caffe.cpp:313] Batch 713, loss = 2.41707
I0817 10:58:35.671489 14586 caffe.cpp:313] Batch 714, accuracy/top1 = 0.62
I0817 10:58:35.671511 14586 caffe.cpp:313] Batch 714, accuracy/top5 = 0.8
I0817 10:58:35.671515 14586 caffe.cpp:313] Batch 714, loss = 1.63596
I0817 10:58:35.734098 14586 caffe.cpp:313] Batch 715, accuracy/top1 = 0.52
I0817 10:58:35.734120 14586 caffe.cpp:313] Batch 715, accuracy/top5 = 0.84
I0817 10:58:35.734124 14586 caffe.cpp:313] Batch 715, loss = 1.95063
I0817 10:58:35.796849 14586 caffe.cpp:313] Batch 716, accuracy/top1 = 0.6
I0817 10:58:35.796871 14586 caffe.cpp:313] Batch 716, accuracy/top5 = 0.76
I0817 10:58:35.796875 14586 caffe.cpp:313] Batch 716, loss = 2.39696
I0817 10:58:35.860280 14586 caffe.cpp:313] Batch 717, accuracy/top1 = 0.72
I0817 10:58:35.860298 14586 caffe.cpp:313] Batch 717, accuracy/top5 = 0.86
I0817 10:58:35.860301 14586 caffe.cpp:313] Batch 717, loss = 1.44438
I0817 10:58:35.922988 14586 caffe.cpp:313] Batch 718, accuracy/top1 = 0.54
I0817 10:58:35.923012 14586 caffe.cpp:313] Batch 718, accuracy/top5 = 0.72
I0817 10:58:35.923014 14586 caffe.cpp:313] Batch 718, loss = 2.28741
I0817 10:58:35.985618 14586 caffe.cpp:313] Batch 719, accuracy/top1 = 0.62
I0817 10:58:35.985641 14586 caffe.cpp:313] Batch 719, accuracy/top5 = 0.76
I0817 10:58:35.985644 14586 caffe.cpp:313] Batch 719, loss = 1.84618
I0817 10:58:36.048434 14586 caffe.cpp:313] Batch 720, accuracy/top1 = 0.52
I0817 10:58:36.048454 14586 caffe.cpp:313] Batch 720, accuracy/top5 = 0.88
I0817 10:58:36.048456 14586 caffe.cpp:313] Batch 720, loss = 1.7433
I0817 10:58:36.111173 14586 caffe.cpp:313] Batch 721, accuracy/top1 = 0.62
I0817 10:58:36.111196 14586 caffe.cpp:313] Batch 721, accuracy/top5 = 0.82
I0817 10:58:36.111199 14586 caffe.cpp:313] Batch 721, loss = 1.82434
I0817 10:58:36.173805 14586 caffe.cpp:313] Batch 722, accuracy/top1 = 0.6
I0817 10:58:36.173827 14586 caffe.cpp:313] Batch 722, accuracy/top5 = 0.8
I0817 10:58:36.173831 14586 caffe.cpp:313] Batch 722, loss = 1.91808
I0817 10:58:36.236416 14586 caffe.cpp:313] Batch 723, accuracy/top1 = 0.54
I0817 10:58:36.236438 14586 caffe.cpp:313] Batch 723, accuracy/top5 = 0.82
I0817 10:58:36.236440 14586 caffe.cpp:313] Batch 723, loss = 1.78374
I0817 10:58:36.298997 14586 caffe.cpp:313] Batch 724, accuracy/top1 = 0.58
I0817 10:58:36.299019 14586 caffe.cpp:313] Batch 724, accuracy/top5 = 0.92
I0817 10:58:36.299022 14586 caffe.cpp:313] Batch 724, loss = 1.32983
I0817 10:58:36.361708 14586 caffe.cpp:313] Batch 725, accuracy/top1 = 0.64
I0817 10:58:36.361727 14586 caffe.cpp:313] Batch 725, accuracy/top5 = 0.92
I0817 10:58:36.361730 14586 caffe.cpp:313] Batch 725, loss = 1.39994
I0817 10:58:36.424386 14586 caffe.cpp:313] Batch 726, accuracy/top1 = 0.5
I0817 10:58:36.424405 14586 caffe.cpp:313] Batch 726, accuracy/top5 = 0.84
I0817 10:58:36.424407 14586 caffe.cpp:313] Batch 726, loss = 1.80786
I0817 10:58:36.487066 14586 caffe.cpp:313] Batch 727, accuracy/top1 = 0.58
I0817 10:58:36.487087 14586 caffe.cpp:313] Batch 727, accuracy/top5 = 0.84
I0817 10:58:36.487090 14586 caffe.cpp:313] Batch 727, loss = 1.82029
I0817 10:58:36.549607 14586 caffe.cpp:313] Batch 728, accuracy/top1 = 0.64
I0817 10:58:36.549628 14586 caffe.cpp:313] Batch 728, accuracy/top5 = 0.86
I0817 10:58:36.549631 14586 caffe.cpp:313] Batch 728, loss = 1.45874
I0817 10:58:36.612257 14586 caffe.cpp:313] Batch 729, accuracy/top1 = 0.66
I0817 10:58:36.612278 14586 caffe.cpp:313] Batch 729, accuracy/top5 = 0.86
I0817 10:58:36.612282 14586 caffe.cpp:313] Batch 729, loss = 1.32035
I0817 10:58:36.674849 14586 caffe.cpp:313] Batch 730, accuracy/top1 = 0.54
I0817 10:58:36.674871 14586 caffe.cpp:313] Batch 730, accuracy/top5 = 0.78
I0817 10:58:36.674875 14586 caffe.cpp:313] Batch 730, loss = 1.93782
I0817 10:58:36.737627 14586 caffe.cpp:313] Batch 731, accuracy/top1 = 0.48
I0817 10:58:36.737648 14586 caffe.cpp:313] Batch 731, accuracy/top5 = 0.74
I0817 10:58:36.737651 14586 caffe.cpp:313] Batch 731, loss = 2.06352
I0817 10:58:36.800256 14586 caffe.cpp:313] Batch 732, accuracy/top1 = 0.7
I0817 10:58:36.800277 14586 caffe.cpp:313] Batch 732, accuracy/top5 = 0.86
I0817 10:58:36.800281 14586 caffe.cpp:313] Batch 732, loss = 1.43173
I0817 10:58:36.863229 14586 caffe.cpp:313] Batch 733, accuracy/top1 = 0.4
I0817 10:58:36.863246 14586 caffe.cpp:313] Batch 733, accuracy/top5 = 0.78
I0817 10:58:36.863248 14586 caffe.cpp:313] Batch 733, loss = 2.33404
I0817 10:58:36.926017 14586 caffe.cpp:313] Batch 734, accuracy/top1 = 0.56
I0817 10:58:36.926039 14586 caffe.cpp:313] Batch 734, accuracy/top5 = 0.82
I0817 10:58:36.926043 14586 caffe.cpp:313] Batch 734, loss = 1.77074
I0817 10:58:36.988668 14586 caffe.cpp:313] Batch 735, accuracy/top1 = 0.58
I0817 10:58:36.988690 14586 caffe.cpp:313] Batch 735, accuracy/top5 = 0.74
I0817 10:58:36.988693 14586 caffe.cpp:313] Batch 735, loss = 1.95188
I0817 10:58:37.051412 14586 caffe.cpp:313] Batch 736, accuracy/top1 = 0.56
I0817 10:58:37.051429 14586 caffe.cpp:313] Batch 736, accuracy/top5 = 0.84
I0817 10:58:37.051432 14586 caffe.cpp:313] Batch 736, loss = 1.73738
I0817 10:58:37.114156 14586 caffe.cpp:313] Batch 737, accuracy/top1 = 0.62
I0817 10:58:37.114176 14586 caffe.cpp:313] Batch 737, accuracy/top5 = 0.86
I0817 10:58:37.114179 14586 caffe.cpp:313] Batch 737, loss = 1.77975
I0817 10:58:37.176892 14586 caffe.cpp:313] Batch 738, accuracy/top1 = 0.56
I0817 10:58:37.176913 14586 caffe.cpp:313] Batch 738, accuracy/top5 = 0.8
I0817 10:58:37.176915 14586 caffe.cpp:313] Batch 738, loss = 1.61858
I0817 10:58:37.239533 14586 caffe.cpp:313] Batch 739, accuracy/top1 = 0.62
I0817 10:58:37.239554 14586 caffe.cpp:313] Batch 739, accuracy/top5 = 0.86
I0817 10:58:37.239557 14586 caffe.cpp:313] Batch 739, loss = 1.59134
I0817 10:58:37.302109 14586 caffe.cpp:313] Batch 740, accuracy/top1 = 0.62
I0817 10:58:37.302131 14586 caffe.cpp:313] Batch 740, accuracy/top5 = 0.88
I0817 10:58:37.302134 14586 caffe.cpp:313] Batch 740, loss = 1.41245
I0817 10:58:37.364949 14586 caffe.cpp:313] Batch 741, accuracy/top1 = 0.66
I0817 10:58:37.364970 14586 caffe.cpp:313] Batch 741, accuracy/top5 = 0.86
I0817 10:58:37.364974 14586 caffe.cpp:313] Batch 741, loss = 1.53687
I0817 10:58:37.427758 14586 caffe.cpp:313] Batch 742, accuracy/top1 = 0.62
I0817 10:58:37.427780 14586 caffe.cpp:313] Batch 742, accuracy/top5 = 0.82
I0817 10:58:37.427783 14586 caffe.cpp:313] Batch 742, loss = 1.6981
I0817 10:58:37.490453 14586 caffe.cpp:313] Batch 743, accuracy/top1 = 0.56
I0817 10:58:37.490473 14586 caffe.cpp:313] Batch 743, accuracy/top5 = 0.84
I0817 10:58:37.490476 14586 caffe.cpp:313] Batch 743, loss = 1.95818
I0817 10:58:37.553176 14586 caffe.cpp:313] Batch 744, accuracy/top1 = 0.56
I0817 10:58:37.553198 14586 caffe.cpp:313] Batch 744, accuracy/top5 = 0.82
I0817 10:58:37.553201 14586 caffe.cpp:313] Batch 744, loss = 1.94269
I0817 10:58:37.615905 14586 caffe.cpp:313] Batch 745, accuracy/top1 = 0.66
I0817 10:58:37.615926 14586 caffe.cpp:313] Batch 745, accuracy/top5 = 0.88
I0817 10:58:37.615929 14586 caffe.cpp:313] Batch 745, loss = 1.40155
I0817 10:58:37.678719 14586 caffe.cpp:313] Batch 746, accuracy/top1 = 0.62
I0817 10:58:37.678741 14586 caffe.cpp:313] Batch 746, accuracy/top5 = 0.82
I0817 10:58:37.678745 14586 caffe.cpp:313] Batch 746, loss = 1.67903
I0817 10:58:37.741510 14586 caffe.cpp:313] Batch 747, accuracy/top1 = 0.58
I0817 10:58:37.741533 14586 caffe.cpp:313] Batch 747, accuracy/top5 = 0.82
I0817 10:58:37.741535 14586 caffe.cpp:313] Batch 747, loss = 1.68471
I0817 10:58:37.804234 14586 caffe.cpp:313] Batch 748, accuracy/top1 = 0.64
I0817 10:58:37.804256 14586 caffe.cpp:313] Batch 748, accuracy/top5 = 0.84
I0817 10:58:37.804273 14586 caffe.cpp:313] Batch 748, loss = 1.47584
I0817 10:58:37.867982 14586 caffe.cpp:313] Batch 749, accuracy/top1 = 0.62
I0817 10:58:37.868000 14586 caffe.cpp:313] Batch 749, accuracy/top5 = 0.86
I0817 10:58:37.868003 14586 caffe.cpp:313] Batch 749, loss = 1.32803
I0817 10:58:37.930815 14586 caffe.cpp:313] Batch 750, accuracy/top1 = 0.68
I0817 10:58:37.930837 14586 caffe.cpp:313] Batch 750, accuracy/top5 = 0.82
I0817 10:58:37.930840 14586 caffe.cpp:313] Batch 750, loss = 1.5588
I0817 10:58:37.993475 14586 caffe.cpp:313] Batch 751, accuracy/top1 = 0.58
I0817 10:58:37.993497 14586 caffe.cpp:313] Batch 751, accuracy/top5 = 0.84
I0817 10:58:37.993500 14586 caffe.cpp:313] Batch 751, loss = 1.72654
I0817 10:58:38.056068 14586 caffe.cpp:313] Batch 752, accuracy/top1 = 0.68
I0817 10:58:38.056087 14586 caffe.cpp:313] Batch 752, accuracy/top5 = 0.88
I0817 10:58:38.056089 14586 caffe.cpp:313] Batch 752, loss = 1.22801
I0817 10:58:38.118717 14586 caffe.cpp:313] Batch 753, accuracy/top1 = 0.5
I0817 10:58:38.118738 14586 caffe.cpp:313] Batch 753, accuracy/top5 = 0.78
I0817 10:58:38.118742 14586 caffe.cpp:313] Batch 753, loss = 2.15249
I0817 10:58:38.181429 14586 caffe.cpp:313] Batch 754, accuracy/top1 = 0.52
I0817 10:58:38.181452 14586 caffe.cpp:313] Batch 754, accuracy/top5 = 0.78
I0817 10:58:38.181454 14586 caffe.cpp:313] Batch 754, loss = 1.97909
I0817 10:58:38.244211 14586 caffe.cpp:313] Batch 755, accuracy/top1 = 0.5
I0817 10:58:38.244232 14586 caffe.cpp:313] Batch 755, accuracy/top5 = 0.76
I0817 10:58:38.244235 14586 caffe.cpp:313] Batch 755, loss = 2.28008
I0817 10:58:38.306962 14586 caffe.cpp:313] Batch 756, accuracy/top1 = 0.66
I0817 10:58:38.306982 14586 caffe.cpp:313] Batch 756, accuracy/top5 = 0.86
I0817 10:58:38.306985 14586 caffe.cpp:313] Batch 756, loss = 1.53873
I0817 10:58:38.369616 14586 caffe.cpp:313] Batch 757, accuracy/top1 = 0.6
I0817 10:58:38.369637 14586 caffe.cpp:313] Batch 757, accuracy/top5 = 0.82
I0817 10:58:38.369640 14586 caffe.cpp:313] Batch 757, loss = 1.44468
I0817 10:58:38.432132 14586 caffe.cpp:313] Batch 758, accuracy/top1 = 0.68
I0817 10:58:38.432153 14586 caffe.cpp:313] Batch 758, accuracy/top5 = 0.88
I0817 10:58:38.432157 14586 caffe.cpp:313] Batch 758, loss = 1.30009
I0817 10:58:38.494843 14586 caffe.cpp:313] Batch 759, accuracy/top1 = 0.62
I0817 10:58:38.494863 14586 caffe.cpp:313] Batch 759, accuracy/top5 = 0.82
I0817 10:58:38.494865 14586 caffe.cpp:313] Batch 759, loss = 1.77723
I0817 10:58:38.557835 14586 caffe.cpp:313] Batch 760, accuracy/top1 = 0.62
I0817 10:58:38.557854 14586 caffe.cpp:313] Batch 760, accuracy/top5 = 0.86
I0817 10:58:38.557857 14586 caffe.cpp:313] Batch 760, loss = 1.56792
I0817 10:58:38.620633 14586 caffe.cpp:313] Batch 761, accuracy/top1 = 0.68
I0817 10:58:38.620656 14586 caffe.cpp:313] Batch 761, accuracy/top5 = 0.86
I0817 10:58:38.620658 14586 caffe.cpp:313] Batch 761, loss = 1.66181
I0817 10:58:38.683267 14586 caffe.cpp:313] Batch 762, accuracy/top1 = 0.56
I0817 10:58:38.683290 14586 caffe.cpp:313] Batch 762, accuracy/top5 = 0.76
I0817 10:58:38.683292 14586 caffe.cpp:313] Batch 762, loss = 1.85766
I0817 10:58:38.746099 14586 caffe.cpp:313] Batch 763, accuracy/top1 = 0.58
I0817 10:58:38.746121 14586 caffe.cpp:313] Batch 763, accuracy/top5 = 0.82
I0817 10:58:38.746124 14586 caffe.cpp:313] Batch 763, loss = 1.64492
I0817 10:58:38.808974 14586 caffe.cpp:313] Batch 764, accuracy/top1 = 0.44
I0817 10:58:38.808995 14586 caffe.cpp:313] Batch 764, accuracy/top5 = 0.7
I0817 10:58:38.808998 14586 caffe.cpp:313] Batch 764, loss = 2.40351
I0817 10:58:38.872370 14586 caffe.cpp:313] Batch 765, accuracy/top1 = 0.64
I0817 10:58:38.872387 14586 caffe.cpp:313] Batch 765, accuracy/top5 = 0.88
I0817 10:58:38.872390 14586 caffe.cpp:313] Batch 765, loss = 1.55334
I0817 10:58:38.934903 14586 caffe.cpp:313] Batch 766, accuracy/top1 = 0.52
I0817 10:58:38.934926 14586 caffe.cpp:313] Batch 766, accuracy/top5 = 0.84
I0817 10:58:38.934928 14586 caffe.cpp:313] Batch 766, loss = 1.78284
I0817 10:58:38.997715 14586 caffe.cpp:313] Batch 767, accuracy/top1 = 0.6
I0817 10:58:38.997750 14586 caffe.cpp:313] Batch 767, accuracy/top5 = 0.82
I0817 10:58:38.997753 14586 caffe.cpp:313] Batch 767, loss = 1.75103
I0817 10:58:39.060493 14586 caffe.cpp:313] Batch 768, accuracy/top1 = 0.6
I0817 10:58:39.060514 14586 caffe.cpp:313] Batch 768, accuracy/top5 = 0.84
I0817 10:58:39.060518 14586 caffe.cpp:313] Batch 768, loss = 1.60283
I0817 10:58:39.123199 14586 caffe.cpp:313] Batch 769, accuracy/top1 = 0.62
I0817 10:58:39.123221 14586 caffe.cpp:313] Batch 769, accuracy/top5 = 0.84
I0817 10:58:39.123224 14586 caffe.cpp:313] Batch 769, loss = 1.48714
I0817 10:58:39.185971 14586 caffe.cpp:313] Batch 770, accuracy/top1 = 0.58
I0817 10:58:39.185992 14586 caffe.cpp:313] Batch 770, accuracy/top5 = 0.86
I0817 10:58:39.185995 14586 caffe.cpp:313] Batch 770, loss = 1.74671
I0817 10:58:39.248596 14586 caffe.cpp:313] Batch 771, accuracy/top1 = 0.6
I0817 10:58:39.248615 14586 caffe.cpp:313] Batch 771, accuracy/top5 = 0.78
I0817 10:58:39.248617 14586 caffe.cpp:313] Batch 771, loss = 2.28951
I0817 10:58:39.311271 14586 caffe.cpp:313] Batch 772, accuracy/top1 = 0.56
I0817 10:58:39.311292 14586 caffe.cpp:313] Batch 772, accuracy/top5 = 0.76
I0817 10:58:39.311295 14586 caffe.cpp:313] Batch 772, loss = 2.06076
I0817 10:58:39.373922 14586 caffe.cpp:313] Batch 773, accuracy/top1 = 0.46
I0817 10:58:39.373944 14586 caffe.cpp:313] Batch 773, accuracy/top5 = 0.8
I0817 10:58:39.373947 14586 caffe.cpp:313] Batch 773, loss = 2.33917
I0817 10:58:39.436561 14586 caffe.cpp:313] Batch 774, accuracy/top1 = 0.56
I0817 10:58:39.436583 14586 caffe.cpp:313] Batch 774, accuracy/top5 = 0.82
I0817 10:58:39.436585 14586 caffe.cpp:313] Batch 774, loss = 1.68879
I0817 10:58:39.499253 14586 caffe.cpp:313] Batch 775, accuracy/top1 = 0.56
I0817 10:58:39.499274 14586 caffe.cpp:313] Batch 775, accuracy/top5 = 0.76
I0817 10:58:39.499277 14586 caffe.cpp:313] Batch 775, loss = 1.76727
I0817 10:58:39.561959 14586 caffe.cpp:313] Batch 776, accuracy/top1 = 0.66
I0817 10:58:39.561980 14586 caffe.cpp:313] Batch 776, accuracy/top5 = 0.8
I0817 10:58:39.561982 14586 caffe.cpp:313] Batch 776, loss = 2.09092
I0817 10:58:39.624636 14586 caffe.cpp:313] Batch 777, accuracy/top1 = 0.52
I0817 10:58:39.624658 14586 caffe.cpp:313] Batch 777, accuracy/top5 = 0.8
I0817 10:58:39.624661 14586 caffe.cpp:313] Batch 777, loss = 1.87309
I0817 10:58:39.687355 14586 caffe.cpp:313] Batch 778, accuracy/top1 = 0.58
I0817 10:58:39.687377 14586 caffe.cpp:313] Batch 778, accuracy/top5 = 0.82
I0817 10:58:39.687381 14586 caffe.cpp:313] Batch 778, loss = 1.51792
I0817 10:58:39.750064 14586 caffe.cpp:313] Batch 779, accuracy/top1 = 0.58
I0817 10:58:39.750085 14586 caffe.cpp:313] Batch 779, accuracy/top5 = 0.78
I0817 10:58:39.750088 14586 caffe.cpp:313] Batch 779, loss = 1.94992
I0817 10:58:39.812793 14586 caffe.cpp:313] Batch 780, accuracy/top1 = 0.54
I0817 10:58:39.812813 14586 caffe.cpp:313] Batch 780, accuracy/top5 = 0.84
I0817 10:58:39.812816 14586 caffe.cpp:313] Batch 780, loss = 1.67008
I0817 10:58:39.876080 14586 caffe.cpp:313] Batch 781, accuracy/top1 = 0.62
I0817 10:58:39.876096 14586 caffe.cpp:313] Batch 781, accuracy/top5 = 0.86
I0817 10:58:39.876099 14586 caffe.cpp:313] Batch 781, loss = 1.4312
I0817 10:58:39.938732 14586 caffe.cpp:313] Batch 782, accuracy/top1 = 0.74
I0817 10:58:39.938753 14586 caffe.cpp:313] Batch 782, accuracy/top5 = 0.9
I0817 10:58:39.938756 14586 caffe.cpp:313] Batch 782, loss = 1.21415
I0817 10:58:40.001271 14586 caffe.cpp:313] Batch 783, accuracy/top1 = 0.6
I0817 10:58:40.001292 14586 caffe.cpp:313] Batch 783, accuracy/top5 = 0.84
I0817 10:58:40.001294 14586 caffe.cpp:313] Batch 783, loss = 1.60974
I0817 10:58:40.063990 14586 caffe.cpp:313] Batch 784, accuracy/top1 = 0.68
I0817 10:58:40.064009 14586 caffe.cpp:313] Batch 784, accuracy/top5 = 0.82
I0817 10:58:40.064013 14586 caffe.cpp:313] Batch 784, loss = 1.40279
I0817 10:58:40.126710 14586 caffe.cpp:313] Batch 785, accuracy/top1 = 0.6
I0817 10:58:40.126731 14586 caffe.cpp:313] Batch 785, accuracy/top5 = 0.82
I0817 10:58:40.126734 14586 caffe.cpp:313] Batch 785, loss = 1.95804
I0817 10:58:40.189422 14586 caffe.cpp:313] Batch 786, accuracy/top1 = 0.66
I0817 10:58:40.189445 14586 caffe.cpp:313] Batch 786, accuracy/top5 = 0.9
I0817 10:58:40.189447 14586 caffe.cpp:313] Batch 786, loss = 1.00867
I0817 10:58:40.252086 14586 caffe.cpp:313] Batch 787, accuracy/top1 = 0.52
I0817 10:58:40.252107 14586 caffe.cpp:313] Batch 787, accuracy/top5 = 0.88
I0817 10:58:40.252110 14586 caffe.cpp:313] Batch 787, loss = 1.58464
I0817 10:58:40.314919 14586 caffe.cpp:313] Batch 788, accuracy/top1 = 0.52
I0817 10:58:40.314939 14586 caffe.cpp:313] Batch 788, accuracy/top5 = 0.78
I0817 10:58:40.314942 14586 caffe.cpp:313] Batch 788, loss = 2.04148
I0817 10:58:40.377701 14586 caffe.cpp:313] Batch 789, accuracy/top1 = 0.64
I0817 10:58:40.377722 14586 caffe.cpp:313] Batch 789, accuracy/top5 = 0.84
I0817 10:58:40.377724 14586 caffe.cpp:313] Batch 789, loss = 1.48646
I0817 10:58:40.440316 14586 caffe.cpp:313] Batch 790, accuracy/top1 = 0.52
I0817 10:58:40.440337 14586 caffe.cpp:313] Batch 790, accuracy/top5 = 0.88
I0817 10:58:40.440340 14586 caffe.cpp:313] Batch 790, loss = 1.63673
I0817 10:58:40.502813 14586 caffe.cpp:313] Batch 791, accuracy/top1 = 0.44
I0817 10:58:40.502835 14586 caffe.cpp:313] Batch 791, accuracy/top5 = 0.74
I0817 10:58:40.502837 14586 caffe.cpp:313] Batch 791, loss = 2.25794
I0817 10:58:40.565407 14586 caffe.cpp:313] Batch 792, accuracy/top1 = 0.46
I0817 10:58:40.565429 14586 caffe.cpp:313] Batch 792, accuracy/top5 = 0.76
I0817 10:58:40.565433 14586 caffe.cpp:313] Batch 792, loss = 1.96168
I0817 10:58:40.628216 14586 caffe.cpp:313] Batch 793, accuracy/top1 = 0.6
I0817 10:58:40.628234 14586 caffe.cpp:313] Batch 793, accuracy/top5 = 0.8
I0817 10:58:40.628237 14586 caffe.cpp:313] Batch 793, loss = 1.78906
I0817 10:58:40.691076 14586 caffe.cpp:313] Batch 794, accuracy/top1 = 0.64
I0817 10:58:40.691094 14586 caffe.cpp:313] Batch 794, accuracy/top5 = 0.82
I0817 10:58:40.691097 14586 caffe.cpp:313] Batch 794, loss = 1.64781
I0817 10:58:40.753962 14586 caffe.cpp:313] Batch 795, accuracy/top1 = 0.54
I0817 10:58:40.753983 14586 caffe.cpp:313] Batch 795, accuracy/top5 = 0.8
I0817 10:58:40.753988 14586 caffe.cpp:313] Batch 795, loss = 2.00018
I0817 10:58:40.816628 14586 caffe.cpp:313] Batch 796, accuracy/top1 = 0.6
I0817 10:58:40.816649 14586 caffe.cpp:313] Batch 796, accuracy/top5 = 0.76
I0817 10:58:40.816653 14586 caffe.cpp:313] Batch 796, loss = 1.92911
I0817 10:58:40.879614 14586 caffe.cpp:313] Batch 797, accuracy/top1 = 0.56
I0817 10:58:40.879632 14586 caffe.cpp:313] Batch 797, accuracy/top5 = 0.76
I0817 10:58:40.879636 14586 caffe.cpp:313] Batch 797, loss = 2.01042
I0817 10:58:40.942401 14586 caffe.cpp:313] Batch 798, accuracy/top1 = 0.6
I0817 10:58:40.942425 14586 caffe.cpp:313] Batch 798, accuracy/top5 = 0.88
I0817 10:58:40.942427 14586 caffe.cpp:313] Batch 798, loss = 1.46247
I0817 10:58:41.005172 14586 caffe.cpp:313] Batch 799, accuracy/top1 = 0.66
I0817 10:58:41.005192 14586 caffe.cpp:313] Batch 799, accuracy/top5 = 0.86
I0817 10:58:41.005194 14586 caffe.cpp:313] Batch 799, loss = 1.66679
I0817 10:58:41.067719 14586 caffe.cpp:313] Batch 800, accuracy/top1 = 0.48
I0817 10:58:41.067741 14586 caffe.cpp:313] Batch 800, accuracy/top5 = 0.64
I0817 10:58:41.067744 14586 caffe.cpp:313] Batch 800, loss = 2.87637
I0817 10:58:41.130331 14586 caffe.cpp:313] Batch 801, accuracy/top1 = 0.62
I0817 10:58:41.130352 14586 caffe.cpp:313] Batch 801, accuracy/top5 = 0.82
I0817 10:58:41.130354 14586 caffe.cpp:313] Batch 801, loss = 1.7373
I0817 10:58:41.192960 14586 caffe.cpp:313] Batch 802, accuracy/top1 = 0.58
I0817 10:58:41.192981 14586 caffe.cpp:313] Batch 802, accuracy/top5 = 0.86
I0817 10:58:41.192983 14586 caffe.cpp:313] Batch 802, loss = 1.71056
I0817 10:58:41.255686 14586 caffe.cpp:313] Batch 803, accuracy/top1 = 0.64
I0817 10:58:41.255702 14586 caffe.cpp:313] Batch 803, accuracy/top5 = 0.8
I0817 10:58:41.255704 14586 caffe.cpp:313] Batch 803, loss = 1.66887
I0817 10:58:41.318433 14586 caffe.cpp:313] Batch 804, accuracy/top1 = 0.58
I0817 10:58:41.318454 14586 caffe.cpp:313] Batch 804, accuracy/top5 = 0.92
I0817 10:58:41.318457 14586 caffe.cpp:313] Batch 804, loss = 1.56513
I0817 10:58:41.381108 14586 caffe.cpp:313] Batch 805, accuracy/top1 = 0.68
I0817 10:58:41.381129 14586 caffe.cpp:313] Batch 805, accuracy/top5 = 0.84
I0817 10:58:41.381132 14586 caffe.cpp:313] Batch 805, loss = 1.74349
I0817 10:58:41.443668 14586 caffe.cpp:313] Batch 806, accuracy/top1 = 0.7
I0817 10:58:41.443689 14586 caffe.cpp:313] Batch 806, accuracy/top5 = 0.88
I0817 10:58:41.443692 14586 caffe.cpp:313] Batch 806, loss = 1.17083
I0817 10:58:41.506248 14586 caffe.cpp:313] Batch 807, accuracy/top1 = 0.56
I0817 10:58:41.506269 14586 caffe.cpp:313] Batch 807, accuracy/top5 = 0.86
I0817 10:58:41.506273 14586 caffe.cpp:313] Batch 807, loss = 1.97135
I0817 10:58:41.568920 14586 caffe.cpp:313] Batch 808, accuracy/top1 = 0.58
I0817 10:58:41.568941 14586 caffe.cpp:313] Batch 808, accuracy/top5 = 0.8
I0817 10:58:41.568944 14586 caffe.cpp:313] Batch 808, loss = 1.84357
I0817 10:58:41.631708 14586 caffe.cpp:313] Batch 809, accuracy/top1 = 0.48
I0817 10:58:41.631728 14586 caffe.cpp:313] Batch 809, accuracy/top5 = 0.72
I0817 10:58:41.631731 14586 caffe.cpp:313] Batch 809, loss = 2.45596
I0817 10:58:41.694553 14586 caffe.cpp:313] Batch 810, accuracy/top1 = 0.54
I0817 10:58:41.694576 14586 caffe.cpp:313] Batch 810, accuracy/top5 = 0.8
I0817 10:58:41.694578 14586 caffe.cpp:313] Batch 810, loss = 1.82238
I0817 10:58:41.757308 14586 caffe.cpp:313] Batch 811, accuracy/top1 = 0.6
I0817 10:58:41.757329 14586 caffe.cpp:313] Batch 811, accuracy/top5 = 0.82
I0817 10:58:41.757333 14586 caffe.cpp:313] Batch 811, loss = 2.11941
I0817 10:58:41.820086 14586 caffe.cpp:313] Batch 812, accuracy/top1 = 0.5
I0817 10:58:41.820107 14586 caffe.cpp:313] Batch 812, accuracy/top5 = 0.84
I0817 10:58:41.820111 14586 caffe.cpp:313] Batch 812, loss = 1.79512
I0817 10:58:41.883083 14586 caffe.cpp:313] Batch 813, accuracy/top1 = 0.52
I0817 10:58:41.883100 14586 caffe.cpp:313] Batch 813, accuracy/top5 = 0.78
I0817 10:58:41.883103 14586 caffe.cpp:313] Batch 813, loss = 1.96475
I0817 10:58:41.945804 14586 caffe.cpp:313] Batch 814, accuracy/top1 = 0.4
I0817 10:58:41.945827 14586 caffe.cpp:313] Batch 814, accuracy/top5 = 0.7
I0817 10:58:41.945830 14586 caffe.cpp:313] Batch 814, loss = 2.66598
I0817 10:58:42.008394 14586 caffe.cpp:313] Batch 815, accuracy/top1 = 0.54
I0817 10:58:42.008414 14586 caffe.cpp:313] Batch 815, accuracy/top5 = 0.9
I0817 10:58:42.008416 14586 caffe.cpp:313] Batch 815, loss = 1.38848
I0817 10:58:42.071030 14586 caffe.cpp:313] Batch 816, accuracy/top1 = 0.5
I0817 10:58:42.071051 14586 caffe.cpp:313] Batch 816, accuracy/top5 = 0.78
I0817 10:58:42.071054 14586 caffe.cpp:313] Batch 816, loss = 2.16032
I0817 10:58:42.133625 14586 caffe.cpp:313] Batch 817, accuracy/top1 = 0.62
I0817 10:58:42.133646 14586 caffe.cpp:313] Batch 817, accuracy/top5 = 0.86
I0817 10:58:42.133649 14586 caffe.cpp:313] Batch 817, loss = 1.68779
I0817 10:58:42.196419 14586 caffe.cpp:313] Batch 818, accuracy/top1 = 0.62
I0817 10:58:42.196440 14586 caffe.cpp:313] Batch 818, accuracy/top5 = 0.86
I0817 10:58:42.196444 14586 caffe.cpp:313] Batch 818, loss = 1.51624
I0817 10:58:42.259188 14586 caffe.cpp:313] Batch 819, accuracy/top1 = 0.72
I0817 10:58:42.259210 14586 caffe.cpp:313] Batch 819, accuracy/top5 = 0.82
I0817 10:58:42.259213 14586 caffe.cpp:313] Batch 819, loss = 1.55178
I0817 10:58:42.321784 14586 caffe.cpp:313] Batch 820, accuracy/top1 = 0.58
I0817 10:58:42.321805 14586 caffe.cpp:313] Batch 820, accuracy/top5 = 0.78
I0817 10:58:42.321808 14586 caffe.cpp:313] Batch 820, loss = 1.81725
I0817 10:58:42.384495 14586 caffe.cpp:313] Batch 821, accuracy/top1 = 0.56
I0817 10:58:42.384516 14586 caffe.cpp:313] Batch 821, accuracy/top5 = 0.82
I0817 10:58:42.384518 14586 caffe.cpp:313] Batch 821, loss = 1.80179
I0817 10:58:42.447262 14586 caffe.cpp:313] Batch 822, accuracy/top1 = 0.52
I0817 10:58:42.447283 14586 caffe.cpp:313] Batch 822, accuracy/top5 = 0.8
I0817 10:58:42.447286 14586 caffe.cpp:313] Batch 822, loss = 2.01632
I0817 10:58:42.509935 14586 caffe.cpp:313] Batch 823, accuracy/top1 = 0.62
I0817 10:58:42.509956 14586 caffe.cpp:313] Batch 823, accuracy/top5 = 0.9
I0817 10:58:42.509974 14586 caffe.cpp:313] Batch 823, loss = 1.45962
I0817 10:58:42.572744 14586 caffe.cpp:313] Batch 824, accuracy/top1 = 0.62
I0817 10:58:42.572765 14586 caffe.cpp:313] Batch 824, accuracy/top5 = 0.78
I0817 10:58:42.572768 14586 caffe.cpp:313] Batch 824, loss = 1.87111
I0817 10:58:42.635365 14586 caffe.cpp:313] Batch 825, accuracy/top1 = 0.68
I0817 10:58:42.635385 14586 caffe.cpp:313] Batch 825, accuracy/top5 = 0.84
I0817 10:58:42.635388 14586 caffe.cpp:313] Batch 825, loss = 1.46443
I0817 10:58:42.698168 14586 caffe.cpp:313] Batch 826, accuracy/top1 = 0.56
I0817 10:58:42.698191 14586 caffe.cpp:313] Batch 826, accuracy/top5 = 0.84
I0817 10:58:42.698194 14586 caffe.cpp:313] Batch 826, loss = 1.73309
I0817 10:58:42.761010 14586 caffe.cpp:313] Batch 827, accuracy/top1 = 0.66
I0817 10:58:42.761030 14586 caffe.cpp:313] Batch 827, accuracy/top5 = 0.92
I0817 10:58:42.761032 14586 caffe.cpp:313] Batch 827, loss = 1.29515
I0817 10:58:42.823928 14586 caffe.cpp:313] Batch 828, accuracy/top1 = 0.54
I0817 10:58:42.823948 14586 caffe.cpp:313] Batch 828, accuracy/top5 = 0.74
I0817 10:58:42.823951 14586 caffe.cpp:313] Batch 828, loss = 2.06656
I0817 10:58:42.886934 14586 caffe.cpp:313] Batch 829, accuracy/top1 = 0.52
I0817 10:58:42.886955 14586 caffe.cpp:313] Batch 829, accuracy/top5 = 0.76
I0817 10:58:42.886957 14586 caffe.cpp:313] Batch 829, loss = 2.56524
I0817 10:58:42.949690 14586 caffe.cpp:313] Batch 830, accuracy/top1 = 0.68
I0817 10:58:42.949713 14586 caffe.cpp:313] Batch 830, accuracy/top5 = 0.84
I0817 10:58:42.949717 14586 caffe.cpp:313] Batch 830, loss = 1.49087
I0817 10:58:43.012537 14586 caffe.cpp:313] Batch 831, accuracy/top1 = 0.6
I0817 10:58:43.012557 14586 caffe.cpp:313] Batch 831, accuracy/top5 = 0.86
I0817 10:58:43.012560 14586 caffe.cpp:313] Batch 831, loss = 1.60146
I0817 10:58:43.075242 14586 caffe.cpp:313] Batch 832, accuracy/top1 = 0.44
I0817 10:58:43.075263 14586 caffe.cpp:313] Batch 832, accuracy/top5 = 0.72
I0817 10:58:43.075266 14586 caffe.cpp:313] Batch 832, loss = 2.21319
I0817 10:58:43.137991 14586 caffe.cpp:313] Batch 833, accuracy/top1 = 0.62
I0817 10:58:43.138012 14586 caffe.cpp:313] Batch 833, accuracy/top5 = 0.82
I0817 10:58:43.138015 14586 caffe.cpp:313] Batch 833, loss = 1.66249
I0817 10:58:43.200850 14586 caffe.cpp:313] Batch 834, accuracy/top1 = 0.62
I0817 10:58:43.200871 14586 caffe.cpp:313] Batch 834, accuracy/top5 = 0.8
I0817 10:58:43.200875 14586 caffe.cpp:313] Batch 834, loss = 2.0657
I0817 10:58:43.263762 14586 caffe.cpp:313] Batch 835, accuracy/top1 = 0.58
I0817 10:58:43.263778 14586 caffe.cpp:313] Batch 835, accuracy/top5 = 0.8
I0817 10:58:43.263782 14586 caffe.cpp:313] Batch 835, loss = 2.01355
I0817 10:58:43.326638 14586 caffe.cpp:313] Batch 836, accuracy/top1 = 0.66
I0817 10:58:43.326659 14586 caffe.cpp:313] Batch 836, accuracy/top5 = 0.84
I0817 10:58:43.326663 14586 caffe.cpp:313] Batch 836, loss = 1.48448
I0817 10:58:43.389466 14586 caffe.cpp:313] Batch 837, accuracy/top1 = 0.6
I0817 10:58:43.389487 14586 caffe.cpp:313] Batch 837, accuracy/top5 = 0.8
I0817 10:58:43.389489 14586 caffe.cpp:313] Batch 837, loss = 1.51126
I0817 10:58:43.452255 14586 caffe.cpp:313] Batch 838, accuracy/top1 = 0.48
I0817 10:58:43.452275 14586 caffe.cpp:313] Batch 838, accuracy/top5 = 0.82
I0817 10:58:43.452278 14586 caffe.cpp:313] Batch 838, loss = 1.8193
I0817 10:58:43.515120 14586 caffe.cpp:313] Batch 839, accuracy/top1 = 0.6
I0817 10:58:43.515141 14586 caffe.cpp:313] Batch 839, accuracy/top5 = 0.78
I0817 10:58:43.515143 14586 caffe.cpp:313] Batch 839, loss = 1.81161
I0817 10:58:43.577992 14586 caffe.cpp:313] Batch 840, accuracy/top1 = 0.56
I0817 10:58:43.578014 14586 caffe.cpp:313] Batch 840, accuracy/top5 = 0.76
I0817 10:58:43.578017 14586 caffe.cpp:313] Batch 840, loss = 2.00253
I0817 10:58:43.640707 14586 caffe.cpp:313] Batch 841, accuracy/top1 = 0.54
I0817 10:58:43.640728 14586 caffe.cpp:313] Batch 841, accuracy/top5 = 0.78
I0817 10:58:43.640732 14586 caffe.cpp:313] Batch 841, loss = 1.92266
I0817 10:58:43.703356 14586 caffe.cpp:313] Batch 842, accuracy/top1 = 0.6
I0817 10:58:43.703392 14586 caffe.cpp:313] Batch 842, accuracy/top5 = 0.86
I0817 10:58:43.703395 14586 caffe.cpp:313] Batch 842, loss = 1.54264
I0817 10:58:43.766037 14586 caffe.cpp:313] Batch 843, accuracy/top1 = 0.5
I0817 10:58:43.766059 14586 caffe.cpp:313] Batch 843, accuracy/top5 = 0.86
I0817 10:58:43.766062 14586 caffe.cpp:313] Batch 843, loss = 1.83261
I0817 10:58:43.828920 14586 caffe.cpp:313] Batch 844, accuracy/top1 = 0.62
I0817 10:58:43.828943 14586 caffe.cpp:313] Batch 844, accuracy/top5 = 0.86
I0817 10:58:43.828944 14586 caffe.cpp:313] Batch 844, loss = 1.5894
I0817 10:58:43.891877 14586 caffe.cpp:313] Batch 845, accuracy/top1 = 0.6
I0817 10:58:43.891898 14586 caffe.cpp:313] Batch 845, accuracy/top5 = 0.76
I0817 10:58:43.891901 14586 caffe.cpp:313] Batch 845, loss = 1.93434
I0817 10:58:43.954632 14586 caffe.cpp:313] Batch 846, accuracy/top1 = 0.54
I0817 10:58:43.954654 14586 caffe.cpp:313] Batch 846, accuracy/top5 = 0.82
I0817 10:58:43.954658 14586 caffe.cpp:313] Batch 846, loss = 1.77095
I0817 10:58:44.017315 14586 caffe.cpp:313] Batch 847, accuracy/top1 = 0.54
I0817 10:58:44.017338 14586 caffe.cpp:313] Batch 847, accuracy/top5 = 0.7
I0817 10:58:44.017340 14586 caffe.cpp:313] Batch 847, loss = 2.21639
I0817 10:58:44.080147 14586 caffe.cpp:313] Batch 848, accuracy/top1 = 0.58
I0817 10:58:44.080168 14586 caffe.cpp:313] Batch 848, accuracy/top5 = 0.84
I0817 10:58:44.080171 14586 caffe.cpp:313] Batch 848, loss = 1.74887
I0817 10:58:44.143007 14586 caffe.cpp:313] Batch 849, accuracy/top1 = 0.62
I0817 10:58:44.143029 14586 caffe.cpp:313] Batch 849, accuracy/top5 = 0.9
I0817 10:58:44.143033 14586 caffe.cpp:313] Batch 849, loss = 1.55699
I0817 10:58:44.205756 14586 caffe.cpp:313] Batch 850, accuracy/top1 = 0.6
I0817 10:58:44.205778 14586 caffe.cpp:313] Batch 850, accuracy/top5 = 0.82
I0817 10:58:44.205781 14586 caffe.cpp:313] Batch 850, loss = 1.7837
I0817 10:58:44.268467 14586 caffe.cpp:313] Batch 851, accuracy/top1 = 0.54
I0817 10:58:44.268491 14586 caffe.cpp:313] Batch 851, accuracy/top5 = 0.82
I0817 10:58:44.268493 14586 caffe.cpp:313] Batch 851, loss = 2.04098
I0817 10:58:44.331233 14586 caffe.cpp:313] Batch 852, accuracy/top1 = 0.54
I0817 10:58:44.331255 14586 caffe.cpp:313] Batch 852, accuracy/top5 = 0.78
I0817 10:58:44.331259 14586 caffe.cpp:313] Batch 852, loss = 2.03534
I0817 10:58:44.393941 14586 caffe.cpp:313] Batch 853, accuracy/top1 = 0.7
I0817 10:58:44.393962 14586 caffe.cpp:313] Batch 853, accuracy/top5 = 0.86
I0817 10:58:44.393965 14586 caffe.cpp:313] Batch 853, loss = 1.37425
I0817 10:58:44.456670 14586 caffe.cpp:313] Batch 854, accuracy/top1 = 0.66
I0817 10:58:44.456692 14586 caffe.cpp:313] Batch 854, accuracy/top5 = 0.82
I0817 10:58:44.456696 14586 caffe.cpp:313] Batch 854, loss = 1.58463
I0817 10:58:44.519395 14586 caffe.cpp:313] Batch 855, accuracy/top1 = 0.44
I0817 10:58:44.519417 14586 caffe.cpp:313] Batch 855, accuracy/top5 = 0.74
I0817 10:58:44.519419 14586 caffe.cpp:313] Batch 855, loss = 2.28102
I0817 10:58:44.582165 14586 caffe.cpp:313] Batch 856, accuracy/top1 = 0.5
I0817 10:58:44.582186 14586 caffe.cpp:313] Batch 856, accuracy/top5 = 0.8
I0817 10:58:44.582190 14586 caffe.cpp:313] Batch 856, loss = 2.01556
I0817 10:58:44.645056 14586 caffe.cpp:313] Batch 857, accuracy/top1 = 0.68
I0817 10:58:44.645078 14586 caffe.cpp:313] Batch 857, accuracy/top5 = 0.88
I0817 10:58:44.645081 14586 caffe.cpp:313] Batch 857, loss = 1.36542
I0817 10:58:44.707851 14586 caffe.cpp:313] Batch 858, accuracy/top1 = 0.56
I0817 10:58:44.707873 14586 caffe.cpp:313] Batch 858, accuracy/top5 = 0.9
I0817 10:58:44.707876 14586 caffe.cpp:313] Batch 858, loss = 1.42018
I0817 10:58:44.770617 14586 caffe.cpp:313] Batch 859, accuracy/top1 = 0.58
I0817 10:58:44.770638 14586 caffe.cpp:313] Batch 859, accuracy/top5 = 0.8
I0817 10:58:44.770642 14586 caffe.cpp:313] Batch 859, loss = 1.94232
I0817 10:58:44.833379 14586 caffe.cpp:313] Batch 860, accuracy/top1 = 0.6
I0817 10:58:44.833400 14586 caffe.cpp:313] Batch 860, accuracy/top5 = 0.78
I0817 10:58:44.833403 14586 caffe.cpp:313] Batch 860, loss = 1.68544
I0817 10:58:44.896545 14586 caffe.cpp:313] Batch 861, accuracy/top1 = 0.7
I0817 10:58:44.896566 14586 caffe.cpp:313] Batch 861, accuracy/top5 = 0.82
I0817 10:58:44.896569 14586 caffe.cpp:313] Batch 861, loss = 1.5526
I0817 10:58:44.959529 14586 caffe.cpp:313] Batch 862, accuracy/top1 = 0.56
I0817 10:58:44.959548 14586 caffe.cpp:313] Batch 862, accuracy/top5 = 0.88
I0817 10:58:44.959553 14586 caffe.cpp:313] Batch 862, loss = 1.63075
I0817 10:58:45.022363 14586 caffe.cpp:313] Batch 863, accuracy/top1 = 0.6
I0817 10:58:45.022382 14586 caffe.cpp:313] Batch 863, accuracy/top5 = 0.74
I0817 10:58:45.022385 14586 caffe.cpp:313] Batch 863, loss = 1.80999
I0817 10:58:45.085041 14586 caffe.cpp:313] Batch 864, accuracy/top1 = 0.64
I0817 10:58:45.085062 14586 caffe.cpp:313] Batch 864, accuracy/top5 = 0.88
I0817 10:58:45.085065 14586 caffe.cpp:313] Batch 864, loss = 1.48218
I0817 10:58:45.147840 14586 caffe.cpp:313] Batch 865, accuracy/top1 = 0.62
I0817 10:58:45.147862 14586 caffe.cpp:313] Batch 865, accuracy/top5 = 0.78
I0817 10:58:45.147866 14586 caffe.cpp:313] Batch 865, loss = 1.93583
I0817 10:58:45.210660 14586 caffe.cpp:313] Batch 866, accuracy/top1 = 0.6
I0817 10:58:45.210681 14586 caffe.cpp:313] Batch 866, accuracy/top5 = 0.86
I0817 10:58:45.210685 14586 caffe.cpp:313] Batch 866, loss = 1.46979
I0817 10:58:45.273437 14586 caffe.cpp:313] Batch 867, accuracy/top1 = 0.6
I0817 10:58:45.273459 14586 caffe.cpp:313] Batch 867, accuracy/top5 = 0.72
I0817 10:58:45.273463 14586 caffe.cpp:313] Batch 867, loss = 2.13258
I0817 10:58:45.336112 14586 caffe.cpp:313] Batch 868, accuracy/top1 = 0.56
I0817 10:58:45.336134 14586 caffe.cpp:313] Batch 868, accuracy/top5 = 0.78
I0817 10:58:45.336138 14586 caffe.cpp:313] Batch 868, loss = 1.98842
I0817 10:58:45.398766 14586 caffe.cpp:313] Batch 869, accuracy/top1 = 0.48
I0817 10:58:45.398788 14586 caffe.cpp:313] Batch 869, accuracy/top5 = 0.8
I0817 10:58:45.398792 14586 caffe.cpp:313] Batch 869, loss = 2.04823
I0817 10:58:45.461390 14586 caffe.cpp:313] Batch 870, accuracy/top1 = 0.52
I0817 10:58:45.461412 14586 caffe.cpp:313] Batch 870, accuracy/top5 = 0.72
I0817 10:58:45.461416 14586 caffe.cpp:313] Batch 870, loss = 2.2458
I0817 10:58:45.524160 14586 caffe.cpp:313] Batch 871, accuracy/top1 = 0.6
I0817 10:58:45.524183 14586 caffe.cpp:313] Batch 871, accuracy/top5 = 0.84
I0817 10:58:45.524185 14586 caffe.cpp:313] Batch 871, loss = 1.59699
I0817 10:58:45.587009 14586 caffe.cpp:313] Batch 872, accuracy/top1 = 0.54
I0817 10:58:45.587030 14586 caffe.cpp:313] Batch 872, accuracy/top5 = 0.8
I0817 10:58:45.587033 14586 caffe.cpp:313] Batch 872, loss = 1.78343
I0817 10:58:45.649739 14586 caffe.cpp:313] Batch 873, accuracy/top1 = 0.62
I0817 10:58:45.649761 14586 caffe.cpp:313] Batch 873, accuracy/top5 = 0.86
I0817 10:58:45.649765 14586 caffe.cpp:313] Batch 873, loss = 1.71179
I0817 10:58:45.712538 14586 caffe.cpp:313] Batch 874, accuracy/top1 = 0.68
I0817 10:58:45.712560 14586 caffe.cpp:313] Batch 874, accuracy/top5 = 0.82
I0817 10:58:45.712563 14586 caffe.cpp:313] Batch 874, loss = 1.60826
I0817 10:58:45.775305 14586 caffe.cpp:313] Batch 875, accuracy/top1 = 0.64
I0817 10:58:45.775326 14586 caffe.cpp:313] Batch 875, accuracy/top5 = 0.8
I0817 10:58:45.775329 14586 caffe.cpp:313] Batch 875, loss = 1.66203
I0817 10:58:45.838155 14586 caffe.cpp:313] Batch 876, accuracy/top1 = 0.64
I0817 10:58:45.838176 14586 caffe.cpp:313] Batch 876, accuracy/top5 = 0.84
I0817 10:58:45.838179 14586 caffe.cpp:313] Batch 876, loss = 1.40685
I0817 10:58:45.901198 14586 caffe.cpp:313] Batch 877, accuracy/top1 = 0.6
I0817 10:58:45.901217 14586 caffe.cpp:313] Batch 877, accuracy/top5 = 0.8
I0817 10:58:45.901221 14586 caffe.cpp:313] Batch 877, loss = 1.68611
I0817 10:58:45.963999 14586 caffe.cpp:313] Batch 878, accuracy/top1 = 0.52
I0817 10:58:45.964021 14586 caffe.cpp:313] Batch 878, accuracy/top5 = 0.72
I0817 10:58:45.964025 14586 caffe.cpp:313] Batch 878, loss = 2.19636
I0817 10:58:46.026785 14586 caffe.cpp:313] Batch 879, accuracy/top1 = 0.6
I0817 10:58:46.026803 14586 caffe.cpp:313] Batch 879, accuracy/top5 = 0.82
I0817 10:58:46.026806 14586 caffe.cpp:313] Batch 879, loss = 1.49428
I0817 10:58:46.089640 14586 caffe.cpp:313] Batch 880, accuracy/top1 = 0.66
I0817 10:58:46.089661 14586 caffe.cpp:313] Batch 880, accuracy/top5 = 0.84
I0817 10:58:46.089664 14586 caffe.cpp:313] Batch 880, loss = 1.4512
I0817 10:58:46.152462 14586 caffe.cpp:313] Batch 881, accuracy/top1 = 0.6
I0817 10:58:46.152482 14586 caffe.cpp:313] Batch 881, accuracy/top5 = 0.88
I0817 10:58:46.152485 14586 caffe.cpp:313] Batch 881, loss = 1.70183
I0817 10:58:46.215306 14586 caffe.cpp:313] Batch 882, accuracy/top1 = 0.62
I0817 10:58:46.215327 14586 caffe.cpp:313] Batch 882, accuracy/top5 = 0.82
I0817 10:58:46.215330 14586 caffe.cpp:313] Batch 882, loss = 1.37572
I0817 10:58:46.278184 14586 caffe.cpp:313] Batch 883, accuracy/top1 = 0.62
I0817 10:58:46.278205 14586 caffe.cpp:313] Batch 883, accuracy/top5 = 0.76
I0817 10:58:46.278208 14586 caffe.cpp:313] Batch 883, loss = 1.93394
I0817 10:58:46.341002 14586 caffe.cpp:313] Batch 884, accuracy/top1 = 0.44
I0817 10:58:46.341023 14586 caffe.cpp:313] Batch 884, accuracy/top5 = 0.8
I0817 10:58:46.341027 14586 caffe.cpp:313] Batch 884, loss = 1.97852
I0817 10:58:46.403738 14586 caffe.cpp:313] Batch 885, accuracy/top1 = 0.5
I0817 10:58:46.403759 14586 caffe.cpp:313] Batch 885, accuracy/top5 = 0.9
I0817 10:58:46.403761 14586 caffe.cpp:313] Batch 885, loss = 1.65015
I0817 10:58:46.466372 14586 caffe.cpp:313] Batch 886, accuracy/top1 = 0.62
I0817 10:58:46.466393 14586 caffe.cpp:313] Batch 886, accuracy/top5 = 0.84
I0817 10:58:46.466397 14586 caffe.cpp:313] Batch 886, loss = 1.71988
I0817 10:58:46.529228 14586 caffe.cpp:313] Batch 887, accuracy/top1 = 0.54
I0817 10:58:46.529250 14586 caffe.cpp:313] Batch 887, accuracy/top5 = 0.84
I0817 10:58:46.529253 14586 caffe.cpp:313] Batch 887, loss = 1.75883
I0817 10:58:46.592000 14586 caffe.cpp:313] Batch 888, accuracy/top1 = 0.58
I0817 10:58:46.592022 14586 caffe.cpp:313] Batch 888, accuracy/top5 = 0.82
I0817 10:58:46.592025 14586 caffe.cpp:313] Batch 888, loss = 1.90841
I0817 10:58:46.654731 14586 caffe.cpp:313] Batch 889, accuracy/top1 = 0.56
I0817 10:58:46.654753 14586 caffe.cpp:313] Batch 889, accuracy/top5 = 0.86
I0817 10:58:46.654757 14586 caffe.cpp:313] Batch 889, loss = 1.90385
I0817 10:58:46.717344 14586 caffe.cpp:313] Batch 890, accuracy/top1 = 0.5
I0817 10:58:46.717366 14586 caffe.cpp:313] Batch 890, accuracy/top5 = 0.76
I0817 10:58:46.717370 14586 caffe.cpp:313] Batch 890, loss = 2.09204
I0817 10:58:46.780232 14586 caffe.cpp:313] Batch 891, accuracy/top1 = 0.6
I0817 10:58:46.780254 14586 caffe.cpp:313] Batch 891, accuracy/top5 = 0.74
I0817 10:58:46.780257 14586 caffe.cpp:313] Batch 891, loss = 1.84054
I0817 10:58:46.843098 14586 caffe.cpp:313] Batch 892, accuracy/top1 = 0.54
I0817 10:58:46.843122 14586 caffe.cpp:313] Batch 892, accuracy/top5 = 0.8
I0817 10:58:46.843124 14586 caffe.cpp:313] Batch 892, loss = 1.82861
I0817 10:58:46.906033 14586 caffe.cpp:313] Batch 893, accuracy/top1 = 0.6
I0817 10:58:46.906054 14586 caffe.cpp:313] Batch 893, accuracy/top5 = 0.84
I0817 10:58:46.906057 14586 caffe.cpp:313] Batch 893, loss = 1.72719
I0817 10:58:46.968811 14586 caffe.cpp:313] Batch 894, accuracy/top1 = 0.46
I0817 10:58:46.968832 14586 caffe.cpp:313] Batch 894, accuracy/top5 = 0.72
I0817 10:58:46.968835 14586 caffe.cpp:313] Batch 894, loss = 2.27506
I0817 10:58:47.031672 14586 caffe.cpp:313] Batch 895, accuracy/top1 = 0.72
I0817 10:58:47.031690 14586 caffe.cpp:313] Batch 895, accuracy/top5 = 0.92
I0817 10:58:47.031693 14586 caffe.cpp:313] Batch 895, loss = 1.11229
I0817 10:58:47.094647 14586 caffe.cpp:313] Batch 896, accuracy/top1 = 0.52
I0817 10:58:47.094667 14586 caffe.cpp:313] Batch 896, accuracy/top5 = 0.74
I0817 10:58:47.094671 14586 caffe.cpp:313] Batch 896, loss = 1.79996
I0817 10:58:47.157531 14586 caffe.cpp:313] Batch 897, accuracy/top1 = 0.68
I0817 10:58:47.157553 14586 caffe.cpp:313] Batch 897, accuracy/top5 = 0.78
I0817 10:58:47.157557 14586 caffe.cpp:313] Batch 897, loss = 1.60354
I0817 10:58:47.220360 14586 caffe.cpp:313] Batch 898, accuracy/top1 = 0.64
I0817 10:58:47.220381 14586 caffe.cpp:313] Batch 898, accuracy/top5 = 0.86
I0817 10:58:47.220399 14586 caffe.cpp:313] Batch 898, loss = 1.50716
I0817 10:58:47.283228 14586 caffe.cpp:313] Batch 899, accuracy/top1 = 0.68
I0817 10:58:47.283249 14586 caffe.cpp:313] Batch 899, accuracy/top5 = 0.86
I0817 10:58:47.283252 14586 caffe.cpp:313] Batch 899, loss = 1.55591
I0817 10:58:47.346129 14586 caffe.cpp:313] Batch 900, accuracy/top1 = 0.62
I0817 10:58:47.346148 14586 caffe.cpp:313] Batch 900, accuracy/top5 = 0.86
I0817 10:58:47.346150 14586 caffe.cpp:313] Batch 900, loss = 1.34523
I0817 10:58:47.408812 14586 caffe.cpp:313] Batch 901, accuracy/top1 = 0.54
I0817 10:58:47.408833 14586 caffe.cpp:313] Batch 901, accuracy/top5 = 0.78
I0817 10:58:47.408836 14586 caffe.cpp:313] Batch 901, loss = 1.93475
I0817 10:58:47.471640 14586 caffe.cpp:313] Batch 902, accuracy/top1 = 0.56
I0817 10:58:47.471663 14586 caffe.cpp:313] Batch 902, accuracy/top5 = 0.86
I0817 10:58:47.471665 14586 caffe.cpp:313] Batch 902, loss = 1.67275
I0817 10:58:47.534413 14586 caffe.cpp:313] Batch 903, accuracy/top1 = 0.68
I0817 10:58:47.534435 14586 caffe.cpp:313] Batch 903, accuracy/top5 = 0.8
I0817 10:58:47.534438 14586 caffe.cpp:313] Batch 903, loss = 1.52738
I0817 10:58:47.597298 14586 caffe.cpp:313] Batch 904, accuracy/top1 = 0.7
I0817 10:58:47.597321 14586 caffe.cpp:313] Batch 904, accuracy/top5 = 0.86
I0817 10:58:47.597324 14586 caffe.cpp:313] Batch 904, loss = 1.56109
I0817 10:58:47.660179 14586 caffe.cpp:313] Batch 905, accuracy/top1 = 0.54
I0817 10:58:47.660202 14586 caffe.cpp:313] Batch 905, accuracy/top5 = 0.82
I0817 10:58:47.660204 14586 caffe.cpp:313] Batch 905, loss = 1.87972
I0817 10:58:47.723021 14586 caffe.cpp:313] Batch 906, accuracy/top1 = 0.6
I0817 10:58:47.723042 14586 caffe.cpp:313] Batch 906, accuracy/top5 = 0.8
I0817 10:58:47.723045 14586 caffe.cpp:313] Batch 906, loss = 1.65915
I0817 10:58:47.785797 14586 caffe.cpp:313] Batch 907, accuracy/top1 = 0.52
I0817 10:58:47.785820 14586 caffe.cpp:313] Batch 907, accuracy/top5 = 0.86
I0817 10:58:47.785822 14586 caffe.cpp:313] Batch 907, loss = 1.67052
I0817 10:58:47.848887 14586 caffe.cpp:313] Batch 908, accuracy/top1 = 0.6
I0817 10:58:47.848909 14586 caffe.cpp:313] Batch 908, accuracy/top5 = 0.86
I0817 10:58:47.848912 14586 caffe.cpp:313] Batch 908, loss = 1.53281
I0817 10:58:47.911906 14586 caffe.cpp:313] Batch 909, accuracy/top1 = 0.64
I0817 10:58:47.911926 14586 caffe.cpp:313] Batch 909, accuracy/top5 = 0.84
I0817 10:58:47.911929 14586 caffe.cpp:313] Batch 909, loss = 1.5357
I0817 10:58:47.974680 14586 caffe.cpp:313] Batch 910, accuracy/top1 = 0.54
I0817 10:58:47.974702 14586 caffe.cpp:313] Batch 910, accuracy/top5 = 0.76
I0817 10:58:47.974705 14586 caffe.cpp:313] Batch 910, loss = 2.21006
I0817 10:58:48.037390 14586 caffe.cpp:313] Batch 911, accuracy/top1 = 0.54
I0817 10:58:48.037408 14586 caffe.cpp:313] Batch 911, accuracy/top5 = 0.82
I0817 10:58:48.037411 14586 caffe.cpp:313] Batch 911, loss = 1.84634
I0817 10:58:48.100028 14586 caffe.cpp:313] Batch 912, accuracy/top1 = 0.6
I0817 10:58:48.100049 14586 caffe.cpp:313] Batch 912, accuracy/top5 = 0.76
I0817 10:58:48.100052 14586 caffe.cpp:313] Batch 912, loss = 1.72205
I0817 10:58:48.162778 14586 caffe.cpp:313] Batch 913, accuracy/top1 = 0.58
I0817 10:58:48.162799 14586 caffe.cpp:313] Batch 913, accuracy/top5 = 0.8
I0817 10:58:48.162802 14586 caffe.cpp:313] Batch 913, loss = 1.79877
I0817 10:58:48.225483 14586 caffe.cpp:313] Batch 914, accuracy/top1 = 0.64
I0817 10:58:48.225505 14586 caffe.cpp:313] Batch 914, accuracy/top5 = 0.8
I0817 10:58:48.225508 14586 caffe.cpp:313] Batch 914, loss = 1.87108
I0817 10:58:48.288164 14586 caffe.cpp:313] Batch 915, accuracy/top1 = 0.66
I0817 10:58:48.288187 14586 caffe.cpp:313] Batch 915, accuracy/top5 = 0.8
I0817 10:58:48.288189 14586 caffe.cpp:313] Batch 915, loss = 1.73449
I0817 10:58:48.353308 14586 caffe.cpp:313] Batch 916, accuracy/top1 = 0.68
I0817 10:58:48.353365 14586 caffe.cpp:313] Batch 916, accuracy/top5 = 0.86
I0817 10:58:48.353379 14586 caffe.cpp:313] Batch 916, loss = 1.52044
I0817 10:58:48.417798 14586 caffe.cpp:313] Batch 917, accuracy/top1 = 0.66
I0817 10:58:48.417861 14586 caffe.cpp:313] Batch 917, accuracy/top5 = 0.82
I0817 10:58:48.417874 14586 caffe.cpp:313] Batch 917, loss = 1.62252
I0817 10:58:48.480779 14586 caffe.cpp:313] Batch 918, accuracy/top1 = 0.58
I0817 10:58:48.480801 14586 caffe.cpp:313] Batch 918, accuracy/top5 = 0.76
I0817 10:58:48.480804 14586 caffe.cpp:313] Batch 918, loss = 1.84145
I0817 10:58:48.543618 14586 caffe.cpp:313] Batch 919, accuracy/top1 = 0.62
I0817 10:58:48.543642 14586 caffe.cpp:313] Batch 919, accuracy/top5 = 0.78
I0817 10:58:48.543643 14586 caffe.cpp:313] Batch 919, loss = 1.99044
I0817 10:58:48.606518 14586 caffe.cpp:313] Batch 920, accuracy/top1 = 0.64
I0817 10:58:48.606539 14586 caffe.cpp:313] Batch 920, accuracy/top5 = 0.8
I0817 10:58:48.606542 14586 caffe.cpp:313] Batch 920, loss = 1.81201
I0817 10:58:48.669291 14586 caffe.cpp:313] Batch 921, accuracy/top1 = 0.58
I0817 10:58:48.669312 14586 caffe.cpp:313] Batch 921, accuracy/top5 = 0.78
I0817 10:58:48.669315 14586 caffe.cpp:313] Batch 921, loss = 1.8894
I0817 10:58:48.732111 14586 caffe.cpp:313] Batch 922, accuracy/top1 = 0.72
I0817 10:58:48.732136 14586 caffe.cpp:313] Batch 922, accuracy/top5 = 0.9
I0817 10:58:48.732138 14586 caffe.cpp:313] Batch 922, loss = 1.17538
I0817 10:58:48.795006 14586 caffe.cpp:313] Batch 923, accuracy/top1 = 0.68
I0817 10:58:48.795027 14586 caffe.cpp:313] Batch 923, accuracy/top5 = 0.8
I0817 10:58:48.795030 14586 caffe.cpp:313] Batch 923, loss = 2.01277
I0817 10:58:48.858806 14586 caffe.cpp:313] Batch 924, accuracy/top1 = 0.6
I0817 10:58:48.858824 14586 caffe.cpp:313] Batch 924, accuracy/top5 = 0.88
I0817 10:58:48.858826 14586 caffe.cpp:313] Batch 924, loss = 1.56412
I0817 10:58:48.921655 14586 caffe.cpp:313] Batch 925, accuracy/top1 = 0.58
I0817 10:58:48.921676 14586 caffe.cpp:313] Batch 925, accuracy/top5 = 0.8
I0817 10:58:48.921679 14586 caffe.cpp:313] Batch 925, loss = 1.88526
I0817 10:58:48.984372 14586 caffe.cpp:313] Batch 926, accuracy/top1 = 0.66
I0817 10:58:48.984395 14586 caffe.cpp:313] Batch 926, accuracy/top5 = 0.8
I0817 10:58:48.984398 14586 caffe.cpp:313] Batch 926, loss = 1.99104
I0817 10:58:49.047222 14586 caffe.cpp:313] Batch 927, accuracy/top1 = 0.54
I0817 10:58:49.047240 14586 caffe.cpp:313] Batch 927, accuracy/top5 = 0.72
I0817 10:58:49.047242 14586 caffe.cpp:313] Batch 927, loss = 2.15183
I0817 10:58:49.110072 14586 caffe.cpp:313] Batch 928, accuracy/top1 = 0.7
I0817 10:58:49.110091 14586 caffe.cpp:313] Batch 928, accuracy/top5 = 0.88
I0817 10:58:49.110095 14586 caffe.cpp:313] Batch 928, loss = 1.35411
I0817 10:58:49.173070 14586 caffe.cpp:313] Batch 929, accuracy/top1 = 0.54
I0817 10:58:49.173091 14586 caffe.cpp:313] Batch 929, accuracy/top5 = 0.84
I0817 10:58:49.173094 14586 caffe.cpp:313] Batch 929, loss = 1.59755
I0817 10:58:49.236062 14586 caffe.cpp:313] Batch 930, accuracy/top1 = 0.64
I0817 10:58:49.236081 14586 caffe.cpp:313] Batch 930, accuracy/top5 = 0.78
I0817 10:58:49.236084 14586 caffe.cpp:313] Batch 930, loss = 1.75479
I0817 10:58:49.298992 14586 caffe.cpp:313] Batch 931, accuracy/top1 = 0.54
I0817 10:58:49.299015 14586 caffe.cpp:313] Batch 931, accuracy/top5 = 0.82
I0817 10:58:49.299017 14586 caffe.cpp:313] Batch 931, loss = 2.24914
I0817 10:58:49.361852 14586 caffe.cpp:313] Batch 932, accuracy/top1 = 0.64
I0817 10:58:49.361870 14586 caffe.cpp:313] Batch 932, accuracy/top5 = 0.82
I0817 10:58:49.361872 14586 caffe.cpp:313] Batch 932, loss = 1.59453
I0817 10:58:49.424556 14586 caffe.cpp:313] Batch 933, accuracy/top1 = 0.64
I0817 10:58:49.424578 14586 caffe.cpp:313] Batch 933, accuracy/top5 = 0.8
I0817 10:58:49.424582 14586 caffe.cpp:313] Batch 933, loss = 2.06305
I0817 10:58:49.487350 14586 caffe.cpp:313] Batch 934, accuracy/top1 = 0.6
I0817 10:58:49.487372 14586 caffe.cpp:313] Batch 934, accuracy/top5 = 0.74
I0817 10:58:49.487375 14586 caffe.cpp:313] Batch 934, loss = 1.94022
I0817 10:58:49.550235 14586 caffe.cpp:313] Batch 935, accuracy/top1 = 0.64
I0817 10:58:49.550256 14586 caffe.cpp:313] Batch 935, accuracy/top5 = 0.78
I0817 10:58:49.550259 14586 caffe.cpp:313] Batch 935, loss = 2.09436
I0817 10:58:49.613138 14586 caffe.cpp:313] Batch 936, accuracy/top1 = 0.64
I0817 10:58:49.613159 14586 caffe.cpp:313] Batch 936, accuracy/top5 = 0.86
I0817 10:58:49.613162 14586 caffe.cpp:313] Batch 936, loss = 1.61705
I0817 10:58:49.675952 14586 caffe.cpp:313] Batch 937, accuracy/top1 = 0.58
I0817 10:58:49.675974 14586 caffe.cpp:313] Batch 937, accuracy/top5 = 0.84
I0817 10:58:49.675977 14586 caffe.cpp:313] Batch 937, loss = 1.77043
I0817 10:58:49.738811 14586 caffe.cpp:313] Batch 938, accuracy/top1 = 0.54
I0817 10:58:49.738833 14586 caffe.cpp:313] Batch 938, accuracy/top5 = 0.8
I0817 10:58:49.738837 14586 caffe.cpp:313] Batch 938, loss = 1.99112
I0817 10:58:49.801579 14586 caffe.cpp:313] Batch 939, accuracy/top1 = 0.56
I0817 10:58:49.801601 14586 caffe.cpp:313] Batch 939, accuracy/top5 = 0.78
I0817 10:58:49.801604 14586 caffe.cpp:313] Batch 939, loss = 1.88508
I0817 10:58:49.865396 14586 caffe.cpp:313] Batch 940, accuracy/top1 = 0.56
I0817 10:58:49.865413 14586 caffe.cpp:313] Batch 940, accuracy/top5 = 0.8
I0817 10:58:49.865417 14586 caffe.cpp:313] Batch 940, loss = 1.85787
I0817 10:58:49.928237 14586 caffe.cpp:313] Batch 941, accuracy/top1 = 0.58
I0817 10:58:49.928257 14586 caffe.cpp:313] Batch 941, accuracy/top5 = 0.78
I0817 10:58:49.928261 14586 caffe.cpp:313] Batch 941, loss = 1.94919
I0817 10:58:49.991107 14586 caffe.cpp:313] Batch 942, accuracy/top1 = 0.52
I0817 10:58:49.991130 14586 caffe.cpp:313] Batch 942, accuracy/top5 = 0.76
I0817 10:58:49.991132 14586 caffe.cpp:313] Batch 942, loss = 2.12031
I0817 10:58:50.053767 14586 caffe.cpp:313] Batch 943, accuracy/top1 = 0.58
I0817 10:58:50.053786 14586 caffe.cpp:313] Batch 943, accuracy/top5 = 0.82
I0817 10:58:50.053789 14586 caffe.cpp:313] Batch 943, loss = 1.62223
I0817 10:58:50.116482 14586 caffe.cpp:313] Batch 944, accuracy/top1 = 0.58
I0817 10:58:50.116503 14586 caffe.cpp:313] Batch 944, accuracy/top5 = 0.84
I0817 10:58:50.116506 14586 caffe.cpp:313] Batch 944, loss = 1.50576
I0817 10:58:50.179129 14586 caffe.cpp:313] Batch 945, accuracy/top1 = 0.58
I0817 10:58:50.179221 14586 caffe.cpp:313] Batch 945, accuracy/top5 = 0.84
I0817 10:58:50.179226 14586 caffe.cpp:313] Batch 945, loss = 1.99001
I0817 10:58:50.241988 14586 caffe.cpp:313] Batch 946, accuracy/top1 = 0.62
I0817 10:58:50.242008 14586 caffe.cpp:313] Batch 946, accuracy/top5 = 0.78
I0817 10:58:50.242012 14586 caffe.cpp:313] Batch 946, loss = 1.91883
I0817 10:58:50.304903 14586 caffe.cpp:313] Batch 947, accuracy/top1 = 0.64
I0817 10:58:50.304925 14586 caffe.cpp:313] Batch 947, accuracy/top5 = 0.88
I0817 10:58:50.304929 14586 caffe.cpp:313] Batch 947, loss = 1.29706
I0817 10:58:50.367653 14586 caffe.cpp:313] Batch 948, accuracy/top1 = 0.5
I0817 10:58:50.367676 14586 caffe.cpp:313] Batch 948, accuracy/top5 = 0.74
I0817 10:58:50.367679 14586 caffe.cpp:313] Batch 948, loss = 2.28255
I0817 10:58:50.430518 14586 caffe.cpp:313] Batch 949, accuracy/top1 = 0.66
I0817 10:58:50.430541 14586 caffe.cpp:313] Batch 949, accuracy/top5 = 0.86
I0817 10:58:50.430542 14586 caffe.cpp:313] Batch 949, loss = 1.34075
I0817 10:58:50.493412 14586 caffe.cpp:313] Batch 950, accuracy/top1 = 0.64
I0817 10:58:50.493433 14586 caffe.cpp:313] Batch 950, accuracy/top5 = 0.76
I0817 10:58:50.493436 14586 caffe.cpp:313] Batch 950, loss = 2.05328
I0817 10:58:50.556176 14586 caffe.cpp:313] Batch 951, accuracy/top1 = 0.72
I0817 10:58:50.556198 14586 caffe.cpp:313] Batch 951, accuracy/top5 = 0.88
I0817 10:58:50.556201 14586 caffe.cpp:313] Batch 951, loss = 1.21205
I0817 10:58:50.618787 14586 caffe.cpp:313] Batch 952, accuracy/top1 = 0.7
I0817 10:58:50.618808 14586 caffe.cpp:313] Batch 952, accuracy/top5 = 0.82
I0817 10:58:50.618811 14586 caffe.cpp:313] Batch 952, loss = 2.07632
I0817 10:58:50.681668 14586 caffe.cpp:313] Batch 953, accuracy/top1 = 0.52
I0817 10:58:50.681689 14586 caffe.cpp:313] Batch 953, accuracy/top5 = 0.74
I0817 10:58:50.681692 14586 caffe.cpp:313] Batch 953, loss = 2.23308
I0817 10:58:50.744520 14586 caffe.cpp:313] Batch 954, accuracy/top1 = 0.5
I0817 10:58:50.744544 14586 caffe.cpp:313] Batch 954, accuracy/top5 = 0.74
I0817 10:58:50.744546 14586 caffe.cpp:313] Batch 954, loss = 2.27375
I0817 10:58:50.807327 14586 caffe.cpp:313] Batch 955, accuracy/top1 = 0.54
I0817 10:58:50.807349 14586 caffe.cpp:313] Batch 955, accuracy/top5 = 0.76
I0817 10:58:50.807353 14586 caffe.cpp:313] Batch 955, loss = 2.15143
I0817 10:58:50.870318 14586 caffe.cpp:313] Batch 956, accuracy/top1 = 0.56
I0817 10:58:50.870335 14586 caffe.cpp:313] Batch 956, accuracy/top5 = 0.84
I0817 10:58:50.870338 14586 caffe.cpp:313] Batch 956, loss = 1.92893
I0817 10:58:50.933143 14586 caffe.cpp:313] Batch 957, accuracy/top1 = 0.52
I0817 10:58:50.933164 14586 caffe.cpp:313] Batch 957, accuracy/top5 = 0.8
I0817 10:58:50.933167 14586 caffe.cpp:313] Batch 957, loss = 2.10975
I0817 10:58:50.995998 14586 caffe.cpp:313] Batch 958, accuracy/top1 = 0.6
I0817 10:58:50.996021 14586 caffe.cpp:313] Batch 958, accuracy/top5 = 0.88
I0817 10:58:50.996023 14586 caffe.cpp:313] Batch 958, loss = 1.62717
I0817 10:58:51.058786 14586 caffe.cpp:313] Batch 959, accuracy/top1 = 0.54
I0817 10:58:51.058806 14586 caffe.cpp:313] Batch 959, accuracy/top5 = 0.82
I0817 10:58:51.058809 14586 caffe.cpp:313] Batch 959, loss = 1.95643
I0817 10:58:51.121409 14586 caffe.cpp:313] Batch 960, accuracy/top1 = 0.64
I0817 10:58:51.121430 14586 caffe.cpp:313] Batch 960, accuracy/top5 = 0.84
I0817 10:58:51.121433 14586 caffe.cpp:313] Batch 960, loss = 1.75115
I0817 10:58:51.184216 14586 caffe.cpp:313] Batch 961, accuracy/top1 = 0.5
I0817 10:58:51.184237 14586 caffe.cpp:313] Batch 961, accuracy/top5 = 0.74
I0817 10:58:51.184240 14586 caffe.cpp:313] Batch 961, loss = 2.35058
I0817 10:58:51.247143 14586 caffe.cpp:313] Batch 962, accuracy/top1 = 0.6
I0817 10:58:51.247160 14586 caffe.cpp:313] Batch 962, accuracy/top5 = 0.88
I0817 10:58:51.247164 14586 caffe.cpp:313] Batch 962, loss = 1.39396
I0817 10:58:51.310148 14586 caffe.cpp:313] Batch 963, accuracy/top1 = 0.48
I0817 10:58:51.310168 14586 caffe.cpp:313] Batch 963, accuracy/top5 = 0.76
I0817 10:58:51.310170 14586 caffe.cpp:313] Batch 963, loss = 2.02668
I0817 10:58:51.373121 14586 caffe.cpp:313] Batch 964, accuracy/top1 = 0.6
I0817 10:58:51.373148 14586 caffe.cpp:313] Batch 964, accuracy/top5 = 0.8
I0817 10:58:51.373152 14586 caffe.cpp:313] Batch 964, loss = 1.82539
I0817 10:58:51.435856 14586 caffe.cpp:313] Batch 965, accuracy/top1 = 0.52
I0817 10:58:51.435875 14586 caffe.cpp:313] Batch 965, accuracy/top5 = 0.76
I0817 10:58:51.435878 14586 caffe.cpp:313] Batch 965, loss = 2.0132
I0817 10:58:51.498615 14586 caffe.cpp:313] Batch 966, accuracy/top1 = 0.54
I0817 10:58:51.498636 14586 caffe.cpp:313] Batch 966, accuracy/top5 = 0.82
I0817 10:58:51.498639 14586 caffe.cpp:313] Batch 966, loss = 2.0503
I0817 10:58:51.561522 14586 caffe.cpp:313] Batch 967, accuracy/top1 = 0.52
I0817 10:58:51.561542 14586 caffe.cpp:313] Batch 967, accuracy/top5 = 0.82
I0817 10:58:51.561545 14586 caffe.cpp:313] Batch 967, loss = 1.89443
I0817 10:58:51.624234 14586 caffe.cpp:313] Batch 968, accuracy/top1 = 0.58
I0817 10:58:51.624255 14586 caffe.cpp:313] Batch 968, accuracy/top5 = 0.8
I0817 10:58:51.624258 14586 caffe.cpp:313] Batch 968, loss = 2.10617
I0817 10:58:51.687011 14586 caffe.cpp:313] Batch 969, accuracy/top1 = 0.52
I0817 10:58:51.687031 14586 caffe.cpp:313] Batch 969, accuracy/top5 = 0.8
I0817 10:58:51.687034 14586 caffe.cpp:313] Batch 969, loss = 1.73607
I0817 10:58:51.749780 14586 caffe.cpp:313] Batch 970, accuracy/top1 = 0.64
I0817 10:58:51.749802 14586 caffe.cpp:313] Batch 970, accuracy/top5 = 0.82
I0817 10:58:51.749805 14586 caffe.cpp:313] Batch 970, loss = 1.60022
I0817 10:58:51.812567 14586 caffe.cpp:313] Batch 971, accuracy/top1 = 0.64
I0817 10:58:51.812588 14586 caffe.cpp:313] Batch 971, accuracy/top5 = 0.9
I0817 10:58:51.812592 14586 caffe.cpp:313] Batch 971, loss = 1.50805
I0817 10:58:51.875651 14586 caffe.cpp:313] Batch 972, accuracy/top1 = 0.62
I0817 10:58:51.875669 14586 caffe.cpp:313] Batch 972, accuracy/top5 = 0.9
I0817 10:58:51.875671 14586 caffe.cpp:313] Batch 972, loss = 1.49859
I0817 10:58:51.938303 14586 caffe.cpp:313] Batch 973, accuracy/top1 = 0.44
I0817 10:58:51.938325 14586 caffe.cpp:313] Batch 973, accuracy/top5 = 0.74
I0817 10:58:51.938328 14586 caffe.cpp:313] Batch 973, loss = 2.37363
I0817 10:58:52.000998 14586 caffe.cpp:313] Batch 974, accuracy/top1 = 0.56
I0817 10:58:52.001019 14586 caffe.cpp:313] Batch 974, accuracy/top5 = 0.82
I0817 10:58:52.001022 14586 caffe.cpp:313] Batch 974, loss = 1.78066
I0817 10:58:52.063673 14586 caffe.cpp:313] Batch 975, accuracy/top1 = 0.66
I0817 10:58:52.063693 14586 caffe.cpp:313] Batch 975, accuracy/top5 = 0.8
I0817 10:58:52.063696 14586 caffe.cpp:313] Batch 975, loss = 1.65167
I0817 10:58:52.126536 14586 caffe.cpp:313] Batch 976, accuracy/top1 = 0.54
I0817 10:58:52.126557 14586 caffe.cpp:313] Batch 976, accuracy/top5 = 0.76
I0817 10:58:52.126560 14586 caffe.cpp:313] Batch 976, loss = 1.98399
I0817 10:58:52.189338 14586 caffe.cpp:313] Batch 977, accuracy/top1 = 0.56
I0817 10:58:52.189359 14586 caffe.cpp:313] Batch 977, accuracy/top5 = 0.8
I0817 10:58:52.189363 14586 caffe.cpp:313] Batch 977, loss = 1.86095
I0817 10:58:52.252046 14586 caffe.cpp:313] Batch 978, accuracy/top1 = 0.54
I0817 10:58:52.252068 14586 caffe.cpp:313] Batch 978, accuracy/top5 = 0.76
I0817 10:58:52.252071 14586 caffe.cpp:313] Batch 978, loss = 2.17502
I0817 10:58:52.314723 14586 caffe.cpp:313] Batch 979, accuracy/top1 = 0.6
I0817 10:58:52.314744 14586 caffe.cpp:313] Batch 979, accuracy/top5 = 0.82
I0817 10:58:52.314748 14586 caffe.cpp:313] Batch 979, loss = 1.75383
I0817 10:58:52.377467 14586 caffe.cpp:313] Batch 980, accuracy/top1 = 0.54
I0817 10:58:52.377490 14586 caffe.cpp:313] Batch 980, accuracy/top5 = 0.74
I0817 10:58:52.377491 14586 caffe.cpp:313] Batch 980, loss = 2.23879
I0817 10:58:52.440052 14586 caffe.cpp:313] Batch 981, accuracy/top1 = 0.52
I0817 10:58:52.440075 14586 caffe.cpp:313] Batch 981, accuracy/top5 = 0.74
I0817 10:58:52.440078 14586 caffe.cpp:313] Batch 981, loss = 2.11889
I0817 10:58:52.502715 14586 caffe.cpp:313] Batch 982, accuracy/top1 = 0.56
I0817 10:58:52.502737 14586 caffe.cpp:313] Batch 982, accuracy/top5 = 0.68
I0817 10:58:52.502740 14586 caffe.cpp:313] Batch 982, loss = 2.62231
I0817 10:58:52.565426 14586 caffe.cpp:313] Batch 983, accuracy/top1 = 0.48
I0817 10:58:52.565449 14586 caffe.cpp:313] Batch 983, accuracy/top5 = 0.78
I0817 10:58:52.565452 14586 caffe.cpp:313] Batch 983, loss = 2.38975
I0817 10:58:52.628254 14586 caffe.cpp:313] Batch 984, accuracy/top1 = 0.7
I0817 10:58:52.628275 14586 caffe.cpp:313] Batch 984, accuracy/top5 = 0.9
I0817 10:58:52.628278 14586 caffe.cpp:313] Batch 984, loss = 1.36328
I0817 10:58:52.691151 14586 caffe.cpp:313] Batch 985, accuracy/top1 = 0.62
I0817 10:58:52.691174 14586 caffe.cpp:313] Batch 985, accuracy/top5 = 0.86
I0817 10:58:52.691176 14586 caffe.cpp:313] Batch 985, loss = 1.56022
I0817 10:58:52.753976 14586 caffe.cpp:313] Batch 986, accuracy/top1 = 0.56
I0817 10:58:52.753998 14586 caffe.cpp:313] Batch 986, accuracy/top5 = 0.78
I0817 10:58:52.754001 14586 caffe.cpp:313] Batch 986, loss = 2.09855
I0817 10:58:52.816705 14586 caffe.cpp:313] Batch 987, accuracy/top1 = 0.52
I0817 10:58:52.816727 14586 caffe.cpp:313] Batch 987, accuracy/top5 = 0.78
I0817 10:58:52.816730 14586 caffe.cpp:313] Batch 987, loss = 1.89621
I0817 10:58:52.879941 14586 caffe.cpp:313] Batch 988, accuracy/top1 = 0.54
I0817 10:58:52.879958 14586 caffe.cpp:313] Batch 988, accuracy/top5 = 0.84
I0817 10:58:52.879961 14586 caffe.cpp:313] Batch 988, loss = 1.77873
I0817 10:58:52.942739 14586 caffe.cpp:313] Batch 989, accuracy/top1 = 0.46
I0817 10:58:52.942761 14586 caffe.cpp:313] Batch 989, accuracy/top5 = 0.76
I0817 10:58:52.942764 14586 caffe.cpp:313] Batch 989, loss = 1.94277
I0817 10:58:53.005568 14586 caffe.cpp:313] Batch 990, accuracy/top1 = 0.62
I0817 10:58:53.005590 14586 caffe.cpp:313] Batch 990, accuracy/top5 = 0.86
I0817 10:58:53.005594 14586 caffe.cpp:313] Batch 990, loss = 1.31043
I0817 10:58:53.068217 14586 caffe.cpp:313] Batch 991, accuracy/top1 = 0.66
I0817 10:58:53.068239 14586 caffe.cpp:313] Batch 991, accuracy/top5 = 0.86
I0817 10:58:53.068243 14586 caffe.cpp:313] Batch 991, loss = 1.64038
I0817 10:58:53.130904 14586 caffe.cpp:313] Batch 992, accuracy/top1 = 0.62
I0817 10:58:53.130928 14586 caffe.cpp:313] Batch 992, accuracy/top5 = 0.82
I0817 10:58:53.130929 14586 caffe.cpp:313] Batch 992, loss = 1.3797
I0817 10:58:53.193645 14586 caffe.cpp:313] Batch 993, accuracy/top1 = 0.68
I0817 10:58:53.193667 14586 caffe.cpp:313] Batch 993, accuracy/top5 = 0.86
I0817 10:58:53.193670 14586 caffe.cpp:313] Batch 993, loss = 1.32431
I0817 10:58:53.256427 14586 caffe.cpp:313] Batch 994, accuracy/top1 = 0.68
I0817 10:58:53.256445 14586 caffe.cpp:313] Batch 994, accuracy/top5 = 0.92
I0817 10:58:53.256448 14586 caffe.cpp:313] Batch 994, loss = 1.3607
I0817 10:58:53.319211 14586 caffe.cpp:313] Batch 995, accuracy/top1 = 0.64
I0817 10:58:53.319233 14586 caffe.cpp:313] Batch 995, accuracy/top5 = 0.82
I0817 10:58:53.319236 14586 caffe.cpp:313] Batch 995, loss = 1.73583
I0817 10:58:53.382035 14586 caffe.cpp:313] Batch 996, accuracy/top1 = 0.56
I0817 10:58:53.382055 14586 caffe.cpp:313] Batch 996, accuracy/top5 = 0.8
I0817 10:58:53.382057 14586 caffe.cpp:313] Batch 996, loss = 1.73074
I0817 10:58:53.432507 14619 data_reader.cpp:288] Starting prefetch of epoch 1
I0817 10:58:53.447413 14586 caffe.cpp:313] Batch 997, accuracy/top1 = 0.64
I0817 10:58:53.447438 14586 caffe.cpp:313] Batch 997, accuracy/top5 = 0.86
I0817 10:58:53.447443 14586 caffe.cpp:313] Batch 997, loss = 1.71568
I0817 10:58:53.510890 14586 caffe.cpp:313] Batch 998, accuracy/top1 = 0.48
I0817 10:58:53.510910 14586 caffe.cpp:313] Batch 998, accuracy/top5 = 0.7
I0817 10:58:53.510912 14586 caffe.cpp:313] Batch 998, loss = 2.13354
I0817 10:58:53.574291 14586 caffe.cpp:313] Batch 999, accuracy/top1 = 0.74
I0817 10:58:53.574313 14586 caffe.cpp:313] Batch 999, accuracy/top5 = 0.88
I0817 10:58:53.574316 14586 caffe.cpp:313] Batch 999, loss = 1.38884
I0817 10:58:53.574319 14586 caffe.cpp:318] Loss: 1.79763
I0817 10:58:53.574327 14586 caffe.cpp:330] accuracy/top1 = 0.582959
I0817 10:58:53.574331 14586 caffe.cpp:330] accuracy/top5 = 0.812541
I0817 10:58:53.574335 14586 caffe.cpp:330] loss = 1.79763 (* 1 = 1.79763 loss)
