I0816 15:05:40.305168 22807 caffe.cpp:608] This is NVCaffe 0.16.3 started at Wed Aug 16 15:05:40 2017
I0816 15:05:40.305305 22807 caffe.cpp:611] CuDNN version: 6021
I0816 15:05:40.305310 22807 caffe.cpp:612] CuBLAS version: 8000
I0816 15:05:40.305312 22807 caffe.cpp:613] CUDA version: 8000
I0816 15:05:40.305315 22807 caffe.cpp:614] CUDA driver version: 8000
I0816 15:05:40.305323 22807 caffe.cpp:263] Not using GPU #2 for single-GPU function
I0816 15:05:40.305330 22807 caffe.cpp:263] Not using GPU #1 for single-GPU function
I0816 15:05:40.305913 22807 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0816 15:05:40.306498 22807 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0816 15:05:40.306504 22807 caffe.cpp:275] Use GPU with device ID 0
I0816 15:05:40.306864 22807 caffe.cpp:279] GPU device name: GeForce GTX 1080
I0816 15:05:40.308279 22807 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
quantize: true
I0816 15:05:40.308428 22807 net.cpp:104] Using FLOAT as default forward math type
I0816 15:05:40.308432 22807 net.cpp:110] Using FLOAT as default backward math type
I0816 15:05:40.308436 22807 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0816 15:05:40.308441 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.308490 22807 net.cpp:184] Created Layer data (0)
I0816 15:05:40.308495 22807 net.cpp:530] data -> data
I0816 15:05:40.308504 22807 net.cpp:530] data -> label
I0816 15:05:40.308524 22807 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 50
I0816 15:05:40.308826 22807 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0816 15:05:40.315467 22826 db_lmdb.cpp:24] Opened lmdb ./data/ilsvrc12_val_lmdb
I0816 15:05:40.316875 22807 data_layer.cpp:185] (0) ReshapePrefetch 50, 3, 224, 224
I0816 15:05:40.316917 22807 data_layer.cpp:209] (0) Output data size: 50, 3, 224, 224
I0816 15:05:40.316925 22807 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0816 15:05:40.316948 22807 net.cpp:245] Setting up data
I0816 15:05:40.316959 22807 net.cpp:252] TEST Top shape for layer 0 'data' 50 3 224 224 (7526400)
I0816 15:05:40.316967 22807 net.cpp:252] TEST Top shape for layer 0 'data' 50 (50)
I0816 15:05:40.316982 22807 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0816 15:05:40.316989 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.317005 22807 net.cpp:184] Created Layer label_data_1_split (1)
I0816 15:05:40.317010 22807 net.cpp:561] label_data_1_split <- label
I0816 15:05:40.317031 22807 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0816 15:05:40.317040 22807 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0816 15:05:40.317051 22807 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0816 15:05:40.317081 22807 net.cpp:245] Setting up label_data_1_split
I0816 15:05:40.317086 22807 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0816 15:05:40.317090 22807 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0816 15:05:40.317091 22807 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0816 15:05:40.317095 22807 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0816 15:05:40.317096 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.317106 22807 net.cpp:184] Created Layer data/bias (2)
I0816 15:05:40.317108 22807 net.cpp:561] data/bias <- data
I0816 15:05:40.317111 22807 net.cpp:530] data/bias -> data/bias
I0816 15:05:40.318437 22827 data_layer.cpp:97] (0) Parser threads: 1
I0816 15:05:40.318446 22827 data_layer.cpp:99] (0) Transformer threads: 1
I0816 15:05:40.323565 22807 net.cpp:245] Setting up data/bias
I0816 15:05:40.323602 22807 net.cpp:252] TEST Top shape for layer 2 'data/bias' 50 3 224 224 (7526400)
I0816 15:05:40.323619 22807 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0816 15:05:40.323626 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.323652 22807 net.cpp:184] Created Layer conv1a (3)
I0816 15:05:40.323657 22807 net.cpp:561] conv1a <- data/bias
I0816 15:05:40.323662 22807 net.cpp:530] conv1a -> conv1a
I0816 15:05:40.617419 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 8.02G, req 0G)
I0816 15:05:40.617439 22807 net.cpp:245] Setting up conv1a
I0816 15:05:40.617446 22807 net.cpp:252] TEST Top shape for layer 3 'conv1a' 50 32 112 112 (20070400)
I0816 15:05:40.617458 22807 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0816 15:05:40.617463 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.617480 22807 net.cpp:184] Created Layer conv1a/bn (4)
I0816 15:05:40.617485 22807 net.cpp:561] conv1a/bn <- conv1a
I0816 15:05:40.617489 22807 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0816 15:05:40.617974 22807 net.cpp:245] Setting up conv1a/bn
I0816 15:05:40.617983 22807 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 50 32 112 112 (20070400)
I0816 15:05:40.617993 22807 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0816 15:05:40.617998 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.618005 22807 net.cpp:184] Created Layer conv1a/relu (5)
I0816 15:05:40.618008 22807 net.cpp:561] conv1a/relu <- conv1a
I0816 15:05:40.618012 22807 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0816 15:05:40.618027 22807 net.cpp:245] Setting up conv1a/relu
I0816 15:05:40.618032 22807 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 50 32 112 112 (20070400)
I0816 15:05:40.618036 22807 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0816 15:05:40.618041 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.618054 22807 net.cpp:184] Created Layer conv1b (6)
I0816 15:05:40.618058 22807 net.cpp:561] conv1b <- conv1a
I0816 15:05:40.618062 22807 net.cpp:530] conv1b -> conv1b
I0816 15:05:40.627727 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.93G, req 0G)
I0816 15:05:40.627744 22807 net.cpp:245] Setting up conv1b
I0816 15:05:40.627753 22807 net.cpp:252] TEST Top shape for layer 6 'conv1b' 50 32 112 112 (20070400)
I0816 15:05:40.627763 22807 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0816 15:05:40.627768 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.627779 22807 net.cpp:184] Created Layer conv1b/bn (7)
I0816 15:05:40.627784 22807 net.cpp:561] conv1b/bn <- conv1b
I0816 15:05:40.627789 22807 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0816 15:05:40.628273 22807 net.cpp:245] Setting up conv1b/bn
I0816 15:05:40.628281 22807 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 50 32 112 112 (20070400)
I0816 15:05:40.628293 22807 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0816 15:05:40.628296 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.628303 22807 net.cpp:184] Created Layer conv1b/relu (8)
I0816 15:05:40.628306 22807 net.cpp:561] conv1b/relu <- conv1b
I0816 15:05:40.628310 22807 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0816 15:05:40.628317 22807 net.cpp:245] Setting up conv1b/relu
I0816 15:05:40.628322 22807 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 50 32 112 112 (20070400)
I0816 15:05:40.628325 22807 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0816 15:05:40.628330 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.628340 22807 net.cpp:184] Created Layer pool1 (9)
I0816 15:05:40.628342 22807 net.cpp:561] pool1 <- conv1b
I0816 15:05:40.628347 22807 net.cpp:530] pool1 -> pool1
I0816 15:05:40.628397 22807 net.cpp:245] Setting up pool1
I0816 15:05:40.628404 22807 net.cpp:252] TEST Top shape for layer 9 'pool1' 50 32 56 56 (5017600)
I0816 15:05:40.628408 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0816 15:05:40.628413 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.628423 22807 net.cpp:184] Created Layer res2a_branch2a (10)
I0816 15:05:40.628427 22807 net.cpp:561] res2a_branch2a <- pool1
I0816 15:05:40.628432 22807 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0816 15:05:40.637586 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0816 15:05:40.637598 22807 net.cpp:245] Setting up res2a_branch2a
I0816 15:05:40.637604 22807 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 50 64 56 56 (10035200)
I0816 15:05:40.637614 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0816 15:05:40.637619 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.637625 22807 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0816 15:05:40.637629 22807 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0816 15:05:40.637634 22807 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0816 15:05:40.638062 22807 net.cpp:245] Setting up res2a_branch2a/bn
I0816 15:05:40.638069 22807 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 50 64 56 56 (10035200)
I0816 15:05:40.638078 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0816 15:05:40.638083 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.638087 22807 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0816 15:05:40.638092 22807 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0816 15:05:40.638097 22807 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0816 15:05:40.638103 22807 net.cpp:245] Setting up res2a_branch2a/relu
I0816 15:05:40.638108 22807 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 50 64 56 56 (10035200)
I0816 15:05:40.638113 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0816 15:05:40.638116 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.638134 22807 net.cpp:184] Created Layer res2a_branch2b (13)
I0816 15:05:40.638137 22807 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0816 15:05:40.638141 22807 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0816 15:05:40.642969 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.82G, req 0G)
I0816 15:05:40.642982 22807 net.cpp:245] Setting up res2a_branch2b
I0816 15:05:40.642987 22807 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 50 64 56 56 (10035200)
I0816 15:05:40.643002 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0816 15:05:40.643007 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.643019 22807 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0816 15:05:40.643023 22807 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0816 15:05:40.643028 22807 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0816 15:05:40.643448 22807 net.cpp:245] Setting up res2a_branch2b/bn
I0816 15:05:40.643456 22807 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 50 64 56 56 (10035200)
I0816 15:05:40.643466 22807 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0816 15:05:40.643471 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.643479 22807 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0816 15:05:40.643482 22807 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0816 15:05:40.643486 22807 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0816 15:05:40.643492 22807 net.cpp:245] Setting up res2a_branch2b/relu
I0816 15:05:40.643497 22807 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 50 64 56 56 (10035200)
I0816 15:05:40.643501 22807 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0816 15:05:40.643506 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.643512 22807 net.cpp:184] Created Layer pool2 (16)
I0816 15:05:40.643517 22807 net.cpp:561] pool2 <- res2a_branch2b
I0816 15:05:40.643520 22807 net.cpp:530] pool2 -> pool2
I0816 15:05:40.643553 22807 net.cpp:245] Setting up pool2
I0816 15:05:40.643558 22807 net.cpp:252] TEST Top shape for layer 16 'pool2' 50 64 28 28 (2508800)
I0816 15:05:40.643563 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0816 15:05:40.643568 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.643576 22807 net.cpp:184] Created Layer res3a_branch2a (17)
I0816 15:05:40.643580 22807 net.cpp:561] res3a_branch2a <- pool2
I0816 15:05:40.643584 22807 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0816 15:05:40.652951 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.79G, req 0G)
I0816 15:05:40.652969 22807 net.cpp:245] Setting up res3a_branch2a
I0816 15:05:40.652976 22807 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 50 128 28 28 (5017600)
I0816 15:05:40.652984 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0816 15:05:40.652992 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.653002 22807 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0816 15:05:40.653007 22807 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0816 15:05:40.653012 22807 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0816 15:05:40.653456 22807 net.cpp:245] Setting up res3a_branch2a/bn
I0816 15:05:40.653465 22807 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 50 128 28 28 (5017600)
I0816 15:05:40.653475 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0816 15:05:40.653479 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.653484 22807 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0816 15:05:40.653488 22807 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0816 15:05:40.653492 22807 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0816 15:05:40.653499 22807 net.cpp:245] Setting up res3a_branch2a/relu
I0816 15:05:40.653503 22807 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 50 128 28 28 (5017600)
I0816 15:05:40.653508 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0816 15:05:40.653512 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.653537 22807 net.cpp:184] Created Layer res3a_branch2b (20)
I0816 15:05:40.653540 22807 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0816 15:05:40.653544 22807 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0816 15:05:40.657376 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.77G, req 0G)
I0816 15:05:40.657387 22807 net.cpp:245] Setting up res3a_branch2b
I0816 15:05:40.657393 22807 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 50 128 28 28 (5017600)
I0816 15:05:40.657400 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0816 15:05:40.657405 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.657411 22807 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0816 15:05:40.657415 22807 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0816 15:05:40.657419 22807 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0816 15:05:40.657820 22807 net.cpp:245] Setting up res3a_branch2b/bn
I0816 15:05:40.657829 22807 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 50 128 28 28 (5017600)
I0816 15:05:40.657836 22807 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0816 15:05:40.657840 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.657845 22807 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0816 15:05:40.657850 22807 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0816 15:05:40.657853 22807 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0816 15:05:40.657860 22807 net.cpp:245] Setting up res3a_branch2b/relu
I0816 15:05:40.657866 22807 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 50 128 28 28 (5017600)
I0816 15:05:40.657869 22807 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0816 15:05:40.657873 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.657881 22807 net.cpp:184] Created Layer pool3 (23)
I0816 15:05:40.657884 22807 net.cpp:561] pool3 <- res3a_branch2b
I0816 15:05:40.657888 22807 net.cpp:530] pool3 -> pool3
I0816 15:05:40.657927 22807 net.cpp:245] Setting up pool3
I0816 15:05:40.657932 22807 net.cpp:252] TEST Top shape for layer 23 'pool3' 50 128 14 14 (1254400)
I0816 15:05:40.657938 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0816 15:05:40.657941 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.657955 22807 net.cpp:184] Created Layer res4a_branch2a (24)
I0816 15:05:40.657959 22807 net.cpp:561] res4a_branch2a <- pool3
I0816 15:05:40.657963 22807 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0816 15:05:40.671066 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.75G, req 0G)
I0816 15:05:40.671077 22807 net.cpp:245] Setting up res4a_branch2a
I0816 15:05:40.671083 22807 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 50 256 14 14 (2508800)
I0816 15:05:40.671090 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0816 15:05:40.671095 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.671103 22807 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0816 15:05:40.671108 22807 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0816 15:05:40.671111 22807 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0816 15:05:40.671525 22807 net.cpp:245] Setting up res4a_branch2a/bn
I0816 15:05:40.671533 22807 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 50 256 14 14 (2508800)
I0816 15:05:40.671542 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0816 15:05:40.671546 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.671558 22807 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0816 15:05:40.671563 22807 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0816 15:05:40.671568 22807 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0816 15:05:40.671576 22807 net.cpp:245] Setting up res4a_branch2a/relu
I0816 15:05:40.671581 22807 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 50 256 14 14 (2508800)
I0816 15:05:40.671586 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0816 15:05:40.671591 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.671599 22807 net.cpp:184] Created Layer res4a_branch2b (27)
I0816 15:05:40.671602 22807 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0816 15:05:40.671607 22807 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0816 15:05:40.677453 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.74G, req 0G)
I0816 15:05:40.677469 22807 net.cpp:245] Setting up res4a_branch2b
I0816 15:05:40.677475 22807 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 50 256 14 14 (2508800)
I0816 15:05:40.677482 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0816 15:05:40.677489 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.677497 22807 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0816 15:05:40.677501 22807 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0816 15:05:40.677507 22807 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0816 15:05:40.678019 22807 net.cpp:245] Setting up res4a_branch2b/bn
I0816 15:05:40.678026 22807 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 50 256 14 14 (2508800)
I0816 15:05:40.678035 22807 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0816 15:05:40.678040 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.678045 22807 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0816 15:05:40.678050 22807 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0816 15:05:40.678055 22807 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0816 15:05:40.678061 22807 net.cpp:245] Setting up res4a_branch2b/relu
I0816 15:05:40.678066 22807 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 50 256 14 14 (2508800)
I0816 15:05:40.678069 22807 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0816 15:05:40.678074 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.678081 22807 net.cpp:184] Created Layer pool4 (30)
I0816 15:05:40.678086 22807 net.cpp:561] pool4 <- res4a_branch2b
I0816 15:05:40.678089 22807 net.cpp:530] pool4 -> pool4
I0816 15:05:40.678127 22807 net.cpp:245] Setting up pool4
I0816 15:05:40.678138 22807 net.cpp:252] TEST Top shape for layer 30 'pool4' 50 256 7 7 (627200)
I0816 15:05:40.678141 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0816 15:05:40.678146 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.678155 22807 net.cpp:184] Created Layer res5a_branch2a (31)
I0816 15:05:40.678159 22807 net.cpp:561] res5a_branch2a <- pool4
I0816 15:05:40.678164 22807 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0816 15:05:40.710963 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.72G, req 0G)
I0816 15:05:40.710984 22807 net.cpp:245] Setting up res5a_branch2a
I0816 15:05:40.710992 22807 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 50 512 7 7 (1254400)
I0816 15:05:40.711002 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0816 15:05:40.711007 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.711022 22807 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0816 15:05:40.711028 22807 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0816 15:05:40.711043 22807 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0816 15:05:40.711522 22807 net.cpp:245] Setting up res5a_branch2a/bn
I0816 15:05:40.711530 22807 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 50 512 7 7 (1254400)
I0816 15:05:40.711539 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0816 15:05:40.711544 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.711550 22807 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0816 15:05:40.711555 22807 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0816 15:05:40.711558 22807 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0816 15:05:40.711565 22807 net.cpp:245] Setting up res5a_branch2a/relu
I0816 15:05:40.711570 22807 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 50 512 7 7 (1254400)
I0816 15:05:40.711575 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0816 15:05:40.711578 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.711589 22807 net.cpp:184] Created Layer res5a_branch2b (34)
I0816 15:05:40.711593 22807 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0816 15:05:40.711597 22807 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0816 15:05:40.727334 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 1  (limit 7.71G, req 0G)
I0816 15:05:40.727347 22807 net.cpp:245] Setting up res5a_branch2b
I0816 15:05:40.727354 22807 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 50 512 7 7 (1254400)
I0816 15:05:40.727365 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0816 15:05:40.727370 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.727377 22807 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0816 15:05:40.727382 22807 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0816 15:05:40.727386 22807 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0816 15:05:40.727818 22807 net.cpp:245] Setting up res5a_branch2b/bn
I0816 15:05:40.727825 22807 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 50 512 7 7 (1254400)
I0816 15:05:40.727833 22807 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0816 15:05:40.727838 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.727844 22807 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0816 15:05:40.727849 22807 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0816 15:05:40.727854 22807 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0816 15:05:40.727860 22807 net.cpp:245] Setting up res5a_branch2b/relu
I0816 15:05:40.727865 22807 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 50 512 7 7 (1254400)
I0816 15:05:40.727869 22807 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0816 15:05:40.727874 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.727880 22807 net.cpp:184] Created Layer pool5 (37)
I0816 15:05:40.727885 22807 net.cpp:561] pool5 <- res5a_branch2b
I0816 15:05:40.727890 22807 net.cpp:530] pool5 -> pool5
I0816 15:05:40.727910 22807 net.cpp:245] Setting up pool5
I0816 15:05:40.727915 22807 net.cpp:252] TEST Top shape for layer 37 'pool5' 50 512 1 1 (25600)
I0816 15:05:40.727918 22807 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0816 15:05:40.727923 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.727932 22807 net.cpp:184] Created Layer fc1000 (38)
I0816 15:05:40.727936 22807 net.cpp:561] fc1000 <- pool5
I0816 15:05:40.727941 22807 net.cpp:530] fc1000 -> fc1000
I0816 15:05:40.738651 22807 net.cpp:245] Setting up fc1000
I0816 15:05:40.738675 22807 net.cpp:252] TEST Top shape for layer 38 'fc1000' 50 1000 (50000)
I0816 15:05:40.738701 22807 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0816 15:05:40.738706 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.738714 22807 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0816 15:05:40.738720 22807 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0816 15:05:40.738726 22807 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0816 15:05:40.738739 22807 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0816 15:05:40.738745 22807 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0816 15:05:40.738801 22807 net.cpp:245] Setting up fc1000_fc1000_0_split
I0816 15:05:40.738806 22807 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0816 15:05:40.738811 22807 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0816 15:05:40.738816 22807 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0816 15:05:40.738819 22807 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0816 15:05:40.738823 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.738840 22807 net.cpp:184] Created Layer loss (40)
I0816 15:05:40.738844 22807 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0816 15:05:40.738849 22807 net.cpp:561] loss <- label_data_1_split_0
I0816 15:05:40.738853 22807 net.cpp:530] loss -> loss
I0816 15:05:40.739004 22807 net.cpp:245] Setting up loss
I0816 15:05:40.739012 22807 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0816 15:05:40.739017 22807 net.cpp:256]     with loss weight 1
I0816 15:05:40.739025 22807 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0816 15:05:40.739029 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.739038 22807 net.cpp:184] Created Layer accuracy/top1 (41)
I0816 15:05:40.739042 22807 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0816 15:05:40.739047 22807 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0816 15:05:40.739051 22807 net.cpp:530] accuracy/top1 -> accuracy/top1
I0816 15:05:40.739059 22807 net.cpp:245] Setting up accuracy/top1
I0816 15:05:40.739064 22807 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0816 15:05:40.739068 22807 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0816 15:05:40.739073 22807 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0816 15:05:40.739084 22807 net.cpp:184] Created Layer accuracy/top5 (42)
I0816 15:05:40.739087 22807 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0816 15:05:40.739092 22807 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0816 15:05:40.739097 22807 net.cpp:530] accuracy/top5 -> accuracy/top5
I0816 15:05:40.739104 22807 net.cpp:245] Setting up accuracy/top5
I0816 15:05:40.739109 22807 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0816 15:05:40.739114 22807 net.cpp:325] accuracy/top5 does not need backward computation.
I0816 15:05:40.739117 22807 net.cpp:325] accuracy/top1 does not need backward computation.
I0816 15:05:40.739121 22807 net.cpp:323] loss needs backward computation.
I0816 15:05:40.739125 22807 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0816 15:05:40.739130 22807 net.cpp:323] fc1000 needs backward computation.
I0816 15:05:40.739133 22807 net.cpp:323] pool5 needs backward computation.
I0816 15:05:40.739136 22807 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0816 15:05:40.739140 22807 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0816 15:05:40.739143 22807 net.cpp:323] res5a_branch2b needs backward computation.
I0816 15:05:40.739147 22807 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0816 15:05:40.739151 22807 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0816 15:05:40.739156 22807 net.cpp:323] res5a_branch2a needs backward computation.
I0816 15:05:40.739164 22807 net.cpp:323] pool4 needs backward computation.
I0816 15:05:40.739168 22807 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0816 15:05:40.739172 22807 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0816 15:05:40.739176 22807 net.cpp:323] res4a_branch2b needs backward computation.
I0816 15:05:40.739179 22807 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0816 15:05:40.739183 22807 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0816 15:05:40.739187 22807 net.cpp:323] res4a_branch2a needs backward computation.
I0816 15:05:40.739190 22807 net.cpp:323] pool3 needs backward computation.
I0816 15:05:40.739194 22807 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0816 15:05:40.739198 22807 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0816 15:05:40.739202 22807 net.cpp:323] res3a_branch2b needs backward computation.
I0816 15:05:40.739205 22807 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0816 15:05:40.739209 22807 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0816 15:05:40.739212 22807 net.cpp:323] res3a_branch2a needs backward computation.
I0816 15:05:40.739217 22807 net.cpp:323] pool2 needs backward computation.
I0816 15:05:40.739220 22807 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0816 15:05:40.739223 22807 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0816 15:05:40.739228 22807 net.cpp:323] res2a_branch2b needs backward computation.
I0816 15:05:40.739230 22807 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0816 15:05:40.739234 22807 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0816 15:05:40.739238 22807 net.cpp:323] res2a_branch2a needs backward computation.
I0816 15:05:40.739241 22807 net.cpp:323] pool1 needs backward computation.
I0816 15:05:40.739245 22807 net.cpp:323] conv1b/relu needs backward computation.
I0816 15:05:40.739249 22807 net.cpp:323] conv1b/bn needs backward computation.
I0816 15:05:40.739253 22807 net.cpp:323] conv1b needs backward computation.
I0816 15:05:40.739256 22807 net.cpp:323] conv1a/relu needs backward computation.
I0816 15:05:40.739260 22807 net.cpp:323] conv1a/bn needs backward computation.
I0816 15:05:40.739264 22807 net.cpp:323] conv1a needs backward computation.
I0816 15:05:40.739267 22807 net.cpp:325] data/bias does not need backward computation.
I0816 15:05:40.739272 22807 net.cpp:325] label_data_1_split does not need backward computation.
I0816 15:05:40.739276 22807 net.cpp:325] data does not need backward computation.
I0816 15:05:40.739280 22807 net.cpp:367] This network produces output accuracy/top1
I0816 15:05:40.739284 22807 net.cpp:367] This network produces output accuracy/top5
I0816 15:05:40.739287 22807 net.cpp:367] This network produces output loss
I0816 15:05:40.739321 22807 net.cpp:389] Top memory (TEST) required for data: 933273600 diff: 8
I0816 15:05:40.739326 22807 net.cpp:392] Bottom memory (TEST) required for data: 933273600 diff: 933273600
I0816 15:05:40.739329 22807 net.cpp:395] Shared (in-place) memory (TEST) by data: 622182400 diff: 622182400
I0816 15:05:40.739333 22807 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0816 15:05:40.739336 22807 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0816 15:05:40.739341 22807 net.cpp:407] Network initialization done.
I0816 15:05:40.744215 22807 net.cpp:1095] Copying source layer data Type:Data #blobs=0
I0816 15:05:40.744244 22807 net.cpp:1095] Copying source layer data/bias Type:Bias #blobs=1
I0816 15:05:40.744294 22807 net.cpp:1095] Copying source layer conv1a Type:Convolution #blobs=2
I0816 15:05:40.744313 22807 net.cpp:1095] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0816 15:05:40.744498 22807 net.cpp:1095] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0816 15:05:40.744503 22807 net.cpp:1095] Copying source layer conv1b Type:Convolution #blobs=2
I0816 15:05:40.744516 22807 net.cpp:1095] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0816 15:05:40.744626 22807 net.cpp:1095] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0816 15:05:40.744632 22807 net.cpp:1095] Copying source layer pool1 Type:Pooling #blobs=0
I0816 15:05:40.744634 22807 net.cpp:1095] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0816 15:05:40.744655 22807 net.cpp:1095] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0816 15:05:40.744747 22807 net.cpp:1095] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0816 15:05:40.744752 22807 net.cpp:1095] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0816 15:05:40.744767 22807 net.cpp:1095] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0816 15:05:40.744861 22807 net.cpp:1095] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0816 15:05:40.744868 22807 net.cpp:1095] Copying source layer pool2 Type:Pooling #blobs=0
I0816 15:05:40.744870 22807 net.cpp:1095] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0816 15:05:40.744910 22807 net.cpp:1095] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0816 15:05:40.744994 22807 net.cpp:1095] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0816 15:05:40.744999 22807 net.cpp:1095] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0816 15:05:40.745024 22807 net.cpp:1095] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0816 15:05:40.745102 22807 net.cpp:1095] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0816 15:05:40.745107 22807 net.cpp:1095] Copying source layer pool3 Type:Pooling #blobs=0
I0816 15:05:40.745111 22807 net.cpp:1095] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0816 15:05:40.745224 22807 net.cpp:1095] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0816 15:05:40.745306 22807 net.cpp:1095] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0816 15:05:40.745311 22807 net.cpp:1095] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0816 15:05:40.745371 22807 net.cpp:1095] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0816 15:05:40.745455 22807 net.cpp:1095] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0816 15:05:40.745460 22807 net.cpp:1095] Copying source layer pool4 Type:Pooling #blobs=0
I0816 15:05:40.745463 22807 net.cpp:1095] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0816 15:05:40.745838 22807 net.cpp:1095] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0816 15:05:40.745930 22807 net.cpp:1095] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0816 15:05:40.745935 22807 net.cpp:1095] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0816 15:05:40.746112 22807 net.cpp:1095] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0816 15:05:40.746188 22807 net.cpp:1095] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0816 15:05:40.746193 22807 net.cpp:1095] Copying source layer pool5 Type:Pooling #blobs=0
I0816 15:05:40.746197 22807 net.cpp:1095] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0816 15:05:40.746323 22807 net.cpp:1095] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0816 15:05:40.746367 22807 caffe.cpp:290] Running for 1000 iterations.
I0816 15:05:40.752573 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.68G, req 0G)
I0816 15:05:40.766646 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.52G, req 0G)
I0816 15:05:40.783419 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.33G, req 0G)
I0816 15:05:40.790688 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.25G, req 0G)
I0816 15:05:40.803900 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.15G, req 0G)
I0816 15:05:40.808992 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.11G, req 0G)
I0816 15:05:40.818068 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.06G, req 0G)
I0816 15:05:40.822607 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.04G, req 0G)
I0816 15:05:40.831594 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.02G, req 0G)
I0816 15:05:40.836256 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 1  (limit 7G, req 0G)
I0816 15:05:40.871078 22807 caffe.cpp:313] Batch 0, accuracy/top1 = 0.56
I0816 15:05:40.871104 22807 caffe.cpp:313] Batch 0, accuracy/top5 = 0.8
I0816 15:05:40.871109 22807 caffe.cpp:313] Batch 0, loss = 1.76059
I0816 15:05:40.871114 22807 net.cpp:1620] Adding quantization params at infer/iter index: 1
I0816 15:05:40.879895 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.74G/1 1  (limit 6.25G, req 0G)
I0816 15:05:40.899935 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0816 15:05:40.925299 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0816 15:05:40.935956 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0816 15:05:40.950927 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0816 15:05:40.957692 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0816 15:05:40.971547 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 1.48G/1 6  (limit 5.51G, req 0G)
I0816 15:05:40.976624 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0G)
I0816 15:05:40.996467 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 1.48G/1 7  (limit 5.51G, req 0.05G)
I0816 15:05:41.002393 22807 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 1.48G/2 6  (limit 5.51G, req 0.05G)
I0816 15:05:41.034615 22807 caffe.cpp:313] Batch 1, accuracy/top1 = 0.6
I0816 15:05:41.034634 22807 caffe.cpp:313] Batch 1, accuracy/top5 = 0.78
I0816 15:05:41.034637 22807 caffe.cpp:313] Batch 1, loss = 1.89292
I0816 15:05:41.097975 22807 caffe.cpp:313] Batch 2, accuracy/top1 = 0.54
I0816 15:05:41.097998 22807 caffe.cpp:313] Batch 2, accuracy/top5 = 0.76
I0816 15:05:41.098001 22807 caffe.cpp:313] Batch 2, loss = 2.22469
I0816 15:05:41.161237 22807 caffe.cpp:313] Batch 3, accuracy/top1 = 0.66
I0816 15:05:41.161259 22807 caffe.cpp:313] Batch 3, accuracy/top5 = 0.8
I0816 15:05:41.161262 22807 caffe.cpp:313] Batch 3, loss = 1.54865
I0816 15:05:41.224247 22807 caffe.cpp:313] Batch 4, accuracy/top1 = 0.58
I0816 15:05:41.224270 22807 caffe.cpp:313] Batch 4, accuracy/top5 = 0.78
I0816 15:05:41.224273 22807 caffe.cpp:313] Batch 4, loss = 1.88079
I0816 15:05:41.287143 22807 caffe.cpp:313] Batch 5, accuracy/top1 = 0.6
I0816 15:05:41.287165 22807 caffe.cpp:313] Batch 5, accuracy/top5 = 0.86
I0816 15:05:41.287169 22807 caffe.cpp:313] Batch 5, loss = 1.50854
I0816 15:05:41.350003 22807 caffe.cpp:313] Batch 6, accuracy/top1 = 0.7
I0816 15:05:41.350025 22807 caffe.cpp:313] Batch 6, accuracy/top5 = 0.84
I0816 15:05:41.350028 22807 caffe.cpp:313] Batch 6, loss = 1.44042
I0816 15:05:41.412997 22807 caffe.cpp:313] Batch 7, accuracy/top1 = 0.58
I0816 15:05:41.413018 22807 caffe.cpp:313] Batch 7, accuracy/top5 = 0.84
I0816 15:05:41.413022 22807 caffe.cpp:313] Batch 7, loss = 1.68177
I0816 15:05:41.475956 22807 caffe.cpp:313] Batch 8, accuracy/top1 = 0.66
I0816 15:05:41.475978 22807 caffe.cpp:313] Batch 8, accuracy/top5 = 0.86
I0816 15:05:41.475981 22807 caffe.cpp:313] Batch 8, loss = 1.41964
I0816 15:05:41.539350 22807 caffe.cpp:313] Batch 9, accuracy/top1 = 0.54
I0816 15:05:41.539371 22807 caffe.cpp:313] Batch 9, accuracy/top5 = 0.9
I0816 15:05:41.539373 22807 caffe.cpp:313] Batch 9, loss = 1.72912
I0816 15:05:41.602174 22807 caffe.cpp:313] Batch 10, accuracy/top1 = 0.56
I0816 15:05:41.602195 22807 caffe.cpp:313] Batch 10, accuracy/top5 = 0.9
I0816 15:05:41.602198 22807 caffe.cpp:313] Batch 10, loss = 1.5357
I0816 15:05:41.664961 22807 caffe.cpp:313] Batch 11, accuracy/top1 = 0.58
I0816 15:05:41.664980 22807 caffe.cpp:313] Batch 11, accuracy/top5 = 0.84
I0816 15:05:41.664983 22807 caffe.cpp:313] Batch 11, loss = 1.46341
I0816 15:05:41.727828 22807 caffe.cpp:313] Batch 12, accuracy/top1 = 0.64
I0816 15:05:41.727849 22807 caffe.cpp:313] Batch 12, accuracy/top5 = 0.92
I0816 15:05:41.727852 22807 caffe.cpp:313] Batch 12, loss = 1.47277
I0816 15:05:41.790623 22807 caffe.cpp:313] Batch 13, accuracy/top1 = 0.58
I0816 15:05:41.790647 22807 caffe.cpp:313] Batch 13, accuracy/top5 = 0.86
I0816 15:05:41.790649 22807 caffe.cpp:313] Batch 13, loss = 1.44036
I0816 15:05:41.853617 22807 caffe.cpp:313] Batch 14, accuracy/top1 = 0.4
I0816 15:05:41.853639 22807 caffe.cpp:313] Batch 14, accuracy/top5 = 0.76
I0816 15:05:41.853643 22807 caffe.cpp:313] Batch 14, loss = 2.22469
I0816 15:05:41.916467 22807 caffe.cpp:313] Batch 15, accuracy/top1 = 0.56
I0816 15:05:41.916489 22807 caffe.cpp:313] Batch 15, accuracy/top5 = 0.64
I0816 15:05:41.916492 22807 caffe.cpp:313] Batch 15, loss = 2.47236
I0816 15:05:41.979425 22807 caffe.cpp:313] Batch 16, accuracy/top1 = 0.5
I0816 15:05:41.979446 22807 caffe.cpp:313] Batch 16, accuracy/top5 = 0.82
I0816 15:05:41.979449 22807 caffe.cpp:313] Batch 16, loss = 2.03718
I0816 15:05:42.042378 22807 caffe.cpp:313] Batch 17, accuracy/top1 = 0.54
I0816 15:05:42.042397 22807 caffe.cpp:313] Batch 17, accuracy/top5 = 0.76
I0816 15:05:42.042399 22807 caffe.cpp:313] Batch 17, loss = 2.04652
I0816 15:05:42.105234 22807 caffe.cpp:313] Batch 18, accuracy/top1 = 0.64
I0816 15:05:42.105257 22807 caffe.cpp:313] Batch 18, accuracy/top5 = 0.9
I0816 15:05:42.105259 22807 caffe.cpp:313] Batch 18, loss = 1.70072
I0816 15:05:42.168040 22807 caffe.cpp:313] Batch 19, accuracy/top1 = 0.56
I0816 15:05:42.168061 22807 caffe.cpp:313] Batch 19, accuracy/top5 = 0.9
I0816 15:05:42.168064 22807 caffe.cpp:313] Batch 19, loss = 1.49636
I0816 15:05:42.230959 22807 caffe.cpp:313] Batch 20, accuracy/top1 = 0.56
I0816 15:05:42.230979 22807 caffe.cpp:313] Batch 20, accuracy/top5 = 0.78
I0816 15:05:42.230983 22807 caffe.cpp:313] Batch 20, loss = 1.74751
I0816 15:05:42.293812 22807 caffe.cpp:313] Batch 21, accuracy/top1 = 0.58
I0816 15:05:42.293833 22807 caffe.cpp:313] Batch 21, accuracy/top5 = 0.76
I0816 15:05:42.293836 22807 caffe.cpp:313] Batch 21, loss = 1.84409
I0816 15:05:42.356519 22807 caffe.cpp:313] Batch 22, accuracy/top1 = 0.5
I0816 15:05:42.356542 22807 caffe.cpp:313] Batch 22, accuracy/top5 = 0.8
I0816 15:05:42.356545 22807 caffe.cpp:313] Batch 22, loss = 2.15043
I0816 15:05:42.419291 22807 caffe.cpp:313] Batch 23, accuracy/top1 = 0.6
I0816 15:05:42.419312 22807 caffe.cpp:313] Batch 23, accuracy/top5 = 0.78
I0816 15:05:42.419315 22807 caffe.cpp:313] Batch 23, loss = 1.90446
I0816 15:05:42.482069 22807 caffe.cpp:313] Batch 24, accuracy/top1 = 0.6
I0816 15:05:42.482090 22807 caffe.cpp:313] Batch 24, accuracy/top5 = 0.86
I0816 15:05:42.482094 22807 caffe.cpp:313] Batch 24, loss = 1.4287
I0816 15:05:42.545408 22807 caffe.cpp:313] Batch 25, accuracy/top1 = 0.58
I0816 15:05:42.545428 22807 caffe.cpp:313] Batch 25, accuracy/top5 = 0.82
I0816 15:05:42.545431 22807 caffe.cpp:313] Batch 25, loss = 1.74891
I0816 15:05:42.608242 22807 caffe.cpp:313] Batch 26, accuracy/top1 = 0.5
I0816 15:05:42.608264 22807 caffe.cpp:313] Batch 26, accuracy/top5 = 0.84
I0816 15:05:42.608268 22807 caffe.cpp:313] Batch 26, loss = 1.89676
I0816 15:05:42.671259 22807 caffe.cpp:313] Batch 27, accuracy/top1 = 0.4
I0816 15:05:42.671280 22807 caffe.cpp:313] Batch 27, accuracy/top5 = 0.6
I0816 15:05:42.671283 22807 caffe.cpp:313] Batch 27, loss = 2.79728
I0816 15:05:42.734225 22807 caffe.cpp:313] Batch 28, accuracy/top1 = 0.64
I0816 15:05:42.734246 22807 caffe.cpp:313] Batch 28, accuracy/top5 = 0.78
I0816 15:05:42.734248 22807 caffe.cpp:313] Batch 28, loss = 1.5454
I0816 15:05:42.797210 22807 caffe.cpp:313] Batch 29, accuracy/top1 = 0.52
I0816 15:05:42.797232 22807 caffe.cpp:313] Batch 29, accuracy/top5 = 0.74
I0816 15:05:42.797235 22807 caffe.cpp:313] Batch 29, loss = 2.15833
I0816 15:05:42.860020 22807 caffe.cpp:313] Batch 30, accuracy/top1 = 0.56
I0816 15:05:42.860043 22807 caffe.cpp:313] Batch 30, accuracy/top5 = 0.78
I0816 15:05:42.860045 22807 caffe.cpp:313] Batch 30, loss = 2.16232
I0816 15:05:42.922946 22807 caffe.cpp:313] Batch 31, accuracy/top1 = 0.58
I0816 15:05:42.922969 22807 caffe.cpp:313] Batch 31, accuracy/top5 = 0.82
I0816 15:05:42.922972 22807 caffe.cpp:313] Batch 31, loss = 1.85904
I0816 15:05:42.985716 22807 caffe.cpp:313] Batch 32, accuracy/top1 = 0.54
I0816 15:05:42.985738 22807 caffe.cpp:313] Batch 32, accuracy/top5 = 0.76
I0816 15:05:42.985740 22807 caffe.cpp:313] Batch 32, loss = 2.10379
I0816 15:05:43.048701 22807 caffe.cpp:313] Batch 33, accuracy/top1 = 0.6
I0816 15:05:43.048719 22807 caffe.cpp:313] Batch 33, accuracy/top5 = 0.8
I0816 15:05:43.048722 22807 caffe.cpp:313] Batch 33, loss = 1.74104
I0816 15:05:43.111570 22807 caffe.cpp:313] Batch 34, accuracy/top1 = 0.46
I0816 15:05:43.111593 22807 caffe.cpp:313] Batch 34, accuracy/top5 = 0.84
I0816 15:05:43.111595 22807 caffe.cpp:313] Batch 34, loss = 1.95776
I0816 15:05:43.174345 22807 caffe.cpp:313] Batch 35, accuracy/top1 = 0.7
I0816 15:05:43.174367 22807 caffe.cpp:313] Batch 35, accuracy/top5 = 0.8
I0816 15:05:43.174371 22807 caffe.cpp:313] Batch 35, loss = 1.58678
I0816 15:05:43.237151 22807 caffe.cpp:313] Batch 36, accuracy/top1 = 0.54
I0816 15:05:43.237174 22807 caffe.cpp:313] Batch 36, accuracy/top5 = 0.74
I0816 15:05:43.237177 22807 caffe.cpp:313] Batch 36, loss = 1.99382
I0816 15:05:43.299942 22807 caffe.cpp:313] Batch 37, accuracy/top1 = 0.64
I0816 15:05:43.299963 22807 caffe.cpp:313] Batch 37, accuracy/top5 = 0.84
I0816 15:05:43.299967 22807 caffe.cpp:313] Batch 37, loss = 1.53445
I0816 15:05:43.362768 22807 caffe.cpp:313] Batch 38, accuracy/top1 = 0.48
I0816 15:05:43.362789 22807 caffe.cpp:313] Batch 38, accuracy/top5 = 0.72
I0816 15:05:43.362793 22807 caffe.cpp:313] Batch 38, loss = 2.73192
I0816 15:05:43.425616 22807 caffe.cpp:313] Batch 39, accuracy/top1 = 0.64
I0816 15:05:43.425637 22807 caffe.cpp:313] Batch 39, accuracy/top5 = 0.82
I0816 15:05:43.425642 22807 caffe.cpp:313] Batch 39, loss = 1.77489
I0816 15:05:43.488557 22807 caffe.cpp:313] Batch 40, accuracy/top1 = 0.52
I0816 15:05:43.488579 22807 caffe.cpp:313] Batch 40, accuracy/top5 = 0.76
I0816 15:05:43.488584 22807 caffe.cpp:313] Batch 40, loss = 2.37258
I0816 15:05:43.551692 22807 caffe.cpp:313] Batch 41, accuracy/top1 = 0.6
I0816 15:05:43.551713 22807 caffe.cpp:313] Batch 41, accuracy/top5 = 0.86
I0816 15:05:43.551717 22807 caffe.cpp:313] Batch 41, loss = 1.52317
I0816 15:05:43.614416 22807 caffe.cpp:313] Batch 42, accuracy/top1 = 0.58
I0816 15:05:43.614439 22807 caffe.cpp:313] Batch 42, accuracy/top5 = 0.78
I0816 15:05:43.614441 22807 caffe.cpp:313] Batch 42, loss = 1.99506
I0816 15:05:43.677314 22807 caffe.cpp:313] Batch 43, accuracy/top1 = 0.56
I0816 15:05:43.677335 22807 caffe.cpp:313] Batch 43, accuracy/top5 = 0.88
I0816 15:05:43.677338 22807 caffe.cpp:313] Batch 43, loss = 1.37439
I0816 15:05:43.740093 22807 caffe.cpp:313] Batch 44, accuracy/top1 = 0.5
I0816 15:05:43.740113 22807 caffe.cpp:313] Batch 44, accuracy/top5 = 0.82
I0816 15:05:43.740116 22807 caffe.cpp:313] Batch 44, loss = 1.78207
I0816 15:05:43.802906 22807 caffe.cpp:313] Batch 45, accuracy/top1 = 0.62
I0816 15:05:43.802927 22807 caffe.cpp:313] Batch 45, accuracy/top5 = 0.76
I0816 15:05:43.802930 22807 caffe.cpp:313] Batch 45, loss = 2.18955
I0816 15:05:43.865675 22807 caffe.cpp:313] Batch 46, accuracy/top1 = 0.7
I0816 15:05:43.865698 22807 caffe.cpp:313] Batch 46, accuracy/top5 = 0.88
I0816 15:05:43.865701 22807 caffe.cpp:313] Batch 46, loss = 1.46814
I0816 15:05:43.928692 22807 caffe.cpp:313] Batch 47, accuracy/top1 = 0.54
I0816 15:05:43.928714 22807 caffe.cpp:313] Batch 47, accuracy/top5 = 0.82
I0816 15:05:43.928717 22807 caffe.cpp:313] Batch 47, loss = 2.09057
I0816 15:05:43.991392 22807 caffe.cpp:313] Batch 48, accuracy/top1 = 0.56
I0816 15:05:43.991415 22807 caffe.cpp:313] Batch 48, accuracy/top5 = 0.8
I0816 15:05:43.991418 22807 caffe.cpp:313] Batch 48, loss = 1.95473
I0816 15:05:44.054126 22807 caffe.cpp:313] Batch 49, accuracy/top1 = 0.6
I0816 15:05:44.054145 22807 caffe.cpp:313] Batch 49, accuracy/top5 = 0.84
I0816 15:05:44.054149 22807 caffe.cpp:313] Batch 49, loss = 1.58204
I0816 15:05:44.117018 22807 caffe.cpp:313] Batch 50, accuracy/top1 = 0.56
I0816 15:05:44.117040 22807 caffe.cpp:313] Batch 50, accuracy/top5 = 0.78
I0816 15:05:44.117043 22807 caffe.cpp:313] Batch 50, loss = 1.96441
I0816 15:05:44.179888 22807 caffe.cpp:313] Batch 51, accuracy/top1 = 0.58
I0816 15:05:44.179909 22807 caffe.cpp:313] Batch 51, accuracy/top5 = 0.74
I0816 15:05:44.179913 22807 caffe.cpp:313] Batch 51, loss = 1.96952
I0816 15:05:44.242745 22807 caffe.cpp:313] Batch 52, accuracy/top1 = 0.58
I0816 15:05:44.242768 22807 caffe.cpp:313] Batch 52, accuracy/top5 = 0.8
I0816 15:05:44.242770 22807 caffe.cpp:313] Batch 52, loss = 1.81991
I0816 15:05:44.305554 22807 caffe.cpp:313] Batch 53, accuracy/top1 = 0.5
I0816 15:05:44.305577 22807 caffe.cpp:313] Batch 53, accuracy/top5 = 0.74
I0816 15:05:44.305579 22807 caffe.cpp:313] Batch 53, loss = 2.31852
I0816 15:05:44.368356 22807 caffe.cpp:313] Batch 54, accuracy/top1 = 0.7
I0816 15:05:44.368378 22807 caffe.cpp:313] Batch 54, accuracy/top5 = 0.88
I0816 15:05:44.368381 22807 caffe.cpp:313] Batch 54, loss = 1.29691
I0816 15:05:44.431247 22807 caffe.cpp:313] Batch 55, accuracy/top1 = 0.52
I0816 15:05:44.431269 22807 caffe.cpp:313] Batch 55, accuracy/top5 = 0.88
I0816 15:05:44.431272 22807 caffe.cpp:313] Batch 55, loss = 1.51307
I0816 15:05:44.494181 22807 caffe.cpp:313] Batch 56, accuracy/top1 = 0.62
I0816 15:05:44.494221 22807 caffe.cpp:313] Batch 56, accuracy/top5 = 0.92
I0816 15:05:44.494225 22807 caffe.cpp:313] Batch 56, loss = 1.26097
I0816 15:05:44.557399 22807 caffe.cpp:313] Batch 57, accuracy/top1 = 0.58
I0816 15:05:44.557420 22807 caffe.cpp:313] Batch 57, accuracy/top5 = 0.82
I0816 15:05:44.557423 22807 caffe.cpp:313] Batch 57, loss = 1.95819
I0816 15:05:44.620235 22807 caffe.cpp:313] Batch 58, accuracy/top1 = 0.68
I0816 15:05:44.620256 22807 caffe.cpp:313] Batch 58, accuracy/top5 = 0.88
I0816 15:05:44.620260 22807 caffe.cpp:313] Batch 58, loss = 1.41042
I0816 15:05:44.683087 22807 caffe.cpp:313] Batch 59, accuracy/top1 = 0.68
I0816 15:05:44.683109 22807 caffe.cpp:313] Batch 59, accuracy/top5 = 0.88
I0816 15:05:44.683111 22807 caffe.cpp:313] Batch 59, loss = 1.30509
I0816 15:05:44.745903 22807 caffe.cpp:313] Batch 60, accuracy/top1 = 0.64
I0816 15:05:44.745925 22807 caffe.cpp:313] Batch 60, accuracy/top5 = 0.86
I0816 15:05:44.745929 22807 caffe.cpp:313] Batch 60, loss = 1.45555
I0816 15:05:44.808835 22807 caffe.cpp:313] Batch 61, accuracy/top1 = 0.56
I0816 15:05:44.808852 22807 caffe.cpp:313] Batch 61, accuracy/top5 = 0.86
I0816 15:05:44.808856 22807 caffe.cpp:313] Batch 61, loss = 1.84526
I0816 15:05:44.871919 22807 caffe.cpp:313] Batch 62, accuracy/top1 = 0.54
I0816 15:05:44.871940 22807 caffe.cpp:313] Batch 62, accuracy/top5 = 0.88
I0816 15:05:44.871943 22807 caffe.cpp:313] Batch 62, loss = 1.41306
I0816 15:05:44.934702 22807 caffe.cpp:313] Batch 63, accuracy/top1 = 0.62
I0816 15:05:44.934725 22807 caffe.cpp:313] Batch 63, accuracy/top5 = 0.78
I0816 15:05:44.934728 22807 caffe.cpp:313] Batch 63, loss = 1.68835
I0816 15:05:44.997406 22807 caffe.cpp:313] Batch 64, accuracy/top1 = 0.52
I0816 15:05:44.997427 22807 caffe.cpp:313] Batch 64, accuracy/top5 = 0.72
I0816 15:05:44.997431 22807 caffe.cpp:313] Batch 64, loss = 1.97526
I0816 15:05:45.060299 22807 caffe.cpp:313] Batch 65, accuracy/top1 = 0.52
I0816 15:05:45.060319 22807 caffe.cpp:313] Batch 65, accuracy/top5 = 0.76
I0816 15:05:45.060322 22807 caffe.cpp:313] Batch 65, loss = 1.93962
I0816 15:05:45.123169 22807 caffe.cpp:313] Batch 66, accuracy/top1 = 0.64
I0816 15:05:45.123191 22807 caffe.cpp:313] Batch 66, accuracy/top5 = 0.82
I0816 15:05:45.123194 22807 caffe.cpp:313] Batch 66, loss = 1.57577
I0816 15:05:45.185916 22807 caffe.cpp:313] Batch 67, accuracy/top1 = 0.52
I0816 15:05:45.185938 22807 caffe.cpp:313] Batch 67, accuracy/top5 = 0.8
I0816 15:05:45.185941 22807 caffe.cpp:313] Batch 67, loss = 1.9049
I0816 15:05:45.248703 22807 caffe.cpp:313] Batch 68, accuracy/top1 = 0.64
I0816 15:05:45.248725 22807 caffe.cpp:313] Batch 68, accuracy/top5 = 0.88
I0816 15:05:45.248728 22807 caffe.cpp:313] Batch 68, loss = 1.34334
I0816 15:05:45.311512 22807 caffe.cpp:313] Batch 69, accuracy/top1 = 0.58
I0816 15:05:45.311534 22807 caffe.cpp:313] Batch 69, accuracy/top5 = 0.78
I0816 15:05:45.311537 22807 caffe.cpp:313] Batch 69, loss = 1.8509
I0816 15:05:45.374207 22807 caffe.cpp:313] Batch 70, accuracy/top1 = 0.48
I0816 15:05:45.374228 22807 caffe.cpp:313] Batch 70, accuracy/top5 = 0.76
I0816 15:05:45.374231 22807 caffe.cpp:313] Batch 70, loss = 2.21546
I0816 15:05:45.436954 22807 caffe.cpp:313] Batch 71, accuracy/top1 = 0.46
I0816 15:05:45.436976 22807 caffe.cpp:313] Batch 71, accuracy/top5 = 0.76
I0816 15:05:45.436980 22807 caffe.cpp:313] Batch 71, loss = 2.28032
I0816 15:05:45.500216 22807 caffe.cpp:313] Batch 72, accuracy/top1 = 0.64
I0816 15:05:45.500234 22807 caffe.cpp:313] Batch 72, accuracy/top5 = 0.84
I0816 15:05:45.500237 22807 caffe.cpp:313] Batch 72, loss = 1.58621
I0816 15:05:45.563081 22807 caffe.cpp:313] Batch 73, accuracy/top1 = 0.62
I0816 15:05:45.563102 22807 caffe.cpp:313] Batch 73, accuracy/top5 = 0.86
I0816 15:05:45.563105 22807 caffe.cpp:313] Batch 73, loss = 1.59345
I0816 15:05:45.626046 22807 caffe.cpp:313] Batch 74, accuracy/top1 = 0.58
I0816 15:05:45.626067 22807 caffe.cpp:313] Batch 74, accuracy/top5 = 0.82
I0816 15:05:45.626070 22807 caffe.cpp:313] Batch 74, loss = 1.67245
I0816 15:05:45.688786 22807 caffe.cpp:313] Batch 75, accuracy/top1 = 0.58
I0816 15:05:45.688807 22807 caffe.cpp:313] Batch 75, accuracy/top5 = 0.78
I0816 15:05:45.688809 22807 caffe.cpp:313] Batch 75, loss = 1.835
I0816 15:05:45.751644 22807 caffe.cpp:313] Batch 76, accuracy/top1 = 0.6
I0816 15:05:45.751662 22807 caffe.cpp:313] Batch 76, accuracy/top5 = 0.72
I0816 15:05:45.751665 22807 caffe.cpp:313] Batch 76, loss = 1.94013
I0816 15:05:45.814443 22807 caffe.cpp:313] Batch 77, accuracy/top1 = 0.6
I0816 15:05:45.814465 22807 caffe.cpp:313] Batch 77, accuracy/top5 = 0.86
I0816 15:05:45.814468 22807 caffe.cpp:313] Batch 77, loss = 1.54591
I0816 15:05:45.877210 22807 caffe.cpp:313] Batch 78, accuracy/top1 = 0.54
I0816 15:05:45.877231 22807 caffe.cpp:313] Batch 78, accuracy/top5 = 0.78
I0816 15:05:45.877235 22807 caffe.cpp:313] Batch 78, loss = 2.14768
I0816 15:05:45.939936 22807 caffe.cpp:313] Batch 79, accuracy/top1 = 0.74
I0816 15:05:45.939960 22807 caffe.cpp:313] Batch 79, accuracy/top5 = 0.88
I0816 15:05:45.939962 22807 caffe.cpp:313] Batch 79, loss = 1.26794
I0816 15:05:46.002833 22807 caffe.cpp:313] Batch 80, accuracy/top1 = 0.42
I0816 15:05:46.002854 22807 caffe.cpp:313] Batch 80, accuracy/top5 = 0.72
I0816 15:05:46.002857 22807 caffe.cpp:313] Batch 80, loss = 2.40467
I0816 15:05:46.065747 22807 caffe.cpp:313] Batch 81, accuracy/top1 = 0.68
I0816 15:05:46.065768 22807 caffe.cpp:313] Batch 81, accuracy/top5 = 0.8
I0816 15:05:46.065770 22807 caffe.cpp:313] Batch 81, loss = 1.7288
I0816 15:05:46.128756 22807 caffe.cpp:313] Batch 82, accuracy/top1 = 0.58
I0816 15:05:46.128777 22807 caffe.cpp:313] Batch 82, accuracy/top5 = 0.78
I0816 15:05:46.128782 22807 caffe.cpp:313] Batch 82, loss = 1.79066
I0816 15:05:46.191522 22807 caffe.cpp:313] Batch 83, accuracy/top1 = 0.56
I0816 15:05:46.191545 22807 caffe.cpp:313] Batch 83, accuracy/top5 = 0.72
I0816 15:05:46.191548 22807 caffe.cpp:313] Batch 83, loss = 2.24721
I0816 15:05:46.254344 22807 caffe.cpp:313] Batch 84, accuracy/top1 = 0.6
I0816 15:05:46.254366 22807 caffe.cpp:313] Batch 84, accuracy/top5 = 0.74
I0816 15:05:46.254369 22807 caffe.cpp:313] Batch 84, loss = 1.91548
I0816 15:05:46.317026 22807 caffe.cpp:313] Batch 85, accuracy/top1 = 0.74
I0816 15:05:46.317049 22807 caffe.cpp:313] Batch 85, accuracy/top5 = 0.92
I0816 15:05:46.317051 22807 caffe.cpp:313] Batch 85, loss = 1.19464
I0816 15:05:46.379951 22807 caffe.cpp:313] Batch 86, accuracy/top1 = 0.52
I0816 15:05:46.379972 22807 caffe.cpp:313] Batch 86, accuracy/top5 = 0.68
I0816 15:05:46.379976 22807 caffe.cpp:313] Batch 86, loss = 2.008
I0816 15:05:46.442885 22807 caffe.cpp:313] Batch 87, accuracy/top1 = 0.64
I0816 15:05:46.442906 22807 caffe.cpp:313] Batch 87, accuracy/top5 = 0.84
I0816 15:05:46.442910 22807 caffe.cpp:313] Batch 87, loss = 1.65714
I0816 15:05:46.506085 22807 caffe.cpp:313] Batch 88, accuracy/top1 = 0.66
I0816 15:05:46.506103 22807 caffe.cpp:313] Batch 88, accuracy/top5 = 0.82
I0816 15:05:46.506105 22807 caffe.cpp:313] Batch 88, loss = 1.51262
I0816 15:05:46.568979 22807 caffe.cpp:313] Batch 89, accuracy/top1 = 0.58
I0816 15:05:46.569001 22807 caffe.cpp:313] Batch 89, accuracy/top5 = 0.78
I0816 15:05:46.569005 22807 caffe.cpp:313] Batch 89, loss = 2.00651
I0816 15:05:46.631826 22807 caffe.cpp:313] Batch 90, accuracy/top1 = 0.66
I0816 15:05:46.631849 22807 caffe.cpp:313] Batch 90, accuracy/top5 = 0.86
I0816 15:05:46.631851 22807 caffe.cpp:313] Batch 90, loss = 1.34568
I0816 15:05:46.694743 22807 caffe.cpp:313] Batch 91, accuracy/top1 = 0.6
I0816 15:05:46.694766 22807 caffe.cpp:313] Batch 91, accuracy/top5 = 0.72
I0816 15:05:46.694768 22807 caffe.cpp:313] Batch 91, loss = 2.09194
I0816 15:05:46.757530 22807 caffe.cpp:313] Batch 92, accuracy/top1 = 0.58
I0816 15:05:46.757552 22807 caffe.cpp:313] Batch 92, accuracy/top5 = 0.72
I0816 15:05:46.757555 22807 caffe.cpp:313] Batch 92, loss = 2.19914
I0816 15:05:46.820332 22807 caffe.cpp:313] Batch 93, accuracy/top1 = 0.62
I0816 15:05:46.820353 22807 caffe.cpp:313] Batch 93, accuracy/top5 = 0.88
I0816 15:05:46.820356 22807 caffe.cpp:313] Batch 93, loss = 1.79376
I0816 15:05:46.883182 22807 caffe.cpp:313] Batch 94, accuracy/top1 = 0.7
I0816 15:05:46.883200 22807 caffe.cpp:313] Batch 94, accuracy/top5 = 0.9
I0816 15:05:46.883203 22807 caffe.cpp:313] Batch 94, loss = 1.20508
I0816 15:05:46.946321 22807 caffe.cpp:313] Batch 95, accuracy/top1 = 0.6
I0816 15:05:46.946341 22807 caffe.cpp:313] Batch 95, accuracy/top5 = 0.76
I0816 15:05:46.946344 22807 caffe.cpp:313] Batch 95, loss = 1.99288
I0816 15:05:47.009377 22807 caffe.cpp:313] Batch 96, accuracy/top1 = 0.5
I0816 15:05:47.009397 22807 caffe.cpp:313] Batch 96, accuracy/top5 = 0.7
I0816 15:05:47.009400 22807 caffe.cpp:313] Batch 96, loss = 2.1504
I0816 15:05:47.072315 22807 caffe.cpp:313] Batch 97, accuracy/top1 = 0.68
I0816 15:05:47.072337 22807 caffe.cpp:313] Batch 97, accuracy/top5 = 0.84
I0816 15:05:47.072340 22807 caffe.cpp:313] Batch 97, loss = 1.57015
I0816 15:05:47.135062 22807 caffe.cpp:313] Batch 98, accuracy/top1 = 0.5
I0816 15:05:47.135084 22807 caffe.cpp:313] Batch 98, accuracy/top5 = 0.9
I0816 15:05:47.135087 22807 caffe.cpp:313] Batch 98, loss = 1.80117
I0816 15:05:47.197861 22807 caffe.cpp:313] Batch 99, accuracy/top1 = 0.62
I0816 15:05:47.197883 22807 caffe.cpp:313] Batch 99, accuracy/top5 = 0.82
I0816 15:05:47.197886 22807 caffe.cpp:313] Batch 99, loss = 1.72545
I0816 15:05:47.260601 22807 caffe.cpp:313] Batch 100, accuracy/top1 = 0.64
I0816 15:05:47.260622 22807 caffe.cpp:313] Batch 100, accuracy/top5 = 0.82
I0816 15:05:47.260625 22807 caffe.cpp:313] Batch 100, loss = 1.41848
I0816 15:05:47.323352 22807 caffe.cpp:313] Batch 101, accuracy/top1 = 0.68
I0816 15:05:47.323374 22807 caffe.cpp:313] Batch 101, accuracy/top5 = 0.86
I0816 15:05:47.323377 22807 caffe.cpp:313] Batch 101, loss = 1.52173
I0816 15:05:47.386158 22807 caffe.cpp:313] Batch 102, accuracy/top1 = 0.56
I0816 15:05:47.386180 22807 caffe.cpp:313] Batch 102, accuracy/top5 = 0.74
I0816 15:05:47.386183 22807 caffe.cpp:313] Batch 102, loss = 2.61662
I0816 15:05:47.448988 22807 caffe.cpp:313] Batch 103, accuracy/top1 = 0.7
I0816 15:05:47.449012 22807 caffe.cpp:313] Batch 103, accuracy/top5 = 0.92
I0816 15:05:47.449014 22807 caffe.cpp:313] Batch 103, loss = 1.37837
I0816 15:05:47.512131 22807 caffe.cpp:313] Batch 104, accuracy/top1 = 0.56
I0816 15:05:47.512150 22807 caffe.cpp:313] Batch 104, accuracy/top5 = 0.84
I0816 15:05:47.512152 22807 caffe.cpp:313] Batch 104, loss = 1.70824
I0816 15:05:47.574996 22807 caffe.cpp:313] Batch 105, accuracy/top1 = 0.58
I0816 15:05:47.575018 22807 caffe.cpp:313] Batch 105, accuracy/top5 = 0.74
I0816 15:05:47.575021 22807 caffe.cpp:313] Batch 105, loss = 2.01038
I0816 15:05:47.637868 22807 caffe.cpp:313] Batch 106, accuracy/top1 = 0.54
I0816 15:05:47.637892 22807 caffe.cpp:313] Batch 106, accuracy/top5 = 0.8
I0816 15:05:47.637894 22807 caffe.cpp:313] Batch 106, loss = 1.81745
I0816 15:05:47.700645 22807 caffe.cpp:313] Batch 107, accuracy/top1 = 0.44
I0816 15:05:47.700667 22807 caffe.cpp:313] Batch 107, accuracy/top5 = 0.72
I0816 15:05:47.700670 22807 caffe.cpp:313] Batch 107, loss = 2.0854
I0816 15:05:47.763589 22807 caffe.cpp:313] Batch 108, accuracy/top1 = 0.56
I0816 15:05:47.763607 22807 caffe.cpp:313] Batch 108, accuracy/top5 = 0.86
I0816 15:05:47.763609 22807 caffe.cpp:313] Batch 108, loss = 1.55801
I0816 15:05:47.826545 22807 caffe.cpp:313] Batch 109, accuracy/top1 = 0.66
I0816 15:05:47.826567 22807 caffe.cpp:313] Batch 109, accuracy/top5 = 0.76
I0816 15:05:47.826571 22807 caffe.cpp:313] Batch 109, loss = 1.4245
I0816 15:05:47.889415 22807 caffe.cpp:313] Batch 110, accuracy/top1 = 0.58
I0816 15:05:47.889437 22807 caffe.cpp:313] Batch 110, accuracy/top5 = 0.74
I0816 15:05:47.889441 22807 caffe.cpp:313] Batch 110, loss = 2.19073
I0816 15:05:47.952209 22807 caffe.cpp:313] Batch 111, accuracy/top1 = 0.5
I0816 15:05:47.952231 22807 caffe.cpp:313] Batch 111, accuracy/top5 = 0.82
I0816 15:05:47.952234 22807 caffe.cpp:313] Batch 111, loss = 2.02758
I0816 15:05:48.015148 22807 caffe.cpp:313] Batch 112, accuracy/top1 = 0.6
I0816 15:05:48.015169 22807 caffe.cpp:313] Batch 112, accuracy/top5 = 0.76
I0816 15:05:48.015172 22807 caffe.cpp:313] Batch 112, loss = 2.03926
I0816 15:05:48.078130 22807 caffe.cpp:313] Batch 113, accuracy/top1 = 0.58
I0816 15:05:48.078152 22807 caffe.cpp:313] Batch 113, accuracy/top5 = 0.88
I0816 15:05:48.078155 22807 caffe.cpp:313] Batch 113, loss = 1.37475
I0816 15:05:48.140964 22807 caffe.cpp:313] Batch 114, accuracy/top1 = 0.6
I0816 15:05:48.140986 22807 caffe.cpp:313] Batch 114, accuracy/top5 = 0.8
I0816 15:05:48.140990 22807 caffe.cpp:313] Batch 114, loss = 1.72811
I0816 15:05:48.203850 22807 caffe.cpp:313] Batch 115, accuracy/top1 = 0.58
I0816 15:05:48.203871 22807 caffe.cpp:313] Batch 115, accuracy/top5 = 0.82
I0816 15:05:48.203874 22807 caffe.cpp:313] Batch 115, loss = 1.89567
I0816 15:05:48.266566 22807 caffe.cpp:313] Batch 116, accuracy/top1 = 0.5
I0816 15:05:48.266588 22807 caffe.cpp:313] Batch 116, accuracy/top5 = 0.76
I0816 15:05:48.266592 22807 caffe.cpp:313] Batch 116, loss = 1.95062
I0816 15:05:48.329277 22807 caffe.cpp:313] Batch 117, accuracy/top1 = 0.5
I0816 15:05:48.329298 22807 caffe.cpp:313] Batch 117, accuracy/top5 = 0.84
I0816 15:05:48.329301 22807 caffe.cpp:313] Batch 117, loss = 2.07621
I0816 15:05:48.392138 22807 caffe.cpp:313] Batch 118, accuracy/top1 = 0.44
I0816 15:05:48.392160 22807 caffe.cpp:313] Batch 118, accuracy/top5 = 0.72
I0816 15:05:48.392163 22807 caffe.cpp:313] Batch 118, loss = 2.75372
I0816 15:05:48.455051 22807 caffe.cpp:313] Batch 119, accuracy/top1 = 0.62
I0816 15:05:48.455073 22807 caffe.cpp:313] Batch 119, accuracy/top5 = 0.86
I0816 15:05:48.455076 22807 caffe.cpp:313] Batch 119, loss = 1.53145
I0816 15:05:48.518167 22807 caffe.cpp:313] Batch 120, accuracy/top1 = 0.56
I0816 15:05:48.518184 22807 caffe.cpp:313] Batch 120, accuracy/top5 = 0.84
I0816 15:05:48.518187 22807 caffe.cpp:313] Batch 120, loss = 1.95814
I0816 15:05:48.581055 22807 caffe.cpp:313] Batch 121, accuracy/top1 = 0.62
I0816 15:05:48.581077 22807 caffe.cpp:313] Batch 121, accuracy/top5 = 0.82
I0816 15:05:48.581080 22807 caffe.cpp:313] Batch 121, loss = 1.73875
I0816 15:05:48.643930 22807 caffe.cpp:313] Batch 122, accuracy/top1 = 0.56
I0816 15:05:48.643954 22807 caffe.cpp:313] Batch 122, accuracy/top5 = 0.76
I0816 15:05:48.643956 22807 caffe.cpp:313] Batch 122, loss = 2.47094
I0816 15:05:48.706749 22807 caffe.cpp:313] Batch 123, accuracy/top1 = 0.52
I0816 15:05:48.706771 22807 caffe.cpp:313] Batch 123, accuracy/top5 = 0.78
I0816 15:05:48.706789 22807 caffe.cpp:313] Batch 123, loss = 2.10615
I0816 15:05:48.769630 22807 caffe.cpp:313] Batch 124, accuracy/top1 = 0.62
I0816 15:05:48.769652 22807 caffe.cpp:313] Batch 124, accuracy/top5 = 0.8
I0816 15:05:48.769655 22807 caffe.cpp:313] Batch 124, loss = 1.72903
I0816 15:05:48.832348 22807 caffe.cpp:313] Batch 125, accuracy/top1 = 0.62
I0816 15:05:48.832370 22807 caffe.cpp:313] Batch 125, accuracy/top5 = 0.9
I0816 15:05:48.832373 22807 caffe.cpp:313] Batch 125, loss = 1.51917
I0816 15:05:48.895156 22807 caffe.cpp:313] Batch 126, accuracy/top1 = 0.48
I0816 15:05:48.895179 22807 caffe.cpp:313] Batch 126, accuracy/top5 = 0.82
I0816 15:05:48.895181 22807 caffe.cpp:313] Batch 126, loss = 1.89502
I0816 15:05:48.957989 22807 caffe.cpp:313] Batch 127, accuracy/top1 = 0.48
I0816 15:05:48.958010 22807 caffe.cpp:313] Batch 127, accuracy/top5 = 0.8
I0816 15:05:48.958014 22807 caffe.cpp:313] Batch 127, loss = 2.14557
I0816 15:05:49.020819 22807 caffe.cpp:313] Batch 128, accuracy/top1 = 0.64
I0816 15:05:49.020838 22807 caffe.cpp:313] Batch 128, accuracy/top5 = 0.84
I0816 15:05:49.020841 22807 caffe.cpp:313] Batch 128, loss = 1.54127
I0816 15:05:49.083835 22807 caffe.cpp:313] Batch 129, accuracy/top1 = 0.56
I0816 15:05:49.083855 22807 caffe.cpp:313] Batch 129, accuracy/top5 = 0.84
I0816 15:05:49.083860 22807 caffe.cpp:313] Batch 129, loss = 1.67755
I0816 15:05:49.146970 22807 caffe.cpp:313] Batch 130, accuracy/top1 = 0.56
I0816 15:05:49.146991 22807 caffe.cpp:313] Batch 130, accuracy/top5 = 0.84
I0816 15:05:49.146996 22807 caffe.cpp:313] Batch 130, loss = 1.67688
I0816 15:05:49.209996 22807 caffe.cpp:313] Batch 131, accuracy/top1 = 0.64
I0816 15:05:49.210017 22807 caffe.cpp:313] Batch 131, accuracy/top5 = 0.86
I0816 15:05:49.210022 22807 caffe.cpp:313] Batch 131, loss = 1.46809
I0816 15:05:49.272773 22807 caffe.cpp:313] Batch 132, accuracy/top1 = 0.68
I0816 15:05:49.272795 22807 caffe.cpp:313] Batch 132, accuracy/top5 = 0.82
I0816 15:05:49.272799 22807 caffe.cpp:313] Batch 132, loss = 1.89112
I0816 15:05:49.335675 22807 caffe.cpp:313] Batch 133, accuracy/top1 = 0.56
I0816 15:05:49.335697 22807 caffe.cpp:313] Batch 133, accuracy/top5 = 0.8
I0816 15:05:49.335701 22807 caffe.cpp:313] Batch 133, loss = 2.0714
I0816 15:05:49.398603 22807 caffe.cpp:313] Batch 134, accuracy/top1 = 0.68
I0816 15:05:49.398625 22807 caffe.cpp:313] Batch 134, accuracy/top5 = 0.86
I0816 15:05:49.398629 22807 caffe.cpp:313] Batch 134, loss = 1.4607
I0816 15:05:49.461591 22807 caffe.cpp:313] Batch 135, accuracy/top1 = 0.5
I0816 15:05:49.461613 22807 caffe.cpp:313] Batch 135, accuracy/top5 = 0.82
I0816 15:05:49.461617 22807 caffe.cpp:313] Batch 135, loss = 1.80117
I0816 15:05:49.527462 22807 caffe.cpp:313] Batch 136, accuracy/top1 = 0.5
I0816 15:05:49.527482 22807 caffe.cpp:313] Batch 136, accuracy/top5 = 0.72
I0816 15:05:49.527484 22807 caffe.cpp:313] Batch 136, loss = 2.17206
I0816 15:05:49.590324 22807 caffe.cpp:313] Batch 137, accuracy/top1 = 0.58
I0816 15:05:49.590348 22807 caffe.cpp:313] Batch 137, accuracy/top5 = 0.88
I0816 15:05:49.590350 22807 caffe.cpp:313] Batch 137, loss = 1.46629
I0816 15:05:49.653095 22807 caffe.cpp:313] Batch 138, accuracy/top1 = 0.64
I0816 15:05:49.653117 22807 caffe.cpp:313] Batch 138, accuracy/top5 = 0.84
I0816 15:05:49.653121 22807 caffe.cpp:313] Batch 138, loss = 1.54129
I0816 15:05:49.715912 22807 caffe.cpp:313] Batch 139, accuracy/top1 = 0.62
I0816 15:05:49.715935 22807 caffe.cpp:313] Batch 139, accuracy/top5 = 0.74
I0816 15:05:49.715939 22807 caffe.cpp:313] Batch 139, loss = 2.1195
I0816 15:05:49.778843 22807 caffe.cpp:313] Batch 140, accuracy/top1 = 0.58
I0816 15:05:49.778862 22807 caffe.cpp:313] Batch 140, accuracy/top5 = 0.74
I0816 15:05:49.778865 22807 caffe.cpp:313] Batch 140, loss = 2.06111
I0816 15:05:49.841774 22807 caffe.cpp:313] Batch 141, accuracy/top1 = 0.58
I0816 15:05:49.841797 22807 caffe.cpp:313] Batch 141, accuracy/top5 = 0.86
I0816 15:05:49.841800 22807 caffe.cpp:313] Batch 141, loss = 1.45673
I0816 15:05:49.904676 22807 caffe.cpp:313] Batch 142, accuracy/top1 = 0.58
I0816 15:05:49.904712 22807 caffe.cpp:313] Batch 142, accuracy/top5 = 0.8
I0816 15:05:49.904716 22807 caffe.cpp:313] Batch 142, loss = 1.91851
I0816 15:05:49.967506 22807 caffe.cpp:313] Batch 143, accuracy/top1 = 0.52
I0816 15:05:49.967528 22807 caffe.cpp:313] Batch 143, accuracy/top5 = 0.76
I0816 15:05:49.967531 22807 caffe.cpp:313] Batch 143, loss = 2.18347
I0816 15:05:50.030385 22807 caffe.cpp:313] Batch 144, accuracy/top1 = 0.56
I0816 15:05:50.030405 22807 caffe.cpp:313] Batch 144, accuracy/top5 = 0.84
I0816 15:05:50.030408 22807 caffe.cpp:313] Batch 144, loss = 1.79649
I0816 15:05:50.093327 22807 caffe.cpp:313] Batch 145, accuracy/top1 = 0.7
I0816 15:05:50.093350 22807 caffe.cpp:313] Batch 145, accuracy/top5 = 0.88
I0816 15:05:50.093353 22807 caffe.cpp:313] Batch 145, loss = 1.56073
I0816 15:05:50.156143 22807 caffe.cpp:313] Batch 146, accuracy/top1 = 0.6
I0816 15:05:50.156165 22807 caffe.cpp:313] Batch 146, accuracy/top5 = 0.88
I0816 15:05:50.156169 22807 caffe.cpp:313] Batch 146, loss = 1.45853
I0816 15:05:50.218911 22807 caffe.cpp:313] Batch 147, accuracy/top1 = 0.62
I0816 15:05:50.218933 22807 caffe.cpp:313] Batch 147, accuracy/top5 = 0.9
I0816 15:05:50.218936 22807 caffe.cpp:313] Batch 147, loss = 1.38109
I0816 15:05:50.281793 22807 caffe.cpp:313] Batch 148, accuracy/top1 = 0.54
I0816 15:05:50.281816 22807 caffe.cpp:313] Batch 148, accuracy/top5 = 0.76
I0816 15:05:50.281819 22807 caffe.cpp:313] Batch 148, loss = 2.09832
I0816 15:05:50.344609 22807 caffe.cpp:313] Batch 149, accuracy/top1 = 0.62
I0816 15:05:50.344630 22807 caffe.cpp:313] Batch 149, accuracy/top5 = 0.88
I0816 15:05:50.344633 22807 caffe.cpp:313] Batch 149, loss = 1.38723
I0816 15:05:50.407371 22807 caffe.cpp:313] Batch 150, accuracy/top1 = 0.6
I0816 15:05:50.407392 22807 caffe.cpp:313] Batch 150, accuracy/top5 = 0.8
I0816 15:05:50.407395 22807 caffe.cpp:313] Batch 150, loss = 1.92372
I0816 15:05:50.470175 22807 caffe.cpp:313] Batch 151, accuracy/top1 = 0.62
I0816 15:05:50.470197 22807 caffe.cpp:313] Batch 151, accuracy/top5 = 0.84
I0816 15:05:50.470201 22807 caffe.cpp:313] Batch 151, loss = 1.50628
I0816 15:05:50.533442 22807 caffe.cpp:313] Batch 152, accuracy/top1 = 0.58
I0816 15:05:50.533459 22807 caffe.cpp:313] Batch 152, accuracy/top5 = 0.8
I0816 15:05:50.533463 22807 caffe.cpp:313] Batch 152, loss = 1.83332
I0816 15:05:50.596307 22807 caffe.cpp:313] Batch 153, accuracy/top1 = 0.54
I0816 15:05:50.596328 22807 caffe.cpp:313] Batch 153, accuracy/top5 = 0.82
I0816 15:05:50.596333 22807 caffe.cpp:313] Batch 153, loss = 2.1135
I0816 15:05:50.659127 22807 caffe.cpp:313] Batch 154, accuracy/top1 = 0.62
I0816 15:05:50.659149 22807 caffe.cpp:313] Batch 154, accuracy/top5 = 0.82
I0816 15:05:50.659153 22807 caffe.cpp:313] Batch 154, loss = 1.44758
I0816 15:05:50.721959 22807 caffe.cpp:313] Batch 155, accuracy/top1 = 0.6
I0816 15:05:50.721982 22807 caffe.cpp:313] Batch 155, accuracy/top5 = 0.82
I0816 15:05:50.721985 22807 caffe.cpp:313] Batch 155, loss = 1.70741
I0816 15:05:50.784785 22807 caffe.cpp:313] Batch 156, accuracy/top1 = 0.66
I0816 15:05:50.784807 22807 caffe.cpp:313] Batch 156, accuracy/top5 = 0.84
I0816 15:05:50.784811 22807 caffe.cpp:313] Batch 156, loss = 1.80187
I0816 15:05:50.847650 22807 caffe.cpp:313] Batch 157, accuracy/top1 = 0.54
I0816 15:05:50.847671 22807 caffe.cpp:313] Batch 157, accuracy/top5 = 0.84
I0816 15:05:50.847674 22807 caffe.cpp:313] Batch 157, loss = 1.61624
I0816 15:05:50.910419 22807 caffe.cpp:313] Batch 158, accuracy/top1 = 0.68
I0816 15:05:50.910441 22807 caffe.cpp:313] Batch 158, accuracy/top5 = 0.86
I0816 15:05:50.910444 22807 caffe.cpp:313] Batch 158, loss = 1.57424
I0816 15:05:50.973208 22807 caffe.cpp:313] Batch 159, accuracy/top1 = 0.56
I0816 15:05:50.973228 22807 caffe.cpp:313] Batch 159, accuracy/top5 = 0.78
I0816 15:05:50.973232 22807 caffe.cpp:313] Batch 159, loss = 1.95778
I0816 15:05:51.036072 22807 caffe.cpp:313] Batch 160, accuracy/top1 = 0.68
I0816 15:05:51.036088 22807 caffe.cpp:313] Batch 160, accuracy/top5 = 0.84
I0816 15:05:51.036092 22807 caffe.cpp:313] Batch 160, loss = 1.63619
I0816 15:05:51.098798 22807 caffe.cpp:313] Batch 161, accuracy/top1 = 0.62
I0816 15:05:51.098832 22807 caffe.cpp:313] Batch 161, accuracy/top5 = 0.78
I0816 15:05:51.098836 22807 caffe.cpp:313] Batch 161, loss = 2.03289
I0816 15:05:51.161619 22807 caffe.cpp:313] Batch 162, accuracy/top1 = 0.56
I0816 15:05:51.161638 22807 caffe.cpp:313] Batch 162, accuracy/top5 = 0.82
I0816 15:05:51.161641 22807 caffe.cpp:313] Batch 162, loss = 1.73111
I0816 15:05:51.224720 22807 caffe.cpp:313] Batch 163, accuracy/top1 = 0.6
I0816 15:05:51.224740 22807 caffe.cpp:313] Batch 163, accuracy/top5 = 0.86
I0816 15:05:51.224742 22807 caffe.cpp:313] Batch 163, loss = 1.65211
I0816 15:05:51.287734 22807 caffe.cpp:313] Batch 164, accuracy/top1 = 0.64
I0816 15:05:51.287755 22807 caffe.cpp:313] Batch 164, accuracy/top5 = 0.8
I0816 15:05:51.287757 22807 caffe.cpp:313] Batch 164, loss = 1.56658
I0816 15:05:51.350533 22807 caffe.cpp:313] Batch 165, accuracy/top1 = 0.68
I0816 15:05:51.350556 22807 caffe.cpp:313] Batch 165, accuracy/top5 = 0.88
I0816 15:05:51.350559 22807 caffe.cpp:313] Batch 165, loss = 1.19453
I0816 15:05:51.413372 22807 caffe.cpp:313] Batch 166, accuracy/top1 = 0.46
I0816 15:05:51.413394 22807 caffe.cpp:313] Batch 166, accuracy/top5 = 0.78
I0816 15:05:51.413398 22807 caffe.cpp:313] Batch 166, loss = 2.01931
I0816 15:05:51.476286 22807 caffe.cpp:313] Batch 167, accuracy/top1 = 0.62
I0816 15:05:51.476307 22807 caffe.cpp:313] Batch 167, accuracy/top5 = 0.8
I0816 15:05:51.476310 22807 caffe.cpp:313] Batch 167, loss = 1.5605
I0816 15:05:51.539430 22807 caffe.cpp:313] Batch 168, accuracy/top1 = 0.68
I0816 15:05:51.539448 22807 caffe.cpp:313] Batch 168, accuracy/top5 = 0.9
I0816 15:05:51.539451 22807 caffe.cpp:313] Batch 168, loss = 1.35431
I0816 15:05:51.602284 22807 caffe.cpp:313] Batch 169, accuracy/top1 = 0.7
I0816 15:05:51.602305 22807 caffe.cpp:313] Batch 169, accuracy/top5 = 0.86
I0816 15:05:51.602309 22807 caffe.cpp:313] Batch 169, loss = 1.34701
I0816 15:05:51.665189 22807 caffe.cpp:313] Batch 170, accuracy/top1 = 0.58
I0816 15:05:51.665211 22807 caffe.cpp:313] Batch 170, accuracy/top5 = 0.76
I0816 15:05:51.665215 22807 caffe.cpp:313] Batch 170, loss = 1.82011
I0816 15:05:51.728044 22807 caffe.cpp:313] Batch 171, accuracy/top1 = 0.56
I0816 15:05:51.728065 22807 caffe.cpp:313] Batch 171, accuracy/top5 = 0.88
I0816 15:05:51.728068 22807 caffe.cpp:313] Batch 171, loss = 1.8218
I0816 15:05:51.790866 22807 caffe.cpp:313] Batch 172, accuracy/top1 = 0.68
I0816 15:05:51.790889 22807 caffe.cpp:313] Batch 172, accuracy/top5 = 0.86
I0816 15:05:51.790891 22807 caffe.cpp:313] Batch 172, loss = 1.59553
I0816 15:05:51.853729 22807 caffe.cpp:313] Batch 173, accuracy/top1 = 0.6
I0816 15:05:51.853749 22807 caffe.cpp:313] Batch 173, accuracy/top5 = 0.78
I0816 15:05:51.853752 22807 caffe.cpp:313] Batch 173, loss = 1.92621
I0816 15:05:51.916517 22807 caffe.cpp:313] Batch 174, accuracy/top1 = 0.68
I0816 15:05:51.916539 22807 caffe.cpp:313] Batch 174, accuracy/top5 = 0.8
I0816 15:05:51.916543 22807 caffe.cpp:313] Batch 174, loss = 1.80685
I0816 15:05:51.979343 22807 caffe.cpp:313] Batch 175, accuracy/top1 = 0.58
I0816 15:05:51.979367 22807 caffe.cpp:313] Batch 175, accuracy/top5 = 0.76
I0816 15:05:51.979369 22807 caffe.cpp:313] Batch 175, loss = 1.95409
I0816 15:05:52.042220 22807 caffe.cpp:313] Batch 176, accuracy/top1 = 0.48
I0816 15:05:52.042237 22807 caffe.cpp:313] Batch 176, accuracy/top5 = 0.74
I0816 15:05:52.042240 22807 caffe.cpp:313] Batch 176, loss = 2.15398
I0816 15:05:52.105121 22807 caffe.cpp:313] Batch 177, accuracy/top1 = 0.54
I0816 15:05:52.105144 22807 caffe.cpp:313] Batch 177, accuracy/top5 = 0.76
I0816 15:05:52.105147 22807 caffe.cpp:313] Batch 177, loss = 1.95769
I0816 15:05:52.167824 22807 caffe.cpp:313] Batch 178, accuracy/top1 = 0.54
I0816 15:05:52.167845 22807 caffe.cpp:313] Batch 178, accuracy/top5 = 0.84
I0816 15:05:52.167848 22807 caffe.cpp:313] Batch 178, loss = 1.80211
I0816 15:05:52.230732 22807 caffe.cpp:313] Batch 179, accuracy/top1 = 0.66
I0816 15:05:52.230754 22807 caffe.cpp:313] Batch 179, accuracy/top5 = 0.84
I0816 15:05:52.230757 22807 caffe.cpp:313] Batch 179, loss = 1.66427
I0816 15:05:52.293625 22807 caffe.cpp:313] Batch 180, accuracy/top1 = 0.6
I0816 15:05:52.293648 22807 caffe.cpp:313] Batch 180, accuracy/top5 = 0.82
I0816 15:05:52.293650 22807 caffe.cpp:313] Batch 180, loss = 1.8827
I0816 15:05:52.356416 22807 caffe.cpp:313] Batch 181, accuracy/top1 = 0.52
I0816 15:05:52.356437 22807 caffe.cpp:313] Batch 181, accuracy/top5 = 0.72
I0816 15:05:52.356441 22807 caffe.cpp:313] Batch 181, loss = 2.06531
I0816 15:05:52.419119 22807 caffe.cpp:313] Batch 182, accuracy/top1 = 0.54
I0816 15:05:52.419142 22807 caffe.cpp:313] Batch 182, accuracy/top5 = 0.8
I0816 15:05:52.419144 22807 caffe.cpp:313] Batch 182, loss = 2.20565
I0816 15:05:52.482023 22807 caffe.cpp:313] Batch 183, accuracy/top1 = 0.48
I0816 15:05:52.482045 22807 caffe.cpp:313] Batch 183, accuracy/top5 = 0.76
I0816 15:05:52.482048 22807 caffe.cpp:313] Batch 183, loss = 2.19559
I0816 15:05:52.545222 22807 caffe.cpp:313] Batch 184, accuracy/top1 = 0.64
I0816 15:05:52.545243 22807 caffe.cpp:313] Batch 184, accuracy/top5 = 0.88
I0816 15:05:52.545246 22807 caffe.cpp:313] Batch 184, loss = 1.70613
I0816 15:05:52.608052 22807 caffe.cpp:313] Batch 185, accuracy/top1 = 0.56
I0816 15:05:52.608073 22807 caffe.cpp:313] Batch 185, accuracy/top5 = 0.8
I0816 15:05:52.608077 22807 caffe.cpp:313] Batch 185, loss = 1.96364
I0816 15:05:52.670902 22807 caffe.cpp:313] Batch 186, accuracy/top1 = 0.56
I0816 15:05:52.670924 22807 caffe.cpp:313] Batch 186, accuracy/top5 = 0.84
I0816 15:05:52.670928 22807 caffe.cpp:313] Batch 186, loss = 1.57612
I0816 15:05:52.733626 22807 caffe.cpp:313] Batch 187, accuracy/top1 = 0.56
I0816 15:05:52.733649 22807 caffe.cpp:313] Batch 187, accuracy/top5 = 0.8
I0816 15:05:52.733651 22807 caffe.cpp:313] Batch 187, loss = 1.80949
I0816 15:05:52.796521 22807 caffe.cpp:313] Batch 188, accuracy/top1 = 0.6
I0816 15:05:52.796543 22807 caffe.cpp:313] Batch 188, accuracy/top5 = 0.8
I0816 15:05:52.796546 22807 caffe.cpp:313] Batch 188, loss = 1.59293
I0816 15:05:52.859397 22807 caffe.cpp:313] Batch 189, accuracy/top1 = 0.58
I0816 15:05:52.859419 22807 caffe.cpp:313] Batch 189, accuracy/top5 = 0.78
I0816 15:05:52.859422 22807 caffe.cpp:313] Batch 189, loss = 1.99374
I0816 15:05:52.922310 22807 caffe.cpp:313] Batch 190, accuracy/top1 = 0.64
I0816 15:05:52.922333 22807 caffe.cpp:313] Batch 190, accuracy/top5 = 0.88
I0816 15:05:52.922335 22807 caffe.cpp:313] Batch 190, loss = 1.4638
I0816 15:05:52.985013 22807 caffe.cpp:313] Batch 191, accuracy/top1 = 0.5
I0816 15:05:52.985034 22807 caffe.cpp:313] Batch 191, accuracy/top5 = 0.74
I0816 15:05:52.985038 22807 caffe.cpp:313] Batch 191, loss = 2.28254
I0816 15:05:53.047773 22807 caffe.cpp:313] Batch 192, accuracy/top1 = 0.52
I0816 15:05:53.047791 22807 caffe.cpp:313] Batch 192, accuracy/top5 = 0.82
I0816 15:05:53.047793 22807 caffe.cpp:313] Batch 192, loss = 1.91659
I0816 15:05:53.110642 22807 caffe.cpp:313] Batch 193, accuracy/top1 = 0.58
I0816 15:05:53.110663 22807 caffe.cpp:313] Batch 193, accuracy/top5 = 0.82
I0816 15:05:53.110666 22807 caffe.cpp:313] Batch 193, loss = 1.73582
I0816 15:05:53.173437 22807 caffe.cpp:313] Batch 194, accuracy/top1 = 0.62
I0816 15:05:53.173460 22807 caffe.cpp:313] Batch 194, accuracy/top5 = 0.84
I0816 15:05:53.173462 22807 caffe.cpp:313] Batch 194, loss = 1.56504
I0816 15:05:53.236176 22807 caffe.cpp:313] Batch 195, accuracy/top1 = 0.62
I0816 15:05:53.236198 22807 caffe.cpp:313] Batch 195, accuracy/top5 = 0.8
I0816 15:05:53.236202 22807 caffe.cpp:313] Batch 195, loss = 1.65209
I0816 15:05:53.299123 22807 caffe.cpp:313] Batch 196, accuracy/top1 = 0.7
I0816 15:05:53.299141 22807 caffe.cpp:313] Batch 196, accuracy/top5 = 0.84
I0816 15:05:53.299144 22807 caffe.cpp:313] Batch 196, loss = 1.23164
I0816 15:05:53.362196 22807 caffe.cpp:313] Batch 197, accuracy/top1 = 0.62
I0816 15:05:53.362215 22807 caffe.cpp:313] Batch 197, accuracy/top5 = 0.88
I0816 15:05:53.362218 22807 caffe.cpp:313] Batch 197, loss = 1.53838
I0816 15:05:53.425117 22807 caffe.cpp:313] Batch 198, accuracy/top1 = 0.6
I0816 15:05:53.425137 22807 caffe.cpp:313] Batch 198, accuracy/top5 = 0.84
I0816 15:05:53.425148 22807 caffe.cpp:313] Batch 198, loss = 1.78324
I0816 15:05:53.487910 22807 caffe.cpp:313] Batch 199, accuracy/top1 = 0.68
I0816 15:05:53.487932 22807 caffe.cpp:313] Batch 199, accuracy/top5 = 0.82
I0816 15:05:53.487936 22807 caffe.cpp:313] Batch 199, loss = 1.32253
I0816 15:05:53.551064 22807 caffe.cpp:313] Batch 200, accuracy/top1 = 0.62
I0816 15:05:53.551080 22807 caffe.cpp:313] Batch 200, accuracy/top5 = 0.82
I0816 15:05:53.551084 22807 caffe.cpp:313] Batch 200, loss = 1.71124
I0816 15:05:53.613940 22807 caffe.cpp:313] Batch 201, accuracy/top1 = 0.44
I0816 15:05:53.613961 22807 caffe.cpp:313] Batch 201, accuracy/top5 = 0.74
I0816 15:05:53.613965 22807 caffe.cpp:313] Batch 201, loss = 2.16037
I0816 15:05:53.676899 22807 caffe.cpp:313] Batch 202, accuracy/top1 = 0.48
I0816 15:05:53.676920 22807 caffe.cpp:313] Batch 202, accuracy/top5 = 0.84
I0816 15:05:53.676924 22807 caffe.cpp:313] Batch 202, loss = 1.91242
I0816 15:05:53.739806 22807 caffe.cpp:313] Batch 203, accuracy/top1 = 0.64
I0816 15:05:53.739830 22807 caffe.cpp:313] Batch 203, accuracy/top5 = 0.82
I0816 15:05:53.739832 22807 caffe.cpp:313] Batch 203, loss = 1.64314
I0816 15:05:53.802695 22807 caffe.cpp:313] Batch 204, accuracy/top1 = 0.7
I0816 15:05:53.802717 22807 caffe.cpp:313] Batch 204, accuracy/top5 = 0.86
I0816 15:05:53.802721 22807 caffe.cpp:313] Batch 204, loss = 1.40118
I0816 15:05:53.865571 22807 caffe.cpp:313] Batch 205, accuracy/top1 = 0.54
I0816 15:05:53.865587 22807 caffe.cpp:313] Batch 205, accuracy/top5 = 0.86
I0816 15:05:53.865591 22807 caffe.cpp:313] Batch 205, loss = 1.66645
I0816 15:05:53.928539 22807 caffe.cpp:313] Batch 206, accuracy/top1 = 0.52
I0816 15:05:53.928561 22807 caffe.cpp:313] Batch 206, accuracy/top5 = 0.86
I0816 15:05:53.928565 22807 caffe.cpp:313] Batch 206, loss = 1.67079
I0816 15:05:53.991348 22807 caffe.cpp:313] Batch 207, accuracy/top1 = 0.54
I0816 15:05:53.991369 22807 caffe.cpp:313] Batch 207, accuracy/top5 = 0.82
I0816 15:05:53.991371 22807 caffe.cpp:313] Batch 207, loss = 1.86323
I0816 15:05:54.054205 22807 caffe.cpp:313] Batch 208, accuracy/top1 = 0.52
I0816 15:05:54.054224 22807 caffe.cpp:313] Batch 208, accuracy/top5 = 0.7
I0816 15:05:54.054227 22807 caffe.cpp:313] Batch 208, loss = 2.31683
I0816 15:05:54.116973 22807 caffe.cpp:313] Batch 209, accuracy/top1 = 0.62
I0816 15:05:54.116994 22807 caffe.cpp:313] Batch 209, accuracy/top5 = 0.9
I0816 15:05:54.116998 22807 caffe.cpp:313] Batch 209, loss = 1.53183
I0816 15:05:54.179950 22807 caffe.cpp:313] Batch 210, accuracy/top1 = 0.42
I0816 15:05:54.179972 22807 caffe.cpp:313] Batch 210, accuracy/top5 = 0.68
I0816 15:05:54.179975 22807 caffe.cpp:313] Batch 210, loss = 2.97472
I0816 15:05:54.242894 22807 caffe.cpp:313] Batch 211, accuracy/top1 = 0.58
I0816 15:05:54.242916 22807 caffe.cpp:313] Batch 211, accuracy/top5 = 0.86
I0816 15:05:54.242920 22807 caffe.cpp:313] Batch 211, loss = 1.75165
I0816 15:05:54.305799 22807 caffe.cpp:313] Batch 212, accuracy/top1 = 0.58
I0816 15:05:54.305820 22807 caffe.cpp:313] Batch 212, accuracy/top5 = 0.8
I0816 15:05:54.305824 22807 caffe.cpp:313] Batch 212, loss = 1.66218
I0816 15:05:54.368631 22807 caffe.cpp:313] Batch 213, accuracy/top1 = 0.64
I0816 15:05:54.368654 22807 caffe.cpp:313] Batch 213, accuracy/top5 = 0.84
I0816 15:05:54.368656 22807 caffe.cpp:313] Batch 213, loss = 1.75526
I0816 15:05:54.431632 22807 caffe.cpp:313] Batch 214, accuracy/top1 = 0.54
I0816 15:05:54.431653 22807 caffe.cpp:313] Batch 214, accuracy/top5 = 0.86
I0816 15:05:54.431656 22807 caffe.cpp:313] Batch 214, loss = 1.74137
I0816 15:05:54.494500 22807 caffe.cpp:313] Batch 215, accuracy/top1 = 0.48
I0816 15:05:54.494523 22807 caffe.cpp:313] Batch 215, accuracy/top5 = 0.76
I0816 15:05:54.494525 22807 caffe.cpp:313] Batch 215, loss = 2.05929
I0816 15:05:54.557555 22807 caffe.cpp:313] Batch 216, accuracy/top1 = 0.68
I0816 15:05:54.557577 22807 caffe.cpp:313] Batch 216, accuracy/top5 = 0.9
I0816 15:05:54.557580 22807 caffe.cpp:313] Batch 216, loss = 1.30293
I0816 15:05:54.620370 22807 caffe.cpp:313] Batch 217, accuracy/top1 = 0.58
I0816 15:05:54.620405 22807 caffe.cpp:313] Batch 217, accuracy/top5 = 0.8
I0816 15:05:54.620409 22807 caffe.cpp:313] Batch 217, loss = 1.72025
I0816 15:05:54.683174 22807 caffe.cpp:313] Batch 218, accuracy/top1 = 0.6
I0816 15:05:54.683197 22807 caffe.cpp:313] Batch 218, accuracy/top5 = 0.82
I0816 15:05:54.683199 22807 caffe.cpp:313] Batch 218, loss = 1.77994
I0816 15:05:54.745967 22807 caffe.cpp:313] Batch 219, accuracy/top1 = 0.66
I0816 15:05:54.745990 22807 caffe.cpp:313] Batch 219, accuracy/top5 = 0.86
I0816 15:05:54.745992 22807 caffe.cpp:313] Batch 219, loss = 1.46232
I0816 15:05:54.808820 22807 caffe.cpp:313] Batch 220, accuracy/top1 = 0.5
I0816 15:05:54.808840 22807 caffe.cpp:313] Batch 220, accuracy/top5 = 0.76
I0816 15:05:54.808843 22807 caffe.cpp:313] Batch 220, loss = 2.20999
I0816 15:05:54.871551 22807 caffe.cpp:313] Batch 221, accuracy/top1 = 0.62
I0816 15:05:54.871573 22807 caffe.cpp:313] Batch 221, accuracy/top5 = 0.88
I0816 15:05:54.871577 22807 caffe.cpp:313] Batch 221, loss = 1.50335
I0816 15:05:54.934350 22807 caffe.cpp:313] Batch 222, accuracy/top1 = 0.6
I0816 15:05:54.934372 22807 caffe.cpp:313] Batch 222, accuracy/top5 = 0.78
I0816 15:05:54.934376 22807 caffe.cpp:313] Batch 222, loss = 2.08889
I0816 15:05:54.997189 22807 caffe.cpp:313] Batch 223, accuracy/top1 = 0.46
I0816 15:05:54.997210 22807 caffe.cpp:313] Batch 223, accuracy/top5 = 0.8
I0816 15:05:54.997212 22807 caffe.cpp:313] Batch 223, loss = 2.00157
I0816 15:05:55.060060 22807 caffe.cpp:313] Batch 224, accuracy/top1 = 0.46
I0816 15:05:55.060079 22807 caffe.cpp:313] Batch 224, accuracy/top5 = 0.76
I0816 15:05:55.060082 22807 caffe.cpp:313] Batch 224, loss = 2.23029
I0816 15:05:55.122921 22807 caffe.cpp:313] Batch 225, accuracy/top1 = 0.7
I0816 15:05:55.122943 22807 caffe.cpp:313] Batch 225, accuracy/top5 = 0.84
I0816 15:05:55.122946 22807 caffe.cpp:313] Batch 225, loss = 1.54023
I0816 15:05:55.185797 22807 caffe.cpp:313] Batch 226, accuracy/top1 = 0.62
I0816 15:05:55.185819 22807 caffe.cpp:313] Batch 226, accuracy/top5 = 0.86
I0816 15:05:55.185822 22807 caffe.cpp:313] Batch 226, loss = 1.65709
I0816 15:05:55.248651 22807 caffe.cpp:313] Batch 227, accuracy/top1 = 0.62
I0816 15:05:55.248673 22807 caffe.cpp:313] Batch 227, accuracy/top5 = 0.86
I0816 15:05:55.248677 22807 caffe.cpp:313] Batch 227, loss = 1.4632
I0816 15:05:55.311619 22807 caffe.cpp:313] Batch 228, accuracy/top1 = 0.6
I0816 15:05:55.311640 22807 caffe.cpp:313] Batch 228, accuracy/top5 = 0.78
I0816 15:05:55.311645 22807 caffe.cpp:313] Batch 228, loss = 1.52351
I0816 15:05:55.374441 22807 caffe.cpp:313] Batch 229, accuracy/top1 = 0.64
I0816 15:05:55.374464 22807 caffe.cpp:313] Batch 229, accuracy/top5 = 0.82
I0816 15:05:55.374467 22807 caffe.cpp:313] Batch 229, loss = 1.47743
I0816 15:05:55.437383 22807 caffe.cpp:313] Batch 230, accuracy/top1 = 0.72
I0816 15:05:55.437402 22807 caffe.cpp:313] Batch 230, accuracy/top5 = 0.92
I0816 15:05:55.437405 22807 caffe.cpp:313] Batch 230, loss = 1.17631
I0816 15:05:55.500941 22807 caffe.cpp:313] Batch 231, accuracy/top1 = 0.48
I0816 15:05:55.500967 22807 caffe.cpp:313] Batch 231, accuracy/top5 = 0.74
I0816 15:05:55.500970 22807 caffe.cpp:313] Batch 231, loss = 2.24602
I0816 15:05:55.564929 22807 caffe.cpp:313] Batch 232, accuracy/top1 = 0.54
I0816 15:05:55.564950 22807 caffe.cpp:313] Batch 232, accuracy/top5 = 0.76
I0816 15:05:55.564954 22807 caffe.cpp:313] Batch 232, loss = 2.10995
I0816 15:05:55.628422 22807 caffe.cpp:313] Batch 233, accuracy/top1 = 0.58
I0816 15:05:55.628443 22807 caffe.cpp:313] Batch 233, accuracy/top5 = 0.86
I0816 15:05:55.628448 22807 caffe.cpp:313] Batch 233, loss = 1.63589
I0816 15:05:55.691308 22807 caffe.cpp:313] Batch 234, accuracy/top1 = 0.5
I0816 15:05:55.691329 22807 caffe.cpp:313] Batch 234, accuracy/top5 = 0.78
I0816 15:05:55.691334 22807 caffe.cpp:313] Batch 234, loss = 1.96749
I0816 15:05:55.754058 22807 caffe.cpp:313] Batch 235, accuracy/top1 = 0.56
I0816 15:05:55.754079 22807 caffe.cpp:313] Batch 235, accuracy/top5 = 0.84
I0816 15:05:55.754084 22807 caffe.cpp:313] Batch 235, loss = 1.60429
I0816 15:05:55.817059 22807 caffe.cpp:313] Batch 236, accuracy/top1 = 0.56
I0816 15:05:55.817080 22807 caffe.cpp:313] Batch 236, accuracy/top5 = 0.78
I0816 15:05:55.817085 22807 caffe.cpp:313] Batch 236, loss = 2.05142
I0816 15:05:55.880168 22807 caffe.cpp:313] Batch 237, accuracy/top1 = 0.64
I0816 15:05:55.880185 22807 caffe.cpp:313] Batch 237, accuracy/top5 = 0.92
I0816 15:05:55.880190 22807 caffe.cpp:313] Batch 237, loss = 1.27498
I0816 15:05:55.943183 22807 caffe.cpp:313] Batch 238, accuracy/top1 = 0.62
I0816 15:05:55.943204 22807 caffe.cpp:313] Batch 238, accuracy/top5 = 0.86
I0816 15:05:55.943208 22807 caffe.cpp:313] Batch 238, loss = 1.75486
I0816 15:05:56.006099 22807 caffe.cpp:313] Batch 239, accuracy/top1 = 0.66
I0816 15:05:56.006121 22807 caffe.cpp:313] Batch 239, accuracy/top5 = 0.9
I0816 15:05:56.006125 22807 caffe.cpp:313] Batch 239, loss = 1.25228
I0816 15:05:56.068954 22807 caffe.cpp:313] Batch 240, accuracy/top1 = 0.52
I0816 15:05:56.068976 22807 caffe.cpp:313] Batch 240, accuracy/top5 = 0.84
I0816 15:05:56.068980 22807 caffe.cpp:313] Batch 240, loss = 1.60907
I0816 15:05:56.131908 22807 caffe.cpp:313] Batch 241, accuracy/top1 = 0.46
I0816 15:05:56.131930 22807 caffe.cpp:313] Batch 241, accuracy/top5 = 0.72
I0816 15:05:56.131934 22807 caffe.cpp:313] Batch 241, loss = 2.33046
I0816 15:05:56.194907 22807 caffe.cpp:313] Batch 242, accuracy/top1 = 0.58
I0816 15:05:56.194929 22807 caffe.cpp:313] Batch 242, accuracy/top5 = 0.86
I0816 15:05:56.194933 22807 caffe.cpp:313] Batch 242, loss = 1.58145
I0816 15:05:56.257851 22807 caffe.cpp:313] Batch 243, accuracy/top1 = 0.46
I0816 15:05:56.257874 22807 caffe.cpp:313] Batch 243, accuracy/top5 = 0.8
I0816 15:05:56.257879 22807 caffe.cpp:313] Batch 243, loss = 1.80001
I0816 15:05:56.320755 22807 caffe.cpp:313] Batch 244, accuracy/top1 = 0.5
I0816 15:05:56.320775 22807 caffe.cpp:313] Batch 244, accuracy/top5 = 0.8
I0816 15:05:56.320780 22807 caffe.cpp:313] Batch 244, loss = 2.05717
I0816 15:05:56.383697 22807 caffe.cpp:313] Batch 245, accuracy/top1 = 0.44
I0816 15:05:56.383718 22807 caffe.cpp:313] Batch 245, accuracy/top5 = 0.64
I0816 15:05:56.383721 22807 caffe.cpp:313] Batch 245, loss = 2.52429
I0816 15:05:56.446672 22807 caffe.cpp:313] Batch 246, accuracy/top1 = 0.52
I0816 15:05:56.446694 22807 caffe.cpp:313] Batch 246, accuracy/top5 = 0.82
I0816 15:05:56.446698 22807 caffe.cpp:313] Batch 246, loss = 2.07955
I0816 15:05:56.509805 22807 caffe.cpp:313] Batch 247, accuracy/top1 = 0.44
I0816 15:05:56.509824 22807 caffe.cpp:313] Batch 247, accuracy/top5 = 0.7
I0816 15:05:56.509827 22807 caffe.cpp:313] Batch 247, loss = 2.28389
I0816 15:05:56.572695 22807 caffe.cpp:313] Batch 248, accuracy/top1 = 0.52
I0816 15:05:56.572717 22807 caffe.cpp:313] Batch 248, accuracy/top5 = 0.66
I0816 15:05:56.572721 22807 caffe.cpp:313] Batch 248, loss = 2.39184
I0816 15:05:56.635483 22807 caffe.cpp:313] Batch 249, accuracy/top1 = 0.52
I0816 15:05:56.635505 22807 caffe.cpp:313] Batch 249, accuracy/top5 = 0.76
I0816 15:05:56.635509 22807 caffe.cpp:313] Batch 249, loss = 2.03634
I0816 15:05:56.698446 22807 caffe.cpp:313] Batch 250, accuracy/top1 = 0.7
I0816 15:05:56.698468 22807 caffe.cpp:313] Batch 250, accuracy/top5 = 0.94
I0816 15:05:56.698472 22807 caffe.cpp:313] Batch 250, loss = 1.28347
I0816 15:05:56.761348 22807 caffe.cpp:313] Batch 251, accuracy/top1 = 0.6
I0816 15:05:56.761368 22807 caffe.cpp:313] Batch 251, accuracy/top5 = 0.82
I0816 15:05:56.761373 22807 caffe.cpp:313] Batch 251, loss = 1.59405
I0816 15:05:56.824162 22807 caffe.cpp:313] Batch 252, accuracy/top1 = 0.56
I0816 15:05:56.824182 22807 caffe.cpp:313] Batch 252, accuracy/top5 = 0.72
I0816 15:05:56.824187 22807 caffe.cpp:313] Batch 252, loss = 2.45727
I0816 15:05:56.887117 22807 caffe.cpp:313] Batch 253, accuracy/top1 = 0.56
I0816 15:05:56.887140 22807 caffe.cpp:313] Batch 253, accuracy/top5 = 0.82
I0816 15:05:56.887143 22807 caffe.cpp:313] Batch 253, loss = 1.80907
I0816 15:05:56.949996 22807 caffe.cpp:313] Batch 254, accuracy/top1 = 0.56
I0816 15:05:56.950018 22807 caffe.cpp:313] Batch 254, accuracy/top5 = 0.76
I0816 15:05:56.950022 22807 caffe.cpp:313] Batch 254, loss = 1.98931
I0816 15:05:57.013029 22807 caffe.cpp:313] Batch 255, accuracy/top1 = 0.52
I0816 15:05:57.013052 22807 caffe.cpp:313] Batch 255, accuracy/top5 = 0.78
I0816 15:05:57.013056 22807 caffe.cpp:313] Batch 255, loss = 2.39401
I0816 15:05:57.076532 22807 caffe.cpp:313] Batch 256, accuracy/top1 = 0.58
I0816 15:05:57.076555 22807 caffe.cpp:313] Batch 256, accuracy/top5 = 0.86
I0816 15:05:57.076558 22807 caffe.cpp:313] Batch 256, loss = 1.48377
I0816 15:05:57.139895 22807 caffe.cpp:313] Batch 257, accuracy/top1 = 0.58
I0816 15:05:57.139919 22807 caffe.cpp:313] Batch 257, accuracy/top5 = 0.8
I0816 15:05:57.139922 22807 caffe.cpp:313] Batch 257, loss = 1.98602
I0816 15:05:57.203356 22807 caffe.cpp:313] Batch 258, accuracy/top1 = 0.56
I0816 15:05:57.203378 22807 caffe.cpp:313] Batch 258, accuracy/top5 = 0.76
I0816 15:05:57.203382 22807 caffe.cpp:313] Batch 258, loss = 2.16408
I0816 15:05:57.266721 22807 caffe.cpp:313] Batch 259, accuracy/top1 = 0.5
I0816 15:05:57.266743 22807 caffe.cpp:313] Batch 259, accuracy/top5 = 0.86
I0816 15:05:57.266748 22807 caffe.cpp:313] Batch 259, loss = 1.97938
I0816 15:05:57.330160 22807 caffe.cpp:313] Batch 260, accuracy/top1 = 0.56
I0816 15:05:57.330183 22807 caffe.cpp:313] Batch 260, accuracy/top5 = 0.8
I0816 15:05:57.330188 22807 caffe.cpp:313] Batch 260, loss = 1.72582
I0816 15:05:57.393662 22807 caffe.cpp:313] Batch 261, accuracy/top1 = 0.6
I0816 15:05:57.393685 22807 caffe.cpp:313] Batch 261, accuracy/top5 = 0.78
I0816 15:05:57.393689 22807 caffe.cpp:313] Batch 261, loss = 1.80485
I0816 15:05:57.457235 22807 caffe.cpp:313] Batch 262, accuracy/top1 = 0.54
I0816 15:05:57.457257 22807 caffe.cpp:313] Batch 262, accuracy/top5 = 0.76
I0816 15:05:57.457262 22807 caffe.cpp:313] Batch 262, loss = 1.9479
I0816 15:05:57.520920 22807 caffe.cpp:313] Batch 263, accuracy/top1 = 0.62
I0816 15:05:57.520938 22807 caffe.cpp:313] Batch 263, accuracy/top5 = 0.82
I0816 15:05:57.520943 22807 caffe.cpp:313] Batch 263, loss = 1.79032
I0816 15:05:57.584450 22807 caffe.cpp:313] Batch 264, accuracy/top1 = 0.54
I0816 15:05:57.584470 22807 caffe.cpp:313] Batch 264, accuracy/top5 = 0.82
I0816 15:05:57.584475 22807 caffe.cpp:313] Batch 264, loss = 1.86225
I0816 15:05:57.648128 22807 caffe.cpp:313] Batch 265, accuracy/top1 = 0.68
I0816 15:05:57.648151 22807 caffe.cpp:313] Batch 265, accuracy/top5 = 0.86
I0816 15:05:57.648155 22807 caffe.cpp:313] Batch 265, loss = 1.43543
I0816 15:05:57.711627 22807 caffe.cpp:313] Batch 266, accuracy/top1 = 0.62
I0816 15:05:57.711649 22807 caffe.cpp:313] Batch 266, accuracy/top5 = 0.8
I0816 15:05:57.711653 22807 caffe.cpp:313] Batch 266, loss = 1.70538
I0816 15:05:57.774958 22807 caffe.cpp:313] Batch 267, accuracy/top1 = 0.58
I0816 15:05:57.774981 22807 caffe.cpp:313] Batch 267, accuracy/top5 = 0.88
I0816 15:05:57.774984 22807 caffe.cpp:313] Batch 267, loss = 1.61246
I0816 15:05:57.838387 22807 caffe.cpp:313] Batch 268, accuracy/top1 = 0.58
I0816 15:05:57.838408 22807 caffe.cpp:313] Batch 268, accuracy/top5 = 0.82
I0816 15:05:57.838413 22807 caffe.cpp:313] Batch 268, loss = 1.69316
I0816 15:05:57.901933 22807 caffe.cpp:313] Batch 269, accuracy/top1 = 0.64
I0816 15:05:57.901952 22807 caffe.cpp:313] Batch 269, accuracy/top5 = 0.86
I0816 15:05:57.901957 22807 caffe.cpp:313] Batch 269, loss = 1.71443
I0816 15:05:57.965380 22807 caffe.cpp:313] Batch 270, accuracy/top1 = 0.56
I0816 15:05:57.965404 22807 caffe.cpp:313] Batch 270, accuracy/top5 = 0.76
I0816 15:05:57.965409 22807 caffe.cpp:313] Batch 270, loss = 1.9984
I0816 15:05:58.029229 22807 caffe.cpp:313] Batch 271, accuracy/top1 = 0.56
I0816 15:05:58.029248 22807 caffe.cpp:313] Batch 271, accuracy/top5 = 0.76
I0816 15:05:58.029253 22807 caffe.cpp:313] Batch 271, loss = 2.22932
I0816 15:05:58.092655 22807 caffe.cpp:313] Batch 272, accuracy/top1 = 0.58
I0816 15:05:58.092679 22807 caffe.cpp:313] Batch 272, accuracy/top5 = 0.8
I0816 15:05:58.092682 22807 caffe.cpp:313] Batch 272, loss = 1.86042
I0816 15:05:58.156126 22807 caffe.cpp:313] Batch 273, accuracy/top1 = 0.62
I0816 15:05:58.156149 22807 caffe.cpp:313] Batch 273, accuracy/top5 = 0.88
I0816 15:05:58.156170 22807 caffe.cpp:313] Batch 273, loss = 1.47249
I0816 15:05:58.219527 22807 caffe.cpp:313] Batch 274, accuracy/top1 = 0.56
I0816 15:05:58.219549 22807 caffe.cpp:313] Batch 274, accuracy/top5 = 0.84
I0816 15:05:58.219554 22807 caffe.cpp:313] Batch 274, loss = 1.87251
I0816 15:05:58.282896 22807 caffe.cpp:313] Batch 275, accuracy/top1 = 0.64
I0816 15:05:58.282919 22807 caffe.cpp:313] Batch 275, accuracy/top5 = 0.82
I0816 15:05:58.282923 22807 caffe.cpp:313] Batch 275, loss = 1.70444
I0816 15:05:58.346412 22807 caffe.cpp:313] Batch 276, accuracy/top1 = 0.66
I0816 15:05:58.346436 22807 caffe.cpp:313] Batch 276, accuracy/top5 = 0.82
I0816 15:05:58.346439 22807 caffe.cpp:313] Batch 276, loss = 1.60248
I0816 15:05:58.409801 22807 caffe.cpp:313] Batch 277, accuracy/top1 = 0.58
I0816 15:05:58.409822 22807 caffe.cpp:313] Batch 277, accuracy/top5 = 0.78
I0816 15:05:58.409827 22807 caffe.cpp:313] Batch 277, loss = 1.85458
I0816 15:05:58.473129 22807 caffe.cpp:313] Batch 278, accuracy/top1 = 0.48
I0816 15:05:58.473150 22807 caffe.cpp:313] Batch 278, accuracy/top5 = 0.76
I0816 15:05:58.473155 22807 caffe.cpp:313] Batch 278, loss = 2.31812
I0816 15:05:58.537091 22807 caffe.cpp:313] Batch 279, accuracy/top1 = 0.58
I0816 15:05:58.537109 22807 caffe.cpp:313] Batch 279, accuracy/top5 = 0.76
I0816 15:05:58.537113 22807 caffe.cpp:313] Batch 279, loss = 2.35731
I0816 15:05:58.600559 22807 caffe.cpp:313] Batch 280, accuracy/top1 = 0.5
I0816 15:05:58.600582 22807 caffe.cpp:313] Batch 280, accuracy/top5 = 0.88
I0816 15:05:58.600587 22807 caffe.cpp:313] Batch 280, loss = 1.82518
I0816 15:05:58.663985 22807 caffe.cpp:313] Batch 281, accuracy/top1 = 0.64
I0816 15:05:58.664006 22807 caffe.cpp:313] Batch 281, accuracy/top5 = 0.84
I0816 15:05:58.664011 22807 caffe.cpp:313] Batch 281, loss = 1.89208
I0816 15:05:58.727521 22807 caffe.cpp:313] Batch 282, accuracy/top1 = 0.56
I0816 15:05:58.727545 22807 caffe.cpp:313] Batch 282, accuracy/top5 = 0.8
I0816 15:05:58.727548 22807 caffe.cpp:313] Batch 282, loss = 1.65019
I0816 15:05:58.790987 22807 caffe.cpp:313] Batch 283, accuracy/top1 = 0.5
I0816 15:05:58.791008 22807 caffe.cpp:313] Batch 283, accuracy/top5 = 0.78
I0816 15:05:58.791013 22807 caffe.cpp:313] Batch 283, loss = 2.06325
I0816 15:05:58.854569 22807 caffe.cpp:313] Batch 284, accuracy/top1 = 0.54
I0816 15:05:58.854593 22807 caffe.cpp:313] Batch 284, accuracy/top5 = 0.76
I0816 15:05:58.854596 22807 caffe.cpp:313] Batch 284, loss = 2.01116
I0816 15:05:58.917969 22807 caffe.cpp:313] Batch 285, accuracy/top1 = 0.62
I0816 15:05:58.917992 22807 caffe.cpp:313] Batch 285, accuracy/top5 = 0.86
I0816 15:05:58.917997 22807 caffe.cpp:313] Batch 285, loss = 1.44998
I0816 15:05:58.981516 22807 caffe.cpp:313] Batch 286, accuracy/top1 = 0.66
I0816 15:05:58.981539 22807 caffe.cpp:313] Batch 286, accuracy/top5 = 0.84
I0816 15:05:58.981544 22807 caffe.cpp:313] Batch 286, loss = 1.37011
I0816 15:05:59.045047 22807 caffe.cpp:313] Batch 287, accuracy/top1 = 0.54
I0816 15:05:59.045064 22807 caffe.cpp:313] Batch 287, accuracy/top5 = 0.78
I0816 15:05:59.045069 22807 caffe.cpp:313] Batch 287, loss = 2.07553
I0816 15:05:59.108548 22807 caffe.cpp:313] Batch 288, accuracy/top1 = 0.62
I0816 15:05:59.108572 22807 caffe.cpp:313] Batch 288, accuracy/top5 = 0.84
I0816 15:05:59.108577 22807 caffe.cpp:313] Batch 288, loss = 1.97018
I0816 15:05:59.171977 22807 caffe.cpp:313] Batch 289, accuracy/top1 = 0.54
I0816 15:05:59.172000 22807 caffe.cpp:313] Batch 289, accuracy/top5 = 0.88
I0816 15:05:59.172004 22807 caffe.cpp:313] Batch 289, loss = 1.46616
I0816 15:05:59.235437 22807 caffe.cpp:313] Batch 290, accuracy/top1 = 0.58
I0816 15:05:59.235460 22807 caffe.cpp:313] Batch 290, accuracy/top5 = 0.76
I0816 15:05:59.235465 22807 caffe.cpp:313] Batch 290, loss = 2.09343
I0816 15:05:59.298791 22807 caffe.cpp:313] Batch 291, accuracy/top1 = 0.58
I0816 15:05:59.298815 22807 caffe.cpp:313] Batch 291, accuracy/top5 = 0.76
I0816 15:05:59.298818 22807 caffe.cpp:313] Batch 291, loss = 2.03582
I0816 15:05:59.362253 22807 caffe.cpp:313] Batch 292, accuracy/top1 = 0.58
I0816 15:05:59.362289 22807 caffe.cpp:313] Batch 292, accuracy/top5 = 0.84
I0816 15:05:59.362294 22807 caffe.cpp:313] Batch 292, loss = 1.76018
I0816 15:05:59.425637 22807 caffe.cpp:313] Batch 293, accuracy/top1 = 0.7
I0816 15:05:59.425660 22807 caffe.cpp:313] Batch 293, accuracy/top5 = 0.82
I0816 15:05:59.425664 22807 caffe.cpp:313] Batch 293, loss = 1.43267
I0816 15:05:59.489171 22807 caffe.cpp:313] Batch 294, accuracy/top1 = 0.7
I0816 15:05:59.489192 22807 caffe.cpp:313] Batch 294, accuracy/top5 = 0.92
I0816 15:05:59.489197 22807 caffe.cpp:313] Batch 294, loss = 0.991849
I0816 15:05:59.552848 22807 caffe.cpp:313] Batch 295, accuracy/top1 = 0.5
I0816 15:05:59.552870 22807 caffe.cpp:313] Batch 295, accuracy/top5 = 0.7
I0816 15:05:59.552875 22807 caffe.cpp:313] Batch 295, loss = 2.0741
I0816 15:05:59.616215 22807 caffe.cpp:313] Batch 296, accuracy/top1 = 0.6
I0816 15:05:59.616238 22807 caffe.cpp:313] Batch 296, accuracy/top5 = 0.86
I0816 15:05:59.616242 22807 caffe.cpp:313] Batch 296, loss = 1.46908
I0816 15:05:59.679780 22807 caffe.cpp:313] Batch 297, accuracy/top1 = 0.62
I0816 15:05:59.679800 22807 caffe.cpp:313] Batch 297, accuracy/top5 = 0.82
I0816 15:05:59.679805 22807 caffe.cpp:313] Batch 297, loss = 1.4536
I0816 15:05:59.743419 22807 caffe.cpp:313] Batch 298, accuracy/top1 = 0.58
I0816 15:05:59.743439 22807 caffe.cpp:313] Batch 298, accuracy/top5 = 0.82
I0816 15:05:59.743443 22807 caffe.cpp:313] Batch 298, loss = 1.92403
I0816 15:05:59.807195 22807 caffe.cpp:313] Batch 299, accuracy/top1 = 0.56
I0816 15:05:59.807216 22807 caffe.cpp:313] Batch 299, accuracy/top5 = 0.78
I0816 15:05:59.807221 22807 caffe.cpp:313] Batch 299, loss = 2.06848
I0816 15:05:59.870633 22807 caffe.cpp:313] Batch 300, accuracy/top1 = 0.5
I0816 15:05:59.870656 22807 caffe.cpp:313] Batch 300, accuracy/top5 = 0.7
I0816 15:05:59.870661 22807 caffe.cpp:313] Batch 300, loss = 2.23495
I0816 15:05:59.934149 22807 caffe.cpp:313] Batch 301, accuracy/top1 = 0.52
I0816 15:05:59.934167 22807 caffe.cpp:313] Batch 301, accuracy/top5 = 0.76
I0816 15:05:59.934171 22807 caffe.cpp:313] Batch 301, loss = 2.28196
I0816 15:05:59.997310 22807 caffe.cpp:313] Batch 302, accuracy/top1 = 0.7
I0816 15:05:59.997333 22807 caffe.cpp:313] Batch 302, accuracy/top5 = 0.86
I0816 15:05:59.997336 22807 caffe.cpp:313] Batch 302, loss = 1.54702
I0816 15:06:00.060971 22807 caffe.cpp:313] Batch 303, accuracy/top1 = 0.54
I0816 15:06:00.060995 22807 caffe.cpp:313] Batch 303, accuracy/top5 = 0.86
I0816 15:06:00.060999 22807 caffe.cpp:313] Batch 303, loss = 1.63217
I0816 15:06:00.124454 22807 caffe.cpp:313] Batch 304, accuracy/top1 = 0.6
I0816 15:06:00.124476 22807 caffe.cpp:313] Batch 304, accuracy/top5 = 0.84
I0816 15:06:00.124480 22807 caffe.cpp:313] Batch 304, loss = 1.44366
I0816 15:06:00.187942 22807 caffe.cpp:313] Batch 305, accuracy/top1 = 0.68
I0816 15:06:00.187964 22807 caffe.cpp:313] Batch 305, accuracy/top5 = 0.88
I0816 15:06:00.187969 22807 caffe.cpp:313] Batch 305, loss = 1.23295
I0816 15:06:00.251307 22807 caffe.cpp:313] Batch 306, accuracy/top1 = 0.62
I0816 15:06:00.251330 22807 caffe.cpp:313] Batch 306, accuracy/top5 = 0.88
I0816 15:06:00.251335 22807 caffe.cpp:313] Batch 306, loss = 1.48804
I0816 15:06:00.314947 22807 caffe.cpp:313] Batch 307, accuracy/top1 = 0.64
I0816 15:06:00.314970 22807 caffe.cpp:313] Batch 307, accuracy/top5 = 0.82
I0816 15:06:00.314975 22807 caffe.cpp:313] Batch 307, loss = 1.80586
I0816 15:06:00.378391 22807 caffe.cpp:313] Batch 308, accuracy/top1 = 0.72
I0816 15:06:00.378413 22807 caffe.cpp:313] Batch 308, accuracy/top5 = 0.86
I0816 15:06:00.378417 22807 caffe.cpp:313] Batch 308, loss = 1.48819
I0816 15:06:00.441910 22807 caffe.cpp:313] Batch 309, accuracy/top1 = 0.54
I0816 15:06:00.441932 22807 caffe.cpp:313] Batch 309, accuracy/top5 = 0.76
I0816 15:06:00.441936 22807 caffe.cpp:313] Batch 309, loss = 2.05389
I0816 15:06:00.505518 22807 caffe.cpp:313] Batch 310, accuracy/top1 = 0.64
I0816 15:06:00.505543 22807 caffe.cpp:313] Batch 310, accuracy/top5 = 0.9
I0816 15:06:00.505548 22807 caffe.cpp:313] Batch 310, loss = 1.3147
I0816 15:06:00.568572 22807 caffe.cpp:313] Batch 311, accuracy/top1 = 0.52
I0816 15:06:00.568594 22807 caffe.cpp:313] Batch 311, accuracy/top5 = 0.76
I0816 15:06:00.568599 22807 caffe.cpp:313] Batch 311, loss = 2.38008
I0816 15:06:00.631629 22807 caffe.cpp:313] Batch 312, accuracy/top1 = 0.66
I0816 15:06:00.631651 22807 caffe.cpp:313] Batch 312, accuracy/top5 = 0.8
I0816 15:06:00.631656 22807 caffe.cpp:313] Batch 312, loss = 1.84737
I0816 15:06:00.694600 22807 caffe.cpp:313] Batch 313, accuracy/top1 = 0.64
I0816 15:06:00.694622 22807 caffe.cpp:313] Batch 313, accuracy/top5 = 0.86
I0816 15:06:00.694628 22807 caffe.cpp:313] Batch 313, loss = 1.52511
I0816 15:06:00.757452 22807 caffe.cpp:313] Batch 314, accuracy/top1 = 0.64
I0816 15:06:00.757474 22807 caffe.cpp:313] Batch 314, accuracy/top5 = 0.86
I0816 15:06:00.757478 22807 caffe.cpp:313] Batch 314, loss = 1.38057
I0816 15:06:00.820358 22807 caffe.cpp:313] Batch 315, accuracy/top1 = 0.6
I0816 15:06:00.820379 22807 caffe.cpp:313] Batch 315, accuracy/top5 = 0.8
I0816 15:06:00.820384 22807 caffe.cpp:313] Batch 315, loss = 1.85764
I0816 15:06:00.883294 22807 caffe.cpp:313] Batch 316, accuracy/top1 = 0.5
I0816 15:06:00.883316 22807 caffe.cpp:313] Batch 316, accuracy/top5 = 0.78
I0816 15:06:00.883322 22807 caffe.cpp:313] Batch 316, loss = 2.28028
I0816 15:06:00.946298 22807 caffe.cpp:313] Batch 317, accuracy/top1 = 0.6
I0816 15:06:00.946321 22807 caffe.cpp:313] Batch 317, accuracy/top5 = 0.78
I0816 15:06:00.946326 22807 caffe.cpp:313] Batch 317, loss = 1.78714
I0816 15:06:01.009237 22807 caffe.cpp:313] Batch 318, accuracy/top1 = 0.66
I0816 15:06:01.009255 22807 caffe.cpp:313] Batch 318, accuracy/top5 = 0.84
I0816 15:06:01.009260 22807 caffe.cpp:313] Batch 318, loss = 1.57518
I0816 15:06:01.072260 22807 caffe.cpp:313] Batch 319, accuracy/top1 = 0.54
I0816 15:06:01.072281 22807 caffe.cpp:313] Batch 319, accuracy/top5 = 0.82
I0816 15:06:01.072286 22807 caffe.cpp:313] Batch 319, loss = 1.79134
I0816 15:06:01.135108 22807 caffe.cpp:313] Batch 320, accuracy/top1 = 0.54
I0816 15:06:01.135129 22807 caffe.cpp:313] Batch 320, accuracy/top5 = 0.72
I0816 15:06:01.135133 22807 caffe.cpp:313] Batch 320, loss = 2.21278
I0816 15:06:01.197983 22807 caffe.cpp:313] Batch 321, accuracy/top1 = 0.6
I0816 15:06:01.198005 22807 caffe.cpp:313] Batch 321, accuracy/top5 = 0.82
I0816 15:06:01.198009 22807 caffe.cpp:313] Batch 321, loss = 1.94461
I0816 15:06:01.260900 22807 caffe.cpp:313] Batch 322, accuracy/top1 = 0.56
I0816 15:06:01.260922 22807 caffe.cpp:313] Batch 322, accuracy/top5 = 0.94
I0816 15:06:01.260926 22807 caffe.cpp:313] Batch 322, loss = 1.15872
I0816 15:06:01.323812 22807 caffe.cpp:313] Batch 323, accuracy/top1 = 0.6
I0816 15:06:01.323834 22807 caffe.cpp:313] Batch 323, accuracy/top5 = 0.8
I0816 15:06:01.323838 22807 caffe.cpp:313] Batch 323, loss = 1.93565
I0816 15:06:01.386734 22807 caffe.cpp:313] Batch 324, accuracy/top1 = 0.5
I0816 15:06:01.386755 22807 caffe.cpp:313] Batch 324, accuracy/top5 = 0.7
I0816 15:06:01.386760 22807 caffe.cpp:313] Batch 324, loss = 2.10814
I0816 15:06:01.449597 22807 caffe.cpp:313] Batch 325, accuracy/top1 = 0.54
I0816 15:06:01.449617 22807 caffe.cpp:313] Batch 325, accuracy/top5 = 0.76
I0816 15:06:01.449621 22807 caffe.cpp:313] Batch 325, loss = 1.98419
I0816 15:06:01.513258 22807 caffe.cpp:313] Batch 326, accuracy/top1 = 0.54
I0816 15:06:01.513281 22807 caffe.cpp:313] Batch 326, accuracy/top5 = 0.82
I0816 15:06:01.513285 22807 caffe.cpp:313] Batch 326, loss = 2.01154
I0816 15:06:01.576256 22807 caffe.cpp:313] Batch 327, accuracy/top1 = 0.58
I0816 15:06:01.576277 22807 caffe.cpp:313] Batch 327, accuracy/top5 = 0.7
I0816 15:06:01.576282 22807 caffe.cpp:313] Batch 327, loss = 2.10162
I0816 15:06:01.639225 22807 caffe.cpp:313] Batch 328, accuracy/top1 = 0.44
I0816 15:06:01.639247 22807 caffe.cpp:313] Batch 328, accuracy/top5 = 0.8
I0816 15:06:01.639251 22807 caffe.cpp:313] Batch 328, loss = 2.04558
I0816 15:06:01.702100 22807 caffe.cpp:313] Batch 329, accuracy/top1 = 0.6
I0816 15:06:01.702121 22807 caffe.cpp:313] Batch 329, accuracy/top5 = 0.82
I0816 15:06:01.702126 22807 caffe.cpp:313] Batch 329, loss = 1.66308
I0816 15:06:01.765060 22807 caffe.cpp:313] Batch 330, accuracy/top1 = 0.58
I0816 15:06:01.765084 22807 caffe.cpp:313] Batch 330, accuracy/top5 = 0.84
I0816 15:06:01.765087 22807 caffe.cpp:313] Batch 330, loss = 1.82254
I0816 15:06:01.828119 22807 caffe.cpp:313] Batch 331, accuracy/top1 = 0.48
I0816 15:06:01.828142 22807 caffe.cpp:313] Batch 331, accuracy/top5 = 0.8
I0816 15:06:01.828146 22807 caffe.cpp:313] Batch 331, loss = 2.08596
I0816 15:06:01.891233 22807 caffe.cpp:313] Batch 332, accuracy/top1 = 0.56
I0816 15:06:01.891254 22807 caffe.cpp:313] Batch 332, accuracy/top5 = 0.82
I0816 15:06:01.891258 22807 caffe.cpp:313] Batch 332, loss = 1.62511
I0816 15:06:01.954900 22807 caffe.cpp:313] Batch 333, accuracy/top1 = 0.52
I0816 15:06:01.954916 22807 caffe.cpp:313] Batch 333, accuracy/top5 = 0.8
I0816 15:06:01.954921 22807 caffe.cpp:313] Batch 333, loss = 1.76463
I0816 15:06:02.017843 22807 caffe.cpp:313] Batch 334, accuracy/top1 = 0.66
I0816 15:06:02.017863 22807 caffe.cpp:313] Batch 334, accuracy/top5 = 0.94
I0816 15:06:02.017868 22807 caffe.cpp:313] Batch 334, loss = 1.3212
I0816 15:06:02.080782 22807 caffe.cpp:313] Batch 335, accuracy/top1 = 0.52
I0816 15:06:02.080803 22807 caffe.cpp:313] Batch 335, accuracy/top5 = 0.72
I0816 15:06:02.080807 22807 caffe.cpp:313] Batch 335, loss = 2.17433
I0816 15:06:02.143714 22807 caffe.cpp:313] Batch 336, accuracy/top1 = 0.72
I0816 15:06:02.143738 22807 caffe.cpp:313] Batch 336, accuracy/top5 = 0.86
I0816 15:06:02.143741 22807 caffe.cpp:313] Batch 336, loss = 1.32248
I0816 15:06:02.206454 22807 caffe.cpp:313] Batch 337, accuracy/top1 = 0.72
I0816 15:06:02.206476 22807 caffe.cpp:313] Batch 337, accuracy/top5 = 0.88
I0816 15:06:02.206480 22807 caffe.cpp:313] Batch 337, loss = 1.37923
I0816 15:06:02.269244 22807 caffe.cpp:313] Batch 338, accuracy/top1 = 0.62
I0816 15:06:02.269268 22807 caffe.cpp:313] Batch 338, accuracy/top5 = 0.76
I0816 15:06:02.269271 22807 caffe.cpp:313] Batch 338, loss = 1.68649
I0816 15:06:02.332162 22807 caffe.cpp:313] Batch 339, accuracy/top1 = 0.52
I0816 15:06:02.332185 22807 caffe.cpp:313] Batch 339, accuracy/top5 = 0.84
I0816 15:06:02.332190 22807 caffe.cpp:313] Batch 339, loss = 1.87443
I0816 15:06:02.395004 22807 caffe.cpp:313] Batch 340, accuracy/top1 = 0.5
I0816 15:06:02.395027 22807 caffe.cpp:313] Batch 340, accuracy/top5 = 0.8
I0816 15:06:02.395032 22807 caffe.cpp:313] Batch 340, loss = 2.27564
I0816 15:06:02.457738 22807 caffe.cpp:313] Batch 341, accuracy/top1 = 0.6
I0816 15:06:02.457761 22807 caffe.cpp:313] Batch 341, accuracy/top5 = 0.76
I0816 15:06:02.457764 22807 caffe.cpp:313] Batch 341, loss = 1.64161
I0816 15:06:02.521004 22807 caffe.cpp:313] Batch 342, accuracy/top1 = 0.6
I0816 15:06:02.521023 22807 caffe.cpp:313] Batch 342, accuracy/top5 = 0.84
I0816 15:06:02.521026 22807 caffe.cpp:313] Batch 342, loss = 1.60361
I0816 15:06:02.583880 22807 caffe.cpp:313] Batch 343, accuracy/top1 = 0.54
I0816 15:06:02.583904 22807 caffe.cpp:313] Batch 343, accuracy/top5 = 0.76
I0816 15:06:02.583907 22807 caffe.cpp:313] Batch 343, loss = 1.76204
I0816 15:06:02.646718 22807 caffe.cpp:313] Batch 344, accuracy/top1 = 0.58
I0816 15:06:02.646739 22807 caffe.cpp:313] Batch 344, accuracy/top5 = 0.88
I0816 15:06:02.646744 22807 caffe.cpp:313] Batch 344, loss = 1.45088
I0816 15:06:02.709632 22807 caffe.cpp:313] Batch 345, accuracy/top1 = 0.56
I0816 15:06:02.709655 22807 caffe.cpp:313] Batch 345, accuracy/top5 = 0.88
I0816 15:06:02.709659 22807 caffe.cpp:313] Batch 345, loss = 1.64109
I0816 15:06:02.772505 22807 caffe.cpp:313] Batch 346, accuracy/top1 = 0.5
I0816 15:06:02.772527 22807 caffe.cpp:313] Batch 346, accuracy/top5 = 0.72
I0816 15:06:02.772531 22807 caffe.cpp:313] Batch 346, loss = 2.14417
I0816 15:06:02.835233 22807 caffe.cpp:313] Batch 347, accuracy/top1 = 0.56
I0816 15:06:02.835255 22807 caffe.cpp:313] Batch 347, accuracy/top5 = 0.9
I0816 15:06:02.835259 22807 caffe.cpp:313] Batch 347, loss = 1.59603
I0816 15:06:02.898192 22807 caffe.cpp:313] Batch 348, accuracy/top1 = 0.66
I0816 15:06:02.898216 22807 caffe.cpp:313] Batch 348, accuracy/top5 = 0.84
I0816 15:06:02.898236 22807 caffe.cpp:313] Batch 348, loss = 1.44167
I0816 15:06:02.961244 22807 caffe.cpp:313] Batch 349, accuracy/top1 = 0.52
I0816 15:06:02.961267 22807 caffe.cpp:313] Batch 349, accuracy/top5 = 0.78
I0816 15:06:02.961272 22807 caffe.cpp:313] Batch 349, loss = 2.23791
I0816 15:06:03.024180 22807 caffe.cpp:313] Batch 350, accuracy/top1 = 0.68
I0816 15:06:03.024199 22807 caffe.cpp:313] Batch 350, accuracy/top5 = 0.78
I0816 15:06:03.024204 22807 caffe.cpp:313] Batch 350, loss = 1.51354
I0816 15:06:03.087116 22807 caffe.cpp:313] Batch 351, accuracy/top1 = 0.66
I0816 15:06:03.087138 22807 caffe.cpp:313] Batch 351, accuracy/top5 = 0.8
I0816 15:06:03.087142 22807 caffe.cpp:313] Batch 351, loss = 1.60045
I0816 15:06:03.150004 22807 caffe.cpp:313] Batch 352, accuracy/top1 = 0.56
I0816 15:06:03.150027 22807 caffe.cpp:313] Batch 352, accuracy/top5 = 0.74
I0816 15:06:03.150032 22807 caffe.cpp:313] Batch 352, loss = 2.3975
I0816 15:06:03.213026 22807 caffe.cpp:313] Batch 353, accuracy/top1 = 0.56
I0816 15:06:03.213047 22807 caffe.cpp:313] Batch 353, accuracy/top5 = 0.78
I0816 15:06:03.213052 22807 caffe.cpp:313] Batch 353, loss = 2.00686
I0816 15:06:03.275880 22807 caffe.cpp:313] Batch 354, accuracy/top1 = 0.52
I0816 15:06:03.275903 22807 caffe.cpp:313] Batch 354, accuracy/top5 = 0.78
I0816 15:06:03.275907 22807 caffe.cpp:313] Batch 354, loss = 2.40719
I0816 15:06:03.338763 22807 caffe.cpp:313] Batch 355, accuracy/top1 = 0.56
I0816 15:06:03.338786 22807 caffe.cpp:313] Batch 355, accuracy/top5 = 0.82
I0816 15:06:03.338790 22807 caffe.cpp:313] Batch 355, loss = 1.94749
I0816 15:06:03.401605 22807 caffe.cpp:313] Batch 356, accuracy/top1 = 0.56
I0816 15:06:03.401628 22807 caffe.cpp:313] Batch 356, accuracy/top5 = 0.78
I0816 15:06:03.401631 22807 caffe.cpp:313] Batch 356, loss = 1.70731
I0816 15:06:03.464532 22807 caffe.cpp:313] Batch 357, accuracy/top1 = 0.6
I0816 15:06:03.464555 22807 caffe.cpp:313] Batch 357, accuracy/top5 = 0.88
I0816 15:06:03.464560 22807 caffe.cpp:313] Batch 357, loss = 1.50428
I0816 15:06:03.527835 22807 caffe.cpp:313] Batch 358, accuracy/top1 = 0.5
I0816 15:06:03.527853 22807 caffe.cpp:313] Batch 358, accuracy/top5 = 0.76
I0816 15:06:03.527858 22807 caffe.cpp:313] Batch 358, loss = 2.2197
I0816 15:06:03.590901 22807 caffe.cpp:313] Batch 359, accuracy/top1 = 0.44
I0816 15:06:03.590924 22807 caffe.cpp:313] Batch 359, accuracy/top5 = 0.84
I0816 15:06:03.590929 22807 caffe.cpp:313] Batch 359, loss = 2.29384
I0816 15:06:03.653805 22807 caffe.cpp:313] Batch 360, accuracy/top1 = 0.66
I0816 15:06:03.653828 22807 caffe.cpp:313] Batch 360, accuracy/top5 = 0.82
I0816 15:06:03.653832 22807 caffe.cpp:313] Batch 360, loss = 1.91065
I0816 15:06:03.716717 22807 caffe.cpp:313] Batch 361, accuracy/top1 = 0.58
I0816 15:06:03.716740 22807 caffe.cpp:313] Batch 361, accuracy/top5 = 0.86
I0816 15:06:03.716745 22807 caffe.cpp:313] Batch 361, loss = 1.57497
I0816 15:06:03.779836 22807 caffe.cpp:313] Batch 362, accuracy/top1 = 0.56
I0816 15:06:03.779858 22807 caffe.cpp:313] Batch 362, accuracy/top5 = 0.76
I0816 15:06:03.779862 22807 caffe.cpp:313] Batch 362, loss = 2.03841
I0816 15:06:03.842663 22807 caffe.cpp:313] Batch 363, accuracy/top1 = 0.56
I0816 15:06:03.842684 22807 caffe.cpp:313] Batch 363, accuracy/top5 = 0.82
I0816 15:06:03.842689 22807 caffe.cpp:313] Batch 363, loss = 1.95589
I0816 15:06:03.905689 22807 caffe.cpp:313] Batch 364, accuracy/top1 = 0.62
I0816 15:06:03.905711 22807 caffe.cpp:313] Batch 364, accuracy/top5 = 0.82
I0816 15:06:03.905715 22807 caffe.cpp:313] Batch 364, loss = 1.5116
I0816 15:06:03.968684 22807 caffe.cpp:313] Batch 365, accuracy/top1 = 0.68
I0816 15:06:03.968704 22807 caffe.cpp:313] Batch 365, accuracy/top5 = 0.82
I0816 15:06:03.968708 22807 caffe.cpp:313] Batch 365, loss = 1.59424
I0816 15:06:04.031827 22807 caffe.cpp:313] Batch 366, accuracy/top1 = 0.5
I0816 15:06:04.031847 22807 caffe.cpp:313] Batch 366, accuracy/top5 = 0.8
I0816 15:06:04.031852 22807 caffe.cpp:313] Batch 366, loss = 1.95427
I0816 15:06:04.094919 22807 caffe.cpp:313] Batch 367, accuracy/top1 = 0.6
I0816 15:06:04.094949 22807 caffe.cpp:313] Batch 367, accuracy/top5 = 0.82
I0816 15:06:04.094954 22807 caffe.cpp:313] Batch 367, loss = 1.64362
I0816 15:06:04.157874 22807 caffe.cpp:313] Batch 368, accuracy/top1 = 0.5
I0816 15:06:04.157896 22807 caffe.cpp:313] Batch 368, accuracy/top5 = 0.82
I0816 15:06:04.157902 22807 caffe.cpp:313] Batch 368, loss = 1.86042
I0816 15:06:04.220724 22807 caffe.cpp:313] Batch 369, accuracy/top1 = 0.64
I0816 15:06:04.220746 22807 caffe.cpp:313] Batch 369, accuracy/top5 = 0.88
I0816 15:06:04.220751 22807 caffe.cpp:313] Batch 369, loss = 1.52183
I0816 15:06:04.283565 22807 caffe.cpp:313] Batch 370, accuracy/top1 = 0.72
I0816 15:06:04.283586 22807 caffe.cpp:313] Batch 370, accuracy/top5 = 0.8
I0816 15:06:04.283591 22807 caffe.cpp:313] Batch 370, loss = 1.63418
I0816 15:06:04.346609 22807 caffe.cpp:313] Batch 371, accuracy/top1 = 0.7
I0816 15:06:04.346631 22807 caffe.cpp:313] Batch 371, accuracy/top5 = 0.8
I0816 15:06:04.346634 22807 caffe.cpp:313] Batch 371, loss = 1.68329
I0816 15:06:04.409415 22807 caffe.cpp:313] Batch 372, accuracy/top1 = 0.7
I0816 15:06:04.409436 22807 caffe.cpp:313] Batch 372, accuracy/top5 = 0.88
I0816 15:06:04.409441 22807 caffe.cpp:313] Batch 372, loss = 1.39564
I0816 15:06:04.472373 22807 caffe.cpp:313] Batch 373, accuracy/top1 = 0.48
I0816 15:06:04.472395 22807 caffe.cpp:313] Batch 373, accuracy/top5 = 0.76
I0816 15:06:04.472399 22807 caffe.cpp:313] Batch 373, loss = 2.42443
I0816 15:06:04.535769 22807 caffe.cpp:313] Batch 374, accuracy/top1 = 0.58
I0816 15:06:04.535789 22807 caffe.cpp:313] Batch 374, accuracy/top5 = 0.8
I0816 15:06:04.535792 22807 caffe.cpp:313] Batch 374, loss = 1.75763
I0816 15:06:04.598762 22807 caffe.cpp:313] Batch 375, accuracy/top1 = 0.68
I0816 15:06:04.598783 22807 caffe.cpp:313] Batch 375, accuracy/top5 = 0.9
I0816 15:06:04.598788 22807 caffe.cpp:313] Batch 375, loss = 1.16652
I0816 15:06:04.661768 22807 caffe.cpp:313] Batch 376, accuracy/top1 = 0.54
I0816 15:06:04.661790 22807 caffe.cpp:313] Batch 376, accuracy/top5 = 0.86
I0816 15:06:04.661795 22807 caffe.cpp:313] Batch 376, loss = 1.60234
I0816 15:06:04.724774 22807 caffe.cpp:313] Batch 377, accuracy/top1 = 0.5
I0816 15:06:04.724797 22807 caffe.cpp:313] Batch 377, accuracy/top5 = 0.78
I0816 15:06:04.724802 22807 caffe.cpp:313] Batch 377, loss = 1.89857
I0816 15:06:04.787780 22807 caffe.cpp:313] Batch 378, accuracy/top1 = 0.68
I0816 15:06:04.787801 22807 caffe.cpp:313] Batch 378, accuracy/top5 = 0.86
I0816 15:06:04.787806 22807 caffe.cpp:313] Batch 378, loss = 1.51232
I0816 15:06:04.850756 22807 caffe.cpp:313] Batch 379, accuracy/top1 = 0.68
I0816 15:06:04.850778 22807 caffe.cpp:313] Batch 379, accuracy/top5 = 0.9
I0816 15:06:04.850782 22807 caffe.cpp:313] Batch 379, loss = 1.37283
I0816 15:06:04.913699 22807 caffe.cpp:313] Batch 380, accuracy/top1 = 0.62
I0816 15:06:04.913722 22807 caffe.cpp:313] Batch 380, accuracy/top5 = 0.84
I0816 15:06:04.913727 22807 caffe.cpp:313] Batch 380, loss = 1.59227
I0816 15:06:04.976502 22807 caffe.cpp:313] Batch 381, accuracy/top1 = 0.44
I0816 15:06:04.976524 22807 caffe.cpp:313] Batch 381, accuracy/top5 = 0.72
I0816 15:06:04.976528 22807 caffe.cpp:313] Batch 381, loss = 2.41417
I0816 15:06:05.039311 22807 caffe.cpp:313] Batch 382, accuracy/top1 = 0.58
I0816 15:06:05.039330 22807 caffe.cpp:313] Batch 382, accuracy/top5 = 0.7
I0816 15:06:05.039335 22807 caffe.cpp:313] Batch 382, loss = 2.126
I0816 15:06:05.102206 22807 caffe.cpp:313] Batch 383, accuracy/top1 = 0.64
I0816 15:06:05.102229 22807 caffe.cpp:313] Batch 383, accuracy/top5 = 0.86
I0816 15:06:05.102233 22807 caffe.cpp:313] Batch 383, loss = 1.64823
I0816 15:06:05.165099 22807 caffe.cpp:313] Batch 384, accuracy/top1 = 0.64
I0816 15:06:05.165122 22807 caffe.cpp:313] Batch 384, accuracy/top5 = 0.86
I0816 15:06:05.165127 22807 caffe.cpp:313] Batch 384, loss = 1.69903
I0816 15:06:05.227985 22807 caffe.cpp:313] Batch 385, accuracy/top1 = 0.6
I0816 15:06:05.228008 22807 caffe.cpp:313] Batch 385, accuracy/top5 = 0.82
I0816 15:06:05.228013 22807 caffe.cpp:313] Batch 385, loss = 1.56679
I0816 15:06:05.290957 22807 caffe.cpp:313] Batch 386, accuracy/top1 = 0.64
I0816 15:06:05.290980 22807 caffe.cpp:313] Batch 386, accuracy/top5 = 0.84
I0816 15:06:05.290984 22807 caffe.cpp:313] Batch 386, loss = 1.70129
I0816 15:06:05.353852 22807 caffe.cpp:313] Batch 387, accuracy/top1 = 0.52
I0816 15:06:05.353874 22807 caffe.cpp:313] Batch 387, accuracy/top5 = 0.8
I0816 15:06:05.353878 22807 caffe.cpp:313] Batch 387, loss = 1.69086
I0816 15:06:05.416729 22807 caffe.cpp:313] Batch 388, accuracy/top1 = 0.54
I0816 15:06:05.416750 22807 caffe.cpp:313] Batch 388, accuracy/top5 = 0.86
I0816 15:06:05.416755 22807 caffe.cpp:313] Batch 388, loss = 1.57946
I0816 15:06:05.479656 22807 caffe.cpp:313] Batch 389, accuracy/top1 = 0.5
I0816 15:06:05.479678 22807 caffe.cpp:313] Batch 389, accuracy/top5 = 0.7
I0816 15:06:05.479683 22807 caffe.cpp:313] Batch 389, loss = 2.13891
I0816 15:06:05.543193 22807 caffe.cpp:313] Batch 390, accuracy/top1 = 0.62
I0816 15:06:05.543211 22807 caffe.cpp:313] Batch 390, accuracy/top5 = 0.92
I0816 15:06:05.543216 22807 caffe.cpp:313] Batch 390, loss = 1.53226
I0816 15:06:05.606231 22807 caffe.cpp:313] Batch 391, accuracy/top1 = 0.56
I0816 15:06:05.606254 22807 caffe.cpp:313] Batch 391, accuracy/top5 = 0.84
I0816 15:06:05.606259 22807 caffe.cpp:313] Batch 391, loss = 1.80559
I0816 15:06:05.669214 22807 caffe.cpp:313] Batch 392, accuracy/top1 = 0.52
I0816 15:06:05.669237 22807 caffe.cpp:313] Batch 392, accuracy/top5 = 0.88
I0816 15:06:05.669241 22807 caffe.cpp:313] Batch 392, loss = 1.63799
I0816 15:06:05.732261 22807 caffe.cpp:313] Batch 393, accuracy/top1 = 0.54
I0816 15:06:05.732285 22807 caffe.cpp:313] Batch 393, accuracy/top5 = 0.68
I0816 15:06:05.732288 22807 caffe.cpp:313] Batch 393, loss = 2.20354
I0816 15:06:05.795258 22807 caffe.cpp:313] Batch 394, accuracy/top1 = 0.64
I0816 15:06:05.795281 22807 caffe.cpp:313] Batch 394, accuracy/top5 = 0.9
I0816 15:06:05.795285 22807 caffe.cpp:313] Batch 394, loss = 1.38066
I0816 15:06:05.858245 22807 caffe.cpp:313] Batch 395, accuracy/top1 = 0.74
I0816 15:06:05.858268 22807 caffe.cpp:313] Batch 395, accuracy/top5 = 0.88
I0816 15:06:05.858273 22807 caffe.cpp:313] Batch 395, loss = 1.55387
I0816 15:06:05.921291 22807 caffe.cpp:313] Batch 396, accuracy/top1 = 0.54
I0816 15:06:05.921314 22807 caffe.cpp:313] Batch 396, accuracy/top5 = 0.84
I0816 15:06:05.921319 22807 caffe.cpp:313] Batch 396, loss = 1.79627
I0816 15:06:05.984177 22807 caffe.cpp:313] Batch 397, accuracy/top1 = 0.5
I0816 15:06:05.984200 22807 caffe.cpp:313] Batch 397, accuracy/top5 = 0.78
I0816 15:06:05.984205 22807 caffe.cpp:313] Batch 397, loss = 2.41179
I0816 15:06:06.047278 22807 caffe.cpp:313] Batch 398, accuracy/top1 = 0.66
I0816 15:06:06.047296 22807 caffe.cpp:313] Batch 398, accuracy/top5 = 0.84
I0816 15:06:06.047299 22807 caffe.cpp:313] Batch 398, loss = 1.813
I0816 15:06:06.110395 22807 caffe.cpp:313] Batch 399, accuracy/top1 = 0.64
I0816 15:06:06.110417 22807 caffe.cpp:313] Batch 399, accuracy/top5 = 0.84
I0816 15:06:06.110421 22807 caffe.cpp:313] Batch 399, loss = 1.63141
I0816 15:06:06.173455 22807 caffe.cpp:313] Batch 400, accuracy/top1 = 0.5
I0816 15:06:06.173475 22807 caffe.cpp:313] Batch 400, accuracy/top5 = 0.72
I0816 15:06:06.173480 22807 caffe.cpp:313] Batch 400, loss = 2.11118
I0816 15:06:06.236515 22807 caffe.cpp:313] Batch 401, accuracy/top1 = 0.6
I0816 15:06:06.236536 22807 caffe.cpp:313] Batch 401, accuracy/top5 = 0.9
I0816 15:06:06.236541 22807 caffe.cpp:313] Batch 401, loss = 1.57405
I0816 15:06:06.299463 22807 caffe.cpp:313] Batch 402, accuracy/top1 = 0.64
I0816 15:06:06.299486 22807 caffe.cpp:313] Batch 402, accuracy/top5 = 0.76
I0816 15:06:06.299490 22807 caffe.cpp:313] Batch 402, loss = 1.98996
I0816 15:06:06.362515 22807 caffe.cpp:313] Batch 403, accuracy/top1 = 0.52
I0816 15:06:06.362537 22807 caffe.cpp:313] Batch 403, accuracy/top5 = 0.8
I0816 15:06:06.362542 22807 caffe.cpp:313] Batch 403, loss = 1.91615
I0816 15:06:06.425549 22807 caffe.cpp:313] Batch 404, accuracy/top1 = 0.74
I0816 15:06:06.425570 22807 caffe.cpp:313] Batch 404, accuracy/top5 = 0.88
I0816 15:06:06.425575 22807 caffe.cpp:313] Batch 404, loss = 1.4038
I0816 15:06:06.488440 22807 caffe.cpp:313] Batch 405, accuracy/top1 = 0.66
I0816 15:06:06.488461 22807 caffe.cpp:313] Batch 405, accuracy/top5 = 0.82
I0816 15:06:06.488464 22807 caffe.cpp:313] Batch 405, loss = 1.71149
I0816 15:06:06.551673 22807 caffe.cpp:313] Batch 406, accuracy/top1 = 0.66
I0816 15:06:06.551692 22807 caffe.cpp:313] Batch 406, accuracy/top5 = 0.86
I0816 15:06:06.551695 22807 caffe.cpp:313] Batch 406, loss = 1.58567
I0816 15:06:06.614615 22807 caffe.cpp:313] Batch 407, accuracy/top1 = 0.7
I0816 15:06:06.614637 22807 caffe.cpp:313] Batch 407, accuracy/top5 = 0.92
I0816 15:06:06.614642 22807 caffe.cpp:313] Batch 407, loss = 1.20431
I0816 15:06:06.677464 22807 caffe.cpp:313] Batch 408, accuracy/top1 = 0.5
I0816 15:06:06.677485 22807 caffe.cpp:313] Batch 408, accuracy/top5 = 0.78
I0816 15:06:06.677490 22807 caffe.cpp:313] Batch 408, loss = 2.21202
I0816 15:06:06.740262 22807 caffe.cpp:313] Batch 409, accuracy/top1 = 0.52
I0816 15:06:06.740284 22807 caffe.cpp:313] Batch 409, accuracy/top5 = 0.82
I0816 15:06:06.740288 22807 caffe.cpp:313] Batch 409, loss = 1.94116
I0816 15:06:06.803205 22807 caffe.cpp:313] Batch 410, accuracy/top1 = 0.6
I0816 15:06:06.803228 22807 caffe.cpp:313] Batch 410, accuracy/top5 = 0.78
I0816 15:06:06.803232 22807 caffe.cpp:313] Batch 410, loss = 1.86692
I0816 15:06:06.866116 22807 caffe.cpp:313] Batch 411, accuracy/top1 = 0.64
I0816 15:06:06.866138 22807 caffe.cpp:313] Batch 411, accuracy/top5 = 0.84
I0816 15:06:06.866142 22807 caffe.cpp:313] Batch 411, loss = 1.65872
I0816 15:06:06.929057 22807 caffe.cpp:313] Batch 412, accuracy/top1 = 0.62
I0816 15:06:06.929080 22807 caffe.cpp:313] Batch 412, accuracy/top5 = 0.88
I0816 15:06:06.929085 22807 caffe.cpp:313] Batch 412, loss = 1.42765
I0816 15:06:06.991896 22807 caffe.cpp:313] Batch 413, accuracy/top1 = 0.56
I0816 15:06:06.991919 22807 caffe.cpp:313] Batch 413, accuracy/top5 = 0.78
I0816 15:06:06.991922 22807 caffe.cpp:313] Batch 413, loss = 2.03563
I0816 15:06:07.054903 22807 caffe.cpp:313] Batch 414, accuracy/top1 = 0.52
I0816 15:06:07.054922 22807 caffe.cpp:313] Batch 414, accuracy/top5 = 0.82
I0816 15:06:07.054927 22807 caffe.cpp:313] Batch 414, loss = 1.987
I0816 15:06:07.117789 22807 caffe.cpp:313] Batch 415, accuracy/top1 = 0.64
I0816 15:06:07.117810 22807 caffe.cpp:313] Batch 415, accuracy/top5 = 0.8
I0816 15:06:07.117815 22807 caffe.cpp:313] Batch 415, loss = 1.67016
I0816 15:06:07.180753 22807 caffe.cpp:313] Batch 416, accuracy/top1 = 0.48
I0816 15:06:07.180774 22807 caffe.cpp:313] Batch 416, accuracy/top5 = 0.82
I0816 15:06:07.180779 22807 caffe.cpp:313] Batch 416, loss = 2.13429
I0816 15:06:07.243614 22807 caffe.cpp:313] Batch 417, accuracy/top1 = 0.56
I0816 15:06:07.243636 22807 caffe.cpp:313] Batch 417, accuracy/top5 = 0.78
I0816 15:06:07.243640 22807 caffe.cpp:313] Batch 417, loss = 1.87507
I0816 15:06:07.306486 22807 caffe.cpp:313] Batch 418, accuracy/top1 = 0.48
I0816 15:06:07.306509 22807 caffe.cpp:313] Batch 418, accuracy/top5 = 0.86
I0816 15:06:07.306514 22807 caffe.cpp:313] Batch 418, loss = 1.62385
I0816 15:06:07.369330 22807 caffe.cpp:313] Batch 419, accuracy/top1 = 0.56
I0816 15:06:07.369351 22807 caffe.cpp:313] Batch 419, accuracy/top5 = 0.78
I0816 15:06:07.369355 22807 caffe.cpp:313] Batch 419, loss = 2.0226
I0816 15:06:07.432284 22807 caffe.cpp:313] Batch 420, accuracy/top1 = 0.54
I0816 15:06:07.432307 22807 caffe.cpp:313] Batch 420, accuracy/top5 = 0.84
I0816 15:06:07.432310 22807 caffe.cpp:313] Batch 420, loss = 1.83075
I0816 15:06:07.495285 22807 caffe.cpp:313] Batch 421, accuracy/top1 = 0.66
I0816 15:06:07.495308 22807 caffe.cpp:313] Batch 421, accuracy/top5 = 0.84
I0816 15:06:07.495312 22807 caffe.cpp:313] Batch 421, loss = 1.72169
I0816 15:06:07.558609 22807 caffe.cpp:313] Batch 422, accuracy/top1 = 0.56
I0816 15:06:07.558630 22807 caffe.cpp:313] Batch 422, accuracy/top5 = 0.78
I0816 15:06:07.558634 22807 caffe.cpp:313] Batch 422, loss = 1.88898
I0816 15:06:07.621513 22807 caffe.cpp:313] Batch 423, accuracy/top1 = 0.58
I0816 15:06:07.621536 22807 caffe.cpp:313] Batch 423, accuracy/top5 = 0.74
I0816 15:06:07.621556 22807 caffe.cpp:313] Batch 423, loss = 2.21886
I0816 15:06:07.684389 22807 caffe.cpp:313] Batch 424, accuracy/top1 = 0.6
I0816 15:06:07.684412 22807 caffe.cpp:313] Batch 424, accuracy/top5 = 0.9
I0816 15:06:07.684417 22807 caffe.cpp:313] Batch 424, loss = 1.31115
I0816 15:06:07.747273 22807 caffe.cpp:313] Batch 425, accuracy/top1 = 0.66
I0816 15:06:07.747294 22807 caffe.cpp:313] Batch 425, accuracy/top5 = 0.82
I0816 15:06:07.747298 22807 caffe.cpp:313] Batch 425, loss = 1.86118
I0816 15:06:07.810235 22807 caffe.cpp:313] Batch 426, accuracy/top1 = 0.5
I0816 15:06:07.810257 22807 caffe.cpp:313] Batch 426, accuracy/top5 = 0.76
I0816 15:06:07.810261 22807 caffe.cpp:313] Batch 426, loss = 1.94792
I0816 15:06:07.873200 22807 caffe.cpp:313] Batch 427, accuracy/top1 = 0.6
I0816 15:06:07.873222 22807 caffe.cpp:313] Batch 427, accuracy/top5 = 0.82
I0816 15:06:07.873227 22807 caffe.cpp:313] Batch 427, loss = 1.6894
I0816 15:06:07.936095 22807 caffe.cpp:313] Batch 428, accuracy/top1 = 0.66
I0816 15:06:07.936117 22807 caffe.cpp:313] Batch 428, accuracy/top5 = 0.88
I0816 15:06:07.936121 22807 caffe.cpp:313] Batch 428, loss = 1.37215
I0816 15:06:07.999042 22807 caffe.cpp:313] Batch 429, accuracy/top1 = 0.68
I0816 15:06:07.999064 22807 caffe.cpp:313] Batch 429, accuracy/top5 = 0.84
I0816 15:06:07.999068 22807 caffe.cpp:313] Batch 429, loss = 1.43506
I0816 15:06:08.062026 22807 caffe.cpp:313] Batch 430, accuracy/top1 = 0.54
I0816 15:06:08.062043 22807 caffe.cpp:313] Batch 430, accuracy/top5 = 0.88
I0816 15:06:08.062048 22807 caffe.cpp:313] Batch 430, loss = 1.46589
I0816 15:06:08.125012 22807 caffe.cpp:313] Batch 431, accuracy/top1 = 0.62
I0816 15:06:08.125035 22807 caffe.cpp:313] Batch 431, accuracy/top5 = 0.84
I0816 15:06:08.125039 22807 caffe.cpp:313] Batch 431, loss = 1.92382
I0816 15:06:08.187873 22807 caffe.cpp:313] Batch 432, accuracy/top1 = 0.5
I0816 15:06:08.187896 22807 caffe.cpp:313] Batch 432, accuracy/top5 = 0.72
I0816 15:06:08.187901 22807 caffe.cpp:313] Batch 432, loss = 2.32333
I0816 15:06:08.250972 22807 caffe.cpp:313] Batch 433, accuracy/top1 = 0.58
I0816 15:06:08.250993 22807 caffe.cpp:313] Batch 433, accuracy/top5 = 0.88
I0816 15:06:08.250998 22807 caffe.cpp:313] Batch 433, loss = 1.55615
I0816 15:06:08.314083 22807 caffe.cpp:313] Batch 434, accuracy/top1 = 0.44
I0816 15:06:08.314102 22807 caffe.cpp:313] Batch 434, accuracy/top5 = 0.78
I0816 15:06:08.314105 22807 caffe.cpp:313] Batch 434, loss = 2.18918
I0816 15:06:08.377104 22807 caffe.cpp:313] Batch 435, accuracy/top1 = 0.66
I0816 15:06:08.377126 22807 caffe.cpp:313] Batch 435, accuracy/top5 = 0.88
I0816 15:06:08.377130 22807 caffe.cpp:313] Batch 435, loss = 1.50293
I0816 15:06:08.439941 22807 caffe.cpp:313] Batch 436, accuracy/top1 = 0.54
I0816 15:06:08.439965 22807 caffe.cpp:313] Batch 436, accuracy/top5 = 0.78
I0816 15:06:08.439967 22807 caffe.cpp:313] Batch 436, loss = 2.05898
I0816 15:06:08.502823 22807 caffe.cpp:313] Batch 437, accuracy/top1 = 0.48
I0816 15:06:08.502846 22807 caffe.cpp:313] Batch 437, accuracy/top5 = 0.7
I0816 15:06:08.502848 22807 caffe.cpp:313] Batch 437, loss = 2.12348
I0816 15:06:08.565960 22807 caffe.cpp:313] Batch 438, accuracy/top1 = 0.6
I0816 15:06:08.565982 22807 caffe.cpp:313] Batch 438, accuracy/top5 = 0.8
I0816 15:06:08.565985 22807 caffe.cpp:313] Batch 438, loss = 1.82312
I0816 15:06:08.628957 22807 caffe.cpp:313] Batch 439, accuracy/top1 = 0.62
I0816 15:06:08.628978 22807 caffe.cpp:313] Batch 439, accuracy/top5 = 0.8
I0816 15:06:08.628981 22807 caffe.cpp:313] Batch 439, loss = 1.96878
I0816 15:06:08.691874 22807 caffe.cpp:313] Batch 440, accuracy/top1 = 0.54
I0816 15:06:08.691895 22807 caffe.cpp:313] Batch 440, accuracy/top5 = 0.76
I0816 15:06:08.691898 22807 caffe.cpp:313] Batch 440, loss = 1.69096
I0816 15:06:08.754837 22807 caffe.cpp:313] Batch 441, accuracy/top1 = 0.52
I0816 15:06:08.754858 22807 caffe.cpp:313] Batch 441, accuracy/top5 = 0.86
I0816 15:06:08.754861 22807 caffe.cpp:313] Batch 441, loss = 1.62996
I0816 15:06:08.817662 22807 caffe.cpp:313] Batch 442, accuracy/top1 = 0.58
I0816 15:06:08.817695 22807 caffe.cpp:313] Batch 442, accuracy/top5 = 0.88
I0816 15:06:08.817699 22807 caffe.cpp:313] Batch 442, loss = 1.64952
I0816 15:06:08.880478 22807 caffe.cpp:313] Batch 443, accuracy/top1 = 0.7
I0816 15:06:08.880501 22807 caffe.cpp:313] Batch 443, accuracy/top5 = 0.82
I0816 15:06:08.880504 22807 caffe.cpp:313] Batch 443, loss = 1.49505
I0816 15:06:08.943404 22807 caffe.cpp:313] Batch 444, accuracy/top1 = 0.68
I0816 15:06:08.943426 22807 caffe.cpp:313] Batch 444, accuracy/top5 = 0.84
I0816 15:06:08.943429 22807 caffe.cpp:313] Batch 444, loss = 1.28322
I0816 15:06:09.006150 22807 caffe.cpp:313] Batch 445, accuracy/top1 = 0.6
I0816 15:06:09.006172 22807 caffe.cpp:313] Batch 445, accuracy/top5 = 0.84
I0816 15:06:09.006175 22807 caffe.cpp:313] Batch 445, loss = 1.60783
I0816 15:06:09.068888 22807 caffe.cpp:313] Batch 446, accuracy/top1 = 0.6
I0816 15:06:09.068909 22807 caffe.cpp:313] Batch 446, accuracy/top5 = 0.86
I0816 15:06:09.068912 22807 caffe.cpp:313] Batch 446, loss = 1.45768
I0816 15:06:09.131692 22807 caffe.cpp:313] Batch 447, accuracy/top1 = 0.6
I0816 15:06:09.131714 22807 caffe.cpp:313] Batch 447, accuracy/top5 = 0.82
I0816 15:06:09.131717 22807 caffe.cpp:313] Batch 447, loss = 1.69107
I0816 15:06:09.194453 22807 caffe.cpp:313] Batch 448, accuracy/top1 = 0.58
I0816 15:06:09.194476 22807 caffe.cpp:313] Batch 448, accuracy/top5 = 0.82
I0816 15:06:09.194479 22807 caffe.cpp:313] Batch 448, loss = 1.50208
I0816 15:06:09.257294 22807 caffe.cpp:313] Batch 449, accuracy/top1 = 0.52
I0816 15:06:09.257316 22807 caffe.cpp:313] Batch 449, accuracy/top5 = 0.8
I0816 15:06:09.257320 22807 caffe.cpp:313] Batch 449, loss = 2.01838
I0816 15:06:09.320103 22807 caffe.cpp:313] Batch 450, accuracy/top1 = 0.62
I0816 15:06:09.320125 22807 caffe.cpp:313] Batch 450, accuracy/top5 = 0.8
I0816 15:06:09.320137 22807 caffe.cpp:313] Batch 450, loss = 1.72529
I0816 15:06:09.382863 22807 caffe.cpp:313] Batch 451, accuracy/top1 = 0.58
I0816 15:06:09.382886 22807 caffe.cpp:313] Batch 451, accuracy/top5 = 0.84
I0816 15:06:09.382889 22807 caffe.cpp:313] Batch 451, loss = 1.68553
I0816 15:06:09.445847 22807 caffe.cpp:313] Batch 452, accuracy/top1 = 0.58
I0816 15:06:09.445868 22807 caffe.cpp:313] Batch 452, accuracy/top5 = 0.84
I0816 15:06:09.445870 22807 caffe.cpp:313] Batch 452, loss = 1.44115
I0816 15:06:09.508767 22807 caffe.cpp:313] Batch 453, accuracy/top1 = 0.6
I0816 15:06:09.508790 22807 caffe.cpp:313] Batch 453, accuracy/top5 = 0.84
I0816 15:06:09.508795 22807 caffe.cpp:313] Batch 453, loss = 1.6856
I0816 15:06:09.571938 22807 caffe.cpp:313] Batch 454, accuracy/top1 = 0.48
I0816 15:06:09.571959 22807 caffe.cpp:313] Batch 454, accuracy/top5 = 0.78
I0816 15:06:09.571962 22807 caffe.cpp:313] Batch 454, loss = 2.17461
I0816 15:06:09.634747 22807 caffe.cpp:313] Batch 455, accuracy/top1 = 0.54
I0816 15:06:09.634769 22807 caffe.cpp:313] Batch 455, accuracy/top5 = 0.82
I0816 15:06:09.634773 22807 caffe.cpp:313] Batch 455, loss = 1.80009
I0816 15:06:09.697578 22807 caffe.cpp:313] Batch 456, accuracy/top1 = 0.58
I0816 15:06:09.697600 22807 caffe.cpp:313] Batch 456, accuracy/top5 = 0.88
I0816 15:06:09.697603 22807 caffe.cpp:313] Batch 456, loss = 1.98553
I0816 15:06:09.760512 22807 caffe.cpp:313] Batch 457, accuracy/top1 = 0.48
I0816 15:06:09.760535 22807 caffe.cpp:313] Batch 457, accuracy/top5 = 0.7
I0816 15:06:09.760537 22807 caffe.cpp:313] Batch 457, loss = 2.06587
I0816 15:06:09.823477 22807 caffe.cpp:313] Batch 458, accuracy/top1 = 0.54
I0816 15:06:09.823498 22807 caffe.cpp:313] Batch 458, accuracy/top5 = 0.68
I0816 15:06:09.823503 22807 caffe.cpp:313] Batch 458, loss = 2.23166
I0816 15:06:09.886420 22807 caffe.cpp:313] Batch 459, accuracy/top1 = 0.62
I0816 15:06:09.886441 22807 caffe.cpp:313] Batch 459, accuracy/top5 = 0.86
I0816 15:06:09.886445 22807 caffe.cpp:313] Batch 459, loss = 1.36931
I0816 15:06:09.949232 22807 caffe.cpp:313] Batch 460, accuracy/top1 = 0.62
I0816 15:06:09.949254 22807 caffe.cpp:313] Batch 460, accuracy/top5 = 0.78
I0816 15:06:09.949259 22807 caffe.cpp:313] Batch 460, loss = 1.7754
I0816 15:06:10.012131 22807 caffe.cpp:313] Batch 461, accuracy/top1 = 0.66
I0816 15:06:10.012154 22807 caffe.cpp:313] Batch 461, accuracy/top5 = 0.9
I0816 15:06:10.012157 22807 caffe.cpp:313] Batch 461, loss = 1.42306
I0816 15:06:10.075078 22807 caffe.cpp:313] Batch 462, accuracy/top1 = 0.6
I0816 15:06:10.075100 22807 caffe.cpp:313] Batch 462, accuracy/top5 = 0.84
I0816 15:06:10.075103 22807 caffe.cpp:313] Batch 462, loss = 1.41806
I0816 15:06:10.137966 22807 caffe.cpp:313] Batch 463, accuracy/top1 = 0.54
I0816 15:06:10.137989 22807 caffe.cpp:313] Batch 463, accuracy/top5 = 0.7
I0816 15:06:10.137991 22807 caffe.cpp:313] Batch 463, loss = 2.07549
I0816 15:06:10.200775 22807 caffe.cpp:313] Batch 464, accuracy/top1 = 0.52
I0816 15:06:10.200798 22807 caffe.cpp:313] Batch 464, accuracy/top5 = 0.86
I0816 15:06:10.200801 22807 caffe.cpp:313] Batch 464, loss = 1.74319
I0816 15:06:10.263694 22807 caffe.cpp:313] Batch 465, accuracy/top1 = 0.6
I0816 15:06:10.263715 22807 caffe.cpp:313] Batch 465, accuracy/top5 = 0.82
I0816 15:06:10.263718 22807 caffe.cpp:313] Batch 465, loss = 1.61387
I0816 15:06:10.326596 22807 caffe.cpp:313] Batch 466, accuracy/top1 = 0.52
I0816 15:06:10.326715 22807 caffe.cpp:313] Batch 466, accuracy/top5 = 0.82
I0816 15:06:10.326720 22807 caffe.cpp:313] Batch 466, loss = 1.82237
I0816 15:06:10.389767 22807 caffe.cpp:313] Batch 467, accuracy/top1 = 0.66
I0816 15:06:10.389787 22807 caffe.cpp:313] Batch 467, accuracy/top5 = 0.9
I0816 15:06:10.389791 22807 caffe.cpp:313] Batch 467, loss = 1.51439
I0816 15:06:10.452823 22807 caffe.cpp:313] Batch 468, accuracy/top1 = 0.62
I0816 15:06:10.452842 22807 caffe.cpp:313] Batch 468, accuracy/top5 = 0.8
I0816 15:06:10.452846 22807 caffe.cpp:313] Batch 468, loss = 1.83353
I0816 15:06:10.516227 22807 caffe.cpp:313] Batch 469, accuracy/top1 = 0.52
I0816 15:06:10.516253 22807 caffe.cpp:313] Batch 469, accuracy/top5 = 0.84
I0816 15:06:10.516258 22807 caffe.cpp:313] Batch 469, loss = 1.66821
I0816 15:06:10.579216 22807 caffe.cpp:313] Batch 470, accuracy/top1 = 0.56
I0816 15:06:10.579238 22807 caffe.cpp:313] Batch 470, accuracy/top5 = 0.86
I0816 15:06:10.579242 22807 caffe.cpp:313] Batch 470, loss = 1.41868
I0816 15:06:10.642253 22807 caffe.cpp:313] Batch 471, accuracy/top1 = 0.66
I0816 15:06:10.642274 22807 caffe.cpp:313] Batch 471, accuracy/top5 = 0.88
I0816 15:06:10.642278 22807 caffe.cpp:313] Batch 471, loss = 1.39322
I0816 15:06:10.705191 22807 caffe.cpp:313] Batch 472, accuracy/top1 = 0.6
I0816 15:06:10.705214 22807 caffe.cpp:313] Batch 472, accuracy/top5 = 0.82
I0816 15:06:10.705219 22807 caffe.cpp:313] Batch 472, loss = 1.64267
I0816 15:06:10.768144 22807 caffe.cpp:313] Batch 473, accuracy/top1 = 0.7
I0816 15:06:10.768165 22807 caffe.cpp:313] Batch 473, accuracy/top5 = 0.84
I0816 15:06:10.768170 22807 caffe.cpp:313] Batch 473, loss = 1.73144
I0816 15:06:10.831034 22807 caffe.cpp:313] Batch 474, accuracy/top1 = 0.58
I0816 15:06:10.831058 22807 caffe.cpp:313] Batch 474, accuracy/top5 = 0.82
I0816 15:06:10.831061 22807 caffe.cpp:313] Batch 474, loss = 1.76342
I0816 15:06:10.893955 22807 caffe.cpp:313] Batch 475, accuracy/top1 = 0.56
I0816 15:06:10.893978 22807 caffe.cpp:313] Batch 475, accuracy/top5 = 0.82
I0816 15:06:10.893982 22807 caffe.cpp:313] Batch 475, loss = 1.85527
I0816 15:06:10.956948 22807 caffe.cpp:313] Batch 476, accuracy/top1 = 0.54
I0816 15:06:10.956971 22807 caffe.cpp:313] Batch 476, accuracy/top5 = 0.8
I0816 15:06:10.956975 22807 caffe.cpp:313] Batch 476, loss = 1.93462
I0816 15:06:11.019917 22807 caffe.cpp:313] Batch 477, accuracy/top1 = 0.44
I0816 15:06:11.019937 22807 caffe.cpp:313] Batch 477, accuracy/top5 = 0.78
I0816 15:06:11.019942 22807 caffe.cpp:313] Batch 477, loss = 1.85643
I0816 15:06:11.082816 22807 caffe.cpp:313] Batch 478, accuracy/top1 = 0.54
I0816 15:06:11.082839 22807 caffe.cpp:313] Batch 478, accuracy/top5 = 0.82
I0816 15:06:11.082842 22807 caffe.cpp:313] Batch 478, loss = 1.79227
I0816 15:06:11.145814 22807 caffe.cpp:313] Batch 479, accuracy/top1 = 0.56
I0816 15:06:11.145835 22807 caffe.cpp:313] Batch 479, accuracy/top5 = 0.76
I0816 15:06:11.145840 22807 caffe.cpp:313] Batch 479, loss = 2.09576
I0816 15:06:11.208745 22807 caffe.cpp:313] Batch 480, accuracy/top1 = 0.62
I0816 15:06:11.208767 22807 caffe.cpp:313] Batch 480, accuracy/top5 = 0.84
I0816 15:06:11.208771 22807 caffe.cpp:313] Batch 480, loss = 1.60565
I0816 15:06:11.271677 22807 caffe.cpp:313] Batch 481, accuracy/top1 = 0.56
I0816 15:06:11.271699 22807 caffe.cpp:313] Batch 481, accuracy/top5 = 0.8
I0816 15:06:11.271703 22807 caffe.cpp:313] Batch 481, loss = 1.87717
I0816 15:06:11.334563 22807 caffe.cpp:313] Batch 482, accuracy/top1 = 0.46
I0816 15:06:11.334584 22807 caffe.cpp:313] Batch 482, accuracy/top5 = 0.76
I0816 15:06:11.334589 22807 caffe.cpp:313] Batch 482, loss = 2.36121
I0816 15:06:11.397632 22807 caffe.cpp:313] Batch 483, accuracy/top1 = 0.52
I0816 15:06:11.397655 22807 caffe.cpp:313] Batch 483, accuracy/top5 = 0.84
I0816 15:06:11.397657 22807 caffe.cpp:313] Batch 483, loss = 1.61473
I0816 15:06:11.460592 22807 caffe.cpp:313] Batch 484, accuracy/top1 = 0.54
I0816 15:06:11.460614 22807 caffe.cpp:313] Batch 484, accuracy/top5 = 0.76
I0816 15:06:11.460618 22807 caffe.cpp:313] Batch 484, loss = 2.36647
I0816 15:06:11.523835 22807 caffe.cpp:313] Batch 485, accuracy/top1 = 0.68
I0816 15:06:11.523865 22807 caffe.cpp:313] Batch 485, accuracy/top5 = 0.76
I0816 15:06:11.523869 22807 caffe.cpp:313] Batch 485, loss = 1.69292
I0816 15:06:11.586746 22807 caffe.cpp:313] Batch 486, accuracy/top1 = 0.64
I0816 15:06:11.586768 22807 caffe.cpp:313] Batch 486, accuracy/top5 = 0.9
I0816 15:06:11.586772 22807 caffe.cpp:313] Batch 486, loss = 1.16394
I0816 15:06:11.649554 22807 caffe.cpp:313] Batch 487, accuracy/top1 = 0.56
I0816 15:06:11.649575 22807 caffe.cpp:313] Batch 487, accuracy/top5 = 0.74
I0816 15:06:11.649579 22807 caffe.cpp:313] Batch 487, loss = 2.35456
I0816 15:06:11.712532 22807 caffe.cpp:313] Batch 488, accuracy/top1 = 0.48
I0816 15:06:11.712553 22807 caffe.cpp:313] Batch 488, accuracy/top5 = 0.8
I0816 15:06:11.712556 22807 caffe.cpp:313] Batch 488, loss = 1.97105
I0816 15:06:11.775421 22807 caffe.cpp:313] Batch 489, accuracy/top1 = 0.6
I0816 15:06:11.775444 22807 caffe.cpp:313] Batch 489, accuracy/top5 = 0.8
I0816 15:06:11.775446 22807 caffe.cpp:313] Batch 489, loss = 1.73055
I0816 15:06:11.838330 22807 caffe.cpp:313] Batch 490, accuracy/top1 = 0.52
I0816 15:06:11.838351 22807 caffe.cpp:313] Batch 490, accuracy/top5 = 0.84
I0816 15:06:11.838356 22807 caffe.cpp:313] Batch 490, loss = 1.75103
I0816 15:06:11.901239 22807 caffe.cpp:313] Batch 491, accuracy/top1 = 0.62
I0816 15:06:11.901262 22807 caffe.cpp:313] Batch 491, accuracy/top5 = 0.86
I0816 15:06:11.901265 22807 caffe.cpp:313] Batch 491, loss = 1.70467
I0816 15:06:11.964180 22807 caffe.cpp:313] Batch 492, accuracy/top1 = 0.58
I0816 15:06:11.964202 22807 caffe.cpp:313] Batch 492, accuracy/top5 = 0.74
I0816 15:06:11.964205 22807 caffe.cpp:313] Batch 492, loss = 2.25981
I0816 15:06:12.027036 22807 caffe.cpp:313] Batch 493, accuracy/top1 = 0.6
I0816 15:06:12.027055 22807 caffe.cpp:313] Batch 493, accuracy/top5 = 0.8
I0816 15:06:12.027057 22807 caffe.cpp:313] Batch 493, loss = 1.85445
I0816 15:06:12.089831 22807 caffe.cpp:313] Batch 494, accuracy/top1 = 0.5
I0816 15:06:12.089854 22807 caffe.cpp:313] Batch 494, accuracy/top5 = 0.76
I0816 15:06:12.089856 22807 caffe.cpp:313] Batch 494, loss = 1.92923
I0816 15:06:12.152701 22807 caffe.cpp:313] Batch 495, accuracy/top1 = 0.64
I0816 15:06:12.152720 22807 caffe.cpp:313] Batch 495, accuracy/top5 = 0.88
I0816 15:06:12.152724 22807 caffe.cpp:313] Batch 495, loss = 1.42474
I0816 15:06:12.215515 22807 caffe.cpp:313] Batch 496, accuracy/top1 = 0.54
I0816 15:06:12.215536 22807 caffe.cpp:313] Batch 496, accuracy/top5 = 0.82
I0816 15:06:12.215539 22807 caffe.cpp:313] Batch 496, loss = 1.85552
I0816 15:06:12.278447 22807 caffe.cpp:313] Batch 497, accuracy/top1 = 0.56
I0816 15:06:12.278470 22807 caffe.cpp:313] Batch 497, accuracy/top5 = 0.74
I0816 15:06:12.278472 22807 caffe.cpp:313] Batch 497, loss = 1.96522
I0816 15:06:12.341307 22807 caffe.cpp:313] Batch 498, accuracy/top1 = 0.66
I0816 15:06:12.341328 22807 caffe.cpp:313] Batch 498, accuracy/top5 = 0.86
I0816 15:06:12.341331 22807 caffe.cpp:313] Batch 498, loss = 1.30802
I0816 15:06:12.404211 22807 caffe.cpp:313] Batch 499, accuracy/top1 = 0.56
I0816 15:06:12.404232 22807 caffe.cpp:313] Batch 499, accuracy/top5 = 0.78
I0816 15:06:12.404235 22807 caffe.cpp:313] Batch 499, loss = 1.77149
I0816 15:06:12.467072 22807 caffe.cpp:313] Batch 500, accuracy/top1 = 0.6
I0816 15:06:12.467094 22807 caffe.cpp:313] Batch 500, accuracy/top5 = 0.8
I0816 15:06:12.467098 22807 caffe.cpp:313] Batch 500, loss = 2.02082
I0816 15:06:12.530675 22807 caffe.cpp:313] Batch 501, accuracy/top1 = 0.58
I0816 15:06:12.530694 22807 caffe.cpp:313] Batch 501, accuracy/top5 = 0.78
I0816 15:06:12.530697 22807 caffe.cpp:313] Batch 501, loss = 1.90254
I0816 15:06:12.593683 22807 caffe.cpp:313] Batch 502, accuracy/top1 = 0.38
I0816 15:06:12.593703 22807 caffe.cpp:313] Batch 502, accuracy/top5 = 0.76
I0816 15:06:12.593706 22807 caffe.cpp:313] Batch 502, loss = 2.37037
I0816 15:06:12.656705 22807 caffe.cpp:313] Batch 503, accuracy/top1 = 0.62
I0816 15:06:12.656726 22807 caffe.cpp:313] Batch 503, accuracy/top5 = 0.78
I0816 15:06:12.656729 22807 caffe.cpp:313] Batch 503, loss = 1.91541
I0816 15:06:12.719540 22807 caffe.cpp:313] Batch 504, accuracy/top1 = 0.6
I0816 15:06:12.719563 22807 caffe.cpp:313] Batch 504, accuracy/top5 = 0.88
I0816 15:06:12.719565 22807 caffe.cpp:313] Batch 504, loss = 1.36771
I0816 15:06:12.782446 22807 caffe.cpp:313] Batch 505, accuracy/top1 = 0.54
I0816 15:06:12.782469 22807 caffe.cpp:313] Batch 505, accuracy/top5 = 0.88
I0816 15:06:12.782471 22807 caffe.cpp:313] Batch 505, loss = 1.65202
I0816 15:06:12.845288 22807 caffe.cpp:313] Batch 506, accuracy/top1 = 0.62
I0816 15:06:12.845310 22807 caffe.cpp:313] Batch 506, accuracy/top5 = 0.86
I0816 15:06:12.845314 22807 caffe.cpp:313] Batch 506, loss = 1.40888
I0816 15:06:12.908116 22807 caffe.cpp:313] Batch 507, accuracy/top1 = 0.48
I0816 15:06:12.908139 22807 caffe.cpp:313] Batch 507, accuracy/top5 = 0.8
I0816 15:06:12.908143 22807 caffe.cpp:313] Batch 507, loss = 2.30549
I0816 15:06:12.970993 22807 caffe.cpp:313] Batch 508, accuracy/top1 = 0.64
I0816 15:06:12.971015 22807 caffe.cpp:313] Batch 508, accuracy/top5 = 0.9
I0816 15:06:12.971019 22807 caffe.cpp:313] Batch 508, loss = 1.84947
I0816 15:06:13.033850 22807 caffe.cpp:313] Batch 509, accuracy/top1 = 0.52
I0816 15:06:13.033870 22807 caffe.cpp:313] Batch 509, accuracy/top5 = 0.84
I0816 15:06:13.033874 22807 caffe.cpp:313] Batch 509, loss = 1.80431
I0816 15:06:13.096732 22807 caffe.cpp:313] Batch 510, accuracy/top1 = 0.54
I0816 15:06:13.096755 22807 caffe.cpp:313] Batch 510, accuracy/top5 = 0.76
I0816 15:06:13.096758 22807 caffe.cpp:313] Batch 510, loss = 1.88982
I0816 15:06:13.159510 22807 caffe.cpp:313] Batch 511, accuracy/top1 = 0.62
I0816 15:06:13.159533 22807 caffe.cpp:313] Batch 511, accuracy/top5 = 0.86
I0816 15:06:13.159535 22807 caffe.cpp:313] Batch 511, loss = 1.6002
I0816 15:06:13.222416 22807 caffe.cpp:313] Batch 512, accuracy/top1 = 0.68
I0816 15:06:13.222439 22807 caffe.cpp:313] Batch 512, accuracy/top5 = 0.84
I0816 15:06:13.222442 22807 caffe.cpp:313] Batch 512, loss = 1.39214
I0816 15:06:13.285219 22807 caffe.cpp:313] Batch 513, accuracy/top1 = 0.52
I0816 15:06:13.285241 22807 caffe.cpp:313] Batch 513, accuracy/top5 = 0.78
I0816 15:06:13.285244 22807 caffe.cpp:313] Batch 513, loss = 2.00112
I0816 15:06:13.348203 22807 caffe.cpp:313] Batch 514, accuracy/top1 = 0.52
I0816 15:06:13.348227 22807 caffe.cpp:313] Batch 514, accuracy/top5 = 0.8
I0816 15:06:13.348229 22807 caffe.cpp:313] Batch 514, loss = 1.80062
I0816 15:06:13.411146 22807 caffe.cpp:313] Batch 515, accuracy/top1 = 0.56
I0816 15:06:13.411170 22807 caffe.cpp:313] Batch 515, accuracy/top5 = 0.76
I0816 15:06:13.411172 22807 caffe.cpp:313] Batch 515, loss = 1.96031
I0816 15:06:13.474097 22807 caffe.cpp:313] Batch 516, accuracy/top1 = 0.6
I0816 15:06:13.474119 22807 caffe.cpp:313] Batch 516, accuracy/top5 = 0.82
I0816 15:06:13.474123 22807 caffe.cpp:313] Batch 516, loss = 2.07695
I0816 15:06:13.537480 22807 caffe.cpp:313] Batch 517, accuracy/top1 = 0.62
I0816 15:06:13.537498 22807 caffe.cpp:313] Batch 517, accuracy/top5 = 0.82
I0816 15:06:13.537502 22807 caffe.cpp:313] Batch 517, loss = 1.45246
I0816 15:06:13.600472 22807 caffe.cpp:313] Batch 518, accuracy/top1 = 0.62
I0816 15:06:13.600493 22807 caffe.cpp:313] Batch 518, accuracy/top5 = 0.82
I0816 15:06:13.600497 22807 caffe.cpp:313] Batch 518, loss = 1.75475
I0816 15:06:13.663465 22807 caffe.cpp:313] Batch 519, accuracy/top1 = 0.6
I0816 15:06:13.663486 22807 caffe.cpp:313] Batch 519, accuracy/top5 = 0.82
I0816 15:06:13.663489 22807 caffe.cpp:313] Batch 519, loss = 1.72657
I0816 15:06:13.726327 22807 caffe.cpp:313] Batch 520, accuracy/top1 = 0.5
I0816 15:06:13.726349 22807 caffe.cpp:313] Batch 520, accuracy/top5 = 0.76
I0816 15:06:13.726352 22807 caffe.cpp:313] Batch 520, loss = 2.13985
I0816 15:06:13.789224 22807 caffe.cpp:313] Batch 521, accuracy/top1 = 0.56
I0816 15:06:13.789247 22807 caffe.cpp:313] Batch 521, accuracy/top5 = 0.84
I0816 15:06:13.789250 22807 caffe.cpp:313] Batch 521, loss = 1.73522
I0816 15:06:13.852118 22807 caffe.cpp:313] Batch 522, accuracy/top1 = 0.5
I0816 15:06:13.852140 22807 caffe.cpp:313] Batch 522, accuracy/top5 = 0.9
I0816 15:06:13.852157 22807 caffe.cpp:313] Batch 522, loss = 1.57401
I0816 15:06:13.915205 22807 caffe.cpp:313] Batch 523, accuracy/top1 = 0.62
I0816 15:06:13.915228 22807 caffe.cpp:313] Batch 523, accuracy/top5 = 0.88
I0816 15:06:13.915231 22807 caffe.cpp:313] Batch 523, loss = 1.45836
I0816 15:06:13.978039 22807 caffe.cpp:313] Batch 524, accuracy/top1 = 0.52
I0816 15:06:13.978060 22807 caffe.cpp:313] Batch 524, accuracy/top5 = 0.8
I0816 15:06:13.978065 22807 caffe.cpp:313] Batch 524, loss = 1.74865
I0816 15:06:14.040856 22807 caffe.cpp:313] Batch 525, accuracy/top1 = 0.62
I0816 15:06:14.040874 22807 caffe.cpp:313] Batch 525, accuracy/top5 = 0.8
I0816 15:06:14.040879 22807 caffe.cpp:313] Batch 525, loss = 1.79106
I0816 15:06:14.103610 22807 caffe.cpp:313] Batch 526, accuracy/top1 = 0.46
I0816 15:06:14.103632 22807 caffe.cpp:313] Batch 526, accuracy/top5 = 0.78
I0816 15:06:14.103636 22807 caffe.cpp:313] Batch 526, loss = 2.56362
I0816 15:06:14.166419 22807 caffe.cpp:313] Batch 527, accuracy/top1 = 0.56
I0816 15:06:14.166435 22807 caffe.cpp:313] Batch 527, accuracy/top5 = 0.82
I0816 15:06:14.166440 22807 caffe.cpp:313] Batch 527, loss = 1.73124
I0816 15:06:14.229337 22807 caffe.cpp:313] Batch 528, accuracy/top1 = 0.64
I0816 15:06:14.229358 22807 caffe.cpp:313] Batch 528, accuracy/top5 = 0.84
I0816 15:06:14.229362 22807 caffe.cpp:313] Batch 528, loss = 1.56058
I0816 15:06:14.292155 22807 caffe.cpp:313] Batch 529, accuracy/top1 = 0.5
I0816 15:06:14.292176 22807 caffe.cpp:313] Batch 529, accuracy/top5 = 0.82
I0816 15:06:14.292181 22807 caffe.cpp:313] Batch 529, loss = 1.7828
I0816 15:06:14.355074 22807 caffe.cpp:313] Batch 530, accuracy/top1 = 0.58
I0816 15:06:14.355096 22807 caffe.cpp:313] Batch 530, accuracy/top5 = 0.84
I0816 15:06:14.355099 22807 caffe.cpp:313] Batch 530, loss = 1.75162
I0816 15:06:14.417803 22807 caffe.cpp:313] Batch 531, accuracy/top1 = 0.52
I0816 15:06:14.417825 22807 caffe.cpp:313] Batch 531, accuracy/top5 = 0.84
I0816 15:06:14.417829 22807 caffe.cpp:313] Batch 531, loss = 1.86574
I0816 15:06:14.480731 22807 caffe.cpp:313] Batch 532, accuracy/top1 = 0.6
I0816 15:06:14.480753 22807 caffe.cpp:313] Batch 532, accuracy/top5 = 0.9
I0816 15:06:14.480757 22807 caffe.cpp:313] Batch 532, loss = 1.47476
I0816 15:06:14.544023 22807 caffe.cpp:313] Batch 533, accuracy/top1 = 0.46
I0816 15:06:14.544040 22807 caffe.cpp:313] Batch 533, accuracy/top5 = 0.7
I0816 15:06:14.544044 22807 caffe.cpp:313] Batch 533, loss = 2.33085
I0816 15:06:14.606992 22807 caffe.cpp:313] Batch 534, accuracy/top1 = 0.64
I0816 15:06:14.607012 22807 caffe.cpp:313] Batch 534, accuracy/top5 = 0.76
I0816 15:06:14.607015 22807 caffe.cpp:313] Batch 534, loss = 1.58825
I0816 15:06:14.669905 22807 caffe.cpp:313] Batch 535, accuracy/top1 = 0.52
I0816 15:06:14.669925 22807 caffe.cpp:313] Batch 535, accuracy/top5 = 0.84
I0816 15:06:14.669929 22807 caffe.cpp:313] Batch 535, loss = 1.62023
I0816 15:06:14.733011 22807 caffe.cpp:313] Batch 536, accuracy/top1 = 0.64
I0816 15:06:14.733029 22807 caffe.cpp:313] Batch 536, accuracy/top5 = 0.86
I0816 15:06:14.733033 22807 caffe.cpp:313] Batch 536, loss = 1.31685
I0816 15:06:14.796106 22807 caffe.cpp:313] Batch 537, accuracy/top1 = 0.62
I0816 15:06:14.796128 22807 caffe.cpp:313] Batch 537, accuracy/top5 = 0.88
I0816 15:06:14.796133 22807 caffe.cpp:313] Batch 537, loss = 1.46932
I0816 15:06:14.858892 22807 caffe.cpp:313] Batch 538, accuracy/top1 = 0.52
I0816 15:06:14.858914 22807 caffe.cpp:313] Batch 538, accuracy/top5 = 0.82
I0816 15:06:14.858917 22807 caffe.cpp:313] Batch 538, loss = 1.80234
I0816 15:06:14.921880 22807 caffe.cpp:313] Batch 539, accuracy/top1 = 0.38
I0816 15:06:14.921902 22807 caffe.cpp:313] Batch 539, accuracy/top5 = 0.76
I0816 15:06:14.921905 22807 caffe.cpp:313] Batch 539, loss = 2.40885
I0816 15:06:14.984768 22807 caffe.cpp:313] Batch 540, accuracy/top1 = 0.54
I0816 15:06:14.984791 22807 caffe.cpp:313] Batch 540, accuracy/top5 = 0.76
I0816 15:06:14.984793 22807 caffe.cpp:313] Batch 540, loss = 1.86866
I0816 15:06:15.047746 22807 caffe.cpp:313] Batch 541, accuracy/top1 = 0.6
I0816 15:06:15.047778 22807 caffe.cpp:313] Batch 541, accuracy/top5 = 0.8
I0816 15:06:15.047781 22807 caffe.cpp:313] Batch 541, loss = 1.75807
I0816 15:06:15.110677 22807 caffe.cpp:313] Batch 542, accuracy/top1 = 0.6
I0816 15:06:15.110700 22807 caffe.cpp:313] Batch 542, accuracy/top5 = 0.78
I0816 15:06:15.110703 22807 caffe.cpp:313] Batch 542, loss = 2.01449
I0816 15:06:15.173620 22807 caffe.cpp:313] Batch 543, accuracy/top1 = 0.62
I0816 15:06:15.173642 22807 caffe.cpp:313] Batch 543, accuracy/top5 = 0.88
I0816 15:06:15.173645 22807 caffe.cpp:313] Batch 543, loss = 1.46247
I0816 15:06:15.236500 22807 caffe.cpp:313] Batch 544, accuracy/top1 = 0.72
I0816 15:06:15.236523 22807 caffe.cpp:313] Batch 544, accuracy/top5 = 0.84
I0816 15:06:15.236526 22807 caffe.cpp:313] Batch 544, loss = 1.48856
I0816 15:06:15.299490 22807 caffe.cpp:313] Batch 545, accuracy/top1 = 0.54
I0816 15:06:15.299512 22807 caffe.cpp:313] Batch 545, accuracy/top5 = 0.82
I0816 15:06:15.299515 22807 caffe.cpp:313] Batch 545, loss = 1.72973
I0816 15:06:15.362458 22807 caffe.cpp:313] Batch 546, accuracy/top1 = 0.64
I0816 15:06:15.362479 22807 caffe.cpp:313] Batch 546, accuracy/top5 = 0.88
I0816 15:06:15.362483 22807 caffe.cpp:313] Batch 546, loss = 1.71972
I0816 15:06:15.425393 22807 caffe.cpp:313] Batch 547, accuracy/top1 = 0.5
I0816 15:06:15.425415 22807 caffe.cpp:313] Batch 547, accuracy/top5 = 0.84
I0816 15:06:15.425418 22807 caffe.cpp:313] Batch 547, loss = 1.6975
I0816 15:06:15.488266 22807 caffe.cpp:313] Batch 548, accuracy/top1 = 0.54
I0816 15:06:15.488288 22807 caffe.cpp:313] Batch 548, accuracy/top5 = 0.76
I0816 15:06:15.488291 22807 caffe.cpp:313] Batch 548, loss = 2.14927
I0816 15:06:15.551390 22807 caffe.cpp:313] Batch 549, accuracy/top1 = 0.6
I0816 15:06:15.551406 22807 caffe.cpp:313] Batch 549, accuracy/top5 = 0.76
I0816 15:06:15.551410 22807 caffe.cpp:313] Batch 549, loss = 2.05101
I0816 15:06:15.614349 22807 caffe.cpp:313] Batch 550, accuracy/top1 = 0.5
I0816 15:06:15.614372 22807 caffe.cpp:313] Batch 550, accuracy/top5 = 0.82
I0816 15:06:15.614374 22807 caffe.cpp:313] Batch 550, loss = 1.80111
I0816 15:06:15.677093 22807 caffe.cpp:313] Batch 551, accuracy/top1 = 0.66
I0816 15:06:15.677114 22807 caffe.cpp:313] Batch 551, accuracy/top5 = 0.8
I0816 15:06:15.677117 22807 caffe.cpp:313] Batch 551, loss = 1.53441
I0816 15:06:15.740008 22807 caffe.cpp:313] Batch 552, accuracy/top1 = 0.64
I0816 15:06:15.740030 22807 caffe.cpp:313] Batch 552, accuracy/top5 = 0.82
I0816 15:06:15.740032 22807 caffe.cpp:313] Batch 552, loss = 1.59171
I0816 15:06:15.802785 22807 caffe.cpp:313] Batch 553, accuracy/top1 = 0.6
I0816 15:06:15.802809 22807 caffe.cpp:313] Batch 553, accuracy/top5 = 0.8
I0816 15:06:15.802811 22807 caffe.cpp:313] Batch 553, loss = 1.59268
I0816 15:06:15.865661 22807 caffe.cpp:313] Batch 554, accuracy/top1 = 0.52
I0816 15:06:15.865684 22807 caffe.cpp:313] Batch 554, accuracy/top5 = 0.82
I0816 15:06:15.865687 22807 caffe.cpp:313] Batch 554, loss = 1.70134
I0816 15:06:15.928586 22807 caffe.cpp:313] Batch 555, accuracy/top1 = 0.62
I0816 15:06:15.928606 22807 caffe.cpp:313] Batch 555, accuracy/top5 = 0.96
I0816 15:06:15.928611 22807 caffe.cpp:313] Batch 555, loss = 1.32138
I0816 15:06:15.991395 22807 caffe.cpp:313] Batch 556, accuracy/top1 = 0.6
I0816 15:06:15.991415 22807 caffe.cpp:313] Batch 556, accuracy/top5 = 0.78
I0816 15:06:15.991420 22807 caffe.cpp:313] Batch 556, loss = 1.71816
I0816 15:06:16.054214 22807 caffe.cpp:313] Batch 557, accuracy/top1 = 0.56
I0816 15:06:16.054232 22807 caffe.cpp:313] Batch 557, accuracy/top5 = 0.86
I0816 15:06:16.054235 22807 caffe.cpp:313] Batch 557, loss = 1.70813
I0816 15:06:16.117094 22807 caffe.cpp:313] Batch 558, accuracy/top1 = 0.46
I0816 15:06:16.117115 22807 caffe.cpp:313] Batch 558, accuracy/top5 = 0.76
I0816 15:06:16.117117 22807 caffe.cpp:313] Batch 558, loss = 2.18963
I0816 15:06:16.180205 22807 caffe.cpp:313] Batch 559, accuracy/top1 = 0.6
I0816 15:06:16.180223 22807 caffe.cpp:313] Batch 559, accuracy/top5 = 0.8
I0816 15:06:16.180227 22807 caffe.cpp:313] Batch 559, loss = 1.76676
I0816 15:06:16.243152 22807 caffe.cpp:313] Batch 560, accuracy/top1 = 0.64
I0816 15:06:16.243186 22807 caffe.cpp:313] Batch 560, accuracy/top5 = 0.84
I0816 15:06:16.243191 22807 caffe.cpp:313] Batch 560, loss = 1.79423
I0816 15:06:16.306105 22807 caffe.cpp:313] Batch 561, accuracy/top1 = 0.6
I0816 15:06:16.306126 22807 caffe.cpp:313] Batch 561, accuracy/top5 = 0.76
I0816 15:06:16.306129 22807 caffe.cpp:313] Batch 561, loss = 2.01393
I0816 15:06:16.368944 22807 caffe.cpp:313] Batch 562, accuracy/top1 = 0.54
I0816 15:06:16.368966 22807 caffe.cpp:313] Batch 562, accuracy/top5 = 0.82
I0816 15:06:16.368969 22807 caffe.cpp:313] Batch 562, loss = 1.75142
I0816 15:06:16.434619 22807 caffe.cpp:313] Batch 563, accuracy/top1 = 0.62
I0816 15:06:16.434679 22807 caffe.cpp:313] Batch 563, accuracy/top5 = 0.8
I0816 15:06:16.434691 22807 caffe.cpp:313] Batch 563, loss = 1.80413
I0816 15:06:16.497877 22807 caffe.cpp:313] Batch 564, accuracy/top1 = 0.64
I0816 15:06:16.497903 22807 caffe.cpp:313] Batch 564, accuracy/top5 = 0.84
I0816 15:06:16.497907 22807 caffe.cpp:313] Batch 564, loss = 1.66407
I0816 15:06:16.559659 22807 caffe.cpp:313] Batch 565, accuracy/top1 = 0.6
I0816 15:06:16.559682 22807 caffe.cpp:313] Batch 565, accuracy/top5 = 0.86
I0816 15:06:16.559687 22807 caffe.cpp:313] Batch 565, loss = 1.54334
I0816 15:06:16.559705 22807 blocking_queue.cpp:40] Data layer prefetch queue empty
I0816 15:06:16.633999 22807 caffe.cpp:313] Batch 566, accuracy/top1 = 0.58
I0816 15:06:16.634021 22807 caffe.cpp:313] Batch 566, accuracy/top5 = 0.78
I0816 15:06:16.634027 22807 caffe.cpp:313] Batch 566, loss = 1.91565
I0816 15:06:16.697078 22807 caffe.cpp:313] Batch 567, accuracy/top1 = 0.48
I0816 15:06:16.697101 22807 caffe.cpp:313] Batch 567, accuracy/top5 = 0.78
I0816 15:06:16.697105 22807 caffe.cpp:313] Batch 567, loss = 1.95481
I0816 15:06:16.760151 22807 caffe.cpp:313] Batch 568, accuracy/top1 = 0.48
I0816 15:06:16.760170 22807 caffe.cpp:313] Batch 568, accuracy/top5 = 0.7
I0816 15:06:16.760174 22807 caffe.cpp:313] Batch 568, loss = 2.00127
I0816 15:06:16.823282 22807 caffe.cpp:313] Batch 569, accuracy/top1 = 0.46
I0816 15:06:16.823302 22807 caffe.cpp:313] Batch 569, accuracy/top5 = 0.72
I0816 15:06:16.823305 22807 caffe.cpp:313] Batch 569, loss = 2.65846
I0816 15:06:16.886358 22807 caffe.cpp:313] Batch 570, accuracy/top1 = 0.66
I0816 15:06:16.886379 22807 caffe.cpp:313] Batch 570, accuracy/top5 = 0.8
I0816 15:06:16.886382 22807 caffe.cpp:313] Batch 570, loss = 1.64435
I0816 15:06:16.949327 22807 caffe.cpp:313] Batch 571, accuracy/top1 = 0.46
I0816 15:06:16.949349 22807 caffe.cpp:313] Batch 571, accuracy/top5 = 0.66
I0816 15:06:16.949354 22807 caffe.cpp:313] Batch 571, loss = 2.49036
I0816 15:06:17.012336 22807 caffe.cpp:313] Batch 572, accuracy/top1 = 0.5
I0816 15:06:17.012358 22807 caffe.cpp:313] Batch 572, accuracy/top5 = 0.84
I0816 15:06:17.012362 22807 caffe.cpp:313] Batch 572, loss = 1.85792
I0816 15:06:17.075227 22807 caffe.cpp:313] Batch 573, accuracy/top1 = 0.68
I0816 15:06:17.075249 22807 caffe.cpp:313] Batch 573, accuracy/top5 = 0.84
I0816 15:06:17.075253 22807 caffe.cpp:313] Batch 573, loss = 1.825
I0816 15:06:17.138198 22807 caffe.cpp:313] Batch 574, accuracy/top1 = 0.54
I0816 15:06:17.138221 22807 caffe.cpp:313] Batch 574, accuracy/top5 = 0.76
I0816 15:06:17.138224 22807 caffe.cpp:313] Batch 574, loss = 2.15518
I0816 15:06:17.201162 22807 caffe.cpp:313] Batch 575, accuracy/top1 = 0.52
I0816 15:06:17.201184 22807 caffe.cpp:313] Batch 575, accuracy/top5 = 0.76
I0816 15:06:17.201189 22807 caffe.cpp:313] Batch 575, loss = 2.03888
I0816 15:06:17.264145 22807 caffe.cpp:313] Batch 576, accuracy/top1 = 0.7
I0816 15:06:17.264166 22807 caffe.cpp:313] Batch 576, accuracy/top5 = 0.9
I0816 15:06:17.264171 22807 caffe.cpp:313] Batch 576, loss = 1.25855
I0816 15:06:17.327108 22807 caffe.cpp:313] Batch 577, accuracy/top1 = 0.56
I0816 15:06:17.327129 22807 caffe.cpp:313] Batch 577, accuracy/top5 = 0.86
I0816 15:06:17.327134 22807 caffe.cpp:313] Batch 577, loss = 1.64308
I0816 15:06:17.390112 22807 caffe.cpp:313] Batch 578, accuracy/top1 = 0.6
I0816 15:06:17.390136 22807 caffe.cpp:313] Batch 578, accuracy/top5 = 0.8
I0816 15:06:17.390156 22807 caffe.cpp:313] Batch 578, loss = 1.95055
I0816 15:06:17.453052 22807 caffe.cpp:313] Batch 579, accuracy/top1 = 0.62
I0816 15:06:17.453074 22807 caffe.cpp:313] Batch 579, accuracy/top5 = 0.76
I0816 15:06:17.453078 22807 caffe.cpp:313] Batch 579, loss = 2.05696
I0816 15:06:17.516125 22807 caffe.cpp:313] Batch 580, accuracy/top1 = 0.66
I0816 15:06:17.516160 22807 caffe.cpp:313] Batch 580, accuracy/top5 = 0.88
I0816 15:06:17.516165 22807 caffe.cpp:313] Batch 580, loss = 1.59269
I0816 15:06:17.579396 22807 caffe.cpp:313] Batch 581, accuracy/top1 = 0.56
I0816 15:06:17.579417 22807 caffe.cpp:313] Batch 581, accuracy/top5 = 0.86
I0816 15:06:17.579421 22807 caffe.cpp:313] Batch 581, loss = 1.83322
I0816 15:06:17.642377 22807 caffe.cpp:313] Batch 582, accuracy/top1 = 0.6
I0816 15:06:17.642400 22807 caffe.cpp:313] Batch 582, accuracy/top5 = 0.84
I0816 15:06:17.642405 22807 caffe.cpp:313] Batch 582, loss = 1.51747
I0816 15:06:17.705256 22807 caffe.cpp:313] Batch 583, accuracy/top1 = 0.68
I0816 15:06:17.705279 22807 caffe.cpp:313] Batch 583, accuracy/top5 = 0.82
I0816 15:06:17.705283 22807 caffe.cpp:313] Batch 583, loss = 1.66893
I0816 15:06:17.768229 22807 caffe.cpp:313] Batch 584, accuracy/top1 = 0.58
I0816 15:06:17.768250 22807 caffe.cpp:313] Batch 584, accuracy/top5 = 0.9
I0816 15:06:17.768255 22807 caffe.cpp:313] Batch 584, loss = 1.2484
I0816 15:06:17.831212 22807 caffe.cpp:313] Batch 585, accuracy/top1 = 0.66
I0816 15:06:17.831234 22807 caffe.cpp:313] Batch 585, accuracy/top5 = 0.84
I0816 15:06:17.831238 22807 caffe.cpp:313] Batch 585, loss = 1.45213
I0816 15:06:17.894045 22807 caffe.cpp:313] Batch 586, accuracy/top1 = 0.54
I0816 15:06:17.894068 22807 caffe.cpp:313] Batch 586, accuracy/top5 = 0.82
I0816 15:06:17.894071 22807 caffe.cpp:313] Batch 586, loss = 1.74744
I0816 15:06:17.957051 22807 caffe.cpp:313] Batch 587, accuracy/top1 = 0.66
I0816 15:06:17.957074 22807 caffe.cpp:313] Batch 587, accuracy/top5 = 0.82
I0816 15:06:17.957078 22807 caffe.cpp:313] Batch 587, loss = 1.3037
I0816 15:06:18.019894 22807 caffe.cpp:313] Batch 588, accuracy/top1 = 0.64
I0816 15:06:18.019915 22807 caffe.cpp:313] Batch 588, accuracy/top5 = 0.86
I0816 15:06:18.019919 22807 caffe.cpp:313] Batch 588, loss = 1.40268
I0816 15:06:18.082878 22807 caffe.cpp:313] Batch 589, accuracy/top1 = 0.58
I0816 15:06:18.082901 22807 caffe.cpp:313] Batch 589, accuracy/top5 = 0.86
I0816 15:06:18.082904 22807 caffe.cpp:313] Batch 589, loss = 1.81249
I0816 15:06:18.145922 22807 caffe.cpp:313] Batch 590, accuracy/top1 = 0.58
I0816 15:06:18.145943 22807 caffe.cpp:313] Batch 590, accuracy/top5 = 0.82
I0816 15:06:18.145947 22807 caffe.cpp:313] Batch 590, loss = 1.95284
I0816 15:06:18.208860 22807 caffe.cpp:313] Batch 591, accuracy/top1 = 0.62
I0816 15:06:18.208878 22807 caffe.cpp:313] Batch 591, accuracy/top5 = 0.78
I0816 15:06:18.208883 22807 caffe.cpp:313] Batch 591, loss = 1.69935
I0816 15:06:18.271924 22807 caffe.cpp:313] Batch 592, accuracy/top1 = 0.58
I0816 15:06:18.271946 22807 caffe.cpp:313] Batch 592, accuracy/top5 = 0.84
I0816 15:06:18.271951 22807 caffe.cpp:313] Batch 592, loss = 1.61764
I0816 15:06:18.334834 22807 caffe.cpp:313] Batch 593, accuracy/top1 = 0.5
I0816 15:06:18.334857 22807 caffe.cpp:313] Batch 593, accuracy/top5 = 0.74
I0816 15:06:18.334861 22807 caffe.cpp:313] Batch 593, loss = 2.15988
I0816 15:06:18.397747 22807 caffe.cpp:313] Batch 594, accuracy/top1 = 0.56
I0816 15:06:18.397768 22807 caffe.cpp:313] Batch 594, accuracy/top5 = 0.82
I0816 15:06:18.397773 22807 caffe.cpp:313] Batch 594, loss = 1.85977
I0816 15:06:18.460697 22807 caffe.cpp:313] Batch 595, accuracy/top1 = 0.64
I0816 15:06:18.460721 22807 caffe.cpp:313] Batch 595, accuracy/top5 = 0.9
I0816 15:06:18.460724 22807 caffe.cpp:313] Batch 595, loss = 1.52718
I0816 15:06:18.524271 22807 caffe.cpp:313] Batch 596, accuracy/top1 = 0.54
I0816 15:06:18.524291 22807 caffe.cpp:313] Batch 596, accuracy/top5 = 0.68
I0816 15:06:18.524294 22807 caffe.cpp:313] Batch 596, loss = 2.31655
I0816 15:06:18.587131 22807 caffe.cpp:313] Batch 597, accuracy/top1 = 0.72
I0816 15:06:18.587167 22807 caffe.cpp:313] Batch 597, accuracy/top5 = 0.88
I0816 15:06:18.587172 22807 caffe.cpp:313] Batch 597, loss = 1.23991
I0816 15:06:18.650024 22807 caffe.cpp:313] Batch 598, accuracy/top1 = 0.46
I0816 15:06:18.650048 22807 caffe.cpp:313] Batch 598, accuracy/top5 = 0.72
I0816 15:06:18.650051 22807 caffe.cpp:313] Batch 598, loss = 2.27646
I0816 15:06:18.713048 22807 caffe.cpp:313] Batch 599, accuracy/top1 = 0.58
I0816 15:06:18.713070 22807 caffe.cpp:313] Batch 599, accuracy/top5 = 0.76
I0816 15:06:18.713075 22807 caffe.cpp:313] Batch 599, loss = 1.90849
I0816 15:06:18.776031 22807 caffe.cpp:313] Batch 600, accuracy/top1 = 0.54
I0816 15:06:18.776054 22807 caffe.cpp:313] Batch 600, accuracy/top5 = 0.76
I0816 15:06:18.776058 22807 caffe.cpp:313] Batch 600, loss = 1.88942
I0816 15:06:18.838922 22807 caffe.cpp:313] Batch 601, accuracy/top1 = 0.56
I0816 15:06:18.838945 22807 caffe.cpp:313] Batch 601, accuracy/top5 = 0.9
I0816 15:06:18.838949 22807 caffe.cpp:313] Batch 601, loss = 1.48672
I0816 15:06:18.901924 22807 caffe.cpp:313] Batch 602, accuracy/top1 = 0.46
I0816 15:06:18.901944 22807 caffe.cpp:313] Batch 602, accuracy/top5 = 0.74
I0816 15:06:18.901948 22807 caffe.cpp:313] Batch 602, loss = 2.3079
I0816 15:06:18.965157 22807 caffe.cpp:313] Batch 603, accuracy/top1 = 0.66
I0816 15:06:18.965178 22807 caffe.cpp:313] Batch 603, accuracy/top5 = 0.78
I0816 15:06:18.965181 22807 caffe.cpp:313] Batch 603, loss = 1.38481
I0816 15:06:19.028357 22807 caffe.cpp:313] Batch 604, accuracy/top1 = 0.72
I0816 15:06:19.028378 22807 caffe.cpp:313] Batch 604, accuracy/top5 = 0.96
I0816 15:06:19.028381 22807 caffe.cpp:313] Batch 604, loss = 1.00083
I0816 15:06:19.091415 22807 caffe.cpp:313] Batch 605, accuracy/top1 = 0.52
I0816 15:06:19.091439 22807 caffe.cpp:313] Batch 605, accuracy/top5 = 0.66
I0816 15:06:19.091442 22807 caffe.cpp:313] Batch 605, loss = 2.20881
I0816 15:06:19.154413 22807 caffe.cpp:313] Batch 606, accuracy/top1 = 0.62
I0816 15:06:19.154436 22807 caffe.cpp:313] Batch 606, accuracy/top5 = 0.84
I0816 15:06:19.154440 22807 caffe.cpp:313] Batch 606, loss = 1.77674
I0816 15:06:19.217347 22807 caffe.cpp:313] Batch 607, accuracy/top1 = 0.54
I0816 15:06:19.217370 22807 caffe.cpp:313] Batch 607, accuracy/top5 = 0.78
I0816 15:06:19.217375 22807 caffe.cpp:313] Batch 607, loss = 1.805
I0816 15:06:19.280390 22807 caffe.cpp:313] Batch 608, accuracy/top1 = 0.58
I0816 15:06:19.280412 22807 caffe.cpp:313] Batch 608, accuracy/top5 = 0.84
I0816 15:06:19.280416 22807 caffe.cpp:313] Batch 608, loss = 1.60146
I0816 15:06:19.343240 22807 caffe.cpp:313] Batch 609, accuracy/top1 = 0.6
I0816 15:06:19.343261 22807 caffe.cpp:313] Batch 609, accuracy/top5 = 0.8
I0816 15:06:19.343266 22807 caffe.cpp:313] Batch 609, loss = 1.97239
I0816 15:06:19.406304 22807 caffe.cpp:313] Batch 610, accuracy/top1 = 0.52
I0816 15:06:19.406327 22807 caffe.cpp:313] Batch 610, accuracy/top5 = 0.76
I0816 15:06:19.406332 22807 caffe.cpp:313] Batch 610, loss = 2.05308
I0816 15:06:19.469126 22807 caffe.cpp:313] Batch 611, accuracy/top1 = 0.64
I0816 15:06:19.469148 22807 caffe.cpp:313] Batch 611, accuracy/top5 = 0.8
I0816 15:06:19.469152 22807 caffe.cpp:313] Batch 611, loss = 1.70332
I0816 15:06:19.532441 22807 caffe.cpp:313] Batch 612, accuracy/top1 = 0.62
I0816 15:06:19.532459 22807 caffe.cpp:313] Batch 612, accuracy/top5 = 0.82
I0816 15:06:19.532464 22807 caffe.cpp:313] Batch 612, loss = 1.50507
I0816 15:06:19.595530 22807 caffe.cpp:313] Batch 613, accuracy/top1 = 0.54
I0816 15:06:19.595552 22807 caffe.cpp:313] Batch 613, accuracy/top5 = 0.76
I0816 15:06:19.595556 22807 caffe.cpp:313] Batch 613, loss = 2.20318
I0816 15:06:19.658478 22807 caffe.cpp:313] Batch 614, accuracy/top1 = 0.5
I0816 15:06:19.658500 22807 caffe.cpp:313] Batch 614, accuracy/top5 = 0.78
I0816 15:06:19.658505 22807 caffe.cpp:313] Batch 614, loss = 2.17275
I0816 15:06:19.721498 22807 caffe.cpp:313] Batch 615, accuracy/top1 = 0.42
I0816 15:06:19.721520 22807 caffe.cpp:313] Batch 615, accuracy/top5 = 0.78
I0816 15:06:19.721525 22807 caffe.cpp:313] Batch 615, loss = 2.19838
I0816 15:06:19.784461 22807 caffe.cpp:313] Batch 616, accuracy/top1 = 0.52
I0816 15:06:19.784483 22807 caffe.cpp:313] Batch 616, accuracy/top5 = 0.84
I0816 15:06:19.784488 22807 caffe.cpp:313] Batch 616, loss = 1.86286
I0816 15:06:19.847368 22807 caffe.cpp:313] Batch 617, accuracy/top1 = 0.5
I0816 15:06:19.847389 22807 caffe.cpp:313] Batch 617, accuracy/top5 = 0.76
I0816 15:06:19.847393 22807 caffe.cpp:313] Batch 617, loss = 2.01015
I0816 15:06:19.910445 22807 caffe.cpp:313] Batch 618, accuracy/top1 = 0.46
I0816 15:06:19.910468 22807 caffe.cpp:313] Batch 618, accuracy/top5 = 0.82
I0816 15:06:19.910472 22807 caffe.cpp:313] Batch 618, loss = 2.05873
I0816 15:06:19.973428 22807 caffe.cpp:313] Batch 619, accuracy/top1 = 0.7
I0816 15:06:19.973449 22807 caffe.cpp:313] Batch 619, accuracy/top5 = 0.84
I0816 15:06:19.973454 22807 caffe.cpp:313] Batch 619, loss = 1.3062
I0816 15:06:20.036257 22807 caffe.cpp:313] Batch 620, accuracy/top1 = 0.5
I0816 15:06:20.036275 22807 caffe.cpp:313] Batch 620, accuracy/top5 = 0.8
I0816 15:06:20.036279 22807 caffe.cpp:313] Batch 620, loss = 1.85799
I0816 15:06:20.099298 22807 caffe.cpp:313] Batch 621, accuracy/top1 = 0.56
I0816 15:06:20.099320 22807 caffe.cpp:313] Batch 621, accuracy/top5 = 0.82
I0816 15:06:20.099325 22807 caffe.cpp:313] Batch 621, loss = 1.89437
I0816 15:06:20.162398 22807 caffe.cpp:313] Batch 622, accuracy/top1 = 0.54
I0816 15:06:20.162420 22807 caffe.cpp:313] Batch 622, accuracy/top5 = 0.78
I0816 15:06:20.162425 22807 caffe.cpp:313] Batch 622, loss = 2.06309
I0816 15:06:20.225428 22807 caffe.cpp:313] Batch 623, accuracy/top1 = 0.52
I0816 15:06:20.225445 22807 caffe.cpp:313] Batch 623, accuracy/top5 = 0.84
I0816 15:06:20.225450 22807 caffe.cpp:313] Batch 623, loss = 2.01694
I0816 15:06:20.288594 22807 caffe.cpp:313] Batch 624, accuracy/top1 = 0.58
I0816 15:06:20.288615 22807 caffe.cpp:313] Batch 624, accuracy/top5 = 0.8
I0816 15:06:20.288619 22807 caffe.cpp:313] Batch 624, loss = 1.82185
I0816 15:06:20.351470 22807 caffe.cpp:313] Batch 625, accuracy/top1 = 0.56
I0816 15:06:20.351493 22807 caffe.cpp:313] Batch 625, accuracy/top5 = 0.78
I0816 15:06:20.351498 22807 caffe.cpp:313] Batch 625, loss = 2.34479
I0816 15:06:20.414484 22807 caffe.cpp:313] Batch 626, accuracy/top1 = 0.42
I0816 15:06:20.414505 22807 caffe.cpp:313] Batch 626, accuracy/top5 = 0.68
I0816 15:06:20.414510 22807 caffe.cpp:313] Batch 626, loss = 2.76701
I0816 15:06:20.477445 22807 caffe.cpp:313] Batch 627, accuracy/top1 = 0.48
I0816 15:06:20.477468 22807 caffe.cpp:313] Batch 627, accuracy/top5 = 0.78
I0816 15:06:20.477473 22807 caffe.cpp:313] Batch 627, loss = 2.26759
I0816 15:06:20.540792 22807 caffe.cpp:313] Batch 628, accuracy/top1 = 0.58
I0816 15:06:20.540809 22807 caffe.cpp:313] Batch 628, accuracy/top5 = 0.82
I0816 15:06:20.540814 22807 caffe.cpp:313] Batch 628, loss = 1.9545
I0816 15:06:20.603739 22807 caffe.cpp:313] Batch 629, accuracy/top1 = 0.56
I0816 15:06:20.603760 22807 caffe.cpp:313] Batch 629, accuracy/top5 = 0.72
I0816 15:06:20.603765 22807 caffe.cpp:313] Batch 629, loss = 2.05405
I0816 15:06:20.666716 22807 caffe.cpp:313] Batch 630, accuracy/top1 = 0.44
I0816 15:06:20.666739 22807 caffe.cpp:313] Batch 630, accuracy/top5 = 0.6
I0816 15:06:20.666743 22807 caffe.cpp:313] Batch 630, loss = 2.5298
I0816 15:06:20.729734 22807 caffe.cpp:313] Batch 631, accuracy/top1 = 0.62
I0816 15:06:20.729756 22807 caffe.cpp:313] Batch 631, accuracy/top5 = 0.88
I0816 15:06:20.729760 22807 caffe.cpp:313] Batch 631, loss = 1.35617
I0816 15:06:20.792682 22807 caffe.cpp:313] Batch 632, accuracy/top1 = 0.54
I0816 15:06:20.792706 22807 caffe.cpp:313] Batch 632, accuracy/top5 = 0.84
I0816 15:06:20.792709 22807 caffe.cpp:313] Batch 632, loss = 1.60871
I0816 15:06:20.855675 22807 caffe.cpp:313] Batch 633, accuracy/top1 = 0.58
I0816 15:06:20.855698 22807 caffe.cpp:313] Batch 633, accuracy/top5 = 0.72
I0816 15:06:20.855702 22807 caffe.cpp:313] Batch 633, loss = 2.05836
I0816 15:06:20.918725 22807 caffe.cpp:313] Batch 634, accuracy/top1 = 0.54
I0816 15:06:20.918746 22807 caffe.cpp:313] Batch 634, accuracy/top5 = 0.74
I0816 15:06:20.918766 22807 caffe.cpp:313] Batch 634, loss = 2.30995
I0816 15:06:20.981621 22807 caffe.cpp:313] Batch 635, accuracy/top1 = 0.62
I0816 15:06:20.981644 22807 caffe.cpp:313] Batch 635, accuracy/top5 = 0.8
I0816 15:06:20.981648 22807 caffe.cpp:313] Batch 635, loss = 1.84175
I0816 15:06:21.044627 22807 caffe.cpp:313] Batch 636, accuracy/top1 = 0.56
I0816 15:06:21.044648 22807 caffe.cpp:313] Batch 636, accuracy/top5 = 0.78
I0816 15:06:21.044652 22807 caffe.cpp:313] Batch 636, loss = 2.13632
I0816 15:06:21.108295 22807 caffe.cpp:313] Batch 637, accuracy/top1 = 0.54
I0816 15:06:21.108316 22807 caffe.cpp:313] Batch 637, accuracy/top5 = 0.88
I0816 15:06:21.108320 22807 caffe.cpp:313] Batch 637, loss = 1.59605
I0816 15:06:21.171926 22807 caffe.cpp:313] Batch 638, accuracy/top1 = 0.56
I0816 15:06:21.171949 22807 caffe.cpp:313] Batch 638, accuracy/top5 = 0.8
I0816 15:06:21.171953 22807 caffe.cpp:313] Batch 638, loss = 1.75808
I0816 15:06:21.235304 22807 caffe.cpp:313] Batch 639, accuracy/top1 = 0.56
I0816 15:06:21.235327 22807 caffe.cpp:313] Batch 639, accuracy/top5 = 0.82
I0816 15:06:21.235330 22807 caffe.cpp:313] Batch 639, loss = 1.71954
I0816 15:06:21.298825 22807 caffe.cpp:313] Batch 640, accuracy/top1 = 0.48
I0816 15:06:21.298848 22807 caffe.cpp:313] Batch 640, accuracy/top5 = 0.8
I0816 15:06:21.298853 22807 caffe.cpp:313] Batch 640, loss = 1.88618
I0816 15:06:21.362272 22807 caffe.cpp:313] Batch 641, accuracy/top1 = 0.5
I0816 15:06:21.362293 22807 caffe.cpp:313] Batch 641, accuracy/top5 = 0.86
I0816 15:06:21.362298 22807 caffe.cpp:313] Batch 641, loss = 1.65639
I0816 15:06:21.425767 22807 caffe.cpp:313] Batch 642, accuracy/top1 = 0.62
I0816 15:06:21.425791 22807 caffe.cpp:313] Batch 642, accuracy/top5 = 0.78
I0816 15:06:21.425796 22807 caffe.cpp:313] Batch 642, loss = 1.86508
I0816 15:06:21.489260 22807 caffe.cpp:313] Batch 643, accuracy/top1 = 0.46
I0816 15:06:21.489282 22807 caffe.cpp:313] Batch 643, accuracy/top5 = 0.84
I0816 15:06:21.489287 22807 caffe.cpp:313] Batch 643, loss = 1.69254
I0816 15:06:21.553158 22807 caffe.cpp:313] Batch 644, accuracy/top1 = 0.56
I0816 15:06:21.553175 22807 caffe.cpp:313] Batch 644, accuracy/top5 = 0.78
I0816 15:06:21.553179 22807 caffe.cpp:313] Batch 644, loss = 2.01281
I0816 15:06:21.616617 22807 caffe.cpp:313] Batch 645, accuracy/top1 = 0.56
I0816 15:06:21.616639 22807 caffe.cpp:313] Batch 645, accuracy/top5 = 0.88
I0816 15:06:21.616643 22807 caffe.cpp:313] Batch 645, loss = 1.62237
I0816 15:06:21.680197 22807 caffe.cpp:313] Batch 646, accuracy/top1 = 0.62
I0816 15:06:21.680220 22807 caffe.cpp:313] Batch 646, accuracy/top5 = 0.86
I0816 15:06:21.680225 22807 caffe.cpp:313] Batch 646, loss = 1.51754
I0816 15:06:21.743660 22807 caffe.cpp:313] Batch 647, accuracy/top1 = 0.5
I0816 15:06:21.743682 22807 caffe.cpp:313] Batch 647, accuracy/top5 = 0.72
I0816 15:06:21.743687 22807 caffe.cpp:313] Batch 647, loss = 2.26081
I0816 15:06:21.807138 22807 caffe.cpp:313] Batch 648, accuracy/top1 = 0.6
I0816 15:06:21.807162 22807 caffe.cpp:313] Batch 648, accuracy/top5 = 0.82
I0816 15:06:21.807165 22807 caffe.cpp:313] Batch 648, loss = 1.44085
I0816 15:06:21.870493 22807 caffe.cpp:313] Batch 649, accuracy/top1 = 0.58
I0816 15:06:21.870517 22807 caffe.cpp:313] Batch 649, accuracy/top5 = 0.76
I0816 15:06:21.870520 22807 caffe.cpp:313] Batch 649, loss = 1.83338
I0816 15:06:21.933995 22807 caffe.cpp:313] Batch 650, accuracy/top1 = 0.6
I0816 15:06:21.934017 22807 caffe.cpp:313] Batch 650, accuracy/top5 = 0.78
I0816 15:06:21.934021 22807 caffe.cpp:313] Batch 650, loss = 1.67838
I0816 15:06:21.997509 22807 caffe.cpp:313] Batch 651, accuracy/top1 = 0.5
I0816 15:06:21.997532 22807 caffe.cpp:313] Batch 651, accuracy/top5 = 0.7
I0816 15:06:21.997536 22807 caffe.cpp:313] Batch 651, loss = 2.32815
I0816 15:06:22.061091 22807 caffe.cpp:313] Batch 652, accuracy/top1 = 0.52
I0816 15:06:22.061111 22807 caffe.cpp:313] Batch 652, accuracy/top5 = 0.76
I0816 15:06:22.061115 22807 caffe.cpp:313] Batch 652, loss = 2.19419
I0816 15:06:22.124601 22807 caffe.cpp:313] Batch 653, accuracy/top1 = 0.3
I0816 15:06:22.124625 22807 caffe.cpp:313] Batch 653, accuracy/top5 = 0.8
I0816 15:06:22.124646 22807 caffe.cpp:313] Batch 653, loss = 2.11329
I0816 15:06:22.187965 22807 caffe.cpp:313] Batch 654, accuracy/top1 = 0.5
I0816 15:06:22.187988 22807 caffe.cpp:313] Batch 654, accuracy/top5 = 0.84
I0816 15:06:22.187993 22807 caffe.cpp:313] Batch 654, loss = 1.92716
I0816 15:06:22.251570 22807 caffe.cpp:313] Batch 655, accuracy/top1 = 0.64
I0816 15:06:22.251590 22807 caffe.cpp:313] Batch 655, accuracy/top5 = 0.84
I0816 15:06:22.251595 22807 caffe.cpp:313] Batch 655, loss = 1.40765
I0816 15:06:22.314533 22807 caffe.cpp:313] Batch 656, accuracy/top1 = 0.64
I0816 15:06:22.314554 22807 caffe.cpp:313] Batch 656, accuracy/top5 = 0.9
I0816 15:06:22.314558 22807 caffe.cpp:313] Batch 656, loss = 1.50865
I0816 15:06:22.377442 22807 caffe.cpp:313] Batch 657, accuracy/top1 = 0.56
I0816 15:06:22.377465 22807 caffe.cpp:313] Batch 657, accuracy/top5 = 0.74
I0816 15:06:22.377468 22807 caffe.cpp:313] Batch 657, loss = 1.82983
I0816 15:06:22.440376 22807 caffe.cpp:313] Batch 658, accuracy/top1 = 0.48
I0816 15:06:22.440397 22807 caffe.cpp:313] Batch 658, accuracy/top5 = 0.74
I0816 15:06:22.440402 22807 caffe.cpp:313] Batch 658, loss = 1.92614
I0816 15:06:22.503281 22807 caffe.cpp:313] Batch 659, accuracy/top1 = 0.48
I0816 15:06:22.503304 22807 caffe.cpp:313] Batch 659, accuracy/top5 = 0.76
I0816 15:06:22.503307 22807 caffe.cpp:313] Batch 659, loss = 2.03378
I0816 15:06:22.566596 22807 caffe.cpp:313] Batch 660, accuracy/top1 = 0.7
I0816 15:06:22.566618 22807 caffe.cpp:313] Batch 660, accuracy/top5 = 0.78
I0816 15:06:22.566623 22807 caffe.cpp:313] Batch 660, loss = 1.58807
I0816 15:06:22.629629 22807 caffe.cpp:313] Batch 661, accuracy/top1 = 0.64
I0816 15:06:22.629652 22807 caffe.cpp:313] Batch 661, accuracy/top5 = 0.84
I0816 15:06:22.629655 22807 caffe.cpp:313] Batch 661, loss = 1.53783
I0816 15:06:22.692629 22807 caffe.cpp:313] Batch 662, accuracy/top1 = 0.4
I0816 15:06:22.692651 22807 caffe.cpp:313] Batch 662, accuracy/top5 = 0.76
I0816 15:06:22.692656 22807 caffe.cpp:313] Batch 662, loss = 2.08395
I0816 15:06:22.755610 22807 caffe.cpp:313] Batch 663, accuracy/top1 = 0.64
I0816 15:06:22.755633 22807 caffe.cpp:313] Batch 663, accuracy/top5 = 0.76
I0816 15:06:22.755637 22807 caffe.cpp:313] Batch 663, loss = 2.09409
I0816 15:06:22.818507 22807 caffe.cpp:313] Batch 664, accuracy/top1 = 0.54
I0816 15:06:22.818531 22807 caffe.cpp:313] Batch 664, accuracy/top5 = 0.8
I0816 15:06:22.818534 22807 caffe.cpp:313] Batch 664, loss = 1.94282
I0816 15:06:22.881352 22807 caffe.cpp:313] Batch 665, accuracy/top1 = 0.56
I0816 15:06:22.881374 22807 caffe.cpp:313] Batch 665, accuracy/top5 = 0.72
I0816 15:06:22.881378 22807 caffe.cpp:313] Batch 665, loss = 1.91135
I0816 15:06:22.944357 22807 caffe.cpp:313] Batch 666, accuracy/top1 = 0.6
I0816 15:06:22.944380 22807 caffe.cpp:313] Batch 666, accuracy/top5 = 0.84
I0816 15:06:22.944383 22807 caffe.cpp:313] Batch 666, loss = 1.71957
I0816 15:06:23.007290 22807 caffe.cpp:313] Batch 667, accuracy/top1 = 0.58
I0816 15:06:23.007311 22807 caffe.cpp:313] Batch 667, accuracy/top5 = 0.8
I0816 15:06:23.007315 22807 caffe.cpp:313] Batch 667, loss = 1.88164
I0816 15:06:23.070199 22807 caffe.cpp:313] Batch 668, accuracy/top1 = 0.54
I0816 15:06:23.070221 22807 caffe.cpp:313] Batch 668, accuracy/top5 = 0.74
I0816 15:06:23.070225 22807 caffe.cpp:313] Batch 668, loss = 2.0222
I0816 15:06:23.133144 22807 caffe.cpp:313] Batch 669, accuracy/top1 = 0.72
I0816 15:06:23.133163 22807 caffe.cpp:313] Batch 669, accuracy/top5 = 0.92
I0816 15:06:23.133167 22807 caffe.cpp:313] Batch 669, loss = 1.20752
I0816 15:06:23.196255 22807 caffe.cpp:313] Batch 670, accuracy/top1 = 0.6
I0816 15:06:23.196275 22807 caffe.cpp:313] Batch 670, accuracy/top5 = 0.78
I0816 15:06:23.196280 22807 caffe.cpp:313] Batch 670, loss = 1.90021
I0816 15:06:23.259333 22807 caffe.cpp:313] Batch 671, accuracy/top1 = 0.64
I0816 15:06:23.259356 22807 caffe.cpp:313] Batch 671, accuracy/top5 = 0.82
I0816 15:06:23.259359 22807 caffe.cpp:313] Batch 671, loss = 1.64186
I0816 15:06:23.322254 22807 caffe.cpp:313] Batch 672, accuracy/top1 = 0.5
I0816 15:06:23.322289 22807 caffe.cpp:313] Batch 672, accuracy/top5 = 0.86
I0816 15:06:23.322294 22807 caffe.cpp:313] Batch 672, loss = 2.04669
I0816 15:06:23.385133 22807 caffe.cpp:313] Batch 673, accuracy/top1 = 0.66
I0816 15:06:23.385154 22807 caffe.cpp:313] Batch 673, accuracy/top5 = 0.86
I0816 15:06:23.385159 22807 caffe.cpp:313] Batch 673, loss = 1.2248
I0816 15:06:23.447998 22807 caffe.cpp:313] Batch 674, accuracy/top1 = 0.7
I0816 15:06:23.448021 22807 caffe.cpp:313] Batch 674, accuracy/top5 = 0.9
I0816 15:06:23.448025 22807 caffe.cpp:313] Batch 674, loss = 1.11173
I0816 15:06:23.510937 22807 caffe.cpp:313] Batch 675, accuracy/top1 = 0.56
I0816 15:06:23.510959 22807 caffe.cpp:313] Batch 675, accuracy/top5 = 0.74
I0816 15:06:23.510963 22807 caffe.cpp:313] Batch 675, loss = 2.03894
I0816 15:06:23.574223 22807 caffe.cpp:313] Batch 676, accuracy/top1 = 0.46
I0816 15:06:23.574244 22807 caffe.cpp:313] Batch 676, accuracy/top5 = 0.76
I0816 15:06:23.574249 22807 caffe.cpp:313] Batch 676, loss = 1.87008
I0816 15:06:23.637053 22807 caffe.cpp:313] Batch 677, accuracy/top1 = 0.54
I0816 15:06:23.637076 22807 caffe.cpp:313] Batch 677, accuracy/top5 = 0.84
I0816 15:06:23.637081 22807 caffe.cpp:313] Batch 677, loss = 1.5698
I0816 15:06:23.699925 22807 caffe.cpp:313] Batch 678, accuracy/top1 = 0.54
I0816 15:06:23.699949 22807 caffe.cpp:313] Batch 678, accuracy/top5 = 0.8
I0816 15:06:23.699952 22807 caffe.cpp:313] Batch 678, loss = 1.93953
I0816 15:06:23.762961 22807 caffe.cpp:313] Batch 679, accuracy/top1 = 0.66
I0816 15:06:23.762984 22807 caffe.cpp:313] Batch 679, accuracy/top5 = 0.84
I0816 15:06:23.762989 22807 caffe.cpp:313] Batch 679, loss = 1.5891
I0816 15:06:23.825877 22807 caffe.cpp:313] Batch 680, accuracy/top1 = 0.62
I0816 15:06:23.825899 22807 caffe.cpp:313] Batch 680, accuracy/top5 = 0.88
I0816 15:06:23.825903 22807 caffe.cpp:313] Batch 680, loss = 1.46799
I0816 15:06:23.888777 22807 caffe.cpp:313] Batch 681, accuracy/top1 = 0.64
I0816 15:06:23.888801 22807 caffe.cpp:313] Batch 681, accuracy/top5 = 0.88
I0816 15:06:23.888805 22807 caffe.cpp:313] Batch 681, loss = 1.442
I0816 15:06:23.951658 22807 caffe.cpp:313] Batch 682, accuracy/top1 = 0.5
I0816 15:06:23.951680 22807 caffe.cpp:313] Batch 682, accuracy/top5 = 0.82
I0816 15:06:23.951684 22807 caffe.cpp:313] Batch 682, loss = 1.94735
I0816 15:06:24.014700 22807 caffe.cpp:313] Batch 683, accuracy/top1 = 0.5
I0816 15:06:24.014722 22807 caffe.cpp:313] Batch 683, accuracy/top5 = 0.8
I0816 15:06:24.014727 22807 caffe.cpp:313] Batch 683, loss = 2.12685
I0816 15:06:24.077730 22807 caffe.cpp:313] Batch 684, accuracy/top1 = 0.52
I0816 15:06:24.077754 22807 caffe.cpp:313] Batch 684, accuracy/top5 = 0.8
I0816 15:06:24.077757 22807 caffe.cpp:313] Batch 684, loss = 2.01663
I0816 15:06:24.140537 22807 caffe.cpp:313] Batch 685, accuracy/top1 = 0.52
I0816 15:06:24.140558 22807 caffe.cpp:313] Batch 685, accuracy/top5 = 0.82
I0816 15:06:24.140563 22807 caffe.cpp:313] Batch 685, loss = 2.0202
I0816 15:06:24.203408 22807 caffe.cpp:313] Batch 686, accuracy/top1 = 0.5
I0816 15:06:24.203430 22807 caffe.cpp:313] Batch 686, accuracy/top5 = 0.72
I0816 15:06:24.203434 22807 caffe.cpp:313] Batch 686, loss = 2.07865
I0816 15:06:24.266382 22807 caffe.cpp:313] Batch 687, accuracy/top1 = 0.54
I0816 15:06:24.266405 22807 caffe.cpp:313] Batch 687, accuracy/top5 = 0.82
I0816 15:06:24.266409 22807 caffe.cpp:313] Batch 687, loss = 2.28916
I0816 15:06:24.329502 22807 caffe.cpp:313] Batch 688, accuracy/top1 = 0.56
I0816 15:06:24.329522 22807 caffe.cpp:313] Batch 688, accuracy/top5 = 0.86
I0816 15:06:24.329527 22807 caffe.cpp:313] Batch 688, loss = 1.78764
I0816 15:06:24.392442 22807 caffe.cpp:313] Batch 689, accuracy/top1 = 0.58
I0816 15:06:24.392463 22807 caffe.cpp:313] Batch 689, accuracy/top5 = 0.82
I0816 15:06:24.392468 22807 caffe.cpp:313] Batch 689, loss = 1.73268
I0816 15:06:24.455531 22807 caffe.cpp:313] Batch 690, accuracy/top1 = 0.5
I0816 15:06:24.455554 22807 caffe.cpp:313] Batch 690, accuracy/top5 = 0.8
I0816 15:06:24.455557 22807 caffe.cpp:313] Batch 690, loss = 2.00111
I0816 15:06:24.518607 22807 caffe.cpp:313] Batch 691, accuracy/top1 = 0.58
I0816 15:06:24.518626 22807 caffe.cpp:313] Batch 691, accuracy/top5 = 0.78
I0816 15:06:24.518631 22807 caffe.cpp:313] Batch 691, loss = 1.84766
I0816 15:06:24.581786 22807 caffe.cpp:313] Batch 692, accuracy/top1 = 0.58
I0816 15:06:24.581809 22807 caffe.cpp:313] Batch 692, accuracy/top5 = 0.78
I0816 15:06:24.581812 22807 caffe.cpp:313] Batch 692, loss = 2.01959
I0816 15:06:24.644654 22807 caffe.cpp:313] Batch 693, accuracy/top1 = 0.68
I0816 15:06:24.644676 22807 caffe.cpp:313] Batch 693, accuracy/top5 = 0.8
I0816 15:06:24.644680 22807 caffe.cpp:313] Batch 693, loss = 1.6805
I0816 15:06:24.707630 22807 caffe.cpp:313] Batch 694, accuracy/top1 = 0.54
I0816 15:06:24.707653 22807 caffe.cpp:313] Batch 694, accuracy/top5 = 0.78
I0816 15:06:24.707656 22807 caffe.cpp:313] Batch 694, loss = 1.82073
I0816 15:06:24.770547 22807 caffe.cpp:313] Batch 695, accuracy/top1 = 0.56
I0816 15:06:24.770570 22807 caffe.cpp:313] Batch 695, accuracy/top5 = 0.82
I0816 15:06:24.770573 22807 caffe.cpp:313] Batch 695, loss = 1.68167
I0816 15:06:24.833498 22807 caffe.cpp:313] Batch 696, accuracy/top1 = 0.46
I0816 15:06:24.833521 22807 caffe.cpp:313] Batch 696, accuracy/top5 = 0.8
I0816 15:06:24.833525 22807 caffe.cpp:313] Batch 696, loss = 2.01519
I0816 15:06:24.896488 22807 caffe.cpp:313] Batch 697, accuracy/top1 = 0.7
I0816 15:06:24.896512 22807 caffe.cpp:313] Batch 697, accuracy/top5 = 0.88
I0816 15:06:24.896515 22807 caffe.cpp:313] Batch 697, loss = 1.39504
I0816 15:06:24.959492 22807 caffe.cpp:313] Batch 698, accuracy/top1 = 0.5
I0816 15:06:24.959513 22807 caffe.cpp:313] Batch 698, accuracy/top5 = 0.78
I0816 15:06:24.959518 22807 caffe.cpp:313] Batch 698, loss = 2.08174
I0816 15:06:25.022507 22807 caffe.cpp:313] Batch 699, accuracy/top1 = 0.66
I0816 15:06:25.022527 22807 caffe.cpp:313] Batch 699, accuracy/top5 = 0.88
I0816 15:06:25.022532 22807 caffe.cpp:313] Batch 699, loss = 1.3365
I0816 15:06:25.085348 22807 caffe.cpp:313] Batch 700, accuracy/top1 = 0.56
I0816 15:06:25.085371 22807 caffe.cpp:313] Batch 700, accuracy/top5 = 0.8
I0816 15:06:25.085376 22807 caffe.cpp:313] Batch 700, loss = 2.05145
I0816 15:06:25.148344 22807 caffe.cpp:313] Batch 701, accuracy/top1 = 0.48
I0816 15:06:25.148366 22807 caffe.cpp:313] Batch 701, accuracy/top5 = 0.68
I0816 15:06:25.148370 22807 caffe.cpp:313] Batch 701, loss = 2.42432
I0816 15:06:25.211331 22807 caffe.cpp:313] Batch 702, accuracy/top1 = 0.6
I0816 15:06:25.211354 22807 caffe.cpp:313] Batch 702, accuracy/top5 = 0.74
I0816 15:06:25.211359 22807 caffe.cpp:313] Batch 702, loss = 2.12204
I0816 15:06:25.274415 22807 caffe.cpp:313] Batch 703, accuracy/top1 = 0.64
I0816 15:06:25.274433 22807 caffe.cpp:313] Batch 703, accuracy/top5 = 0.9
I0816 15:06:25.274437 22807 caffe.cpp:313] Batch 703, loss = 1.37168
I0816 15:06:25.337641 22807 caffe.cpp:313] Batch 704, accuracy/top1 = 0.58
I0816 15:06:25.337661 22807 caffe.cpp:313] Batch 704, accuracy/top5 = 0.8
I0816 15:06:25.337664 22807 caffe.cpp:313] Batch 704, loss = 2.12408
I0816 15:06:25.400873 22807 caffe.cpp:313] Batch 705, accuracy/top1 = 0.66
I0816 15:06:25.400893 22807 caffe.cpp:313] Batch 705, accuracy/top5 = 0.82
I0816 15:06:25.400897 22807 caffe.cpp:313] Batch 705, loss = 1.39959
I0816 15:06:25.463970 22807 caffe.cpp:313] Batch 706, accuracy/top1 = 0.58
I0816 15:06:25.463992 22807 caffe.cpp:313] Batch 706, accuracy/top5 = 0.84
I0816 15:06:25.463996 22807 caffe.cpp:313] Batch 706, loss = 1.76615
I0816 15:06:25.527326 22807 caffe.cpp:313] Batch 707, accuracy/top1 = 0.6
I0816 15:06:25.527362 22807 caffe.cpp:313] Batch 707, accuracy/top5 = 0.82
I0816 15:06:25.527366 22807 caffe.cpp:313] Batch 707, loss = 1.61646
I0816 15:06:25.590358 22807 caffe.cpp:313] Batch 708, accuracy/top1 = 0.58
I0816 15:06:25.590380 22807 caffe.cpp:313] Batch 708, accuracy/top5 = 0.84
I0816 15:06:25.590384 22807 caffe.cpp:313] Batch 708, loss = 1.55663
I0816 15:06:25.653355 22807 caffe.cpp:313] Batch 709, accuracy/top1 = 0.56
I0816 15:06:25.653378 22807 caffe.cpp:313] Batch 709, accuracy/top5 = 0.8
I0816 15:06:25.653383 22807 caffe.cpp:313] Batch 709, loss = 2.07729
I0816 15:06:25.716461 22807 caffe.cpp:313] Batch 710, accuracy/top1 = 0.54
I0816 15:06:25.716485 22807 caffe.cpp:313] Batch 710, accuracy/top5 = 0.74
I0816 15:06:25.716488 22807 caffe.cpp:313] Batch 710, loss = 2.07661
I0816 15:06:25.779413 22807 caffe.cpp:313] Batch 711, accuracy/top1 = 0.54
I0816 15:06:25.779435 22807 caffe.cpp:313] Batch 711, accuracy/top5 = 0.8
I0816 15:06:25.779439 22807 caffe.cpp:313] Batch 711, loss = 1.91847
I0816 15:06:25.842381 22807 caffe.cpp:313] Batch 712, accuracy/top1 = 0.58
I0816 15:06:25.842403 22807 caffe.cpp:313] Batch 712, accuracy/top5 = 0.78
I0816 15:06:25.842407 22807 caffe.cpp:313] Batch 712, loss = 1.83589
I0816 15:06:25.905197 22807 caffe.cpp:313] Batch 713, accuracy/top1 = 0.44
I0816 15:06:25.905220 22807 caffe.cpp:313] Batch 713, accuracy/top5 = 0.72
I0816 15:06:25.905225 22807 caffe.cpp:313] Batch 713, loss = 2.41801
I0816 15:06:25.968214 22807 caffe.cpp:313] Batch 714, accuracy/top1 = 0.58
I0816 15:06:25.968235 22807 caffe.cpp:313] Batch 714, accuracy/top5 = 0.8
I0816 15:06:25.968240 22807 caffe.cpp:313] Batch 714, loss = 1.67177
I0816 15:06:26.031296 22807 caffe.cpp:313] Batch 715, accuracy/top1 = 0.5
I0816 15:06:26.031316 22807 caffe.cpp:313] Batch 715, accuracy/top5 = 0.84
I0816 15:06:26.031321 22807 caffe.cpp:313] Batch 715, loss = 1.98435
I0816 15:06:26.094298 22807 caffe.cpp:313] Batch 716, accuracy/top1 = 0.6
I0816 15:06:26.094321 22807 caffe.cpp:313] Batch 716, accuracy/top5 = 0.76
I0816 15:06:26.094326 22807 caffe.cpp:313] Batch 716, loss = 2.30919
I0816 15:06:26.157295 22807 caffe.cpp:313] Batch 717, accuracy/top1 = 0.7
I0816 15:06:26.157317 22807 caffe.cpp:313] Batch 717, accuracy/top5 = 0.86
I0816 15:06:26.157321 22807 caffe.cpp:313] Batch 717, loss = 1.45399
I0816 15:06:26.220275 22807 caffe.cpp:313] Batch 718, accuracy/top1 = 0.52
I0816 15:06:26.220297 22807 caffe.cpp:313] Batch 718, accuracy/top5 = 0.72
I0816 15:06:26.220302 22807 caffe.cpp:313] Batch 718, loss = 2.23223
I0816 15:06:26.283308 22807 caffe.cpp:313] Batch 719, accuracy/top1 = 0.6
I0816 15:06:26.283331 22807 caffe.cpp:313] Batch 719, accuracy/top5 = 0.8
I0816 15:06:26.283335 22807 caffe.cpp:313] Batch 719, loss = 1.84797
I0816 15:06:26.346393 22807 caffe.cpp:313] Batch 720, accuracy/top1 = 0.52
I0816 15:06:26.346410 22807 caffe.cpp:313] Batch 720, accuracy/top5 = 0.86
I0816 15:06:26.346415 22807 caffe.cpp:313] Batch 720, loss = 1.72594
I0816 15:06:26.409363 22807 caffe.cpp:313] Batch 721, accuracy/top1 = 0.6
I0816 15:06:26.409385 22807 caffe.cpp:313] Batch 721, accuracy/top5 = 0.84
I0816 15:06:26.409389 22807 caffe.cpp:313] Batch 721, loss = 1.75783
I0816 15:06:26.472373 22807 caffe.cpp:313] Batch 722, accuracy/top1 = 0.56
I0816 15:06:26.472396 22807 caffe.cpp:313] Batch 722, accuracy/top5 = 0.82
I0816 15:06:26.472400 22807 caffe.cpp:313] Batch 722, loss = 1.91526
I0816 15:06:26.535528 22807 caffe.cpp:313] Batch 723, accuracy/top1 = 0.52
I0816 15:06:26.535547 22807 caffe.cpp:313] Batch 723, accuracy/top5 = 0.8
I0816 15:06:26.535550 22807 caffe.cpp:313] Batch 723, loss = 1.77959
I0816 15:06:26.598554 22807 caffe.cpp:313] Batch 724, accuracy/top1 = 0.58
I0816 15:06:26.598577 22807 caffe.cpp:313] Batch 724, accuracy/top5 = 0.92
I0816 15:06:26.598582 22807 caffe.cpp:313] Batch 724, loss = 1.33177
I0816 15:06:26.661547 22807 caffe.cpp:313] Batch 725, accuracy/top1 = 0.58
I0816 15:06:26.661571 22807 caffe.cpp:313] Batch 725, accuracy/top5 = 0.88
I0816 15:06:26.661574 22807 caffe.cpp:313] Batch 725, loss = 1.43435
I0816 15:06:26.724383 22807 caffe.cpp:313] Batch 726, accuracy/top1 = 0.48
I0816 15:06:26.724406 22807 caffe.cpp:313] Batch 726, accuracy/top5 = 0.86
I0816 15:06:26.724409 22807 caffe.cpp:313] Batch 726, loss = 1.77409
I0816 15:06:26.787329 22807 caffe.cpp:313] Batch 727, accuracy/top1 = 0.54
I0816 15:06:26.787353 22807 caffe.cpp:313] Batch 727, accuracy/top5 = 0.84
I0816 15:06:26.787356 22807 caffe.cpp:313] Batch 727, loss = 1.83336
I0816 15:06:26.850318 22807 caffe.cpp:313] Batch 728, accuracy/top1 = 0.64
I0816 15:06:26.850342 22807 caffe.cpp:313] Batch 728, accuracy/top5 = 0.84
I0816 15:06:26.850366 22807 caffe.cpp:313] Batch 728, loss = 1.43122
I0816 15:06:26.913311 22807 caffe.cpp:313] Batch 729, accuracy/top1 = 0.68
I0816 15:06:26.913334 22807 caffe.cpp:313] Batch 729, accuracy/top5 = 0.86
I0816 15:06:26.913338 22807 caffe.cpp:313] Batch 729, loss = 1.34715
I0816 15:06:26.976246 22807 caffe.cpp:313] Batch 730, accuracy/top1 = 0.56
I0816 15:06:26.976269 22807 caffe.cpp:313] Batch 730, accuracy/top5 = 0.8
I0816 15:06:26.976272 22807 caffe.cpp:313] Batch 730, loss = 1.92756
I0816 15:06:27.039328 22807 caffe.cpp:313] Batch 731, accuracy/top1 = 0.46
I0816 15:06:27.039345 22807 caffe.cpp:313] Batch 731, accuracy/top5 = 0.76
I0816 15:06:27.039350 22807 caffe.cpp:313] Batch 731, loss = 2.07509
I0816 15:06:27.102222 22807 caffe.cpp:313] Batch 732, accuracy/top1 = 0.68
I0816 15:06:27.102246 22807 caffe.cpp:313] Batch 732, accuracy/top5 = 0.86
I0816 15:06:27.102249 22807 caffe.cpp:313] Batch 732, loss = 1.47614
I0816 15:06:27.165210 22807 caffe.cpp:313] Batch 733, accuracy/top1 = 0.42
I0816 15:06:27.165232 22807 caffe.cpp:313] Batch 733, accuracy/top5 = 0.78
I0816 15:06:27.165236 22807 caffe.cpp:313] Batch 733, loss = 2.34166
I0816 15:06:27.228214 22807 caffe.cpp:313] Batch 734, accuracy/top1 = 0.56
I0816 15:06:27.228238 22807 caffe.cpp:313] Batch 734, accuracy/top5 = 0.82
I0816 15:06:27.228242 22807 caffe.cpp:313] Batch 734, loss = 1.75801
I0816 15:06:27.291148 22807 caffe.cpp:313] Batch 735, accuracy/top1 = 0.6
I0816 15:06:27.291169 22807 caffe.cpp:313] Batch 735, accuracy/top5 = 0.72
I0816 15:06:27.291174 22807 caffe.cpp:313] Batch 735, loss = 1.95558
I0816 15:06:27.354097 22807 caffe.cpp:313] Batch 736, accuracy/top1 = 0.5
I0816 15:06:27.354120 22807 caffe.cpp:313] Batch 736, accuracy/top5 = 0.84
I0816 15:06:27.354125 22807 caffe.cpp:313] Batch 736, loss = 1.79611
I0816 15:06:27.417155 22807 caffe.cpp:313] Batch 737, accuracy/top1 = 0.58
I0816 15:06:27.417176 22807 caffe.cpp:313] Batch 737, accuracy/top5 = 0.84
I0816 15:06:27.417179 22807 caffe.cpp:313] Batch 737, loss = 1.8659
I0816 15:06:27.480398 22807 caffe.cpp:313] Batch 738, accuracy/top1 = 0.56
I0816 15:06:27.480417 22807 caffe.cpp:313] Batch 738, accuracy/top5 = 0.8
I0816 15:06:27.480422 22807 caffe.cpp:313] Batch 738, loss = 1.64787
I0816 15:06:27.544071 22807 caffe.cpp:313] Batch 739, accuracy/top1 = 0.6
I0816 15:06:27.544090 22807 caffe.cpp:313] Batch 739, accuracy/top5 = 0.86
I0816 15:06:27.544093 22807 caffe.cpp:313] Batch 739, loss = 1.60355
I0816 15:06:27.607168 22807 caffe.cpp:313] Batch 740, accuracy/top1 = 0.62
I0816 15:06:27.607192 22807 caffe.cpp:313] Batch 740, accuracy/top5 = 0.88
I0816 15:06:27.607195 22807 caffe.cpp:313] Batch 740, loss = 1.44753
I0816 15:06:27.670222 22807 caffe.cpp:313] Batch 741, accuracy/top1 = 0.66
I0816 15:06:27.670244 22807 caffe.cpp:313] Batch 741, accuracy/top5 = 0.86
I0816 15:06:27.670248 22807 caffe.cpp:313] Batch 741, loss = 1.59761
I0816 15:06:27.733281 22807 caffe.cpp:313] Batch 742, accuracy/top1 = 0.62
I0816 15:06:27.733304 22807 caffe.cpp:313] Batch 742, accuracy/top5 = 0.82
I0816 15:06:27.733309 22807 caffe.cpp:313] Batch 742, loss = 1.68945
I0816 15:06:27.796407 22807 caffe.cpp:313] Batch 743, accuracy/top1 = 0.54
I0816 15:06:27.796430 22807 caffe.cpp:313] Batch 743, accuracy/top5 = 0.82
I0816 15:06:27.796434 22807 caffe.cpp:313] Batch 743, loss = 1.94703
I0816 15:06:27.859330 22807 caffe.cpp:313] Batch 744, accuracy/top1 = 0.54
I0816 15:06:27.859354 22807 caffe.cpp:313] Batch 744, accuracy/top5 = 0.84
I0816 15:06:27.859359 22807 caffe.cpp:313] Batch 744, loss = 1.95436
I0816 15:06:27.922412 22807 caffe.cpp:313] Batch 745, accuracy/top1 = 0.64
I0816 15:06:27.922435 22807 caffe.cpp:313] Batch 745, accuracy/top5 = 0.84
I0816 15:06:27.922439 22807 caffe.cpp:313] Batch 745, loss = 1.44834
I0816 15:06:27.985417 22807 caffe.cpp:313] Batch 746, accuracy/top1 = 0.6
I0816 15:06:27.985440 22807 caffe.cpp:313] Batch 746, accuracy/top5 = 0.82
I0816 15:06:27.985443 22807 caffe.cpp:313] Batch 746, loss = 1.67294
I0816 15:06:28.048545 22807 caffe.cpp:313] Batch 747, accuracy/top1 = 0.58
I0816 15:06:28.048574 22807 caffe.cpp:313] Batch 747, accuracy/top5 = 0.82
I0816 15:06:28.048579 22807 caffe.cpp:313] Batch 747, loss = 1.68345
I0816 15:06:28.111608 22807 caffe.cpp:313] Batch 748, accuracy/top1 = 0.6
I0816 15:06:28.111630 22807 caffe.cpp:313] Batch 748, accuracy/top5 = 0.84
I0816 15:06:28.111634 22807 caffe.cpp:313] Batch 748, loss = 1.49294
I0816 15:06:28.174612 22807 caffe.cpp:313] Batch 749, accuracy/top1 = 0.64
I0816 15:06:28.174634 22807 caffe.cpp:313] Batch 749, accuracy/top5 = 0.86
I0816 15:06:28.174638 22807 caffe.cpp:313] Batch 749, loss = 1.33671
I0816 15:06:28.237537 22807 caffe.cpp:313] Batch 750, accuracy/top1 = 0.68
I0816 15:06:28.237560 22807 caffe.cpp:313] Batch 750, accuracy/top5 = 0.82
I0816 15:06:28.237565 22807 caffe.cpp:313] Batch 750, loss = 1.55922
I0816 15:06:28.300519 22807 caffe.cpp:313] Batch 751, accuracy/top1 = 0.58
I0816 15:06:28.300541 22807 caffe.cpp:313] Batch 751, accuracy/top5 = 0.78
I0816 15:06:28.300546 22807 caffe.cpp:313] Batch 751, loss = 1.76437
I0816 15:06:28.363533 22807 caffe.cpp:313] Batch 752, accuracy/top1 = 0.7
I0816 15:06:28.363550 22807 caffe.cpp:313] Batch 752, accuracy/top5 = 0.88
I0816 15:06:28.363554 22807 caffe.cpp:313] Batch 752, loss = 1.22181
I0816 15:06:28.426487 22807 caffe.cpp:313] Batch 753, accuracy/top1 = 0.46
I0816 15:06:28.426509 22807 caffe.cpp:313] Batch 753, accuracy/top5 = 0.8
I0816 15:06:28.426514 22807 caffe.cpp:313] Batch 753, loss = 2.14871
I0816 15:06:28.489575 22807 caffe.cpp:313] Batch 754, accuracy/top1 = 0.52
I0816 15:06:28.489598 22807 caffe.cpp:313] Batch 754, accuracy/top5 = 0.78
I0816 15:06:28.489601 22807 caffe.cpp:313] Batch 754, loss = 1.9808
I0816 15:06:28.555089 22807 caffe.cpp:313] Batch 755, accuracy/top1 = 0.46
I0816 15:06:28.555107 22807 caffe.cpp:313] Batch 755, accuracy/top5 = 0.76
I0816 15:06:28.555111 22807 caffe.cpp:313] Batch 755, loss = 2.23526
I0816 15:06:28.618031 22807 caffe.cpp:313] Batch 756, accuracy/top1 = 0.66
I0816 15:06:28.618053 22807 caffe.cpp:313] Batch 756, accuracy/top5 = 0.86
I0816 15:06:28.618057 22807 caffe.cpp:313] Batch 756, loss = 1.57851
I0816 15:06:28.681105 22807 caffe.cpp:313] Batch 757, accuracy/top1 = 0.62
I0816 15:06:28.681128 22807 caffe.cpp:313] Batch 757, accuracy/top5 = 0.84
I0816 15:06:28.681131 22807 caffe.cpp:313] Batch 757, loss = 1.45218
I0816 15:06:28.744109 22807 caffe.cpp:313] Batch 758, accuracy/top1 = 0.7
I0816 15:06:28.744132 22807 caffe.cpp:313] Batch 758, accuracy/top5 = 0.9
I0816 15:06:28.744137 22807 caffe.cpp:313] Batch 758, loss = 1.26392
I0816 15:06:28.807027 22807 caffe.cpp:313] Batch 759, accuracy/top1 = 0.66
I0816 15:06:28.807050 22807 caffe.cpp:313] Batch 759, accuracy/top5 = 0.84
I0816 15:06:28.807054 22807 caffe.cpp:313] Batch 759, loss = 1.77065
I0816 15:06:28.869938 22807 caffe.cpp:313] Batch 760, accuracy/top1 = 0.6
I0816 15:06:28.869961 22807 caffe.cpp:313] Batch 760, accuracy/top5 = 0.86
I0816 15:06:28.869964 22807 caffe.cpp:313] Batch 760, loss = 1.57448
I0816 15:06:28.933121 22807 caffe.cpp:313] Batch 761, accuracy/top1 = 0.66
I0816 15:06:28.933143 22807 caffe.cpp:313] Batch 761, accuracy/top5 = 0.86
I0816 15:06:28.933146 22807 caffe.cpp:313] Batch 761, loss = 1.67195
I0816 15:06:28.995980 22807 caffe.cpp:313] Batch 762, accuracy/top1 = 0.54
I0816 15:06:28.996001 22807 caffe.cpp:313] Batch 762, accuracy/top5 = 0.76
I0816 15:06:28.996003 22807 caffe.cpp:313] Batch 762, loss = 1.91817
I0816 15:06:29.058939 22807 caffe.cpp:313] Batch 763, accuracy/top1 = 0.56
I0816 15:06:29.058959 22807 caffe.cpp:313] Batch 763, accuracy/top5 = 0.82
I0816 15:06:29.058962 22807 caffe.cpp:313] Batch 763, loss = 1.62572
I0816 15:06:29.121840 22807 caffe.cpp:313] Batch 764, accuracy/top1 = 0.46
I0816 15:06:29.121862 22807 caffe.cpp:313] Batch 764, accuracy/top5 = 0.66
I0816 15:06:29.121865 22807 caffe.cpp:313] Batch 764, loss = 2.39601
I0816 15:06:29.184736 22807 caffe.cpp:313] Batch 765, accuracy/top1 = 0.62
I0816 15:06:29.184757 22807 caffe.cpp:313] Batch 765, accuracy/top5 = 0.88
I0816 15:06:29.184761 22807 caffe.cpp:313] Batch 765, loss = 1.57094
I0816 15:06:29.247680 22807 caffe.cpp:313] Batch 766, accuracy/top1 = 0.5
I0816 15:06:29.247704 22807 caffe.cpp:313] Batch 766, accuracy/top5 = 0.84
I0816 15:06:29.247706 22807 caffe.cpp:313] Batch 766, loss = 1.80668
I0816 15:06:29.310662 22807 caffe.cpp:313] Batch 767, accuracy/top1 = 0.66
I0816 15:06:29.310684 22807 caffe.cpp:313] Batch 767, accuracy/top5 = 0.82
I0816 15:06:29.310688 22807 caffe.cpp:313] Batch 767, loss = 1.71904
I0816 15:06:29.373492 22807 caffe.cpp:313] Batch 768, accuracy/top1 = 0.56
I0816 15:06:29.373515 22807 caffe.cpp:313] Batch 768, accuracy/top5 = 0.86
I0816 15:06:29.373518 22807 caffe.cpp:313] Batch 768, loss = 1.64897
I0816 15:06:29.436287 22807 caffe.cpp:313] Batch 769, accuracy/top1 = 0.64
I0816 15:06:29.436308 22807 caffe.cpp:313] Batch 769, accuracy/top5 = 0.84
I0816 15:06:29.436311 22807 caffe.cpp:313] Batch 769, loss = 1.49454
I0816 15:06:29.499194 22807 caffe.cpp:313] Batch 770, accuracy/top1 = 0.6
I0816 15:06:29.499217 22807 caffe.cpp:313] Batch 770, accuracy/top5 = 0.82
I0816 15:06:29.499219 22807 caffe.cpp:313] Batch 770, loss = 1.76355
I0816 15:06:29.562505 22807 caffe.cpp:313] Batch 771, accuracy/top1 = 0.62
I0816 15:06:29.562522 22807 caffe.cpp:313] Batch 771, accuracy/top5 = 0.76
I0816 15:06:29.562525 22807 caffe.cpp:313] Batch 771, loss = 2.28307
I0816 15:06:29.625699 22807 caffe.cpp:313] Batch 772, accuracy/top1 = 0.56
I0816 15:06:29.625720 22807 caffe.cpp:313] Batch 772, accuracy/top5 = 0.76
I0816 15:06:29.625722 22807 caffe.cpp:313] Batch 772, loss = 2.0485
I0816 15:06:29.688748 22807 caffe.cpp:313] Batch 773, accuracy/top1 = 0.48
I0816 15:06:29.688771 22807 caffe.cpp:313] Batch 773, accuracy/top5 = 0.76
I0816 15:06:29.688773 22807 caffe.cpp:313] Batch 773, loss = 2.39103
I0816 15:06:29.751698 22807 caffe.cpp:313] Batch 774, accuracy/top1 = 0.58
I0816 15:06:29.751720 22807 caffe.cpp:313] Batch 774, accuracy/top5 = 0.8
I0816 15:06:29.751724 22807 caffe.cpp:313] Batch 774, loss = 1.70924
I0816 15:06:29.814685 22807 caffe.cpp:313] Batch 775, accuracy/top1 = 0.52
I0816 15:06:29.814707 22807 caffe.cpp:313] Batch 775, accuracy/top5 = 0.78
I0816 15:06:29.814710 22807 caffe.cpp:313] Batch 775, loss = 1.74702
I0816 15:06:29.877635 22807 caffe.cpp:313] Batch 776, accuracy/top1 = 0.66
I0816 15:06:29.877657 22807 caffe.cpp:313] Batch 776, accuracy/top5 = 0.78
I0816 15:06:29.877660 22807 caffe.cpp:313] Batch 776, loss = 2.11164
I0816 15:06:29.940696 22807 caffe.cpp:313] Batch 777, accuracy/top1 = 0.52
I0816 15:06:29.940718 22807 caffe.cpp:313] Batch 777, accuracy/top5 = 0.84
I0816 15:06:29.940721 22807 caffe.cpp:313] Batch 777, loss = 1.85018
I0816 15:06:30.003700 22807 caffe.cpp:313] Batch 778, accuracy/top1 = 0.6
I0816 15:06:30.003721 22807 caffe.cpp:313] Batch 778, accuracy/top5 = 0.82
I0816 15:06:30.003724 22807 caffe.cpp:313] Batch 778, loss = 1.46732
I0816 15:06:30.066613 22807 caffe.cpp:313] Batch 779, accuracy/top1 = 0.56
I0816 15:06:30.066634 22807 caffe.cpp:313] Batch 779, accuracy/top5 = 0.78
I0816 15:06:30.066637 22807 caffe.cpp:313] Batch 779, loss = 2.00217
I0816 15:06:30.129613 22807 caffe.cpp:313] Batch 780, accuracy/top1 = 0.56
I0816 15:06:30.129636 22807 caffe.cpp:313] Batch 780, accuracy/top5 = 0.84
I0816 15:06:30.129638 22807 caffe.cpp:313] Batch 780, loss = 1.65783
I0816 15:06:30.192545 22807 caffe.cpp:313] Batch 781, accuracy/top1 = 0.6
I0816 15:06:30.192567 22807 caffe.cpp:313] Batch 781, accuracy/top5 = 0.86
I0816 15:06:30.192570 22807 caffe.cpp:313] Batch 781, loss = 1.46476
I0816 15:06:30.255492 22807 caffe.cpp:313] Batch 782, accuracy/top1 = 0.76
I0816 15:06:30.255514 22807 caffe.cpp:313] Batch 782, accuracy/top5 = 0.84
I0816 15:06:30.255517 22807 caffe.cpp:313] Batch 782, loss = 1.17143
I0816 15:06:30.318411 22807 caffe.cpp:313] Batch 783, accuracy/top1 = 0.6
I0816 15:06:30.318434 22807 caffe.cpp:313] Batch 783, accuracy/top5 = 0.84
I0816 15:06:30.318437 22807 caffe.cpp:313] Batch 783, loss = 1.66374
I0816 15:06:30.381345 22807 caffe.cpp:313] Batch 784, accuracy/top1 = 0.68
I0816 15:06:30.381362 22807 caffe.cpp:313] Batch 784, accuracy/top5 = 0.84
I0816 15:06:30.381392 22807 caffe.cpp:313] Batch 784, loss = 1.42172
I0816 15:06:30.444424 22807 caffe.cpp:313] Batch 785, accuracy/top1 = 0.62
I0816 15:06:30.444444 22807 caffe.cpp:313] Batch 785, accuracy/top5 = 0.82
I0816 15:06:30.444447 22807 caffe.cpp:313] Batch 785, loss = 1.97605
I0816 15:06:30.507390 22807 caffe.cpp:313] Batch 786, accuracy/top1 = 0.68
I0816 15:06:30.507411 22807 caffe.cpp:313] Batch 786, accuracy/top5 = 0.92
I0816 15:06:30.507414 22807 caffe.cpp:313] Batch 786, loss = 1.06651
I0816 15:06:30.570650 22807 caffe.cpp:313] Batch 787, accuracy/top1 = 0.54
I0816 15:06:30.570672 22807 caffe.cpp:313] Batch 787, accuracy/top5 = 0.84
I0816 15:06:30.570674 22807 caffe.cpp:313] Batch 787, loss = 1.57612
I0816 15:06:30.633587 22807 caffe.cpp:313] Batch 788, accuracy/top1 = 0.54
I0816 15:06:30.633608 22807 caffe.cpp:313] Batch 788, accuracy/top5 = 0.8
I0816 15:06:30.633612 22807 caffe.cpp:313] Batch 788, loss = 2.03884
I0816 15:06:30.696609 22807 caffe.cpp:313] Batch 789, accuracy/top1 = 0.6
I0816 15:06:30.696632 22807 caffe.cpp:313] Batch 789, accuracy/top5 = 0.88
I0816 15:06:30.696635 22807 caffe.cpp:313] Batch 789, loss = 1.54756
I0816 15:06:30.759537 22807 caffe.cpp:313] Batch 790, accuracy/top1 = 0.56
I0816 15:06:30.759559 22807 caffe.cpp:313] Batch 790, accuracy/top5 = 0.88
I0816 15:06:30.759563 22807 caffe.cpp:313] Batch 790, loss = 1.66311
I0816 15:06:30.822415 22807 caffe.cpp:313] Batch 791, accuracy/top1 = 0.46
I0816 15:06:30.822438 22807 caffe.cpp:313] Batch 791, accuracy/top5 = 0.74
I0816 15:06:30.822440 22807 caffe.cpp:313] Batch 791, loss = 2.28027
I0816 15:06:30.885255 22807 caffe.cpp:313] Batch 792, accuracy/top1 = 0.48
I0816 15:06:30.885277 22807 caffe.cpp:313] Batch 792, accuracy/top5 = 0.76
I0816 15:06:30.885280 22807 caffe.cpp:313] Batch 792, loss = 1.93311
I0816 15:06:30.948259 22807 caffe.cpp:313] Batch 793, accuracy/top1 = 0.6
I0816 15:06:30.948281 22807 caffe.cpp:313] Batch 793, accuracy/top5 = 0.8
I0816 15:06:30.948283 22807 caffe.cpp:313] Batch 793, loss = 1.77732
I0816 15:06:31.011272 22807 caffe.cpp:313] Batch 794, accuracy/top1 = 0.66
I0816 15:06:31.011291 22807 caffe.cpp:313] Batch 794, accuracy/top5 = 0.82
I0816 15:06:31.011294 22807 caffe.cpp:313] Batch 794, loss = 1.66339
I0816 15:06:31.074196 22807 caffe.cpp:313] Batch 795, accuracy/top1 = 0.56
I0816 15:06:31.074218 22807 caffe.cpp:313] Batch 795, accuracy/top5 = 0.82
I0816 15:06:31.074221 22807 caffe.cpp:313] Batch 795, loss = 2.00109
I0816 15:06:31.137092 22807 caffe.cpp:313] Batch 796, accuracy/top1 = 0.58
I0816 15:06:31.137115 22807 caffe.cpp:313] Batch 796, accuracy/top5 = 0.72
I0816 15:06:31.137117 22807 caffe.cpp:313] Batch 796, loss = 1.94189
I0816 15:06:31.200053 22807 caffe.cpp:313] Batch 797, accuracy/top1 = 0.5
I0816 15:06:31.200075 22807 caffe.cpp:313] Batch 797, accuracy/top5 = 0.76
I0816 15:06:31.200078 22807 caffe.cpp:313] Batch 797, loss = 2.0528
I0816 15:06:31.263027 22807 caffe.cpp:313] Batch 798, accuracy/top1 = 0.58
I0816 15:06:31.263049 22807 caffe.cpp:313] Batch 798, accuracy/top5 = 0.88
I0816 15:06:31.263053 22807 caffe.cpp:313] Batch 798, loss = 1.46951
I0816 15:06:31.326002 22807 caffe.cpp:313] Batch 799, accuracy/top1 = 0.66
I0816 15:06:31.326023 22807 caffe.cpp:313] Batch 799, accuracy/top5 = 0.86
I0816 15:06:31.326026 22807 caffe.cpp:313] Batch 799, loss = 1.68563
I0816 15:06:31.388916 22807 caffe.cpp:313] Batch 800, accuracy/top1 = 0.5
I0816 15:06:31.388938 22807 caffe.cpp:313] Batch 800, accuracy/top5 = 0.64
I0816 15:06:31.388942 22807 caffe.cpp:313] Batch 800, loss = 2.8898
I0816 15:06:31.451846 22807 caffe.cpp:313] Batch 801, accuracy/top1 = 0.62
I0816 15:06:31.451869 22807 caffe.cpp:313] Batch 801, accuracy/top5 = 0.84
I0816 15:06:31.451872 22807 caffe.cpp:313] Batch 801, loss = 1.65528
I0816 15:06:31.514894 22807 caffe.cpp:313] Batch 802, accuracy/top1 = 0.54
I0816 15:06:31.514916 22807 caffe.cpp:313] Batch 802, accuracy/top5 = 0.86
I0816 15:06:31.514919 22807 caffe.cpp:313] Batch 802, loss = 1.74192
I0816 15:06:31.577960 22807 caffe.cpp:313] Batch 803, accuracy/top1 = 0.62
I0816 15:06:31.577981 22807 caffe.cpp:313] Batch 803, accuracy/top5 = 0.8
I0816 15:06:31.577998 22807 caffe.cpp:313] Batch 803, loss = 1.64767
I0816 15:06:31.640861 22807 caffe.cpp:313] Batch 804, accuracy/top1 = 0.62
I0816 15:06:31.640883 22807 caffe.cpp:313] Batch 804, accuracy/top5 = 0.94
I0816 15:06:31.640887 22807 caffe.cpp:313] Batch 804, loss = 1.48299
I0816 15:06:31.703806 22807 caffe.cpp:313] Batch 805, accuracy/top1 = 0.66
I0816 15:06:31.703826 22807 caffe.cpp:313] Batch 805, accuracy/top5 = 0.84
I0816 15:06:31.703830 22807 caffe.cpp:313] Batch 805, loss = 1.74006
I0816 15:06:31.766885 22807 caffe.cpp:313] Batch 806, accuracy/top1 = 0.66
I0816 15:06:31.766904 22807 caffe.cpp:313] Batch 806, accuracy/top5 = 0.88
I0816 15:06:31.766907 22807 caffe.cpp:313] Batch 806, loss = 1.20938
I0816 15:06:31.830153 22807 caffe.cpp:313] Batch 807, accuracy/top1 = 0.54
I0816 15:06:31.830175 22807 caffe.cpp:313] Batch 807, accuracy/top5 = 0.86
I0816 15:06:31.830179 22807 caffe.cpp:313] Batch 807, loss = 1.95279
I0816 15:06:31.893028 22807 caffe.cpp:313] Batch 808, accuracy/top1 = 0.58
I0816 15:06:31.893049 22807 caffe.cpp:313] Batch 808, accuracy/top5 = 0.82
I0816 15:06:31.893052 22807 caffe.cpp:313] Batch 808, loss = 1.84724
I0816 15:06:31.955971 22807 caffe.cpp:313] Batch 809, accuracy/top1 = 0.48
I0816 15:06:31.955993 22807 caffe.cpp:313] Batch 809, accuracy/top5 = 0.74
I0816 15:06:31.955996 22807 caffe.cpp:313] Batch 809, loss = 2.41594
I0816 15:06:32.018860 22807 caffe.cpp:313] Batch 810, accuracy/top1 = 0.54
I0816 15:06:32.018883 22807 caffe.cpp:313] Batch 810, accuracy/top5 = 0.78
I0816 15:06:32.018887 22807 caffe.cpp:313] Batch 810, loss = 1.86499
I0816 15:06:32.081887 22807 caffe.cpp:313] Batch 811, accuracy/top1 = 0.58
I0816 15:06:32.081908 22807 caffe.cpp:313] Batch 811, accuracy/top5 = 0.78
I0816 15:06:32.081912 22807 caffe.cpp:313] Batch 811, loss = 2.09674
I0816 15:06:32.144948 22807 caffe.cpp:313] Batch 812, accuracy/top1 = 0.48
I0816 15:06:32.144969 22807 caffe.cpp:313] Batch 812, accuracy/top5 = 0.84
I0816 15:06:32.144973 22807 caffe.cpp:313] Batch 812, loss = 1.79877
I0816 15:06:32.207937 22807 caffe.cpp:313] Batch 813, accuracy/top1 = 0.56
I0816 15:06:32.207958 22807 caffe.cpp:313] Batch 813, accuracy/top5 = 0.78
I0816 15:06:32.207962 22807 caffe.cpp:313] Batch 813, loss = 1.94836
I0816 15:06:32.270874 22807 caffe.cpp:313] Batch 814, accuracy/top1 = 0.42
I0816 15:06:32.270896 22807 caffe.cpp:313] Batch 814, accuracy/top5 = 0.7
I0816 15:06:32.270900 22807 caffe.cpp:313] Batch 814, loss = 2.59711
I0816 15:06:32.333849 22807 caffe.cpp:313] Batch 815, accuracy/top1 = 0.54
I0816 15:06:32.333871 22807 caffe.cpp:313] Batch 815, accuracy/top5 = 0.9
I0816 15:06:32.333874 22807 caffe.cpp:313] Batch 815, loss = 1.38659
I0816 15:06:32.396899 22807 caffe.cpp:313] Batch 816, accuracy/top1 = 0.48
I0816 15:06:32.396916 22807 caffe.cpp:313] Batch 816, accuracy/top5 = 0.78
I0816 15:06:32.396919 22807 caffe.cpp:313] Batch 816, loss = 2.17692
I0816 15:06:32.459933 22807 caffe.cpp:313] Batch 817, accuracy/top1 = 0.62
I0816 15:06:32.459954 22807 caffe.cpp:313] Batch 817, accuracy/top5 = 0.86
I0816 15:06:32.459957 22807 caffe.cpp:313] Batch 817, loss = 1.69948
I0816 15:06:32.522990 22807 caffe.cpp:313] Batch 818, accuracy/top1 = 0.62
I0816 15:06:32.523008 22807 caffe.cpp:313] Batch 818, accuracy/top5 = 0.86
I0816 15:06:32.523012 22807 caffe.cpp:313] Batch 818, loss = 1.53493
I0816 15:06:32.586066 22807 caffe.cpp:313] Batch 819, accuracy/top1 = 0.74
I0816 15:06:32.586088 22807 caffe.cpp:313] Batch 819, accuracy/top5 = 0.84
I0816 15:06:32.586091 22807 caffe.cpp:313] Batch 819, loss = 1.56928
I0816 15:06:32.648941 22807 caffe.cpp:313] Batch 820, accuracy/top1 = 0.6
I0816 15:06:32.648963 22807 caffe.cpp:313] Batch 820, accuracy/top5 = 0.78
I0816 15:06:32.648967 22807 caffe.cpp:313] Batch 820, loss = 1.81538
I0816 15:06:32.711931 22807 caffe.cpp:313] Batch 821, accuracy/top1 = 0.56
I0816 15:06:32.711952 22807 caffe.cpp:313] Batch 821, accuracy/top5 = 0.82
I0816 15:06:32.711956 22807 caffe.cpp:313] Batch 821, loss = 1.79427
I0816 15:06:32.774792 22807 caffe.cpp:313] Batch 822, accuracy/top1 = 0.5
I0816 15:06:32.774827 22807 caffe.cpp:313] Batch 822, accuracy/top5 = 0.8
I0816 15:06:32.774830 22807 caffe.cpp:313] Batch 822, loss = 2.03767
I0816 15:06:32.837680 22807 caffe.cpp:313] Batch 823, accuracy/top1 = 0.6
I0816 15:06:32.837702 22807 caffe.cpp:313] Batch 823, accuracy/top5 = 0.9
I0816 15:06:32.837705 22807 caffe.cpp:313] Batch 823, loss = 1.47104
I0816 15:06:32.900560 22807 caffe.cpp:313] Batch 824, accuracy/top1 = 0.6
I0816 15:06:32.900581 22807 caffe.cpp:313] Batch 824, accuracy/top5 = 0.82
I0816 15:06:32.900584 22807 caffe.cpp:313] Batch 824, loss = 1.86574
I0816 15:06:32.963590 22807 caffe.cpp:313] Batch 825, accuracy/top1 = 0.68
I0816 15:06:32.963613 22807 caffe.cpp:313] Batch 825, accuracy/top5 = 0.84
I0816 15:06:32.963616 22807 caffe.cpp:313] Batch 825, loss = 1.47153
I0816 15:06:33.026566 22807 caffe.cpp:313] Batch 826, accuracy/top1 = 0.52
I0816 15:06:33.026585 22807 caffe.cpp:313] Batch 826, accuracy/top5 = 0.86
I0816 15:06:33.026588 22807 caffe.cpp:313] Batch 826, loss = 1.73675
I0816 15:06:33.089480 22807 caffe.cpp:313] Batch 827, accuracy/top1 = 0.62
I0816 15:06:33.089501 22807 caffe.cpp:313] Batch 827, accuracy/top5 = 0.92
I0816 15:06:33.089505 22807 caffe.cpp:313] Batch 827, loss = 1.31978
I0816 15:06:33.152490 22807 caffe.cpp:313] Batch 828, accuracy/top1 = 0.56
I0816 15:06:33.152513 22807 caffe.cpp:313] Batch 828, accuracy/top5 = 0.74
I0816 15:06:33.152515 22807 caffe.cpp:313] Batch 828, loss = 2.06935
I0816 15:06:33.215404 22807 caffe.cpp:313] Batch 829, accuracy/top1 = 0.54
I0816 15:06:33.215427 22807 caffe.cpp:313] Batch 829, accuracy/top5 = 0.76
I0816 15:06:33.215430 22807 caffe.cpp:313] Batch 829, loss = 2.56154
I0816 15:06:33.278359 22807 caffe.cpp:313] Batch 830, accuracy/top1 = 0.68
I0816 15:06:33.278381 22807 caffe.cpp:313] Batch 830, accuracy/top5 = 0.84
I0816 15:06:33.278384 22807 caffe.cpp:313] Batch 830, loss = 1.49272
I0816 15:06:33.341323 22807 caffe.cpp:313] Batch 831, accuracy/top1 = 0.6
I0816 15:06:33.341344 22807 caffe.cpp:313] Batch 831, accuracy/top5 = 0.9
I0816 15:06:33.341348 22807 caffe.cpp:313] Batch 831, loss = 1.59098
I0816 15:06:33.404201 22807 caffe.cpp:313] Batch 832, accuracy/top1 = 0.48
I0816 15:06:33.404223 22807 caffe.cpp:313] Batch 832, accuracy/top5 = 0.72
I0816 15:06:33.404227 22807 caffe.cpp:313] Batch 832, loss = 2.16324
I0816 15:06:33.467180 22807 caffe.cpp:313] Batch 833, accuracy/top1 = 0.58
I0816 15:06:33.467202 22807 caffe.cpp:313] Batch 833, accuracy/top5 = 0.82
I0816 15:06:33.467206 22807 caffe.cpp:313] Batch 833, loss = 1.70953
I0816 15:06:33.530607 22807 caffe.cpp:313] Batch 834, accuracy/top1 = 0.6
I0816 15:06:33.530645 22807 caffe.cpp:313] Batch 834, accuracy/top5 = 0.8
I0816 15:06:33.530649 22807 caffe.cpp:313] Batch 834, loss = 2.06869
I0816 15:06:33.593824 22807 caffe.cpp:313] Batch 835, accuracy/top1 = 0.58
I0816 15:06:33.593847 22807 caffe.cpp:313] Batch 835, accuracy/top5 = 0.78
I0816 15:06:33.593850 22807 caffe.cpp:313] Batch 835, loss = 2.01343
I0816 15:06:33.656914 22807 caffe.cpp:313] Batch 836, accuracy/top1 = 0.64
I0816 15:06:33.656936 22807 caffe.cpp:313] Batch 836, accuracy/top5 = 0.86
I0816 15:06:33.656941 22807 caffe.cpp:313] Batch 836, loss = 1.49249
I0816 15:06:33.719812 22807 caffe.cpp:313] Batch 837, accuracy/top1 = 0.58
I0816 15:06:33.719833 22807 caffe.cpp:313] Batch 837, accuracy/top5 = 0.78
I0816 15:06:33.719837 22807 caffe.cpp:313] Batch 837, loss = 1.49701
I0816 15:06:33.782876 22807 caffe.cpp:313] Batch 838, accuracy/top1 = 0.5
I0816 15:06:33.782898 22807 caffe.cpp:313] Batch 838, accuracy/top5 = 0.84
I0816 15:06:33.782903 22807 caffe.cpp:313] Batch 838, loss = 1.80662
I0816 15:06:33.846087 22807 caffe.cpp:313] Batch 839, accuracy/top1 = 0.6
I0816 15:06:33.846108 22807 caffe.cpp:313] Batch 839, accuracy/top5 = 0.8
I0816 15:06:33.846112 22807 caffe.cpp:313] Batch 839, loss = 1.81176
I0816 15:06:33.909852 22807 caffe.cpp:313] Batch 840, accuracy/top1 = 0.54
I0816 15:06:33.909873 22807 caffe.cpp:313] Batch 840, accuracy/top5 = 0.76
I0816 15:06:33.909876 22807 caffe.cpp:313] Batch 840, loss = 1.94519
I0816 15:06:33.973551 22807 caffe.cpp:313] Batch 841, accuracy/top1 = 0.52
I0816 15:06:33.973572 22807 caffe.cpp:313] Batch 841, accuracy/top5 = 0.76
I0816 15:06:33.973577 22807 caffe.cpp:313] Batch 841, loss = 1.89356
I0816 15:06:34.037120 22807 caffe.cpp:313] Batch 842, accuracy/top1 = 0.6
I0816 15:06:34.037140 22807 caffe.cpp:313] Batch 842, accuracy/top5 = 0.84
I0816 15:06:34.037144 22807 caffe.cpp:313] Batch 842, loss = 1.5308
I0816 15:06:34.100603 22807 caffe.cpp:313] Batch 843, accuracy/top1 = 0.58
I0816 15:06:34.100626 22807 caffe.cpp:313] Batch 843, accuracy/top5 = 0.86
I0816 15:06:34.100630 22807 caffe.cpp:313] Batch 843, loss = 1.82341
I0816 15:06:34.164059 22807 caffe.cpp:313] Batch 844, accuracy/top1 = 0.5
I0816 15:06:34.164083 22807 caffe.cpp:313] Batch 844, accuracy/top5 = 0.86
I0816 15:06:34.164088 22807 caffe.cpp:313] Batch 844, loss = 1.60901
I0816 15:06:34.227677 22807 caffe.cpp:313] Batch 845, accuracy/top1 = 0.56
I0816 15:06:34.227700 22807 caffe.cpp:313] Batch 845, accuracy/top5 = 0.76
I0816 15:06:34.227705 22807 caffe.cpp:313] Batch 845, loss = 1.99309
I0816 15:06:34.291162 22807 caffe.cpp:313] Batch 846, accuracy/top1 = 0.54
I0816 15:06:34.291184 22807 caffe.cpp:313] Batch 846, accuracy/top5 = 0.8
I0816 15:06:34.291188 22807 caffe.cpp:313] Batch 846, loss = 1.8002
I0816 15:06:34.354696 22807 caffe.cpp:313] Batch 847, accuracy/top1 = 0.54
I0816 15:06:34.354718 22807 caffe.cpp:313] Batch 847, accuracy/top5 = 0.74
I0816 15:06:34.354722 22807 caffe.cpp:313] Batch 847, loss = 2.1903
I0816 15:06:34.418124 22807 caffe.cpp:313] Batch 848, accuracy/top1 = 0.54
I0816 15:06:34.418148 22807 caffe.cpp:313] Batch 848, accuracy/top5 = 0.82
I0816 15:06:34.418151 22807 caffe.cpp:313] Batch 848, loss = 1.7989
I0816 15:06:34.481727 22807 caffe.cpp:313] Batch 849, accuracy/top1 = 0.62
I0816 15:06:34.481747 22807 caffe.cpp:313] Batch 849, accuracy/top5 = 0.92
I0816 15:06:34.481751 22807 caffe.cpp:313] Batch 849, loss = 1.50753
I0816 15:06:34.544927 22807 caffe.cpp:313] Batch 850, accuracy/top1 = 0.56
I0816 15:06:34.544945 22807 caffe.cpp:313] Batch 850, accuracy/top5 = 0.82
I0816 15:06:34.544950 22807 caffe.cpp:313] Batch 850, loss = 1.81042
I0816 15:06:34.607954 22807 caffe.cpp:313] Batch 851, accuracy/top1 = 0.52
I0816 15:06:34.607975 22807 caffe.cpp:313] Batch 851, accuracy/top5 = 0.8
I0816 15:06:34.607980 22807 caffe.cpp:313] Batch 851, loss = 2.03879
I0816 15:06:34.671416 22807 caffe.cpp:313] Batch 852, accuracy/top1 = 0.56
I0816 15:06:34.671437 22807 caffe.cpp:313] Batch 852, accuracy/top5 = 0.76
I0816 15:06:34.671442 22807 caffe.cpp:313] Batch 852, loss = 2.05342
I0816 15:06:34.734876 22807 caffe.cpp:313] Batch 853, accuracy/top1 = 0.7
I0816 15:06:34.734899 22807 caffe.cpp:313] Batch 853, accuracy/top5 = 0.86
I0816 15:06:34.734904 22807 caffe.cpp:313] Batch 853, loss = 1.40858
I0816 15:06:34.798410 22807 caffe.cpp:313] Batch 854, accuracy/top1 = 0.66
I0816 15:06:34.798432 22807 caffe.cpp:313] Batch 854, accuracy/top5 = 0.82
I0816 15:06:34.798436 22807 caffe.cpp:313] Batch 854, loss = 1.55708
I0816 15:06:34.861910 22807 caffe.cpp:313] Batch 855, accuracy/top1 = 0.44
I0816 15:06:34.861933 22807 caffe.cpp:313] Batch 855, accuracy/top5 = 0.76
I0816 15:06:34.861938 22807 caffe.cpp:313] Batch 855, loss = 2.2742
I0816 15:06:34.925210 22807 caffe.cpp:313] Batch 856, accuracy/top1 = 0.52
I0816 15:06:34.925232 22807 caffe.cpp:313] Batch 856, accuracy/top5 = 0.82
I0816 15:06:34.925237 22807 caffe.cpp:313] Batch 856, loss = 2.07236
I0816 15:06:34.988579 22807 caffe.cpp:313] Batch 857, accuracy/top1 = 0.68
I0816 15:06:34.988600 22807 caffe.cpp:313] Batch 857, accuracy/top5 = 0.9
I0816 15:06:34.988605 22807 caffe.cpp:313] Batch 857, loss = 1.35217
I0816 15:06:35.052073 22807 caffe.cpp:313] Batch 858, accuracy/top1 = 0.54
I0816 15:06:35.052091 22807 caffe.cpp:313] Batch 858, accuracy/top5 = 0.92
I0816 15:06:35.052095 22807 caffe.cpp:313] Batch 858, loss = 1.4404
I0816 15:06:35.115519 22807 caffe.cpp:313] Batch 859, accuracy/top1 = 0.62
I0816 15:06:35.115540 22807 caffe.cpp:313] Batch 859, accuracy/top5 = 0.76
I0816 15:06:35.115561 22807 caffe.cpp:313] Batch 859, loss = 1.97196
I0816 15:06:35.179102 22807 caffe.cpp:313] Batch 860, accuracy/top1 = 0.58
I0816 15:06:35.179126 22807 caffe.cpp:313] Batch 860, accuracy/top5 = 0.78
I0816 15:06:35.179129 22807 caffe.cpp:313] Batch 860, loss = 1.73576
I0816 15:06:35.242506 22807 caffe.cpp:313] Batch 861, accuracy/top1 = 0.7
I0816 15:06:35.242527 22807 caffe.cpp:313] Batch 861, accuracy/top5 = 0.82
I0816 15:06:35.242532 22807 caffe.cpp:313] Batch 861, loss = 1.55447
I0816 15:06:35.306108 22807 caffe.cpp:313] Batch 862, accuracy/top1 = 0.56
I0816 15:06:35.306131 22807 caffe.cpp:313] Batch 862, accuracy/top5 = 0.86
I0816 15:06:35.306135 22807 caffe.cpp:313] Batch 862, loss = 1.62615
I0816 15:06:35.369498 22807 caffe.cpp:313] Batch 863, accuracy/top1 = 0.64
I0816 15:06:35.369519 22807 caffe.cpp:313] Batch 863, accuracy/top5 = 0.74
I0816 15:06:35.369524 22807 caffe.cpp:313] Batch 863, loss = 1.82252
I0816 15:06:35.433048 22807 caffe.cpp:313] Batch 864, accuracy/top1 = 0.62
I0816 15:06:35.433069 22807 caffe.cpp:313] Batch 864, accuracy/top5 = 0.88
I0816 15:06:35.433074 22807 caffe.cpp:313] Batch 864, loss = 1.47784
I0816 15:06:35.496623 22807 caffe.cpp:313] Batch 865, accuracy/top1 = 0.62
I0816 15:06:35.496646 22807 caffe.cpp:313] Batch 865, accuracy/top5 = 0.78
I0816 15:06:35.496650 22807 caffe.cpp:313] Batch 865, loss = 1.95248
I0816 15:06:35.560642 22807 caffe.cpp:313] Batch 866, accuracy/top1 = 0.62
I0816 15:06:35.560660 22807 caffe.cpp:313] Batch 866, accuracy/top5 = 0.84
I0816 15:06:35.560664 22807 caffe.cpp:313] Batch 866, loss = 1.52802
I0816 15:06:35.624001 22807 caffe.cpp:313] Batch 867, accuracy/top1 = 0.6
I0816 15:06:35.624023 22807 caffe.cpp:313] Batch 867, accuracy/top5 = 0.72
I0816 15:06:35.624027 22807 caffe.cpp:313] Batch 867, loss = 2.13477
I0816 15:06:35.687554 22807 caffe.cpp:313] Batch 868, accuracy/top1 = 0.56
I0816 15:06:35.687577 22807 caffe.cpp:313] Batch 868, accuracy/top5 = 0.78
I0816 15:06:35.687582 22807 caffe.cpp:313] Batch 868, loss = 1.98046
I0816 15:06:35.751022 22807 caffe.cpp:313] Batch 869, accuracy/top1 = 0.5
I0816 15:06:35.751044 22807 caffe.cpp:313] Batch 869, accuracy/top5 = 0.8
I0816 15:06:35.751049 22807 caffe.cpp:313] Batch 869, loss = 2.06587
I0816 15:06:35.814585 22807 caffe.cpp:313] Batch 870, accuracy/top1 = 0.54
I0816 15:06:35.814607 22807 caffe.cpp:313] Batch 870, accuracy/top5 = 0.72
I0816 15:06:35.814611 22807 caffe.cpp:313] Batch 870, loss = 2.2362
I0816 15:06:35.878170 22807 caffe.cpp:313] Batch 871, accuracy/top1 = 0.62
I0816 15:06:35.878193 22807 caffe.cpp:313] Batch 871, accuracy/top5 = 0.86
I0816 15:06:35.878197 22807 caffe.cpp:313] Batch 871, loss = 1.61221
I0816 15:06:35.941807 22807 caffe.cpp:313] Batch 872, accuracy/top1 = 0.56
I0816 15:06:35.941826 22807 caffe.cpp:313] Batch 872, accuracy/top5 = 0.8
I0816 15:06:35.941831 22807 caffe.cpp:313] Batch 872, loss = 1.788
I0816 15:06:36.005611 22807 caffe.cpp:313] Batch 873, accuracy/top1 = 0.6
I0816 15:06:36.005631 22807 caffe.cpp:313] Batch 873, accuracy/top5 = 0.84
I0816 15:06:36.005636 22807 caffe.cpp:313] Batch 873, loss = 1.75362
I0816 15:06:36.069392 22807 caffe.cpp:313] Batch 874, accuracy/top1 = 0.64
I0816 15:06:36.069412 22807 caffe.cpp:313] Batch 874, accuracy/top5 = 0.82
I0816 15:06:36.069416 22807 caffe.cpp:313] Batch 874, loss = 1.58357
I0816 15:06:36.133047 22807 caffe.cpp:313] Batch 875, accuracy/top1 = 0.64
I0816 15:06:36.133070 22807 caffe.cpp:313] Batch 875, accuracy/top5 = 0.8
I0816 15:06:36.133074 22807 caffe.cpp:313] Batch 875, loss = 1.65685
I0816 15:06:36.196576 22807 caffe.cpp:313] Batch 876, accuracy/top1 = 0.62
I0816 15:06:36.196599 22807 caffe.cpp:313] Batch 876, accuracy/top5 = 0.84
I0816 15:06:36.196604 22807 caffe.cpp:313] Batch 876, loss = 1.41608
I0816 15:06:36.260136 22807 caffe.cpp:313] Batch 877, accuracy/top1 = 0.62
I0816 15:06:36.260159 22807 caffe.cpp:313] Batch 877, accuracy/top5 = 0.82
I0816 15:06:36.260164 22807 caffe.cpp:313] Batch 877, loss = 1.65606
I0816 15:06:36.323634 22807 caffe.cpp:313] Batch 878, accuracy/top1 = 0.54
I0816 15:06:36.323657 22807 caffe.cpp:313] Batch 878, accuracy/top5 = 0.72
I0816 15:06:36.323678 22807 caffe.cpp:313] Batch 878, loss = 2.1716
I0816 15:06:36.387143 22807 caffe.cpp:313] Batch 879, accuracy/top1 = 0.62
I0816 15:06:36.387166 22807 caffe.cpp:313] Batch 879, accuracy/top5 = 0.82
I0816 15:06:36.387171 22807 caffe.cpp:313] Batch 879, loss = 1.518
I0816 15:06:36.450680 22807 caffe.cpp:313] Batch 880, accuracy/top1 = 0.68
I0816 15:06:36.450701 22807 caffe.cpp:313] Batch 880, accuracy/top5 = 0.84
I0816 15:06:36.450706 22807 caffe.cpp:313] Batch 880, loss = 1.45001
I0816 15:06:36.514266 22807 caffe.cpp:313] Batch 881, accuracy/top1 = 0.58
I0816 15:06:36.514286 22807 caffe.cpp:313] Batch 881, accuracy/top5 = 0.88
I0816 15:06:36.514291 22807 caffe.cpp:313] Batch 881, loss = 1.70973
I0816 15:06:36.578022 22807 caffe.cpp:313] Batch 882, accuracy/top1 = 0.6
I0816 15:06:36.578043 22807 caffe.cpp:313] Batch 882, accuracy/top5 = 0.84
I0816 15:06:36.578048 22807 caffe.cpp:313] Batch 882, loss = 1.38458
I0816 15:06:36.641007 22807 caffe.cpp:313] Batch 883, accuracy/top1 = 0.62
I0816 15:06:36.641029 22807 caffe.cpp:313] Batch 883, accuracy/top5 = 0.82
I0816 15:06:36.641034 22807 caffe.cpp:313] Batch 883, loss = 1.84594
I0816 15:06:36.704175 22807 caffe.cpp:313] Batch 884, accuracy/top1 = 0.44
I0816 15:06:36.704198 22807 caffe.cpp:313] Batch 884, accuracy/top5 = 0.8
I0816 15:06:36.704202 22807 caffe.cpp:313] Batch 884, loss = 1.99688
I0816 15:06:36.767575 22807 caffe.cpp:313] Batch 885, accuracy/top1 = 0.54
I0816 15:06:36.767597 22807 caffe.cpp:313] Batch 885, accuracy/top5 = 0.92
I0816 15:06:36.767602 22807 caffe.cpp:313] Batch 885, loss = 1.65497
I0816 15:06:36.831116 22807 caffe.cpp:313] Batch 886, accuracy/top1 = 0.64
I0816 15:06:36.831138 22807 caffe.cpp:313] Batch 886, accuracy/top5 = 0.84
I0816 15:06:36.831142 22807 caffe.cpp:313] Batch 886, loss = 1.69691
I0816 15:06:36.894670 22807 caffe.cpp:313] Batch 887, accuracy/top1 = 0.52
I0816 15:06:36.894691 22807 caffe.cpp:313] Batch 887, accuracy/top5 = 0.82
I0816 15:06:36.894695 22807 caffe.cpp:313] Batch 887, loss = 1.77123
I0816 15:06:36.958300 22807 caffe.cpp:313] Batch 888, accuracy/top1 = 0.54
I0816 15:06:36.958323 22807 caffe.cpp:313] Batch 888, accuracy/top5 = 0.82
I0816 15:06:36.958328 22807 caffe.cpp:313] Batch 888, loss = 1.93128
I0816 15:06:37.021898 22807 caffe.cpp:313] Batch 889, accuracy/top1 = 0.54
I0816 15:06:37.021921 22807 caffe.cpp:313] Batch 889, accuracy/top5 = 0.86
I0816 15:06:37.021926 22807 caffe.cpp:313] Batch 889, loss = 1.95109
I0816 15:06:37.085476 22807 caffe.cpp:313] Batch 890, accuracy/top1 = 0.48
I0816 15:06:37.085499 22807 caffe.cpp:313] Batch 890, accuracy/top5 = 0.8
I0816 15:06:37.085502 22807 caffe.cpp:313] Batch 890, loss = 2.0855
I0816 15:06:37.149049 22807 caffe.cpp:313] Batch 891, accuracy/top1 = 0.6
I0816 15:06:37.149070 22807 caffe.cpp:313] Batch 891, accuracy/top5 = 0.8
I0816 15:06:37.149073 22807 caffe.cpp:313] Batch 891, loss = 1.82338
I0816 15:06:37.212661 22807 caffe.cpp:313] Batch 892, accuracy/top1 = 0.52
I0816 15:06:37.212682 22807 caffe.cpp:313] Batch 892, accuracy/top5 = 0.8
I0816 15:06:37.212685 22807 caffe.cpp:313] Batch 892, loss = 1.83364
I0816 15:06:37.276162 22807 caffe.cpp:313] Batch 893, accuracy/top1 = 0.6
I0816 15:06:37.276185 22807 caffe.cpp:313] Batch 893, accuracy/top5 = 0.84
I0816 15:06:37.276187 22807 caffe.cpp:313] Batch 893, loss = 1.67089
I0816 15:06:37.339718 22807 caffe.cpp:313] Batch 894, accuracy/top1 = 0.46
I0816 15:06:37.339740 22807 caffe.cpp:313] Batch 894, accuracy/top5 = 0.7
I0816 15:06:37.339742 22807 caffe.cpp:313] Batch 894, loss = 2.27895
I0816 15:06:37.403103 22807 caffe.cpp:313] Batch 895, accuracy/top1 = 0.72
I0816 15:06:37.403126 22807 caffe.cpp:313] Batch 895, accuracy/top5 = 0.9
I0816 15:06:37.403129 22807 caffe.cpp:313] Batch 895, loss = 1.15565
I0816 15:06:37.466701 22807 caffe.cpp:313] Batch 896, accuracy/top1 = 0.54
I0816 15:06:37.466723 22807 caffe.cpp:313] Batch 896, accuracy/top5 = 0.74
I0816 15:06:37.466727 22807 caffe.cpp:313] Batch 896, loss = 1.78896
I0816 15:06:37.530331 22807 caffe.cpp:313] Batch 897, accuracy/top1 = 0.7
I0816 15:06:37.530365 22807 caffe.cpp:313] Batch 897, accuracy/top5 = 0.78
I0816 15:06:37.530370 22807 caffe.cpp:313] Batch 897, loss = 1.61071
I0816 15:06:37.593439 22807 caffe.cpp:313] Batch 898, accuracy/top1 = 0.6
I0816 15:06:37.593461 22807 caffe.cpp:313] Batch 898, accuracy/top5 = 0.88
I0816 15:06:37.593466 22807 caffe.cpp:313] Batch 898, loss = 1.57335
I0816 15:06:37.656971 22807 caffe.cpp:313] Batch 899, accuracy/top1 = 0.7
I0816 15:06:37.656994 22807 caffe.cpp:313] Batch 899, accuracy/top5 = 0.86
I0816 15:06:37.656997 22807 caffe.cpp:313] Batch 899, loss = 1.54521
I0816 15:06:37.720468 22807 caffe.cpp:313] Batch 900, accuracy/top1 = 0.66
I0816 15:06:37.720489 22807 caffe.cpp:313] Batch 900, accuracy/top5 = 0.88
I0816 15:06:37.720491 22807 caffe.cpp:313] Batch 900, loss = 1.35206
I0816 15:06:37.784036 22807 caffe.cpp:313] Batch 901, accuracy/top1 = 0.58
I0816 15:06:37.784059 22807 caffe.cpp:313] Batch 901, accuracy/top5 = 0.76
I0816 15:06:37.784061 22807 caffe.cpp:313] Batch 901, loss = 1.93757
I0816 15:06:37.847673 22807 caffe.cpp:313] Batch 902, accuracy/top1 = 0.58
I0816 15:06:37.847695 22807 caffe.cpp:313] Batch 902, accuracy/top5 = 0.86
I0816 15:06:37.847699 22807 caffe.cpp:313] Batch 902, loss = 1.6717
I0816 15:06:37.911145 22807 caffe.cpp:313] Batch 903, accuracy/top1 = 0.62
I0816 15:06:37.911167 22807 caffe.cpp:313] Batch 903, accuracy/top5 = 0.8
I0816 15:06:37.911171 22807 caffe.cpp:313] Batch 903, loss = 1.50825
I0816 15:06:37.974758 22807 caffe.cpp:313] Batch 904, accuracy/top1 = 0.68
I0816 15:06:37.974779 22807 caffe.cpp:313] Batch 904, accuracy/top5 = 0.84
I0816 15:06:37.974783 22807 caffe.cpp:313] Batch 904, loss = 1.57129
I0816 15:06:38.038517 22807 caffe.cpp:313] Batch 905, accuracy/top1 = 0.58
I0816 15:06:38.038535 22807 caffe.cpp:313] Batch 905, accuracy/top5 = 0.82
I0816 15:06:38.038538 22807 caffe.cpp:313] Batch 905, loss = 1.8786
I0816 15:06:38.102254 22807 caffe.cpp:313] Batch 906, accuracy/top1 = 0.6
I0816 15:06:38.102275 22807 caffe.cpp:313] Batch 906, accuracy/top5 = 0.78
I0816 15:06:38.102279 22807 caffe.cpp:313] Batch 906, loss = 1.67054
I0816 15:06:38.166026 22807 caffe.cpp:313] Batch 907, accuracy/top1 = 0.48
I0816 15:06:38.166046 22807 caffe.cpp:313] Batch 907, accuracy/top5 = 0.84
I0816 15:06:38.166049 22807 caffe.cpp:313] Batch 907, loss = 1.69288
I0816 15:06:38.229594 22807 caffe.cpp:313] Batch 908, accuracy/top1 = 0.56
I0816 15:06:38.229616 22807 caffe.cpp:313] Batch 908, accuracy/top5 = 0.88
I0816 15:06:38.229619 22807 caffe.cpp:313] Batch 908, loss = 1.55582
I0816 15:06:38.293155 22807 caffe.cpp:313] Batch 909, accuracy/top1 = 0.58
I0816 15:06:38.293179 22807 caffe.cpp:313] Batch 909, accuracy/top5 = 0.86
I0816 15:06:38.293181 22807 caffe.cpp:313] Batch 909, loss = 1.5988
I0816 15:06:38.356647 22807 caffe.cpp:313] Batch 910, accuracy/top1 = 0.54
I0816 15:06:38.356669 22807 caffe.cpp:313] Batch 910, accuracy/top5 = 0.76
I0816 15:06:38.356673 22807 caffe.cpp:313] Batch 910, loss = 2.22571
I0816 15:06:38.420111 22807 caffe.cpp:313] Batch 911, accuracy/top1 = 0.58
I0816 15:06:38.420136 22807 caffe.cpp:313] Batch 911, accuracy/top5 = 0.8
I0816 15:06:38.420140 22807 caffe.cpp:313] Batch 911, loss = 1.86001
I0816 15:06:38.483592 22807 caffe.cpp:313] Batch 912, accuracy/top1 = 0.58
I0816 15:06:38.483614 22807 caffe.cpp:313] Batch 912, accuracy/top5 = 0.76
I0816 15:06:38.483618 22807 caffe.cpp:313] Batch 912, loss = 1.74283
I0816 15:06:38.546973 22807 caffe.cpp:313] Batch 913, accuracy/top1 = 0.58
I0816 15:06:38.546990 22807 caffe.cpp:313] Batch 913, accuracy/top5 = 0.78
I0816 15:06:38.546993 22807 caffe.cpp:313] Batch 913, loss = 1.81494
I0816 15:06:38.609971 22807 caffe.cpp:313] Batch 914, accuracy/top1 = 0.64
I0816 15:06:38.609992 22807 caffe.cpp:313] Batch 914, accuracy/top5 = 0.78
I0816 15:06:38.609994 22807 caffe.cpp:313] Batch 914, loss = 1.90695
I0816 15:06:38.673014 22807 caffe.cpp:313] Batch 915, accuracy/top1 = 0.68
I0816 15:06:38.673035 22807 caffe.cpp:313] Batch 915, accuracy/top5 = 0.8
I0816 15:06:38.673039 22807 caffe.cpp:313] Batch 915, loss = 1.75932
I0816 15:06:38.736007 22807 caffe.cpp:313] Batch 916, accuracy/top1 = 0.66
I0816 15:06:38.736029 22807 caffe.cpp:313] Batch 916, accuracy/top5 = 0.88
I0816 15:06:38.736032 22807 caffe.cpp:313] Batch 916, loss = 1.54963
I0816 15:06:38.799005 22807 caffe.cpp:313] Batch 917, accuracy/top1 = 0.6
I0816 15:06:38.799026 22807 caffe.cpp:313] Batch 917, accuracy/top5 = 0.82
I0816 15:06:38.799028 22807 caffe.cpp:313] Batch 917, loss = 1.66957
I0816 15:06:38.861922 22807 caffe.cpp:313] Batch 918, accuracy/top1 = 0.58
I0816 15:06:38.861945 22807 caffe.cpp:313] Batch 918, accuracy/top5 = 0.76
I0816 15:06:38.861948 22807 caffe.cpp:313] Batch 918, loss = 1.86124
I0816 15:06:38.924800 22807 caffe.cpp:313] Batch 919, accuracy/top1 = 0.62
I0816 15:06:38.924823 22807 caffe.cpp:313] Batch 919, accuracy/top5 = 0.78
I0816 15:06:38.924825 22807 caffe.cpp:313] Batch 919, loss = 1.98381
I0816 15:06:38.987666 22807 caffe.cpp:313] Batch 920, accuracy/top1 = 0.64
I0816 15:06:38.987689 22807 caffe.cpp:313] Batch 920, accuracy/top5 = 0.8
I0816 15:06:38.987691 22807 caffe.cpp:313] Batch 920, loss = 1.84651
I0816 15:06:39.050614 22807 caffe.cpp:313] Batch 921, accuracy/top1 = 0.58
I0816 15:06:39.050633 22807 caffe.cpp:313] Batch 921, accuracy/top5 = 0.82
I0816 15:06:39.050637 22807 caffe.cpp:313] Batch 921, loss = 1.87393
I0816 15:06:39.113584 22807 caffe.cpp:313] Batch 922, accuracy/top1 = 0.74
I0816 15:06:39.113607 22807 caffe.cpp:313] Batch 922, accuracy/top5 = 0.9
I0816 15:06:39.113610 22807 caffe.cpp:313] Batch 922, loss = 1.18148
I0816 15:06:39.176471 22807 caffe.cpp:313] Batch 923, accuracy/top1 = 0.64
I0816 15:06:39.176492 22807 caffe.cpp:313] Batch 923, accuracy/top5 = 0.78
I0816 15:06:39.176496 22807 caffe.cpp:313] Batch 923, loss = 1.97628
I0816 15:06:39.239415 22807 caffe.cpp:313] Batch 924, accuracy/top1 = 0.6
I0816 15:06:39.239437 22807 caffe.cpp:313] Batch 924, accuracy/top5 = 0.88
I0816 15:06:39.239441 22807 caffe.cpp:313] Batch 924, loss = 1.53236
I0816 15:06:39.302191 22807 caffe.cpp:313] Batch 925, accuracy/top1 = 0.58
I0816 15:06:39.302213 22807 caffe.cpp:313] Batch 925, accuracy/top5 = 0.8
I0816 15:06:39.302217 22807 caffe.cpp:313] Batch 925, loss = 1.88386
I0816 15:06:39.365173 22807 caffe.cpp:313] Batch 926, accuracy/top1 = 0.64
I0816 15:06:39.365195 22807 caffe.cpp:313] Batch 926, accuracy/top5 = 0.8
I0816 15:06:39.365198 22807 caffe.cpp:313] Batch 926, loss = 1.99657
I0816 15:06:39.427989 22807 caffe.cpp:313] Batch 927, accuracy/top1 = 0.56
I0816 15:06:39.428011 22807 caffe.cpp:313] Batch 927, accuracy/top5 = 0.72
I0816 15:06:39.428014 22807 caffe.cpp:313] Batch 927, loss = 2.13165
I0816 15:06:39.490931 22807 caffe.cpp:313] Batch 928, accuracy/top1 = 0.7
I0816 15:06:39.490952 22807 caffe.cpp:313] Batch 928, accuracy/top5 = 0.88
I0816 15:06:39.490955 22807 caffe.cpp:313] Batch 928, loss = 1.37765
I0816 15:06:39.554249 22807 caffe.cpp:313] Batch 929, accuracy/top1 = 0.52
I0816 15:06:39.554265 22807 caffe.cpp:313] Batch 929, accuracy/top5 = 0.82
I0816 15:06:39.554270 22807 caffe.cpp:313] Batch 929, loss = 1.50852
I0816 15:06:39.617231 22807 caffe.cpp:313] Batch 930, accuracy/top1 = 0.62
I0816 15:06:39.617254 22807 caffe.cpp:313] Batch 930, accuracy/top5 = 0.8
I0816 15:06:39.617257 22807 caffe.cpp:313] Batch 930, loss = 1.75942
I0816 15:06:39.680207 22807 caffe.cpp:313] Batch 931, accuracy/top1 = 0.52
I0816 15:06:39.680228 22807 caffe.cpp:313] Batch 931, accuracy/top5 = 0.8
I0816 15:06:39.680232 22807 caffe.cpp:313] Batch 931, loss = 2.25547
I0816 15:06:39.743047 22807 caffe.cpp:313] Batch 932, accuracy/top1 = 0.64
I0816 15:06:39.743069 22807 caffe.cpp:313] Batch 932, accuracy/top5 = 0.8
I0816 15:06:39.743072 22807 caffe.cpp:313] Batch 932, loss = 1.63336
I0816 15:06:39.805910 22807 caffe.cpp:313] Batch 933, accuracy/top1 = 0.6
I0816 15:06:39.805932 22807 caffe.cpp:313] Batch 933, accuracy/top5 = 0.8
I0816 15:06:39.805935 22807 caffe.cpp:313] Batch 933, loss = 2.09031
I0816 15:06:39.868866 22807 caffe.cpp:313] Batch 934, accuracy/top1 = 0.56
I0816 15:06:39.868890 22807 caffe.cpp:313] Batch 934, accuracy/top5 = 0.76
I0816 15:06:39.868906 22807 caffe.cpp:313] Batch 934, loss = 1.99793
I0816 15:06:39.931875 22807 caffe.cpp:313] Batch 935, accuracy/top1 = 0.62
I0816 15:06:39.931897 22807 caffe.cpp:313] Batch 935, accuracy/top5 = 0.78
I0816 15:06:39.931900 22807 caffe.cpp:313] Batch 935, loss = 2.09117
I0816 15:06:39.994874 22807 caffe.cpp:313] Batch 936, accuracy/top1 = 0.68
I0816 15:06:39.994894 22807 caffe.cpp:313] Batch 936, accuracy/top5 = 0.86
I0816 15:06:39.994897 22807 caffe.cpp:313] Batch 936, loss = 1.58013
I0816 15:06:40.057802 22807 caffe.cpp:313] Batch 937, accuracy/top1 = 0.58
I0816 15:06:40.057822 22807 caffe.cpp:313] Batch 937, accuracy/top5 = 0.86
I0816 15:06:40.057826 22807 caffe.cpp:313] Batch 937, loss = 1.79951
I0816 15:06:40.120764 22807 caffe.cpp:313] Batch 938, accuracy/top1 = 0.52
I0816 15:06:40.120785 22807 caffe.cpp:313] Batch 938, accuracy/top5 = 0.82
I0816 15:06:40.120789 22807 caffe.cpp:313] Batch 938, loss = 1.91516
I0816 15:06:40.183790 22807 caffe.cpp:313] Batch 939, accuracy/top1 = 0.54
I0816 15:06:40.183809 22807 caffe.cpp:313] Batch 939, accuracy/top5 = 0.78
I0816 15:06:40.183812 22807 caffe.cpp:313] Batch 939, loss = 1.9305
I0816 15:06:40.247171 22807 caffe.cpp:313] Batch 940, accuracy/top1 = 0.54
I0816 15:06:40.247190 22807 caffe.cpp:313] Batch 940, accuracy/top5 = 0.78
I0816 15:06:40.247195 22807 caffe.cpp:313] Batch 940, loss = 1.86061
I0816 15:06:40.310346 22807 caffe.cpp:313] Batch 941, accuracy/top1 = 0.58
I0816 15:06:40.310367 22807 caffe.cpp:313] Batch 941, accuracy/top5 = 0.78
I0816 15:06:40.310370 22807 caffe.cpp:313] Batch 941, loss = 1.97831
I0816 15:06:40.373354 22807 caffe.cpp:313] Batch 942, accuracy/top1 = 0.5
I0816 15:06:40.373472 22807 caffe.cpp:313] Batch 942, accuracy/top5 = 0.76
I0816 15:06:40.373477 22807 caffe.cpp:313] Batch 942, loss = 2.09693
I0816 15:06:40.436208 22807 caffe.cpp:313] Batch 943, accuracy/top1 = 0.54
I0816 15:06:40.436230 22807 caffe.cpp:313] Batch 943, accuracy/top5 = 0.84
I0816 15:06:40.436233 22807 caffe.cpp:313] Batch 943, loss = 1.56767
I0816 15:06:40.499119 22807 caffe.cpp:313] Batch 944, accuracy/top1 = 0.58
I0816 15:06:40.499140 22807 caffe.cpp:313] Batch 944, accuracy/top5 = 0.86
I0816 15:06:40.499143 22807 caffe.cpp:313] Batch 944, loss = 1.49241
I0816 15:06:40.562418 22807 caffe.cpp:313] Batch 945, accuracy/top1 = 0.54
I0816 15:06:40.562438 22807 caffe.cpp:313] Batch 945, accuracy/top5 = 0.82
I0816 15:06:40.562440 22807 caffe.cpp:313] Batch 945, loss = 2.00206
I0816 15:06:40.625327 22807 caffe.cpp:313] Batch 946, accuracy/top1 = 0.62
I0816 15:06:40.625349 22807 caffe.cpp:313] Batch 946, accuracy/top5 = 0.78
I0816 15:06:40.625352 22807 caffe.cpp:313] Batch 946, loss = 1.93016
I0816 15:06:40.688060 22807 caffe.cpp:313] Batch 947, accuracy/top1 = 0.62
I0816 15:06:40.688081 22807 caffe.cpp:313] Batch 947, accuracy/top5 = 0.88
I0816 15:06:40.688084 22807 caffe.cpp:313] Batch 947, loss = 1.28158
I0816 15:06:40.751061 22807 caffe.cpp:313] Batch 948, accuracy/top1 = 0.5
I0816 15:06:40.751085 22807 caffe.cpp:313] Batch 948, accuracy/top5 = 0.74
I0816 15:06:40.751087 22807 caffe.cpp:313] Batch 948, loss = 2.24866
I0816 15:06:40.814105 22807 caffe.cpp:313] Batch 949, accuracy/top1 = 0.66
I0816 15:06:40.814127 22807 caffe.cpp:313] Batch 949, accuracy/top5 = 0.88
I0816 15:06:40.814131 22807 caffe.cpp:313] Batch 949, loss = 1.32731
I0816 15:06:40.877025 22807 caffe.cpp:313] Batch 950, accuracy/top1 = 0.64
I0816 15:06:40.877048 22807 caffe.cpp:313] Batch 950, accuracy/top5 = 0.78
I0816 15:06:40.877050 22807 caffe.cpp:313] Batch 950, loss = 2.07476
I0816 15:06:40.939959 22807 caffe.cpp:313] Batch 951, accuracy/top1 = 0.74
I0816 15:06:40.939980 22807 caffe.cpp:313] Batch 951, accuracy/top5 = 0.9
I0816 15:06:40.939983 22807 caffe.cpp:313] Batch 951, loss = 1.1766
I0816 15:06:41.002827 22807 caffe.cpp:313] Batch 952, accuracy/top1 = 0.66
I0816 15:06:41.002846 22807 caffe.cpp:313] Batch 952, accuracy/top5 = 0.8
I0816 15:06:41.002848 22807 caffe.cpp:313] Batch 952, loss = 2.10329
I0816 15:06:41.065845 22807 caffe.cpp:313] Batch 953, accuracy/top1 = 0.52
I0816 15:06:41.065865 22807 caffe.cpp:313] Batch 953, accuracy/top5 = 0.76
I0816 15:06:41.065867 22807 caffe.cpp:313] Batch 953, loss = 2.22183
I0816 15:06:41.128787 22807 caffe.cpp:313] Batch 954, accuracy/top1 = 0.5
I0816 15:06:41.128810 22807 caffe.cpp:313] Batch 954, accuracy/top5 = 0.72
I0816 15:06:41.128813 22807 caffe.cpp:313] Batch 954, loss = 2.28962
I0816 15:06:41.191653 22807 caffe.cpp:313] Batch 955, accuracy/top1 = 0.54
I0816 15:06:41.191675 22807 caffe.cpp:313] Batch 955, accuracy/top5 = 0.74
I0816 15:06:41.191679 22807 caffe.cpp:313] Batch 955, loss = 2.20791
I0816 15:06:41.254546 22807 caffe.cpp:313] Batch 956, accuracy/top1 = 0.54
I0816 15:06:41.254568 22807 caffe.cpp:313] Batch 956, accuracy/top5 = 0.84
I0816 15:06:41.254571 22807 caffe.cpp:313] Batch 956, loss = 1.92106
I0816 15:06:41.317504 22807 caffe.cpp:313] Batch 957, accuracy/top1 = 0.52
I0816 15:06:41.317525 22807 caffe.cpp:313] Batch 957, accuracy/top5 = 0.8
I0816 15:06:41.317528 22807 caffe.cpp:313] Batch 957, loss = 2.13314
I0816 15:06:41.380570 22807 caffe.cpp:313] Batch 958, accuracy/top1 = 0.62
I0816 15:06:41.380592 22807 caffe.cpp:313] Batch 958, accuracy/top5 = 0.84
I0816 15:06:41.380595 22807 caffe.cpp:313] Batch 958, loss = 1.70978
I0816 15:06:41.443503 22807 caffe.cpp:313] Batch 959, accuracy/top1 = 0.48
I0816 15:06:41.443524 22807 caffe.cpp:313] Batch 959, accuracy/top5 = 0.8
I0816 15:06:41.443527 22807 caffe.cpp:313] Batch 959, loss = 1.98724
I0816 15:06:41.506568 22807 caffe.cpp:313] Batch 960, accuracy/top1 = 0.66
I0816 15:06:41.506590 22807 caffe.cpp:313] Batch 960, accuracy/top5 = 0.84
I0816 15:06:41.506593 22807 caffe.cpp:313] Batch 960, loss = 1.7592
I0816 15:06:41.569723 22807 caffe.cpp:313] Batch 961, accuracy/top1 = 0.52
I0816 15:06:41.569759 22807 caffe.cpp:313] Batch 961, accuracy/top5 = 0.74
I0816 15:06:41.569764 22807 caffe.cpp:313] Batch 961, loss = 2.26553
I0816 15:06:41.632742 22807 caffe.cpp:313] Batch 962, accuracy/top1 = 0.62
I0816 15:06:41.632762 22807 caffe.cpp:313] Batch 962, accuracy/top5 = 0.88
I0816 15:06:41.632766 22807 caffe.cpp:313] Batch 962, loss = 1.34566
I0816 15:06:41.695750 22807 caffe.cpp:313] Batch 963, accuracy/top1 = 0.48
I0816 15:06:41.695772 22807 caffe.cpp:313] Batch 963, accuracy/top5 = 0.74
I0816 15:06:41.695775 22807 caffe.cpp:313] Batch 963, loss = 2.03792
I0816 15:06:41.758738 22807 caffe.cpp:313] Batch 964, accuracy/top1 = 0.6
I0816 15:06:41.758760 22807 caffe.cpp:313] Batch 964, accuracy/top5 = 0.82
I0816 15:06:41.758764 22807 caffe.cpp:313] Batch 964, loss = 1.84308
I0816 15:06:41.821569 22807 caffe.cpp:313] Batch 965, accuracy/top1 = 0.54
I0816 15:06:41.821591 22807 caffe.cpp:313] Batch 965, accuracy/top5 = 0.78
I0816 15:06:41.821594 22807 caffe.cpp:313] Batch 965, loss = 2.00662
I0816 15:06:41.884300 22807 caffe.cpp:313] Batch 966, accuracy/top1 = 0.54
I0816 15:06:41.884322 22807 caffe.cpp:313] Batch 966, accuracy/top5 = 0.84
I0816 15:06:41.884326 22807 caffe.cpp:313] Batch 966, loss = 2.04501
I0816 15:06:41.947336 22807 caffe.cpp:313] Batch 967, accuracy/top1 = 0.5
I0816 15:06:41.947358 22807 caffe.cpp:313] Batch 967, accuracy/top5 = 0.84
I0816 15:06:41.947361 22807 caffe.cpp:313] Batch 967, loss = 1.94144
I0816 15:06:42.010241 22807 caffe.cpp:313] Batch 968, accuracy/top1 = 0.58
I0816 15:06:42.010262 22807 caffe.cpp:313] Batch 968, accuracy/top5 = 0.84
I0816 15:06:42.010264 22807 caffe.cpp:313] Batch 968, loss = 2.01045
I0816 15:06:42.073266 22807 caffe.cpp:313] Batch 969, accuracy/top1 = 0.48
I0816 15:06:42.073287 22807 caffe.cpp:313] Batch 969, accuracy/top5 = 0.84
I0816 15:06:42.073290 22807 caffe.cpp:313] Batch 969, loss = 1.79556
I0816 15:06:42.136133 22807 caffe.cpp:313] Batch 970, accuracy/top1 = 0.64
I0816 15:06:42.136154 22807 caffe.cpp:313] Batch 970, accuracy/top5 = 0.82
I0816 15:06:42.136157 22807 caffe.cpp:313] Batch 970, loss = 1.64688
I0816 15:06:42.199102 22807 caffe.cpp:313] Batch 971, accuracy/top1 = 0.64
I0816 15:06:42.199123 22807 caffe.cpp:313] Batch 971, accuracy/top5 = 0.88
I0816 15:06:42.199126 22807 caffe.cpp:313] Batch 971, loss = 1.48483
I0816 15:06:42.261961 22807 caffe.cpp:313] Batch 972, accuracy/top1 = 0.6
I0816 15:06:42.261983 22807 caffe.cpp:313] Batch 972, accuracy/top5 = 0.92
I0816 15:06:42.261986 22807 caffe.cpp:313] Batch 972, loss = 1.56464
I0816 15:06:42.324973 22807 caffe.cpp:313] Batch 973, accuracy/top1 = 0.4
I0816 15:06:42.324992 22807 caffe.cpp:313] Batch 973, accuracy/top5 = 0.78
I0816 15:06:42.324995 22807 caffe.cpp:313] Batch 973, loss = 2.39307
I0816 15:06:42.388008 22807 caffe.cpp:313] Batch 974, accuracy/top1 = 0.56
I0816 15:06:42.388028 22807 caffe.cpp:313] Batch 974, accuracy/top5 = 0.82
I0816 15:06:42.388032 22807 caffe.cpp:313] Batch 974, loss = 1.81092
I0816 15:06:42.451020 22807 caffe.cpp:313] Batch 975, accuracy/top1 = 0.66
I0816 15:06:42.451040 22807 caffe.cpp:313] Batch 975, accuracy/top5 = 0.8
I0816 15:06:42.451042 22807 caffe.cpp:313] Batch 975, loss = 1.65916
I0816 15:06:42.514065 22807 caffe.cpp:313] Batch 976, accuracy/top1 = 0.54
I0816 15:06:42.514086 22807 caffe.cpp:313] Batch 976, accuracy/top5 = 0.78
I0816 15:06:42.514089 22807 caffe.cpp:313] Batch 976, loss = 1.95821
I0816 15:06:42.577388 22807 caffe.cpp:313] Batch 977, accuracy/top1 = 0.54
I0816 15:06:42.577405 22807 caffe.cpp:313] Batch 977, accuracy/top5 = 0.8
I0816 15:06:42.577409 22807 caffe.cpp:313] Batch 977, loss = 1.87444
I0816 15:06:42.640400 22807 caffe.cpp:313] Batch 978, accuracy/top1 = 0.54
I0816 15:06:42.640422 22807 caffe.cpp:313] Batch 978, accuracy/top5 = 0.74
I0816 15:06:42.640425 22807 caffe.cpp:313] Batch 978, loss = 2.20027
I0816 15:06:42.703425 22807 caffe.cpp:313] Batch 979, accuracy/top1 = 0.6
I0816 15:06:42.703446 22807 caffe.cpp:313] Batch 979, accuracy/top5 = 0.84
I0816 15:06:42.703449 22807 caffe.cpp:313] Batch 979, loss = 1.78899
I0816 15:06:42.766378 22807 caffe.cpp:313] Batch 980, accuracy/top1 = 0.54
I0816 15:06:42.766399 22807 caffe.cpp:313] Batch 980, accuracy/top5 = 0.78
I0816 15:06:42.766402 22807 caffe.cpp:313] Batch 980, loss = 2.21514
I0816 15:06:42.829315 22807 caffe.cpp:313] Batch 981, accuracy/top1 = 0.5
I0816 15:06:42.829336 22807 caffe.cpp:313] Batch 981, accuracy/top5 = 0.74
I0816 15:06:42.829340 22807 caffe.cpp:313] Batch 981, loss = 2.07532
I0816 15:06:42.892282 22807 caffe.cpp:313] Batch 982, accuracy/top1 = 0.54
I0816 15:06:42.892303 22807 caffe.cpp:313] Batch 982, accuracy/top5 = 0.68
I0816 15:06:42.892307 22807 caffe.cpp:313] Batch 982, loss = 2.57275
I0816 15:06:42.955260 22807 caffe.cpp:313] Batch 983, accuracy/top1 = 0.5
I0816 15:06:42.955281 22807 caffe.cpp:313] Batch 983, accuracy/top5 = 0.78
I0816 15:06:42.955284 22807 caffe.cpp:313] Batch 983, loss = 2.3787
I0816 15:06:43.018231 22807 caffe.cpp:313] Batch 984, accuracy/top1 = 0.7
I0816 15:06:43.018254 22807 caffe.cpp:313] Batch 984, accuracy/top5 = 0.9
I0816 15:06:43.018256 22807 caffe.cpp:313] Batch 984, loss = 1.32632
I0816 15:06:43.081073 22807 caffe.cpp:313] Batch 985, accuracy/top1 = 0.6
I0816 15:06:43.081094 22807 caffe.cpp:313] Batch 985, accuracy/top5 = 0.84
I0816 15:06:43.081097 22807 caffe.cpp:313] Batch 985, loss = 1.54542
I0816 15:06:43.143898 22807 caffe.cpp:313] Batch 986, accuracy/top1 = 0.56
I0816 15:06:43.143919 22807 caffe.cpp:313] Batch 986, accuracy/top5 = 0.76
I0816 15:06:43.143923 22807 caffe.cpp:313] Batch 986, loss = 2.02919
I0816 15:06:43.206877 22807 caffe.cpp:313] Batch 987, accuracy/top1 = 0.52
I0816 15:06:43.206902 22807 caffe.cpp:313] Batch 987, accuracy/top5 = 0.78
I0816 15:06:43.206904 22807 caffe.cpp:313] Batch 987, loss = 1.92107
I0816 15:06:43.269773 22807 caffe.cpp:313] Batch 988, accuracy/top1 = 0.54
I0816 15:06:43.269795 22807 caffe.cpp:313] Batch 988, accuracy/top5 = 0.82
I0816 15:06:43.269798 22807 caffe.cpp:313] Batch 988, loss = 1.78358
I0816 15:06:43.332674 22807 caffe.cpp:313] Batch 989, accuracy/top1 = 0.5
I0816 15:06:43.332696 22807 caffe.cpp:313] Batch 989, accuracy/top5 = 0.76
I0816 15:06:43.332700 22807 caffe.cpp:313] Batch 989, loss = 1.93827
I0816 15:06:43.395586 22807 caffe.cpp:313] Batch 990, accuracy/top1 = 0.62
I0816 15:06:43.395607 22807 caffe.cpp:313] Batch 990, accuracy/top5 = 0.86
I0816 15:06:43.395611 22807 caffe.cpp:313] Batch 990, loss = 1.28678
I0816 15:06:43.458498 22807 caffe.cpp:313] Batch 991, accuracy/top1 = 0.64
I0816 15:06:43.458519 22807 caffe.cpp:313] Batch 991, accuracy/top5 = 0.86
I0816 15:06:43.458523 22807 caffe.cpp:313] Batch 991, loss = 1.64052
I0816 15:06:43.521397 22807 caffe.cpp:313] Batch 992, accuracy/top1 = 0.62
I0816 15:06:43.521420 22807 caffe.cpp:313] Batch 992, accuracy/top5 = 0.82
I0816 15:06:43.521422 22807 caffe.cpp:313] Batch 992, loss = 1.3987
I0816 15:06:43.584456 22807 caffe.cpp:313] Batch 993, accuracy/top1 = 0.64
I0816 15:06:43.584478 22807 caffe.cpp:313] Batch 993, accuracy/top5 = 0.86
I0816 15:06:43.584481 22807 caffe.cpp:313] Batch 993, loss = 1.34029
I0816 15:06:43.647548 22807 caffe.cpp:313] Batch 994, accuracy/top1 = 0.68
I0816 15:06:43.647569 22807 caffe.cpp:313] Batch 994, accuracy/top5 = 0.92
I0816 15:06:43.647572 22807 caffe.cpp:313] Batch 994, loss = 1.37891
I0816 15:06:43.710518 22807 caffe.cpp:313] Batch 995, accuracy/top1 = 0.56
I0816 15:06:43.710541 22807 caffe.cpp:313] Batch 995, accuracy/top5 = 0.82
I0816 15:06:43.710544 22807 caffe.cpp:313] Batch 995, loss = 1.81623
I0816 15:06:43.773550 22807 caffe.cpp:313] Batch 996, accuracy/top1 = 0.56
I0816 15:06:43.773572 22807 caffe.cpp:313] Batch 996, accuracy/top5 = 0.8
I0816 15:06:43.773576 22807 caffe.cpp:313] Batch 996, loss = 1.76161
I0816 15:06:43.820212 22826 data_reader.cpp:288] Starting prefetch of epoch 1
I0816 15:06:43.836370 22807 caffe.cpp:313] Batch 997, accuracy/top1 = 0.6
I0816 15:06:43.836390 22807 caffe.cpp:313] Batch 997, accuracy/top5 = 0.86
I0816 15:06:43.836393 22807 caffe.cpp:313] Batch 997, loss = 1.72218
I0816 15:06:43.899355 22807 caffe.cpp:313] Batch 998, accuracy/top1 = 0.48
I0816 15:06:43.899391 22807 caffe.cpp:313] Batch 998, accuracy/top5 = 0.72
I0816 15:06:43.899394 22807 caffe.cpp:313] Batch 998, loss = 2.12238
I0816 15:06:43.962183 22807 caffe.cpp:313] Batch 999, accuracy/top1 = 0.66
I0816 15:06:43.962204 22807 caffe.cpp:313] Batch 999, accuracy/top5 = 0.9
I0816 15:06:43.962208 22807 caffe.cpp:313] Batch 999, loss = 1.40734
I0816 15:06:43.962210 22807 caffe.cpp:318] Loss: 1.79881
I0816 15:06:43.962218 22807 caffe.cpp:330] accuracy/top1 = 0.57838
I0816 15:06:43.962222 22807 caffe.cpp:330] accuracy/top5 = 0.812922
I0816 15:06:43.962227 22807 caffe.cpp:330] loss = 1.79881 (* 1 = 1.79881 loss)
