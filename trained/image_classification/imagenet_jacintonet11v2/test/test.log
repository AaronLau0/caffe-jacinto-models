I0629 14:07:30.148375 17196 caffe.cpp:608] This is NVCaffe 0.16.2 started at Thu Jun 29 14:07:29 2017
I0629 14:07:30.148500 17196 caffe.cpp:611] CuDNN version: 6.0.21
I0629 14:07:30.148504 17196 caffe.cpp:612] CuBLAS version: 8000
I0629 14:07:30.148505 17196 caffe.cpp:613] CUDA version: 8000
I0629 14:07:30.148507 17196 caffe.cpp:614] CUDA driver version: 8000
I0629 14:07:30.148512 17196 caffe.cpp:263] Not using GPU #1 for single-GPU function
I0629 14:07:30.152519 17196 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0629 14:07:30.153095 17196 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8277393408, dev_info[0]: total=8506769408 free=8277393408
I0629 14:07:30.153103 17196 caffe.cpp:275] Use GPU with device ID 0
I0629 14:07:30.153383 17196 caffe.cpp:279] GPU device name: GeForce GTX 1080
I0629 14:07:30.154657 17196 net.cpp:77] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0629 14:07:30.154770 17196 net.cpp:108] Using FLOAT as default forward math type
I0629 14:07:30.154775 17196 net.cpp:114] Using FLOAT as default backward math type
I0629 14:07:30.154778 17196 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0629 14:07:30.154781 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.154824 17196 net.cpp:183] Created Layer data (0)
I0629 14:07:30.154829 17196 net.cpp:529] data -> data
I0629 14:07:30.154836 17196 net.cpp:529] data -> label
I0629 14:07:30.154851 17196 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 50
I0629 14:07:30.155143 17196 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0629 14:07:30.161471 17241 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0629 14:07:30.162778 17196 data_layer.cpp:188] ReshapePrefetch 50, 3, 224, 224
I0629 14:07:30.162816 17196 data_layer.cpp:206] Output data size: 50, 3, 224, 224
I0629 14:07:30.162819 17196 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0629 14:07:30.162845 17196 net.cpp:244] Setting up data
I0629 14:07:30.162860 17196 net.cpp:251] TEST Top shape for layer 0 'data' 50 3 224 224 (7526400)
I0629 14:07:30.162868 17196 net.cpp:251] TEST Top shape for layer 0 'data' 50 (50)
I0629 14:07:30.162876 17196 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0629 14:07:30.162883 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.162896 17196 net.cpp:183] Created Layer label_data_1_split (1)
I0629 14:07:30.162902 17196 net.cpp:560] label_data_1_split <- label
I0629 14:07:30.162911 17196 net.cpp:529] label_data_1_split -> label_data_1_split_0
I0629 14:07:30.162919 17196 net.cpp:529] label_data_1_split -> label_data_1_split_1
I0629 14:07:30.162922 17196 net.cpp:529] label_data_1_split -> label_data_1_split_2
I0629 14:07:30.162976 17196 net.cpp:244] Setting up label_data_1_split
I0629 14:07:30.162982 17196 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0629 14:07:30.162987 17196 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0629 14:07:30.162992 17196 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 50 (50)
I0629 14:07:30.162997 17196 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0629 14:07:30.163002 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.163013 17196 net.cpp:183] Created Layer data/bias (2)
I0629 14:07:30.163017 17196 net.cpp:560] data/bias <- data
I0629 14:07:30.163022 17196 net.cpp:529] data/bias -> data/bias
I0629 14:07:30.164759 17196 net.cpp:244] Setting up data/bias
I0629 14:07:30.164772 17196 net.cpp:251] TEST Top shape for layer 2 'data/bias' 50 3 224 224 (7526400)
I0629 14:07:30.164783 17196 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0629 14:07:30.164789 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.164813 17196 net.cpp:183] Created Layer conv1a (3)
I0629 14:07:30.164818 17196 net.cpp:560] conv1a <- data/bias
I0629 14:07:30.164824 17196 net.cpp:529] conv1a -> conv1a
I0629 14:07:30.166154 17242 data_layer.cpp:188] ReshapePrefetch 50, 3, 224, 224
I0629 14:07:30.166165 17242 data_layer.cpp:206] Output data size: 50, 3, 224, 224
I0629 14:07:30.176218 17242 data_layer.cpp:110] [0] Parser threads: 1
I0629 14:07:30.176234 17242 data_layer.cpp:112] [0] Transformer threads: 1
I0629 14:07:30.469151 17196 net.cpp:244] Setting up conv1a
I0629 14:07:30.469172 17196 net.cpp:251] TEST Top shape for layer 3 'conv1a' 50 32 112 112 (20070400)
I0629 14:07:30.469182 17196 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0629 14:07:30.469187 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.469198 17196 net.cpp:183] Created Layer conv1a/bn (4)
I0629 14:07:30.469202 17196 net.cpp:560] conv1a/bn <- conv1a
I0629 14:07:30.469204 17196 net.cpp:512] conv1a/bn -> conv1a (in-place)
I0629 14:07:30.470510 17196 net.cpp:244] Setting up conv1a/bn
I0629 14:07:30.470520 17196 net.cpp:251] TEST Top shape for layer 4 'conv1a/bn' 50 32 112 112 (20070400)
I0629 14:07:30.470527 17196 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0629 14:07:30.470530 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.470535 17196 net.cpp:183] Created Layer conv1a/relu (5)
I0629 14:07:30.470536 17196 net.cpp:560] conv1a/relu <- conv1a
I0629 14:07:30.470540 17196 net.cpp:512] conv1a/relu -> conv1a (in-place)
I0629 14:07:30.470551 17196 net.cpp:244] Setting up conv1a/relu
I0629 14:07:30.470553 17196 net.cpp:251] TEST Top shape for layer 5 'conv1a/relu' 50 32 112 112 (20070400)
I0629 14:07:30.470556 17196 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0629 14:07:30.470558 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.470566 17196 net.cpp:183] Created Layer conv1b (6)
I0629 14:07:30.470569 17196 net.cpp:560] conv1b <- conv1a
I0629 14:07:30.470571 17196 net.cpp:529] conv1b -> conv1b
I0629 14:07:30.479940 17196 net.cpp:244] Setting up conv1b
I0629 14:07:30.479950 17196 net.cpp:251] TEST Top shape for layer 6 'conv1b' 50 32 112 112 (20070400)
I0629 14:07:30.479956 17196 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0629 14:07:30.479959 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.479966 17196 net.cpp:183] Created Layer conv1b/bn (7)
I0629 14:07:30.479969 17196 net.cpp:560] conv1b/bn <- conv1b
I0629 14:07:30.479971 17196 net.cpp:512] conv1b/bn -> conv1b (in-place)
I0629 14:07:30.481204 17196 net.cpp:244] Setting up conv1b/bn
I0629 14:07:30.481214 17196 net.cpp:251] TEST Top shape for layer 7 'conv1b/bn' 50 32 112 112 (20070400)
I0629 14:07:30.481230 17196 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0629 14:07:30.481232 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.481235 17196 net.cpp:183] Created Layer conv1b/relu (8)
I0629 14:07:30.481238 17196 net.cpp:560] conv1b/relu <- conv1b
I0629 14:07:30.481240 17196 net.cpp:512] conv1b/relu -> conv1b (in-place)
I0629 14:07:30.481245 17196 net.cpp:244] Setting up conv1b/relu
I0629 14:07:30.481246 17196 net.cpp:251] TEST Top shape for layer 8 'conv1b/relu' 50 32 112 112 (20070400)
I0629 14:07:30.481248 17196 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0629 14:07:30.481251 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.481256 17196 net.cpp:183] Created Layer pool1 (9)
I0629 14:07:30.481259 17196 net.cpp:560] pool1 <- conv1b
I0629 14:07:30.481261 17196 net.cpp:529] pool1 -> pool1
I0629 14:07:30.481314 17196 net.cpp:244] Setting up pool1
I0629 14:07:30.481322 17196 net.cpp:251] TEST Top shape for layer 9 'pool1' 50 32 56 56 (5017600)
I0629 14:07:30.481325 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0629 14:07:30.481329 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.481338 17196 net.cpp:183] Created Layer res2a_branch2a (10)
I0629 14:07:30.481341 17196 net.cpp:560] res2a_branch2a <- pool1
I0629 14:07:30.481345 17196 net.cpp:529] res2a_branch2a -> res2a_branch2a
I0629 14:07:30.490176 17196 net.cpp:244] Setting up res2a_branch2a
I0629 14:07:30.490187 17196 net.cpp:251] TEST Top shape for layer 10 'res2a_branch2a' 50 64 56 56 (10035200)
I0629 14:07:30.490193 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0629 14:07:30.490196 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.490201 17196 net.cpp:183] Created Layer res2a_branch2a/bn (11)
I0629 14:07:30.490203 17196 net.cpp:560] res2a_branch2a/bn <- res2a_branch2a
I0629 14:07:30.490206 17196 net.cpp:512] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0629 14:07:30.491242 17196 net.cpp:244] Setting up res2a_branch2a/bn
I0629 14:07:30.491251 17196 net.cpp:251] TEST Top shape for layer 11 'res2a_branch2a/bn' 50 64 56 56 (10035200)
I0629 14:07:30.491257 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0629 14:07:30.491259 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.491263 17196 net.cpp:183] Created Layer res2a_branch2a/relu (12)
I0629 14:07:30.491266 17196 net.cpp:560] res2a_branch2a/relu <- res2a_branch2a
I0629 14:07:30.491267 17196 net.cpp:512] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0629 14:07:30.491271 17196 net.cpp:244] Setting up res2a_branch2a/relu
I0629 14:07:30.491273 17196 net.cpp:251] TEST Top shape for layer 12 'res2a_branch2a/relu' 50 64 56 56 (10035200)
I0629 14:07:30.491276 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0629 14:07:30.491277 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.491282 17196 net.cpp:183] Created Layer res2a_branch2b (13)
I0629 14:07:30.491286 17196 net.cpp:560] res2a_branch2b <- res2a_branch2a
I0629 14:07:30.491287 17196 net.cpp:529] res2a_branch2b -> res2a_branch2b
I0629 14:07:30.496171 17196 net.cpp:244] Setting up res2a_branch2b
I0629 14:07:30.496182 17196 net.cpp:251] TEST Top shape for layer 13 'res2a_branch2b' 50 64 56 56 (10035200)
I0629 14:07:30.496187 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0629 14:07:30.496191 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.496196 17196 net.cpp:183] Created Layer res2a_branch2b/bn (14)
I0629 14:07:30.496199 17196 net.cpp:560] res2a_branch2b/bn <- res2a_branch2b
I0629 14:07:30.496202 17196 net.cpp:512] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0629 14:07:30.497258 17196 net.cpp:244] Setting up res2a_branch2b/bn
I0629 14:07:30.497267 17196 net.cpp:251] TEST Top shape for layer 14 'res2a_branch2b/bn' 50 64 56 56 (10035200)
I0629 14:07:30.497274 17196 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0629 14:07:30.497277 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.497280 17196 net.cpp:183] Created Layer res2a_branch2b/relu (15)
I0629 14:07:30.497283 17196 net.cpp:560] res2a_branch2b/relu <- res2a_branch2b
I0629 14:07:30.497285 17196 net.cpp:512] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0629 14:07:30.497289 17196 net.cpp:244] Setting up res2a_branch2b/relu
I0629 14:07:30.497292 17196 net.cpp:251] TEST Top shape for layer 15 'res2a_branch2b/relu' 50 64 56 56 (10035200)
I0629 14:07:30.497294 17196 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0629 14:07:30.497298 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.497303 17196 net.cpp:183] Created Layer pool2 (16)
I0629 14:07:30.497305 17196 net.cpp:560] pool2 <- res2a_branch2b
I0629 14:07:30.497308 17196 net.cpp:529] pool2 -> pool2
I0629 14:07:30.497344 17196 net.cpp:244] Setting up pool2
I0629 14:07:30.497347 17196 net.cpp:251] TEST Top shape for layer 16 'pool2' 50 64 28 28 (2508800)
I0629 14:07:30.497350 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0629 14:07:30.497354 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.497365 17196 net.cpp:183] Created Layer res3a_branch2a (17)
I0629 14:07:30.497370 17196 net.cpp:560] res3a_branch2a <- pool2
I0629 14:07:30.497373 17196 net.cpp:529] res3a_branch2a -> res3a_branch2a
I0629 14:07:30.506306 17196 net.cpp:244] Setting up res3a_branch2a
I0629 14:07:30.506323 17196 net.cpp:251] TEST Top shape for layer 17 'res3a_branch2a' 50 128 28 28 (5017600)
I0629 14:07:30.506330 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0629 14:07:30.506332 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.506340 17196 net.cpp:183] Created Layer res3a_branch2a/bn (18)
I0629 14:07:30.506342 17196 net.cpp:560] res3a_branch2a/bn <- res3a_branch2a
I0629 14:07:30.506345 17196 net.cpp:512] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0629 14:07:30.507282 17196 net.cpp:244] Setting up res3a_branch2a/bn
I0629 14:07:30.507292 17196 net.cpp:251] TEST Top shape for layer 18 'res3a_branch2a/bn' 50 128 28 28 (5017600)
I0629 14:07:30.507299 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0629 14:07:30.507302 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.507305 17196 net.cpp:183] Created Layer res3a_branch2a/relu (19)
I0629 14:07:30.507308 17196 net.cpp:560] res3a_branch2a/relu <- res3a_branch2a
I0629 14:07:30.507310 17196 net.cpp:512] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0629 14:07:30.507315 17196 net.cpp:244] Setting up res3a_branch2a/relu
I0629 14:07:30.507318 17196 net.cpp:251] TEST Top shape for layer 19 'res3a_branch2a/relu' 50 128 28 28 (5017600)
I0629 14:07:30.507319 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0629 14:07:30.507321 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.507329 17196 net.cpp:183] Created Layer res3a_branch2b (20)
I0629 14:07:30.507333 17196 net.cpp:560] res3a_branch2b <- res3a_branch2a
I0629 14:07:30.507335 17196 net.cpp:529] res3a_branch2b -> res3a_branch2b
I0629 14:07:30.511034 17196 net.cpp:244] Setting up res3a_branch2b
I0629 14:07:30.511044 17196 net.cpp:251] TEST Top shape for layer 20 'res3a_branch2b' 50 128 28 28 (5017600)
I0629 14:07:30.511049 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0629 14:07:30.511051 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.511065 17196 net.cpp:183] Created Layer res3a_branch2b/bn (21)
I0629 14:07:30.511068 17196 net.cpp:560] res3a_branch2b/bn <- res3a_branch2b
I0629 14:07:30.511071 17196 net.cpp:512] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0629 14:07:30.511972 17196 net.cpp:244] Setting up res3a_branch2b/bn
I0629 14:07:30.511983 17196 net.cpp:251] TEST Top shape for layer 21 'res3a_branch2b/bn' 50 128 28 28 (5017600)
I0629 14:07:30.511989 17196 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0629 14:07:30.511992 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.511996 17196 net.cpp:183] Created Layer res3a_branch2b/relu (22)
I0629 14:07:30.511997 17196 net.cpp:560] res3a_branch2b/relu <- res3a_branch2b
I0629 14:07:30.511999 17196 net.cpp:512] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0629 14:07:30.512003 17196 net.cpp:244] Setting up res3a_branch2b/relu
I0629 14:07:30.512006 17196 net.cpp:251] TEST Top shape for layer 22 'res3a_branch2b/relu' 50 128 28 28 (5017600)
I0629 14:07:30.512008 17196 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0629 14:07:30.512011 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.512014 17196 net.cpp:183] Created Layer pool3 (23)
I0629 14:07:30.512017 17196 net.cpp:560] pool3 <- res3a_branch2b
I0629 14:07:30.512019 17196 net.cpp:529] pool3 -> pool3
I0629 14:07:30.512053 17196 net.cpp:244] Setting up pool3
I0629 14:07:30.512058 17196 net.cpp:251] TEST Top shape for layer 23 'pool3' 50 128 14 14 (1254400)
I0629 14:07:30.512059 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0629 14:07:30.512061 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.512068 17196 net.cpp:183] Created Layer res4a_branch2a (24)
I0629 14:07:30.512071 17196 net.cpp:560] res4a_branch2a <- pool3
I0629 14:07:30.512074 17196 net.cpp:529] res4a_branch2a -> res4a_branch2a
I0629 14:07:30.524843 17196 net.cpp:244] Setting up res4a_branch2a
I0629 14:07:30.524854 17196 net.cpp:251] TEST Top shape for layer 24 'res4a_branch2a' 50 256 14 14 (2508800)
I0629 14:07:30.524858 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0629 14:07:30.524862 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.524865 17196 net.cpp:183] Created Layer res4a_branch2a/bn (25)
I0629 14:07:30.524868 17196 net.cpp:560] res4a_branch2a/bn <- res4a_branch2a
I0629 14:07:30.524870 17196 net.cpp:512] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0629 14:07:30.525732 17196 net.cpp:244] Setting up res4a_branch2a/bn
I0629 14:07:30.525740 17196 net.cpp:251] TEST Top shape for layer 25 'res4a_branch2a/bn' 50 256 14 14 (2508800)
I0629 14:07:30.525746 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0629 14:07:30.525749 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.525753 17196 net.cpp:183] Created Layer res4a_branch2a/relu (26)
I0629 14:07:30.525754 17196 net.cpp:560] res4a_branch2a/relu <- res4a_branch2a
I0629 14:07:30.525758 17196 net.cpp:512] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0629 14:07:30.525761 17196 net.cpp:244] Setting up res4a_branch2a/relu
I0629 14:07:30.525763 17196 net.cpp:251] TEST Top shape for layer 26 'res4a_branch2a/relu' 50 256 14 14 (2508800)
I0629 14:07:30.525765 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0629 14:07:30.525768 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.525773 17196 net.cpp:183] Created Layer res4a_branch2b (27)
I0629 14:07:30.525775 17196 net.cpp:560] res4a_branch2b <- res4a_branch2a
I0629 14:07:30.525779 17196 net.cpp:529] res4a_branch2b -> res4a_branch2b
I0629 14:07:30.530761 17196 net.cpp:244] Setting up res4a_branch2b
I0629 14:07:30.530774 17196 net.cpp:251] TEST Top shape for layer 27 'res4a_branch2b' 50 256 14 14 (2508800)
I0629 14:07:30.530779 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0629 14:07:30.530782 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.530788 17196 net.cpp:183] Created Layer res4a_branch2b/bn (28)
I0629 14:07:30.530791 17196 net.cpp:560] res4a_branch2b/bn <- res4a_branch2b
I0629 14:07:30.530793 17196 net.cpp:512] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0629 14:07:30.531669 17196 net.cpp:244] Setting up res4a_branch2b/bn
I0629 14:07:30.531678 17196 net.cpp:251] TEST Top shape for layer 28 'res4a_branch2b/bn' 50 256 14 14 (2508800)
I0629 14:07:30.531685 17196 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0629 14:07:30.531688 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.531692 17196 net.cpp:183] Created Layer res4a_branch2b/relu (29)
I0629 14:07:30.531693 17196 net.cpp:560] res4a_branch2b/relu <- res4a_branch2b
I0629 14:07:30.531697 17196 net.cpp:512] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0629 14:07:30.531700 17196 net.cpp:244] Setting up res4a_branch2b/relu
I0629 14:07:30.531702 17196 net.cpp:251] TEST Top shape for layer 29 'res4a_branch2b/relu' 50 256 14 14 (2508800)
I0629 14:07:30.531704 17196 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0629 14:07:30.531708 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.531710 17196 net.cpp:183] Created Layer pool4 (30)
I0629 14:07:30.531713 17196 net.cpp:560] pool4 <- res4a_branch2b
I0629 14:07:30.531716 17196 net.cpp:529] pool4 -> pool4
I0629 14:07:30.531754 17196 net.cpp:244] Setting up pool4
I0629 14:07:30.531760 17196 net.cpp:251] TEST Top shape for layer 30 'pool4' 50 256 7 7 (627200)
I0629 14:07:30.531764 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0629 14:07:30.531769 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.531777 17196 net.cpp:183] Created Layer res5a_branch2a (31)
I0629 14:07:30.531781 17196 net.cpp:560] res5a_branch2a <- pool4
I0629 14:07:30.531785 17196 net.cpp:529] res5a_branch2a -> res5a_branch2a
I0629 14:07:30.563602 17196 net.cpp:244] Setting up res5a_branch2a
I0629 14:07:30.563624 17196 net.cpp:251] TEST Top shape for layer 31 'res5a_branch2a' 50 512 7 7 (1254400)
I0629 14:07:30.563632 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0629 14:07:30.563637 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.563645 17196 net.cpp:183] Created Layer res5a_branch2a/bn (32)
I0629 14:07:30.563649 17196 net.cpp:560] res5a_branch2a/bn <- res5a_branch2a
I0629 14:07:30.563652 17196 net.cpp:512] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0629 14:07:30.564617 17196 net.cpp:244] Setting up res5a_branch2a/bn
I0629 14:07:30.564626 17196 net.cpp:251] TEST Top shape for layer 32 'res5a_branch2a/bn' 50 512 7 7 (1254400)
I0629 14:07:30.564633 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0629 14:07:30.564636 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.564640 17196 net.cpp:183] Created Layer res5a_branch2a/relu (33)
I0629 14:07:30.564641 17196 net.cpp:560] res5a_branch2a/relu <- res5a_branch2a
I0629 14:07:30.564643 17196 net.cpp:512] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0629 14:07:30.564648 17196 net.cpp:244] Setting up res5a_branch2a/relu
I0629 14:07:30.564651 17196 net.cpp:251] TEST Top shape for layer 33 'res5a_branch2a/relu' 50 512 7 7 (1254400)
I0629 14:07:30.564653 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0629 14:07:30.564656 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.564672 17196 net.cpp:183] Created Layer res5a_branch2b (34)
I0629 14:07:30.564676 17196 net.cpp:560] res5a_branch2b <- res5a_branch2a
I0629 14:07:30.564677 17196 net.cpp:529] res5a_branch2b -> res5a_branch2b
I0629 14:07:30.580282 17196 net.cpp:244] Setting up res5a_branch2b
I0629 14:07:30.580296 17196 net.cpp:251] TEST Top shape for layer 34 'res5a_branch2b' 50 512 7 7 (1254400)
I0629 14:07:30.580304 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0629 14:07:30.580307 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.580312 17196 net.cpp:183] Created Layer res5a_branch2b/bn (35)
I0629 14:07:30.580315 17196 net.cpp:560] res5a_branch2b/bn <- res5a_branch2b
I0629 14:07:30.580317 17196 net.cpp:512] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0629 14:07:30.581159 17196 net.cpp:244] Setting up res5a_branch2b/bn
I0629 14:07:30.581168 17196 net.cpp:251] TEST Top shape for layer 35 'res5a_branch2b/bn' 50 512 7 7 (1254400)
I0629 14:07:30.581174 17196 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0629 14:07:30.581177 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.581181 17196 net.cpp:183] Created Layer res5a_branch2b/relu (36)
I0629 14:07:30.581182 17196 net.cpp:560] res5a_branch2b/relu <- res5a_branch2b
I0629 14:07:30.581184 17196 net.cpp:512] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0629 14:07:30.581188 17196 net.cpp:244] Setting up res5a_branch2b/relu
I0629 14:07:30.581192 17196 net.cpp:251] TEST Top shape for layer 36 'res5a_branch2b/relu' 50 512 7 7 (1254400)
I0629 14:07:30.581193 17196 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0629 14:07:30.581195 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.581199 17196 net.cpp:183] Created Layer pool5 (37)
I0629 14:07:30.581202 17196 net.cpp:560] pool5 <- res5a_branch2b
I0629 14:07:30.581205 17196 net.cpp:529] pool5 -> pool5
I0629 14:07:30.581223 17196 net.cpp:244] Setting up pool5
I0629 14:07:30.581226 17196 net.cpp:251] TEST Top shape for layer 37 'pool5' 50 512 1 1 (25600)
I0629 14:07:30.581228 17196 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0629 14:07:30.581230 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.581236 17196 net.cpp:183] Created Layer fc1000 (38)
I0629 14:07:30.581238 17196 net.cpp:560] fc1000 <- pool5
I0629 14:07:30.581241 17196 net.cpp:529] fc1000 -> fc1000
I0629 14:07:30.592133 17196 net.cpp:244] Setting up fc1000
I0629 14:07:30.592155 17196 net.cpp:251] TEST Top shape for layer 38 'fc1000' 50 1000 (50000)
I0629 14:07:30.592162 17196 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0629 14:07:30.592165 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.592170 17196 net.cpp:183] Created Layer fc1000_fc1000_0_split (39)
I0629 14:07:30.592173 17196 net.cpp:560] fc1000_fc1000_0_split <- fc1000
I0629 14:07:30.592176 17196 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0629 14:07:30.592180 17196 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0629 14:07:30.592182 17196 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0629 14:07:30.592213 17196 net.cpp:244] Setting up fc1000_fc1000_0_split
I0629 14:07:30.592217 17196 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0629 14:07:30.592221 17196 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0629 14:07:30.592222 17196 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 50 1000 (50000)
I0629 14:07:30.592224 17196 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0629 14:07:30.592226 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.592254 17196 net.cpp:183] Created Layer loss (40)
I0629 14:07:30.592258 17196 net.cpp:560] loss <- fc1000_fc1000_0_split_0
I0629 14:07:30.592262 17196 net.cpp:560] loss <- label_data_1_split_0
I0629 14:07:30.592267 17196 net.cpp:529] loss -> loss
I0629 14:07:30.592433 17196 net.cpp:244] Setting up loss
I0629 14:07:30.592442 17196 net.cpp:251] TEST Top shape for layer 40 'loss' (1)
I0629 14:07:30.592445 17196 net.cpp:255]     with loss weight 1
I0629 14:07:30.592460 17196 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0629 14:07:30.592464 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.592474 17196 net.cpp:183] Created Layer accuracy/top1 (41)
I0629 14:07:30.592479 17196 net.cpp:560] accuracy/top1 <- fc1000_fc1000_0_split_1
I0629 14:07:30.592483 17196 net.cpp:560] accuracy/top1 <- label_data_1_split_1
I0629 14:07:30.592488 17196 net.cpp:529] accuracy/top1 -> accuracy/top1
I0629 14:07:30.592494 17196 net.cpp:244] Setting up accuracy/top1
I0629 14:07:30.592497 17196 net.cpp:251] TEST Top shape for layer 41 'accuracy/top1' (1)
I0629 14:07:30.592500 17196 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0629 14:07:30.592504 17196 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0629 14:07:30.592511 17196 net.cpp:183] Created Layer accuracy/top5 (42)
I0629 14:07:30.592515 17196 net.cpp:560] accuracy/top5 <- fc1000_fc1000_0_split_2
I0629 14:07:30.592519 17196 net.cpp:560] accuracy/top5 <- label_data_1_split_2
I0629 14:07:30.592523 17196 net.cpp:529] accuracy/top5 -> accuracy/top5
I0629 14:07:30.592528 17196 net.cpp:244] Setting up accuracy/top5
I0629 14:07:30.592537 17196 net.cpp:251] TEST Top shape for layer 42 'accuracy/top5' (1)
I0629 14:07:30.592541 17196 net.cpp:324] accuracy/top5 does not need backward computation.
I0629 14:07:30.592546 17196 net.cpp:324] accuracy/top1 does not need backward computation.
I0629 14:07:30.592550 17196 net.cpp:322] loss needs backward computation.
I0629 14:07:30.592555 17196 net.cpp:322] fc1000_fc1000_0_split needs backward computation.
I0629 14:07:30.592558 17196 net.cpp:322] fc1000 needs backward computation.
I0629 14:07:30.592562 17196 net.cpp:322] pool5 needs backward computation.
I0629 14:07:30.592566 17196 net.cpp:322] res5a_branch2b/relu needs backward computation.
I0629 14:07:30.592571 17196 net.cpp:322] res5a_branch2b/bn needs backward computation.
I0629 14:07:30.592574 17196 net.cpp:322] res5a_branch2b needs backward computation.
I0629 14:07:30.592578 17196 net.cpp:322] res5a_branch2a/relu needs backward computation.
I0629 14:07:30.592582 17196 net.cpp:322] res5a_branch2a/bn needs backward computation.
I0629 14:07:30.592586 17196 net.cpp:322] res5a_branch2a needs backward computation.
I0629 14:07:30.592591 17196 net.cpp:322] pool4 needs backward computation.
I0629 14:07:30.592594 17196 net.cpp:322] res4a_branch2b/relu needs backward computation.
I0629 14:07:30.592598 17196 net.cpp:322] res4a_branch2b/bn needs backward computation.
I0629 14:07:30.592602 17196 net.cpp:322] res4a_branch2b needs backward computation.
I0629 14:07:30.592605 17196 net.cpp:322] res4a_branch2a/relu needs backward computation.
I0629 14:07:30.592609 17196 net.cpp:322] res4a_branch2a/bn needs backward computation.
I0629 14:07:30.592613 17196 net.cpp:322] res4a_branch2a needs backward computation.
I0629 14:07:30.592618 17196 net.cpp:322] pool3 needs backward computation.
I0629 14:07:30.592622 17196 net.cpp:322] res3a_branch2b/relu needs backward computation.
I0629 14:07:30.592627 17196 net.cpp:322] res3a_branch2b/bn needs backward computation.
I0629 14:07:30.592630 17196 net.cpp:322] res3a_branch2b needs backward computation.
I0629 14:07:30.592634 17196 net.cpp:322] res3a_branch2a/relu needs backward computation.
I0629 14:07:30.592638 17196 net.cpp:322] res3a_branch2a/bn needs backward computation.
I0629 14:07:30.592643 17196 net.cpp:322] res3a_branch2a needs backward computation.
I0629 14:07:30.592646 17196 net.cpp:322] pool2 needs backward computation.
I0629 14:07:30.592656 17196 net.cpp:322] res2a_branch2b/relu needs backward computation.
I0629 14:07:30.592660 17196 net.cpp:322] res2a_branch2b/bn needs backward computation.
I0629 14:07:30.592664 17196 net.cpp:322] res2a_branch2b needs backward computation.
I0629 14:07:30.592669 17196 net.cpp:322] res2a_branch2a/relu needs backward computation.
I0629 14:07:30.592672 17196 net.cpp:322] res2a_branch2a/bn needs backward computation.
I0629 14:07:30.592676 17196 net.cpp:322] res2a_branch2a needs backward computation.
I0629 14:07:30.592679 17196 net.cpp:322] pool1 needs backward computation.
I0629 14:07:30.592684 17196 net.cpp:322] conv1b/relu needs backward computation.
I0629 14:07:30.592687 17196 net.cpp:322] conv1b/bn needs backward computation.
I0629 14:07:30.592691 17196 net.cpp:322] conv1b needs backward computation.
I0629 14:07:30.592695 17196 net.cpp:322] conv1a/relu needs backward computation.
I0629 14:07:30.592699 17196 net.cpp:322] conv1a/bn needs backward computation.
I0629 14:07:30.592702 17196 net.cpp:322] conv1a needs backward computation.
I0629 14:07:30.592706 17196 net.cpp:324] data/bias does not need backward computation.
I0629 14:07:30.592711 17196 net.cpp:324] label_data_1_split does not need backward computation.
I0629 14:07:30.592716 17196 net.cpp:324] data does not need backward computation.
I0629 14:07:30.592720 17196 net.cpp:366] This network produces output accuracy/top1
I0629 14:07:30.592725 17196 net.cpp:366] This network produces output accuracy/top5
I0629 14:07:30.592728 17196 net.cpp:366] This network produces output loss
I0629 14:07:30.592774 17196 net.cpp:388] Top memory (TEST) required for data: 933273600 diff: 622182408
I0629 14:07:30.592778 17196 net.cpp:391] Bottom memory (TEST) required for data: 933273600 diff: 933273600
I0629 14:07:30.592783 17196 net.cpp:394] Shared (in-place) memory (TEST) by data: 622182400 diff: 622182400
I0629 14:07:30.592787 17196 net.cpp:397] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0629 14:07:30.592790 17196 net.cpp:400] Parameters shared memory (TEST) by data: 0 diff: 0
I0629 14:07:30.592794 17196 net.cpp:406] Network initialization done.
I0629 14:07:30.687014 17196 net.cpp:1087] Copying source layer data Type:Data #blobs=0
I0629 14:07:30.687069 17196 net.cpp:1087] Copying source layer data/bias Type:Bias #blobs=1
I0629 14:07:30.687152 17196 net.cpp:1087] Copying source layer conv1a Type:Convolution #blobs=2
I0629 14:07:30.687223 17196 net.cpp:1087] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0629 14:07:30.688199 17196 net.cpp:1087] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0629 14:07:30.688228 17196 net.cpp:1087] Copying source layer conv1b Type:Convolution #blobs=2
I0629 14:07:30.688266 17196 net.cpp:1087] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0629 14:07:30.689051 17196 net.cpp:1087] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0629 14:07:30.689079 17196 net.cpp:1087] Copying source layer pool1 Type:Pooling #blobs=0
I0629 14:07:30.689088 17196 net.cpp:1087] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0629 14:07:30.689136 17196 net.cpp:1087] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0629 14:07:30.689977 17196 net.cpp:1087] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0629 14:07:30.690006 17196 net.cpp:1087] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0629 14:07:30.690048 17196 net.cpp:1087] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0629 14:07:30.690824 17196 net.cpp:1087] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0629 14:07:30.690850 17196 net.cpp:1087] Copying source layer pool2 Type:Pooling #blobs=0
I0629 14:07:30.690861 17196 net.cpp:1087] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0629 14:07:30.690973 17196 net.cpp:1087] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0629 14:07:30.691730 17196 net.cpp:1087] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0629 14:07:30.691756 17196 net.cpp:1087] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0629 14:07:30.691872 17196 net.cpp:1087] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0629 14:07:30.692598 17196 net.cpp:1087] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0629 14:07:30.692623 17196 net.cpp:1087] Copying source layer pool3 Type:Pooling #blobs=0
I0629 14:07:30.692634 17196 net.cpp:1087] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0629 14:07:30.692934 17196 net.cpp:1087] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0629 14:07:30.693696 17196 net.cpp:1087] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0629 14:07:30.693724 17196 net.cpp:1087] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0629 14:07:30.693904 17196 net.cpp:1087] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0629 14:07:30.694625 17196 net.cpp:1087] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0629 14:07:30.694651 17196 net.cpp:1087] Copying source layer pool4 Type:Pooling #blobs=0
I0629 14:07:30.694663 17196 net.cpp:1087] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0629 14:07:30.695693 17196 net.cpp:1087] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0629 14:07:30.696430 17196 net.cpp:1087] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0629 14:07:30.696455 17196 net.cpp:1087] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0629 14:07:30.696995 17196 net.cpp:1087] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0629 14:07:30.697731 17196 net.cpp:1087] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0629 14:07:30.697758 17196 net.cpp:1087] Copying source layer pool5 Type:Pooling #blobs=0
I0629 14:07:30.697769 17196 net.cpp:1087] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0629 14:07:30.698197 17196 net.cpp:1087] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0629 14:07:30.698387 17196 caffe.cpp:290] Running for 1000 iterations.
I0629 14:07:30.788043 17196 caffe.cpp:313] Batch 0, accuracy/top1 = 0.58
I0629 14:07:30.788064 17196 caffe.cpp:313] Batch 0, accuracy/top5 = 0.8
I0629 14:07:30.788067 17196 caffe.cpp:313] Batch 0, loss = 1.93184
I0629 14:07:30.853109 17196 caffe.cpp:313] Batch 1, accuracy/top1 = 0.64
I0629 14:07:30.853128 17196 caffe.cpp:313] Batch 1, accuracy/top5 = 0.76
I0629 14:07:30.853132 17196 caffe.cpp:313] Batch 1, loss = 1.79793
I0629 14:07:30.878237 17196 caffe.cpp:313] Batch 2, accuracy/top1 = 0.56
I0629 14:07:30.878252 17196 caffe.cpp:313] Batch 2, accuracy/top5 = 0.76
I0629 14:07:30.878255 17196 caffe.cpp:313] Batch 2, loss = 2.2322
I0629 14:07:30.878262 17196 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 14:07:30.932109 17196 caffe.cpp:313] Batch 3, accuracy/top1 = 0.62
I0629 14:07:30.932133 17196 caffe.cpp:313] Batch 3, accuracy/top5 = 0.82
I0629 14:07:30.932137 17196 caffe.cpp:313] Batch 3, loss = 1.56155
I0629 14:07:30.984746 17196 caffe.cpp:313] Batch 4, accuracy/top1 = 0.6
I0629 14:07:30.984771 17196 caffe.cpp:313] Batch 4, accuracy/top5 = 0.82
I0629 14:07:30.984776 17196 caffe.cpp:313] Batch 4, loss = 1.75786
I0629 14:07:31.038317 17196 caffe.cpp:313] Batch 5, accuracy/top1 = 0.7
I0629 14:07:31.038339 17196 caffe.cpp:313] Batch 5, accuracy/top5 = 0.86
I0629 14:07:31.038343 17196 caffe.cpp:313] Batch 5, loss = 1.35605
I0629 14:07:31.092277 17196 caffe.cpp:313] Batch 6, accuracy/top1 = 0.58
I0629 14:07:31.092303 17196 caffe.cpp:313] Batch 6, accuracy/top5 = 0.82
I0629 14:07:31.092306 17196 caffe.cpp:313] Batch 6, loss = 1.74524
I0629 14:07:31.146670 17196 caffe.cpp:313] Batch 7, accuracy/top1 = 0.62
I0629 14:07:31.146695 17196 caffe.cpp:313] Batch 7, accuracy/top5 = 0.84
I0629 14:07:31.146699 17196 caffe.cpp:313] Batch 7, loss = 1.83467
I0629 14:07:31.200639 17196 caffe.cpp:313] Batch 8, accuracy/top1 = 0.6
I0629 14:07:31.200664 17196 caffe.cpp:313] Batch 8, accuracy/top5 = 0.92
I0629 14:07:31.200669 17196 caffe.cpp:313] Batch 8, loss = 1.34597
I0629 14:07:31.253841 17196 caffe.cpp:313] Batch 9, accuracy/top1 = 0.5
I0629 14:07:31.253885 17196 caffe.cpp:313] Batch 9, accuracy/top5 = 0.8
I0629 14:07:31.253888 17196 caffe.cpp:313] Batch 9, loss = 1.93124
I0629 14:07:31.307734 17196 caffe.cpp:313] Batch 10, accuracy/top1 = 0.54
I0629 14:07:31.307760 17196 caffe.cpp:313] Batch 10, accuracy/top5 = 0.76
I0629 14:07:31.307763 17196 caffe.cpp:313] Batch 10, loss = 1.63866
I0629 14:07:31.362906 17196 caffe.cpp:313] Batch 11, accuracy/top1 = 0.62
I0629 14:07:31.362931 17196 caffe.cpp:313] Batch 11, accuracy/top5 = 0.9
I0629 14:07:31.362936 17196 caffe.cpp:313] Batch 11, loss = 1.44366
I0629 14:07:31.415881 17196 caffe.cpp:313] Batch 12, accuracy/top1 = 0.54
I0629 14:07:31.415905 17196 caffe.cpp:313] Batch 12, accuracy/top5 = 0.86
I0629 14:07:31.415910 17196 caffe.cpp:313] Batch 12, loss = 1.61836
I0629 14:07:31.470007 17196 caffe.cpp:313] Batch 13, accuracy/top1 = 0.6
I0629 14:07:31.470032 17196 caffe.cpp:313] Batch 13, accuracy/top5 = 0.84
I0629 14:07:31.470036 17196 caffe.cpp:313] Batch 13, loss = 1.62091
I0629 14:07:31.523511 17196 caffe.cpp:313] Batch 14, accuracy/top1 = 0.48
I0629 14:07:31.523537 17196 caffe.cpp:313] Batch 14, accuracy/top5 = 0.74
I0629 14:07:31.523541 17196 caffe.cpp:313] Batch 14, loss = 2.19945
I0629 14:07:31.577917 17196 caffe.cpp:313] Batch 15, accuracy/top1 = 0.52
I0629 14:07:31.577944 17196 caffe.cpp:313] Batch 15, accuracy/top5 = 0.64
I0629 14:07:31.577949 17196 caffe.cpp:313] Batch 15, loss = 2.7234
I0629 14:07:31.631978 17196 caffe.cpp:313] Batch 16, accuracy/top1 = 0.46
I0629 14:07:31.632001 17196 caffe.cpp:313] Batch 16, accuracy/top5 = 0.74
I0629 14:07:31.632004 17196 caffe.cpp:313] Batch 16, loss = 2.28204
I0629 14:07:31.687427 17196 caffe.cpp:313] Batch 17, accuracy/top1 = 0.48
I0629 14:07:31.687450 17196 caffe.cpp:313] Batch 17, accuracy/top5 = 0.8
I0629 14:07:31.687453 17196 caffe.cpp:313] Batch 17, loss = 2.04561
I0629 14:07:31.738226 17196 caffe.cpp:313] Batch 18, accuracy/top1 = 0.56
I0629 14:07:31.738250 17196 caffe.cpp:313] Batch 18, accuracy/top5 = 0.84
I0629 14:07:31.738252 17196 caffe.cpp:313] Batch 18, loss = 2.09692
I0629 14:07:31.788280 17196 caffe.cpp:313] Batch 19, accuracy/top1 = 0.62
I0629 14:07:31.788303 17196 caffe.cpp:313] Batch 19, accuracy/top5 = 0.82
I0629 14:07:31.788306 17196 caffe.cpp:313] Batch 19, loss = 1.79403
I0629 14:07:31.837082 17196 caffe.cpp:313] Batch 20, accuracy/top1 = 0.46
I0629 14:07:31.837105 17196 caffe.cpp:313] Batch 20, accuracy/top5 = 0.78
I0629 14:07:31.837108 17196 caffe.cpp:313] Batch 20, loss = 2.19956
I0629 14:07:31.885949 17196 caffe.cpp:313] Batch 21, accuracy/top1 = 0.62
I0629 14:07:31.885972 17196 caffe.cpp:313] Batch 21, accuracy/top5 = 0.76
I0629 14:07:31.885975 17196 caffe.cpp:313] Batch 21, loss = 1.95627
I0629 14:07:31.934828 17196 caffe.cpp:313] Batch 22, accuracy/top1 = 0.42
I0629 14:07:31.934847 17196 caffe.cpp:313] Batch 22, accuracy/top5 = 0.84
I0629 14:07:31.934850 17196 caffe.cpp:313] Batch 22, loss = 2.3995
I0629 14:07:31.985247 17196 caffe.cpp:313] Batch 23, accuracy/top1 = 0.6
I0629 14:07:31.985271 17196 caffe.cpp:313] Batch 23, accuracy/top5 = 0.84
I0629 14:07:31.985275 17196 caffe.cpp:313] Batch 23, loss = 1.63215
I0629 14:07:32.036562 17196 caffe.cpp:313] Batch 24, accuracy/top1 = 0.68
I0629 14:07:32.036582 17196 caffe.cpp:313] Batch 24, accuracy/top5 = 0.84
I0629 14:07:32.036586 17196 caffe.cpp:313] Batch 24, loss = 1.37299
I0629 14:07:32.086902 17196 caffe.cpp:313] Batch 25, accuracy/top1 = 0.62
I0629 14:07:32.086922 17196 caffe.cpp:313] Batch 25, accuracy/top5 = 0.76
I0629 14:07:32.086925 17196 caffe.cpp:313] Batch 25, loss = 1.71599
I0629 14:07:32.138630 17196 caffe.cpp:313] Batch 26, accuracy/top1 = 0.58
I0629 14:07:32.138651 17196 caffe.cpp:313] Batch 26, accuracy/top5 = 0.8
I0629 14:07:32.138654 17196 caffe.cpp:313] Batch 26, loss = 1.87266
I0629 14:07:32.186707 17196 caffe.cpp:313] Batch 27, accuracy/top1 = 0.4
I0629 14:07:32.186728 17196 caffe.cpp:313] Batch 27, accuracy/top5 = 0.72
I0629 14:07:32.186730 17196 caffe.cpp:313] Batch 27, loss = 2.98865
I0629 14:07:32.235741 17196 caffe.cpp:313] Batch 28, accuracy/top1 = 0.56
I0629 14:07:32.235782 17196 caffe.cpp:313] Batch 28, accuracy/top5 = 0.78
I0629 14:07:32.235785 17196 caffe.cpp:313] Batch 28, loss = 2.09348
I0629 14:07:32.284988 17196 caffe.cpp:313] Batch 29, accuracy/top1 = 0.54
I0629 14:07:32.285012 17196 caffe.cpp:313] Batch 29, accuracy/top5 = 0.8
I0629 14:07:32.285014 17196 caffe.cpp:313] Batch 29, loss = 1.8889
I0629 14:07:32.334980 17196 caffe.cpp:313] Batch 30, accuracy/top1 = 0.62
I0629 14:07:32.335003 17196 caffe.cpp:313] Batch 30, accuracy/top5 = 0.8
I0629 14:07:32.335006 17196 caffe.cpp:313] Batch 30, loss = 1.99491
I0629 14:07:32.384349 17196 caffe.cpp:313] Batch 31, accuracy/top1 = 0.58
I0629 14:07:32.384373 17196 caffe.cpp:313] Batch 31, accuracy/top5 = 0.78
I0629 14:07:32.384377 17196 caffe.cpp:313] Batch 31, loss = 1.92782
I0629 14:07:32.433519 17196 caffe.cpp:313] Batch 32, accuracy/top1 = 0.58
I0629 14:07:32.433543 17196 caffe.cpp:313] Batch 32, accuracy/top5 = 0.76
I0629 14:07:32.433547 17196 caffe.cpp:313] Batch 32, loss = 1.94803
I0629 14:07:32.483381 17196 caffe.cpp:313] Batch 33, accuracy/top1 = 0.46
I0629 14:07:32.483404 17196 caffe.cpp:313] Batch 33, accuracy/top5 = 0.82
I0629 14:07:32.483407 17196 caffe.cpp:313] Batch 33, loss = 1.96672
I0629 14:07:32.531646 17196 caffe.cpp:313] Batch 34, accuracy/top1 = 0.56
I0629 14:07:32.531671 17196 caffe.cpp:313] Batch 34, accuracy/top5 = 0.78
I0629 14:07:32.531673 17196 caffe.cpp:313] Batch 34, loss = 1.96366
I0629 14:07:32.581008 17196 caffe.cpp:313] Batch 35, accuracy/top1 = 0.58
I0629 14:07:32.581033 17196 caffe.cpp:313] Batch 35, accuracy/top5 = 0.8
I0629 14:07:32.581037 17196 caffe.cpp:313] Batch 35, loss = 1.57523
I0629 14:07:32.629163 17196 caffe.cpp:313] Batch 36, accuracy/top1 = 0.52
I0629 14:07:32.629187 17196 caffe.cpp:313] Batch 36, accuracy/top5 = 0.74
I0629 14:07:32.629190 17196 caffe.cpp:313] Batch 36, loss = 2.13629
I0629 14:07:32.680420 17196 caffe.cpp:313] Batch 37, accuracy/top1 = 0.66
I0629 14:07:32.680444 17196 caffe.cpp:313] Batch 37, accuracy/top5 = 0.88
I0629 14:07:32.680446 17196 caffe.cpp:313] Batch 37, loss = 1.49055
I0629 14:07:32.730962 17196 caffe.cpp:313] Batch 38, accuracy/top1 = 0.46
I0629 14:07:32.730985 17196 caffe.cpp:313] Batch 38, accuracy/top5 = 0.66
I0629 14:07:32.730988 17196 caffe.cpp:313] Batch 38, loss = 2.69406
I0629 14:07:32.780717 17196 caffe.cpp:313] Batch 39, accuracy/top1 = 0.66
I0629 14:07:32.780741 17196 caffe.cpp:313] Batch 39, accuracy/top5 = 0.82
I0629 14:07:32.780745 17196 caffe.cpp:313] Batch 39, loss = 1.69426
I0629 14:07:32.830633 17196 caffe.cpp:313] Batch 40, accuracy/top1 = 0.48
I0629 14:07:32.830657 17196 caffe.cpp:313] Batch 40, accuracy/top5 = 0.68
I0629 14:07:32.830659 17196 caffe.cpp:313] Batch 40, loss = 2.40422
I0629 14:07:32.880568 17196 caffe.cpp:313] Batch 41, accuracy/top1 = 0.52
I0629 14:07:32.880591 17196 caffe.cpp:313] Batch 41, accuracy/top5 = 0.84
I0629 14:07:32.880594 17196 caffe.cpp:313] Batch 41, loss = 1.7319
I0629 14:07:32.930953 17196 caffe.cpp:313] Batch 42, accuracy/top1 = 0.58
I0629 14:07:32.930974 17196 caffe.cpp:313] Batch 42, accuracy/top5 = 0.82
I0629 14:07:32.930977 17196 caffe.cpp:313] Batch 42, loss = 1.9319
I0629 14:07:32.981381 17196 caffe.cpp:313] Batch 43, accuracy/top1 = 0.66
I0629 14:07:32.981405 17196 caffe.cpp:313] Batch 43, accuracy/top5 = 0.84
I0629 14:07:32.981408 17196 caffe.cpp:313] Batch 43, loss = 1.41893
I0629 14:07:33.032088 17196 caffe.cpp:313] Batch 44, accuracy/top1 = 0.54
I0629 14:07:33.032107 17196 caffe.cpp:313] Batch 44, accuracy/top5 = 0.72
I0629 14:07:33.032110 17196 caffe.cpp:313] Batch 44, loss = 1.87995
I0629 14:07:33.082588 17196 caffe.cpp:313] Batch 45, accuracy/top1 = 0.6
I0629 14:07:33.082613 17196 caffe.cpp:313] Batch 45, accuracy/top5 = 0.82
I0629 14:07:33.082617 17196 caffe.cpp:313] Batch 45, loss = 2.00056
I0629 14:07:33.132222 17196 caffe.cpp:313] Batch 46, accuracy/top1 = 0.7
I0629 14:07:33.132241 17196 caffe.cpp:313] Batch 46, accuracy/top5 = 0.82
I0629 14:07:33.132243 17196 caffe.cpp:313] Batch 46, loss = 1.52091
I0629 14:07:33.182030 17196 caffe.cpp:313] Batch 47, accuracy/top1 = 0.48
I0629 14:07:33.182070 17196 caffe.cpp:313] Batch 47, accuracy/top5 = 0.82
I0629 14:07:33.182072 17196 caffe.cpp:313] Batch 47, loss = 1.95876
I0629 14:07:33.232125 17196 caffe.cpp:313] Batch 48, accuracy/top1 = 0.52
I0629 14:07:33.232148 17196 caffe.cpp:313] Batch 48, accuracy/top5 = 0.8
I0629 14:07:33.232151 17196 caffe.cpp:313] Batch 48, loss = 1.95786
I0629 14:07:33.281786 17196 caffe.cpp:313] Batch 49, accuracy/top1 = 0.56
I0629 14:07:33.281811 17196 caffe.cpp:313] Batch 49, accuracy/top5 = 0.8
I0629 14:07:33.281814 17196 caffe.cpp:313] Batch 49, loss = 1.72247
I0629 14:07:33.332358 17196 caffe.cpp:313] Batch 50, accuracy/top1 = 0.68
I0629 14:07:33.332382 17196 caffe.cpp:313] Batch 50, accuracy/top5 = 0.8
I0629 14:07:33.332386 17196 caffe.cpp:313] Batch 50, loss = 1.77554
I0629 14:07:33.382817 17196 caffe.cpp:313] Batch 51, accuracy/top1 = 0.52
I0629 14:07:33.382841 17196 caffe.cpp:313] Batch 51, accuracy/top5 = 0.84
I0629 14:07:33.382844 17196 caffe.cpp:313] Batch 51, loss = 1.77568
I0629 14:07:33.432153 17196 caffe.cpp:313] Batch 52, accuracy/top1 = 0.58
I0629 14:07:33.432178 17196 caffe.cpp:313] Batch 52, accuracy/top5 = 0.74
I0629 14:07:33.432180 17196 caffe.cpp:313] Batch 52, loss = 1.99396
I0629 14:07:33.480989 17196 caffe.cpp:313] Batch 53, accuracy/top1 = 0.5
I0629 14:07:33.481011 17196 caffe.cpp:313] Batch 53, accuracy/top5 = 0.68
I0629 14:07:33.481015 17196 caffe.cpp:313] Batch 53, loss = 2.49106
I0629 14:07:33.529780 17196 caffe.cpp:313] Batch 54, accuracy/top1 = 0.64
I0629 14:07:33.529805 17196 caffe.cpp:313] Batch 54, accuracy/top5 = 0.92
I0629 14:07:33.529808 17196 caffe.cpp:313] Batch 54, loss = 1.34965
I0629 14:07:33.580080 17196 caffe.cpp:313] Batch 55, accuracy/top1 = 0.6
I0629 14:07:33.580103 17196 caffe.cpp:313] Batch 55, accuracy/top5 = 0.88
I0629 14:07:33.580106 17196 caffe.cpp:313] Batch 55, loss = 1.50749
I0629 14:07:33.629345 17196 caffe.cpp:313] Batch 56, accuracy/top1 = 0.58
I0629 14:07:33.629369 17196 caffe.cpp:313] Batch 56, accuracy/top5 = 0.82
I0629 14:07:33.629371 17196 caffe.cpp:313] Batch 56, loss = 1.60065
I0629 14:07:33.679039 17196 caffe.cpp:313] Batch 57, accuracy/top1 = 0.58
I0629 14:07:33.679062 17196 caffe.cpp:313] Batch 57, accuracy/top5 = 0.84
I0629 14:07:33.679065 17196 caffe.cpp:313] Batch 57, loss = 1.90239
I0629 14:07:33.730262 17196 caffe.cpp:313] Batch 58, accuracy/top1 = 0.68
I0629 14:07:33.730285 17196 caffe.cpp:313] Batch 58, accuracy/top5 = 0.82
I0629 14:07:33.730288 17196 caffe.cpp:313] Batch 58, loss = 1.62988
I0629 14:07:33.780622 17196 caffe.cpp:313] Batch 59, accuracy/top1 = 0.62
I0629 14:07:33.780645 17196 caffe.cpp:313] Batch 59, accuracy/top5 = 0.84
I0629 14:07:33.780648 17196 caffe.cpp:313] Batch 59, loss = 1.46072
I0629 14:07:33.831457 17196 caffe.cpp:313] Batch 60, accuracy/top1 = 0.6
I0629 14:07:33.831481 17196 caffe.cpp:313] Batch 60, accuracy/top5 = 0.86
I0629 14:07:33.831485 17196 caffe.cpp:313] Batch 60, loss = 1.50452
I0629 14:07:33.880914 17196 caffe.cpp:313] Batch 61, accuracy/top1 = 0.58
I0629 14:07:33.880939 17196 caffe.cpp:313] Batch 61, accuracy/top5 = 0.82
I0629 14:07:33.880942 17196 caffe.cpp:313] Batch 61, loss = 1.97719
I0629 14:07:33.932062 17196 caffe.cpp:313] Batch 62, accuracy/top1 = 0.56
I0629 14:07:33.932085 17196 caffe.cpp:313] Batch 62, accuracy/top5 = 0.74
I0629 14:07:33.932087 17196 caffe.cpp:313] Batch 62, loss = 1.97086
I0629 14:07:33.981371 17196 caffe.cpp:313] Batch 63, accuracy/top1 = 0.58
I0629 14:07:33.981395 17196 caffe.cpp:313] Batch 63, accuracy/top5 = 0.82
I0629 14:07:33.981397 17196 caffe.cpp:313] Batch 63, loss = 1.80138
I0629 14:07:34.031755 17196 caffe.cpp:313] Batch 64, accuracy/top1 = 0.5
I0629 14:07:34.031775 17196 caffe.cpp:313] Batch 64, accuracy/top5 = 0.7
I0629 14:07:34.031779 17196 caffe.cpp:313] Batch 64, loss = 2.1578
I0629 14:07:34.080926 17196 caffe.cpp:313] Batch 65, accuracy/top1 = 0.58
I0629 14:07:34.080950 17196 caffe.cpp:313] Batch 65, accuracy/top5 = 0.74
I0629 14:07:34.080953 17196 caffe.cpp:313] Batch 65, loss = 2.02573
I0629 14:07:34.132141 17196 caffe.cpp:313] Batch 66, accuracy/top1 = 0.66
I0629 14:07:34.132175 17196 caffe.cpp:313] Batch 66, accuracy/top5 = 0.8
I0629 14:07:34.132179 17196 caffe.cpp:313] Batch 66, loss = 1.70524
I0629 14:07:34.181041 17196 caffe.cpp:313] Batch 67, accuracy/top1 = 0.58
I0629 14:07:34.181059 17196 caffe.cpp:313] Batch 67, accuracy/top5 = 0.82
I0629 14:07:34.181062 17196 caffe.cpp:313] Batch 67, loss = 1.64112
I0629 14:07:34.230651 17196 caffe.cpp:313] Batch 68, accuracy/top1 = 0.68
I0629 14:07:34.230671 17196 caffe.cpp:313] Batch 68, accuracy/top5 = 0.86
I0629 14:07:34.230674 17196 caffe.cpp:313] Batch 68, loss = 1.32171
I0629 14:07:34.281347 17196 caffe.cpp:313] Batch 69, accuracy/top1 = 0.54
I0629 14:07:34.281366 17196 caffe.cpp:313] Batch 69, accuracy/top5 = 0.78
I0629 14:07:34.281369 17196 caffe.cpp:313] Batch 69, loss = 2.18165
I0629 14:07:34.331162 17196 caffe.cpp:313] Batch 70, accuracy/top1 = 0.5
I0629 14:07:34.331185 17196 caffe.cpp:313] Batch 70, accuracy/top5 = 0.7
I0629 14:07:34.331188 17196 caffe.cpp:313] Batch 70, loss = 2.47192
I0629 14:07:34.380348 17196 caffe.cpp:313] Batch 71, accuracy/top1 = 0.44
I0629 14:07:34.380372 17196 caffe.cpp:313] Batch 71, accuracy/top5 = 0.74
I0629 14:07:34.380374 17196 caffe.cpp:313] Batch 71, loss = 2.42813
I0629 14:07:34.428817 17196 caffe.cpp:313] Batch 72, accuracy/top1 = 0.56
I0629 14:07:34.428841 17196 caffe.cpp:313] Batch 72, accuracy/top5 = 0.78
I0629 14:07:34.428844 17196 caffe.cpp:313] Batch 72, loss = 1.89665
I0629 14:07:34.477526 17196 caffe.cpp:313] Batch 73, accuracy/top1 = 0.6
I0629 14:07:34.477552 17196 caffe.cpp:313] Batch 73, accuracy/top5 = 0.84
I0629 14:07:34.477555 17196 caffe.cpp:313] Batch 73, loss = 1.83675
I0629 14:07:34.526787 17196 caffe.cpp:313] Batch 74, accuracy/top1 = 0.6
I0629 14:07:34.526808 17196 caffe.cpp:313] Batch 74, accuracy/top5 = 0.86
I0629 14:07:34.526811 17196 caffe.cpp:313] Batch 74, loss = 1.56295
I0629 14:07:34.575608 17196 caffe.cpp:313] Batch 75, accuracy/top1 = 0.54
I0629 14:07:34.575631 17196 caffe.cpp:313] Batch 75, accuracy/top5 = 0.74
I0629 14:07:34.575634 17196 caffe.cpp:313] Batch 75, loss = 2.03161
I0629 14:07:34.624346 17196 caffe.cpp:313] Batch 76, accuracy/top1 = 0.54
I0629 14:07:34.624370 17196 caffe.cpp:313] Batch 76, accuracy/top5 = 0.72
I0629 14:07:34.624373 17196 caffe.cpp:313] Batch 76, loss = 2.19117
I0629 14:07:34.672885 17196 caffe.cpp:313] Batch 77, accuracy/top1 = 0.58
I0629 14:07:34.672909 17196 caffe.cpp:313] Batch 77, accuracy/top5 = 0.82
I0629 14:07:34.672911 17196 caffe.cpp:313] Batch 77, loss = 1.71132
I0629 14:07:34.721654 17196 caffe.cpp:313] Batch 78, accuracy/top1 = 0.46
I0629 14:07:34.721678 17196 caffe.cpp:313] Batch 78, accuracy/top5 = 0.74
I0629 14:07:34.721680 17196 caffe.cpp:313] Batch 78, loss = 2.43123
I0629 14:07:34.770973 17196 caffe.cpp:313] Batch 79, accuracy/top1 = 0.66
I0629 14:07:34.770995 17196 caffe.cpp:313] Batch 79, accuracy/top5 = 0.86
I0629 14:07:34.770998 17196 caffe.cpp:313] Batch 79, loss = 1.52669
I0629 14:07:34.820828 17196 caffe.cpp:313] Batch 80, accuracy/top1 = 0.4
I0629 14:07:34.820852 17196 caffe.cpp:313] Batch 80, accuracy/top5 = 0.68
I0629 14:07:34.820854 17196 caffe.cpp:313] Batch 80, loss = 2.50883
I0629 14:07:34.869951 17196 caffe.cpp:313] Batch 81, accuracy/top1 = 0.68
I0629 14:07:34.869973 17196 caffe.cpp:313] Batch 81, accuracy/top5 = 0.82
I0629 14:07:34.869976 17196 caffe.cpp:313] Batch 81, loss = 1.55022
I0629 14:07:34.919911 17196 caffe.cpp:313] Batch 82, accuracy/top1 = 0.58
I0629 14:07:34.919932 17196 caffe.cpp:313] Batch 82, accuracy/top5 = 0.78
I0629 14:07:34.919935 17196 caffe.cpp:313] Batch 82, loss = 1.90054
I0629 14:07:34.968379 17196 caffe.cpp:313] Batch 83, accuracy/top1 = 0.54
I0629 14:07:34.968402 17196 caffe.cpp:313] Batch 83, accuracy/top5 = 0.74
I0629 14:07:34.968405 17196 caffe.cpp:313] Batch 83, loss = 2.26057
I0629 14:07:35.018093 17196 caffe.cpp:313] Batch 84, accuracy/top1 = 0.56
I0629 14:07:35.018117 17196 caffe.cpp:313] Batch 84, accuracy/top5 = 0.78
I0629 14:07:35.018121 17196 caffe.cpp:313] Batch 84, loss = 1.88587
I0629 14:07:35.068044 17196 caffe.cpp:313] Batch 85, accuracy/top1 = 0.62
I0629 14:07:35.068083 17196 caffe.cpp:313] Batch 85, accuracy/top5 = 0.88
I0629 14:07:35.068086 17196 caffe.cpp:313] Batch 85, loss = 1.41023
I0629 14:07:35.118427 17196 caffe.cpp:313] Batch 86, accuracy/top1 = 0.52
I0629 14:07:35.118444 17196 caffe.cpp:313] Batch 86, accuracy/top5 = 0.66
I0629 14:07:35.118448 17196 caffe.cpp:313] Batch 86, loss = 2.4189
I0629 14:07:35.167428 17196 caffe.cpp:313] Batch 87, accuracy/top1 = 0.62
I0629 14:07:35.167451 17196 caffe.cpp:313] Batch 87, accuracy/top5 = 0.84
I0629 14:07:35.167454 17196 caffe.cpp:313] Batch 87, loss = 1.73509
I0629 14:07:35.217507 17196 caffe.cpp:313] Batch 88, accuracy/top1 = 0.68
I0629 14:07:35.217531 17196 caffe.cpp:313] Batch 88, accuracy/top5 = 0.8
I0629 14:07:35.217535 17196 caffe.cpp:313] Batch 88, loss = 1.41339
I0629 14:07:35.266865 17196 caffe.cpp:313] Batch 89, accuracy/top1 = 0.54
I0629 14:07:35.266890 17196 caffe.cpp:313] Batch 89, accuracy/top5 = 0.78
I0629 14:07:35.266892 17196 caffe.cpp:313] Batch 89, loss = 1.99252
I0629 14:07:35.316427 17196 caffe.cpp:313] Batch 90, accuracy/top1 = 0.64
I0629 14:07:35.316452 17196 caffe.cpp:313] Batch 90, accuracy/top5 = 0.9
I0629 14:07:35.316454 17196 caffe.cpp:313] Batch 90, loss = 1.32113
I0629 14:07:35.365932 17196 caffe.cpp:313] Batch 91, accuracy/top1 = 0.52
I0629 14:07:35.365955 17196 caffe.cpp:313] Batch 91, accuracy/top5 = 0.68
I0629 14:07:35.365958 17196 caffe.cpp:313] Batch 91, loss = 2.66013
I0629 14:07:35.415400 17196 caffe.cpp:313] Batch 92, accuracy/top1 = 0.52
I0629 14:07:35.415424 17196 caffe.cpp:313] Batch 92, accuracy/top5 = 0.76
I0629 14:07:35.415427 17196 caffe.cpp:313] Batch 92, loss = 2.06678
I0629 14:07:35.464749 17196 caffe.cpp:313] Batch 93, accuracy/top1 = 0.58
I0629 14:07:35.464773 17196 caffe.cpp:313] Batch 93, accuracy/top5 = 0.84
I0629 14:07:35.464776 17196 caffe.cpp:313] Batch 93, loss = 1.72397
I0629 14:07:35.514580 17196 caffe.cpp:313] Batch 94, accuracy/top1 = 0.68
I0629 14:07:35.514603 17196 caffe.cpp:313] Batch 94, accuracy/top5 = 0.9
I0629 14:07:35.514606 17196 caffe.cpp:313] Batch 94, loss = 1.34892
I0629 14:07:35.564302 17196 caffe.cpp:313] Batch 95, accuracy/top1 = 0.6
I0629 14:07:35.564327 17196 caffe.cpp:313] Batch 95, accuracy/top5 = 0.8
I0629 14:07:35.564329 17196 caffe.cpp:313] Batch 95, loss = 1.94316
I0629 14:07:35.613939 17196 caffe.cpp:313] Batch 96, accuracy/top1 = 0.48
I0629 14:07:35.613962 17196 caffe.cpp:313] Batch 96, accuracy/top5 = 0.84
I0629 14:07:35.613965 17196 caffe.cpp:313] Batch 96, loss = 2.13691
I0629 14:07:35.663460 17196 caffe.cpp:313] Batch 97, accuracy/top1 = 0.58
I0629 14:07:35.663486 17196 caffe.cpp:313] Batch 97, accuracy/top5 = 0.78
I0629 14:07:35.663489 17196 caffe.cpp:313] Batch 97, loss = 1.78769
I0629 14:07:35.712884 17196 caffe.cpp:313] Batch 98, accuracy/top1 = 0.48
I0629 14:07:35.712908 17196 caffe.cpp:313] Batch 98, accuracy/top5 = 0.78
I0629 14:07:35.712911 17196 caffe.cpp:313] Batch 98, loss = 2.16284
I0629 14:07:35.763069 17196 caffe.cpp:313] Batch 99, accuracy/top1 = 0.52
I0629 14:07:35.763092 17196 caffe.cpp:313] Batch 99, accuracy/top5 = 0.8
I0629 14:07:35.763095 17196 caffe.cpp:313] Batch 99, loss = 1.83433
I0629 14:07:35.811924 17196 caffe.cpp:313] Batch 100, accuracy/top1 = 0.66
I0629 14:07:35.811949 17196 caffe.cpp:313] Batch 100, accuracy/top5 = 0.9
I0629 14:07:35.811952 17196 caffe.cpp:313] Batch 100, loss = 1.25604
I0629 14:07:35.860780 17196 caffe.cpp:313] Batch 101, accuracy/top1 = 0.66
I0629 14:07:35.860803 17196 caffe.cpp:313] Batch 101, accuracy/top5 = 0.8
I0629 14:07:35.860806 17196 caffe.cpp:313] Batch 101, loss = 1.73089
I0629 14:07:35.910275 17196 caffe.cpp:313] Batch 102, accuracy/top1 = 0.42
I0629 14:07:35.910300 17196 caffe.cpp:313] Batch 102, accuracy/top5 = 0.68
I0629 14:07:35.910302 17196 caffe.cpp:313] Batch 102, loss = 2.79722
I0629 14:07:35.960144 17196 caffe.cpp:313] Batch 103, accuracy/top1 = 0.68
I0629 14:07:35.960167 17196 caffe.cpp:313] Batch 103, accuracy/top5 = 0.82
I0629 14:07:35.960170 17196 caffe.cpp:313] Batch 103, loss = 1.39134
I0629 14:07:36.009325 17196 caffe.cpp:313] Batch 104, accuracy/top1 = 0.56
I0629 14:07:36.009361 17196 caffe.cpp:313] Batch 104, accuracy/top5 = 0.86
I0629 14:07:36.009366 17196 caffe.cpp:313] Batch 104, loss = 1.57698
I0629 14:07:36.058802 17196 caffe.cpp:313] Batch 105, accuracy/top1 = 0.64
I0629 14:07:36.058825 17196 caffe.cpp:313] Batch 105, accuracy/top5 = 0.72
I0629 14:07:36.058827 17196 caffe.cpp:313] Batch 105, loss = 2.04052
I0629 14:07:36.108341 17196 caffe.cpp:313] Batch 106, accuracy/top1 = 0.6
I0629 14:07:36.108363 17196 caffe.cpp:313] Batch 106, accuracy/top5 = 0.72
I0629 14:07:36.108366 17196 caffe.cpp:313] Batch 106, loss = 2.00753
I0629 14:07:36.157615 17196 caffe.cpp:313] Batch 107, accuracy/top1 = 0.58
I0629 14:07:36.157634 17196 caffe.cpp:313] Batch 107, accuracy/top5 = 0.72
I0629 14:07:36.157637 17196 caffe.cpp:313] Batch 107, loss = 2.13486
I0629 14:07:36.206995 17196 caffe.cpp:313] Batch 108, accuracy/top1 = 0.5
I0629 14:07:36.207013 17196 caffe.cpp:313] Batch 108, accuracy/top5 = 0.72
I0629 14:07:36.207016 17196 caffe.cpp:313] Batch 108, loss = 2.11054
I0629 14:07:36.257505 17196 caffe.cpp:313] Batch 109, accuracy/top1 = 0.68
I0629 14:07:36.257527 17196 caffe.cpp:313] Batch 109, accuracy/top5 = 0.78
I0629 14:07:36.257530 17196 caffe.cpp:313] Batch 109, loss = 1.41652
I0629 14:07:36.306903 17196 caffe.cpp:313] Batch 110, accuracy/top1 = 0.46
I0629 14:07:36.306927 17196 caffe.cpp:313] Batch 110, accuracy/top5 = 0.72
I0629 14:07:36.306931 17196 caffe.cpp:313] Batch 110, loss = 2.17305
I0629 14:07:36.357652 17196 caffe.cpp:313] Batch 111, accuracy/top1 = 0.52
I0629 14:07:36.357672 17196 caffe.cpp:313] Batch 111, accuracy/top5 = 0.76
I0629 14:07:36.357676 17196 caffe.cpp:313] Batch 111, loss = 2.11178
I0629 14:07:36.406805 17196 caffe.cpp:313] Batch 112, accuracy/top1 = 0.58
I0629 14:07:36.406824 17196 caffe.cpp:313] Batch 112, accuracy/top5 = 0.72
I0629 14:07:36.406827 17196 caffe.cpp:313] Batch 112, loss = 2.06179
I0629 14:07:36.457139 17196 caffe.cpp:313] Batch 113, accuracy/top1 = 0.66
I0629 14:07:36.457161 17196 caffe.cpp:313] Batch 113, accuracy/top5 = 0.78
I0629 14:07:36.457165 17196 caffe.cpp:313] Batch 113, loss = 1.43937
I0629 14:07:36.504673 17196 caffe.cpp:313] Batch 114, accuracy/top1 = 0.6
I0629 14:07:36.504696 17196 caffe.cpp:313] Batch 114, accuracy/top5 = 0.78
I0629 14:07:36.504699 17196 caffe.cpp:313] Batch 114, loss = 1.90358
I0629 14:07:36.554215 17196 caffe.cpp:313] Batch 115, accuracy/top1 = 0.58
I0629 14:07:36.554239 17196 caffe.cpp:313] Batch 115, accuracy/top5 = 0.8
I0629 14:07:36.554241 17196 caffe.cpp:313] Batch 115, loss = 2.05519
I0629 14:07:36.604365 17196 caffe.cpp:313] Batch 116, accuracy/top1 = 0.5
I0629 14:07:36.604389 17196 caffe.cpp:313] Batch 116, accuracy/top5 = 0.78
I0629 14:07:36.604393 17196 caffe.cpp:313] Batch 116, loss = 1.99796
I0629 14:07:36.653108 17196 caffe.cpp:313] Batch 117, accuracy/top1 = 0.46
I0629 14:07:36.653132 17196 caffe.cpp:313] Batch 117, accuracy/top5 = 0.78
I0629 14:07:36.653136 17196 caffe.cpp:313] Batch 117, loss = 2.15321
I0629 14:07:36.702390 17196 caffe.cpp:313] Batch 118, accuracy/top1 = 0.4
I0629 14:07:36.702414 17196 caffe.cpp:313] Batch 118, accuracy/top5 = 0.74
I0629 14:07:36.702417 17196 caffe.cpp:313] Batch 118, loss = 2.8401
I0629 14:07:36.752737 17196 caffe.cpp:313] Batch 119, accuracy/top1 = 0.64
I0629 14:07:36.752764 17196 caffe.cpp:313] Batch 119, accuracy/top5 = 0.84
I0629 14:07:36.752768 17196 caffe.cpp:313] Batch 119, loss = 1.70587
I0629 14:07:36.801440 17196 caffe.cpp:313] Batch 120, accuracy/top1 = 0.58
I0629 14:07:36.801465 17196 caffe.cpp:313] Batch 120, accuracy/top5 = 0.82
I0629 14:07:36.801467 17196 caffe.cpp:313] Batch 120, loss = 1.72012
I0629 14:07:36.849452 17196 caffe.cpp:313] Batch 121, accuracy/top1 = 0.6
I0629 14:07:36.849478 17196 caffe.cpp:313] Batch 121, accuracy/top5 = 0.86
I0629 14:07:36.849480 17196 caffe.cpp:313] Batch 121, loss = 1.61089
I0629 14:07:36.897855 17196 caffe.cpp:313] Batch 122, accuracy/top1 = 0.56
I0629 14:07:36.897879 17196 caffe.cpp:313] Batch 122, accuracy/top5 = 0.74
I0629 14:07:36.897882 17196 caffe.cpp:313] Batch 122, loss = 2.56577
I0629 14:07:36.946280 17196 caffe.cpp:313] Batch 123, accuracy/top1 = 0.52
I0629 14:07:36.946305 17196 caffe.cpp:313] Batch 123, accuracy/top5 = 0.84
I0629 14:07:36.946307 17196 caffe.cpp:313] Batch 123, loss = 1.88257
I0629 14:07:36.995229 17196 caffe.cpp:313] Batch 124, accuracy/top1 = 0.56
I0629 14:07:36.995252 17196 caffe.cpp:313] Batch 124, accuracy/top5 = 0.72
I0629 14:07:36.995255 17196 caffe.cpp:313] Batch 124, loss = 2.20329
I0629 14:07:37.044217 17196 caffe.cpp:313] Batch 125, accuracy/top1 = 0.64
I0629 14:07:37.044241 17196 caffe.cpp:313] Batch 125, accuracy/top5 = 0.84
I0629 14:07:37.044245 17196 caffe.cpp:313] Batch 125, loss = 1.67065
I0629 14:07:37.093685 17196 caffe.cpp:313] Batch 126, accuracy/top1 = 0.48
I0629 14:07:37.093709 17196 caffe.cpp:313] Batch 126, accuracy/top5 = 0.84
I0629 14:07:37.093713 17196 caffe.cpp:313] Batch 126, loss = 2.01854
I0629 14:07:37.142134 17196 caffe.cpp:313] Batch 127, accuracy/top1 = 0.5
I0629 14:07:37.142158 17196 caffe.cpp:313] Batch 127, accuracy/top5 = 0.76
I0629 14:07:37.142160 17196 caffe.cpp:313] Batch 127, loss = 2.08926
I0629 14:07:37.191725 17196 caffe.cpp:313] Batch 128, accuracy/top1 = 0.62
I0629 14:07:37.191747 17196 caffe.cpp:313] Batch 128, accuracy/top5 = 0.84
I0629 14:07:37.191751 17196 caffe.cpp:313] Batch 128, loss = 1.63579
I0629 14:07:37.241725 17196 caffe.cpp:313] Batch 129, accuracy/top1 = 0.6
I0629 14:07:37.241750 17196 caffe.cpp:313] Batch 129, accuracy/top5 = 0.88
I0629 14:07:37.241753 17196 caffe.cpp:313] Batch 129, loss = 1.64861
I0629 14:07:37.291240 17196 caffe.cpp:313] Batch 130, accuracy/top1 = 0.56
I0629 14:07:37.291265 17196 caffe.cpp:313] Batch 130, accuracy/top5 = 0.82
I0629 14:07:37.291268 17196 caffe.cpp:313] Batch 130, loss = 1.66365
I0629 14:07:37.338670 17196 caffe.cpp:313] Batch 131, accuracy/top1 = 0.64
I0629 14:07:37.338695 17196 caffe.cpp:313] Batch 131, accuracy/top5 = 0.84
I0629 14:07:37.338697 17196 caffe.cpp:313] Batch 131, loss = 1.60594
I0629 14:07:37.386868 17196 caffe.cpp:313] Batch 132, accuracy/top1 = 0.64
I0629 14:07:37.386893 17196 caffe.cpp:313] Batch 132, accuracy/top5 = 0.76
I0629 14:07:37.386895 17196 caffe.cpp:313] Batch 132, loss = 1.92333
I0629 14:07:37.435232 17196 caffe.cpp:313] Batch 133, accuracy/top1 = 0.54
I0629 14:07:37.435256 17196 caffe.cpp:313] Batch 133, accuracy/top5 = 0.78
I0629 14:07:37.435258 17196 caffe.cpp:313] Batch 133, loss = 2.19084
I0629 14:07:37.484556 17196 caffe.cpp:313] Batch 134, accuracy/top1 = 0.62
I0629 14:07:37.484578 17196 caffe.cpp:313] Batch 134, accuracy/top5 = 0.84
I0629 14:07:37.484581 17196 caffe.cpp:313] Batch 134, loss = 1.65211
I0629 14:07:37.532483 17196 caffe.cpp:313] Batch 135, accuracy/top1 = 0.56
I0629 14:07:37.532510 17196 caffe.cpp:313] Batch 135, accuracy/top5 = 0.76
I0629 14:07:37.532512 17196 caffe.cpp:313] Batch 135, loss = 1.86344
I0629 14:07:37.581501 17196 caffe.cpp:313] Batch 136, accuracy/top1 = 0.52
I0629 14:07:37.581526 17196 caffe.cpp:313] Batch 136, accuracy/top5 = 0.7
I0629 14:07:37.581529 17196 caffe.cpp:313] Batch 136, loss = 2.21295
I0629 14:07:37.630905 17196 caffe.cpp:313] Batch 137, accuracy/top1 = 0.6
I0629 14:07:37.630929 17196 caffe.cpp:313] Batch 137, accuracy/top5 = 0.78
I0629 14:07:37.630934 17196 caffe.cpp:313] Batch 137, loss = 1.78402
I0629 14:07:37.679419 17196 caffe.cpp:313] Batch 138, accuracy/top1 = 0.66
I0629 14:07:37.679442 17196 caffe.cpp:313] Batch 138, accuracy/top5 = 0.92
I0629 14:07:37.679445 17196 caffe.cpp:313] Batch 138, loss = 1.35209
I0629 14:07:37.727921 17196 caffe.cpp:313] Batch 139, accuracy/top1 = 0.58
I0629 14:07:37.727944 17196 caffe.cpp:313] Batch 139, accuracy/top5 = 0.74
I0629 14:07:37.727947 17196 caffe.cpp:313] Batch 139, loss = 2.24241
I0629 14:07:37.776448 17196 caffe.cpp:313] Batch 140, accuracy/top1 = 0.46
I0629 14:07:37.776471 17196 caffe.cpp:313] Batch 140, accuracy/top5 = 0.76
I0629 14:07:37.776474 17196 caffe.cpp:313] Batch 140, loss = 2.13661
I0629 14:07:37.826354 17196 caffe.cpp:313] Batch 141, accuracy/top1 = 0.62
I0629 14:07:37.826378 17196 caffe.cpp:313] Batch 141, accuracy/top5 = 0.84
I0629 14:07:37.826397 17196 caffe.cpp:313] Batch 141, loss = 1.75262
I0629 14:07:37.876102 17196 caffe.cpp:313] Batch 142, accuracy/top1 = 0.48
I0629 14:07:37.876127 17196 caffe.cpp:313] Batch 142, accuracy/top5 = 0.76
I0629 14:07:37.876130 17196 caffe.cpp:313] Batch 142, loss = 2.15891
I0629 14:07:37.926362 17196 caffe.cpp:313] Batch 143, accuracy/top1 = 0.54
I0629 14:07:37.926383 17196 caffe.cpp:313] Batch 143, accuracy/top5 = 0.78
I0629 14:07:37.926386 17196 caffe.cpp:313] Batch 143, loss = 2.2248
I0629 14:07:37.975484 17196 caffe.cpp:313] Batch 144, accuracy/top1 = 0.56
I0629 14:07:37.975508 17196 caffe.cpp:313] Batch 144, accuracy/top5 = 0.84
I0629 14:07:37.975512 17196 caffe.cpp:313] Batch 144, loss = 1.85385
I0629 14:07:38.024049 17196 caffe.cpp:313] Batch 145, accuracy/top1 = 0.62
I0629 14:07:38.024070 17196 caffe.cpp:313] Batch 145, accuracy/top5 = 0.82
I0629 14:07:38.024073 17196 caffe.cpp:313] Batch 145, loss = 1.82295
I0629 14:07:38.073421 17196 caffe.cpp:313] Batch 146, accuracy/top1 = 0.7
I0629 14:07:38.073444 17196 caffe.cpp:313] Batch 146, accuracy/top5 = 0.9
I0629 14:07:38.073448 17196 caffe.cpp:313] Batch 146, loss = 1.34852
I0629 14:07:38.123175 17196 caffe.cpp:313] Batch 147, accuracy/top1 = 0.58
I0629 14:07:38.123194 17196 caffe.cpp:313] Batch 147, accuracy/top5 = 0.86
I0629 14:07:38.123198 17196 caffe.cpp:313] Batch 147, loss = 1.6303
I0629 14:07:38.172094 17196 caffe.cpp:313] Batch 148, accuracy/top1 = 0.56
I0629 14:07:38.172119 17196 caffe.cpp:313] Batch 148, accuracy/top5 = 0.84
I0629 14:07:38.172123 17196 caffe.cpp:313] Batch 148, loss = 2.1555
I0629 14:07:38.222117 17196 caffe.cpp:313] Batch 149, accuracy/top1 = 0.6
I0629 14:07:38.222136 17196 caffe.cpp:313] Batch 149, accuracy/top5 = 0.8
I0629 14:07:38.222141 17196 caffe.cpp:313] Batch 149, loss = 1.66433
I0629 14:07:38.271540 17196 caffe.cpp:313] Batch 150, accuracy/top1 = 0.56
I0629 14:07:38.271564 17196 caffe.cpp:313] Batch 150, accuracy/top5 = 0.78
I0629 14:07:38.271567 17196 caffe.cpp:313] Batch 150, loss = 1.79047
I0629 14:07:38.321408 17196 caffe.cpp:313] Batch 151, accuracy/top1 = 0.62
I0629 14:07:38.321431 17196 caffe.cpp:313] Batch 151, accuracy/top5 = 0.86
I0629 14:07:38.321435 17196 caffe.cpp:313] Batch 151, loss = 1.55573
I0629 14:07:38.370030 17196 caffe.cpp:313] Batch 152, accuracy/top1 = 0.58
I0629 14:07:38.370054 17196 caffe.cpp:313] Batch 152, accuracy/top5 = 0.78
I0629 14:07:38.370059 17196 caffe.cpp:313] Batch 152, loss = 1.91161
I0629 14:07:38.419417 17196 caffe.cpp:313] Batch 153, accuracy/top1 = 0.5
I0629 14:07:38.419442 17196 caffe.cpp:313] Batch 153, accuracy/top5 = 0.82
I0629 14:07:38.419446 17196 caffe.cpp:313] Batch 153, loss = 2.05112
I0629 14:07:38.468849 17196 caffe.cpp:313] Batch 154, accuracy/top1 = 0.56
I0629 14:07:38.468870 17196 caffe.cpp:313] Batch 154, accuracy/top5 = 0.84
I0629 14:07:38.468875 17196 caffe.cpp:313] Batch 154, loss = 1.66597
I0629 14:07:38.517930 17196 caffe.cpp:313] Batch 155, accuracy/top1 = 0.5
I0629 14:07:38.517951 17196 caffe.cpp:313] Batch 155, accuracy/top5 = 0.8
I0629 14:07:38.517954 17196 caffe.cpp:313] Batch 155, loss = 1.92065
I0629 14:07:38.567189 17196 caffe.cpp:313] Batch 156, accuracy/top1 = 0.64
I0629 14:07:38.567210 17196 caffe.cpp:313] Batch 156, accuracy/top5 = 0.78
I0629 14:07:38.567214 17196 caffe.cpp:313] Batch 156, loss = 1.91687
I0629 14:07:38.616622 17196 caffe.cpp:313] Batch 157, accuracy/top1 = 0.58
I0629 14:07:38.616645 17196 caffe.cpp:313] Batch 157, accuracy/top5 = 0.8
I0629 14:07:38.616649 17196 caffe.cpp:313] Batch 157, loss = 1.69443
I0629 14:07:38.666399 17196 caffe.cpp:313] Batch 158, accuracy/top1 = 0.68
I0629 14:07:38.666422 17196 caffe.cpp:313] Batch 158, accuracy/top5 = 0.88
I0629 14:07:38.666426 17196 caffe.cpp:313] Batch 158, loss = 1.59287
I0629 14:07:38.716153 17196 caffe.cpp:313] Batch 159, accuracy/top1 = 0.54
I0629 14:07:38.716178 17196 caffe.cpp:313] Batch 159, accuracy/top5 = 0.84
I0629 14:07:38.716182 17196 caffe.cpp:313] Batch 159, loss = 1.80275
I0629 14:07:38.765089 17196 caffe.cpp:313] Batch 160, accuracy/top1 = 0.6
I0629 14:07:38.765127 17196 caffe.cpp:313] Batch 160, accuracy/top5 = 0.82
I0629 14:07:38.765132 17196 caffe.cpp:313] Batch 160, loss = 1.73819
I0629 14:07:38.814929 17196 caffe.cpp:313] Batch 161, accuracy/top1 = 0.62
I0629 14:07:38.814954 17196 caffe.cpp:313] Batch 161, accuracy/top5 = 0.8
I0629 14:07:38.814959 17196 caffe.cpp:313] Batch 161, loss = 2.08271
I0629 14:07:38.864784 17196 caffe.cpp:313] Batch 162, accuracy/top1 = 0.54
I0629 14:07:38.864807 17196 caffe.cpp:313] Batch 162, accuracy/top5 = 0.8
I0629 14:07:38.864811 17196 caffe.cpp:313] Batch 162, loss = 1.776
I0629 14:07:38.914749 17196 caffe.cpp:313] Batch 163, accuracy/top1 = 0.58
I0629 14:07:38.914774 17196 caffe.cpp:313] Batch 163, accuracy/top5 = 0.84
I0629 14:07:38.914778 17196 caffe.cpp:313] Batch 163, loss = 1.728
I0629 14:07:38.965420 17196 caffe.cpp:313] Batch 164, accuracy/top1 = 0.68
I0629 14:07:38.965445 17196 caffe.cpp:313] Batch 164, accuracy/top5 = 0.8
I0629 14:07:38.965448 17196 caffe.cpp:313] Batch 164, loss = 1.66247
I0629 14:07:39.014503 17196 caffe.cpp:313] Batch 165, accuracy/top1 = 0.68
I0629 14:07:39.014526 17196 caffe.cpp:313] Batch 165, accuracy/top5 = 0.88
I0629 14:07:39.014530 17196 caffe.cpp:313] Batch 165, loss = 1.2124
I0629 14:07:39.064051 17196 caffe.cpp:313] Batch 166, accuracy/top1 = 0.52
I0629 14:07:39.064075 17196 caffe.cpp:313] Batch 166, accuracy/top5 = 0.7
I0629 14:07:39.064079 17196 caffe.cpp:313] Batch 166, loss = 2.21808
I0629 14:07:39.112324 17196 caffe.cpp:313] Batch 167, accuracy/top1 = 0.52
I0629 14:07:39.112346 17196 caffe.cpp:313] Batch 167, accuracy/top5 = 0.82
I0629 14:07:39.112350 17196 caffe.cpp:313] Batch 167, loss = 1.72566
I0629 14:07:39.160745 17196 caffe.cpp:313] Batch 168, accuracy/top1 = 0.6
I0629 14:07:39.160769 17196 caffe.cpp:313] Batch 168, accuracy/top5 = 0.86
I0629 14:07:39.160773 17196 caffe.cpp:313] Batch 168, loss = 1.57885
I0629 14:07:39.209957 17196 caffe.cpp:313] Batch 169, accuracy/top1 = 0.7
I0629 14:07:39.209981 17196 caffe.cpp:313] Batch 169, accuracy/top5 = 0.88
I0629 14:07:39.209986 17196 caffe.cpp:313] Batch 169, loss = 1.29836
I0629 14:07:39.258517 17196 caffe.cpp:313] Batch 170, accuracy/top1 = 0.64
I0629 14:07:39.258541 17196 caffe.cpp:313] Batch 170, accuracy/top5 = 0.76
I0629 14:07:39.258545 17196 caffe.cpp:313] Batch 170, loss = 2.02337
I0629 14:07:39.307832 17196 caffe.cpp:313] Batch 171, accuracy/top1 = 0.52
I0629 14:07:39.307857 17196 caffe.cpp:313] Batch 171, accuracy/top5 = 0.78
I0629 14:07:39.307860 17196 caffe.cpp:313] Batch 171, loss = 2.22377
I0629 14:07:39.357625 17196 caffe.cpp:313] Batch 172, accuracy/top1 = 0.6
I0629 14:07:39.357648 17196 caffe.cpp:313] Batch 172, accuracy/top5 = 0.86
I0629 14:07:39.357652 17196 caffe.cpp:313] Batch 172, loss = 1.74714
I0629 14:07:39.407254 17196 caffe.cpp:313] Batch 173, accuracy/top1 = 0.56
I0629 14:07:39.407279 17196 caffe.cpp:313] Batch 173, accuracy/top5 = 0.84
I0629 14:07:39.407284 17196 caffe.cpp:313] Batch 173, loss = 1.732
I0629 14:07:39.455900 17196 caffe.cpp:313] Batch 174, accuracy/top1 = 0.58
I0629 14:07:39.455925 17196 caffe.cpp:313] Batch 174, accuracy/top5 = 0.8
I0629 14:07:39.455929 17196 caffe.cpp:313] Batch 174, loss = 1.80404
I0629 14:07:39.504684 17196 caffe.cpp:313] Batch 175, accuracy/top1 = 0.52
I0629 14:07:39.504709 17196 caffe.cpp:313] Batch 175, accuracy/top5 = 0.74
I0629 14:07:39.504712 17196 caffe.cpp:313] Batch 175, loss = 2.18041
I0629 14:07:39.554064 17196 caffe.cpp:313] Batch 176, accuracy/top1 = 0.52
I0629 14:07:39.554090 17196 caffe.cpp:313] Batch 176, accuracy/top5 = 0.8
I0629 14:07:39.554093 17196 caffe.cpp:313] Batch 176, loss = 1.94867
I0629 14:07:39.602687 17196 caffe.cpp:313] Batch 177, accuracy/top1 = 0.52
I0629 14:07:39.602711 17196 caffe.cpp:313] Batch 177, accuracy/top5 = 0.78
I0629 14:07:39.602715 17196 caffe.cpp:313] Batch 177, loss = 1.8474
I0629 14:07:39.651943 17196 caffe.cpp:313] Batch 178, accuracy/top1 = 0.46
I0629 14:07:39.651968 17196 caffe.cpp:313] Batch 178, accuracy/top5 = 0.74
I0629 14:07:39.651970 17196 caffe.cpp:313] Batch 178, loss = 2.26303
I0629 14:07:39.702517 17196 caffe.cpp:313] Batch 179, accuracy/top1 = 0.64
I0629 14:07:39.702556 17196 caffe.cpp:313] Batch 179, accuracy/top5 = 0.84
I0629 14:07:39.702559 17196 caffe.cpp:313] Batch 179, loss = 1.82765
I0629 14:07:39.751830 17196 caffe.cpp:313] Batch 180, accuracy/top1 = 0.64
I0629 14:07:39.751854 17196 caffe.cpp:313] Batch 180, accuracy/top5 = 0.82
I0629 14:07:39.751857 17196 caffe.cpp:313] Batch 180, loss = 1.72685
I0629 14:07:39.801494 17196 caffe.cpp:313] Batch 181, accuracy/top1 = 0.5
I0629 14:07:39.801518 17196 caffe.cpp:313] Batch 181, accuracy/top5 = 0.72
I0629 14:07:39.801522 17196 caffe.cpp:313] Batch 181, loss = 2.2987
I0629 14:07:39.851519 17196 caffe.cpp:313] Batch 182, accuracy/top1 = 0.54
I0629 14:07:39.851542 17196 caffe.cpp:313] Batch 182, accuracy/top5 = 0.78
I0629 14:07:39.851546 17196 caffe.cpp:313] Batch 182, loss = 2.19153
I0629 14:07:39.901181 17196 caffe.cpp:313] Batch 183, accuracy/top1 = 0.52
I0629 14:07:39.901206 17196 caffe.cpp:313] Batch 183, accuracy/top5 = 0.82
I0629 14:07:39.901208 17196 caffe.cpp:313] Batch 183, loss = 2.04133
I0629 14:07:39.949993 17196 caffe.cpp:313] Batch 184, accuracy/top1 = 0.48
I0629 14:07:39.950016 17196 caffe.cpp:313] Batch 184, accuracy/top5 = 0.84
I0629 14:07:39.950019 17196 caffe.cpp:313] Batch 184, loss = 1.97033
I0629 14:07:39.999361 17196 caffe.cpp:313] Batch 185, accuracy/top1 = 0.52
I0629 14:07:39.999384 17196 caffe.cpp:313] Batch 185, accuracy/top5 = 0.84
I0629 14:07:39.999387 17196 caffe.cpp:313] Batch 185, loss = 1.87194
I0629 14:07:40.049365 17196 caffe.cpp:313] Batch 186, accuracy/top1 = 0.58
I0629 14:07:40.049386 17196 caffe.cpp:313] Batch 186, accuracy/top5 = 0.88
I0629 14:07:40.049389 17196 caffe.cpp:313] Batch 186, loss = 1.67883
I0629 14:07:40.099627 17196 caffe.cpp:313] Batch 187, accuracy/top1 = 0.54
I0629 14:07:40.099650 17196 caffe.cpp:313] Batch 187, accuracy/top5 = 0.88
I0629 14:07:40.099653 17196 caffe.cpp:313] Batch 187, loss = 1.60245
I0629 14:07:40.149021 17196 caffe.cpp:313] Batch 188, accuracy/top1 = 0.54
I0629 14:07:40.149040 17196 caffe.cpp:313] Batch 188, accuracy/top5 = 0.76
I0629 14:07:40.149044 17196 caffe.cpp:313] Batch 188, loss = 1.60775
I0629 14:07:40.199089 17196 caffe.cpp:313] Batch 189, accuracy/top1 = 0.52
I0629 14:07:40.199112 17196 caffe.cpp:313] Batch 189, accuracy/top5 = 0.8
I0629 14:07:40.199115 17196 caffe.cpp:313] Batch 189, loss = 2.10686
I0629 14:07:40.248409 17196 caffe.cpp:313] Batch 190, accuracy/top1 = 0.64
I0629 14:07:40.248425 17196 caffe.cpp:313] Batch 190, accuracy/top5 = 0.9
I0629 14:07:40.248428 17196 caffe.cpp:313] Batch 190, loss = 1.50348
I0629 14:07:40.298319 17196 caffe.cpp:313] Batch 191, accuracy/top1 = 0.54
I0629 14:07:40.298341 17196 caffe.cpp:313] Batch 191, accuracy/top5 = 0.76
I0629 14:07:40.298343 17196 caffe.cpp:313] Batch 191, loss = 2.30571
I0629 14:07:40.347580 17196 caffe.cpp:313] Batch 192, accuracy/top1 = 0.5
I0629 14:07:40.347605 17196 caffe.cpp:313] Batch 192, accuracy/top5 = 0.8
I0629 14:07:40.347609 17196 caffe.cpp:313] Batch 192, loss = 1.91945
I0629 14:07:40.397541 17196 caffe.cpp:313] Batch 193, accuracy/top1 = 0.6
I0629 14:07:40.397574 17196 caffe.cpp:313] Batch 193, accuracy/top5 = 0.7
I0629 14:07:40.397578 17196 caffe.cpp:313] Batch 193, loss = 1.69122
I0629 14:07:40.446250 17196 caffe.cpp:313] Batch 194, accuracy/top1 = 0.64
I0629 14:07:40.446274 17196 caffe.cpp:313] Batch 194, accuracy/top5 = 0.86
I0629 14:07:40.446277 17196 caffe.cpp:313] Batch 194, loss = 1.53567
I0629 14:07:40.495820 17196 caffe.cpp:313] Batch 195, accuracy/top1 = 0.56
I0629 14:07:40.495844 17196 caffe.cpp:313] Batch 195, accuracy/top5 = 0.8
I0629 14:07:40.495847 17196 caffe.cpp:313] Batch 195, loss = 1.69413
I0629 14:07:40.545655 17196 caffe.cpp:313] Batch 196, accuracy/top1 = 0.66
I0629 14:07:40.545678 17196 caffe.cpp:313] Batch 196, accuracy/top5 = 0.8
I0629 14:07:40.545681 17196 caffe.cpp:313] Batch 196, loss = 1.46022
I0629 14:07:40.595501 17196 caffe.cpp:313] Batch 197, accuracy/top1 = 0.64
I0629 14:07:40.595521 17196 caffe.cpp:313] Batch 197, accuracy/top5 = 0.86
I0629 14:07:40.595525 17196 caffe.cpp:313] Batch 197, loss = 1.52544
I0629 14:07:40.646416 17196 caffe.cpp:313] Batch 198, accuracy/top1 = 0.62
I0629 14:07:40.646435 17196 caffe.cpp:313] Batch 198, accuracy/top5 = 0.82
I0629 14:07:40.646438 17196 caffe.cpp:313] Batch 198, loss = 1.86921
I0629 14:07:40.695513 17196 caffe.cpp:313] Batch 199, accuracy/top1 = 0.72
I0629 14:07:40.695534 17196 caffe.cpp:313] Batch 199, accuracy/top5 = 0.82
I0629 14:07:40.695538 17196 caffe.cpp:313] Batch 199, loss = 1.53939
I0629 14:07:40.744294 17196 caffe.cpp:313] Batch 200, accuracy/top1 = 0.54
I0629 14:07:40.744318 17196 caffe.cpp:313] Batch 200, accuracy/top5 = 0.8
I0629 14:07:40.744320 17196 caffe.cpp:313] Batch 200, loss = 1.98608
I0629 14:07:40.794680 17196 caffe.cpp:313] Batch 201, accuracy/top1 = 0.44
I0629 14:07:40.794704 17196 caffe.cpp:313] Batch 201, accuracy/top5 = 0.8
I0629 14:07:40.794708 17196 caffe.cpp:313] Batch 201, loss = 2.21125
I0629 14:07:40.844693 17196 caffe.cpp:313] Batch 202, accuracy/top1 = 0.48
I0629 14:07:40.844717 17196 caffe.cpp:313] Batch 202, accuracy/top5 = 0.82
I0629 14:07:40.844720 17196 caffe.cpp:313] Batch 202, loss = 1.979
I0629 14:07:40.894094 17196 caffe.cpp:313] Batch 203, accuracy/top1 = 0.58
I0629 14:07:40.894117 17196 caffe.cpp:313] Batch 203, accuracy/top5 = 0.86
I0629 14:07:40.894120 17196 caffe.cpp:313] Batch 203, loss = 1.59202
I0629 14:07:40.943859 17196 caffe.cpp:313] Batch 204, accuracy/top1 = 0.66
I0629 14:07:40.943882 17196 caffe.cpp:313] Batch 204, accuracy/top5 = 0.88
I0629 14:07:40.943886 17196 caffe.cpp:313] Batch 204, loss = 1.26024
I0629 14:07:40.993139 17196 caffe.cpp:313] Batch 205, accuracy/top1 = 0.52
I0629 14:07:40.993163 17196 caffe.cpp:313] Batch 205, accuracy/top5 = 0.76
I0629 14:07:40.993165 17196 caffe.cpp:313] Batch 205, loss = 2.18768
I0629 14:07:41.042738 17196 caffe.cpp:313] Batch 206, accuracy/top1 = 0.62
I0629 14:07:41.042760 17196 caffe.cpp:313] Batch 206, accuracy/top5 = 0.92
I0629 14:07:41.042763 17196 caffe.cpp:313] Batch 206, loss = 1.41035
I0629 14:07:41.092196 17196 caffe.cpp:313] Batch 207, accuracy/top1 = 0.58
I0629 14:07:41.092221 17196 caffe.cpp:313] Batch 207, accuracy/top5 = 0.82
I0629 14:07:41.092224 17196 caffe.cpp:313] Batch 207, loss = 1.88079
I0629 14:07:41.140739 17196 caffe.cpp:313] Batch 208, accuracy/top1 = 0.46
I0629 14:07:41.140758 17196 caffe.cpp:313] Batch 208, accuracy/top5 = 0.74
I0629 14:07:41.140761 17196 caffe.cpp:313] Batch 208, loss = 2.303
I0629 14:07:41.189190 17196 caffe.cpp:313] Batch 209, accuracy/top1 = 0.64
I0629 14:07:41.189214 17196 caffe.cpp:313] Batch 209, accuracy/top5 = 0.84
I0629 14:07:41.189218 17196 caffe.cpp:313] Batch 209, loss = 1.71456
I0629 14:07:41.238656 17196 caffe.cpp:313] Batch 210, accuracy/top1 = 0.42
I0629 14:07:41.238682 17196 caffe.cpp:313] Batch 210, accuracy/top5 = 0.7
I0629 14:07:41.238685 17196 caffe.cpp:313] Batch 210, loss = 2.83559
I0629 14:07:41.288269 17196 caffe.cpp:313] Batch 211, accuracy/top1 = 0.56
I0629 14:07:41.288292 17196 caffe.cpp:313] Batch 211, accuracy/top5 = 0.76
I0629 14:07:41.288295 17196 caffe.cpp:313] Batch 211, loss = 2.10909
I0629 14:07:41.338224 17196 caffe.cpp:313] Batch 212, accuracy/top1 = 0.7
I0629 14:07:41.338248 17196 caffe.cpp:313] Batch 212, accuracy/top5 = 0.82
I0629 14:07:41.338251 17196 caffe.cpp:313] Batch 212, loss = 1.72923
I0629 14:07:41.387362 17196 caffe.cpp:313] Batch 213, accuracy/top1 = 0.58
I0629 14:07:41.387385 17196 caffe.cpp:313] Batch 213, accuracy/top5 = 0.8
I0629 14:07:41.387388 17196 caffe.cpp:313] Batch 213, loss = 1.62957
I0629 14:07:41.437114 17196 caffe.cpp:313] Batch 214, accuracy/top1 = 0.46
I0629 14:07:41.437137 17196 caffe.cpp:313] Batch 214, accuracy/top5 = 0.84
I0629 14:07:41.437140 17196 caffe.cpp:313] Batch 214, loss = 1.97897
I0629 14:07:41.484747 17196 caffe.cpp:313] Batch 215, accuracy/top1 = 0.5
I0629 14:07:41.484771 17196 caffe.cpp:313] Batch 215, accuracy/top5 = 0.78
I0629 14:07:41.484773 17196 caffe.cpp:313] Batch 215, loss = 1.93909
I0629 14:07:41.533922 17196 caffe.cpp:313] Batch 216, accuracy/top1 = 0.72
I0629 14:07:41.533946 17196 caffe.cpp:313] Batch 216, accuracy/top5 = 0.86
I0629 14:07:41.533965 17196 caffe.cpp:313] Batch 216, loss = 1.47686
I0629 14:07:41.583127 17196 caffe.cpp:313] Batch 217, accuracy/top1 = 0.54
I0629 14:07:41.583150 17196 caffe.cpp:313] Batch 217, accuracy/top5 = 0.84
I0629 14:07:41.583153 17196 caffe.cpp:313] Batch 217, loss = 1.90237
I0629 14:07:41.632078 17196 caffe.cpp:313] Batch 218, accuracy/top1 = 0.56
I0629 14:07:41.632102 17196 caffe.cpp:313] Batch 218, accuracy/top5 = 0.84
I0629 14:07:41.632104 17196 caffe.cpp:313] Batch 218, loss = 1.87741
I0629 14:07:41.681195 17196 caffe.cpp:313] Batch 219, accuracy/top1 = 0.56
I0629 14:07:41.681217 17196 caffe.cpp:313] Batch 219, accuracy/top5 = 0.9
I0629 14:07:41.681221 17196 caffe.cpp:313] Batch 219, loss = 1.57967
I0629 14:07:41.730391 17196 caffe.cpp:313] Batch 220, accuracy/top1 = 0.48
I0629 14:07:41.730415 17196 caffe.cpp:313] Batch 220, accuracy/top5 = 0.7
I0629 14:07:41.730419 17196 caffe.cpp:313] Batch 220, loss = 2.3799
I0629 14:07:41.779114 17196 caffe.cpp:313] Batch 221, accuracy/top1 = 0.62
I0629 14:07:41.779139 17196 caffe.cpp:313] Batch 221, accuracy/top5 = 0.82
I0629 14:07:41.779141 17196 caffe.cpp:313] Batch 221, loss = 1.65624
I0629 14:07:41.828564 17196 caffe.cpp:313] Batch 222, accuracy/top1 = 0.62
I0629 14:07:41.828588 17196 caffe.cpp:313] Batch 222, accuracy/top5 = 0.8
I0629 14:07:41.828590 17196 caffe.cpp:313] Batch 222, loss = 2.14484
I0629 14:07:41.876983 17196 caffe.cpp:313] Batch 223, accuracy/top1 = 0.48
I0629 14:07:41.877007 17196 caffe.cpp:313] Batch 223, accuracy/top5 = 0.84
I0629 14:07:41.877009 17196 caffe.cpp:313] Batch 223, loss = 1.93441
I0629 14:07:41.926923 17196 caffe.cpp:313] Batch 224, accuracy/top1 = 0.5
I0629 14:07:41.926945 17196 caffe.cpp:313] Batch 224, accuracy/top5 = 0.8
I0629 14:07:41.926949 17196 caffe.cpp:313] Batch 224, loss = 2.10954
I0629 14:07:41.975260 17196 caffe.cpp:313] Batch 225, accuracy/top1 = 0.58
I0629 14:07:41.975286 17196 caffe.cpp:313] Batch 225, accuracy/top5 = 0.86
I0629 14:07:41.975288 17196 caffe.cpp:313] Batch 225, loss = 1.653
I0629 14:07:42.025044 17196 caffe.cpp:313] Batch 226, accuracy/top1 = 0.64
I0629 14:07:42.025065 17196 caffe.cpp:313] Batch 226, accuracy/top5 = 0.82
I0629 14:07:42.025068 17196 caffe.cpp:313] Batch 226, loss = 1.69486
I0629 14:07:42.074810 17196 caffe.cpp:313] Batch 227, accuracy/top1 = 0.54
I0629 14:07:42.074834 17196 caffe.cpp:313] Batch 227, accuracy/top5 = 0.84
I0629 14:07:42.074837 17196 caffe.cpp:313] Batch 227, loss = 1.55013
I0629 14:07:42.124662 17196 caffe.cpp:313] Batch 228, accuracy/top1 = 0.64
I0629 14:07:42.124683 17196 caffe.cpp:313] Batch 228, accuracy/top5 = 0.8
I0629 14:07:42.124686 17196 caffe.cpp:313] Batch 228, loss = 1.56996
I0629 14:07:42.174324 17196 caffe.cpp:313] Batch 229, accuracy/top1 = 0.6
I0629 14:07:42.174347 17196 caffe.cpp:313] Batch 229, accuracy/top5 = 0.86
I0629 14:07:42.174350 17196 caffe.cpp:313] Batch 229, loss = 1.52314
I0629 14:07:42.224158 17196 caffe.cpp:313] Batch 230, accuracy/top1 = 0.72
I0629 14:07:42.224181 17196 caffe.cpp:313] Batch 230, accuracy/top5 = 0.88
I0629 14:07:42.224184 17196 caffe.cpp:313] Batch 230, loss = 1.30993
I0629 14:07:42.273305 17196 caffe.cpp:313] Batch 231, accuracy/top1 = 0.56
I0629 14:07:42.273325 17196 caffe.cpp:313] Batch 231, accuracy/top5 = 0.74
I0629 14:07:42.273329 17196 caffe.cpp:313] Batch 231, loss = 2.2402
I0629 14:07:42.322953 17196 caffe.cpp:313] Batch 232, accuracy/top1 = 0.5
I0629 14:07:42.322978 17196 caffe.cpp:313] Batch 232, accuracy/top5 = 0.78
I0629 14:07:42.322980 17196 caffe.cpp:313] Batch 232, loss = 1.69194
I0629 14:07:42.372014 17196 caffe.cpp:313] Batch 233, accuracy/top1 = 0.58
I0629 14:07:42.372038 17196 caffe.cpp:313] Batch 233, accuracy/top5 = 0.84
I0629 14:07:42.372041 17196 caffe.cpp:313] Batch 233, loss = 1.72511
I0629 14:07:42.421388 17196 caffe.cpp:313] Batch 234, accuracy/top1 = 0.64
I0629 14:07:42.421411 17196 caffe.cpp:313] Batch 234, accuracy/top5 = 0.8
I0629 14:07:42.421414 17196 caffe.cpp:313] Batch 234, loss = 2.00288
I0629 14:07:42.470654 17196 caffe.cpp:313] Batch 235, accuracy/top1 = 0.6
I0629 14:07:42.470690 17196 caffe.cpp:313] Batch 235, accuracy/top5 = 0.84
I0629 14:07:42.470695 17196 caffe.cpp:313] Batch 235, loss = 1.496
I0629 14:07:42.520279 17196 caffe.cpp:313] Batch 236, accuracy/top1 = 0.56
I0629 14:07:42.520303 17196 caffe.cpp:313] Batch 236, accuracy/top5 = 0.78
I0629 14:07:42.520305 17196 caffe.cpp:313] Batch 236, loss = 2.03157
I0629 14:07:42.569926 17196 caffe.cpp:313] Batch 237, accuracy/top1 = 0.54
I0629 14:07:42.569950 17196 caffe.cpp:313] Batch 237, accuracy/top5 = 0.88
I0629 14:07:42.569953 17196 caffe.cpp:313] Batch 237, loss = 1.46551
I0629 14:07:42.619428 17196 caffe.cpp:313] Batch 238, accuracy/top1 = 0.62
I0629 14:07:42.619451 17196 caffe.cpp:313] Batch 238, accuracy/top5 = 0.8
I0629 14:07:42.619454 17196 caffe.cpp:313] Batch 238, loss = 1.64235
I0629 14:07:42.669610 17196 caffe.cpp:313] Batch 239, accuracy/top1 = 0.58
I0629 14:07:42.669633 17196 caffe.cpp:313] Batch 239, accuracy/top5 = 0.88
I0629 14:07:42.669636 17196 caffe.cpp:313] Batch 239, loss = 1.41763
I0629 14:07:42.719208 17196 caffe.cpp:313] Batch 240, accuracy/top1 = 0.58
I0629 14:07:42.719228 17196 caffe.cpp:313] Batch 240, accuracy/top5 = 0.84
I0629 14:07:42.719230 17196 caffe.cpp:313] Batch 240, loss = 1.63415
I0629 14:07:42.768373 17196 caffe.cpp:313] Batch 241, accuracy/top1 = 0.5
I0629 14:07:42.768393 17196 caffe.cpp:313] Batch 241, accuracy/top5 = 0.76
I0629 14:07:42.768396 17196 caffe.cpp:313] Batch 241, loss = 2.18022
I0629 14:07:42.818651 17196 caffe.cpp:313] Batch 242, accuracy/top1 = 0.7
I0629 14:07:42.818671 17196 caffe.cpp:313] Batch 242, accuracy/top5 = 0.84
I0629 14:07:42.818675 17196 caffe.cpp:313] Batch 242, loss = 1.47515
I0629 14:07:42.867532 17196 caffe.cpp:313] Batch 243, accuracy/top1 = 0.52
I0629 14:07:42.867555 17196 caffe.cpp:313] Batch 243, accuracy/top5 = 0.76
I0629 14:07:42.867558 17196 caffe.cpp:313] Batch 243, loss = 1.93505
I0629 14:07:42.917068 17196 caffe.cpp:313] Batch 244, accuracy/top1 = 0.42
I0629 14:07:42.917090 17196 caffe.cpp:313] Batch 244, accuracy/top5 = 0.8
I0629 14:07:42.917093 17196 caffe.cpp:313] Batch 244, loss = 2.39924
I0629 14:07:42.967111 17196 caffe.cpp:313] Batch 245, accuracy/top1 = 0.44
I0629 14:07:42.967135 17196 caffe.cpp:313] Batch 245, accuracy/top5 = 0.72
I0629 14:07:42.967139 17196 caffe.cpp:313] Batch 245, loss = 2.45165
I0629 14:07:43.016947 17196 caffe.cpp:313] Batch 246, accuracy/top1 = 0.5
I0629 14:07:43.016969 17196 caffe.cpp:313] Batch 246, accuracy/top5 = 0.74
I0629 14:07:43.016973 17196 caffe.cpp:313] Batch 246, loss = 2.24687
I0629 14:07:43.067477 17196 caffe.cpp:313] Batch 247, accuracy/top1 = 0.42
I0629 14:07:43.067499 17196 caffe.cpp:313] Batch 247, accuracy/top5 = 0.7
I0629 14:07:43.067503 17196 caffe.cpp:313] Batch 247, loss = 2.47449
I0629 14:07:43.117327 17196 caffe.cpp:313] Batch 248, accuracy/top1 = 0.56
I0629 14:07:43.117350 17196 caffe.cpp:313] Batch 248, accuracy/top5 = 0.74
I0629 14:07:43.117353 17196 caffe.cpp:313] Batch 248, loss = 2.16261
I0629 14:07:43.167238 17196 caffe.cpp:313] Batch 249, accuracy/top1 = 0.48
I0629 14:07:43.167261 17196 caffe.cpp:313] Batch 249, accuracy/top5 = 0.8
I0629 14:07:43.167264 17196 caffe.cpp:313] Batch 249, loss = 2.0193
I0629 14:07:43.217504 17196 caffe.cpp:313] Batch 250, accuracy/top1 = 0.6
I0629 14:07:43.217526 17196 caffe.cpp:313] Batch 250, accuracy/top5 = 0.88
I0629 14:07:43.217530 17196 caffe.cpp:313] Batch 250, loss = 1.40868
I0629 14:07:43.267006 17196 caffe.cpp:313] Batch 251, accuracy/top1 = 0.6
I0629 14:07:43.267030 17196 caffe.cpp:313] Batch 251, accuracy/top5 = 0.82
I0629 14:07:43.267033 17196 caffe.cpp:313] Batch 251, loss = 1.66722
I0629 14:07:43.316563 17196 caffe.cpp:313] Batch 252, accuracy/top1 = 0.5
I0629 14:07:43.316587 17196 caffe.cpp:313] Batch 252, accuracy/top5 = 0.7
I0629 14:07:43.316591 17196 caffe.cpp:313] Batch 252, loss = 2.25455
I0629 14:07:43.366212 17196 caffe.cpp:313] Batch 253, accuracy/top1 = 0.44
I0629 14:07:43.366235 17196 caffe.cpp:313] Batch 253, accuracy/top5 = 0.8
I0629 14:07:43.366238 17196 caffe.cpp:313] Batch 253, loss = 2.08671
I0629 14:07:43.415693 17196 caffe.cpp:313] Batch 254, accuracy/top1 = 0.48
I0629 14:07:43.415730 17196 caffe.cpp:313] Batch 254, accuracy/top5 = 0.78
I0629 14:07:43.415735 17196 caffe.cpp:313] Batch 254, loss = 2.18199
I0629 14:07:43.465045 17196 caffe.cpp:313] Batch 255, accuracy/top1 = 0.56
I0629 14:07:43.465068 17196 caffe.cpp:313] Batch 255, accuracy/top5 = 0.76
I0629 14:07:43.465071 17196 caffe.cpp:313] Batch 255, loss = 2.31473
I0629 14:07:43.514995 17196 caffe.cpp:313] Batch 256, accuracy/top1 = 0.56
I0629 14:07:43.515018 17196 caffe.cpp:313] Batch 256, accuracy/top5 = 0.8
I0629 14:07:43.515022 17196 caffe.cpp:313] Batch 256, loss = 1.87991
I0629 14:07:43.565004 17196 caffe.cpp:313] Batch 257, accuracy/top1 = 0.58
I0629 14:07:43.565027 17196 caffe.cpp:313] Batch 257, accuracy/top5 = 0.78
I0629 14:07:43.565030 17196 caffe.cpp:313] Batch 257, loss = 2.11514
I0629 14:07:43.613978 17196 caffe.cpp:313] Batch 258, accuracy/top1 = 0.56
I0629 14:07:43.614002 17196 caffe.cpp:313] Batch 258, accuracy/top5 = 0.74
I0629 14:07:43.614006 17196 caffe.cpp:313] Batch 258, loss = 2.02619
I0629 14:07:43.663256 17196 caffe.cpp:313] Batch 259, accuracy/top1 = 0.46
I0629 14:07:43.663280 17196 caffe.cpp:313] Batch 259, accuracy/top5 = 0.76
I0629 14:07:43.663282 17196 caffe.cpp:313] Batch 259, loss = 2.18306
I0629 14:07:43.712297 17196 caffe.cpp:313] Batch 260, accuracy/top1 = 0.54
I0629 14:07:43.712321 17196 caffe.cpp:313] Batch 260, accuracy/top5 = 0.8
I0629 14:07:43.712324 17196 caffe.cpp:313] Batch 260, loss = 1.84508
I0629 14:07:43.762044 17196 caffe.cpp:313] Batch 261, accuracy/top1 = 0.54
I0629 14:07:43.762068 17196 caffe.cpp:313] Batch 261, accuracy/top5 = 0.78
I0629 14:07:43.762070 17196 caffe.cpp:313] Batch 261, loss = 1.96276
I0629 14:07:43.810927 17196 caffe.cpp:313] Batch 262, accuracy/top1 = 0.54
I0629 14:07:43.810952 17196 caffe.cpp:313] Batch 262, accuracy/top5 = 0.74
I0629 14:07:43.810956 17196 caffe.cpp:313] Batch 262, loss = 2.03191
I0629 14:07:43.860335 17196 caffe.cpp:313] Batch 263, accuracy/top1 = 0.58
I0629 14:07:43.860358 17196 caffe.cpp:313] Batch 263, accuracy/top5 = 0.82
I0629 14:07:43.860361 17196 caffe.cpp:313] Batch 263, loss = 1.75085
I0629 14:07:43.910425 17196 caffe.cpp:313] Batch 264, accuracy/top1 = 0.52
I0629 14:07:43.910449 17196 caffe.cpp:313] Batch 264, accuracy/top5 = 0.78
I0629 14:07:43.910452 17196 caffe.cpp:313] Batch 264, loss = 1.78007
I0629 14:07:43.959554 17196 caffe.cpp:313] Batch 265, accuracy/top1 = 0.68
I0629 14:07:43.959578 17196 caffe.cpp:313] Batch 265, accuracy/top5 = 0.84
I0629 14:07:43.959581 17196 caffe.cpp:313] Batch 265, loss = 1.65214
I0629 14:07:44.008844 17196 caffe.cpp:313] Batch 266, accuracy/top1 = 0.6
I0629 14:07:44.008867 17196 caffe.cpp:313] Batch 266, accuracy/top5 = 0.76
I0629 14:07:44.008870 17196 caffe.cpp:313] Batch 266, loss = 1.84358
I0629 14:07:44.057418 17196 caffe.cpp:313] Batch 267, accuracy/top1 = 0.68
I0629 14:07:44.057440 17196 caffe.cpp:313] Batch 267, accuracy/top5 = 0.86
I0629 14:07:44.057442 17196 caffe.cpp:313] Batch 267, loss = 1.53314
I0629 14:07:44.106662 17196 caffe.cpp:313] Batch 268, accuracy/top1 = 0.6
I0629 14:07:44.106685 17196 caffe.cpp:313] Batch 268, accuracy/top5 = 0.76
I0629 14:07:44.106688 17196 caffe.cpp:313] Batch 268, loss = 1.98526
I0629 14:07:44.156494 17196 caffe.cpp:313] Batch 269, accuracy/top1 = 0.58
I0629 14:07:44.156512 17196 caffe.cpp:313] Batch 269, accuracy/top5 = 0.8
I0629 14:07:44.156515 17196 caffe.cpp:313] Batch 269, loss = 1.71116
I0629 14:07:44.205948 17196 caffe.cpp:313] Batch 270, accuracy/top1 = 0.44
I0629 14:07:44.205971 17196 caffe.cpp:313] Batch 270, accuracy/top5 = 0.76
I0629 14:07:44.205973 17196 caffe.cpp:313] Batch 270, loss = 2.23186
I0629 14:07:44.255868 17196 caffe.cpp:313] Batch 271, accuracy/top1 = 0.52
I0629 14:07:44.255892 17196 caffe.cpp:313] Batch 271, accuracy/top5 = 0.74
I0629 14:07:44.255895 17196 caffe.cpp:313] Batch 271, loss = 2.48491
I0629 14:07:44.305265 17196 caffe.cpp:313] Batch 272, accuracy/top1 = 0.5
I0629 14:07:44.305284 17196 caffe.cpp:313] Batch 272, accuracy/top5 = 0.8
I0629 14:07:44.305286 17196 caffe.cpp:313] Batch 272, loss = 2.1507
I0629 14:07:44.355494 17196 caffe.cpp:313] Batch 273, accuracy/top1 = 0.58
I0629 14:07:44.355517 17196 caffe.cpp:313] Batch 273, accuracy/top5 = 0.82
I0629 14:07:44.355520 17196 caffe.cpp:313] Batch 273, loss = 1.74874
I0629 14:07:44.404908 17196 caffe.cpp:313] Batch 274, accuracy/top1 = 0.54
I0629 14:07:44.404932 17196 caffe.cpp:313] Batch 274, accuracy/top5 = 0.78
I0629 14:07:44.404935 17196 caffe.cpp:313] Batch 274, loss = 2.00753
I0629 14:07:44.453590 17196 caffe.cpp:313] Batch 275, accuracy/top1 = 0.64
I0629 14:07:44.453613 17196 caffe.cpp:313] Batch 275, accuracy/top5 = 0.84
I0629 14:07:44.453615 17196 caffe.cpp:313] Batch 275, loss = 1.70664
I0629 14:07:44.503566 17196 caffe.cpp:313] Batch 276, accuracy/top1 = 0.6
I0629 14:07:44.503588 17196 caffe.cpp:313] Batch 276, accuracy/top5 = 0.82
I0629 14:07:44.503592 17196 caffe.cpp:313] Batch 276, loss = 1.6178
I0629 14:07:44.553004 17196 caffe.cpp:313] Batch 277, accuracy/top1 = 0.58
I0629 14:07:44.553027 17196 caffe.cpp:313] Batch 277, accuracy/top5 = 0.78
I0629 14:07:44.553030 17196 caffe.cpp:313] Batch 277, loss = 1.85163
I0629 14:07:44.603361 17196 caffe.cpp:313] Batch 278, accuracy/top1 = 0.46
I0629 14:07:44.603385 17196 caffe.cpp:313] Batch 278, accuracy/top5 = 0.74
I0629 14:07:44.603389 17196 caffe.cpp:313] Batch 278, loss = 2.38922
I0629 14:07:44.652469 17196 caffe.cpp:313] Batch 279, accuracy/top1 = 0.54
I0629 14:07:44.652493 17196 caffe.cpp:313] Batch 279, accuracy/top5 = 0.72
I0629 14:07:44.652496 17196 caffe.cpp:313] Batch 279, loss = 2.30962
I0629 14:07:44.702200 17196 caffe.cpp:313] Batch 280, accuracy/top1 = 0.5
I0629 14:07:44.702225 17196 caffe.cpp:313] Batch 280, accuracy/top5 = 0.86
I0629 14:07:44.702229 17196 caffe.cpp:313] Batch 280, loss = 1.84143
I0629 14:07:44.751561 17196 caffe.cpp:313] Batch 281, accuracy/top1 = 0.58
I0629 14:07:44.751585 17196 caffe.cpp:313] Batch 281, accuracy/top5 = 0.9
I0629 14:07:44.751588 17196 caffe.cpp:313] Batch 281, loss = 2.07091
I0629 14:07:44.800846 17196 caffe.cpp:313] Batch 282, accuracy/top1 = 0.62
I0629 14:07:44.800870 17196 caffe.cpp:313] Batch 282, accuracy/top5 = 0.82
I0629 14:07:44.800873 17196 caffe.cpp:313] Batch 282, loss = 1.61848
I0629 14:07:44.849436 17196 caffe.cpp:313] Batch 283, accuracy/top1 = 0.54
I0629 14:07:44.849457 17196 caffe.cpp:313] Batch 283, accuracy/top5 = 0.76
I0629 14:07:44.849459 17196 caffe.cpp:313] Batch 283, loss = 2.06892
I0629 14:07:44.899673 17196 caffe.cpp:313] Batch 284, accuracy/top1 = 0.58
I0629 14:07:44.899695 17196 caffe.cpp:313] Batch 284, accuracy/top5 = 0.74
I0629 14:07:44.899698 17196 caffe.cpp:313] Batch 284, loss = 1.97181
I0629 14:07:44.948653 17196 caffe.cpp:313] Batch 285, accuracy/top1 = 0.6
I0629 14:07:44.948673 17196 caffe.cpp:313] Batch 285, accuracy/top5 = 0.88
I0629 14:07:44.948678 17196 caffe.cpp:313] Batch 285, loss = 1.62102
I0629 14:07:44.996963 17196 caffe.cpp:313] Batch 286, accuracy/top1 = 0.58
I0629 14:07:44.996986 17196 caffe.cpp:313] Batch 286, accuracy/top5 = 0.78
I0629 14:07:44.996989 17196 caffe.cpp:313] Batch 286, loss = 1.70601
I0629 14:07:45.046291 17196 caffe.cpp:313] Batch 287, accuracy/top1 = 0.52
I0629 14:07:45.046314 17196 caffe.cpp:313] Batch 287, accuracy/top5 = 0.72
I0629 14:07:45.046315 17196 caffe.cpp:313] Batch 287, loss = 2.30749
I0629 14:07:45.095367 17196 caffe.cpp:313] Batch 288, accuracy/top1 = 0.6
I0629 14:07:45.095391 17196 caffe.cpp:313] Batch 288, accuracy/top5 = 0.82
I0629 14:07:45.095394 17196 caffe.cpp:313] Batch 288, loss = 2.04237
I0629 14:07:45.146077 17196 caffe.cpp:313] Batch 289, accuracy/top1 = 0.56
I0629 14:07:45.146096 17196 caffe.cpp:313] Batch 289, accuracy/top5 = 0.82
I0629 14:07:45.146100 17196 caffe.cpp:313] Batch 289, loss = 1.84839
I0629 14:07:45.195190 17196 caffe.cpp:313] Batch 290, accuracy/top1 = 0.54
I0629 14:07:45.195214 17196 caffe.cpp:313] Batch 290, accuracy/top5 = 0.8
I0629 14:07:45.195217 17196 caffe.cpp:313] Batch 290, loss = 1.99588
I0629 14:07:45.244724 17196 caffe.cpp:313] Batch 291, accuracy/top1 = 0.52
I0629 14:07:45.244747 17196 caffe.cpp:313] Batch 291, accuracy/top5 = 0.76
I0629 14:07:45.244767 17196 caffe.cpp:313] Batch 291, loss = 2.30247
I0629 14:07:45.294490 17196 caffe.cpp:313] Batch 292, accuracy/top1 = 0.6
I0629 14:07:45.294513 17196 caffe.cpp:313] Batch 292, accuracy/top5 = 0.82
I0629 14:07:45.294517 17196 caffe.cpp:313] Batch 292, loss = 1.90121
I0629 14:07:45.344643 17196 caffe.cpp:313] Batch 293, accuracy/top1 = 0.64
I0629 14:07:45.344667 17196 caffe.cpp:313] Batch 293, accuracy/top5 = 0.86
I0629 14:07:45.344671 17196 caffe.cpp:313] Batch 293, loss = 1.61638
I0629 14:07:45.393406 17196 caffe.cpp:313] Batch 294, accuracy/top1 = 0.74
I0629 14:07:45.393430 17196 caffe.cpp:313] Batch 294, accuracy/top5 = 0.96
I0629 14:07:45.393434 17196 caffe.cpp:313] Batch 294, loss = 0.805114
I0629 14:07:45.443164 17196 caffe.cpp:313] Batch 295, accuracy/top1 = 0.52
I0629 14:07:45.443188 17196 caffe.cpp:313] Batch 295, accuracy/top5 = 0.74
I0629 14:07:45.443192 17196 caffe.cpp:313] Batch 295, loss = 2.08289
I0629 14:07:45.492547 17196 caffe.cpp:313] Batch 296, accuracy/top1 = 0.6
I0629 14:07:45.492569 17196 caffe.cpp:313] Batch 296, accuracy/top5 = 0.86
I0629 14:07:45.492573 17196 caffe.cpp:313] Batch 296, loss = 1.29946
I0629 14:07:45.542024 17196 caffe.cpp:313] Batch 297, accuracy/top1 = 0.56
I0629 14:07:45.542049 17196 caffe.cpp:313] Batch 297, accuracy/top5 = 0.8
I0629 14:07:45.542052 17196 caffe.cpp:313] Batch 297, loss = 1.52178
I0629 14:07:45.590693 17196 caffe.cpp:313] Batch 298, accuracy/top1 = 0.56
I0629 14:07:45.590718 17196 caffe.cpp:313] Batch 298, accuracy/top5 = 0.78
I0629 14:07:45.590720 17196 caffe.cpp:313] Batch 298, loss = 1.99755
I0629 14:07:45.639044 17196 caffe.cpp:313] Batch 299, accuracy/top1 = 0.46
I0629 14:07:45.639066 17196 caffe.cpp:313] Batch 299, accuracy/top5 = 0.72
I0629 14:07:45.639070 17196 caffe.cpp:313] Batch 299, loss = 2.35949
I0629 14:07:45.687862 17196 caffe.cpp:313] Batch 300, accuracy/top1 = 0.5
I0629 14:07:45.687886 17196 caffe.cpp:313] Batch 300, accuracy/top5 = 0.64
I0629 14:07:45.687889 17196 caffe.cpp:313] Batch 300, loss = 2.45572
I0629 14:07:45.736692 17196 caffe.cpp:313] Batch 301, accuracy/top1 = 0.48
I0629 14:07:45.736717 17196 caffe.cpp:313] Batch 301, accuracy/top5 = 0.72
I0629 14:07:45.736721 17196 caffe.cpp:313] Batch 301, loss = 2.49146
I0629 14:07:45.785531 17196 caffe.cpp:313] Batch 302, accuracy/top1 = 0.68
I0629 14:07:45.785562 17196 caffe.cpp:313] Batch 302, accuracy/top5 = 0.82
I0629 14:07:45.785565 17196 caffe.cpp:313] Batch 302, loss = 1.61467
I0629 14:07:45.835343 17196 caffe.cpp:313] Batch 303, accuracy/top1 = 0.58
I0629 14:07:45.835368 17196 caffe.cpp:313] Batch 303, accuracy/top5 = 0.86
I0629 14:07:45.835371 17196 caffe.cpp:313] Batch 303, loss = 1.5208
I0629 14:07:45.883977 17196 caffe.cpp:313] Batch 304, accuracy/top1 = 0.64
I0629 14:07:45.884002 17196 caffe.cpp:313] Batch 304, accuracy/top5 = 0.86
I0629 14:07:45.884006 17196 caffe.cpp:313] Batch 304, loss = 1.61745
I0629 14:07:45.934619 17196 caffe.cpp:313] Batch 305, accuracy/top1 = 0.66
I0629 14:07:45.934641 17196 caffe.cpp:313] Batch 305, accuracy/top5 = 0.82
I0629 14:07:45.934644 17196 caffe.cpp:313] Batch 305, loss = 1.31921
I0629 14:07:45.983189 17196 caffe.cpp:313] Batch 306, accuracy/top1 = 0.72
I0629 14:07:45.983212 17196 caffe.cpp:313] Batch 306, accuracy/top5 = 0.86
I0629 14:07:45.983216 17196 caffe.cpp:313] Batch 306, loss = 1.39341
I0629 14:07:46.032701 17196 caffe.cpp:313] Batch 307, accuracy/top1 = 0.62
I0629 14:07:46.032721 17196 caffe.cpp:313] Batch 307, accuracy/top5 = 0.82
I0629 14:07:46.032724 17196 caffe.cpp:313] Batch 307, loss = 1.64894
I0629 14:07:46.080842 17196 caffe.cpp:313] Batch 308, accuracy/top1 = 0.74
I0629 14:07:46.080866 17196 caffe.cpp:313] Batch 308, accuracy/top5 = 0.84
I0629 14:07:46.080869 17196 caffe.cpp:313] Batch 308, loss = 1.45605
I0629 14:07:46.131613 17196 caffe.cpp:313] Batch 309, accuracy/top1 = 0.54
I0629 14:07:46.131629 17196 caffe.cpp:313] Batch 309, accuracy/top5 = 0.82
I0629 14:07:46.131633 17196 caffe.cpp:313] Batch 309, loss = 1.87425
I0629 14:07:46.181601 17196 caffe.cpp:313] Batch 310, accuracy/top1 = 0.66
I0629 14:07:46.181638 17196 caffe.cpp:313] Batch 310, accuracy/top5 = 0.84
I0629 14:07:46.181643 17196 caffe.cpp:313] Batch 310, loss = 1.42058
I0629 14:07:46.229533 17196 caffe.cpp:313] Batch 311, accuracy/top1 = 0.56
I0629 14:07:46.229583 17196 caffe.cpp:313] Batch 311, accuracy/top5 = 0.74
I0629 14:07:46.229586 17196 caffe.cpp:313] Batch 311, loss = 2.42308
I0629 14:07:46.279690 17196 caffe.cpp:313] Batch 312, accuracy/top1 = 0.64
I0629 14:07:46.279712 17196 caffe.cpp:313] Batch 312, accuracy/top5 = 0.8
I0629 14:07:46.279716 17196 caffe.cpp:313] Batch 312, loss = 1.83074
I0629 14:07:46.329192 17196 caffe.cpp:313] Batch 313, accuracy/top1 = 0.6
I0629 14:07:46.329211 17196 caffe.cpp:313] Batch 313, accuracy/top5 = 0.82
I0629 14:07:46.329215 17196 caffe.cpp:313] Batch 313, loss = 1.82585
I0629 14:07:46.378034 17196 caffe.cpp:313] Batch 314, accuracy/top1 = 0.64
I0629 14:07:46.378057 17196 caffe.cpp:313] Batch 314, accuracy/top5 = 0.9
I0629 14:07:46.378059 17196 caffe.cpp:313] Batch 314, loss = 1.45378
I0629 14:07:46.426641 17196 caffe.cpp:313] Batch 315, accuracy/top1 = 0.6
I0629 14:07:46.426666 17196 caffe.cpp:313] Batch 315, accuracy/top5 = 0.84
I0629 14:07:46.426671 17196 caffe.cpp:313] Batch 315, loss = 1.88612
I0629 14:07:46.475800 17196 caffe.cpp:313] Batch 316, accuracy/top1 = 0.62
I0629 14:07:46.475824 17196 caffe.cpp:313] Batch 316, accuracy/top5 = 0.8
I0629 14:07:46.475827 17196 caffe.cpp:313] Batch 316, loss = 1.92204
I0629 14:07:46.525071 17196 caffe.cpp:313] Batch 317, accuracy/top1 = 0.6
I0629 14:07:46.525095 17196 caffe.cpp:313] Batch 317, accuracy/top5 = 0.82
I0629 14:07:46.525099 17196 caffe.cpp:313] Batch 317, loss = 1.5519
I0629 14:07:46.574389 17196 caffe.cpp:313] Batch 318, accuracy/top1 = 0.6
I0629 14:07:46.574414 17196 caffe.cpp:313] Batch 318, accuracy/top5 = 0.76
I0629 14:07:46.574417 17196 caffe.cpp:313] Batch 318, loss = 2.01125
I0629 14:07:46.623714 17196 caffe.cpp:313] Batch 319, accuracy/top1 = 0.54
I0629 14:07:46.623739 17196 caffe.cpp:313] Batch 319, accuracy/top5 = 0.8
I0629 14:07:46.623741 17196 caffe.cpp:313] Batch 319, loss = 1.73189
I0629 14:07:46.672855 17196 caffe.cpp:313] Batch 320, accuracy/top1 = 0.5
I0629 14:07:46.672880 17196 caffe.cpp:313] Batch 320, accuracy/top5 = 0.78
I0629 14:07:46.672883 17196 caffe.cpp:313] Batch 320, loss = 2.01936
I0629 14:07:46.722733 17196 caffe.cpp:313] Batch 321, accuracy/top1 = 0.58
I0629 14:07:46.722756 17196 caffe.cpp:313] Batch 321, accuracy/top5 = 0.78
I0629 14:07:46.722759 17196 caffe.cpp:313] Batch 321, loss = 2.11346
I0629 14:07:46.771893 17196 caffe.cpp:313] Batch 322, accuracy/top1 = 0.64
I0629 14:07:46.771916 17196 caffe.cpp:313] Batch 322, accuracy/top5 = 0.9
I0629 14:07:46.771919 17196 caffe.cpp:313] Batch 322, loss = 1.40395
I0629 14:07:46.821894 17196 caffe.cpp:313] Batch 323, accuracy/top1 = 0.6
I0629 14:07:46.821919 17196 caffe.cpp:313] Batch 323, accuracy/top5 = 0.76
I0629 14:07:46.821923 17196 caffe.cpp:313] Batch 323, loss = 2.05749
I0629 14:07:46.870872 17196 caffe.cpp:313] Batch 324, accuracy/top1 = 0.5
I0629 14:07:46.870898 17196 caffe.cpp:313] Batch 324, accuracy/top5 = 0.68
I0629 14:07:46.870900 17196 caffe.cpp:313] Batch 324, loss = 2.127
I0629 14:07:46.920578 17196 caffe.cpp:313] Batch 325, accuracy/top1 = 0.64
I0629 14:07:46.920600 17196 caffe.cpp:313] Batch 325, accuracy/top5 = 0.74
I0629 14:07:46.920603 17196 caffe.cpp:313] Batch 325, loss = 1.86555
I0629 14:07:46.969851 17196 caffe.cpp:313] Batch 326, accuracy/top1 = 0.52
I0629 14:07:46.969872 17196 caffe.cpp:313] Batch 326, accuracy/top5 = 0.82
I0629 14:07:46.969876 17196 caffe.cpp:313] Batch 326, loss = 1.84248
I0629 14:07:47.019387 17196 caffe.cpp:313] Batch 327, accuracy/top1 = 0.52
I0629 14:07:47.019407 17196 caffe.cpp:313] Batch 327, accuracy/top5 = 0.7
I0629 14:07:47.019409 17196 caffe.cpp:313] Batch 327, loss = 2.11158
I0629 14:07:47.069079 17196 caffe.cpp:313] Batch 328, accuracy/top1 = 0.48
I0629 14:07:47.069100 17196 caffe.cpp:313] Batch 328, accuracy/top5 = 0.8
I0629 14:07:47.069103 17196 caffe.cpp:313] Batch 328, loss = 1.83001
I0629 14:07:47.118283 17196 caffe.cpp:313] Batch 329, accuracy/top1 = 0.48
I0629 14:07:47.118320 17196 caffe.cpp:313] Batch 329, accuracy/top5 = 0.8
I0629 14:07:47.118324 17196 caffe.cpp:313] Batch 329, loss = 1.90314
I0629 14:07:47.165849 17196 caffe.cpp:313] Batch 330, accuracy/top1 = 0.52
I0629 14:07:47.165868 17196 caffe.cpp:313] Batch 330, accuracy/top5 = 0.82
I0629 14:07:47.165870 17196 caffe.cpp:313] Batch 330, loss = 1.7868
I0629 14:07:47.214881 17196 caffe.cpp:313] Batch 331, accuracy/top1 = 0.54
I0629 14:07:47.214905 17196 caffe.cpp:313] Batch 331, accuracy/top5 = 0.8
I0629 14:07:47.214908 17196 caffe.cpp:313] Batch 331, loss = 1.96117
I0629 14:07:47.264765 17196 caffe.cpp:313] Batch 332, accuracy/top1 = 0.62
I0629 14:07:47.264787 17196 caffe.cpp:313] Batch 332, accuracy/top5 = 0.86
I0629 14:07:47.264791 17196 caffe.cpp:313] Batch 332, loss = 1.87409
I0629 14:07:47.313720 17196 caffe.cpp:313] Batch 333, accuracy/top1 = 0.58
I0629 14:07:47.313743 17196 caffe.cpp:313] Batch 333, accuracy/top5 = 0.82
I0629 14:07:47.313746 17196 caffe.cpp:313] Batch 333, loss = 1.91477
I0629 14:07:47.363239 17196 caffe.cpp:313] Batch 334, accuracy/top1 = 0.7
I0629 14:07:47.363261 17196 caffe.cpp:313] Batch 334, accuracy/top5 = 0.9
I0629 14:07:47.363265 17196 caffe.cpp:313] Batch 334, loss = 1.10774
I0629 14:07:47.413449 17196 caffe.cpp:313] Batch 335, accuracy/top1 = 0.54
I0629 14:07:47.413472 17196 caffe.cpp:313] Batch 335, accuracy/top5 = 0.78
I0629 14:07:47.413475 17196 caffe.cpp:313] Batch 335, loss = 1.98703
I0629 14:07:47.464448 17196 caffe.cpp:313] Batch 336, accuracy/top1 = 0.68
I0629 14:07:47.464473 17196 caffe.cpp:313] Batch 336, accuracy/top5 = 0.88
I0629 14:07:47.464475 17196 caffe.cpp:313] Batch 336, loss = 1.30555
I0629 14:07:47.514133 17196 caffe.cpp:313] Batch 337, accuracy/top1 = 0.66
I0629 14:07:47.514158 17196 caffe.cpp:313] Batch 337, accuracy/top5 = 0.82
I0629 14:07:47.514160 17196 caffe.cpp:313] Batch 337, loss = 1.54954
I0629 14:07:47.563349 17196 caffe.cpp:313] Batch 338, accuracy/top1 = 0.58
I0629 14:07:47.563374 17196 caffe.cpp:313] Batch 338, accuracy/top5 = 0.86
I0629 14:07:47.563376 17196 caffe.cpp:313] Batch 338, loss = 1.83531
I0629 14:07:47.612046 17196 caffe.cpp:313] Batch 339, accuracy/top1 = 0.66
I0629 14:07:47.612069 17196 caffe.cpp:313] Batch 339, accuracy/top5 = 0.82
I0629 14:07:47.612072 17196 caffe.cpp:313] Batch 339, loss = 1.56218
I0629 14:07:47.661290 17196 caffe.cpp:313] Batch 340, accuracy/top1 = 0.54
I0629 14:07:47.661314 17196 caffe.cpp:313] Batch 340, accuracy/top5 = 0.78
I0629 14:07:47.661317 17196 caffe.cpp:313] Batch 340, loss = 2.31244
I0629 14:07:47.711302 17196 caffe.cpp:313] Batch 341, accuracy/top1 = 0.6
I0629 14:07:47.711325 17196 caffe.cpp:313] Batch 341, accuracy/top5 = 0.82
I0629 14:07:47.711328 17196 caffe.cpp:313] Batch 341, loss = 1.75384
I0629 14:07:47.760023 17196 caffe.cpp:313] Batch 342, accuracy/top1 = 0.6
I0629 14:07:47.760046 17196 caffe.cpp:313] Batch 342, accuracy/top5 = 0.8
I0629 14:07:47.760049 17196 caffe.cpp:313] Batch 342, loss = 1.9296
I0629 14:07:47.809746 17196 caffe.cpp:313] Batch 343, accuracy/top1 = 0.6
I0629 14:07:47.809770 17196 caffe.cpp:313] Batch 343, accuracy/top5 = 0.78
I0629 14:07:47.809773 17196 caffe.cpp:313] Batch 343, loss = 1.86399
I0629 14:07:47.859294 17196 caffe.cpp:313] Batch 344, accuracy/top1 = 0.52
I0629 14:07:47.859318 17196 caffe.cpp:313] Batch 344, accuracy/top5 = 0.82
I0629 14:07:47.859320 17196 caffe.cpp:313] Batch 344, loss = 1.74785
I0629 14:07:47.908959 17196 caffe.cpp:313] Batch 345, accuracy/top1 = 0.56
I0629 14:07:47.908983 17196 caffe.cpp:313] Batch 345, accuracy/top5 = 0.84
I0629 14:07:47.908987 17196 caffe.cpp:313] Batch 345, loss = 1.65847
I0629 14:07:47.958324 17196 caffe.cpp:313] Batch 346, accuracy/top1 = 0.44
I0629 14:07:47.958348 17196 caffe.cpp:313] Batch 346, accuracy/top5 = 0.64
I0629 14:07:47.958350 17196 caffe.cpp:313] Batch 346, loss = 2.68236
I0629 14:07:48.008149 17196 caffe.cpp:313] Batch 347, accuracy/top1 = 0.62
I0629 14:07:48.008172 17196 caffe.cpp:313] Batch 347, accuracy/top5 = 0.84
I0629 14:07:48.008175 17196 caffe.cpp:313] Batch 347, loss = 1.51264
I0629 14:07:48.058127 17196 caffe.cpp:313] Batch 348, accuracy/top1 = 0.64
I0629 14:07:48.058151 17196 caffe.cpp:313] Batch 348, accuracy/top5 = 0.88
I0629 14:07:48.058154 17196 caffe.cpp:313] Batch 348, loss = 1.30119
I0629 14:07:48.107234 17196 caffe.cpp:313] Batch 349, accuracy/top1 = 0.54
I0629 14:07:48.107257 17196 caffe.cpp:313] Batch 349, accuracy/top5 = 0.78
I0629 14:07:48.107260 17196 caffe.cpp:313] Batch 349, loss = 2.2887
I0629 14:07:48.156776 17196 caffe.cpp:313] Batch 350, accuracy/top1 = 0.68
I0629 14:07:48.156795 17196 caffe.cpp:313] Batch 350, accuracy/top5 = 0.86
I0629 14:07:48.156798 17196 caffe.cpp:313] Batch 350, loss = 1.50892
I0629 14:07:48.205492 17196 caffe.cpp:313] Batch 351, accuracy/top1 = 0.56
I0629 14:07:48.205518 17196 caffe.cpp:313] Batch 351, accuracy/top5 = 0.88
I0629 14:07:48.205520 17196 caffe.cpp:313] Batch 351, loss = 1.59011
I0629 14:07:48.255322 17196 caffe.cpp:313] Batch 352, accuracy/top1 = 0.6
I0629 14:07:48.255345 17196 caffe.cpp:313] Batch 352, accuracy/top5 = 0.66
I0629 14:07:48.255348 17196 caffe.cpp:313] Batch 352, loss = 2.35864
I0629 14:07:48.304971 17196 caffe.cpp:313] Batch 353, accuracy/top1 = 0.6
I0629 14:07:48.304994 17196 caffe.cpp:313] Batch 353, accuracy/top5 = 0.78
I0629 14:07:48.304997 17196 caffe.cpp:313] Batch 353, loss = 1.93682
I0629 14:07:48.354925 17196 caffe.cpp:313] Batch 354, accuracy/top1 = 0.6
I0629 14:07:48.354944 17196 caffe.cpp:313] Batch 354, accuracy/top5 = 0.76
I0629 14:07:48.354948 17196 caffe.cpp:313] Batch 354, loss = 2.25077
I0629 14:07:48.404247 17196 caffe.cpp:313] Batch 355, accuracy/top1 = 0.64
I0629 14:07:48.404269 17196 caffe.cpp:313] Batch 355, accuracy/top5 = 0.78
I0629 14:07:48.404273 17196 caffe.cpp:313] Batch 355, loss = 1.94306
I0629 14:07:48.453457 17196 caffe.cpp:313] Batch 356, accuracy/top1 = 0.64
I0629 14:07:48.453481 17196 caffe.cpp:313] Batch 356, accuracy/top5 = 0.78
I0629 14:07:48.453485 17196 caffe.cpp:313] Batch 356, loss = 2.0719
I0629 14:07:48.502374 17196 caffe.cpp:313] Batch 357, accuracy/top1 = 0.64
I0629 14:07:48.502398 17196 caffe.cpp:313] Batch 357, accuracy/top5 = 0.88
I0629 14:07:48.502401 17196 caffe.cpp:313] Batch 357, loss = 1.32856
I0629 14:07:48.551177 17196 caffe.cpp:313] Batch 358, accuracy/top1 = 0.54
I0629 14:07:48.551200 17196 caffe.cpp:313] Batch 358, accuracy/top5 = 0.74
I0629 14:07:48.551203 17196 caffe.cpp:313] Batch 358, loss = 2.09963
I0629 14:07:48.602064 17196 caffe.cpp:313] Batch 359, accuracy/top1 = 0.54
I0629 14:07:48.602087 17196 caffe.cpp:313] Batch 359, accuracy/top5 = 0.76
I0629 14:07:48.602090 17196 caffe.cpp:313] Batch 359, loss = 2.34511
I0629 14:07:48.650653 17196 caffe.cpp:313] Batch 360, accuracy/top1 = 0.62
I0629 14:07:48.650676 17196 caffe.cpp:313] Batch 360, accuracy/top5 = 0.86
I0629 14:07:48.650679 17196 caffe.cpp:313] Batch 360, loss = 1.88321
I0629 14:07:48.700053 17196 caffe.cpp:313] Batch 361, accuracy/top1 = 0.54
I0629 14:07:48.700078 17196 caffe.cpp:313] Batch 361, accuracy/top5 = 0.78
I0629 14:07:48.700080 17196 caffe.cpp:313] Batch 361, loss = 1.82035
I0629 14:07:48.749951 17196 caffe.cpp:313] Batch 362, accuracy/top1 = 0.54
I0629 14:07:48.749975 17196 caffe.cpp:313] Batch 362, accuracy/top5 = 0.78
I0629 14:07:48.749979 17196 caffe.cpp:313] Batch 362, loss = 2.05968
I0629 14:07:48.799051 17196 caffe.cpp:313] Batch 363, accuracy/top1 = 0.56
I0629 14:07:48.799074 17196 caffe.cpp:313] Batch 363, accuracy/top5 = 0.8
I0629 14:07:48.799077 17196 caffe.cpp:313] Batch 363, loss = 1.90402
I0629 14:07:48.849402 17196 caffe.cpp:313] Batch 364, accuracy/top1 = 0.6
I0629 14:07:48.849426 17196 caffe.cpp:313] Batch 364, accuracy/top5 = 0.8
I0629 14:07:48.849428 17196 caffe.cpp:313] Batch 364, loss = 1.55279
I0629 14:07:48.899391 17196 caffe.cpp:313] Batch 365, accuracy/top1 = 0.56
I0629 14:07:48.899415 17196 caffe.cpp:313] Batch 365, accuracy/top5 = 0.82
I0629 14:07:48.899418 17196 caffe.cpp:313] Batch 365, loss = 2.03115
I0629 14:07:48.949580 17196 caffe.cpp:313] Batch 366, accuracy/top1 = 0.54
I0629 14:07:48.949604 17196 caffe.cpp:313] Batch 366, accuracy/top5 = 0.78
I0629 14:07:48.949621 17196 caffe.cpp:313] Batch 366, loss = 2.02422
I0629 14:07:48.999886 17196 caffe.cpp:313] Batch 367, accuracy/top1 = 0.62
I0629 14:07:48.999910 17196 caffe.cpp:313] Batch 367, accuracy/top5 = 0.8
I0629 14:07:48.999913 17196 caffe.cpp:313] Batch 367, loss = 1.56851
I0629 14:07:49.049981 17196 caffe.cpp:313] Batch 368, accuracy/top1 = 0.5
I0629 14:07:49.050004 17196 caffe.cpp:313] Batch 368, accuracy/top5 = 0.86
I0629 14:07:49.050006 17196 caffe.cpp:313] Batch 368, loss = 1.95581
I0629 14:07:49.099205 17196 caffe.cpp:313] Batch 369, accuracy/top1 = 0.58
I0629 14:07:49.099225 17196 caffe.cpp:313] Batch 369, accuracy/top5 = 0.8
I0629 14:07:49.099227 17196 caffe.cpp:313] Batch 369, loss = 1.78622
I0629 14:07:49.147811 17196 caffe.cpp:313] Batch 370, accuracy/top1 = 0.66
I0629 14:07:49.147832 17196 caffe.cpp:313] Batch 370, accuracy/top5 = 0.82
I0629 14:07:49.147835 17196 caffe.cpp:313] Batch 370, loss = 1.91942
I0629 14:07:49.196930 17196 caffe.cpp:313] Batch 371, accuracy/top1 = 0.64
I0629 14:07:49.196952 17196 caffe.cpp:313] Batch 371, accuracy/top5 = 0.8
I0629 14:07:49.196955 17196 caffe.cpp:313] Batch 371, loss = 1.68813
I0629 14:07:49.246330 17196 caffe.cpp:313] Batch 372, accuracy/top1 = 0.64
I0629 14:07:49.246351 17196 caffe.cpp:313] Batch 372, accuracy/top5 = 0.74
I0629 14:07:49.246354 17196 caffe.cpp:313] Batch 372, loss = 1.87781
I0629 14:07:49.294479 17196 caffe.cpp:313] Batch 373, accuracy/top1 = 0.46
I0629 14:07:49.294504 17196 caffe.cpp:313] Batch 373, accuracy/top5 = 0.78
I0629 14:07:49.294507 17196 caffe.cpp:313] Batch 373, loss = 2.51155
I0629 14:07:49.343955 17196 caffe.cpp:313] Batch 374, accuracy/top1 = 0.58
I0629 14:07:49.343978 17196 caffe.cpp:313] Batch 374, accuracy/top5 = 0.78
I0629 14:07:49.343981 17196 caffe.cpp:313] Batch 374, loss = 1.67903
I0629 14:07:49.393412 17196 caffe.cpp:313] Batch 375, accuracy/top1 = 0.64
I0629 14:07:49.393435 17196 caffe.cpp:313] Batch 375, accuracy/top5 = 0.82
I0629 14:07:49.393438 17196 caffe.cpp:313] Batch 375, loss = 1.72467
I0629 14:07:49.442628 17196 caffe.cpp:313] Batch 376, accuracy/top1 = 0.54
I0629 14:07:49.442652 17196 caffe.cpp:313] Batch 376, accuracy/top5 = 0.84
I0629 14:07:49.442656 17196 caffe.cpp:313] Batch 376, loss = 1.67452
I0629 14:07:49.492344 17196 caffe.cpp:313] Batch 377, accuracy/top1 = 0.56
I0629 14:07:49.492367 17196 caffe.cpp:313] Batch 377, accuracy/top5 = 0.8
I0629 14:07:49.492369 17196 caffe.cpp:313] Batch 377, loss = 1.72029
I0629 14:07:49.542445 17196 caffe.cpp:313] Batch 378, accuracy/top1 = 0.64
I0629 14:07:49.542469 17196 caffe.cpp:313] Batch 378, accuracy/top5 = 0.84
I0629 14:07:49.542471 17196 caffe.cpp:313] Batch 378, loss = 1.70006
I0629 14:07:49.591572 17196 caffe.cpp:313] Batch 379, accuracy/top1 = 0.76
I0629 14:07:49.591595 17196 caffe.cpp:313] Batch 379, accuracy/top5 = 0.88
I0629 14:07:49.591598 17196 caffe.cpp:313] Batch 379, loss = 1.25126
I0629 14:07:49.641114 17196 caffe.cpp:313] Batch 380, accuracy/top1 = 0.56
I0629 14:07:49.641139 17196 caffe.cpp:313] Batch 380, accuracy/top5 = 0.84
I0629 14:07:49.641142 17196 caffe.cpp:313] Batch 380, loss = 1.63373
I0629 14:07:49.690393 17196 caffe.cpp:313] Batch 381, accuracy/top1 = 0.42
I0629 14:07:49.690418 17196 caffe.cpp:313] Batch 381, accuracy/top5 = 0.76
I0629 14:07:49.690421 17196 caffe.cpp:313] Batch 381, loss = 2.28197
I0629 14:07:49.739455 17196 caffe.cpp:313] Batch 382, accuracy/top1 = 0.58
I0629 14:07:49.739480 17196 caffe.cpp:313] Batch 382, accuracy/top5 = 0.7
I0629 14:07:49.739483 17196 caffe.cpp:313] Batch 382, loss = 2.25686
I0629 14:07:49.788604 17196 caffe.cpp:313] Batch 383, accuracy/top1 = 0.6
I0629 14:07:49.788626 17196 caffe.cpp:313] Batch 383, accuracy/top5 = 0.82
I0629 14:07:49.788630 17196 caffe.cpp:313] Batch 383, loss = 1.72805
I0629 14:07:49.837919 17196 caffe.cpp:313] Batch 384, accuracy/top1 = 0.56
I0629 14:07:49.837944 17196 caffe.cpp:313] Batch 384, accuracy/top5 = 0.78
I0629 14:07:49.837946 17196 caffe.cpp:313] Batch 384, loss = 1.83318
I0629 14:07:49.888301 17196 caffe.cpp:313] Batch 385, accuracy/top1 = 0.62
I0629 14:07:49.888346 17196 caffe.cpp:313] Batch 385, accuracy/top5 = 0.84
I0629 14:07:49.888350 17196 caffe.cpp:313] Batch 385, loss = 1.64582
I0629 14:07:49.938380 17196 caffe.cpp:313] Batch 386, accuracy/top1 = 0.58
I0629 14:07:49.938402 17196 caffe.cpp:313] Batch 386, accuracy/top5 = 0.82
I0629 14:07:49.938405 17196 caffe.cpp:313] Batch 386, loss = 1.94414
I0629 14:07:49.986860 17196 caffe.cpp:313] Batch 387, accuracy/top1 = 0.62
I0629 14:07:49.986884 17196 caffe.cpp:313] Batch 387, accuracy/top5 = 0.84
I0629 14:07:49.986887 17196 caffe.cpp:313] Batch 387, loss = 1.58907
I0629 14:07:50.036396 17196 caffe.cpp:313] Batch 388, accuracy/top1 = 0.56
I0629 14:07:50.036417 17196 caffe.cpp:313] Batch 388, accuracy/top5 = 0.86
I0629 14:07:50.036420 17196 caffe.cpp:313] Batch 388, loss = 1.64877
I0629 14:07:50.085186 17196 caffe.cpp:313] Batch 389, accuracy/top1 = 0.56
I0629 14:07:50.085209 17196 caffe.cpp:313] Batch 389, accuracy/top5 = 0.7
I0629 14:07:50.085212 17196 caffe.cpp:313] Batch 389, loss = 2.47327
I0629 14:07:50.134857 17196 caffe.cpp:313] Batch 390, accuracy/top1 = 0.68
I0629 14:07:50.134876 17196 caffe.cpp:313] Batch 390, accuracy/top5 = 0.86
I0629 14:07:50.134879 17196 caffe.cpp:313] Batch 390, loss = 1.51592
I0629 14:07:50.184861 17196 caffe.cpp:313] Batch 391, accuracy/top1 = 0.58
I0629 14:07:50.184885 17196 caffe.cpp:313] Batch 391, accuracy/top5 = 0.84
I0629 14:07:50.184887 17196 caffe.cpp:313] Batch 391, loss = 1.8624
I0629 14:07:50.234258 17196 caffe.cpp:313] Batch 392, accuracy/top1 = 0.6
I0629 14:07:50.234282 17196 caffe.cpp:313] Batch 392, accuracy/top5 = 0.86
I0629 14:07:50.234285 17196 caffe.cpp:313] Batch 392, loss = 1.56443
I0629 14:07:50.284307 17196 caffe.cpp:313] Batch 393, accuracy/top1 = 0.52
I0629 14:07:50.284332 17196 caffe.cpp:313] Batch 393, accuracy/top5 = 0.7
I0629 14:07:50.284335 17196 caffe.cpp:313] Batch 393, loss = 2.52916
I0629 14:07:50.333467 17196 caffe.cpp:313] Batch 394, accuracy/top1 = 0.56
I0629 14:07:50.333490 17196 caffe.cpp:313] Batch 394, accuracy/top5 = 0.76
I0629 14:07:50.333493 17196 caffe.cpp:313] Batch 394, loss = 1.83737
I0629 14:07:50.383183 17196 caffe.cpp:313] Batch 395, accuracy/top1 = 0.6
I0629 14:07:50.383203 17196 caffe.cpp:313] Batch 395, accuracy/top5 = 0.84
I0629 14:07:50.383205 17196 caffe.cpp:313] Batch 395, loss = 1.65204
I0629 14:07:50.432400 17196 caffe.cpp:313] Batch 396, accuracy/top1 = 0.54
I0629 14:07:50.432425 17196 caffe.cpp:313] Batch 396, accuracy/top5 = 0.74
I0629 14:07:50.432428 17196 caffe.cpp:313] Batch 396, loss = 2.03518
I0629 14:07:50.483404 17196 caffe.cpp:313] Batch 397, accuracy/top1 = 0.36
I0629 14:07:50.483428 17196 caffe.cpp:313] Batch 397, accuracy/top5 = 0.78
I0629 14:07:50.483431 17196 caffe.cpp:313] Batch 397, loss = 2.58496
I0629 14:07:50.532145 17196 caffe.cpp:313] Batch 398, accuracy/top1 = 0.6
I0629 14:07:50.532169 17196 caffe.cpp:313] Batch 398, accuracy/top5 = 0.8
I0629 14:07:50.532172 17196 caffe.cpp:313] Batch 398, loss = 1.93151
I0629 14:07:50.580965 17196 caffe.cpp:313] Batch 399, accuracy/top1 = 0.56
I0629 14:07:50.580988 17196 caffe.cpp:313] Batch 399, accuracy/top5 = 0.8
I0629 14:07:50.580991 17196 caffe.cpp:313] Batch 399, loss = 1.87496
I0629 14:07:50.631026 17196 caffe.cpp:313] Batch 400, accuracy/top1 = 0.46
I0629 14:07:50.631049 17196 caffe.cpp:313] Batch 400, accuracy/top5 = 0.76
I0629 14:07:50.631052 17196 caffe.cpp:313] Batch 400, loss = 2.13085
I0629 14:07:50.680431 17196 caffe.cpp:313] Batch 401, accuracy/top1 = 0.64
I0629 14:07:50.680454 17196 caffe.cpp:313] Batch 401, accuracy/top5 = 0.84
I0629 14:07:50.680457 17196 caffe.cpp:313] Batch 401, loss = 1.60487
I0629 14:07:50.729610 17196 caffe.cpp:313] Batch 402, accuracy/top1 = 0.6
I0629 14:07:50.729634 17196 caffe.cpp:313] Batch 402, accuracy/top5 = 0.78
I0629 14:07:50.729636 17196 caffe.cpp:313] Batch 402, loss = 1.96719
I0629 14:07:50.778914 17196 caffe.cpp:313] Batch 403, accuracy/top1 = 0.5
I0629 14:07:50.778939 17196 caffe.cpp:313] Batch 403, accuracy/top5 = 0.8
I0629 14:07:50.778940 17196 caffe.cpp:313] Batch 403, loss = 1.87227
I0629 14:07:50.828958 17196 caffe.cpp:313] Batch 404, accuracy/top1 = 0.66
I0629 14:07:50.828997 17196 caffe.cpp:313] Batch 404, accuracy/top5 = 0.86
I0629 14:07:50.829000 17196 caffe.cpp:313] Batch 404, loss = 1.78116
I0629 14:07:50.878274 17196 caffe.cpp:313] Batch 405, accuracy/top1 = 0.5
I0629 14:07:50.878298 17196 caffe.cpp:313] Batch 405, accuracy/top5 = 0.84
I0629 14:07:50.878301 17196 caffe.cpp:313] Batch 405, loss = 1.62977
I0629 14:07:50.926978 17196 caffe.cpp:313] Batch 406, accuracy/top1 = 0.7
I0629 14:07:50.927000 17196 caffe.cpp:313] Batch 406, accuracy/top5 = 0.88
I0629 14:07:50.927004 17196 caffe.cpp:313] Batch 406, loss = 1.51577
I0629 14:07:50.976405 17196 caffe.cpp:313] Batch 407, accuracy/top1 = 0.64
I0629 14:07:50.976429 17196 caffe.cpp:313] Batch 407, accuracy/top5 = 0.9
I0629 14:07:50.976433 17196 caffe.cpp:313] Batch 407, loss = 1.40552
I0629 14:07:51.025461 17196 caffe.cpp:313] Batch 408, accuracy/top1 = 0.44
I0629 14:07:51.025482 17196 caffe.cpp:313] Batch 408, accuracy/top5 = 0.68
I0629 14:07:51.025485 17196 caffe.cpp:313] Batch 408, loss = 2.84099
I0629 14:07:51.074959 17196 caffe.cpp:313] Batch 409, accuracy/top1 = 0.42
I0629 14:07:51.074983 17196 caffe.cpp:313] Batch 409, accuracy/top5 = 0.68
I0629 14:07:51.074986 17196 caffe.cpp:313] Batch 409, loss = 2.44012
I0629 14:07:51.124327 17196 caffe.cpp:313] Batch 410, accuracy/top1 = 0.58
I0629 14:07:51.124351 17196 caffe.cpp:313] Batch 410, accuracy/top5 = 0.8
I0629 14:07:51.124354 17196 caffe.cpp:313] Batch 410, loss = 1.96336
I0629 14:07:51.173836 17196 caffe.cpp:313] Batch 411, accuracy/top1 = 0.58
I0629 14:07:51.173861 17196 caffe.cpp:313] Batch 411, accuracy/top5 = 0.84
I0629 14:07:51.173863 17196 caffe.cpp:313] Batch 411, loss = 1.76346
I0629 14:07:51.222829 17196 caffe.cpp:313] Batch 412, accuracy/top1 = 0.66
I0629 14:07:51.222851 17196 caffe.cpp:313] Batch 412, accuracy/top5 = 0.88
I0629 14:07:51.222853 17196 caffe.cpp:313] Batch 412, loss = 1.5797
I0629 14:07:51.272372 17196 caffe.cpp:313] Batch 413, accuracy/top1 = 0.58
I0629 14:07:51.272392 17196 caffe.cpp:313] Batch 413, accuracy/top5 = 0.82
I0629 14:07:51.272394 17196 caffe.cpp:313] Batch 413, loss = 1.77193
I0629 14:07:51.322345 17196 caffe.cpp:313] Batch 414, accuracy/top1 = 0.58
I0629 14:07:51.322366 17196 caffe.cpp:313] Batch 414, accuracy/top5 = 0.8
I0629 14:07:51.322369 17196 caffe.cpp:313] Batch 414, loss = 1.91743
I0629 14:07:51.371253 17196 caffe.cpp:313] Batch 415, accuracy/top1 = 0.6
I0629 14:07:51.371276 17196 caffe.cpp:313] Batch 415, accuracy/top5 = 0.8
I0629 14:07:51.371279 17196 caffe.cpp:313] Batch 415, loss = 1.82336
I0629 14:07:51.419155 17196 caffe.cpp:313] Batch 416, accuracy/top1 = 0.62
I0629 14:07:51.419178 17196 caffe.cpp:313] Batch 416, accuracy/top5 = 0.8
I0629 14:07:51.419183 17196 caffe.cpp:313] Batch 416, loss = 1.7442
I0629 14:07:51.469002 17196 caffe.cpp:313] Batch 417, accuracy/top1 = 0.58
I0629 14:07:51.469024 17196 caffe.cpp:313] Batch 417, accuracy/top5 = 0.84
I0629 14:07:51.469027 17196 caffe.cpp:313] Batch 417, loss = 1.87875
I0629 14:07:51.518687 17196 caffe.cpp:313] Batch 418, accuracy/top1 = 0.62
I0629 14:07:51.518712 17196 caffe.cpp:313] Batch 418, accuracy/top5 = 0.82
I0629 14:07:51.518714 17196 caffe.cpp:313] Batch 418, loss = 1.59258
I0629 14:07:51.568744 17196 caffe.cpp:313] Batch 419, accuracy/top1 = 0.56
I0629 14:07:51.568768 17196 caffe.cpp:313] Batch 419, accuracy/top5 = 0.8
I0629 14:07:51.568771 17196 caffe.cpp:313] Batch 419, loss = 1.90484
I0629 14:07:51.618638 17196 caffe.cpp:313] Batch 420, accuracy/top1 = 0.6
I0629 14:07:51.618662 17196 caffe.cpp:313] Batch 420, accuracy/top5 = 0.88
I0629 14:07:51.618666 17196 caffe.cpp:313] Batch 420, loss = 1.62741
I0629 14:07:51.668253 17196 caffe.cpp:313] Batch 421, accuracy/top1 = 0.68
I0629 14:07:51.668277 17196 caffe.cpp:313] Batch 421, accuracy/top5 = 0.8
I0629 14:07:51.668282 17196 caffe.cpp:313] Batch 421, loss = 1.40847
I0629 14:07:51.717357 17196 caffe.cpp:313] Batch 422, accuracy/top1 = 0.6
I0629 14:07:51.717381 17196 caffe.cpp:313] Batch 422, accuracy/top5 = 0.78
I0629 14:07:51.717386 17196 caffe.cpp:313] Batch 422, loss = 1.80629
I0629 14:07:51.767349 17196 caffe.cpp:313] Batch 423, accuracy/top1 = 0.56
I0629 14:07:51.767374 17196 caffe.cpp:313] Batch 423, accuracy/top5 = 0.78
I0629 14:07:51.767377 17196 caffe.cpp:313] Batch 423, loss = 2.09553
I0629 14:07:51.816656 17196 caffe.cpp:313] Batch 424, accuracy/top1 = 0.7
I0629 14:07:51.816680 17196 caffe.cpp:313] Batch 424, accuracy/top5 = 0.84
I0629 14:07:51.816684 17196 caffe.cpp:313] Batch 424, loss = 1.22147
I0629 14:07:51.865504 17196 caffe.cpp:313] Batch 425, accuracy/top1 = 0.58
I0629 14:07:51.865526 17196 caffe.cpp:313] Batch 425, accuracy/top5 = 0.78
I0629 14:07:51.865530 17196 caffe.cpp:313] Batch 425, loss = 2.00273
I0629 14:07:51.915729 17196 caffe.cpp:313] Batch 426, accuracy/top1 = 0.54
I0629 14:07:51.915751 17196 caffe.cpp:313] Batch 426, accuracy/top5 = 0.8
I0629 14:07:51.915755 17196 caffe.cpp:313] Batch 426, loss = 1.70983
I0629 14:07:51.964790 17196 caffe.cpp:313] Batch 427, accuracy/top1 = 0.56
I0629 14:07:51.964813 17196 caffe.cpp:313] Batch 427, accuracy/top5 = 0.78
I0629 14:07:51.964817 17196 caffe.cpp:313] Batch 427, loss = 1.81609
I0629 14:07:52.013689 17196 caffe.cpp:313] Batch 428, accuracy/top1 = 0.68
I0629 14:07:52.013713 17196 caffe.cpp:313] Batch 428, accuracy/top5 = 0.82
I0629 14:07:52.013717 17196 caffe.cpp:313] Batch 428, loss = 1.49847
I0629 14:07:52.062855 17196 caffe.cpp:313] Batch 429, accuracy/top1 = 0.64
I0629 14:07:52.062880 17196 caffe.cpp:313] Batch 429, accuracy/top5 = 0.82
I0629 14:07:52.062883 17196 caffe.cpp:313] Batch 429, loss = 1.55229
I0629 14:07:52.112398 17196 caffe.cpp:313] Batch 430, accuracy/top1 = 0.58
I0629 14:07:52.112421 17196 caffe.cpp:313] Batch 430, accuracy/top5 = 0.92
I0629 14:07:52.112424 17196 caffe.cpp:313] Batch 430, loss = 1.34173
I0629 14:07:52.162170 17196 caffe.cpp:313] Batch 431, accuracy/top1 = 0.64
I0629 14:07:52.162189 17196 caffe.cpp:313] Batch 431, accuracy/top5 = 0.82
I0629 14:07:52.162191 17196 caffe.cpp:313] Batch 431, loss = 1.83021
I0629 14:07:52.211413 17196 caffe.cpp:313] Batch 432, accuracy/top1 = 0.54
I0629 14:07:52.211437 17196 caffe.cpp:313] Batch 432, accuracy/top5 = 0.74
I0629 14:07:52.211441 17196 caffe.cpp:313] Batch 432, loss = 2.11371
I0629 14:07:52.261597 17196 caffe.cpp:313] Batch 433, accuracy/top1 = 0.58
I0629 14:07:52.261620 17196 caffe.cpp:313] Batch 433, accuracy/top5 = 0.84
I0629 14:07:52.261623 17196 caffe.cpp:313] Batch 433, loss = 1.62644
I0629 14:07:52.311096 17196 caffe.cpp:313] Batch 434, accuracy/top1 = 0.54
I0629 14:07:52.311120 17196 caffe.cpp:313] Batch 434, accuracy/top5 = 0.76
I0629 14:07:52.311123 17196 caffe.cpp:313] Batch 434, loss = 2.3347
I0629 14:07:52.360988 17196 caffe.cpp:313] Batch 435, accuracy/top1 = 0.66
I0629 14:07:52.361011 17196 caffe.cpp:313] Batch 435, accuracy/top5 = 0.88
I0629 14:07:52.361014 17196 caffe.cpp:313] Batch 435, loss = 1.51205
I0629 14:07:52.410570 17196 caffe.cpp:313] Batch 436, accuracy/top1 = 0.58
I0629 14:07:52.410593 17196 caffe.cpp:313] Batch 436, accuracy/top5 = 0.74
I0629 14:07:52.410595 17196 caffe.cpp:313] Batch 436, loss = 2.2746
I0629 14:07:52.460265 17196 caffe.cpp:313] Batch 437, accuracy/top1 = 0.56
I0629 14:07:52.460289 17196 caffe.cpp:313] Batch 437, accuracy/top5 = 0.76
I0629 14:07:52.460291 17196 caffe.cpp:313] Batch 437, loss = 2.00452
I0629 14:07:52.510742 17196 caffe.cpp:313] Batch 438, accuracy/top1 = 0.56
I0629 14:07:52.510764 17196 caffe.cpp:313] Batch 438, accuracy/top5 = 0.82
I0629 14:07:52.510767 17196 caffe.cpp:313] Batch 438, loss = 2.03076
I0629 14:07:52.558977 17196 caffe.cpp:313] Batch 439, accuracy/top1 = 0.56
I0629 14:07:52.559001 17196 caffe.cpp:313] Batch 439, accuracy/top5 = 0.8
I0629 14:07:52.559005 17196 caffe.cpp:313] Batch 439, loss = 2.47425
I0629 14:07:52.608328 17196 caffe.cpp:313] Batch 440, accuracy/top1 = 0.56
I0629 14:07:52.608352 17196 caffe.cpp:313] Batch 440, accuracy/top5 = 0.8
I0629 14:07:52.608355 17196 caffe.cpp:313] Batch 440, loss = 1.91747
I0629 14:07:52.656251 17196 caffe.cpp:313] Batch 441, accuracy/top1 = 0.58
I0629 14:07:52.656275 17196 caffe.cpp:313] Batch 441, accuracy/top5 = 0.88
I0629 14:07:52.656292 17196 caffe.cpp:313] Batch 441, loss = 1.52532
I0629 14:07:52.706732 17196 caffe.cpp:313] Batch 442, accuracy/top1 = 0.62
I0629 14:07:52.706755 17196 caffe.cpp:313] Batch 442, accuracy/top5 = 0.88
I0629 14:07:52.706758 17196 caffe.cpp:313] Batch 442, loss = 1.60773
I0629 14:07:52.755560 17196 caffe.cpp:313] Batch 443, accuracy/top1 = 0.72
I0629 14:07:52.755584 17196 caffe.cpp:313] Batch 443, accuracy/top5 = 0.82
I0629 14:07:52.755587 17196 caffe.cpp:313] Batch 443, loss = 1.5854
I0629 14:07:52.804708 17196 caffe.cpp:313] Batch 444, accuracy/top1 = 0.7
I0629 14:07:52.804729 17196 caffe.cpp:313] Batch 444, accuracy/top5 = 0.88
I0629 14:07:52.804733 17196 caffe.cpp:313] Batch 444, loss = 1.43198
I0629 14:07:52.854666 17196 caffe.cpp:313] Batch 445, accuracy/top1 = 0.68
I0629 14:07:52.854691 17196 caffe.cpp:313] Batch 445, accuracy/top5 = 0.86
I0629 14:07:52.854693 17196 caffe.cpp:313] Batch 445, loss = 1.50026
I0629 14:07:52.904824 17196 caffe.cpp:313] Batch 446, accuracy/top1 = 0.54
I0629 14:07:52.904848 17196 caffe.cpp:313] Batch 446, accuracy/top5 = 0.92
I0629 14:07:52.904851 17196 caffe.cpp:313] Batch 446, loss = 1.48898
I0629 14:07:52.954211 17196 caffe.cpp:313] Batch 447, accuracy/top1 = 0.6
I0629 14:07:52.954233 17196 caffe.cpp:313] Batch 447, accuracy/top5 = 0.78
I0629 14:07:52.954236 17196 caffe.cpp:313] Batch 447, loss = 1.58635
I0629 14:07:53.004171 17196 caffe.cpp:313] Batch 448, accuracy/top1 = 0.64
I0629 14:07:53.004195 17196 caffe.cpp:313] Batch 448, accuracy/top5 = 0.84
I0629 14:07:53.004199 17196 caffe.cpp:313] Batch 448, loss = 1.55394
I0629 14:07:53.054002 17196 caffe.cpp:313] Batch 449, accuracy/top1 = 0.54
I0629 14:07:53.054024 17196 caffe.cpp:313] Batch 449, accuracy/top5 = 0.74
I0629 14:07:53.054028 17196 caffe.cpp:313] Batch 449, loss = 1.87503
I0629 14:07:53.103610 17196 caffe.cpp:313] Batch 450, accuracy/top1 = 0.56
I0629 14:07:53.103633 17196 caffe.cpp:313] Batch 450, accuracy/top5 = 0.78
I0629 14:07:53.103636 17196 caffe.cpp:313] Batch 450, loss = 1.89928
I0629 14:07:53.151952 17196 caffe.cpp:313] Batch 451, accuracy/top1 = 0.48
I0629 14:07:53.151971 17196 caffe.cpp:313] Batch 451, accuracy/top5 = 0.84
I0629 14:07:53.151974 17196 caffe.cpp:313] Batch 451, loss = 1.83427
I0629 14:07:53.201159 17196 caffe.cpp:313] Batch 452, accuracy/top1 = 0.5
I0629 14:07:53.201182 17196 caffe.cpp:313] Batch 452, accuracy/top5 = 0.78
I0629 14:07:53.201185 17196 caffe.cpp:313] Batch 452, loss = 1.69363
I0629 14:07:53.250921 17196 caffe.cpp:313] Batch 453, accuracy/top1 = 0.56
I0629 14:07:53.250946 17196 caffe.cpp:313] Batch 453, accuracy/top5 = 0.84
I0629 14:07:53.250948 17196 caffe.cpp:313] Batch 453, loss = 1.76873
I0629 14:07:53.301941 17196 caffe.cpp:313] Batch 454, accuracy/top1 = 0.48
I0629 14:07:53.301964 17196 caffe.cpp:313] Batch 454, accuracy/top5 = 0.68
I0629 14:07:53.301969 17196 caffe.cpp:313] Batch 454, loss = 2.04143
I0629 14:07:53.351579 17196 caffe.cpp:313] Batch 455, accuracy/top1 = 0.56
I0629 14:07:53.351599 17196 caffe.cpp:313] Batch 455, accuracy/top5 = 0.82
I0629 14:07:53.351601 17196 caffe.cpp:313] Batch 455, loss = 1.8871
I0629 14:07:53.400179 17196 caffe.cpp:313] Batch 456, accuracy/top1 = 0.5
I0629 14:07:53.400198 17196 caffe.cpp:313] Batch 456, accuracy/top5 = 0.88
I0629 14:07:53.400202 17196 caffe.cpp:313] Batch 456, loss = 2.11138
I0629 14:07:53.449394 17196 caffe.cpp:313] Batch 457, accuracy/top1 = 0.54
I0629 14:07:53.449415 17196 caffe.cpp:313] Batch 457, accuracy/top5 = 0.72
I0629 14:07:53.449417 17196 caffe.cpp:313] Batch 457, loss = 2.08285
I0629 14:07:53.497949 17196 caffe.cpp:313] Batch 458, accuracy/top1 = 0.46
I0629 14:07:53.497969 17196 caffe.cpp:313] Batch 458, accuracy/top5 = 0.68
I0629 14:07:53.497972 17196 caffe.cpp:313] Batch 458, loss = 2.46113
I0629 14:07:53.546154 17196 caffe.cpp:313] Batch 459, accuracy/top1 = 0.76
I0629 14:07:53.546177 17196 caffe.cpp:313] Batch 459, accuracy/top5 = 0.88
I0629 14:07:53.546180 17196 caffe.cpp:313] Batch 459, loss = 0.999403
I0629 14:07:53.595270 17196 caffe.cpp:313] Batch 460, accuracy/top1 = 0.62
I0629 14:07:53.595309 17196 caffe.cpp:313] Batch 460, accuracy/top5 = 0.76
I0629 14:07:53.595314 17196 caffe.cpp:313] Batch 460, loss = 1.93465
I0629 14:07:53.643980 17196 caffe.cpp:313] Batch 461, accuracy/top1 = 0.64
I0629 14:07:53.644002 17196 caffe.cpp:313] Batch 461, accuracy/top5 = 0.86
I0629 14:07:53.644006 17196 caffe.cpp:313] Batch 461, loss = 1.63653
I0629 14:07:53.694512 17196 caffe.cpp:313] Batch 462, accuracy/top1 = 0.54
I0629 14:07:53.694536 17196 caffe.cpp:313] Batch 462, accuracy/top5 = 0.76
I0629 14:07:53.694540 17196 caffe.cpp:313] Batch 462, loss = 1.69894
I0629 14:07:53.744698 17196 caffe.cpp:313] Batch 463, accuracy/top1 = 0.54
I0629 14:07:53.744721 17196 caffe.cpp:313] Batch 463, accuracy/top5 = 0.72
I0629 14:07:53.744724 17196 caffe.cpp:313] Batch 463, loss = 2.19932
I0629 14:07:53.794919 17196 caffe.cpp:313] Batch 464, accuracy/top1 = 0.6
I0629 14:07:53.794942 17196 caffe.cpp:313] Batch 464, accuracy/top5 = 0.78
I0629 14:07:53.794945 17196 caffe.cpp:313] Batch 464, loss = 1.87944
I0629 14:07:53.844517 17196 caffe.cpp:313] Batch 465, accuracy/top1 = 0.6
I0629 14:07:53.844540 17196 caffe.cpp:313] Batch 465, accuracy/top5 = 0.78
I0629 14:07:53.844543 17196 caffe.cpp:313] Batch 465, loss = 1.94079
I0629 14:07:53.894026 17196 caffe.cpp:313] Batch 466, accuracy/top1 = 0.62
I0629 14:07:53.894050 17196 caffe.cpp:313] Batch 466, accuracy/top5 = 0.72
I0629 14:07:53.894053 17196 caffe.cpp:313] Batch 466, loss = 1.97406
I0629 14:07:53.942219 17196 caffe.cpp:313] Batch 467, accuracy/top1 = 0.52
I0629 14:07:53.942241 17196 caffe.cpp:313] Batch 467, accuracy/top5 = 0.78
I0629 14:07:53.942245 17196 caffe.cpp:313] Batch 467, loss = 1.79039
I0629 14:07:53.991257 17196 caffe.cpp:313] Batch 468, accuracy/top1 = 0.5
I0629 14:07:53.991281 17196 caffe.cpp:313] Batch 468, accuracy/top5 = 0.8
I0629 14:07:53.991283 17196 caffe.cpp:313] Batch 468, loss = 2.00759
I0629 14:07:54.041184 17196 caffe.cpp:313] Batch 469, accuracy/top1 = 0.54
I0629 14:07:54.041205 17196 caffe.cpp:313] Batch 469, accuracy/top5 = 0.78
I0629 14:07:54.041208 17196 caffe.cpp:313] Batch 469, loss = 2.05675
I0629 14:07:54.090534 17196 caffe.cpp:313] Batch 470, accuracy/top1 = 0.58
I0629 14:07:54.090559 17196 caffe.cpp:313] Batch 470, accuracy/top5 = 0.9
I0629 14:07:54.090561 17196 caffe.cpp:313] Batch 470, loss = 1.61667
I0629 14:07:54.140012 17196 caffe.cpp:313] Batch 471, accuracy/top1 = 0.52
I0629 14:07:54.140028 17196 caffe.cpp:313] Batch 471, accuracy/top5 = 0.84
I0629 14:07:54.140031 17196 caffe.cpp:313] Batch 471, loss = 1.72335
I0629 14:07:54.189584 17196 caffe.cpp:313] Batch 472, accuracy/top1 = 0.64
I0629 14:07:54.189610 17196 caffe.cpp:313] Batch 472, accuracy/top5 = 0.84
I0629 14:07:54.189613 17196 caffe.cpp:313] Batch 472, loss = 1.49768
I0629 14:07:54.239331 17196 caffe.cpp:313] Batch 473, accuracy/top1 = 0.64
I0629 14:07:54.239353 17196 caffe.cpp:313] Batch 473, accuracy/top5 = 0.82
I0629 14:07:54.239356 17196 caffe.cpp:313] Batch 473, loss = 1.64786
I0629 14:07:54.288895 17196 caffe.cpp:313] Batch 474, accuracy/top1 = 0.58
I0629 14:07:54.288919 17196 caffe.cpp:313] Batch 474, accuracy/top5 = 0.82
I0629 14:07:54.288923 17196 caffe.cpp:313] Batch 474, loss = 1.76856
I0629 14:07:54.338301 17196 caffe.cpp:313] Batch 475, accuracy/top1 = 0.56
I0629 14:07:54.338326 17196 caffe.cpp:313] Batch 475, accuracy/top5 = 0.82
I0629 14:07:54.338330 17196 caffe.cpp:313] Batch 475, loss = 1.85872
I0629 14:07:54.387280 17196 caffe.cpp:313] Batch 476, accuracy/top1 = 0.48
I0629 14:07:54.387305 17196 caffe.cpp:313] Batch 476, accuracy/top5 = 0.74
I0629 14:07:54.387308 17196 caffe.cpp:313] Batch 476, loss = 2.07023
I0629 14:07:54.436015 17196 caffe.cpp:313] Batch 477, accuracy/top1 = 0.48
I0629 14:07:54.436038 17196 caffe.cpp:313] Batch 477, accuracy/top5 = 0.74
I0629 14:07:54.436041 17196 caffe.cpp:313] Batch 477, loss = 2.08636
I0629 14:07:54.486018 17196 caffe.cpp:313] Batch 478, accuracy/top1 = 0.56
I0629 14:07:54.486042 17196 caffe.cpp:313] Batch 478, accuracy/top5 = 0.84
I0629 14:07:54.486045 17196 caffe.cpp:313] Batch 478, loss = 1.76288
I0629 14:07:54.535275 17196 caffe.cpp:313] Batch 479, accuracy/top1 = 0.56
I0629 14:07:54.535300 17196 caffe.cpp:313] Batch 479, accuracy/top5 = 0.72
I0629 14:07:54.535302 17196 caffe.cpp:313] Batch 479, loss = 2.02528
I0629 14:07:54.584671 17196 caffe.cpp:313] Batch 480, accuracy/top1 = 0.56
I0629 14:07:54.584693 17196 caffe.cpp:313] Batch 480, accuracy/top5 = 0.84
I0629 14:07:54.584697 17196 caffe.cpp:313] Batch 480, loss = 1.72512
I0629 14:07:54.633944 17196 caffe.cpp:313] Batch 481, accuracy/top1 = 0.5
I0629 14:07:54.633966 17196 caffe.cpp:313] Batch 481, accuracy/top5 = 0.78
I0629 14:07:54.633970 17196 caffe.cpp:313] Batch 481, loss = 1.98549
I0629 14:07:54.683532 17196 caffe.cpp:313] Batch 482, accuracy/top1 = 0.5
I0629 14:07:54.683557 17196 caffe.cpp:313] Batch 482, accuracy/top5 = 0.68
I0629 14:07:54.683559 17196 caffe.cpp:313] Batch 482, loss = 2.34535
I0629 14:07:54.733817 17196 caffe.cpp:313] Batch 483, accuracy/top1 = 0.58
I0629 14:07:54.733840 17196 caffe.cpp:313] Batch 483, accuracy/top5 = 0.84
I0629 14:07:54.733844 17196 caffe.cpp:313] Batch 483, loss = 1.63363
I0629 14:07:54.783257 17196 caffe.cpp:313] Batch 484, accuracy/top1 = 0.5
I0629 14:07:54.783280 17196 caffe.cpp:313] Batch 484, accuracy/top5 = 0.74
I0629 14:07:54.783283 17196 caffe.cpp:313] Batch 484, loss = 2.36292
I0629 14:07:54.833235 17196 caffe.cpp:313] Batch 485, accuracy/top1 = 0.54
I0629 14:07:54.833258 17196 caffe.cpp:313] Batch 485, accuracy/top5 = 0.78
I0629 14:07:54.833261 17196 caffe.cpp:313] Batch 485, loss = 2.00796
I0629 14:07:54.883312 17196 caffe.cpp:313] Batch 486, accuracy/top1 = 0.7
I0629 14:07:54.883337 17196 caffe.cpp:313] Batch 486, accuracy/top5 = 0.9
I0629 14:07:54.883339 17196 caffe.cpp:313] Batch 486, loss = 1.02163
I0629 14:07:54.932294 17196 caffe.cpp:313] Batch 487, accuracy/top1 = 0.58
I0629 14:07:54.932317 17196 caffe.cpp:313] Batch 487, accuracy/top5 = 0.78
I0629 14:07:54.932319 17196 caffe.cpp:313] Batch 487, loss = 2.08152
I0629 14:07:54.981799 17196 caffe.cpp:313] Batch 488, accuracy/top1 = 0.62
I0629 14:07:54.981823 17196 caffe.cpp:313] Batch 488, accuracy/top5 = 0.8
I0629 14:07:54.981827 17196 caffe.cpp:313] Batch 488, loss = 1.91377
I0629 14:07:55.030910 17196 caffe.cpp:313] Batch 489, accuracy/top1 = 0.56
I0629 14:07:55.030930 17196 caffe.cpp:313] Batch 489, accuracy/top5 = 0.8
I0629 14:07:55.030933 17196 caffe.cpp:313] Batch 489, loss = 1.80749
I0629 14:07:55.081516 17196 caffe.cpp:313] Batch 490, accuracy/top1 = 0.44
I0629 14:07:55.081539 17196 caffe.cpp:313] Batch 490, accuracy/top5 = 0.84
I0629 14:07:55.081542 17196 caffe.cpp:313] Batch 490, loss = 1.77404
I0629 14:07:55.131842 17196 caffe.cpp:313] Batch 491, accuracy/top1 = 0.52
I0629 14:07:55.131861 17196 caffe.cpp:313] Batch 491, accuracy/top5 = 0.82
I0629 14:07:55.131865 17196 caffe.cpp:313] Batch 491, loss = 1.76719
I0629 14:07:55.181124 17196 caffe.cpp:313] Batch 492, accuracy/top1 = 0.56
I0629 14:07:55.181147 17196 caffe.cpp:313] Batch 492, accuracy/top5 = 0.88
I0629 14:07:55.181150 17196 caffe.cpp:313] Batch 492, loss = 1.82285
I0629 14:07:55.230659 17196 caffe.cpp:313] Batch 493, accuracy/top1 = 0.6
I0629 14:07:55.230684 17196 caffe.cpp:313] Batch 493, accuracy/top5 = 0.78
I0629 14:07:55.230686 17196 caffe.cpp:313] Batch 493, loss = 1.84276
I0629 14:07:55.280866 17196 caffe.cpp:313] Batch 494, accuracy/top1 = 0.58
I0629 14:07:55.280890 17196 caffe.cpp:313] Batch 494, accuracy/top5 = 0.78
I0629 14:07:55.280894 17196 caffe.cpp:313] Batch 494, loss = 2.0161
I0629 14:07:55.331120 17196 caffe.cpp:313] Batch 495, accuracy/top1 = 0.62
I0629 14:07:55.331142 17196 caffe.cpp:313] Batch 495, accuracy/top5 = 0.9
I0629 14:07:55.331146 17196 caffe.cpp:313] Batch 495, loss = 1.48295
I0629 14:07:55.380558 17196 caffe.cpp:313] Batch 496, accuracy/top1 = 0.54
I0629 14:07:55.380581 17196 caffe.cpp:313] Batch 496, accuracy/top5 = 0.84
I0629 14:07:55.380584 17196 caffe.cpp:313] Batch 496, loss = 1.80987
I0629 14:07:55.429986 17196 caffe.cpp:313] Batch 497, accuracy/top1 = 0.6
I0629 14:07:55.430011 17196 caffe.cpp:313] Batch 497, accuracy/top5 = 0.72
I0629 14:07:55.430014 17196 caffe.cpp:313] Batch 497, loss = 2.14432
I0629 14:07:55.478893 17196 caffe.cpp:313] Batch 498, accuracy/top1 = 0.64
I0629 14:07:55.478914 17196 caffe.cpp:313] Batch 498, accuracy/top5 = 0.84
I0629 14:07:55.478916 17196 caffe.cpp:313] Batch 498, loss = 1.48114
I0629 14:07:55.527657 17196 caffe.cpp:313] Batch 499, accuracy/top1 = 0.54
I0629 14:07:55.527676 17196 caffe.cpp:313] Batch 499, accuracy/top5 = 0.74
I0629 14:07:55.527679 17196 caffe.cpp:313] Batch 499, loss = 1.98656
I0629 14:07:55.576607 17196 caffe.cpp:313] Batch 500, accuracy/top1 = 0.6
I0629 14:07:55.576628 17196 caffe.cpp:313] Batch 500, accuracy/top5 = 0.86
I0629 14:07:55.576632 17196 caffe.cpp:313] Batch 500, loss = 1.89422
I0629 14:07:55.626456 17196 caffe.cpp:313] Batch 501, accuracy/top1 = 0.62
I0629 14:07:55.626479 17196 caffe.cpp:313] Batch 501, accuracy/top5 = 0.78
I0629 14:07:55.626482 17196 caffe.cpp:313] Batch 501, loss = 1.78843
I0629 14:07:55.675395 17196 caffe.cpp:313] Batch 502, accuracy/top1 = 0.48
I0629 14:07:55.675416 17196 caffe.cpp:313] Batch 502, accuracy/top5 = 0.82
I0629 14:07:55.675420 17196 caffe.cpp:313] Batch 502, loss = 1.97023
I0629 14:07:55.724967 17196 caffe.cpp:313] Batch 503, accuracy/top1 = 0.58
I0629 14:07:55.724992 17196 caffe.cpp:313] Batch 503, accuracy/top5 = 0.84
I0629 14:07:55.724994 17196 caffe.cpp:313] Batch 503, loss = 1.65307
I0629 14:07:55.774147 17196 caffe.cpp:313] Batch 504, accuracy/top1 = 0.68
I0629 14:07:55.774171 17196 caffe.cpp:313] Batch 504, accuracy/top5 = 0.82
I0629 14:07:55.774174 17196 caffe.cpp:313] Batch 504, loss = 1.53626
I0629 14:07:55.823971 17196 caffe.cpp:313] Batch 505, accuracy/top1 = 0.58
I0629 14:07:55.823993 17196 caffe.cpp:313] Batch 505, accuracy/top5 = 0.78
I0629 14:07:55.823997 17196 caffe.cpp:313] Batch 505, loss = 1.913
I0629 14:07:55.873474 17196 caffe.cpp:313] Batch 506, accuracy/top1 = 0.66
I0629 14:07:55.873497 17196 caffe.cpp:313] Batch 506, accuracy/top5 = 0.8
I0629 14:07:55.873499 17196 caffe.cpp:313] Batch 506, loss = 1.68406
I0629 14:07:55.923110 17196 caffe.cpp:313] Batch 507, accuracy/top1 = 0.46
I0629 14:07:55.923131 17196 caffe.cpp:313] Batch 507, accuracy/top5 = 0.72
I0629 14:07:55.923135 17196 caffe.cpp:313] Batch 507, loss = 2.74733
I0629 14:07:55.972596 17196 caffe.cpp:313] Batch 508, accuracy/top1 = 0.62
I0629 14:07:55.972620 17196 caffe.cpp:313] Batch 508, accuracy/top5 = 0.86
I0629 14:07:55.972622 17196 caffe.cpp:313] Batch 508, loss = 1.89963
I0629 14:07:56.022883 17196 caffe.cpp:313] Batch 509, accuracy/top1 = 0.54
I0629 14:07:56.022902 17196 caffe.cpp:313] Batch 509, accuracy/top5 = 0.8
I0629 14:07:56.022907 17196 caffe.cpp:313] Batch 509, loss = 1.9589
I0629 14:07:56.072484 17196 caffe.cpp:313] Batch 510, accuracy/top1 = 0.5
I0629 14:07:56.072510 17196 caffe.cpp:313] Batch 510, accuracy/top5 = 0.86
I0629 14:07:56.072512 17196 caffe.cpp:313] Batch 510, loss = 1.67432
I0629 14:07:56.121634 17196 caffe.cpp:313] Batch 511, accuracy/top1 = 0.64
I0629 14:07:56.121656 17196 caffe.cpp:313] Batch 511, accuracy/top5 = 0.84
I0629 14:07:56.121659 17196 caffe.cpp:313] Batch 511, loss = 1.66201
I0629 14:07:56.171591 17196 caffe.cpp:313] Batch 512, accuracy/top1 = 0.64
I0629 14:07:56.171617 17196 caffe.cpp:313] Batch 512, accuracy/top5 = 0.84
I0629 14:07:56.171618 17196 caffe.cpp:313] Batch 512, loss = 1.58107
I0629 14:07:56.221053 17196 caffe.cpp:313] Batch 513, accuracy/top1 = 0.54
I0629 14:07:56.221077 17196 caffe.cpp:313] Batch 513, accuracy/top5 = 0.78
I0629 14:07:56.221081 17196 caffe.cpp:313] Batch 513, loss = 1.91236
I0629 14:07:56.269484 17196 caffe.cpp:313] Batch 514, accuracy/top1 = 0.56
I0629 14:07:56.269508 17196 caffe.cpp:313] Batch 514, accuracy/top5 = 0.82
I0629 14:07:56.269511 17196 caffe.cpp:313] Batch 514, loss = 2.01347
I0629 14:07:56.319285 17196 caffe.cpp:313] Batch 515, accuracy/top1 = 0.58
I0629 14:07:56.319309 17196 caffe.cpp:313] Batch 515, accuracy/top5 = 0.78
I0629 14:07:56.319313 17196 caffe.cpp:313] Batch 515, loss = 1.94179
I0629 14:07:56.368284 17196 caffe.cpp:313] Batch 516, accuracy/top1 = 0.52
I0629 14:07:56.368307 17196 caffe.cpp:313] Batch 516, accuracy/top5 = 0.7
I0629 14:07:56.368325 17196 caffe.cpp:313] Batch 516, loss = 2.39279
I0629 14:07:56.416900 17196 caffe.cpp:313] Batch 517, accuracy/top1 = 0.62
I0629 14:07:56.416918 17196 caffe.cpp:313] Batch 517, accuracy/top5 = 0.86
I0629 14:07:56.416921 17196 caffe.cpp:313] Batch 517, loss = 1.58602
I0629 14:07:56.466434 17196 caffe.cpp:313] Batch 518, accuracy/top1 = 0.56
I0629 14:07:56.466459 17196 caffe.cpp:313] Batch 518, accuracy/top5 = 0.86
I0629 14:07:56.466461 17196 caffe.cpp:313] Batch 518, loss = 1.83866
I0629 14:07:56.514696 17196 caffe.cpp:313] Batch 519, accuracy/top1 = 0.56
I0629 14:07:56.514720 17196 caffe.cpp:313] Batch 519, accuracy/top5 = 0.82
I0629 14:07:56.514724 17196 caffe.cpp:313] Batch 519, loss = 1.88174
I0629 14:07:56.564224 17196 caffe.cpp:313] Batch 520, accuracy/top1 = 0.5
I0629 14:07:56.564249 17196 caffe.cpp:313] Batch 520, accuracy/top5 = 0.78
I0629 14:07:56.564252 17196 caffe.cpp:313] Batch 520, loss = 2.29452
I0629 14:07:56.613517 17196 caffe.cpp:313] Batch 521, accuracy/top1 = 0.54
I0629 14:07:56.613539 17196 caffe.cpp:313] Batch 521, accuracy/top5 = 0.8
I0629 14:07:56.613543 17196 caffe.cpp:313] Batch 521, loss = 2.07131
I0629 14:07:56.663187 17196 caffe.cpp:313] Batch 522, accuracy/top1 = 0.66
I0629 14:07:56.663210 17196 caffe.cpp:313] Batch 522, accuracy/top5 = 0.86
I0629 14:07:56.663214 17196 caffe.cpp:313] Batch 522, loss = 1.49997
I0629 14:07:56.712831 17196 caffe.cpp:313] Batch 523, accuracy/top1 = 0.62
I0629 14:07:56.712857 17196 caffe.cpp:313] Batch 523, accuracy/top5 = 0.84
I0629 14:07:56.712859 17196 caffe.cpp:313] Batch 523, loss = 1.51115
I0629 14:07:56.762332 17196 caffe.cpp:313] Batch 524, accuracy/top1 = 0.5
I0629 14:07:56.762357 17196 caffe.cpp:313] Batch 524, accuracy/top5 = 0.82
I0629 14:07:56.762361 17196 caffe.cpp:313] Batch 524, loss = 1.89023
I0629 14:07:56.811507 17196 caffe.cpp:313] Batch 525, accuracy/top1 = 0.56
I0629 14:07:56.811530 17196 caffe.cpp:313] Batch 525, accuracy/top5 = 0.8
I0629 14:07:56.811533 17196 caffe.cpp:313] Batch 525, loss = 1.85618
I0629 14:07:56.860764 17196 caffe.cpp:313] Batch 526, accuracy/top1 = 0.56
I0629 14:07:56.860788 17196 caffe.cpp:313] Batch 526, accuracy/top5 = 0.7
I0629 14:07:56.860791 17196 caffe.cpp:313] Batch 526, loss = 2.24387
I0629 14:07:56.910379 17196 caffe.cpp:313] Batch 527, accuracy/top1 = 0.56
I0629 14:07:56.910403 17196 caffe.cpp:313] Batch 527, accuracy/top5 = 0.8
I0629 14:07:56.910405 17196 caffe.cpp:313] Batch 527, loss = 1.63531
I0629 14:07:56.960047 17196 caffe.cpp:313] Batch 528, accuracy/top1 = 0.64
I0629 14:07:56.960069 17196 caffe.cpp:313] Batch 528, accuracy/top5 = 0.82
I0629 14:07:56.960072 17196 caffe.cpp:313] Batch 528, loss = 1.71233
I0629 14:07:57.009649 17196 caffe.cpp:313] Batch 529, accuracy/top1 = 0.56
I0629 14:07:57.009672 17196 caffe.cpp:313] Batch 529, accuracy/top5 = 0.88
I0629 14:07:57.009675 17196 caffe.cpp:313] Batch 529, loss = 1.89278
I0629 14:07:57.058485 17196 caffe.cpp:313] Batch 530, accuracy/top1 = 0.58
I0629 14:07:57.058508 17196 caffe.cpp:313] Batch 530, accuracy/top5 = 0.78
I0629 14:07:57.058511 17196 caffe.cpp:313] Batch 530, loss = 1.77523
I0629 14:07:57.108422 17196 caffe.cpp:313] Batch 531, accuracy/top1 = 0.5
I0629 14:07:57.108446 17196 caffe.cpp:313] Batch 531, accuracy/top5 = 0.74
I0629 14:07:57.108449 17196 caffe.cpp:313] Batch 531, loss = 2.05352
I0629 14:07:57.159402 17196 caffe.cpp:313] Batch 532, accuracy/top1 = 0.62
I0629 14:07:57.159421 17196 caffe.cpp:313] Batch 532, accuracy/top5 = 0.9
I0629 14:07:57.159425 17196 caffe.cpp:313] Batch 532, loss = 1.52683
I0629 14:07:57.209213 17196 caffe.cpp:313] Batch 533, accuracy/top1 = 0.36
I0629 14:07:57.209239 17196 caffe.cpp:313] Batch 533, accuracy/top5 = 0.66
I0629 14:07:57.209241 17196 caffe.cpp:313] Batch 533, loss = 2.76841
I0629 14:07:57.258394 17196 caffe.cpp:313] Batch 534, accuracy/top1 = 0.62
I0629 14:07:57.258419 17196 caffe.cpp:313] Batch 534, accuracy/top5 = 0.9
I0629 14:07:57.258421 17196 caffe.cpp:313] Batch 534, loss = 1.42823
I0629 14:07:57.307056 17196 caffe.cpp:313] Batch 535, accuracy/top1 = 0.56
I0629 14:07:57.307096 17196 caffe.cpp:313] Batch 535, accuracy/top5 = 0.84
I0629 14:07:57.307099 17196 caffe.cpp:313] Batch 535, loss = 1.70445
I0629 14:07:57.356293 17196 caffe.cpp:313] Batch 536, accuracy/top1 = 0.66
I0629 14:07:57.356317 17196 caffe.cpp:313] Batch 536, accuracy/top5 = 0.92
I0629 14:07:57.356319 17196 caffe.cpp:313] Batch 536, loss = 1.19722
I0629 14:07:57.406255 17196 caffe.cpp:313] Batch 537, accuracy/top1 = 0.66
I0629 14:07:57.406278 17196 caffe.cpp:313] Batch 537, accuracy/top5 = 0.76
I0629 14:07:57.406282 17196 caffe.cpp:313] Batch 537, loss = 1.55099
I0629 14:07:57.455950 17196 caffe.cpp:313] Batch 538, accuracy/top1 = 0.58
I0629 14:07:57.455976 17196 caffe.cpp:313] Batch 538, accuracy/top5 = 0.78
I0629 14:07:57.455978 17196 caffe.cpp:313] Batch 538, loss = 1.68991
I0629 14:07:57.506557 17196 caffe.cpp:313] Batch 539, accuracy/top1 = 0.46
I0629 14:07:57.506578 17196 caffe.cpp:313] Batch 539, accuracy/top5 = 0.68
I0629 14:07:57.506582 17196 caffe.cpp:313] Batch 539, loss = 2.37858
I0629 14:07:57.555594 17196 caffe.cpp:313] Batch 540, accuracy/top1 = 0.58
I0629 14:07:57.555618 17196 caffe.cpp:313] Batch 540, accuracy/top5 = 0.76
I0629 14:07:57.555620 17196 caffe.cpp:313] Batch 540, loss = 2.0247
I0629 14:07:57.605514 17196 caffe.cpp:313] Batch 541, accuracy/top1 = 0.48
I0629 14:07:57.605532 17196 caffe.cpp:313] Batch 541, accuracy/top5 = 0.84
I0629 14:07:57.605535 17196 caffe.cpp:313] Batch 541, loss = 1.99701
I0629 14:07:57.654186 17196 caffe.cpp:313] Batch 542, accuracy/top1 = 0.64
I0629 14:07:57.654206 17196 caffe.cpp:313] Batch 542, accuracy/top5 = 0.84
I0629 14:07:57.654208 17196 caffe.cpp:313] Batch 542, loss = 1.70889
I0629 14:07:57.703182 17196 caffe.cpp:313] Batch 543, accuracy/top1 = 0.66
I0629 14:07:57.703203 17196 caffe.cpp:313] Batch 543, accuracy/top5 = 0.86
I0629 14:07:57.703205 17196 caffe.cpp:313] Batch 543, loss = 1.3445
I0629 14:07:57.751483 17196 caffe.cpp:313] Batch 544, accuracy/top1 = 0.76
I0629 14:07:57.751507 17196 caffe.cpp:313] Batch 544, accuracy/top5 = 0.84
I0629 14:07:57.751509 17196 caffe.cpp:313] Batch 544, loss = 1.34387
I0629 14:07:57.801791 17196 caffe.cpp:313] Batch 545, accuracy/top1 = 0.5
I0629 14:07:57.801815 17196 caffe.cpp:313] Batch 545, accuracy/top5 = 0.78
I0629 14:07:57.801818 17196 caffe.cpp:313] Batch 545, loss = 2.0858
I0629 14:07:57.851007 17196 caffe.cpp:313] Batch 546, accuracy/top1 = 0.68
I0629 14:07:57.851032 17196 caffe.cpp:313] Batch 546, accuracy/top5 = 0.84
I0629 14:07:57.851034 17196 caffe.cpp:313] Batch 546, loss = 1.53881
I0629 14:07:57.900668 17196 caffe.cpp:313] Batch 547, accuracy/top1 = 0.48
I0629 14:07:57.900692 17196 caffe.cpp:313] Batch 547, accuracy/top5 = 0.78
I0629 14:07:57.900696 17196 caffe.cpp:313] Batch 547, loss = 2.05629
I0629 14:07:57.949610 17196 caffe.cpp:313] Batch 548, accuracy/top1 = 0.58
I0629 14:07:57.949635 17196 caffe.cpp:313] Batch 548, accuracy/top5 = 0.76
I0629 14:07:57.949637 17196 caffe.cpp:313] Batch 548, loss = 1.96315
I0629 14:07:57.999425 17196 caffe.cpp:313] Batch 549, accuracy/top1 = 0.62
I0629 14:07:57.999449 17196 caffe.cpp:313] Batch 549, accuracy/top5 = 0.76
I0629 14:07:57.999451 17196 caffe.cpp:313] Batch 549, loss = 2.15138
I0629 14:07:58.048753 17196 caffe.cpp:313] Batch 550, accuracy/top1 = 0.6
I0629 14:07:58.048777 17196 caffe.cpp:313] Batch 550, accuracy/top5 = 0.82
I0629 14:07:58.048780 17196 caffe.cpp:313] Batch 550, loss = 1.69911
I0629 14:07:58.098768 17196 caffe.cpp:313] Batch 551, accuracy/top1 = 0.66
I0629 14:07:58.098793 17196 caffe.cpp:313] Batch 551, accuracy/top5 = 0.84
I0629 14:07:58.098795 17196 caffe.cpp:313] Batch 551, loss = 1.50757
I0629 14:07:58.148844 17196 caffe.cpp:313] Batch 552, accuracy/top1 = 0.62
I0629 14:07:58.148862 17196 caffe.cpp:313] Batch 552, accuracy/top5 = 0.8
I0629 14:07:58.148865 17196 caffe.cpp:313] Batch 552, loss = 1.73045
I0629 14:07:58.197809 17196 caffe.cpp:313] Batch 553, accuracy/top1 = 0.58
I0629 14:07:58.197834 17196 caffe.cpp:313] Batch 553, accuracy/top5 = 0.86
I0629 14:07:58.197836 17196 caffe.cpp:313] Batch 553, loss = 1.66826
I0629 14:07:58.246736 17196 caffe.cpp:313] Batch 554, accuracy/top1 = 0.54
I0629 14:07:58.246758 17196 caffe.cpp:313] Batch 554, accuracy/top5 = 0.86
I0629 14:07:58.246762 17196 caffe.cpp:313] Batch 554, loss = 1.76863
I0629 14:07:58.296433 17196 caffe.cpp:313] Batch 555, accuracy/top1 = 0.68
I0629 14:07:58.296458 17196 caffe.cpp:313] Batch 555, accuracy/top5 = 0.92
I0629 14:07:58.296460 17196 caffe.cpp:313] Batch 555, loss = 1.25122
I0629 14:07:58.346386 17196 caffe.cpp:313] Batch 556, accuracy/top1 = 0.7
I0629 14:07:58.346410 17196 caffe.cpp:313] Batch 556, accuracy/top5 = 0.8
I0629 14:07:58.346412 17196 caffe.cpp:313] Batch 556, loss = 1.50769
I0629 14:07:58.395975 17196 caffe.cpp:313] Batch 557, accuracy/top1 = 0.52
I0629 14:07:58.395998 17196 caffe.cpp:313] Batch 557, accuracy/top5 = 0.84
I0629 14:07:58.396001 17196 caffe.cpp:313] Batch 557, loss = 1.76338
I0629 14:07:58.444674 17196 caffe.cpp:313] Batch 558, accuracy/top1 = 0.5
I0629 14:07:58.444690 17196 caffe.cpp:313] Batch 558, accuracy/top5 = 0.74
I0629 14:07:58.444694 17196 caffe.cpp:313] Batch 558, loss = 2.40044
I0629 14:07:58.494593 17196 caffe.cpp:313] Batch 559, accuracy/top1 = 0.62
I0629 14:07:58.494617 17196 caffe.cpp:313] Batch 559, accuracy/top5 = 0.78
I0629 14:07:58.494621 17196 caffe.cpp:313] Batch 559, loss = 1.97739
I0629 14:07:58.543093 17196 caffe.cpp:313] Batch 560, accuracy/top1 = 0.62
I0629 14:07:58.543118 17196 caffe.cpp:313] Batch 560, accuracy/top5 = 0.78
I0629 14:07:58.543120 17196 caffe.cpp:313] Batch 560, loss = 1.89415
I0629 14:07:58.592468 17196 caffe.cpp:313] Batch 561, accuracy/top1 = 0.64
I0629 14:07:58.592494 17196 caffe.cpp:313] Batch 561, accuracy/top5 = 0.76
I0629 14:07:58.592496 17196 caffe.cpp:313] Batch 561, loss = 2.17978
I0629 14:07:58.641309 17196 caffe.cpp:313] Batch 562, accuracy/top1 = 0.56
I0629 14:07:58.641333 17196 caffe.cpp:313] Batch 562, accuracy/top5 = 0.78
I0629 14:07:58.641336 17196 caffe.cpp:313] Batch 562, loss = 1.75752
I0629 14:07:58.690809 17196 caffe.cpp:313] Batch 563, accuracy/top1 = 0.58
I0629 14:07:58.690834 17196 caffe.cpp:313] Batch 563, accuracy/top5 = 0.78
I0629 14:07:58.690836 17196 caffe.cpp:313] Batch 563, loss = 1.92424
I0629 14:07:58.740532 17196 caffe.cpp:313] Batch 564, accuracy/top1 = 0.54
I0629 14:07:58.740556 17196 caffe.cpp:313] Batch 564, accuracy/top5 = 0.82
I0629 14:07:58.740559 17196 caffe.cpp:313] Batch 564, loss = 1.78846
I0629 14:07:58.790359 17196 caffe.cpp:313] Batch 565, accuracy/top1 = 0.62
I0629 14:07:58.790383 17196 caffe.cpp:313] Batch 565, accuracy/top5 = 0.86
I0629 14:07:58.790386 17196 caffe.cpp:313] Batch 565, loss = 1.63018
I0629 14:07:58.840036 17196 caffe.cpp:313] Batch 566, accuracy/top1 = 0.5
I0629 14:07:58.840059 17196 caffe.cpp:313] Batch 566, accuracy/top5 = 0.7
I0629 14:07:58.840062 17196 caffe.cpp:313] Batch 566, loss = 2.32049
I0629 14:07:58.889477 17196 caffe.cpp:313] Batch 567, accuracy/top1 = 0.5
I0629 14:07:58.889499 17196 caffe.cpp:313] Batch 567, accuracy/top5 = 0.78
I0629 14:07:58.889503 17196 caffe.cpp:313] Batch 567, loss = 1.98838
I0629 14:07:58.939214 17196 caffe.cpp:313] Batch 568, accuracy/top1 = 0.52
I0629 14:07:58.939237 17196 caffe.cpp:313] Batch 568, accuracy/top5 = 0.74
I0629 14:07:58.939240 17196 caffe.cpp:313] Batch 568, loss = 2.22273
I0629 14:07:58.987920 17196 caffe.cpp:313] Batch 569, accuracy/top1 = 0.4
I0629 14:07:58.987943 17196 caffe.cpp:313] Batch 569, accuracy/top5 = 0.6
I0629 14:07:58.987946 17196 caffe.cpp:313] Batch 569, loss = 2.96917
I0629 14:07:59.037148 17196 caffe.cpp:313] Batch 570, accuracy/top1 = 0.58
I0629 14:07:59.037171 17196 caffe.cpp:313] Batch 570, accuracy/top5 = 0.82
I0629 14:07:59.037176 17196 caffe.cpp:313] Batch 570, loss = 1.56725
I0629 14:07:59.086235 17196 caffe.cpp:313] Batch 571, accuracy/top1 = 0.46
I0629 14:07:59.086258 17196 caffe.cpp:313] Batch 571, accuracy/top5 = 0.7
I0629 14:07:59.086261 17196 caffe.cpp:313] Batch 571, loss = 2.22379
I0629 14:07:59.135862 17196 caffe.cpp:313] Batch 572, accuracy/top1 = 0.58
I0629 14:07:59.135880 17196 caffe.cpp:313] Batch 572, accuracy/top5 = 0.78
I0629 14:07:59.135884 17196 caffe.cpp:313] Batch 572, loss = 1.80238
I0629 14:07:59.185365 17196 caffe.cpp:313] Batch 573, accuracy/top1 = 0.72
I0629 14:07:59.185390 17196 caffe.cpp:313] Batch 573, accuracy/top5 = 0.86
I0629 14:07:59.185394 17196 caffe.cpp:313] Batch 573, loss = 1.41749
I0629 14:07:59.234882 17196 caffe.cpp:313] Batch 574, accuracy/top1 = 0.56
I0629 14:07:59.234906 17196 caffe.cpp:313] Batch 574, accuracy/top5 = 0.76
I0629 14:07:59.234908 17196 caffe.cpp:313] Batch 574, loss = 2.28371
I0629 14:07:59.284101 17196 caffe.cpp:313] Batch 575, accuracy/top1 = 0.6
I0629 14:07:59.284124 17196 caffe.cpp:313] Batch 575, accuracy/top5 = 0.82
I0629 14:07:59.284127 17196 caffe.cpp:313] Batch 575, loss = 1.87818
I0629 14:07:59.332929 17196 caffe.cpp:313] Batch 576, accuracy/top1 = 0.62
I0629 14:07:59.332952 17196 caffe.cpp:313] Batch 576, accuracy/top5 = 0.88
I0629 14:07:59.332955 17196 caffe.cpp:313] Batch 576, loss = 1.43517
I0629 14:07:59.382408 17196 caffe.cpp:313] Batch 577, accuracy/top1 = 0.6
I0629 14:07:59.382432 17196 caffe.cpp:313] Batch 577, accuracy/top5 = 0.8
I0629 14:07:59.382436 17196 caffe.cpp:313] Batch 577, loss = 1.58847
I0629 14:07:59.432703 17196 caffe.cpp:313] Batch 578, accuracy/top1 = 0.58
I0629 14:07:59.432726 17196 caffe.cpp:313] Batch 578, accuracy/top5 = 0.72
I0629 14:07:59.432729 17196 caffe.cpp:313] Batch 578, loss = 2.01514
I0629 14:07:59.481990 17196 caffe.cpp:313] Batch 579, accuracy/top1 = 0.56
I0629 14:07:59.482014 17196 caffe.cpp:313] Batch 579, accuracy/top5 = 0.8
I0629 14:07:59.482017 17196 caffe.cpp:313] Batch 579, loss = 1.99537
I0629 14:07:59.531929 17196 caffe.cpp:313] Batch 580, accuracy/top1 = 0.66
I0629 14:07:59.531952 17196 caffe.cpp:313] Batch 580, accuracy/top5 = 0.78
I0629 14:07:59.531955 17196 caffe.cpp:313] Batch 580, loss = 1.81279
I0629 14:07:59.581984 17196 caffe.cpp:313] Batch 581, accuracy/top1 = 0.56
I0629 14:07:59.582006 17196 caffe.cpp:313] Batch 581, accuracy/top5 = 0.82
I0629 14:07:59.582010 17196 caffe.cpp:313] Batch 581, loss = 1.69168
I0629 14:07:59.631327 17196 caffe.cpp:313] Batch 582, accuracy/top1 = 0.6
I0629 14:07:59.631350 17196 caffe.cpp:313] Batch 582, accuracy/top5 = 0.78
I0629 14:07:59.631353 17196 caffe.cpp:313] Batch 582, loss = 1.66243
I0629 14:07:59.680899 17196 caffe.cpp:313] Batch 583, accuracy/top1 = 0.56
I0629 14:07:59.680923 17196 caffe.cpp:313] Batch 583, accuracy/top5 = 0.78
I0629 14:07:59.680927 17196 caffe.cpp:313] Batch 583, loss = 2.21765
I0629 14:07:59.730507 17196 caffe.cpp:313] Batch 584, accuracy/top1 = 0.64
I0629 14:07:59.730527 17196 caffe.cpp:313] Batch 584, accuracy/top5 = 0.88
I0629 14:07:59.730530 17196 caffe.cpp:313] Batch 584, loss = 1.44079
I0629 14:07:59.780135 17196 caffe.cpp:313] Batch 585, accuracy/top1 = 0.7
I0629 14:07:59.780156 17196 caffe.cpp:313] Batch 585, accuracy/top5 = 0.86
I0629 14:07:59.780160 17196 caffe.cpp:313] Batch 585, loss = 1.5291
I0629 14:07:59.828671 17196 caffe.cpp:313] Batch 586, accuracy/top1 = 0.58
I0629 14:07:59.828693 17196 caffe.cpp:313] Batch 586, accuracy/top5 = 0.8
I0629 14:07:59.828697 17196 caffe.cpp:313] Batch 586, loss = 1.82839
I0629 14:07:59.876260 17196 caffe.cpp:313] Batch 587, accuracy/top1 = 0.6
I0629 14:07:59.876284 17196 caffe.cpp:313] Batch 587, accuracy/top5 = 0.84
I0629 14:07:59.876288 17196 caffe.cpp:313] Batch 587, loss = 1.51509
I0629 14:07:59.924342 17196 caffe.cpp:313] Batch 588, accuracy/top1 = 0.64
I0629 14:07:59.924365 17196 caffe.cpp:313] Batch 588, accuracy/top5 = 0.84
I0629 14:07:59.924368 17196 caffe.cpp:313] Batch 588, loss = 1.51023
I0629 14:07:59.974079 17196 caffe.cpp:313] Batch 589, accuracy/top1 = 0.64
I0629 14:07:59.974103 17196 caffe.cpp:313] Batch 589, accuracy/top5 = 0.86
I0629 14:07:59.974107 17196 caffe.cpp:313] Batch 589, loss = 1.88775
I0629 14:08:00.024040 17196 caffe.cpp:313] Batch 590, accuracy/top1 = 0.6
I0629 14:08:00.024060 17196 caffe.cpp:313] Batch 590, accuracy/top5 = 0.78
I0629 14:08:00.024065 17196 caffe.cpp:313] Batch 590, loss = 2.11983
I0629 14:08:00.073554 17196 caffe.cpp:313] Batch 591, accuracy/top1 = 0.48
I0629 14:08:00.073585 17196 caffe.cpp:313] Batch 591, accuracy/top5 = 0.76
I0629 14:08:00.073607 17196 caffe.cpp:313] Batch 591, loss = 1.84124
I0629 14:08:00.123761 17196 caffe.cpp:313] Batch 592, accuracy/top1 = 0.56
I0629 14:08:00.123788 17196 caffe.cpp:313] Batch 592, accuracy/top5 = 0.84
I0629 14:08:00.123793 17196 caffe.cpp:313] Batch 592, loss = 1.66191
I0629 14:08:00.174119 17196 caffe.cpp:313] Batch 593, accuracy/top1 = 0.46
I0629 14:08:00.174283 17196 caffe.cpp:313] Batch 593, accuracy/top5 = 0.62
I0629 14:08:00.174293 17196 caffe.cpp:313] Batch 593, loss = 2.30355
I0629 14:08:00.223224 17196 caffe.cpp:313] Batch 594, accuracy/top1 = 0.66
I0629 14:08:00.223248 17196 caffe.cpp:313] Batch 594, accuracy/top5 = 0.82
I0629 14:08:00.223251 17196 caffe.cpp:313] Batch 594, loss = 1.70347
I0629 14:08:00.272657 17196 caffe.cpp:313] Batch 595, accuracy/top1 = 0.7
I0629 14:08:00.272681 17196 caffe.cpp:313] Batch 595, accuracy/top5 = 0.9
I0629 14:08:00.272685 17196 caffe.cpp:313] Batch 595, loss = 1.39433
I0629 14:08:00.322098 17196 caffe.cpp:313] Batch 596, accuracy/top1 = 0.48
I0629 14:08:00.322124 17196 caffe.cpp:313] Batch 596, accuracy/top5 = 0.7
I0629 14:08:00.322127 17196 caffe.cpp:313] Batch 596, loss = 2.55323
I0629 14:08:00.371389 17196 caffe.cpp:313] Batch 597, accuracy/top1 = 0.72
I0629 14:08:00.371414 17196 caffe.cpp:313] Batch 597, accuracy/top5 = 0.88
I0629 14:08:00.371418 17196 caffe.cpp:313] Batch 597, loss = 1.27227
I0629 14:08:00.421181 17196 caffe.cpp:313] Batch 598, accuracy/top1 = 0.52
I0629 14:08:00.421205 17196 caffe.cpp:313] Batch 598, accuracy/top5 = 0.8
I0629 14:08:00.421210 17196 caffe.cpp:313] Batch 598, loss = 1.9493
I0629 14:08:00.471204 17196 caffe.cpp:313] Batch 599, accuracy/top1 = 0.56
I0629 14:08:00.471223 17196 caffe.cpp:313] Batch 599, accuracy/top5 = 0.8
I0629 14:08:00.471227 17196 caffe.cpp:313] Batch 599, loss = 1.81679
I0629 14:08:00.520253 17196 caffe.cpp:313] Batch 600, accuracy/top1 = 0.58
I0629 14:08:00.520277 17196 caffe.cpp:313] Batch 600, accuracy/top5 = 0.82
I0629 14:08:00.520282 17196 caffe.cpp:313] Batch 600, loss = 1.97591
I0629 14:08:00.570055 17196 caffe.cpp:313] Batch 601, accuracy/top1 = 0.58
I0629 14:08:00.570080 17196 caffe.cpp:313] Batch 601, accuracy/top5 = 0.9
I0629 14:08:00.570083 17196 caffe.cpp:313] Batch 601, loss = 1.43172
I0629 14:08:00.620363 17196 caffe.cpp:313] Batch 602, accuracy/top1 = 0.52
I0629 14:08:00.620388 17196 caffe.cpp:313] Batch 602, accuracy/top5 = 0.76
I0629 14:08:00.620391 17196 caffe.cpp:313] Batch 602, loss = 2.13861
I0629 14:08:00.670346 17196 caffe.cpp:313] Batch 603, accuracy/top1 = 0.68
I0629 14:08:00.670370 17196 caffe.cpp:313] Batch 603, accuracy/top5 = 0.86
I0629 14:08:00.670374 17196 caffe.cpp:313] Batch 603, loss = 1.18964
I0629 14:08:00.719394 17196 caffe.cpp:313] Batch 604, accuracy/top1 = 0.78
I0629 14:08:00.719419 17196 caffe.cpp:313] Batch 604, accuracy/top5 = 0.98
I0629 14:08:00.719422 17196 caffe.cpp:313] Batch 604, loss = 0.963235
I0629 14:08:00.768322 17196 caffe.cpp:313] Batch 605, accuracy/top1 = 0.48
I0629 14:08:00.768347 17196 caffe.cpp:313] Batch 605, accuracy/top5 = 0.7
I0629 14:08:00.768350 17196 caffe.cpp:313] Batch 605, loss = 2.26591
I0629 14:08:00.817682 17196 caffe.cpp:313] Batch 606, accuracy/top1 = 0.52
I0629 14:08:00.817705 17196 caffe.cpp:313] Batch 606, accuracy/top5 = 0.74
I0629 14:08:00.817709 17196 caffe.cpp:313] Batch 606, loss = 2.19564
I0629 14:08:00.867328 17196 caffe.cpp:313] Batch 607, accuracy/top1 = 0.48
I0629 14:08:00.867352 17196 caffe.cpp:313] Batch 607, accuracy/top5 = 0.82
I0629 14:08:00.867357 17196 caffe.cpp:313] Batch 607, loss = 2.04586
I0629 14:08:00.916906 17196 caffe.cpp:313] Batch 608, accuracy/top1 = 0.56
I0629 14:08:00.916929 17196 caffe.cpp:313] Batch 608, accuracy/top5 = 0.86
I0629 14:08:00.916932 17196 caffe.cpp:313] Batch 608, loss = 1.66381
I0629 14:08:00.966723 17196 caffe.cpp:313] Batch 609, accuracy/top1 = 0.5
I0629 14:08:00.966747 17196 caffe.cpp:313] Batch 609, accuracy/top5 = 0.72
I0629 14:08:00.966751 17196 caffe.cpp:313] Batch 609, loss = 2.03241
I0629 14:08:01.016034 17196 caffe.cpp:313] Batch 610, accuracy/top1 = 0.6
I0629 14:08:01.016059 17196 caffe.cpp:313] Batch 610, accuracy/top5 = 0.74
I0629 14:08:01.016063 17196 caffe.cpp:313] Batch 610, loss = 2.0979
I0629 14:08:01.065560 17196 caffe.cpp:313] Batch 611, accuracy/top1 = 0.52
I0629 14:08:01.065584 17196 caffe.cpp:313] Batch 611, accuracy/top5 = 0.76
I0629 14:08:01.065587 17196 caffe.cpp:313] Batch 611, loss = 2.22061
I0629 14:08:01.114841 17196 caffe.cpp:313] Batch 612, accuracy/top1 = 0.62
I0629 14:08:01.114886 17196 caffe.cpp:313] Batch 612, accuracy/top5 = 0.84
I0629 14:08:01.114892 17196 caffe.cpp:313] Batch 612, loss = 1.61843
I0629 14:08:01.163501 17196 caffe.cpp:313] Batch 613, accuracy/top1 = 0.58
I0629 14:08:01.163522 17196 caffe.cpp:313] Batch 613, accuracy/top5 = 0.74
I0629 14:08:01.163525 17196 caffe.cpp:313] Batch 613, loss = 2.16979
I0629 14:08:01.214484 17196 caffe.cpp:313] Batch 614, accuracy/top1 = 0.52
I0629 14:08:01.214509 17196 caffe.cpp:313] Batch 614, accuracy/top5 = 0.68
I0629 14:08:01.214512 17196 caffe.cpp:313] Batch 614, loss = 2.34479
I0629 14:08:01.265353 17196 caffe.cpp:313] Batch 615, accuracy/top1 = 0.46
I0629 14:08:01.265377 17196 caffe.cpp:313] Batch 615, accuracy/top5 = 0.78
I0629 14:08:01.265379 17196 caffe.cpp:313] Batch 615, loss = 2.16364
I0629 14:08:01.315546 17196 caffe.cpp:313] Batch 616, accuracy/top1 = 0.56
I0629 14:08:01.315570 17196 caffe.cpp:313] Batch 616, accuracy/top5 = 0.76
I0629 14:08:01.315573 17196 caffe.cpp:313] Batch 616, loss = 2.06207
I0629 14:08:01.365487 17196 caffe.cpp:313] Batch 617, accuracy/top1 = 0.58
I0629 14:08:01.365511 17196 caffe.cpp:313] Batch 617, accuracy/top5 = 0.68
I0629 14:08:01.365514 17196 caffe.cpp:313] Batch 617, loss = 2.1988
I0629 14:08:01.415539 17196 caffe.cpp:313] Batch 618, accuracy/top1 = 0.52
I0629 14:08:01.415562 17196 caffe.cpp:313] Batch 618, accuracy/top5 = 0.78
I0629 14:08:01.415565 17196 caffe.cpp:313] Batch 618, loss = 2.26387
I0629 14:08:01.464318 17196 caffe.cpp:313] Batch 619, accuracy/top1 = 0.68
I0629 14:08:01.464341 17196 caffe.cpp:313] Batch 619, accuracy/top5 = 0.82
I0629 14:08:01.464344 17196 caffe.cpp:313] Batch 619, loss = 1.44493
I0629 14:08:01.514037 17196 caffe.cpp:313] Batch 620, accuracy/top1 = 0.54
I0629 14:08:01.514060 17196 caffe.cpp:313] Batch 620, accuracy/top5 = 0.82
I0629 14:08:01.514063 17196 caffe.cpp:313] Batch 620, loss = 1.88555
I0629 14:08:01.562582 17196 caffe.cpp:313] Batch 621, accuracy/top1 = 0.54
I0629 14:08:01.562605 17196 caffe.cpp:313] Batch 621, accuracy/top5 = 0.74
I0629 14:08:01.562608 17196 caffe.cpp:313] Batch 621, loss = 2.36833
I0629 14:08:01.612409 17196 caffe.cpp:313] Batch 622, accuracy/top1 = 0.6
I0629 14:08:01.612433 17196 caffe.cpp:313] Batch 622, accuracy/top5 = 0.82
I0629 14:08:01.612437 17196 caffe.cpp:313] Batch 622, loss = 1.90887
I0629 14:08:01.662569 17196 caffe.cpp:313] Batch 623, accuracy/top1 = 0.48
I0629 14:08:01.662593 17196 caffe.cpp:313] Batch 623, accuracy/top5 = 0.78
I0629 14:08:01.662596 17196 caffe.cpp:313] Batch 623, loss = 2.20842
I0629 14:08:01.712680 17196 caffe.cpp:313] Batch 624, accuracy/top1 = 0.54
I0629 14:08:01.712703 17196 caffe.cpp:313] Batch 624, accuracy/top5 = 0.88
I0629 14:08:01.712707 17196 caffe.cpp:313] Batch 624, loss = 1.77101
I0629 14:08:01.763409 17196 caffe.cpp:313] Batch 625, accuracy/top1 = 0.48
I0629 14:08:01.763434 17196 caffe.cpp:313] Batch 625, accuracy/top5 = 0.78
I0629 14:08:01.763437 17196 caffe.cpp:313] Batch 625, loss = 2.25205
I0629 14:08:01.814038 17196 caffe.cpp:313] Batch 626, accuracy/top1 = 0.46
I0629 14:08:01.814061 17196 caffe.cpp:313] Batch 626, accuracy/top5 = 0.68
I0629 14:08:01.814064 17196 caffe.cpp:313] Batch 626, loss = 2.61428
I0629 14:08:01.865301 17196 caffe.cpp:313] Batch 627, accuracy/top1 = 0.42
I0629 14:08:01.865326 17196 caffe.cpp:313] Batch 627, accuracy/top5 = 0.74
I0629 14:08:01.865332 17196 caffe.cpp:313] Batch 627, loss = 2.25324
I0629 14:08:01.913733 17196 caffe.cpp:313] Batch 628, accuracy/top1 = 0.54
I0629 14:08:01.913753 17196 caffe.cpp:313] Batch 628, accuracy/top5 = 0.8
I0629 14:08:01.913755 17196 caffe.cpp:313] Batch 628, loss = 2.0709
I0629 14:08:01.963716 17196 caffe.cpp:313] Batch 629, accuracy/top1 = 0.46
I0629 14:08:01.963738 17196 caffe.cpp:313] Batch 629, accuracy/top5 = 0.8
I0629 14:08:01.963742 17196 caffe.cpp:313] Batch 629, loss = 2.17525
I0629 14:08:02.013644 17196 caffe.cpp:313] Batch 630, accuracy/top1 = 0.52
I0629 14:08:02.013666 17196 caffe.cpp:313] Batch 630, accuracy/top5 = 0.66
I0629 14:08:02.013669 17196 caffe.cpp:313] Batch 630, loss = 2.47448
I0629 14:08:02.062098 17196 caffe.cpp:313] Batch 631, accuracy/top1 = 0.6
I0629 14:08:02.062120 17196 caffe.cpp:313] Batch 631, accuracy/top5 = 0.84
I0629 14:08:02.062124 17196 caffe.cpp:313] Batch 631, loss = 1.45779
I0629 14:08:02.113400 17196 caffe.cpp:313] Batch 632, accuracy/top1 = 0.54
I0629 14:08:02.113425 17196 caffe.cpp:313] Batch 632, accuracy/top5 = 0.8
I0629 14:08:02.113428 17196 caffe.cpp:313] Batch 632, loss = 1.78406
I0629 14:08:02.164850 17196 caffe.cpp:313] Batch 633, accuracy/top1 = 0.62
I0629 14:08:02.164870 17196 caffe.cpp:313] Batch 633, accuracy/top5 = 0.8
I0629 14:08:02.164872 17196 caffe.cpp:313] Batch 633, loss = 1.93098
I0629 14:08:02.213886 17196 caffe.cpp:313] Batch 634, accuracy/top1 = 0.58
I0629 14:08:02.213910 17196 caffe.cpp:313] Batch 634, accuracy/top5 = 0.72
I0629 14:08:02.213913 17196 caffe.cpp:313] Batch 634, loss = 2.4086
I0629 14:08:02.264714 17196 caffe.cpp:313] Batch 635, accuracy/top1 = 0.62
I0629 14:08:02.264737 17196 caffe.cpp:313] Batch 635, accuracy/top5 = 0.8
I0629 14:08:02.264740 17196 caffe.cpp:313] Batch 635, loss = 1.7145
I0629 14:08:02.315109 17196 caffe.cpp:313] Batch 636, accuracy/top1 = 0.56
I0629 14:08:02.315134 17196 caffe.cpp:313] Batch 636, accuracy/top5 = 0.76
I0629 14:08:02.315136 17196 caffe.cpp:313] Batch 636, loss = 1.99986
I0629 14:08:02.364995 17196 caffe.cpp:313] Batch 637, accuracy/top1 = 0.5
I0629 14:08:02.365017 17196 caffe.cpp:313] Batch 637, accuracy/top5 = 0.82
I0629 14:08:02.365020 17196 caffe.cpp:313] Batch 637, loss = 1.64438
I0629 14:08:02.418639 17196 caffe.cpp:313] Batch 638, accuracy/top1 = 0.6
I0629 14:08:02.418668 17196 caffe.cpp:313] Batch 638, accuracy/top5 = 0.82
I0629 14:08:02.418670 17196 caffe.cpp:313] Batch 638, loss = 1.75368
I0629 14:08:02.470697 17196 caffe.cpp:313] Batch 639, accuracy/top1 = 0.62
I0629 14:08:02.470724 17196 caffe.cpp:313] Batch 639, accuracy/top5 = 0.8
I0629 14:08:02.470728 17196 caffe.cpp:313] Batch 639, loss = 1.75683
I0629 14:08:02.520625 17196 caffe.cpp:313] Batch 640, accuracy/top1 = 0.48
I0629 14:08:02.520649 17196 caffe.cpp:313] Batch 640, accuracy/top5 = 0.72
I0629 14:08:02.520653 17196 caffe.cpp:313] Batch 640, loss = 2.27106
I0629 14:08:02.571606 17196 caffe.cpp:313] Batch 641, accuracy/top1 = 0.52
I0629 14:08:02.571630 17196 caffe.cpp:313] Batch 641, accuracy/top5 = 0.76
I0629 14:08:02.571633 17196 caffe.cpp:313] Batch 641, loss = 1.94622
I0629 14:08:02.621493 17196 caffe.cpp:313] Batch 642, accuracy/top1 = 0.58
I0629 14:08:02.621518 17196 caffe.cpp:313] Batch 642, accuracy/top5 = 0.76
I0629 14:08:02.621522 17196 caffe.cpp:313] Batch 642, loss = 1.98231
I0629 14:08:02.672320 17196 caffe.cpp:313] Batch 643, accuracy/top1 = 0.5
I0629 14:08:02.672344 17196 caffe.cpp:313] Batch 643, accuracy/top5 = 0.76
I0629 14:08:02.672348 17196 caffe.cpp:313] Batch 643, loss = 1.87943
I0629 14:08:02.722054 17196 caffe.cpp:313] Batch 644, accuracy/top1 = 0.5
I0629 14:08:02.722079 17196 caffe.cpp:313] Batch 644, accuracy/top5 = 0.78
I0629 14:08:02.722082 17196 caffe.cpp:313] Batch 644, loss = 2.05813
I0629 14:08:02.772137 17196 caffe.cpp:313] Batch 645, accuracy/top1 = 0.56
I0629 14:08:02.772161 17196 caffe.cpp:313] Batch 645, accuracy/top5 = 0.84
I0629 14:08:02.772166 17196 caffe.cpp:313] Batch 645, loss = 2.09367
I0629 14:08:02.822876 17196 caffe.cpp:313] Batch 646, accuracy/top1 = 0.54
I0629 14:08:02.822899 17196 caffe.cpp:313] Batch 646, accuracy/top5 = 0.86
I0629 14:08:02.822903 17196 caffe.cpp:313] Batch 646, loss = 1.52715
I0629 14:08:02.872493 17196 caffe.cpp:313] Batch 647, accuracy/top1 = 0.56
I0629 14:08:02.872517 17196 caffe.cpp:313] Batch 647, accuracy/top5 = 0.76
I0629 14:08:02.872521 17196 caffe.cpp:313] Batch 647, loss = 2.14707
I0629 14:08:02.921631 17196 caffe.cpp:313] Batch 648, accuracy/top1 = 0.6
I0629 14:08:02.921653 17196 caffe.cpp:313] Batch 648, accuracy/top5 = 0.84
I0629 14:08:02.921658 17196 caffe.cpp:313] Batch 648, loss = 1.57874
I0629 14:08:02.971036 17196 caffe.cpp:313] Batch 649, accuracy/top1 = 0.54
I0629 14:08:02.971062 17196 caffe.cpp:313] Batch 649, accuracy/top5 = 0.82
I0629 14:08:02.971086 17196 caffe.cpp:313] Batch 649, loss = 1.79849
I0629 14:08:03.020332 17196 caffe.cpp:313] Batch 650, accuracy/top1 = 0.6
I0629 14:08:03.020356 17196 caffe.cpp:313] Batch 650, accuracy/top5 = 0.76
I0629 14:08:03.020360 17196 caffe.cpp:313] Batch 650, loss = 1.87285
I0629 14:08:03.071061 17196 caffe.cpp:313] Batch 651, accuracy/top1 = 0.5
I0629 14:08:03.071085 17196 caffe.cpp:313] Batch 651, accuracy/top5 = 0.74
I0629 14:08:03.071089 17196 caffe.cpp:313] Batch 651, loss = 2.36128
I0629 14:08:03.120507 17196 caffe.cpp:313] Batch 652, accuracy/top1 = 0.5
I0629 14:08:03.120527 17196 caffe.cpp:313] Batch 652, accuracy/top5 = 0.66
I0629 14:08:03.120532 17196 caffe.cpp:313] Batch 652, loss = 2.23459
I0629 14:08:03.171030 17196 caffe.cpp:313] Batch 653, accuracy/top1 = 0.38
I0629 14:08:03.171051 17196 caffe.cpp:313] Batch 653, accuracy/top5 = 0.72
I0629 14:08:03.171056 17196 caffe.cpp:313] Batch 653, loss = 2.32324
I0629 14:08:03.219161 17196 caffe.cpp:313] Batch 654, accuracy/top1 = 0.56
I0629 14:08:03.219183 17196 caffe.cpp:313] Batch 654, accuracy/top5 = 0.76
I0629 14:08:03.219187 17196 caffe.cpp:313] Batch 654, loss = 1.96648
I0629 14:08:03.269214 17196 caffe.cpp:313] Batch 655, accuracy/top1 = 0.68
I0629 14:08:03.269239 17196 caffe.cpp:313] Batch 655, accuracy/top5 = 0.9
I0629 14:08:03.269243 17196 caffe.cpp:313] Batch 655, loss = 1.1959
I0629 14:08:03.318239 17196 caffe.cpp:313] Batch 656, accuracy/top1 = 0.58
I0629 14:08:03.318264 17196 caffe.cpp:313] Batch 656, accuracy/top5 = 0.86
I0629 14:08:03.318269 17196 caffe.cpp:313] Batch 656, loss = 1.51719
I0629 14:08:03.368162 17196 caffe.cpp:313] Batch 657, accuracy/top1 = 0.6
I0629 14:08:03.368188 17196 caffe.cpp:313] Batch 657, accuracy/top5 = 0.82
I0629 14:08:03.368192 17196 caffe.cpp:313] Batch 657, loss = 1.68975
I0629 14:08:03.416900 17196 caffe.cpp:313] Batch 658, accuracy/top1 = 0.64
I0629 14:08:03.416923 17196 caffe.cpp:313] Batch 658, accuracy/top5 = 0.8
I0629 14:08:03.416927 17196 caffe.cpp:313] Batch 658, loss = 1.85913
I0629 14:08:03.467113 17196 caffe.cpp:313] Batch 659, accuracy/top1 = 0.54
I0629 14:08:03.467136 17196 caffe.cpp:313] Batch 659, accuracy/top5 = 0.76
I0629 14:08:03.467140 17196 caffe.cpp:313] Batch 659, loss = 2.18385
I0629 14:08:03.515185 17196 caffe.cpp:313] Batch 660, accuracy/top1 = 0.66
I0629 14:08:03.515209 17196 caffe.cpp:313] Batch 660, accuracy/top5 = 0.84
I0629 14:08:03.515213 17196 caffe.cpp:313] Batch 660, loss = 1.58983
I0629 14:08:03.563545 17196 caffe.cpp:313] Batch 661, accuracy/top1 = 0.6
I0629 14:08:03.563568 17196 caffe.cpp:313] Batch 661, accuracy/top5 = 0.8
I0629 14:08:03.563572 17196 caffe.cpp:313] Batch 661, loss = 1.88832
I0629 14:08:03.613003 17196 caffe.cpp:313] Batch 662, accuracy/top1 = 0.58
I0629 14:08:03.613028 17196 caffe.cpp:313] Batch 662, accuracy/top5 = 0.72
I0629 14:08:03.613031 17196 caffe.cpp:313] Batch 662, loss = 2.28749
I0629 14:08:03.662467 17196 caffe.cpp:313] Batch 663, accuracy/top1 = 0.66
I0629 14:08:03.662492 17196 caffe.cpp:313] Batch 663, accuracy/top5 = 0.76
I0629 14:08:03.662495 17196 caffe.cpp:313] Batch 663, loss = 2.12872
I0629 14:08:03.711704 17196 caffe.cpp:313] Batch 664, accuracy/top1 = 0.5
I0629 14:08:03.711727 17196 caffe.cpp:313] Batch 664, accuracy/top5 = 0.78
I0629 14:08:03.711731 17196 caffe.cpp:313] Batch 664, loss = 2.19164
I0629 14:08:03.761008 17196 caffe.cpp:313] Batch 665, accuracy/top1 = 0.52
I0629 14:08:03.761032 17196 caffe.cpp:313] Batch 665, accuracy/top5 = 0.68
I0629 14:08:03.761036 17196 caffe.cpp:313] Batch 665, loss = 2.1603
I0629 14:08:03.810935 17196 caffe.cpp:313] Batch 666, accuracy/top1 = 0.58
I0629 14:08:03.810959 17196 caffe.cpp:313] Batch 666, accuracy/top5 = 0.74
I0629 14:08:03.810963 17196 caffe.cpp:313] Batch 666, loss = 1.87139
I0629 14:08:03.861477 17196 caffe.cpp:313] Batch 667, accuracy/top1 = 0.48
I0629 14:08:03.861501 17196 caffe.cpp:313] Batch 667, accuracy/top5 = 0.8
I0629 14:08:03.861505 17196 caffe.cpp:313] Batch 667, loss = 1.97279
I0629 14:08:03.911545 17196 caffe.cpp:313] Batch 668, accuracy/top1 = 0.58
I0629 14:08:03.911586 17196 caffe.cpp:313] Batch 668, accuracy/top5 = 0.78
I0629 14:08:03.911590 17196 caffe.cpp:313] Batch 668, loss = 2.03752
I0629 14:08:03.960934 17196 caffe.cpp:313] Batch 669, accuracy/top1 = 0.64
I0629 14:08:03.960958 17196 caffe.cpp:313] Batch 669, accuracy/top5 = 0.86
I0629 14:08:03.960963 17196 caffe.cpp:313] Batch 669, loss = 1.61379
I0629 14:08:04.010880 17196 caffe.cpp:313] Batch 670, accuracy/top1 = 0.64
I0629 14:08:04.010906 17196 caffe.cpp:313] Batch 670, accuracy/top5 = 0.78
I0629 14:08:04.010912 17196 caffe.cpp:313] Batch 670, loss = 1.47041
I0629 14:08:04.058706 17196 caffe.cpp:313] Batch 671, accuracy/top1 = 0.56
I0629 14:08:04.058724 17196 caffe.cpp:313] Batch 671, accuracy/top5 = 0.8
I0629 14:08:04.058727 17196 caffe.cpp:313] Batch 671, loss = 1.79326
I0629 14:08:04.108134 17196 caffe.cpp:313] Batch 672, accuracy/top1 = 0.6
I0629 14:08:04.108155 17196 caffe.cpp:313] Batch 672, accuracy/top5 = 0.86
I0629 14:08:04.108157 17196 caffe.cpp:313] Batch 672, loss = 1.87732
I0629 14:08:04.157007 17196 caffe.cpp:313] Batch 673, accuracy/top1 = 0.68
I0629 14:08:04.157027 17196 caffe.cpp:313] Batch 673, accuracy/top5 = 0.9
I0629 14:08:04.157029 17196 caffe.cpp:313] Batch 673, loss = 1.34925
I0629 14:08:04.206686 17196 caffe.cpp:313] Batch 674, accuracy/top1 = 0.72
I0629 14:08:04.206709 17196 caffe.cpp:313] Batch 674, accuracy/top5 = 0.88
I0629 14:08:04.206712 17196 caffe.cpp:313] Batch 674, loss = 1.22339
I0629 14:08:04.256616 17196 caffe.cpp:313] Batch 675, accuracy/top1 = 0.54
I0629 14:08:04.256640 17196 caffe.cpp:313] Batch 675, accuracy/top5 = 0.82
I0629 14:08:04.256644 17196 caffe.cpp:313] Batch 675, loss = 2.03729
I0629 14:08:04.305357 17196 caffe.cpp:313] Batch 676, accuracy/top1 = 0.48
I0629 14:08:04.305380 17196 caffe.cpp:313] Batch 676, accuracy/top5 = 0.8
I0629 14:08:04.305383 17196 caffe.cpp:313] Batch 676, loss = 1.94652
I0629 14:08:04.354948 17196 caffe.cpp:313] Batch 677, accuracy/top1 = 0.64
I0629 14:08:04.354972 17196 caffe.cpp:313] Batch 677, accuracy/top5 = 0.82
I0629 14:08:04.354975 17196 caffe.cpp:313] Batch 677, loss = 1.64881
I0629 14:08:04.405017 17196 caffe.cpp:313] Batch 678, accuracy/top1 = 0.56
I0629 14:08:04.405040 17196 caffe.cpp:313] Batch 678, accuracy/top5 = 0.86
I0629 14:08:04.405043 17196 caffe.cpp:313] Batch 678, loss = 1.85927
I0629 14:08:04.453048 17196 caffe.cpp:313] Batch 679, accuracy/top1 = 0.64
I0629 14:08:04.453073 17196 caffe.cpp:313] Batch 679, accuracy/top5 = 0.84
I0629 14:08:04.453076 17196 caffe.cpp:313] Batch 679, loss = 1.48605
I0629 14:08:04.502835 17196 caffe.cpp:313] Batch 680, accuracy/top1 = 0.66
I0629 14:08:04.502853 17196 caffe.cpp:313] Batch 680, accuracy/top5 = 0.8
I0629 14:08:04.502856 17196 caffe.cpp:313] Batch 680, loss = 1.73935
I0629 14:08:04.552191 17196 caffe.cpp:313] Batch 681, accuracy/top1 = 0.66
I0629 14:08:04.552212 17196 caffe.cpp:313] Batch 681, accuracy/top5 = 0.84
I0629 14:08:04.552217 17196 caffe.cpp:313] Batch 681, loss = 1.57688
I0629 14:08:04.601402 17196 caffe.cpp:313] Batch 682, accuracy/top1 = 0.44
I0629 14:08:04.601425 17196 caffe.cpp:313] Batch 682, accuracy/top5 = 0.82
I0629 14:08:04.601428 17196 caffe.cpp:313] Batch 682, loss = 2.09647
I0629 14:08:04.650501 17196 caffe.cpp:313] Batch 683, accuracy/top1 = 0.5
I0629 14:08:04.650526 17196 caffe.cpp:313] Batch 683, accuracy/top5 = 0.74
I0629 14:08:04.650528 17196 caffe.cpp:313] Batch 683, loss = 2.40055
I0629 14:08:04.700361 17196 caffe.cpp:313] Batch 684, accuracy/top1 = 0.52
I0629 14:08:04.700387 17196 caffe.cpp:313] Batch 684, accuracy/top5 = 0.8
I0629 14:08:04.700389 17196 caffe.cpp:313] Batch 684, loss = 2.09189
I0629 14:08:04.750156 17196 caffe.cpp:313] Batch 685, accuracy/top1 = 0.52
I0629 14:08:04.750180 17196 caffe.cpp:313] Batch 685, accuracy/top5 = 0.74
I0629 14:08:04.750182 17196 caffe.cpp:313] Batch 685, loss = 2.19183
I0629 14:08:04.799834 17196 caffe.cpp:313] Batch 686, accuracy/top1 = 0.48
I0629 14:08:04.799856 17196 caffe.cpp:313] Batch 686, accuracy/top5 = 0.72
I0629 14:08:04.799860 17196 caffe.cpp:313] Batch 686, loss = 2.10565
I0629 14:08:04.848759 17196 caffe.cpp:313] Batch 687, accuracy/top1 = 0.56
I0629 14:08:04.848798 17196 caffe.cpp:313] Batch 687, accuracy/top5 = 0.78
I0629 14:08:04.848803 17196 caffe.cpp:313] Batch 687, loss = 2.31104
I0629 14:08:04.897784 17196 caffe.cpp:313] Batch 688, accuracy/top1 = 0.52
I0629 14:08:04.897806 17196 caffe.cpp:313] Batch 688, accuracy/top5 = 0.76
I0629 14:08:04.897810 17196 caffe.cpp:313] Batch 688, loss = 2.26751
I0629 14:08:04.946907 17196 caffe.cpp:313] Batch 689, accuracy/top1 = 0.68
I0629 14:08:04.946928 17196 caffe.cpp:313] Batch 689, accuracy/top5 = 0.74
I0629 14:08:04.946931 17196 caffe.cpp:313] Batch 689, loss = 1.84614
I0629 14:08:04.996013 17196 caffe.cpp:313] Batch 690, accuracy/top1 = 0.52
I0629 14:08:04.996037 17196 caffe.cpp:313] Batch 690, accuracy/top5 = 0.86
I0629 14:08:04.996040 17196 caffe.cpp:313] Batch 690, loss = 1.86073
I0629 14:08:05.044900 17196 caffe.cpp:313] Batch 691, accuracy/top1 = 0.56
I0629 14:08:05.044922 17196 caffe.cpp:313] Batch 691, accuracy/top5 = 0.8
I0629 14:08:05.044925 17196 caffe.cpp:313] Batch 691, loss = 1.91749
I0629 14:08:05.094815 17196 caffe.cpp:313] Batch 692, accuracy/top1 = 0.5
I0629 14:08:05.094838 17196 caffe.cpp:313] Batch 692, accuracy/top5 = 0.76
I0629 14:08:05.094841 17196 caffe.cpp:313] Batch 692, loss = 1.96116
I0629 14:08:05.144747 17196 caffe.cpp:313] Batch 693, accuracy/top1 = 0.66
I0629 14:08:05.144764 17196 caffe.cpp:313] Batch 693, accuracy/top5 = 0.82
I0629 14:08:05.144767 17196 caffe.cpp:313] Batch 693, loss = 1.89593
I0629 14:08:05.195044 17196 caffe.cpp:313] Batch 694, accuracy/top1 = 0.52
I0629 14:08:05.195070 17196 caffe.cpp:313] Batch 694, accuracy/top5 = 0.72
I0629 14:08:05.195072 17196 caffe.cpp:313] Batch 694, loss = 1.95427
I0629 14:08:05.244376 17196 caffe.cpp:313] Batch 695, accuracy/top1 = 0.58
I0629 14:08:05.244400 17196 caffe.cpp:313] Batch 695, accuracy/top5 = 0.82
I0629 14:08:05.244403 17196 caffe.cpp:313] Batch 695, loss = 1.7968
I0629 14:08:05.294538 17196 caffe.cpp:313] Batch 696, accuracy/top1 = 0.42
I0629 14:08:05.294561 17196 caffe.cpp:313] Batch 696, accuracy/top5 = 0.74
I0629 14:08:05.294564 17196 caffe.cpp:313] Batch 696, loss = 2.09116
I0629 14:08:05.343849 17196 caffe.cpp:313] Batch 697, accuracy/top1 = 0.66
I0629 14:08:05.343873 17196 caffe.cpp:313] Batch 697, accuracy/top5 = 0.92
I0629 14:08:05.343876 17196 caffe.cpp:313] Batch 697, loss = 1.30368
I0629 14:08:05.393694 17196 caffe.cpp:313] Batch 698, accuracy/top1 = 0.56
I0629 14:08:05.393718 17196 caffe.cpp:313] Batch 698, accuracy/top5 = 0.84
I0629 14:08:05.393720 17196 caffe.cpp:313] Batch 698, loss = 2.09098
I0629 14:08:05.441473 17196 caffe.cpp:313] Batch 699, accuracy/top1 = 0.62
I0629 14:08:05.441496 17196 caffe.cpp:313] Batch 699, accuracy/top5 = 0.94
I0629 14:08:05.441499 17196 caffe.cpp:313] Batch 699, loss = 1.29596
I0629 14:08:05.490777 17196 caffe.cpp:313] Batch 700, accuracy/top1 = 0.52
I0629 14:08:05.490799 17196 caffe.cpp:313] Batch 700, accuracy/top5 = 0.74
I0629 14:08:05.490803 17196 caffe.cpp:313] Batch 700, loss = 2.26689
I0629 14:08:05.539217 17196 caffe.cpp:313] Batch 701, accuracy/top1 = 0.5
I0629 14:08:05.539240 17196 caffe.cpp:313] Batch 701, accuracy/top5 = 0.72
I0629 14:08:05.539243 17196 caffe.cpp:313] Batch 701, loss = 2.33488
I0629 14:08:05.588582 17196 caffe.cpp:313] Batch 702, accuracy/top1 = 0.52
I0629 14:08:05.588605 17196 caffe.cpp:313] Batch 702, accuracy/top5 = 0.74
I0629 14:08:05.588608 17196 caffe.cpp:313] Batch 702, loss = 2.22295
I0629 14:08:05.637773 17196 caffe.cpp:313] Batch 703, accuracy/top1 = 0.66
I0629 14:08:05.637797 17196 caffe.cpp:313] Batch 703, accuracy/top5 = 0.9
I0629 14:08:05.637800 17196 caffe.cpp:313] Batch 703, loss = 1.26982
I0629 14:08:05.686902 17196 caffe.cpp:313] Batch 704, accuracy/top1 = 0.54
I0629 14:08:05.686926 17196 caffe.cpp:313] Batch 704, accuracy/top5 = 0.8
I0629 14:08:05.686929 17196 caffe.cpp:313] Batch 704, loss = 2.23087
I0629 14:08:05.736285 17196 caffe.cpp:313] Batch 705, accuracy/top1 = 0.66
I0629 14:08:05.736308 17196 caffe.cpp:313] Batch 705, accuracy/top5 = 0.88
I0629 14:08:05.736311 17196 caffe.cpp:313] Batch 705, loss = 1.45805
I0629 14:08:05.786178 17196 caffe.cpp:313] Batch 706, accuracy/top1 = 0.5
I0629 14:08:05.786201 17196 caffe.cpp:313] Batch 706, accuracy/top5 = 0.78
I0629 14:08:05.786206 17196 caffe.cpp:313] Batch 706, loss = 1.91739
I0629 14:08:05.835616 17196 caffe.cpp:313] Batch 707, accuracy/top1 = 0.64
I0629 14:08:05.835640 17196 caffe.cpp:313] Batch 707, accuracy/top5 = 0.82
I0629 14:08:05.835644 17196 caffe.cpp:313] Batch 707, loss = 1.6887
I0629 14:08:05.885097 17196 caffe.cpp:313] Batch 708, accuracy/top1 = 0.54
I0629 14:08:05.885121 17196 caffe.cpp:313] Batch 708, accuracy/top5 = 0.86
I0629 14:08:05.885125 17196 caffe.cpp:313] Batch 708, loss = 1.57179
I0629 14:08:05.934813 17196 caffe.cpp:313] Batch 709, accuracy/top1 = 0.56
I0629 14:08:05.934834 17196 caffe.cpp:313] Batch 709, accuracy/top5 = 0.82
I0629 14:08:05.934837 17196 caffe.cpp:313] Batch 709, loss = 1.98092
I0629 14:08:05.983207 17196 caffe.cpp:313] Batch 710, accuracy/top1 = 0.66
I0629 14:08:05.983230 17196 caffe.cpp:313] Batch 710, accuracy/top5 = 0.8
I0629 14:08:05.983233 17196 caffe.cpp:313] Batch 710, loss = 2.07622
I0629 14:08:06.033010 17196 caffe.cpp:313] Batch 711, accuracy/top1 = 0.46
I0629 14:08:06.033031 17196 caffe.cpp:313] Batch 711, accuracy/top5 = 0.76
I0629 14:08:06.033035 17196 caffe.cpp:313] Batch 711, loss = 2.16031
I0629 14:08:06.082383 17196 caffe.cpp:313] Batch 712, accuracy/top1 = 0.5
I0629 14:08:06.082407 17196 caffe.cpp:313] Batch 712, accuracy/top5 = 0.8
I0629 14:08:06.082411 17196 caffe.cpp:313] Batch 712, loss = 2.1922
I0629 14:08:06.132438 17196 caffe.cpp:313] Batch 713, accuracy/top1 = 0.46
I0629 14:08:06.132468 17196 caffe.cpp:313] Batch 713, accuracy/top5 = 0.78
I0629 14:08:06.132473 17196 caffe.cpp:313] Batch 713, loss = 2.49303
I0629 14:08:06.192257 17196 caffe.cpp:313] Batch 714, accuracy/top1 = 0.62
I0629 14:08:06.192277 17196 caffe.cpp:313] Batch 714, accuracy/top5 = 0.8
I0629 14:08:06.192281 17196 caffe.cpp:313] Batch 714, loss = 1.80047
I0629 14:08:06.241693 17196 caffe.cpp:313] Batch 715, accuracy/top1 = 0.6
I0629 14:08:06.241714 17196 caffe.cpp:313] Batch 715, accuracy/top5 = 0.8
I0629 14:08:06.241717 17196 caffe.cpp:313] Batch 715, loss = 2.02328
I0629 14:08:06.290920 17196 caffe.cpp:313] Batch 716, accuracy/top1 = 0.62
I0629 14:08:06.290944 17196 caffe.cpp:313] Batch 716, accuracy/top5 = 0.76
I0629 14:08:06.290948 17196 caffe.cpp:313] Batch 716, loss = 2.21512
I0629 14:08:06.340234 17196 caffe.cpp:313] Batch 717, accuracy/top1 = 0.6
I0629 14:08:06.340257 17196 caffe.cpp:313] Batch 717, accuracy/top5 = 0.84
I0629 14:08:06.340261 17196 caffe.cpp:313] Batch 717, loss = 1.5441
I0629 14:08:06.389968 17196 caffe.cpp:313] Batch 718, accuracy/top1 = 0.48
I0629 14:08:06.389992 17196 caffe.cpp:313] Batch 718, accuracy/top5 = 0.64
I0629 14:08:06.389997 17196 caffe.cpp:313] Batch 718, loss = 2.84559
I0629 14:08:06.438887 17196 caffe.cpp:313] Batch 719, accuracy/top1 = 0.6
I0629 14:08:06.438911 17196 caffe.cpp:313] Batch 719, accuracy/top5 = 0.82
I0629 14:08:06.438915 17196 caffe.cpp:313] Batch 719, loss = 1.80179
I0629 14:08:06.488930 17196 caffe.cpp:313] Batch 720, accuracy/top1 = 0.5
I0629 14:08:06.488953 17196 caffe.cpp:313] Batch 720, accuracy/top5 = 0.82
I0629 14:08:06.488957 17196 caffe.cpp:313] Batch 720, loss = 1.76833
I0629 14:08:06.538779 17196 caffe.cpp:313] Batch 721, accuracy/top1 = 0.54
I0629 14:08:06.538799 17196 caffe.cpp:313] Batch 721, accuracy/top5 = 0.76
I0629 14:08:06.538802 17196 caffe.cpp:313] Batch 721, loss = 1.99509
I0629 14:08:06.588814 17196 caffe.cpp:313] Batch 722, accuracy/top1 = 0.64
I0629 14:08:06.588835 17196 caffe.cpp:313] Batch 722, accuracy/top5 = 0.76
I0629 14:08:06.588840 17196 caffe.cpp:313] Batch 722, loss = 1.88132
I0629 14:08:06.638914 17196 caffe.cpp:313] Batch 723, accuracy/top1 = 0.52
I0629 14:08:06.638938 17196 caffe.cpp:313] Batch 723, accuracy/top5 = 0.76
I0629 14:08:06.638942 17196 caffe.cpp:313] Batch 723, loss = 2.05816
I0629 14:08:06.688282 17196 caffe.cpp:313] Batch 724, accuracy/top1 = 0.64
I0629 14:08:06.688305 17196 caffe.cpp:313] Batch 724, accuracy/top5 = 0.9
I0629 14:08:06.688328 17196 caffe.cpp:313] Batch 724, loss = 1.37946
I0629 14:08:06.738169 17196 caffe.cpp:313] Batch 725, accuracy/top1 = 0.62
I0629 14:08:06.738193 17196 caffe.cpp:313] Batch 725, accuracy/top5 = 0.88
I0629 14:08:06.738198 17196 caffe.cpp:313] Batch 725, loss = 1.40314
I0629 14:08:06.788967 17196 caffe.cpp:313] Batch 726, accuracy/top1 = 0.58
I0629 14:08:06.788992 17196 caffe.cpp:313] Batch 726, accuracy/top5 = 0.86
I0629 14:08:06.788996 17196 caffe.cpp:313] Batch 726, loss = 1.62756
I0629 14:08:06.838996 17196 caffe.cpp:313] Batch 727, accuracy/top1 = 0.56
I0629 14:08:06.839020 17196 caffe.cpp:313] Batch 727, accuracy/top5 = 0.82
I0629 14:08:06.839025 17196 caffe.cpp:313] Batch 727, loss = 2.09972
I0629 14:08:06.887984 17196 caffe.cpp:313] Batch 728, accuracy/top1 = 0.64
I0629 14:08:06.888007 17196 caffe.cpp:313] Batch 728, accuracy/top5 = 0.78
I0629 14:08:06.888011 17196 caffe.cpp:313] Batch 728, loss = 1.73859
I0629 14:08:06.937453 17196 caffe.cpp:313] Batch 729, accuracy/top1 = 0.62
I0629 14:08:06.937476 17196 caffe.cpp:313] Batch 729, accuracy/top5 = 0.82
I0629 14:08:06.937480 17196 caffe.cpp:313] Batch 729, loss = 1.78846
I0629 14:08:06.988200 17196 caffe.cpp:313] Batch 730, accuracy/top1 = 0.52
I0629 14:08:06.988224 17196 caffe.cpp:313] Batch 730, accuracy/top5 = 0.72
I0629 14:08:06.988227 17196 caffe.cpp:313] Batch 730, loss = 1.97095
I0629 14:08:07.037335 17196 caffe.cpp:313] Batch 731, accuracy/top1 = 0.48
I0629 14:08:07.037355 17196 caffe.cpp:313] Batch 731, accuracy/top5 = 0.76
I0629 14:08:07.037359 17196 caffe.cpp:313] Batch 731, loss = 2.17499
I0629 14:08:07.087618 17196 caffe.cpp:313] Batch 732, accuracy/top1 = 0.7
I0629 14:08:07.087642 17196 caffe.cpp:313] Batch 732, accuracy/top5 = 0.84
I0629 14:08:07.087646 17196 caffe.cpp:313] Batch 732, loss = 1.64271
I0629 14:08:07.138348 17196 caffe.cpp:313] Batch 733, accuracy/top1 = 0.46
I0629 14:08:07.138367 17196 caffe.cpp:313] Batch 733, accuracy/top5 = 0.78
I0629 14:08:07.138371 17196 caffe.cpp:313] Batch 733, loss = 1.98401
I0629 14:08:07.189258 17196 caffe.cpp:313] Batch 734, accuracy/top1 = 0.54
I0629 14:08:07.189282 17196 caffe.cpp:313] Batch 734, accuracy/top5 = 0.78
I0629 14:08:07.189286 17196 caffe.cpp:313] Batch 734, loss = 1.86914
I0629 14:08:07.238899 17196 caffe.cpp:313] Batch 735, accuracy/top1 = 0.52
I0629 14:08:07.238921 17196 caffe.cpp:313] Batch 735, accuracy/top5 = 0.72
I0629 14:08:07.238925 17196 caffe.cpp:313] Batch 735, loss = 2.12795
I0629 14:08:07.289567 17196 caffe.cpp:313] Batch 736, accuracy/top1 = 0.52
I0629 14:08:07.289592 17196 caffe.cpp:313] Batch 736, accuracy/top5 = 0.78
I0629 14:08:07.289597 17196 caffe.cpp:313] Batch 736, loss = 2.04395
I0629 14:08:07.340263 17196 caffe.cpp:313] Batch 737, accuracy/top1 = 0.54
I0629 14:08:07.340286 17196 caffe.cpp:313] Batch 737, accuracy/top5 = 0.84
I0629 14:08:07.340291 17196 caffe.cpp:313] Batch 737, loss = 1.83023
I0629 14:08:07.391309 17196 caffe.cpp:313] Batch 738, accuracy/top1 = 0.62
I0629 14:08:07.391333 17196 caffe.cpp:313] Batch 738, accuracy/top5 = 0.84
I0629 14:08:07.391337 17196 caffe.cpp:313] Batch 738, loss = 1.54608
I0629 14:08:07.439431 17196 caffe.cpp:313] Batch 739, accuracy/top1 = 0.6
I0629 14:08:07.439455 17196 caffe.cpp:313] Batch 739, accuracy/top5 = 0.84
I0629 14:08:07.439460 17196 caffe.cpp:313] Batch 739, loss = 1.6936
I0629 14:08:07.489271 17196 caffe.cpp:313] Batch 740, accuracy/top1 = 0.68
I0629 14:08:07.489295 17196 caffe.cpp:313] Batch 740, accuracy/top5 = 0.88
I0629 14:08:07.489300 17196 caffe.cpp:313] Batch 740, loss = 1.53224
I0629 14:08:07.538519 17196 caffe.cpp:313] Batch 741, accuracy/top1 = 0.62
I0629 14:08:07.538542 17196 caffe.cpp:313] Batch 741, accuracy/top5 = 0.78
I0629 14:08:07.538547 17196 caffe.cpp:313] Batch 741, loss = 1.76317
I0629 14:08:07.589174 17196 caffe.cpp:313] Batch 742, accuracy/top1 = 0.58
I0629 14:08:07.589198 17196 caffe.cpp:313] Batch 742, accuracy/top5 = 0.84
I0629 14:08:07.589202 17196 caffe.cpp:313] Batch 742, loss = 1.70784
I0629 14:08:07.638774 17196 caffe.cpp:313] Batch 743, accuracy/top1 = 0.42
I0629 14:08:07.638815 17196 caffe.cpp:313] Batch 743, accuracy/top5 = 0.78
I0629 14:08:07.638819 17196 caffe.cpp:313] Batch 743, loss = 2.20194
I0629 14:08:07.688783 17196 caffe.cpp:313] Batch 744, accuracy/top1 = 0.48
I0629 14:08:07.688807 17196 caffe.cpp:313] Batch 744, accuracy/top5 = 0.78
I0629 14:08:07.688812 17196 caffe.cpp:313] Batch 744, loss = 2.10318
I0629 14:08:07.739159 17196 caffe.cpp:313] Batch 745, accuracy/top1 = 0.6
I0629 14:08:07.739183 17196 caffe.cpp:313] Batch 745, accuracy/top5 = 0.78
I0629 14:08:07.739188 17196 caffe.cpp:313] Batch 745, loss = 1.57103
I0629 14:08:07.789409 17196 caffe.cpp:313] Batch 746, accuracy/top1 = 0.62
I0629 14:08:07.789433 17196 caffe.cpp:313] Batch 746, accuracy/top5 = 0.8
I0629 14:08:07.789436 17196 caffe.cpp:313] Batch 746, loss = 1.86514
I0629 14:08:07.840070 17196 caffe.cpp:313] Batch 747, accuracy/top1 = 0.62
I0629 14:08:07.840095 17196 caffe.cpp:313] Batch 747, accuracy/top5 = 0.86
I0629 14:08:07.840098 17196 caffe.cpp:313] Batch 747, loss = 1.60623
I0629 14:08:07.889483 17196 caffe.cpp:313] Batch 748, accuracy/top1 = 0.62
I0629 14:08:07.889508 17196 caffe.cpp:313] Batch 748, accuracy/top5 = 0.86
I0629 14:08:07.889513 17196 caffe.cpp:313] Batch 748, loss = 1.35495
I0629 14:08:07.938715 17196 caffe.cpp:313] Batch 749, accuracy/top1 = 0.64
I0629 14:08:07.938738 17196 caffe.cpp:313] Batch 749, accuracy/top5 = 0.84
I0629 14:08:07.938742 17196 caffe.cpp:313] Batch 749, loss = 1.49955
I0629 14:08:07.988719 17196 caffe.cpp:313] Batch 750, accuracy/top1 = 0.58
I0629 14:08:07.988744 17196 caffe.cpp:313] Batch 750, accuracy/top5 = 0.86
I0629 14:08:07.988749 17196 caffe.cpp:313] Batch 750, loss = 1.62971
I0629 14:08:08.037498 17196 caffe.cpp:313] Batch 751, accuracy/top1 = 0.62
I0629 14:08:08.037520 17196 caffe.cpp:313] Batch 751, accuracy/top5 = 0.78
I0629 14:08:08.037524 17196 caffe.cpp:313] Batch 751, loss = 1.85109
I0629 14:08:08.086449 17196 caffe.cpp:313] Batch 752, accuracy/top1 = 0.64
I0629 14:08:08.086474 17196 caffe.cpp:313] Batch 752, accuracy/top5 = 0.88
I0629 14:08:08.086478 17196 caffe.cpp:313] Batch 752, loss = 1.37001
I0629 14:08:08.136716 17196 caffe.cpp:313] Batch 753, accuracy/top1 = 0.42
I0629 14:08:08.136734 17196 caffe.cpp:313] Batch 753, accuracy/top5 = 0.74
I0629 14:08:08.136737 17196 caffe.cpp:313] Batch 753, loss = 2.10085
I0629 14:08:08.186195 17196 caffe.cpp:313] Batch 754, accuracy/top1 = 0.62
I0629 14:08:08.186219 17196 caffe.cpp:313] Batch 754, accuracy/top5 = 0.84
I0629 14:08:08.186223 17196 caffe.cpp:313] Batch 754, loss = 1.73028
I0629 14:08:08.234995 17196 caffe.cpp:313] Batch 755, accuracy/top1 = 0.54
I0629 14:08:08.235019 17196 caffe.cpp:313] Batch 755, accuracy/top5 = 0.74
I0629 14:08:08.235023 17196 caffe.cpp:313] Batch 755, loss = 2.2055
I0629 14:08:08.284852 17196 caffe.cpp:313] Batch 756, accuracy/top1 = 0.68
I0629 14:08:08.284873 17196 caffe.cpp:313] Batch 756, accuracy/top5 = 0.82
I0629 14:08:08.284876 17196 caffe.cpp:313] Batch 756, loss = 1.57802
I0629 14:08:08.333868 17196 caffe.cpp:313] Batch 757, accuracy/top1 = 0.62
I0629 14:08:08.333886 17196 caffe.cpp:313] Batch 757, accuracy/top5 = 0.84
I0629 14:08:08.333890 17196 caffe.cpp:313] Batch 757, loss = 1.58366
I0629 14:08:08.383232 17196 caffe.cpp:313] Batch 758, accuracy/top1 = 0.66
I0629 14:08:08.383255 17196 caffe.cpp:313] Batch 758, accuracy/top5 = 0.84
I0629 14:08:08.383257 17196 caffe.cpp:313] Batch 758, loss = 1.50762
I0629 14:08:08.432152 17196 caffe.cpp:313] Batch 759, accuracy/top1 = 0.56
I0629 14:08:08.432176 17196 caffe.cpp:313] Batch 759, accuracy/top5 = 0.76
I0629 14:08:08.432179 17196 caffe.cpp:313] Batch 759, loss = 2.24685
I0629 14:08:08.481037 17196 caffe.cpp:313] Batch 760, accuracy/top1 = 0.62
I0629 14:08:08.481062 17196 caffe.cpp:313] Batch 760, accuracy/top5 = 0.9
I0629 14:08:08.481065 17196 caffe.cpp:313] Batch 760, loss = 1.33034
I0629 14:08:08.529263 17196 caffe.cpp:313] Batch 761, accuracy/top1 = 0.54
I0629 14:08:08.529289 17196 caffe.cpp:313] Batch 761, accuracy/top5 = 0.84
I0629 14:08:08.529291 17196 caffe.cpp:313] Batch 761, loss = 1.93779
I0629 14:08:08.578933 17196 caffe.cpp:313] Batch 762, accuracy/top1 = 0.66
I0629 14:08:08.578969 17196 caffe.cpp:313] Batch 762, accuracy/top5 = 0.82
I0629 14:08:08.578971 17196 caffe.cpp:313] Batch 762, loss = 1.77917
I0629 14:08:08.626719 17196 caffe.cpp:313] Batch 763, accuracy/top1 = 0.54
I0629 14:08:08.626744 17196 caffe.cpp:313] Batch 763, accuracy/top5 = 0.78
I0629 14:08:08.626746 17196 caffe.cpp:313] Batch 763, loss = 1.8968
I0629 14:08:08.677040 17196 caffe.cpp:313] Batch 764, accuracy/top1 = 0.38
I0629 14:08:08.677063 17196 caffe.cpp:313] Batch 764, accuracy/top5 = 0.68
I0629 14:08:08.677067 17196 caffe.cpp:313] Batch 764, loss = 2.6288
I0629 14:08:08.726830 17196 caffe.cpp:313] Batch 765, accuracy/top1 = 0.52
I0629 14:08:08.726852 17196 caffe.cpp:313] Batch 765, accuracy/top5 = 0.78
I0629 14:08:08.726855 17196 caffe.cpp:313] Batch 765, loss = 2.04808
I0629 14:08:08.776512 17196 caffe.cpp:313] Batch 766, accuracy/top1 = 0.6
I0629 14:08:08.776537 17196 caffe.cpp:313] Batch 766, accuracy/top5 = 0.84
I0629 14:08:08.776540 17196 caffe.cpp:313] Batch 766, loss = 1.54369
I0629 14:08:08.826309 17196 caffe.cpp:313] Batch 767, accuracy/top1 = 0.56
I0629 14:08:08.826333 17196 caffe.cpp:313] Batch 767, accuracy/top5 = 0.82
I0629 14:08:08.826336 17196 caffe.cpp:313] Batch 767, loss = 1.67897
I0629 14:08:08.875531 17196 caffe.cpp:313] Batch 768, accuracy/top1 = 0.54
I0629 14:08:08.875555 17196 caffe.cpp:313] Batch 768, accuracy/top5 = 0.76
I0629 14:08:08.875558 17196 caffe.cpp:313] Batch 768, loss = 1.81805
I0629 14:08:08.925047 17196 caffe.cpp:313] Batch 769, accuracy/top1 = 0.56
I0629 14:08:08.925068 17196 caffe.cpp:313] Batch 769, accuracy/top5 = 0.8
I0629 14:08:08.925071 17196 caffe.cpp:313] Batch 769, loss = 1.75616
I0629 14:08:08.974592 17196 caffe.cpp:313] Batch 770, accuracy/top1 = 0.54
I0629 14:08:08.974617 17196 caffe.cpp:313] Batch 770, accuracy/top5 = 0.78
I0629 14:08:08.974619 17196 caffe.cpp:313] Batch 770, loss = 2.09284
I0629 14:08:09.023262 17196 caffe.cpp:313] Batch 771, accuracy/top1 = 0.56
I0629 14:08:09.023283 17196 caffe.cpp:313] Batch 771, accuracy/top5 = 0.8
I0629 14:08:09.023286 17196 caffe.cpp:313] Batch 771, loss = 2.1999
I0629 14:08:09.072427 17196 caffe.cpp:313] Batch 772, accuracy/top1 = 0.52
I0629 14:08:09.072451 17196 caffe.cpp:313] Batch 772, accuracy/top5 = 0.76
I0629 14:08:09.072454 17196 caffe.cpp:313] Batch 772, loss = 2.35945
I0629 14:08:09.120690 17196 caffe.cpp:313] Batch 773, accuracy/top1 = 0.54
I0629 14:08:09.120714 17196 caffe.cpp:313] Batch 773, accuracy/top5 = 0.72
I0629 14:08:09.120718 17196 caffe.cpp:313] Batch 773, loss = 2.41065
I0629 14:08:09.171002 17196 caffe.cpp:313] Batch 774, accuracy/top1 = 0.52
I0629 14:08:09.171021 17196 caffe.cpp:313] Batch 774, accuracy/top5 = 0.8
I0629 14:08:09.171025 17196 caffe.cpp:313] Batch 774, loss = 1.80822
I0629 14:08:09.219727 17196 caffe.cpp:313] Batch 775, accuracy/top1 = 0.58
I0629 14:08:09.219751 17196 caffe.cpp:313] Batch 775, accuracy/top5 = 0.84
I0629 14:08:09.219754 17196 caffe.cpp:313] Batch 775, loss = 1.54338
I0629 14:08:09.270025 17196 caffe.cpp:313] Batch 776, accuracy/top1 = 0.68
I0629 14:08:09.270050 17196 caffe.cpp:313] Batch 776, accuracy/top5 = 0.84
I0629 14:08:09.270052 17196 caffe.cpp:313] Batch 776, loss = 1.82537
I0629 14:08:09.319540 17196 caffe.cpp:313] Batch 777, accuracy/top1 = 0.56
I0629 14:08:09.319564 17196 caffe.cpp:313] Batch 777, accuracy/top5 = 0.82
I0629 14:08:09.319567 17196 caffe.cpp:313] Batch 777, loss = 1.85319
I0629 14:08:09.369150 17196 caffe.cpp:313] Batch 778, accuracy/top1 = 0.64
I0629 14:08:09.369174 17196 caffe.cpp:313] Batch 778, accuracy/top5 = 0.82
I0629 14:08:09.369177 17196 caffe.cpp:313] Batch 778, loss = 1.45681
I0629 14:08:09.417542 17196 caffe.cpp:313] Batch 779, accuracy/top1 = 0.66
I0629 14:08:09.417569 17196 caffe.cpp:313] Batch 779, accuracy/top5 = 0.8
I0629 14:08:09.417572 17196 caffe.cpp:313] Batch 779, loss = 2.01944
I0629 14:08:09.466735 17196 caffe.cpp:313] Batch 780, accuracy/top1 = 0.54
I0629 14:08:09.466760 17196 caffe.cpp:313] Batch 780, accuracy/top5 = 0.8
I0629 14:08:09.466763 17196 caffe.cpp:313] Batch 780, loss = 1.92414
I0629 14:08:09.515650 17196 caffe.cpp:313] Batch 781, accuracy/top1 = 0.6
I0629 14:08:09.515671 17196 caffe.cpp:313] Batch 781, accuracy/top5 = 0.8
I0629 14:08:09.515673 17196 caffe.cpp:313] Batch 781, loss = 1.78387
I0629 14:08:09.564414 17196 caffe.cpp:313] Batch 782, accuracy/top1 = 0.68
I0629 14:08:09.564440 17196 caffe.cpp:313] Batch 782, accuracy/top5 = 0.88
I0629 14:08:09.564442 17196 caffe.cpp:313] Batch 782, loss = 1.35197
I0629 14:08:09.613564 17196 caffe.cpp:313] Batch 783, accuracy/top1 = 0.62
I0629 14:08:09.613589 17196 caffe.cpp:313] Batch 783, accuracy/top5 = 0.88
I0629 14:08:09.613591 17196 caffe.cpp:313] Batch 783, loss = 1.51525
I0629 14:08:09.663434 17196 caffe.cpp:313] Batch 784, accuracy/top1 = 0.54
I0629 14:08:09.663458 17196 caffe.cpp:313] Batch 784, accuracy/top5 = 0.76
I0629 14:08:09.663461 17196 caffe.cpp:313] Batch 784, loss = 2.15015
I0629 14:08:09.712625 17196 caffe.cpp:313] Batch 785, accuracy/top1 = 0.46
I0629 14:08:09.712649 17196 caffe.cpp:313] Batch 785, accuracy/top5 = 0.8
I0629 14:08:09.712652 17196 caffe.cpp:313] Batch 785, loss = 1.91157
I0629 14:08:09.761874 17196 caffe.cpp:313] Batch 786, accuracy/top1 = 0.68
I0629 14:08:09.761898 17196 caffe.cpp:313] Batch 786, accuracy/top5 = 0.9
I0629 14:08:09.761901 17196 caffe.cpp:313] Batch 786, loss = 1.16768
I0629 14:08:09.811365 17196 caffe.cpp:313] Batch 787, accuracy/top1 = 0.46
I0629 14:08:09.811389 17196 caffe.cpp:313] Batch 787, accuracy/top5 = 0.84
I0629 14:08:09.811393 17196 caffe.cpp:313] Batch 787, loss = 1.68502
I0629 14:08:09.861075 17196 caffe.cpp:313] Batch 788, accuracy/top1 = 0.54
I0629 14:08:09.861099 17196 caffe.cpp:313] Batch 788, accuracy/top5 = 0.8
I0629 14:08:09.861102 17196 caffe.cpp:313] Batch 788, loss = 2.01386
I0629 14:08:09.910141 17196 caffe.cpp:313] Batch 789, accuracy/top1 = 0.62
I0629 14:08:09.910166 17196 caffe.cpp:313] Batch 789, accuracy/top5 = 0.82
I0629 14:08:09.910168 17196 caffe.cpp:313] Batch 789, loss = 1.60866
I0629 14:08:09.959208 17196 caffe.cpp:313] Batch 790, accuracy/top1 = 0.6
I0629 14:08:09.959230 17196 caffe.cpp:313] Batch 790, accuracy/top5 = 0.84
I0629 14:08:09.959233 17196 caffe.cpp:313] Batch 790, loss = 1.56912
I0629 14:08:10.008532 17196 caffe.cpp:313] Batch 791, accuracy/top1 = 0.54
I0629 14:08:10.008555 17196 caffe.cpp:313] Batch 791, accuracy/top5 = 0.72
I0629 14:08:10.008559 17196 caffe.cpp:313] Batch 791, loss = 2.18515
I0629 14:08:10.056090 17196 caffe.cpp:313] Batch 792, accuracy/top1 = 0.5
I0629 14:08:10.056113 17196 caffe.cpp:313] Batch 792, accuracy/top5 = 0.8
I0629 14:08:10.056115 17196 caffe.cpp:313] Batch 792, loss = 1.9045
I0629 14:08:10.105890 17196 caffe.cpp:313] Batch 793, accuracy/top1 = 0.52
I0629 14:08:10.105914 17196 caffe.cpp:313] Batch 793, accuracy/top5 = 0.76
I0629 14:08:10.105917 17196 caffe.cpp:313] Batch 793, loss = 2.06178
I0629 14:08:10.156508 17196 caffe.cpp:313] Batch 794, accuracy/top1 = 0.64
I0629 14:08:10.156528 17196 caffe.cpp:313] Batch 794, accuracy/top5 = 0.78
I0629 14:08:10.156532 17196 caffe.cpp:313] Batch 794, loss = 1.81377
I0629 14:08:10.205392 17196 caffe.cpp:313] Batch 795, accuracy/top1 = 0.5
I0629 14:08:10.205415 17196 caffe.cpp:313] Batch 795, accuracy/top5 = 0.8
I0629 14:08:10.205418 17196 caffe.cpp:313] Batch 795, loss = 2.29576
I0629 14:08:10.254808 17196 caffe.cpp:313] Batch 796, accuracy/top1 = 0.5
I0629 14:08:10.254833 17196 caffe.cpp:313] Batch 796, accuracy/top5 = 0.74
I0629 14:08:10.254837 17196 caffe.cpp:313] Batch 796, loss = 2.08535
I0629 14:08:10.304430 17196 caffe.cpp:313] Batch 797, accuracy/top1 = 0.52
I0629 14:08:10.304455 17196 caffe.cpp:313] Batch 797, accuracy/top5 = 0.78
I0629 14:08:10.304458 17196 caffe.cpp:313] Batch 797, loss = 2.00085
I0629 14:08:10.354609 17196 caffe.cpp:313] Batch 798, accuracy/top1 = 0.68
I0629 14:08:10.354632 17196 caffe.cpp:313] Batch 798, accuracy/top5 = 0.92
I0629 14:08:10.354635 17196 caffe.cpp:313] Batch 798, loss = 1.4026
I0629 14:08:10.403981 17196 caffe.cpp:313] Batch 799, accuracy/top1 = 0.52
I0629 14:08:10.404000 17196 caffe.cpp:313] Batch 799, accuracy/top5 = 0.74
I0629 14:08:10.404016 17196 caffe.cpp:313] Batch 799, loss = 1.95882
I0629 14:08:10.453573 17196 caffe.cpp:313] Batch 800, accuracy/top1 = 0.46
I0629 14:08:10.453593 17196 caffe.cpp:313] Batch 800, accuracy/top5 = 0.62
I0629 14:08:10.453598 17196 caffe.cpp:313] Batch 800, loss = 3.16828
I0629 14:08:10.502904 17196 caffe.cpp:313] Batch 801, accuracy/top1 = 0.56
I0629 14:08:10.502924 17196 caffe.cpp:313] Batch 801, accuracy/top5 = 0.76
I0629 14:08:10.502928 17196 caffe.cpp:313] Batch 801, loss = 1.72129
I0629 14:08:10.551492 17196 caffe.cpp:313] Batch 802, accuracy/top1 = 0.58
I0629 14:08:10.551517 17196 caffe.cpp:313] Batch 802, accuracy/top5 = 0.84
I0629 14:08:10.551519 17196 caffe.cpp:313] Batch 802, loss = 1.58749
I0629 14:08:10.601480 17196 caffe.cpp:313] Batch 803, accuracy/top1 = 0.66
I0629 14:08:10.601501 17196 caffe.cpp:313] Batch 803, accuracy/top5 = 0.8
I0629 14:08:10.601505 17196 caffe.cpp:313] Batch 803, loss = 1.62546
I0629 14:08:10.650728 17196 caffe.cpp:313] Batch 804, accuracy/top1 = 0.56
I0629 14:08:10.650753 17196 caffe.cpp:313] Batch 804, accuracy/top5 = 0.9
I0629 14:08:10.650756 17196 caffe.cpp:313] Batch 804, loss = 1.68093
I0629 14:08:10.700088 17196 caffe.cpp:313] Batch 805, accuracy/top1 = 0.6
I0629 14:08:10.700111 17196 caffe.cpp:313] Batch 805, accuracy/top5 = 0.8
I0629 14:08:10.700114 17196 caffe.cpp:313] Batch 805, loss = 1.8577
I0629 14:08:10.749022 17196 caffe.cpp:313] Batch 806, accuracy/top1 = 0.6
I0629 14:08:10.749044 17196 caffe.cpp:313] Batch 806, accuracy/top5 = 0.9
I0629 14:08:10.749047 17196 caffe.cpp:313] Batch 806, loss = 1.41513
I0629 14:08:10.798509 17196 caffe.cpp:313] Batch 807, accuracy/top1 = 0.56
I0629 14:08:10.798532 17196 caffe.cpp:313] Batch 807, accuracy/top5 = 0.84
I0629 14:08:10.798537 17196 caffe.cpp:313] Batch 807, loss = 1.86403
I0629 14:08:10.848569 17196 caffe.cpp:313] Batch 808, accuracy/top1 = 0.64
I0629 14:08:10.848592 17196 caffe.cpp:313] Batch 808, accuracy/top5 = 0.88
I0629 14:08:10.848595 17196 caffe.cpp:313] Batch 808, loss = 1.77225
I0629 14:08:10.898794 17196 caffe.cpp:313] Batch 809, accuracy/top1 = 0.48
I0629 14:08:10.898818 17196 caffe.cpp:313] Batch 809, accuracy/top5 = 0.7
I0629 14:08:10.898821 17196 caffe.cpp:313] Batch 809, loss = 2.64051
I0629 14:08:10.948220 17196 caffe.cpp:313] Batch 810, accuracy/top1 = 0.48
I0629 14:08:10.948245 17196 caffe.cpp:313] Batch 810, accuracy/top5 = 0.76
I0629 14:08:10.948247 17196 caffe.cpp:313] Batch 810, loss = 2.14171
I0629 14:08:10.998109 17196 caffe.cpp:313] Batch 811, accuracy/top1 = 0.58
I0629 14:08:10.998134 17196 caffe.cpp:313] Batch 811, accuracy/top5 = 0.74
I0629 14:08:10.998137 17196 caffe.cpp:313] Batch 811, loss = 2.32995
I0629 14:08:11.047389 17196 caffe.cpp:313] Batch 812, accuracy/top1 = 0.46
I0629 14:08:11.047413 17196 caffe.cpp:313] Batch 812, accuracy/top5 = 0.8
I0629 14:08:11.047416 17196 caffe.cpp:313] Batch 812, loss = 2.006
I0629 14:08:11.096403 17196 caffe.cpp:313] Batch 813, accuracy/top1 = 0.52
I0629 14:08:11.096427 17196 caffe.cpp:313] Batch 813, accuracy/top5 = 0.74
I0629 14:08:11.096431 17196 caffe.cpp:313] Batch 813, loss = 1.96871
I0629 14:08:11.146117 17196 caffe.cpp:313] Batch 814, accuracy/top1 = 0.44
I0629 14:08:11.146136 17196 caffe.cpp:313] Batch 814, accuracy/top5 = 0.74
I0629 14:08:11.146137 17196 caffe.cpp:313] Batch 814, loss = 2.36658
I0629 14:08:11.195071 17196 caffe.cpp:313] Batch 815, accuracy/top1 = 0.52
I0629 14:08:11.195093 17196 caffe.cpp:313] Batch 815, accuracy/top5 = 0.82
I0629 14:08:11.195096 17196 caffe.cpp:313] Batch 815, loss = 1.55574
I0629 14:08:11.244822 17196 caffe.cpp:313] Batch 816, accuracy/top1 = 0.52
I0629 14:08:11.244846 17196 caffe.cpp:313] Batch 816, accuracy/top5 = 0.7
I0629 14:08:11.244849 17196 caffe.cpp:313] Batch 816, loss = 2.18625
I0629 14:08:11.294678 17196 caffe.cpp:313] Batch 817, accuracy/top1 = 0.6
I0629 14:08:11.294701 17196 caffe.cpp:313] Batch 817, accuracy/top5 = 0.84
I0629 14:08:11.294704 17196 caffe.cpp:313] Batch 817, loss = 1.67056
I0629 14:08:11.344553 17196 caffe.cpp:313] Batch 818, accuracy/top1 = 0.58
I0629 14:08:11.344599 17196 caffe.cpp:313] Batch 818, accuracy/top5 = 0.86
I0629 14:08:11.344602 17196 caffe.cpp:313] Batch 818, loss = 1.56102
I0629 14:08:11.393630 17196 caffe.cpp:313] Batch 819, accuracy/top1 = 0.66
I0629 14:08:11.393651 17196 caffe.cpp:313] Batch 819, accuracy/top5 = 0.84
I0629 14:08:11.393654 17196 caffe.cpp:313] Batch 819, loss = 1.6013
I0629 14:08:11.442653 17196 caffe.cpp:313] Batch 820, accuracy/top1 = 0.54
I0629 14:08:11.442677 17196 caffe.cpp:313] Batch 820, accuracy/top5 = 0.78
I0629 14:08:11.442680 17196 caffe.cpp:313] Batch 820, loss = 2.06535
I0629 14:08:11.491853 17196 caffe.cpp:313] Batch 821, accuracy/top1 = 0.62
I0629 14:08:11.491876 17196 caffe.cpp:313] Batch 821, accuracy/top5 = 0.86
I0629 14:08:11.491879 17196 caffe.cpp:313] Batch 821, loss = 1.58081
I0629 14:08:11.541745 17196 caffe.cpp:313] Batch 822, accuracy/top1 = 0.6
I0629 14:08:11.541770 17196 caffe.cpp:313] Batch 822, accuracy/top5 = 0.8
I0629 14:08:11.541774 17196 caffe.cpp:313] Batch 822, loss = 1.9901
I0629 14:08:11.591542 17196 caffe.cpp:313] Batch 823, accuracy/top1 = 0.66
I0629 14:08:11.591565 17196 caffe.cpp:313] Batch 823, accuracy/top5 = 0.88
I0629 14:08:11.591568 17196 caffe.cpp:313] Batch 823, loss = 1.49787
I0629 14:08:11.640935 17196 caffe.cpp:313] Batch 824, accuracy/top1 = 0.58
I0629 14:08:11.640959 17196 caffe.cpp:313] Batch 824, accuracy/top5 = 0.84
I0629 14:08:11.640962 17196 caffe.cpp:313] Batch 824, loss = 1.86399
I0629 14:08:11.691704 17196 caffe.cpp:313] Batch 825, accuracy/top1 = 0.68
I0629 14:08:11.691726 17196 caffe.cpp:313] Batch 825, accuracy/top5 = 0.84
I0629 14:08:11.691730 17196 caffe.cpp:313] Batch 825, loss = 1.34811
I0629 14:08:11.740536 17196 caffe.cpp:313] Batch 826, accuracy/top1 = 0.62
I0629 14:08:11.740561 17196 caffe.cpp:313] Batch 826, accuracy/top5 = 0.82
I0629 14:08:11.740563 17196 caffe.cpp:313] Batch 826, loss = 1.68384
I0629 14:08:11.790133 17196 caffe.cpp:313] Batch 827, accuracy/top1 = 0.7
I0629 14:08:11.790158 17196 caffe.cpp:313] Batch 827, accuracy/top5 = 0.9
I0629 14:08:11.790160 17196 caffe.cpp:313] Batch 827, loss = 1.2701
I0629 14:08:11.839704 17196 caffe.cpp:313] Batch 828, accuracy/top1 = 0.58
I0629 14:08:11.839728 17196 caffe.cpp:313] Batch 828, accuracy/top5 = 0.76
I0629 14:08:11.839731 17196 caffe.cpp:313] Batch 828, loss = 1.80885
I0629 14:08:11.889255 17196 caffe.cpp:313] Batch 829, accuracy/top1 = 0.44
I0629 14:08:11.889278 17196 caffe.cpp:313] Batch 829, accuracy/top5 = 0.68
I0629 14:08:11.889281 17196 caffe.cpp:313] Batch 829, loss = 2.95778
I0629 14:08:11.938915 17196 caffe.cpp:313] Batch 830, accuracy/top1 = 0.6
I0629 14:08:11.938936 17196 caffe.cpp:313] Batch 830, accuracy/top5 = 0.78
I0629 14:08:11.938940 17196 caffe.cpp:313] Batch 830, loss = 1.73539
I0629 14:08:11.988545 17196 caffe.cpp:313] Batch 831, accuracy/top1 = 0.58
I0629 14:08:11.988569 17196 caffe.cpp:313] Batch 831, accuracy/top5 = 0.8
I0629 14:08:11.988571 17196 caffe.cpp:313] Batch 831, loss = 1.82884
I0629 14:08:12.039165 17196 caffe.cpp:313] Batch 832, accuracy/top1 = 0.52
I0629 14:08:12.039187 17196 caffe.cpp:313] Batch 832, accuracy/top5 = 0.76
I0629 14:08:12.039191 17196 caffe.cpp:313] Batch 832, loss = 1.9955
I0629 14:08:12.088263 17196 caffe.cpp:313] Batch 833, accuracy/top1 = 0.58
I0629 14:08:12.088287 17196 caffe.cpp:313] Batch 833, accuracy/top5 = 0.8
I0629 14:08:12.088290 17196 caffe.cpp:313] Batch 833, loss = 1.70236
I0629 14:08:12.137526 17196 caffe.cpp:313] Batch 834, accuracy/top1 = 0.62
I0629 14:08:12.137545 17196 caffe.cpp:313] Batch 834, accuracy/top5 = 0.84
I0629 14:08:12.137554 17196 caffe.cpp:313] Batch 834, loss = 1.62583
I0629 14:08:12.186981 17196 caffe.cpp:313] Batch 835, accuracy/top1 = 0.5
I0629 14:08:12.187005 17196 caffe.cpp:313] Batch 835, accuracy/top5 = 0.76
I0629 14:08:12.187008 17196 caffe.cpp:313] Batch 835, loss = 2.0009
I0629 14:08:12.235623 17196 caffe.cpp:313] Batch 836, accuracy/top1 = 0.58
I0629 14:08:12.235646 17196 caffe.cpp:313] Batch 836, accuracy/top5 = 0.82
I0629 14:08:12.235649 17196 caffe.cpp:313] Batch 836, loss = 1.70523
I0629 14:08:12.285223 17196 caffe.cpp:313] Batch 837, accuracy/top1 = 0.64
I0629 14:08:12.285264 17196 caffe.cpp:313] Batch 837, accuracy/top5 = 0.92
I0629 14:08:12.285267 17196 caffe.cpp:313] Batch 837, loss = 1.34647
I0629 14:08:12.334678 17196 caffe.cpp:313] Batch 838, accuracy/top1 = 0.52
I0629 14:08:12.334702 17196 caffe.cpp:313] Batch 838, accuracy/top5 = 0.84
I0629 14:08:12.334704 17196 caffe.cpp:313] Batch 838, loss = 1.8693
I0629 14:08:12.383291 17196 caffe.cpp:313] Batch 839, accuracy/top1 = 0.54
I0629 14:08:12.383314 17196 caffe.cpp:313] Batch 839, accuracy/top5 = 0.82
I0629 14:08:12.383317 17196 caffe.cpp:313] Batch 839, loss = 1.89544
I0629 14:08:12.432981 17196 caffe.cpp:313] Batch 840, accuracy/top1 = 0.64
I0629 14:08:12.433004 17196 caffe.cpp:313] Batch 840, accuracy/top5 = 0.8
I0629 14:08:12.433007 17196 caffe.cpp:313] Batch 840, loss = 1.90213
I0629 14:08:12.483153 17196 caffe.cpp:313] Batch 841, accuracy/top1 = 0.5
I0629 14:08:12.483177 17196 caffe.cpp:313] Batch 841, accuracy/top5 = 0.76
I0629 14:08:12.483180 17196 caffe.cpp:313] Batch 841, loss = 2.15682
I0629 14:08:12.532763 17196 caffe.cpp:313] Batch 842, accuracy/top1 = 0.56
I0629 14:08:12.532784 17196 caffe.cpp:313] Batch 842, accuracy/top5 = 0.88
I0629 14:08:12.532788 17196 caffe.cpp:313] Batch 842, loss = 1.67704
I0629 14:08:12.581099 17196 caffe.cpp:313] Batch 843, accuracy/top1 = 0.48
I0629 14:08:12.581118 17196 caffe.cpp:313] Batch 843, accuracy/top5 = 0.82
I0629 14:08:12.581121 17196 caffe.cpp:313] Batch 843, loss = 1.91048
I0629 14:08:12.630219 17196 caffe.cpp:313] Batch 844, accuracy/top1 = 0.66
I0629 14:08:12.630240 17196 caffe.cpp:313] Batch 844, accuracy/top5 = 0.88
I0629 14:08:12.630244 17196 caffe.cpp:313] Batch 844, loss = 1.44645
I0629 14:08:12.678630 17196 caffe.cpp:313] Batch 845, accuracy/top1 = 0.52
I0629 14:08:12.678654 17196 caffe.cpp:313] Batch 845, accuracy/top5 = 0.76
I0629 14:08:12.678658 17196 caffe.cpp:313] Batch 845, loss = 2.22378
I0629 14:08:12.727143 17196 caffe.cpp:313] Batch 846, accuracy/top1 = 0.5
I0629 14:08:12.727166 17196 caffe.cpp:313] Batch 846, accuracy/top5 = 0.78
I0629 14:08:12.727169 17196 caffe.cpp:313] Batch 846, loss = 2.04641
I0629 14:08:12.776664 17196 caffe.cpp:313] Batch 847, accuracy/top1 = 0.44
I0629 14:08:12.776687 17196 caffe.cpp:313] Batch 847, accuracy/top5 = 0.74
I0629 14:08:12.776690 17196 caffe.cpp:313] Batch 847, loss = 2.24176
I0629 14:08:12.825702 17196 caffe.cpp:313] Batch 848, accuracy/top1 = 0.64
I0629 14:08:12.825726 17196 caffe.cpp:313] Batch 848, accuracy/top5 = 0.8
I0629 14:08:12.825728 17196 caffe.cpp:313] Batch 848, loss = 1.86647
I0629 14:08:12.874698 17196 caffe.cpp:313] Batch 849, accuracy/top1 = 0.58
I0629 14:08:12.874722 17196 caffe.cpp:313] Batch 849, accuracy/top5 = 0.86
I0629 14:08:12.874725 17196 caffe.cpp:313] Batch 849, loss = 1.55351
I0629 14:08:12.923431 17196 caffe.cpp:313] Batch 850, accuracy/top1 = 0.64
I0629 14:08:12.923451 17196 caffe.cpp:313] Batch 850, accuracy/top5 = 0.82
I0629 14:08:12.923454 17196 caffe.cpp:313] Batch 850, loss = 1.64858
I0629 14:08:12.972348 17196 caffe.cpp:313] Batch 851, accuracy/top1 = 0.48
I0629 14:08:12.972373 17196 caffe.cpp:313] Batch 851, accuracy/top5 = 0.82
I0629 14:08:12.972375 17196 caffe.cpp:313] Batch 851, loss = 1.92753
I0629 14:08:13.021299 17196 caffe.cpp:313] Batch 852, accuracy/top1 = 0.56
I0629 14:08:13.021322 17196 caffe.cpp:313] Batch 852, accuracy/top5 = 0.78
I0629 14:08:13.021325 17196 caffe.cpp:313] Batch 852, loss = 1.91557
I0629 14:08:13.071869 17196 caffe.cpp:313] Batch 853, accuracy/top1 = 0.68
I0629 14:08:13.071892 17196 caffe.cpp:313] Batch 853, accuracy/top5 = 0.88
I0629 14:08:13.071895 17196 caffe.cpp:313] Batch 853, loss = 1.4931
I0629 14:08:13.120369 17196 caffe.cpp:313] Batch 854, accuracy/top1 = 0.66
I0629 14:08:13.120393 17196 caffe.cpp:313] Batch 854, accuracy/top5 = 0.8
I0629 14:08:13.120396 17196 caffe.cpp:313] Batch 854, loss = 1.62823
I0629 14:08:13.169677 17196 caffe.cpp:313] Batch 855, accuracy/top1 = 0.56
I0629 14:08:13.169699 17196 caffe.cpp:313] Batch 855, accuracy/top5 = 0.78
I0629 14:08:13.169703 17196 caffe.cpp:313] Batch 855, loss = 2.13133
I0629 14:08:13.219491 17196 caffe.cpp:313] Batch 856, accuracy/top1 = 0.38
I0629 14:08:13.219514 17196 caffe.cpp:313] Batch 856, accuracy/top5 = 0.76
I0629 14:08:13.219517 17196 caffe.cpp:313] Batch 856, loss = 2.24032
I0629 14:08:13.268612 17196 caffe.cpp:313] Batch 857, accuracy/top1 = 0.56
I0629 14:08:13.268636 17196 caffe.cpp:313] Batch 857, accuracy/top5 = 0.76
I0629 14:08:13.268640 17196 caffe.cpp:313] Batch 857, loss = 1.8996
I0629 14:08:13.316737 17196 caffe.cpp:313] Batch 858, accuracy/top1 = 0.64
I0629 14:08:13.316761 17196 caffe.cpp:313] Batch 858, accuracy/top5 = 0.86
I0629 14:08:13.316764 17196 caffe.cpp:313] Batch 858, loss = 1.43323
I0629 14:08:13.366184 17196 caffe.cpp:313] Batch 859, accuracy/top1 = 0.56
I0629 14:08:13.366207 17196 caffe.cpp:313] Batch 859, accuracy/top5 = 0.78
I0629 14:08:13.366211 17196 caffe.cpp:313] Batch 859, loss = 1.93105
I0629 14:08:13.416157 17196 caffe.cpp:313] Batch 860, accuracy/top1 = 0.68
I0629 14:08:13.416182 17196 caffe.cpp:313] Batch 860, accuracy/top5 = 0.82
I0629 14:08:13.416187 17196 caffe.cpp:313] Batch 860, loss = 1.59465
I0629 14:08:13.465080 17196 caffe.cpp:313] Batch 861, accuracy/top1 = 0.68
I0629 14:08:13.465102 17196 caffe.cpp:313] Batch 861, accuracy/top5 = 0.84
I0629 14:08:13.465106 17196 caffe.cpp:313] Batch 861, loss = 1.60215
I0629 14:08:13.513978 17196 caffe.cpp:313] Batch 862, accuracy/top1 = 0.54
I0629 14:08:13.514000 17196 caffe.cpp:313] Batch 862, accuracy/top5 = 0.8
I0629 14:08:13.514003 17196 caffe.cpp:313] Batch 862, loss = 1.80012
I0629 14:08:13.562387 17196 caffe.cpp:313] Batch 863, accuracy/top1 = 0.64
I0629 14:08:13.562412 17196 caffe.cpp:313] Batch 863, accuracy/top5 = 0.78
I0629 14:08:13.562414 17196 caffe.cpp:313] Batch 863, loss = 1.75988
I0629 14:08:13.611325 17196 caffe.cpp:313] Batch 864, accuracy/top1 = 0.7
I0629 14:08:13.611346 17196 caffe.cpp:313] Batch 864, accuracy/top5 = 0.82
I0629 14:08:13.611349 17196 caffe.cpp:313] Batch 864, loss = 1.63754
I0629 14:08:13.661098 17196 caffe.cpp:313] Batch 865, accuracy/top1 = 0.56
I0629 14:08:13.661121 17196 caffe.cpp:313] Batch 865, accuracy/top5 = 0.7
I0629 14:08:13.661124 17196 caffe.cpp:313] Batch 865, loss = 1.96429
I0629 14:08:13.710506 17196 caffe.cpp:313] Batch 866, accuracy/top1 = 0.66
I0629 14:08:13.710530 17196 caffe.cpp:313] Batch 866, accuracy/top5 = 0.82
I0629 14:08:13.710533 17196 caffe.cpp:313] Batch 866, loss = 1.52775
I0629 14:08:13.760740 17196 caffe.cpp:313] Batch 867, accuracy/top1 = 0.52
I0629 14:08:13.760763 17196 caffe.cpp:313] Batch 867, accuracy/top5 = 0.78
I0629 14:08:13.760766 17196 caffe.cpp:313] Batch 867, loss = 2.21282
I0629 14:08:13.810595 17196 caffe.cpp:313] Batch 868, accuracy/top1 = 0.58
I0629 14:08:13.810618 17196 caffe.cpp:313] Batch 868, accuracy/top5 = 0.82
I0629 14:08:13.810621 17196 caffe.cpp:313] Batch 868, loss = 1.9405
I0629 14:08:13.859920 17196 caffe.cpp:313] Batch 869, accuracy/top1 = 0.48
I0629 14:08:13.859943 17196 caffe.cpp:313] Batch 869, accuracy/top5 = 0.84
I0629 14:08:13.859946 17196 caffe.cpp:313] Batch 869, loss = 2.11974
I0629 14:08:13.909729 17196 caffe.cpp:313] Batch 870, accuracy/top1 = 0.48
I0629 14:08:13.909752 17196 caffe.cpp:313] Batch 870, accuracy/top5 = 0.72
I0629 14:08:13.909755 17196 caffe.cpp:313] Batch 870, loss = 2.21221
I0629 14:08:13.959921 17196 caffe.cpp:313] Batch 871, accuracy/top1 = 0.6
I0629 14:08:13.959945 17196 caffe.cpp:313] Batch 871, accuracy/top5 = 0.86
I0629 14:08:13.959949 17196 caffe.cpp:313] Batch 871, loss = 1.61885
I0629 14:08:14.008832 17196 caffe.cpp:313] Batch 872, accuracy/top1 = 0.5
I0629 14:08:14.008857 17196 caffe.cpp:313] Batch 872, accuracy/top5 = 0.82
I0629 14:08:14.008859 17196 caffe.cpp:313] Batch 872, loss = 1.8996
I0629 14:08:14.058416 17196 caffe.cpp:313] Batch 873, accuracy/top1 = 0.58
I0629 14:08:14.058439 17196 caffe.cpp:313] Batch 873, accuracy/top5 = 0.78
I0629 14:08:14.058442 17196 caffe.cpp:313] Batch 873, loss = 1.82494
I0629 14:08:14.107591 17196 caffe.cpp:313] Batch 874, accuracy/top1 = 0.6
I0629 14:08:14.107616 17196 caffe.cpp:313] Batch 874, accuracy/top5 = 0.86
I0629 14:08:14.107635 17196 caffe.cpp:313] Batch 874, loss = 1.72932
I0629 14:08:14.157294 17196 caffe.cpp:313] Batch 875, accuracy/top1 = 0.74
I0629 14:08:14.157315 17196 caffe.cpp:313] Batch 875, accuracy/top5 = 0.86
I0629 14:08:14.157318 17196 caffe.cpp:313] Batch 875, loss = 1.48897
I0629 14:08:14.205901 17196 caffe.cpp:313] Batch 876, accuracy/top1 = 0.56
I0629 14:08:14.205924 17196 caffe.cpp:313] Batch 876, accuracy/top5 = 0.86
I0629 14:08:14.205926 17196 caffe.cpp:313] Batch 876, loss = 1.52611
I0629 14:08:14.256002 17196 caffe.cpp:313] Batch 877, accuracy/top1 = 0.52
I0629 14:08:14.256026 17196 caffe.cpp:313] Batch 877, accuracy/top5 = 0.8
I0629 14:08:14.256028 17196 caffe.cpp:313] Batch 877, loss = 1.78628
I0629 14:08:14.305316 17196 caffe.cpp:313] Batch 878, accuracy/top1 = 0.66
I0629 14:08:14.305341 17196 caffe.cpp:313] Batch 878, accuracy/top5 = 0.82
I0629 14:08:14.305343 17196 caffe.cpp:313] Batch 878, loss = 2.05483
I0629 14:08:14.355340 17196 caffe.cpp:313] Batch 879, accuracy/top1 = 0.56
I0629 14:08:14.355365 17196 caffe.cpp:313] Batch 879, accuracy/top5 = 0.84
I0629 14:08:14.355367 17196 caffe.cpp:313] Batch 879, loss = 1.59012
I0629 14:08:14.404263 17196 caffe.cpp:313] Batch 880, accuracy/top1 = 0.72
I0629 14:08:14.404286 17196 caffe.cpp:313] Batch 880, accuracy/top5 = 0.84
I0629 14:08:14.404289 17196 caffe.cpp:313] Batch 880, loss = 1.34668
I0629 14:08:14.452980 17196 caffe.cpp:313] Batch 881, accuracy/top1 = 0.52
I0629 14:08:14.453002 17196 caffe.cpp:313] Batch 881, accuracy/top5 = 0.82
I0629 14:08:14.453006 17196 caffe.cpp:313] Batch 881, loss = 1.81951
I0629 14:08:14.502483 17196 caffe.cpp:313] Batch 882, accuracy/top1 = 0.48
I0629 14:08:14.502508 17196 caffe.cpp:313] Batch 882, accuracy/top5 = 0.82
I0629 14:08:14.502511 17196 caffe.cpp:313] Batch 882, loss = 1.87855
I0629 14:08:14.551503 17196 caffe.cpp:313] Batch 883, accuracy/top1 = 0.62
I0629 14:08:14.551527 17196 caffe.cpp:313] Batch 883, accuracy/top5 = 0.84
I0629 14:08:14.551529 17196 caffe.cpp:313] Batch 883, loss = 1.65844
I0629 14:08:14.601126 17196 caffe.cpp:313] Batch 884, accuracy/top1 = 0.5
I0629 14:08:14.601150 17196 caffe.cpp:313] Batch 884, accuracy/top5 = 0.78
I0629 14:08:14.601153 17196 caffe.cpp:313] Batch 884, loss = 2.1692
I0629 14:08:14.651149 17196 caffe.cpp:313] Batch 885, accuracy/top1 = 0.6
I0629 14:08:14.651170 17196 caffe.cpp:313] Batch 885, accuracy/top5 = 0.82
I0629 14:08:14.651173 17196 caffe.cpp:313] Batch 885, loss = 1.64459
I0629 14:08:14.699690 17196 caffe.cpp:313] Batch 886, accuracy/top1 = 0.66
I0629 14:08:14.699712 17196 caffe.cpp:313] Batch 886, accuracy/top5 = 0.86
I0629 14:08:14.699715 17196 caffe.cpp:313] Batch 886, loss = 1.7039
I0629 14:08:14.749382 17196 caffe.cpp:313] Batch 887, accuracy/top1 = 0.54
I0629 14:08:14.749403 17196 caffe.cpp:313] Batch 887, accuracy/top5 = 0.7
I0629 14:08:14.749406 17196 caffe.cpp:313] Batch 887, loss = 2.11632
I0629 14:08:14.799185 17196 caffe.cpp:313] Batch 888, accuracy/top1 = 0.5
I0629 14:08:14.799208 17196 caffe.cpp:313] Batch 888, accuracy/top5 = 0.86
I0629 14:08:14.799211 17196 caffe.cpp:313] Batch 888, loss = 1.71366
I0629 14:08:14.848242 17196 caffe.cpp:313] Batch 889, accuracy/top1 = 0.52
I0629 14:08:14.848265 17196 caffe.cpp:313] Batch 889, accuracy/top5 = 0.84
I0629 14:08:14.848268 17196 caffe.cpp:313] Batch 889, loss = 1.85373
I0629 14:08:14.898200 17196 caffe.cpp:313] Batch 890, accuracy/top1 = 0.48
I0629 14:08:14.898223 17196 caffe.cpp:313] Batch 890, accuracy/top5 = 0.76
I0629 14:08:14.898226 17196 caffe.cpp:313] Batch 890, loss = 2.17776
I0629 14:08:14.948137 17196 caffe.cpp:313] Batch 891, accuracy/top1 = 0.64
I0629 14:08:14.948160 17196 caffe.cpp:313] Batch 891, accuracy/top5 = 0.8
I0629 14:08:14.948163 17196 caffe.cpp:313] Batch 891, loss = 1.76831
I0629 14:08:14.997648 17196 caffe.cpp:313] Batch 892, accuracy/top1 = 0.52
I0629 14:08:14.997673 17196 caffe.cpp:313] Batch 892, accuracy/top5 = 0.82
I0629 14:08:14.997676 17196 caffe.cpp:313] Batch 892, loss = 1.77735
I0629 14:08:15.047158 17196 caffe.cpp:313] Batch 893, accuracy/top1 = 0.46
I0629 14:08:15.047197 17196 caffe.cpp:313] Batch 893, accuracy/top5 = 0.8
I0629 14:08:15.047201 17196 caffe.cpp:313] Batch 893, loss = 1.99875
I0629 14:08:15.096293 17196 caffe.cpp:313] Batch 894, accuracy/top1 = 0.54
I0629 14:08:15.096316 17196 caffe.cpp:313] Batch 894, accuracy/top5 = 0.8
I0629 14:08:15.096319 17196 caffe.cpp:313] Batch 894, loss = 2.04861
I0629 14:08:15.146394 17196 caffe.cpp:313] Batch 895, accuracy/top1 = 0.72
I0629 14:08:15.146411 17196 caffe.cpp:313] Batch 895, accuracy/top5 = 0.88
I0629 14:08:15.146414 17196 caffe.cpp:313] Batch 895, loss = 1.19405
I0629 14:08:15.196425 17196 caffe.cpp:313] Batch 896, accuracy/top1 = 0.52
I0629 14:08:15.196449 17196 caffe.cpp:313] Batch 896, accuracy/top5 = 0.74
I0629 14:08:15.196451 17196 caffe.cpp:313] Batch 896, loss = 2.07254
I0629 14:08:15.245339 17196 caffe.cpp:313] Batch 897, accuracy/top1 = 0.54
I0629 14:08:15.245363 17196 caffe.cpp:313] Batch 897, accuracy/top5 = 0.86
I0629 14:08:15.245367 17196 caffe.cpp:313] Batch 897, loss = 1.71979
I0629 14:08:15.294976 17196 caffe.cpp:313] Batch 898, accuracy/top1 = 0.68
I0629 14:08:15.295001 17196 caffe.cpp:313] Batch 898, accuracy/top5 = 0.84
I0629 14:08:15.295003 17196 caffe.cpp:313] Batch 898, loss = 1.47315
I0629 14:08:15.344089 17196 caffe.cpp:313] Batch 899, accuracy/top1 = 0.6
I0629 14:08:15.344112 17196 caffe.cpp:313] Batch 899, accuracy/top5 = 0.86
I0629 14:08:15.344115 17196 caffe.cpp:313] Batch 899, loss = 1.68108
I0629 14:08:15.393826 17196 caffe.cpp:313] Batch 900, accuracy/top1 = 0.72
I0629 14:08:15.393851 17196 caffe.cpp:313] Batch 900, accuracy/top5 = 0.88
I0629 14:08:15.393853 17196 caffe.cpp:313] Batch 900, loss = 1.14583
I0629 14:08:15.443261 17196 caffe.cpp:313] Batch 901, accuracy/top1 = 0.56
I0629 14:08:15.443285 17196 caffe.cpp:313] Batch 901, accuracy/top5 = 0.76
I0629 14:08:15.443289 17196 caffe.cpp:313] Batch 901, loss = 1.85359
I0629 14:08:15.492563 17196 caffe.cpp:313] Batch 902, accuracy/top1 = 0.54
I0629 14:08:15.492586 17196 caffe.cpp:313] Batch 902, accuracy/top5 = 0.78
I0629 14:08:15.492589 17196 caffe.cpp:313] Batch 902, loss = 2.04512
I0629 14:08:15.541921 17196 caffe.cpp:313] Batch 903, accuracy/top1 = 0.6
I0629 14:08:15.541946 17196 caffe.cpp:313] Batch 903, accuracy/top5 = 0.84
I0629 14:08:15.541949 17196 caffe.cpp:313] Batch 903, loss = 1.50643
I0629 14:08:15.591768 17196 caffe.cpp:313] Batch 904, accuracy/top1 = 0.62
I0629 14:08:15.591791 17196 caffe.cpp:313] Batch 904, accuracy/top5 = 0.84
I0629 14:08:15.591794 17196 caffe.cpp:313] Batch 904, loss = 1.68484
I0629 14:08:15.641203 17196 caffe.cpp:313] Batch 905, accuracy/top1 = 0.62
I0629 14:08:15.641227 17196 caffe.cpp:313] Batch 905, accuracy/top5 = 0.82
I0629 14:08:15.641230 17196 caffe.cpp:313] Batch 905, loss = 1.7675
I0629 14:08:15.690269 17196 caffe.cpp:313] Batch 906, accuracy/top1 = 0.66
I0629 14:08:15.690294 17196 caffe.cpp:313] Batch 906, accuracy/top5 = 0.84
I0629 14:08:15.690296 17196 caffe.cpp:313] Batch 906, loss = 1.54134
I0629 14:08:15.739262 17196 caffe.cpp:313] Batch 907, accuracy/top1 = 0.64
I0629 14:08:15.739287 17196 caffe.cpp:313] Batch 907, accuracy/top5 = 0.76
I0629 14:08:15.739290 17196 caffe.cpp:313] Batch 907, loss = 1.99492
I0629 14:08:15.789191 17196 caffe.cpp:313] Batch 908, accuracy/top1 = 0.52
I0629 14:08:15.789214 17196 caffe.cpp:313] Batch 908, accuracy/top5 = 0.8
I0629 14:08:15.789217 17196 caffe.cpp:313] Batch 908, loss = 1.77957
I0629 14:08:15.839262 17196 caffe.cpp:313] Batch 909, accuracy/top1 = 0.62
I0629 14:08:15.839287 17196 caffe.cpp:313] Batch 909, accuracy/top5 = 0.9
I0629 14:08:15.839290 17196 caffe.cpp:313] Batch 909, loss = 1.43308
I0629 14:08:15.888269 17196 caffe.cpp:313] Batch 910, accuracy/top1 = 0.54
I0629 14:08:15.888293 17196 caffe.cpp:313] Batch 910, accuracy/top5 = 0.74
I0629 14:08:15.888296 17196 caffe.cpp:313] Batch 910, loss = 2.04473
I0629 14:08:15.937146 17196 caffe.cpp:313] Batch 911, accuracy/top1 = 0.52
I0629 14:08:15.937170 17196 caffe.cpp:313] Batch 911, accuracy/top5 = 0.78
I0629 14:08:15.937172 17196 caffe.cpp:313] Batch 911, loss = 1.96212
I0629 14:08:15.986313 17196 caffe.cpp:313] Batch 912, accuracy/top1 = 0.5
I0629 14:08:15.986337 17196 caffe.cpp:313] Batch 912, accuracy/top5 = 0.74
I0629 14:08:15.986340 17196 caffe.cpp:313] Batch 912, loss = 1.90647
I0629 14:08:16.035653 17196 caffe.cpp:313] Batch 913, accuracy/top1 = 0.6
I0629 14:08:16.035676 17196 caffe.cpp:313] Batch 913, accuracy/top5 = 0.78
I0629 14:08:16.035678 17196 caffe.cpp:313] Batch 913, loss = 1.96227
I0629 14:08:16.084722 17196 caffe.cpp:313] Batch 914, accuracy/top1 = 0.52
I0629 14:08:16.084745 17196 caffe.cpp:313] Batch 914, accuracy/top5 = 0.74
I0629 14:08:16.084748 17196 caffe.cpp:313] Batch 914, loss = 2.29018
I0629 14:08:16.133826 17196 caffe.cpp:313] Batch 915, accuracy/top1 = 0.62
I0629 14:08:16.133854 17196 caffe.cpp:313] Batch 915, accuracy/top5 = 0.76
I0629 14:08:16.133857 17196 caffe.cpp:313] Batch 915, loss = 1.8976
I0629 14:08:16.182814 17196 caffe.cpp:313] Batch 916, accuracy/top1 = 0.68
I0629 14:08:16.182837 17196 caffe.cpp:313] Batch 916, accuracy/top5 = 0.88
I0629 14:08:16.182840 17196 caffe.cpp:313] Batch 916, loss = 1.55322
I0629 14:08:16.231559 17196 caffe.cpp:313] Batch 917, accuracy/top1 = 0.64
I0629 14:08:16.231583 17196 caffe.cpp:313] Batch 917, accuracy/top5 = 0.82
I0629 14:08:16.231586 17196 caffe.cpp:313] Batch 917, loss = 1.59815
I0629 14:08:16.281291 17196 caffe.cpp:313] Batch 918, accuracy/top1 = 0.62
I0629 14:08:16.281314 17196 caffe.cpp:313] Batch 918, accuracy/top5 = 0.8
I0629 14:08:16.281317 17196 caffe.cpp:313] Batch 918, loss = 1.90183
I0629 14:08:16.329684 17196 caffe.cpp:313] Batch 919, accuracy/top1 = 0.6
I0629 14:08:16.329707 17196 caffe.cpp:313] Batch 919, accuracy/top5 = 0.78
I0629 14:08:16.329710 17196 caffe.cpp:313] Batch 919, loss = 1.91502
I0629 14:08:16.378911 17196 caffe.cpp:313] Batch 920, accuracy/top1 = 0.62
I0629 14:08:16.378933 17196 caffe.cpp:313] Batch 920, accuracy/top5 = 0.76
I0629 14:08:16.378937 17196 caffe.cpp:313] Batch 920, loss = 1.88217
I0629 14:08:16.428853 17196 caffe.cpp:313] Batch 921, accuracy/top1 = 0.54
I0629 14:08:16.428877 17196 caffe.cpp:313] Batch 921, accuracy/top5 = 0.84
I0629 14:08:16.428880 17196 caffe.cpp:313] Batch 921, loss = 1.6295
I0629 14:08:16.478199 17196 caffe.cpp:313] Batch 922, accuracy/top1 = 0.6
I0629 14:08:16.478224 17196 caffe.cpp:313] Batch 922, accuracy/top5 = 0.92
I0629 14:08:16.478226 17196 caffe.cpp:313] Batch 922, loss = 1.2588
I0629 14:08:16.526744 17196 caffe.cpp:313] Batch 923, accuracy/top1 = 0.56
I0629 14:08:16.526767 17196 caffe.cpp:313] Batch 923, accuracy/top5 = 0.82
I0629 14:08:16.526770 17196 caffe.cpp:313] Batch 923, loss = 1.9272
I0629 14:08:16.576985 17196 caffe.cpp:313] Batch 924, accuracy/top1 = 0.56
I0629 14:08:16.577008 17196 caffe.cpp:313] Batch 924, accuracy/top5 = 0.84
I0629 14:08:16.577011 17196 caffe.cpp:313] Batch 924, loss = 1.53593
I0629 14:08:16.626585 17196 caffe.cpp:313] Batch 925, accuracy/top1 = 0.6
I0629 14:08:16.626605 17196 caffe.cpp:313] Batch 925, accuracy/top5 = 0.8
I0629 14:08:16.626607 17196 caffe.cpp:313] Batch 925, loss = 1.96264
I0629 14:08:16.676790 17196 caffe.cpp:313] Batch 926, accuracy/top1 = 0.68
I0629 14:08:16.676812 17196 caffe.cpp:313] Batch 926, accuracy/top5 = 0.82
I0629 14:08:16.676815 17196 caffe.cpp:313] Batch 926, loss = 1.87656
I0629 14:08:16.724684 17196 caffe.cpp:313] Batch 927, accuracy/top1 = 0.54
I0629 14:08:16.724709 17196 caffe.cpp:313] Batch 927, accuracy/top5 = 0.74
I0629 14:08:16.724712 17196 caffe.cpp:313] Batch 927, loss = 2.00671
I0629 14:08:16.773492 17196 caffe.cpp:313] Batch 928, accuracy/top1 = 0.56
I0629 14:08:16.773512 17196 caffe.cpp:313] Batch 928, accuracy/top5 = 0.82
I0629 14:08:16.773515 17196 caffe.cpp:313] Batch 928, loss = 1.49172
I0629 14:08:16.822733 17196 caffe.cpp:313] Batch 929, accuracy/top1 = 0.6
I0629 14:08:16.822754 17196 caffe.cpp:313] Batch 929, accuracy/top5 = 0.84
I0629 14:08:16.822757 17196 caffe.cpp:313] Batch 929, loss = 1.75888
I0629 14:08:16.873255 17196 caffe.cpp:313] Batch 930, accuracy/top1 = 0.64
I0629 14:08:16.873281 17196 caffe.cpp:313] Batch 930, accuracy/top5 = 0.8
I0629 14:08:16.873286 17196 caffe.cpp:313] Batch 930, loss = 1.66417
I0629 14:08:16.921581 17196 caffe.cpp:313] Batch 931, accuracy/top1 = 0.6
I0629 14:08:16.921602 17196 caffe.cpp:313] Batch 931, accuracy/top5 = 0.78
I0629 14:08:16.921605 17196 caffe.cpp:313] Batch 931, loss = 2.00837
I0629 14:08:16.970784 17196 caffe.cpp:313] Batch 932, accuracy/top1 = 0.72
I0629 14:08:16.970809 17196 caffe.cpp:313] Batch 932, accuracy/top5 = 0.84
I0629 14:08:16.970813 17196 caffe.cpp:313] Batch 932, loss = 1.41363
I0629 14:08:17.020081 17196 caffe.cpp:313] Batch 933, accuracy/top1 = 0.56
I0629 14:08:17.020103 17196 caffe.cpp:313] Batch 933, accuracy/top5 = 0.78
I0629 14:08:17.020107 17196 caffe.cpp:313] Batch 933, loss = 2.30782
I0629 14:08:17.070574 17196 caffe.cpp:313] Batch 934, accuracy/top1 = 0.5
I0629 14:08:17.070596 17196 caffe.cpp:313] Batch 934, accuracy/top5 = 0.76
I0629 14:08:17.070600 17196 caffe.cpp:313] Batch 934, loss = 1.89937
I0629 14:08:17.118891 17196 caffe.cpp:313] Batch 935, accuracy/top1 = 0.52
I0629 14:08:17.118913 17196 caffe.cpp:313] Batch 935, accuracy/top5 = 0.76
I0629 14:08:17.118916 17196 caffe.cpp:313] Batch 935, loss = 2.15646
I0629 14:08:17.168526 17196 caffe.cpp:313] Batch 936, accuracy/top1 = 0.68
I0629 14:08:17.168543 17196 caffe.cpp:313] Batch 936, accuracy/top5 = 0.82
I0629 14:08:17.168546 17196 caffe.cpp:313] Batch 936, loss = 1.63117
I0629 14:08:17.218313 17196 caffe.cpp:313] Batch 937, accuracy/top1 = 0.58
I0629 14:08:17.218338 17196 caffe.cpp:313] Batch 937, accuracy/top5 = 0.8
I0629 14:08:17.218341 17196 caffe.cpp:313] Batch 937, loss = 2.1156
I0629 14:08:17.267421 17196 caffe.cpp:313] Batch 938, accuracy/top1 = 0.56
I0629 14:08:17.267446 17196 caffe.cpp:313] Batch 938, accuracy/top5 = 0.8
I0629 14:08:17.267448 17196 caffe.cpp:313] Batch 938, loss = 1.86194
I0629 14:08:17.315919 17196 caffe.cpp:313] Batch 939, accuracy/top1 = 0.5
I0629 14:08:17.315943 17196 caffe.cpp:313] Batch 939, accuracy/top5 = 0.84
I0629 14:08:17.315945 17196 caffe.cpp:313] Batch 939, loss = 1.8099
I0629 14:08:17.365077 17196 caffe.cpp:313] Batch 940, accuracy/top1 = 0.46
I0629 14:08:17.365099 17196 caffe.cpp:313] Batch 940, accuracy/top5 = 0.82
I0629 14:08:17.365103 17196 caffe.cpp:313] Batch 940, loss = 1.8762
I0629 14:08:17.414173 17196 caffe.cpp:313] Batch 941, accuracy/top1 = 0.64
I0629 14:08:17.414197 17196 caffe.cpp:313] Batch 941, accuracy/top5 = 0.78
I0629 14:08:17.414201 17196 caffe.cpp:313] Batch 941, loss = 2.01974
I0629 14:08:17.463408 17196 caffe.cpp:313] Batch 942, accuracy/top1 = 0.52
I0629 14:08:17.463433 17196 caffe.cpp:313] Batch 942, accuracy/top5 = 0.76
I0629 14:08:17.463435 17196 caffe.cpp:313] Batch 942, loss = 2.2258
I0629 14:08:17.511651 17196 caffe.cpp:313] Batch 943, accuracy/top1 = 0.66
I0629 14:08:17.511672 17196 caffe.cpp:313] Batch 943, accuracy/top5 = 0.86
I0629 14:08:17.511675 17196 caffe.cpp:313] Batch 943, loss = 1.51258
I0629 14:08:17.560307 17196 caffe.cpp:313] Batch 944, accuracy/top1 = 0.62
I0629 14:08:17.560329 17196 caffe.cpp:313] Batch 944, accuracy/top5 = 0.8
I0629 14:08:17.560333 17196 caffe.cpp:313] Batch 944, loss = 1.5472
I0629 14:08:17.610087 17196 caffe.cpp:313] Batch 945, accuracy/top1 = 0.52
I0629 14:08:17.610111 17196 caffe.cpp:313] Batch 945, accuracy/top5 = 0.76
I0629 14:08:17.610115 17196 caffe.cpp:313] Batch 945, loss = 2.21111
I0629 14:08:17.658705 17196 caffe.cpp:313] Batch 946, accuracy/top1 = 0.58
I0629 14:08:17.658728 17196 caffe.cpp:313] Batch 946, accuracy/top5 = 0.78
I0629 14:08:17.658731 17196 caffe.cpp:313] Batch 946, loss = 2.14702
I0629 14:08:17.709333 17196 caffe.cpp:313] Batch 947, accuracy/top1 = 0.7
I0629 14:08:17.709357 17196 caffe.cpp:313] Batch 947, accuracy/top5 = 0.9
I0629 14:08:17.709360 17196 caffe.cpp:313] Batch 947, loss = 1.16961
I0629 14:08:17.759547 17196 caffe.cpp:313] Batch 948, accuracy/top1 = 0.54
I0629 14:08:17.759572 17196 caffe.cpp:313] Batch 948, accuracy/top5 = 0.78
I0629 14:08:17.759575 17196 caffe.cpp:313] Batch 948, loss = 2.05076
I0629 14:08:17.808328 17196 caffe.cpp:313] Batch 949, accuracy/top1 = 0.72
I0629 14:08:17.808352 17196 caffe.cpp:313] Batch 949, accuracy/top5 = 0.84
I0629 14:08:17.808372 17196 caffe.cpp:313] Batch 949, loss = 1.30816
I0629 14:08:17.857044 17196 caffe.cpp:313] Batch 950, accuracy/top1 = 0.52
I0629 14:08:17.857069 17196 caffe.cpp:313] Batch 950, accuracy/top5 = 0.74
I0629 14:08:17.857071 17196 caffe.cpp:313] Batch 950, loss = 2.24958
I0629 14:08:17.907274 17196 caffe.cpp:313] Batch 951, accuracy/top1 = 0.76
I0629 14:08:17.907296 17196 caffe.cpp:313] Batch 951, accuracy/top5 = 0.88
I0629 14:08:17.907299 17196 caffe.cpp:313] Batch 951, loss = 1.28842
I0629 14:08:17.957041 17196 caffe.cpp:313] Batch 952, accuracy/top1 = 0.62
I0629 14:08:17.957064 17196 caffe.cpp:313] Batch 952, accuracy/top5 = 0.82
I0629 14:08:17.957067 17196 caffe.cpp:313] Batch 952, loss = 2.07984
I0629 14:08:18.006430 17196 caffe.cpp:313] Batch 953, accuracy/top1 = 0.54
I0629 14:08:18.006454 17196 caffe.cpp:313] Batch 953, accuracy/top5 = 0.78
I0629 14:08:18.006458 17196 caffe.cpp:313] Batch 953, loss = 1.69866
I0629 14:08:18.055680 17196 caffe.cpp:313] Batch 954, accuracy/top1 = 0.52
I0629 14:08:18.055701 17196 caffe.cpp:313] Batch 954, accuracy/top5 = 0.68
I0629 14:08:18.055703 17196 caffe.cpp:313] Batch 954, loss = 2.43214
I0629 14:08:18.105620 17196 caffe.cpp:313] Batch 955, accuracy/top1 = 0.6
I0629 14:08:18.105643 17196 caffe.cpp:313] Batch 955, accuracy/top5 = 0.72
I0629 14:08:18.105646 17196 caffe.cpp:313] Batch 955, loss = 2.26575
I0629 14:08:18.155936 17196 caffe.cpp:313] Batch 956, accuracy/top1 = 0.52
I0629 14:08:18.155956 17196 caffe.cpp:313] Batch 956, accuracy/top5 = 0.88
I0629 14:08:18.155959 17196 caffe.cpp:313] Batch 956, loss = 1.85862
I0629 14:08:18.206161 17196 caffe.cpp:313] Batch 957, accuracy/top1 = 0.5
I0629 14:08:18.206184 17196 caffe.cpp:313] Batch 957, accuracy/top5 = 0.78
I0629 14:08:18.206188 17196 caffe.cpp:313] Batch 957, loss = 2.19935
I0629 14:08:18.255944 17196 caffe.cpp:313] Batch 958, accuracy/top1 = 0.66
I0629 14:08:18.255967 17196 caffe.cpp:313] Batch 958, accuracy/top5 = 0.86
I0629 14:08:18.255970 17196 caffe.cpp:313] Batch 958, loss = 1.82675
I0629 14:08:18.305676 17196 caffe.cpp:313] Batch 959, accuracy/top1 = 0.5
I0629 14:08:18.305701 17196 caffe.cpp:313] Batch 959, accuracy/top5 = 0.76
I0629 14:08:18.305703 17196 caffe.cpp:313] Batch 959, loss = 2.19069
I0629 14:08:18.353622 17196 caffe.cpp:313] Batch 960, accuracy/top1 = 0.6
I0629 14:08:18.353646 17196 caffe.cpp:313] Batch 960, accuracy/top5 = 0.8
I0629 14:08:18.353648 17196 caffe.cpp:313] Batch 960, loss = 1.79352
I0629 14:08:18.402592 17196 caffe.cpp:313] Batch 961, accuracy/top1 = 0.46
I0629 14:08:18.402616 17196 caffe.cpp:313] Batch 961, accuracy/top5 = 0.72
I0629 14:08:18.402619 17196 caffe.cpp:313] Batch 961, loss = 2.54188
I0629 14:08:18.451427 17196 caffe.cpp:313] Batch 962, accuracy/top1 = 0.62
I0629 14:08:18.451452 17196 caffe.cpp:313] Batch 962, accuracy/top5 = 0.82
I0629 14:08:18.451454 17196 caffe.cpp:313] Batch 962, loss = 1.84864
I0629 14:08:18.500938 17196 caffe.cpp:313] Batch 963, accuracy/top1 = 0.48
I0629 14:08:18.500962 17196 caffe.cpp:313] Batch 963, accuracy/top5 = 0.78
I0629 14:08:18.500965 17196 caffe.cpp:313] Batch 963, loss = 1.95019
I0629 14:08:18.549832 17196 caffe.cpp:313] Batch 964, accuracy/top1 = 0.56
I0629 14:08:18.549856 17196 caffe.cpp:313] Batch 964, accuracy/top5 = 0.74
I0629 14:08:18.549860 17196 caffe.cpp:313] Batch 964, loss = 1.73475
I0629 14:08:18.599048 17196 caffe.cpp:313] Batch 965, accuracy/top1 = 0.58
I0629 14:08:18.599076 17196 caffe.cpp:313] Batch 965, accuracy/top5 = 0.78
I0629 14:08:18.599082 17196 caffe.cpp:313] Batch 965, loss = 1.99246
I0629 14:08:18.647939 17196 caffe.cpp:313] Batch 966, accuracy/top1 = 0.6
I0629 14:08:18.647958 17196 caffe.cpp:313] Batch 966, accuracy/top5 = 0.86
I0629 14:08:18.647960 17196 caffe.cpp:313] Batch 966, loss = 2.02067
I0629 14:08:18.698240 17196 caffe.cpp:313] Batch 967, accuracy/top1 = 0.46
I0629 14:08:18.698262 17196 caffe.cpp:313] Batch 967, accuracy/top5 = 0.78
I0629 14:08:18.698266 17196 caffe.cpp:313] Batch 967, loss = 2.18813
I0629 14:08:18.748181 17196 caffe.cpp:313] Batch 968, accuracy/top1 = 0.48
I0629 14:08:18.748220 17196 caffe.cpp:313] Batch 968, accuracy/top5 = 0.8
I0629 14:08:18.748224 17196 caffe.cpp:313] Batch 968, loss = 2.11355
I0629 14:08:18.798454 17196 caffe.cpp:313] Batch 969, accuracy/top1 = 0.56
I0629 14:08:18.798476 17196 caffe.cpp:313] Batch 969, accuracy/top5 = 0.8
I0629 14:08:18.798480 17196 caffe.cpp:313] Batch 969, loss = 1.70628
I0629 14:08:18.847960 17196 caffe.cpp:313] Batch 970, accuracy/top1 = 0.58
I0629 14:08:18.847985 17196 caffe.cpp:313] Batch 970, accuracy/top5 = 0.8
I0629 14:08:18.847987 17196 caffe.cpp:313] Batch 970, loss = 1.7402
I0629 14:08:18.897449 17196 caffe.cpp:313] Batch 971, accuracy/top1 = 0.6
I0629 14:08:18.897472 17196 caffe.cpp:313] Batch 971, accuracy/top5 = 0.82
I0629 14:08:18.897475 17196 caffe.cpp:313] Batch 971, loss = 1.57581
I0629 14:08:18.947755 17196 caffe.cpp:313] Batch 972, accuracy/top1 = 0.66
I0629 14:08:18.947775 17196 caffe.cpp:313] Batch 972, accuracy/top5 = 0.82
I0629 14:08:18.947778 17196 caffe.cpp:313] Batch 972, loss = 1.61251
I0629 14:08:18.999030 17196 caffe.cpp:313] Batch 973, accuracy/top1 = 0.48
I0629 14:08:18.999052 17196 caffe.cpp:313] Batch 973, accuracy/top5 = 0.7
I0629 14:08:18.999054 17196 caffe.cpp:313] Batch 973, loss = 2.47405
I0629 14:08:19.047572 17196 caffe.cpp:313] Batch 974, accuracy/top1 = 0.36
I0629 14:08:19.047595 17196 caffe.cpp:313] Batch 974, accuracy/top5 = 0.74
I0629 14:08:19.047598 17196 caffe.cpp:313] Batch 974, loss = 2.01918
I0629 14:08:19.096242 17196 caffe.cpp:313] Batch 975, accuracy/top1 = 0.62
I0629 14:08:19.096266 17196 caffe.cpp:313] Batch 975, accuracy/top5 = 0.78
I0629 14:08:19.096269 17196 caffe.cpp:313] Batch 975, loss = 1.80815
I0629 14:08:19.145587 17196 caffe.cpp:313] Batch 976, accuracy/top1 = 0.56
I0629 14:08:19.145606 17196 caffe.cpp:313] Batch 976, accuracy/top5 = 0.78
I0629 14:08:19.145608 17196 caffe.cpp:313] Batch 976, loss = 1.9761
I0629 14:08:19.194643 17196 caffe.cpp:313] Batch 977, accuracy/top1 = 0.62
I0629 14:08:19.194669 17196 caffe.cpp:313] Batch 977, accuracy/top5 = 0.84
I0629 14:08:19.194671 17196 caffe.cpp:313] Batch 977, loss = 1.71608
I0629 14:08:19.244269 17196 caffe.cpp:313] Batch 978, accuracy/top1 = 0.56
I0629 14:08:19.244293 17196 caffe.cpp:313] Batch 978, accuracy/top5 = 0.78
I0629 14:08:19.244297 17196 caffe.cpp:313] Batch 978, loss = 2.13529
I0629 14:08:19.294169 17196 caffe.cpp:313] Batch 979, accuracy/top1 = 0.66
I0629 14:08:19.294193 17196 caffe.cpp:313] Batch 979, accuracy/top5 = 0.88
I0629 14:08:19.294196 17196 caffe.cpp:313] Batch 979, loss = 1.77923
I0629 14:08:19.342568 17196 caffe.cpp:313] Batch 980, accuracy/top1 = 0.46
I0629 14:08:19.342592 17196 caffe.cpp:313] Batch 980, accuracy/top5 = 0.72
I0629 14:08:19.342594 17196 caffe.cpp:313] Batch 980, loss = 2.24013
I0629 14:08:19.392431 17196 caffe.cpp:313] Batch 981, accuracy/top1 = 0.56
I0629 14:08:19.392453 17196 caffe.cpp:313] Batch 981, accuracy/top5 = 0.78
I0629 14:08:19.392457 17196 caffe.cpp:313] Batch 981, loss = 2.12288
I0629 14:08:19.441467 17196 caffe.cpp:313] Batch 982, accuracy/top1 = 0.46
I0629 14:08:19.441489 17196 caffe.cpp:313] Batch 982, accuracy/top5 = 0.74
I0629 14:08:19.441493 17196 caffe.cpp:313] Batch 982, loss = 2.83676
I0629 14:08:19.490651 17196 caffe.cpp:313] Batch 983, accuracy/top1 = 0.64
I0629 14:08:19.490674 17196 caffe.cpp:313] Batch 983, accuracy/top5 = 0.82
I0629 14:08:19.490677 17196 caffe.cpp:313] Batch 983, loss = 2.25381
I0629 14:08:19.540166 17196 caffe.cpp:313] Batch 984, accuracy/top1 = 0.6
I0629 14:08:19.540191 17196 caffe.cpp:313] Batch 984, accuracy/top5 = 0.8
I0629 14:08:19.540194 17196 caffe.cpp:313] Batch 984, loss = 1.49065
I0629 14:08:19.589351 17196 caffe.cpp:313] Batch 985, accuracy/top1 = 0.5
I0629 14:08:19.589375 17196 caffe.cpp:313] Batch 985, accuracy/top5 = 0.8
I0629 14:08:19.589377 17196 caffe.cpp:313] Batch 985, loss = 1.8561
I0629 14:08:19.639188 17196 caffe.cpp:313] Batch 986, accuracy/top1 = 0.5
I0629 14:08:19.639210 17196 caffe.cpp:313] Batch 986, accuracy/top5 = 0.76
I0629 14:08:19.639214 17196 caffe.cpp:313] Batch 986, loss = 2.20429
I0629 14:08:19.688275 17196 caffe.cpp:313] Batch 987, accuracy/top1 = 0.56
I0629 14:08:19.688314 17196 caffe.cpp:313] Batch 987, accuracy/top5 = 0.8
I0629 14:08:19.688318 17196 caffe.cpp:313] Batch 987, loss = 1.90932
I0629 14:08:19.737673 17196 caffe.cpp:313] Batch 988, accuracy/top1 = 0.62
I0629 14:08:19.737696 17196 caffe.cpp:313] Batch 988, accuracy/top5 = 0.8
I0629 14:08:19.737699 17196 caffe.cpp:313] Batch 988, loss = 1.74365
I0629 14:08:19.787521 17196 caffe.cpp:313] Batch 989, accuracy/top1 = 0.4
I0629 14:08:19.787545 17196 caffe.cpp:313] Batch 989, accuracy/top5 = 0.78
I0629 14:08:19.787549 17196 caffe.cpp:313] Batch 989, loss = 2.30378
I0629 14:08:19.836709 17196 caffe.cpp:313] Batch 990, accuracy/top1 = 0.54
I0629 14:08:19.836735 17196 caffe.cpp:313] Batch 990, accuracy/top5 = 0.86
I0629 14:08:19.836737 17196 caffe.cpp:313] Batch 990, loss = 1.34828
I0629 14:08:19.886857 17196 caffe.cpp:313] Batch 991, accuracy/top1 = 0.7
I0629 14:08:19.886880 17196 caffe.cpp:313] Batch 991, accuracy/top5 = 0.86
I0629 14:08:19.886883 17196 caffe.cpp:313] Batch 991, loss = 1.7589
I0629 14:08:19.936138 17196 caffe.cpp:313] Batch 992, accuracy/top1 = 0.66
I0629 14:08:19.936161 17196 caffe.cpp:313] Batch 992, accuracy/top5 = 0.82
I0629 14:08:19.936163 17196 caffe.cpp:313] Batch 992, loss = 1.57052
I0629 14:08:19.986277 17196 caffe.cpp:313] Batch 993, accuracy/top1 = 0.58
I0629 14:08:19.986304 17196 caffe.cpp:313] Batch 993, accuracy/top5 = 0.92
I0629 14:08:19.986306 17196 caffe.cpp:313] Batch 993, loss = 1.48395
I0629 14:08:20.035112 17196 caffe.cpp:313] Batch 994, accuracy/top1 = 0.62
I0629 14:08:20.035135 17196 caffe.cpp:313] Batch 994, accuracy/top5 = 0.84
I0629 14:08:20.035137 17196 caffe.cpp:313] Batch 994, loss = 1.49809
I0629 14:08:20.084337 17196 caffe.cpp:313] Batch 995, accuracy/top1 = 0.66
I0629 14:08:20.084362 17196 caffe.cpp:313] Batch 995, accuracy/top5 = 0.78
I0629 14:08:20.084364 17196 caffe.cpp:313] Batch 995, loss = 1.77687
I0629 14:08:20.133419 17196 caffe.cpp:313] Batch 996, accuracy/top1 = 0.6
I0629 14:08:20.133442 17196 caffe.cpp:313] Batch 996, accuracy/top5 = 0.76
I0629 14:08:20.133445 17196 caffe.cpp:313] Batch 996, loss = 1.77228
I0629 14:08:20.183194 17196 caffe.cpp:313] Batch 997, accuracy/top1 = 0.54
I0629 14:08:20.183213 17196 caffe.cpp:313] Batch 997, accuracy/top5 = 0.82
I0629 14:08:20.183217 17196 caffe.cpp:313] Batch 997, loss = 1.78852
I0629 14:08:20.204304 17241 data_reader.cpp:262] Starting prefetch of epoch 1
I0629 14:08:20.231484 17196 caffe.cpp:313] Batch 998, accuracy/top1 = 0.46
I0629 14:08:20.231506 17196 caffe.cpp:313] Batch 998, accuracy/top5 = 0.76
I0629 14:08:20.231509 17196 caffe.cpp:313] Batch 998, loss = 2.1132
I0629 14:08:20.280663 17196 caffe.cpp:313] Batch 999, accuracy/top1 = 0.64
I0629 14:08:20.280686 17196 caffe.cpp:313] Batch 999, accuracy/top5 = 0.82
I0629 14:08:20.280689 17196 caffe.cpp:313] Batch 999, loss = 1.65219
I0629 14:08:20.280692 17196 caffe.cpp:318] Loss: 1.86466
I0629 14:08:20.280699 17196 caffe.cpp:330] accuracy/top1 = 0.57258
I0629 14:08:20.280704 17196 caffe.cpp:330] accuracy/top5 = 0.801742
I0629 14:08:20.280707 17196 caffe.cpp:330] loss = 1.86466 (* 1 = 1.86466 loss)
