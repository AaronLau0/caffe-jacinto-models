Logging output to training/imagenet_jacintonet11v2_2017-06-30_02-08-23/train-log_2017-06-30_02-08-23.txt
WARNING: gnome-keyring:: couldn't connect to: /run/user/30409/keyring-KJvviu/pkcs11: Connection refused
p11-kit: skipping module 'gnome-keyring' whose initialization failed: An error occurred on the device
I0630 02:08:24.384852 28163 caffe.cpp:209] Using GPUs 0, 1, 2
I0630 02:08:24.385319 28163 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0630 02:08:24.385648 28163 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0630 02:08:24.385972 28163 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0630 02:08:24.776280 28163 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/test.prototxt"
test_iter: 1000
test_interval: 2000
base_lr: 0
display: 100
max_iter: 100
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 2
type: "SGD"
I0630 02:08:24.776373 28163 solver.cpp:82] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/train.prototxt
I0630 02:08:24.776844 28163 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0630 02:08:24.776849 28163 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0630 02:08:24.777000 28163 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 42
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0630 02:08:24.777089 28163 layer_factory.hpp:77] Creating layer data
I0630 02:08:24.777180 28163 net.cpp:98] Creating Layer data
I0630 02:08:24.777186 28163 net.cpp:413] data -> data
I0630 02:08:24.777202 28163 net.cpp:413] data -> label
I0630 02:08:24.778026 28196 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0630 02:08:24.780074 28163 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:08:24.780125 28163 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:08:24.805670 28163 net.cpp:148] Setting up data
I0630 02:08:24.805697 28163 net.cpp:155] Top shape: 42 3 224 224 (6322176)
I0630 02:08:24.805701 28163 net.cpp:155] Top shape: 42 (42)
I0630 02:08:24.805703 28163 net.cpp:163] Memory required for data: 25288872
I0630 02:08:24.805712 28163 layer_factory.hpp:77] Creating layer data/bias
I0630 02:08:24.805728 28163 net.cpp:98] Creating Layer data/bias
I0630 02:08:24.805734 28163 net.cpp:439] data/bias <- data
I0630 02:08:24.805744 28163 net.cpp:413] data/bias -> data/bias
I0630 02:08:24.806771 28163 net.cpp:148] Setting up data/bias
I0630 02:08:24.806779 28163 net.cpp:155] Top shape: 42 3 224 224 (6322176)
I0630 02:08:24.806783 28163 net.cpp:163] Memory required for data: 50577576
I0630 02:08:24.806797 28163 layer_factory.hpp:77] Creating layer conv1a
I0630 02:08:24.806809 28163 net.cpp:98] Creating Layer conv1a
I0630 02:08:24.806813 28163 net.cpp:439] conv1a <- data/bias
I0630 02:08:24.806818 28163 net.cpp:413] conv1a -> conv1a
I0630 02:08:24.809622 28198 blocking_queue.cpp:50] Waiting for data
I0630 02:08:24.810575 28163 net.cpp:148] Setting up conv1a
I0630 02:08:24.810585 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.810588 28163 net.cpp:163] Memory required for data: 118014120
I0630 02:08:24.810598 28163 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 02:08:24.810607 28163 net.cpp:98] Creating Layer conv1a/bn
I0630 02:08:24.810611 28163 net.cpp:439] conv1a/bn <- conv1a
I0630 02:08:24.810617 28163 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 02:08:24.811313 28163 net.cpp:148] Setting up conv1a/bn
I0630 02:08:24.811321 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.811326 28163 net.cpp:163] Memory required for data: 185450664
I0630 02:08:24.811337 28163 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 02:08:24.811342 28163 net.cpp:98] Creating Layer conv1a/relu
I0630 02:08:24.811347 28163 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 02:08:24.811352 28163 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 02:08:24.811365 28163 net.cpp:148] Setting up conv1a/relu
I0630 02:08:24.811370 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.811374 28163 net.cpp:163] Memory required for data: 252887208
I0630 02:08:24.811378 28163 layer_factory.hpp:77] Creating layer conv1b
I0630 02:08:24.811393 28163 net.cpp:98] Creating Layer conv1b
I0630 02:08:24.811395 28163 net.cpp:439] conv1b <- conv1a/bn
I0630 02:08:24.811401 28163 net.cpp:413] conv1b -> conv1b
I0630 02:08:24.811715 28163 net.cpp:148] Setting up conv1b
I0630 02:08:24.811722 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.811727 28163 net.cpp:163] Memory required for data: 320323752
I0630 02:08:24.811734 28163 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 02:08:24.811740 28163 net.cpp:98] Creating Layer conv1b/bn
I0630 02:08:24.811744 28163 net.cpp:439] conv1b/bn <- conv1b
I0630 02:08:24.811749 28163 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 02:08:24.812403 28163 net.cpp:148] Setting up conv1b/bn
I0630 02:08:24.812409 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.812413 28163 net.cpp:163] Memory required for data: 387760296
I0630 02:08:24.812422 28163 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 02:08:24.812425 28163 net.cpp:98] Creating Layer conv1b/relu
I0630 02:08:24.812430 28163 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 02:08:24.812436 28163 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 02:08:24.812441 28163 net.cpp:148] Setting up conv1b/relu
I0630 02:08:24.812446 28163 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:08:24.812449 28163 net.cpp:163] Memory required for data: 455196840
I0630 02:08:24.812453 28163 layer_factory.hpp:77] Creating layer pool1
I0630 02:08:24.812461 28163 net.cpp:98] Creating Layer pool1
I0630 02:08:24.812464 28163 net.cpp:439] pool1 <- conv1b/bn
I0630 02:08:24.812469 28163 net.cpp:413] pool1 -> pool1
I0630 02:08:24.812511 28163 net.cpp:148] Setting up pool1
I0630 02:08:24.812516 28163 net.cpp:155] Top shape: 42 32 56 56 (4214784)
I0630 02:08:24.812520 28163 net.cpp:163] Memory required for data: 472055976
I0630 02:08:24.812525 28163 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 02:08:24.812531 28163 net.cpp:98] Creating Layer res2a_branch2a
I0630 02:08:24.812535 28163 net.cpp:439] res2a_branch2a <- pool1
I0630 02:08:24.812541 28163 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 02:08:24.813169 28163 net.cpp:148] Setting up res2a_branch2a
I0630 02:08:24.813176 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.813180 28163 net.cpp:163] Memory required for data: 505774248
I0630 02:08:24.813187 28163 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 02:08:24.813192 28163 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 02:08:24.813196 28163 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 02:08:24.813201 28163 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 02:08:24.813860 28163 net.cpp:148] Setting up res2a_branch2a/bn
I0630 02:08:24.813868 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.813871 28163 net.cpp:163] Memory required for data: 539492520
I0630 02:08:24.813880 28163 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 02:08:24.813884 28163 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 02:08:24.813889 28163 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 02:08:24.813894 28163 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 02:08:24.813899 28163 net.cpp:148] Setting up res2a_branch2a/relu
I0630 02:08:24.813905 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.813908 28163 net.cpp:163] Memory required for data: 573210792
I0630 02:08:24.813912 28163 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 02:08:24.813923 28163 net.cpp:98] Creating Layer res2a_branch2b
I0630 02:08:24.813926 28163 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 02:08:24.813931 28163 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 02:08:24.814391 28163 net.cpp:148] Setting up res2a_branch2b
I0630 02:08:24.814398 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.814401 28163 net.cpp:163] Memory required for data: 606929064
I0630 02:08:24.814406 28163 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 02:08:24.814412 28163 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 02:08:24.814420 28163 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 02:08:24.814426 28163 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 02:08:24.815091 28163 net.cpp:148] Setting up res2a_branch2b/bn
I0630 02:08:24.815099 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.815101 28163 net.cpp:163] Memory required for data: 640647336
I0630 02:08:24.815110 28163 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 02:08:24.815114 28163 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 02:08:24.815119 28163 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 02:08:24.815124 28163 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 02:08:24.815132 28163 net.cpp:148] Setting up res2a_branch2b/relu
I0630 02:08:24.815136 28163 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:08:24.815140 28163 net.cpp:163] Memory required for data: 674365608
I0630 02:08:24.815143 28163 layer_factory.hpp:77] Creating layer pool2
I0630 02:08:24.815148 28163 net.cpp:98] Creating Layer pool2
I0630 02:08:24.815152 28163 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 02:08:24.815156 28163 net.cpp:413] pool2 -> pool2
I0630 02:08:24.815196 28163 net.cpp:148] Setting up pool2
I0630 02:08:24.815201 28163 net.cpp:155] Top shape: 42 64 28 28 (2107392)
I0630 02:08:24.815206 28163 net.cpp:163] Memory required for data: 682795176
I0630 02:08:24.815209 28163 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 02:08:24.815219 28163 net.cpp:98] Creating Layer res3a_branch2a
I0630 02:08:24.815223 28163 net.cpp:439] res3a_branch2a <- pool2
I0630 02:08:24.815228 28163 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 02:08:24.818584 28163 net.cpp:148] Setting up res3a_branch2a
I0630 02:08:24.818595 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.818599 28163 net.cpp:163] Memory required for data: 699654312
I0630 02:08:24.818605 28163 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 02:08:24.818612 28163 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 02:08:24.818616 28163 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 02:08:24.818624 28163 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 02:08:24.819257 28163 net.cpp:148] Setting up res3a_branch2a/bn
I0630 02:08:24.819265 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.819268 28163 net.cpp:163] Memory required for data: 716513448
I0630 02:08:24.819279 28163 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 02:08:24.819283 28163 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 02:08:24.819288 28163 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 02:08:24.819298 28163 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 02:08:24.819303 28163 net.cpp:148] Setting up res3a_branch2a/relu
I0630 02:08:24.819308 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.819311 28163 net.cpp:163] Memory required for data: 733372584
I0630 02:08:24.819315 28163 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 02:08:24.819322 28163 net.cpp:98] Creating Layer res3a_branch2b
I0630 02:08:24.819326 28163 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 02:08:24.819331 28163 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 02:08:24.820436 28163 net.cpp:148] Setting up res3a_branch2b
I0630 02:08:24.820444 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.820447 28163 net.cpp:163] Memory required for data: 750231720
I0630 02:08:24.820453 28163 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 02:08:24.820461 28163 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 02:08:24.820464 28163 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 02:08:24.820469 28163 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 02:08:24.821100 28163 net.cpp:148] Setting up res3a_branch2b/bn
I0630 02:08:24.821107 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.821112 28163 net.cpp:163] Memory required for data: 767090856
I0630 02:08:24.821127 28163 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 02:08:24.821132 28163 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 02:08:24.821136 28163 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 02:08:24.821141 28163 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 02:08:24.821147 28163 net.cpp:148] Setting up res3a_branch2b/relu
I0630 02:08:24.821151 28163 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:08:24.821156 28163 net.cpp:163] Memory required for data: 783949992
I0630 02:08:24.821159 28163 layer_factory.hpp:77] Creating layer pool3
I0630 02:08:24.821164 28163 net.cpp:98] Creating Layer pool3
I0630 02:08:24.821168 28163 net.cpp:439] pool3 <- res3a_branch2b/bn
I0630 02:08:24.821173 28163 net.cpp:413] pool3 -> pool3
I0630 02:08:24.821216 28163 net.cpp:148] Setting up pool3
I0630 02:08:24.821221 28163 net.cpp:155] Top shape: 42 128 14 14 (1053696)
I0630 02:08:24.821225 28163 net.cpp:163] Memory required for data: 788164776
I0630 02:08:24.821229 28163 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 02:08:24.821236 28163 net.cpp:98] Creating Layer res4a_branch2a
I0630 02:08:24.821239 28163 net.cpp:439] res4a_branch2a <- pool3
I0630 02:08:24.821244 28163 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 02:08:24.827327 28163 net.cpp:148] Setting up res4a_branch2a
I0630 02:08:24.827334 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.827337 28163 net.cpp:163] Memory required for data: 796594344
I0630 02:08:24.827344 28163 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 02:08:24.827350 28163 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 02:08:24.827354 28163 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 02:08:24.827359 28163 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 02:08:24.828004 28163 net.cpp:148] Setting up res4a_branch2a/bn
I0630 02:08:24.828011 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.828016 28163 net.cpp:163] Memory required for data: 805023912
I0630 02:08:24.828024 28163 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 02:08:24.828028 28163 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 02:08:24.828032 28163 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 02:08:24.828037 28163 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 02:08:24.828043 28163 net.cpp:148] Setting up res4a_branch2a/relu
I0630 02:08:24.828047 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.828052 28163 net.cpp:163] Memory required for data: 813453480
I0630 02:08:24.828055 28163 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 02:08:24.828061 28163 net.cpp:98] Creating Layer res4a_branch2b
I0630 02:08:24.828065 28163 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 02:08:24.828070 28163 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 02:08:24.831251 28163 net.cpp:148] Setting up res4a_branch2b
I0630 02:08:24.831259 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.831261 28163 net.cpp:163] Memory required for data: 821883048
I0630 02:08:24.831269 28163 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 02:08:24.831274 28163 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 02:08:24.831279 28163 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 02:08:24.831284 28163 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 02:08:24.831907 28163 net.cpp:148] Setting up res4a_branch2b/bn
I0630 02:08:24.831914 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.831918 28163 net.cpp:163] Memory required for data: 830312616
I0630 02:08:24.831925 28163 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 02:08:24.831930 28163 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 02:08:24.831934 28163 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 02:08:24.831938 28163 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 02:08:24.831944 28163 net.cpp:148] Setting up res4a_branch2b/relu
I0630 02:08:24.831954 28163 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:08:24.831957 28163 net.cpp:163] Memory required for data: 838742184
I0630 02:08:24.831961 28163 layer_factory.hpp:77] Creating layer pool4
I0630 02:08:24.831967 28163 net.cpp:98] Creating Layer pool4
I0630 02:08:24.831971 28163 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 02:08:24.831975 28163 net.cpp:413] pool4 -> pool4
I0630 02:08:24.832022 28163 net.cpp:148] Setting up pool4
I0630 02:08:24.832027 28163 net.cpp:155] Top shape: 42 256 7 7 (526848)
I0630 02:08:24.832031 28163 net.cpp:163] Memory required for data: 840849576
I0630 02:08:24.832036 28163 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 02:08:24.832041 28163 net.cpp:98] Creating Layer res5a_branch2a
I0630 02:08:24.832046 28163 net.cpp:439] res5a_branch2a <- pool4
I0630 02:08:24.832051 28163 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 02:08:24.856799 28163 net.cpp:148] Setting up res5a_branch2a
I0630 02:08:24.856820 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.856824 28163 net.cpp:163] Memory required for data: 845064360
I0630 02:08:24.856832 28163 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 02:08:24.856840 28163 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 02:08:24.856845 28163 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 02:08:24.856853 28163 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 02:08:24.857522 28163 net.cpp:148] Setting up res5a_branch2a/bn
I0630 02:08:24.857529 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.857532 28163 net.cpp:163] Memory required for data: 849279144
I0630 02:08:24.857542 28163 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 02:08:24.857547 28163 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 02:08:24.857551 28163 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 02:08:24.857556 28163 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 02:08:24.857563 28163 net.cpp:148] Setting up res5a_branch2a/relu
I0630 02:08:24.857568 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.857571 28163 net.cpp:163] Memory required for data: 853493928
I0630 02:08:24.857574 28163 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 02:08:24.857583 28163 net.cpp:98] Creating Layer res5a_branch2b
I0630 02:08:24.857585 28163 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 02:08:24.857591 28163 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 02:08:24.870481 28163 net.cpp:148] Setting up res5a_branch2b
I0630 02:08:24.870506 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.870509 28163 net.cpp:163] Memory required for data: 857708712
I0630 02:08:24.870524 28163 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 02:08:24.870534 28163 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 02:08:24.870539 28163 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 02:08:24.870545 28163 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 02:08:24.871232 28163 net.cpp:148] Setting up res5a_branch2b/bn
I0630 02:08:24.871240 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.871243 28163 net.cpp:163] Memory required for data: 861923496
I0630 02:08:24.871253 28163 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 02:08:24.871258 28163 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 02:08:24.871261 28163 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 02:08:24.871266 28163 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 02:08:24.871273 28163 net.cpp:148] Setting up res5a_branch2b/relu
I0630 02:08:24.871278 28163 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:08:24.871281 28163 net.cpp:163] Memory required for data: 866138280
I0630 02:08:24.871285 28163 layer_factory.hpp:77] Creating layer pool5
I0630 02:08:24.871294 28163 net.cpp:98] Creating Layer pool5
I0630 02:08:24.871297 28163 net.cpp:439] pool5 <- res5a_branch2b/bn
I0630 02:08:24.871302 28163 net.cpp:413] pool5 -> pool5
I0630 02:08:24.871345 28163 net.cpp:148] Setting up pool5
I0630 02:08:24.871350 28163 net.cpp:155] Top shape: 42 512 1 1 (21504)
I0630 02:08:24.871353 28163 net.cpp:163] Memory required for data: 866224296
I0630 02:08:24.871357 28163 layer_factory.hpp:77] Creating layer fc1000
I0630 02:08:24.871368 28163 net.cpp:98] Creating Layer fc1000
I0630 02:08:24.871372 28163 net.cpp:439] fc1000 <- pool5
I0630 02:08:24.871377 28163 net.cpp:413] fc1000 -> fc1000
I0630 02:08:24.882418 28163 net.cpp:148] Setting up fc1000
I0630 02:08:24.882427 28163 net.cpp:155] Top shape: 42 1000 (42000)
I0630 02:08:24.882431 28163 net.cpp:163] Memory required for data: 866392296
I0630 02:08:24.882436 28163 layer_factory.hpp:77] Creating layer loss
I0630 02:08:24.882442 28163 net.cpp:98] Creating Layer loss
I0630 02:08:24.882447 28163 net.cpp:439] loss <- fc1000
I0630 02:08:24.882452 28163 net.cpp:439] loss <- label
I0630 02:08:24.882458 28163 net.cpp:413] loss -> loss
I0630 02:08:24.882468 28163 layer_factory.hpp:77] Creating layer loss
I0630 02:08:24.882619 28163 net.cpp:148] Setting up loss
I0630 02:08:24.882624 28163 net.cpp:155] Top shape: (1)
I0630 02:08:24.882628 28163 net.cpp:158]     with loss weight 1
I0630 02:08:24.882642 28163 net.cpp:163] Memory required for data: 866392300
I0630 02:08:24.882645 28163 net.cpp:224] loss needs backward computation.
I0630 02:08:24.882650 28163 net.cpp:224] fc1000 needs backward computation.
I0630 02:08:24.882654 28163 net.cpp:224] pool5 needs backward computation.
I0630 02:08:24.882658 28163 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 02:08:24.882661 28163 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 02:08:24.882665 28163 net.cpp:224] res5a_branch2b needs backward computation.
I0630 02:08:24.882670 28163 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 02:08:24.882674 28163 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 02:08:24.882678 28163 net.cpp:224] res5a_branch2a needs backward computation.
I0630 02:08:24.882683 28163 net.cpp:224] pool4 needs backward computation.
I0630 02:08:24.882686 28163 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 02:08:24.882690 28163 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 02:08:24.882694 28163 net.cpp:224] res4a_branch2b needs backward computation.
I0630 02:08:24.882699 28163 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 02:08:24.882702 28163 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 02:08:24.882706 28163 net.cpp:224] res4a_branch2a needs backward computation.
I0630 02:08:24.882710 28163 net.cpp:224] pool3 needs backward computation.
I0630 02:08:24.882715 28163 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 02:08:24.882719 28163 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 02:08:24.882724 28163 net.cpp:224] res3a_branch2b needs backward computation.
I0630 02:08:24.882727 28163 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 02:08:24.882731 28163 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 02:08:24.882735 28163 net.cpp:224] res3a_branch2a needs backward computation.
I0630 02:08:24.882740 28163 net.cpp:224] pool2 needs backward computation.
I0630 02:08:24.882743 28163 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 02:08:24.882747 28163 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 02:08:24.882751 28163 net.cpp:224] res2a_branch2b needs backward computation.
I0630 02:08:24.882755 28163 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 02:08:24.882758 28163 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 02:08:24.882763 28163 net.cpp:224] res2a_branch2a needs backward computation.
I0630 02:08:24.882767 28163 net.cpp:224] pool1 needs backward computation.
I0630 02:08:24.882771 28163 net.cpp:224] conv1b/relu needs backward computation.
I0630 02:08:24.882774 28163 net.cpp:224] conv1b/bn needs backward computation.
I0630 02:08:24.882779 28163 net.cpp:224] conv1b needs backward computation.
I0630 02:08:24.882788 28163 net.cpp:224] conv1a/relu needs backward computation.
I0630 02:08:24.882792 28163 net.cpp:224] conv1a/bn needs backward computation.
I0630 02:08:24.882797 28163 net.cpp:224] conv1a needs backward computation.
I0630 02:08:24.882802 28163 net.cpp:226] data/bias does not need backward computation.
I0630 02:08:24.882805 28163 net.cpp:226] data does not need backward computation.
I0630 02:08:24.882809 28163 net.cpp:268] This network produces output loss
I0630 02:08:24.882829 28163 net.cpp:288] Network initialization done.
I0630 02:08:24.883270 28163 solver.cpp:182] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/test.prototxt
I0630 02:08:24.883458 28163 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0630 02:08:24.883601 28163 layer_factory.hpp:77] Creating layer data
I0630 02:08:24.883661 28163 net.cpp:98] Creating Layer data
I0630 02:08:24.883666 28163 net.cpp:413] data -> data
I0630 02:08:24.883672 28163 net.cpp:413] data -> label
I0630 02:08:24.902891 28199 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0630 02:08:24.903990 28163 data_layer.cpp:78] ReshapePrefetch 50, 3, 224, 224
I0630 02:08:24.904057 28163 data_layer.cpp:83] output data size: 50,3,224,224
I0630 02:08:24.935562 28163 net.cpp:148] Setting up data
I0630 02:08:24.935583 28163 net.cpp:155] Top shape: 50 3 224 224 (7526400)
I0630 02:08:24.935588 28163 net.cpp:155] Top shape: 50 (50)
I0630 02:08:24.935590 28163 net.cpp:163] Memory required for data: 30105800
I0630 02:08:24.935596 28163 layer_factory.hpp:77] Creating layer label_data_1_split
I0630 02:08:24.935607 28163 net.cpp:98] Creating Layer label_data_1_split
I0630 02:08:24.935611 28163 net.cpp:439] label_data_1_split <- label
I0630 02:08:24.935616 28163 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0630 02:08:24.935626 28163 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0630 02:08:24.935631 28163 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0630 02:08:24.935765 28163 net.cpp:148] Setting up label_data_1_split
I0630 02:08:24.935775 28163 net.cpp:155] Top shape: 50 (50)
I0630 02:08:24.935781 28163 net.cpp:155] Top shape: 50 (50)
I0630 02:08:24.935784 28163 net.cpp:155] Top shape: 50 (50)
I0630 02:08:24.935788 28163 net.cpp:163] Memory required for data: 30106400
I0630 02:08:24.935792 28163 layer_factory.hpp:77] Creating layer data/bias
I0630 02:08:24.935801 28163 net.cpp:98] Creating Layer data/bias
I0630 02:08:24.935804 28163 net.cpp:439] data/bias <- data
I0630 02:08:24.935811 28163 net.cpp:413] data/bias -> data/bias
I0630 02:08:24.935963 28163 net.cpp:148] Setting up data/bias
I0630 02:08:24.935968 28163 net.cpp:155] Top shape: 50 3 224 224 (7526400)
I0630 02:08:24.935972 28163 net.cpp:163] Memory required for data: 60212000
I0630 02:08:24.935979 28163 layer_factory.hpp:77] Creating layer conv1a
I0630 02:08:24.935987 28163 net.cpp:98] Creating Layer conv1a
I0630 02:08:24.935992 28163 net.cpp:439] conv1a <- data/bias
I0630 02:08:24.935997 28163 net.cpp:413] conv1a -> conv1a
I0630 02:08:24.936503 28163 net.cpp:148] Setting up conv1a
I0630 02:08:24.936511 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.936514 28163 net.cpp:163] Memory required for data: 140493600
I0630 02:08:24.936522 28163 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 02:08:24.936529 28163 net.cpp:98] Creating Layer conv1a/bn
I0630 02:08:24.936533 28163 net.cpp:439] conv1a/bn <- conv1a
I0630 02:08:24.936538 28163 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 02:08:24.939589 28163 net.cpp:148] Setting up conv1a/bn
I0630 02:08:24.939596 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.939599 28163 net.cpp:163] Memory required for data: 220775200
I0630 02:08:24.939610 28163 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 02:08:24.939621 28163 net.cpp:98] Creating Layer conv1a/relu
I0630 02:08:24.939625 28163 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 02:08:24.939630 28163 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 02:08:24.939637 28163 net.cpp:148] Setting up conv1a/relu
I0630 02:08:24.939642 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.939646 28163 net.cpp:163] Memory required for data: 301056800
I0630 02:08:24.939649 28163 layer_factory.hpp:77] Creating layer conv1b
I0630 02:08:24.939656 28163 net.cpp:98] Creating Layer conv1b
I0630 02:08:24.939661 28163 net.cpp:439] conv1b <- conv1a/bn
I0630 02:08:24.939666 28163 net.cpp:413] conv1b -> conv1b
I0630 02:08:24.940027 28163 net.cpp:148] Setting up conv1b
I0630 02:08:24.940034 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.940038 28163 net.cpp:163] Memory required for data: 381338400
I0630 02:08:24.940045 28163 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 02:08:24.940052 28163 net.cpp:98] Creating Layer conv1b/bn
I0630 02:08:24.940055 28163 net.cpp:439] conv1b/bn <- conv1b
I0630 02:08:24.940062 28163 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 02:08:24.940778 28163 net.cpp:148] Setting up conv1b/bn
I0630 02:08:24.940785 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.940789 28163 net.cpp:163] Memory required for data: 461620000
I0630 02:08:24.940800 28163 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 02:08:24.940805 28163 net.cpp:98] Creating Layer conv1b/relu
I0630 02:08:24.940810 28163 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 02:08:24.940814 28163 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 02:08:24.940820 28163 net.cpp:148] Setting up conv1b/relu
I0630 02:08:24.940825 28163 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:08:24.940829 28163 net.cpp:163] Memory required for data: 541901600
I0630 02:08:24.940832 28163 layer_factory.hpp:77] Creating layer pool1
I0630 02:08:24.940840 28163 net.cpp:98] Creating Layer pool1
I0630 02:08:24.940842 28163 net.cpp:439] pool1 <- conv1b/bn
I0630 02:08:24.940846 28163 net.cpp:413] pool1 -> pool1
I0630 02:08:24.940888 28163 net.cpp:148] Setting up pool1
I0630 02:08:24.940893 28163 net.cpp:155] Top shape: 50 32 56 56 (5017600)
I0630 02:08:24.940897 28163 net.cpp:163] Memory required for data: 561972000
I0630 02:08:24.940901 28163 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 02:08:24.940908 28163 net.cpp:98] Creating Layer res2a_branch2a
I0630 02:08:24.940912 28163 net.cpp:439] res2a_branch2a <- pool1
I0630 02:08:24.940917 28163 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 02:08:24.941573 28163 net.cpp:148] Setting up res2a_branch2a
I0630 02:08:24.941579 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.941583 28163 net.cpp:163] Memory required for data: 602112800
I0630 02:08:24.941591 28163 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 02:08:24.941596 28163 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 02:08:24.941601 28163 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 02:08:24.941606 28163 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 02:08:24.942334 28163 net.cpp:148] Setting up res2a_branch2a/bn
I0630 02:08:24.942342 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.942345 28163 net.cpp:163] Memory required for data: 642253600
I0630 02:08:24.942353 28163 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 02:08:24.942358 28163 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 02:08:24.942363 28163 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 02:08:24.942366 28163 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 02:08:24.942373 28163 net.cpp:148] Setting up res2a_branch2a/relu
I0630 02:08:24.942378 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.942380 28163 net.cpp:163] Memory required for data: 682394400
I0630 02:08:24.942384 28163 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 02:08:24.942390 28163 net.cpp:98] Creating Layer res2a_branch2b
I0630 02:08:24.942399 28163 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 02:08:24.942404 28163 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 02:08:24.942905 28163 net.cpp:148] Setting up res2a_branch2b
I0630 02:08:24.942912 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.942916 28163 net.cpp:163] Memory required for data: 722535200
I0630 02:08:24.942921 28163 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 02:08:24.942927 28163 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 02:08:24.942931 28163 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 02:08:24.942936 28163 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 02:08:24.943667 28163 net.cpp:148] Setting up res2a_branch2b/bn
I0630 02:08:24.943675 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.943678 28163 net.cpp:163] Memory required for data: 762676000
I0630 02:08:24.943687 28163 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 02:08:24.943691 28163 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 02:08:24.943696 28163 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 02:08:24.943701 28163 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 02:08:24.943706 28163 net.cpp:148] Setting up res2a_branch2b/relu
I0630 02:08:24.943711 28163 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:08:24.943714 28163 net.cpp:163] Memory required for data: 802816800
I0630 02:08:24.943717 28163 layer_factory.hpp:77] Creating layer pool2
I0630 02:08:24.943723 28163 net.cpp:98] Creating Layer pool2
I0630 02:08:24.943727 28163 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 02:08:24.943730 28163 net.cpp:413] pool2 -> pool2
I0630 02:08:24.943778 28163 net.cpp:148] Setting up pool2
I0630 02:08:24.943783 28163 net.cpp:155] Top shape: 50 64 28 28 (2508800)
I0630 02:08:24.943787 28163 net.cpp:163] Memory required for data: 812852000
I0630 02:08:24.943791 28163 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 02:08:24.943799 28163 net.cpp:98] Creating Layer res3a_branch2a
I0630 02:08:24.943802 28163 net.cpp:439] res3a_branch2a <- pool2
I0630 02:08:24.943807 28163 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 02:08:24.946485 28163 net.cpp:148] Setting up res3a_branch2a
I0630 02:08:24.946494 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.946498 28163 net.cpp:163] Memory required for data: 832922400
I0630 02:08:24.946504 28163 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 02:08:24.946511 28163 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 02:08:24.946514 28163 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 02:08:24.946526 28163 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 02:08:24.947228 28163 net.cpp:148] Setting up res3a_branch2a/bn
I0630 02:08:24.947237 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.947239 28163 net.cpp:163] Memory required for data: 852992800
I0630 02:08:24.947249 28163 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 02:08:24.947257 28163 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 02:08:24.947262 28163 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 02:08:24.947266 28163 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 02:08:24.947273 28163 net.cpp:148] Setting up res3a_branch2a/relu
I0630 02:08:24.947278 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.947281 28163 net.cpp:163] Memory required for data: 873063200
I0630 02:08:24.947284 28163 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 02:08:24.947291 28163 net.cpp:98] Creating Layer res3a_branch2b
I0630 02:08:24.947294 28163 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 02:08:24.947299 28163 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 02:08:24.948344 28163 net.cpp:148] Setting up res3a_branch2b
I0630 02:08:24.948355 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.948359 28163 net.cpp:163] Memory required for data: 893133600
I0630 02:08:24.948372 28163 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 02:08:24.948379 28163 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 02:08:24.948382 28163 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 02:08:24.948387 28163 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 02:08:24.949074 28163 net.cpp:148] Setting up res3a_branch2b/bn
I0630 02:08:24.949081 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.949085 28163 net.cpp:163] Memory required for data: 913204000
I0630 02:08:24.949093 28163 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 02:08:24.949105 28163 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 02:08:24.949108 28163 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 02:08:24.949113 28163 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 02:08:24.949118 28163 net.cpp:148] Setting up res3a_branch2b/relu
I0630 02:08:24.949123 28163 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:08:24.949126 28163 net.cpp:163] Memory required for data: 933274400
I0630 02:08:24.949131 28163 layer_factory.hpp:77] Creating layer pool3
I0630 02:08:24.949136 28163 net.cpp:98] Creating Layer pool3
I0630 02:08:24.949139 28163 net.cpp:439] pool3 <- res3a_branch2b/bn
I0630 02:08:24.949144 28163 net.cpp:413] pool3 -> pool3
I0630 02:08:24.949188 28163 net.cpp:148] Setting up pool3
I0630 02:08:24.949193 28163 net.cpp:155] Top shape: 50 128 14 14 (1254400)
I0630 02:08:24.949198 28163 net.cpp:163] Memory required for data: 938292000
I0630 02:08:24.949201 28163 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 02:08:24.949208 28163 net.cpp:98] Creating Layer res4a_branch2a
I0630 02:08:24.949211 28163 net.cpp:439] res4a_branch2a <- pool3
I0630 02:08:24.949218 28163 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 02:08:24.955292 28163 net.cpp:148] Setting up res4a_branch2a
I0630 02:08:24.955301 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.955304 28163 net.cpp:163] Memory required for data: 948327200
I0630 02:08:24.955310 28163 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 02:08:24.955317 28163 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 02:08:24.955320 28163 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 02:08:24.955325 28163 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 02:08:24.956022 28163 net.cpp:148] Setting up res4a_branch2a/bn
I0630 02:08:24.956030 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.956033 28163 net.cpp:163] Memory required for data: 958362400
I0630 02:08:24.956043 28163 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 02:08:24.956048 28163 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 02:08:24.956053 28163 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 02:08:24.956058 28163 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 02:08:24.956065 28163 net.cpp:148] Setting up res4a_branch2a/relu
I0630 02:08:24.956069 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.956073 28163 net.cpp:163] Memory required for data: 968397600
I0630 02:08:24.956077 28163 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 02:08:24.956084 28163 net.cpp:98] Creating Layer res4a_branch2b
I0630 02:08:24.956089 28163 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 02:08:24.956094 28163 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 02:08:24.959396 28163 net.cpp:148] Setting up res4a_branch2b
I0630 02:08:24.959408 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.959411 28163 net.cpp:163] Memory required for data: 978432800
I0630 02:08:24.959417 28163 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 02:08:24.959424 28163 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 02:08:24.959429 28163 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 02:08:24.959434 28163 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 02:08:24.960139 28163 net.cpp:148] Setting up res4a_branch2b/bn
I0630 02:08:24.960146 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.960160 28163 net.cpp:163] Memory required for data: 988468000
I0630 02:08:24.960167 28163 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 02:08:24.960172 28163 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 02:08:24.960176 28163 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 02:08:24.960181 28163 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 02:08:24.960188 28163 net.cpp:148] Setting up res4a_branch2b/relu
I0630 02:08:24.960192 28163 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:08:24.960196 28163 net.cpp:163] Memory required for data: 998503200
I0630 02:08:24.960201 28163 layer_factory.hpp:77] Creating layer pool4
I0630 02:08:24.960206 28163 net.cpp:98] Creating Layer pool4
I0630 02:08:24.960211 28163 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 02:08:24.960216 28163 net.cpp:413] pool4 -> pool4
I0630 02:08:24.960261 28163 net.cpp:148] Setting up pool4
I0630 02:08:24.960266 28163 net.cpp:155] Top shape: 50 256 7 7 (627200)
I0630 02:08:24.960270 28163 net.cpp:163] Memory required for data: 1001012000
I0630 02:08:24.960274 28163 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 02:08:24.960281 28163 net.cpp:98] Creating Layer res5a_branch2a
I0630 02:08:24.960284 28163 net.cpp:439] res5a_branch2a <- pool4
I0630 02:08:24.960289 28163 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 02:08:24.985337 28163 net.cpp:148] Setting up res5a_branch2a
I0630 02:08:24.985357 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:24.985360 28163 net.cpp:163] Memory required for data: 1006029600
I0630 02:08:24.985368 28163 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 02:08:24.985378 28163 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 02:08:24.985383 28163 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 02:08:24.985389 28163 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 02:08:24.986106 28163 net.cpp:148] Setting up res5a_branch2a/bn
I0630 02:08:24.986114 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:24.986117 28163 net.cpp:163] Memory required for data: 1011047200
I0630 02:08:24.986125 28163 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 02:08:24.986137 28163 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 02:08:24.986141 28163 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 02:08:24.986145 28163 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 02:08:24.986151 28163 net.cpp:148] Setting up res5a_branch2a/relu
I0630 02:08:24.986155 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:24.986156 28163 net.cpp:163] Memory required for data: 1016064800
I0630 02:08:24.986158 28163 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 02:08:24.986165 28163 net.cpp:98] Creating Layer res5a_branch2b
I0630 02:08:24.986166 28163 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 02:08:24.986169 28163 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 02:08:25.001201 28163 net.cpp:148] Setting up res5a_branch2b
I0630 02:08:25.001217 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:25.001219 28163 net.cpp:163] Memory required for data: 1021082400
I0630 02:08:25.001227 28163 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 02:08:25.001235 28163 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 02:08:25.001237 28163 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 02:08:25.001240 28163 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 02:08:25.001971 28163 net.cpp:148] Setting up res5a_branch2b/bn
I0630 02:08:25.001977 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:25.001979 28163 net.cpp:163] Memory required for data: 1026100000
I0630 02:08:25.001984 28163 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 02:08:25.001988 28163 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 02:08:25.001991 28163 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 02:08:25.001992 28163 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 02:08:25.002007 28163 net.cpp:148] Setting up res5a_branch2b/relu
I0630 02:08:25.002012 28163 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:08:25.002013 28163 net.cpp:163] Memory required for data: 1031117600
I0630 02:08:25.002017 28163 layer_factory.hpp:77] Creating layer pool5
I0630 02:08:25.002023 28163 net.cpp:98] Creating Layer pool5
I0630 02:08:25.002027 28163 net.cpp:439] pool5 <- res5a_branch2b/bn
I0630 02:08:25.002032 28163 net.cpp:413] pool5 -> pool5
I0630 02:08:25.002063 28163 net.cpp:148] Setting up pool5
I0630 02:08:25.002068 28163 net.cpp:155] Top shape: 50 512 1 1 (25600)
I0630 02:08:25.002069 28163 net.cpp:163] Memory required for data: 1031220000
I0630 02:08:25.002073 28163 layer_factory.hpp:77] Creating layer fc1000
I0630 02:08:25.002075 28163 net.cpp:98] Creating Layer fc1000
I0630 02:08:25.002077 28163 net.cpp:439] fc1000 <- pool5
I0630 02:08:25.002081 28163 net.cpp:413] fc1000 -> fc1000
I0630 02:08:25.013155 28163 net.cpp:148] Setting up fc1000
I0630 02:08:25.013167 28163 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:08:25.013170 28163 net.cpp:163] Memory required for data: 1031420000
I0630 02:08:25.013175 28163 layer_factory.hpp:77] Creating layer fc1000_fc1000_0_split
I0630 02:08:25.013178 28163 net.cpp:98] Creating Layer fc1000_fc1000_0_split
I0630 02:08:25.013180 28163 net.cpp:439] fc1000_fc1000_0_split <- fc1000
I0630 02:08:25.013183 28163 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0630 02:08:25.013188 28163 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0630 02:08:25.013191 28163 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0630 02:08:25.013255 28163 net.cpp:148] Setting up fc1000_fc1000_0_split
I0630 02:08:25.013260 28163 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:08:25.013262 28163 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:08:25.013264 28163 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:08:25.013267 28163 net.cpp:163] Memory required for data: 1032020000
I0630 02:08:25.013268 28163 layer_factory.hpp:77] Creating layer loss
I0630 02:08:25.013273 28163 net.cpp:98] Creating Layer loss
I0630 02:08:25.013274 28163 net.cpp:439] loss <- fc1000_fc1000_0_split_0
I0630 02:08:25.013276 28163 net.cpp:439] loss <- label_data_1_split_0
I0630 02:08:25.013279 28163 net.cpp:413] loss -> loss
I0630 02:08:25.013283 28163 layer_factory.hpp:77] Creating layer loss
I0630 02:08:25.013439 28163 net.cpp:148] Setting up loss
I0630 02:08:25.013444 28163 net.cpp:155] Top shape: (1)
I0630 02:08:25.013447 28163 net.cpp:158]     with loss weight 1
I0630 02:08:25.013453 28163 net.cpp:163] Memory required for data: 1032020004
I0630 02:08:25.013455 28163 layer_factory.hpp:77] Creating layer accuracy/top1
I0630 02:08:25.013459 28163 net.cpp:98] Creating Layer accuracy/top1
I0630 02:08:25.013461 28163 net.cpp:439] accuracy/top1 <- fc1000_fc1000_0_split_1
I0630 02:08:25.013463 28163 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0630 02:08:25.013466 28163 net.cpp:413] accuracy/top1 -> accuracy/top1
I0630 02:08:25.013471 28163 net.cpp:148] Setting up accuracy/top1
I0630 02:08:25.013473 28163 net.cpp:155] Top shape: (1)
I0630 02:08:25.013476 28163 net.cpp:163] Memory required for data: 1032020008
I0630 02:08:25.013480 28163 layer_factory.hpp:77] Creating layer accuracy/top5
I0630 02:08:25.013489 28163 net.cpp:98] Creating Layer accuracy/top5
I0630 02:08:25.013495 28163 net.cpp:439] accuracy/top5 <- fc1000_fc1000_0_split_2
I0630 02:08:25.013499 28163 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0630 02:08:25.013504 28163 net.cpp:413] accuracy/top5 -> accuracy/top5
I0630 02:08:25.013509 28163 net.cpp:148] Setting up accuracy/top5
I0630 02:08:25.013514 28163 net.cpp:155] Top shape: (1)
I0630 02:08:25.013516 28163 net.cpp:163] Memory required for data: 1032020012
I0630 02:08:25.013520 28163 net.cpp:226] accuracy/top5 does not need backward computation.
I0630 02:08:25.013523 28163 net.cpp:226] accuracy/top1 does not need backward computation.
I0630 02:08:25.013527 28163 net.cpp:224] loss needs backward computation.
I0630 02:08:25.013540 28163 net.cpp:224] fc1000_fc1000_0_split needs backward computation.
I0630 02:08:25.013545 28163 net.cpp:224] fc1000 needs backward computation.
I0630 02:08:25.013548 28163 net.cpp:224] pool5 needs backward computation.
I0630 02:08:25.013552 28163 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 02:08:25.013556 28163 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 02:08:25.013561 28163 net.cpp:224] res5a_branch2b needs backward computation.
I0630 02:08:25.013566 28163 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 02:08:25.013569 28163 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 02:08:25.013573 28163 net.cpp:224] res5a_branch2a needs backward computation.
I0630 02:08:25.013578 28163 net.cpp:224] pool4 needs backward computation.
I0630 02:08:25.013582 28163 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 02:08:25.013586 28163 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 02:08:25.013589 28163 net.cpp:224] res4a_branch2b needs backward computation.
I0630 02:08:25.013593 28163 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 02:08:25.013597 28163 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 02:08:25.013602 28163 net.cpp:224] res4a_branch2a needs backward computation.
I0630 02:08:25.013605 28163 net.cpp:224] pool3 needs backward computation.
I0630 02:08:25.013609 28163 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 02:08:25.013612 28163 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 02:08:25.013617 28163 net.cpp:224] res3a_branch2b needs backward computation.
I0630 02:08:25.013620 28163 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 02:08:25.013624 28163 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 02:08:25.013628 28163 net.cpp:224] res3a_branch2a needs backward computation.
I0630 02:08:25.013633 28163 net.cpp:224] pool2 needs backward computation.
I0630 02:08:25.013636 28163 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 02:08:25.013640 28163 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 02:08:25.013645 28163 net.cpp:224] res2a_branch2b needs backward computation.
I0630 02:08:25.013649 28163 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 02:08:25.013653 28163 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 02:08:25.013658 28163 net.cpp:224] res2a_branch2a needs backward computation.
I0630 02:08:25.013662 28163 net.cpp:224] pool1 needs backward computation.
I0630 02:08:25.013666 28163 net.cpp:224] conv1b/relu needs backward computation.
I0630 02:08:25.013670 28163 net.cpp:224] conv1b/bn needs backward computation.
I0630 02:08:25.013675 28163 net.cpp:224] conv1b needs backward computation.
I0630 02:08:25.013679 28163 net.cpp:224] conv1a/relu needs backward computation.
I0630 02:08:25.013684 28163 net.cpp:224] conv1a/bn needs backward computation.
I0630 02:08:25.013687 28163 net.cpp:224] conv1a needs backward computation.
I0630 02:08:25.013691 28163 net.cpp:226] data/bias does not need backward computation.
I0630 02:08:25.013695 28163 net.cpp:226] label_data_1_split does not need backward computation.
I0630 02:08:25.013700 28163 net.cpp:226] data does not need backward computation.
I0630 02:08:25.013703 28163 net.cpp:268] This network produces output accuracy/top1
I0630 02:08:25.013707 28163 net.cpp:268] This network produces output accuracy/top5
I0630 02:08:25.013711 28163 net.cpp:268] This network produces output loss
I0630 02:08:25.013736 28163 net.cpp:288] Network initialization done.
I0630 02:08:25.013803 28163 solver.cpp:60] Solver scaffolding done.
I0630 02:08:25.017415 28163 caffe.cpp:145] Finetuning from /data/mmcodec_video2_tier3/users/manu/experiments/object/classification/2017.06.new_script/caffe-0.15/jacintonet11_imagenet_2017.06.12_lmdb_caffe-0.15-2gpu(60.89%)/stage0/jacintonet11_iter_320000.caffemodel
I0630 02:08:32.764169 28163 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:08:32.764261 28163 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:08:33.257032 28163 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:08:33.257115 28163 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:08:33.802640 28163 parallel.cpp:334] Starting Optimization
I0630 02:08:33.802692 28163 solver.cpp:413] Solving jacintonet11v2_train
I0630 02:08:33.802696 28163 solver.cpp:414] Learning Rate Policy: poly
I0630 02:08:33.808503 28163 solver.cpp:471] Iteration 0, Testing net (#0)
I0630 02:08:33.945459 28163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:09:22.744361 28163 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.608879
I0630 02:09:22.744411 28163 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.832402
I0630 02:09:22.744417 28163 solver.cpp:544]     Test net output #2: loss = 1.32894 (* 1 = 1.32894 loss)
I0630 02:09:23.005231 28163 solver.cpp:290] Iteration 0 (0 iter/s, 49.2011s/100 iter), loss = 1.05952
I0630 02:09:23.005254 28163 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:09:23.005261 28163 sgd_solver.cpp:106] Iteration 0, lr = 0
I0630 02:09:38.774896 28163 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/imagenet_jacintonet11v2_iter_100.caffemodel
I0630 02:09:38.806509 28163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/imagenet_jacintonet11v2_iter_100.solverstate
I0630 02:09:38.835595 28163 solver.cpp:451] Iteration 100, loss = 0.928571
I0630 02:09:38.835618 28163 solver.cpp:456] Optimization Done.
I0630 02:09:38.914487 28163 caffe.cpp:246] Optimization Done.
training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse
WARNING: gnome-keyring:: couldn't connect to: /run/user/30409/keyring-KJvviu/pkcs11: Connection refused
p11-kit: skipping module 'gnome-keyring' whose initialization failed: An error occurred on the device
I0630 02:09:40.151670 29777 caffe.cpp:209] Using GPUs 0, 1, 2
I0630 02:09:40.152137 29777 caffe.cpp:214] GPU 0: GeForce GTX 1080
I0630 02:09:40.152465 29777 caffe.cpp:214] GPU 1: GeForce GTX 1080
I0630 02:09:40.152789 29777 caffe.cpp:214] GPU 2: GeForce GTX 1080
I0630 02:09:40.539373 29777 solver.cpp:48] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/test.prototxt"
test_iter: 1000
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 320000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 2
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.01
sparsity_step_iter: 2000
sparsity_start_iter: 0
sparsity_start_factor: 0
I0630 02:09:40.539465 29777 solver.cpp:82] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/train.prototxt
I0630 02:09:40.539917 29777 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0630 02:09:40.539922 29777 net.cpp:327] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0630 02:09:40.540078 29777 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 42
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0630 02:09:40.540159 29777 layer_factory.hpp:77] Creating layer data
I0630 02:09:40.540241 29777 net.cpp:98] Creating Layer data
I0630 02:09:40.540248 29777 net.cpp:413] data -> data
I0630 02:09:40.540268 29777 net.cpp:413] data -> label
I0630 02:09:40.541277 29803 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0630 02:09:40.543381 29777 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:09:40.543438 29777 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:09:40.569190 29777 net.cpp:148] Setting up data
I0630 02:09:40.569226 29777 net.cpp:155] Top shape: 42 3 224 224 (6322176)
I0630 02:09:40.569231 29777 net.cpp:155] Top shape: 42 (42)
I0630 02:09:40.569234 29777 net.cpp:163] Memory required for data: 25288872
I0630 02:09:40.569255 29777 layer_factory.hpp:77] Creating layer data/bias
I0630 02:09:40.569284 29777 net.cpp:98] Creating Layer data/bias
I0630 02:09:40.569291 29777 net.cpp:439] data/bias <- data
I0630 02:09:40.569308 29777 net.cpp:413] data/bias -> data/bias
I0630 02:09:40.570377 29777 net.cpp:148] Setting up data/bias
I0630 02:09:40.570389 29777 net.cpp:155] Top shape: 42 3 224 224 (6322176)
I0630 02:09:40.570391 29777 net.cpp:163] Memory required for data: 50577576
I0630 02:09:40.570402 29777 layer_factory.hpp:77] Creating layer conv1a
I0630 02:09:40.570416 29777 net.cpp:98] Creating Layer conv1a
I0630 02:09:40.570420 29777 net.cpp:439] conv1a <- data/bias
I0630 02:09:40.570425 29777 net.cpp:413] conv1a -> conv1a
I0630 02:09:40.573179 29807 blocking_queue.cpp:50] Waiting for data
I0630 02:09:40.574221 29777 net.cpp:148] Setting up conv1a
I0630 02:09:40.574234 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.574239 29777 net.cpp:163] Memory required for data: 118014120
I0630 02:09:40.574249 29777 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 02:09:40.574257 29777 net.cpp:98] Creating Layer conv1a/bn
I0630 02:09:40.574261 29777 net.cpp:439] conv1a/bn <- conv1a
I0630 02:09:40.574268 29777 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 02:09:40.575001 29777 net.cpp:148] Setting up conv1a/bn
I0630 02:09:40.575007 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.575009 29777 net.cpp:163] Memory required for data: 185450664
I0630 02:09:40.575018 29777 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 02:09:40.575022 29777 net.cpp:98] Creating Layer conv1a/relu
I0630 02:09:40.575024 29777 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 02:09:40.575027 29777 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 02:09:40.575037 29777 net.cpp:148] Setting up conv1a/relu
I0630 02:09:40.575040 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.575050 29777 net.cpp:163] Memory required for data: 252887208
I0630 02:09:40.575052 29777 layer_factory.hpp:77] Creating layer conv1b
I0630 02:09:40.575057 29777 net.cpp:98] Creating Layer conv1b
I0630 02:09:40.575060 29777 net.cpp:439] conv1b <- conv1a/bn
I0630 02:09:40.575063 29777 net.cpp:413] conv1b -> conv1b
I0630 02:09:40.575395 29777 net.cpp:148] Setting up conv1b
I0630 02:09:40.575402 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.575403 29777 net.cpp:163] Memory required for data: 320323752
I0630 02:09:40.575407 29777 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 02:09:40.575412 29777 net.cpp:98] Creating Layer conv1b/bn
I0630 02:09:40.575413 29777 net.cpp:439] conv1b/bn <- conv1b
I0630 02:09:40.575417 29777 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 02:09:40.576089 29777 net.cpp:148] Setting up conv1b/bn
I0630 02:09:40.576095 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.576097 29777 net.cpp:163] Memory required for data: 387760296
I0630 02:09:40.576103 29777 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 02:09:40.576107 29777 net.cpp:98] Creating Layer conv1b/relu
I0630 02:09:40.576108 29777 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 02:09:40.576110 29777 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 02:09:40.576114 29777 net.cpp:148] Setting up conv1b/relu
I0630 02:09:40.576117 29777 net.cpp:155] Top shape: 42 32 112 112 (16859136)
I0630 02:09:40.576118 29777 net.cpp:163] Memory required for data: 455196840
I0630 02:09:40.576120 29777 layer_factory.hpp:77] Creating layer pool1
I0630 02:09:40.576125 29777 net.cpp:98] Creating Layer pool1
I0630 02:09:40.576128 29777 net.cpp:439] pool1 <- conv1b/bn
I0630 02:09:40.576131 29777 net.cpp:413] pool1 -> pool1
I0630 02:09:40.576176 29777 net.cpp:148] Setting up pool1
I0630 02:09:40.576181 29777 net.cpp:155] Top shape: 42 32 56 56 (4214784)
I0630 02:09:40.576184 29777 net.cpp:163] Memory required for data: 472055976
I0630 02:09:40.576185 29777 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 02:09:40.576189 29777 net.cpp:98] Creating Layer res2a_branch2a
I0630 02:09:40.576191 29777 net.cpp:439] res2a_branch2a <- pool1
I0630 02:09:40.576194 29777 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 02:09:40.576836 29777 net.cpp:148] Setting up res2a_branch2a
I0630 02:09:40.576843 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.576844 29777 net.cpp:163] Memory required for data: 505774248
I0630 02:09:40.576848 29777 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 02:09:40.576853 29777 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 02:09:40.576854 29777 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 02:09:40.576858 29777 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 02:09:40.577534 29777 net.cpp:148] Setting up res2a_branch2a/bn
I0630 02:09:40.577540 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.577543 29777 net.cpp:163] Memory required for data: 539492520
I0630 02:09:40.577548 29777 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 02:09:40.577550 29777 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 02:09:40.577553 29777 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 02:09:40.577554 29777 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 02:09:40.577558 29777 net.cpp:148] Setting up res2a_branch2a/relu
I0630 02:09:40.577560 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.577561 29777 net.cpp:163] Memory required for data: 573210792
I0630 02:09:40.577564 29777 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 02:09:40.577571 29777 net.cpp:98] Creating Layer res2a_branch2b
I0630 02:09:40.577575 29777 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 02:09:40.577579 29777 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 02:09:40.578040 29777 net.cpp:148] Setting up res2a_branch2b
I0630 02:09:40.578045 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.578053 29777 net.cpp:163] Memory required for data: 606929064
I0630 02:09:40.578058 29777 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 02:09:40.578061 29777 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 02:09:40.578063 29777 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 02:09:40.578065 29777 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 02:09:40.578747 29777 net.cpp:148] Setting up res2a_branch2b/bn
I0630 02:09:40.578752 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.578754 29777 net.cpp:163] Memory required for data: 640647336
I0630 02:09:40.578759 29777 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 02:09:40.578763 29777 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 02:09:40.578764 29777 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 02:09:40.578766 29777 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 02:09:40.578773 29777 net.cpp:148] Setting up res2a_branch2b/relu
I0630 02:09:40.578774 29777 net.cpp:155] Top shape: 42 64 56 56 (8429568)
I0630 02:09:40.578776 29777 net.cpp:163] Memory required for data: 674365608
I0630 02:09:40.578778 29777 layer_factory.hpp:77] Creating layer pool2
I0630 02:09:40.578781 29777 net.cpp:98] Creating Layer pool2
I0630 02:09:40.578783 29777 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 02:09:40.578785 29777 net.cpp:413] pool2 -> pool2
I0630 02:09:40.578824 29777 net.cpp:148] Setting up pool2
I0630 02:09:40.578829 29777 net.cpp:155] Top shape: 42 64 28 28 (2107392)
I0630 02:09:40.578830 29777 net.cpp:163] Memory required for data: 682795176
I0630 02:09:40.578835 29777 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 02:09:40.578846 29777 net.cpp:98] Creating Layer res3a_branch2a
I0630 02:09:40.578851 29777 net.cpp:439] res3a_branch2a <- pool2
I0630 02:09:40.578855 29777 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 02:09:40.582299 29777 net.cpp:148] Setting up res3a_branch2a
I0630 02:09:40.582315 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.582317 29777 net.cpp:163] Memory required for data: 699654312
I0630 02:09:40.582322 29777 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 02:09:40.582329 29777 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 02:09:40.582332 29777 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 02:09:40.582335 29777 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 02:09:40.582988 29777 net.cpp:148] Setting up res3a_branch2a/bn
I0630 02:09:40.582995 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.582998 29777 net.cpp:163] Memory required for data: 716513448
I0630 02:09:40.583004 29777 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 02:09:40.583009 29777 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 02:09:40.583010 29777 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 02:09:40.583019 29777 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 02:09:40.583021 29777 net.cpp:148] Setting up res3a_branch2a/relu
I0630 02:09:40.583024 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.583025 29777 net.cpp:163] Memory required for data: 733372584
I0630 02:09:40.583029 29777 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 02:09:40.583034 29777 net.cpp:98] Creating Layer res3a_branch2b
I0630 02:09:40.583036 29777 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 02:09:40.583039 29777 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 02:09:40.584044 29777 net.cpp:148] Setting up res3a_branch2b
I0630 02:09:40.584050 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.584053 29777 net.cpp:163] Memory required for data: 750231720
I0630 02:09:40.584055 29777 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 02:09:40.584059 29777 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 02:09:40.584061 29777 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 02:09:40.584064 29777 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 02:09:40.584702 29777 net.cpp:148] Setting up res3a_branch2b/bn
I0630 02:09:40.584714 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.584717 29777 net.cpp:163] Memory required for data: 767090856
I0630 02:09:40.584722 29777 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 02:09:40.584725 29777 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 02:09:40.584728 29777 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 02:09:40.584731 29777 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 02:09:40.584735 29777 net.cpp:148] Setting up res3a_branch2b/relu
I0630 02:09:40.584738 29777 net.cpp:155] Top shape: 42 128 28 28 (4214784)
I0630 02:09:40.584740 29777 net.cpp:163] Memory required for data: 783949992
I0630 02:09:40.584743 29777 layer_factory.hpp:77] Creating layer pool3
I0630 02:09:40.584746 29777 net.cpp:98] Creating Layer pool3
I0630 02:09:40.584749 29777 net.cpp:439] pool3 <- res3a_branch2b/bn
I0630 02:09:40.584753 29777 net.cpp:413] pool3 -> pool3
I0630 02:09:40.584800 29777 net.cpp:148] Setting up pool3
I0630 02:09:40.584805 29777 net.cpp:155] Top shape: 42 128 14 14 (1053696)
I0630 02:09:40.584806 29777 net.cpp:163] Memory required for data: 788164776
I0630 02:09:40.584808 29777 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 02:09:40.584812 29777 net.cpp:98] Creating Layer res4a_branch2a
I0630 02:09:40.584815 29777 net.cpp:439] res4a_branch2a <- pool3
I0630 02:09:40.584817 29777 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 02:09:40.591033 29777 net.cpp:148] Setting up res4a_branch2a
I0630 02:09:40.591045 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.591048 29777 net.cpp:163] Memory required for data: 796594344
I0630 02:09:40.591051 29777 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 02:09:40.591056 29777 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 02:09:40.591058 29777 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 02:09:40.591061 29777 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 02:09:40.591742 29777 net.cpp:148] Setting up res4a_branch2a/bn
I0630 02:09:40.591747 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.591750 29777 net.cpp:163] Memory required for data: 805023912
I0630 02:09:40.591755 29777 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 02:09:40.591758 29777 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 02:09:40.591760 29777 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 02:09:40.591763 29777 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 02:09:40.591766 29777 net.cpp:148] Setting up res4a_branch2a/relu
I0630 02:09:40.591769 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.591771 29777 net.cpp:163] Memory required for data: 813453480
I0630 02:09:40.591773 29777 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 02:09:40.591776 29777 net.cpp:98] Creating Layer res4a_branch2b
I0630 02:09:40.591778 29777 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 02:09:40.591781 29777 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 02:09:40.594979 29777 net.cpp:148] Setting up res4a_branch2b
I0630 02:09:40.594985 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.594987 29777 net.cpp:163] Memory required for data: 821883048
I0630 02:09:40.594990 29777 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 02:09:40.594995 29777 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 02:09:40.594996 29777 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 02:09:40.595000 29777 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 02:09:40.595646 29777 net.cpp:148] Setting up res4a_branch2b/bn
I0630 02:09:40.595652 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.595654 29777 net.cpp:163] Memory required for data: 830312616
I0630 02:09:40.595659 29777 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 02:09:40.595662 29777 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 02:09:40.595664 29777 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 02:09:40.595674 29777 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 02:09:40.595679 29777 net.cpp:148] Setting up res4a_branch2b/relu
I0630 02:09:40.595680 29777 net.cpp:155] Top shape: 42 256 14 14 (2107392)
I0630 02:09:40.595682 29777 net.cpp:163] Memory required for data: 838742184
I0630 02:09:40.595685 29777 layer_factory.hpp:77] Creating layer pool4
I0630 02:09:40.595687 29777 net.cpp:98] Creating Layer pool4
I0630 02:09:40.595690 29777 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 02:09:40.595693 29777 net.cpp:413] pool4 -> pool4
I0630 02:09:40.595736 29777 net.cpp:148] Setting up pool4
I0630 02:09:40.595742 29777 net.cpp:155] Top shape: 42 256 7 7 (526848)
I0630 02:09:40.595744 29777 net.cpp:163] Memory required for data: 840849576
I0630 02:09:40.595746 29777 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 02:09:40.595751 29777 net.cpp:98] Creating Layer res5a_branch2a
I0630 02:09:40.595752 29777 net.cpp:439] res5a_branch2a <- pool4
I0630 02:09:40.595755 29777 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 02:09:40.620772 29777 net.cpp:148] Setting up res5a_branch2a
I0630 02:09:40.620793 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.620795 29777 net.cpp:163] Memory required for data: 845064360
I0630 02:09:40.620801 29777 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 02:09:40.620810 29777 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 02:09:40.620812 29777 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 02:09:40.620816 29777 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 02:09:40.621500 29777 net.cpp:148] Setting up res5a_branch2a/bn
I0630 02:09:40.621506 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.621508 29777 net.cpp:163] Memory required for data: 849279144
I0630 02:09:40.621513 29777 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 02:09:40.621517 29777 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 02:09:40.621520 29777 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 02:09:40.621522 29777 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 02:09:40.621526 29777 net.cpp:148] Setting up res5a_branch2a/relu
I0630 02:09:40.621529 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.621531 29777 net.cpp:163] Memory required for data: 853493928
I0630 02:09:40.621532 29777 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 02:09:40.621537 29777 net.cpp:98] Creating Layer res5a_branch2b
I0630 02:09:40.621539 29777 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 02:09:40.621541 29777 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 02:09:40.634639 29777 net.cpp:148] Setting up res5a_branch2b
I0630 02:09:40.634660 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.634663 29777 net.cpp:163] Memory required for data: 857708712
I0630 02:09:40.634676 29777 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 02:09:40.634685 29777 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 02:09:40.634688 29777 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 02:09:40.634692 29777 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 02:09:40.635387 29777 net.cpp:148] Setting up res5a_branch2b/bn
I0630 02:09:40.635395 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.635396 29777 net.cpp:163] Memory required for data: 861923496
I0630 02:09:40.635401 29777 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 02:09:40.635406 29777 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 02:09:40.635407 29777 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 02:09:40.635409 29777 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 02:09:40.635413 29777 net.cpp:148] Setting up res5a_branch2b/relu
I0630 02:09:40.635416 29777 net.cpp:155] Top shape: 42 512 7 7 (1053696)
I0630 02:09:40.635418 29777 net.cpp:163] Memory required for data: 866138280
I0630 02:09:40.635421 29777 layer_factory.hpp:77] Creating layer pool5
I0630 02:09:40.635426 29777 net.cpp:98] Creating Layer pool5
I0630 02:09:40.635438 29777 net.cpp:439] pool5 <- res5a_branch2b/bn
I0630 02:09:40.635442 29777 net.cpp:413] pool5 -> pool5
I0630 02:09:40.635471 29777 net.cpp:148] Setting up pool5
I0630 02:09:40.635476 29777 net.cpp:155] Top shape: 42 512 1 1 (21504)
I0630 02:09:40.635478 29777 net.cpp:163] Memory required for data: 866224296
I0630 02:09:40.635480 29777 layer_factory.hpp:77] Creating layer fc1000
I0630 02:09:40.635483 29777 net.cpp:98] Creating Layer fc1000
I0630 02:09:40.635486 29777 net.cpp:439] fc1000 <- pool5
I0630 02:09:40.635489 29777 net.cpp:413] fc1000 -> fc1000
I0630 02:09:40.646884 29777 net.cpp:148] Setting up fc1000
I0630 02:09:40.646904 29777 net.cpp:155] Top shape: 42 1000 (42000)
I0630 02:09:40.646906 29777 net.cpp:163] Memory required for data: 866392296
I0630 02:09:40.646914 29777 layer_factory.hpp:77] Creating layer loss
I0630 02:09:40.646924 29777 net.cpp:98] Creating Layer loss
I0630 02:09:40.646927 29777 net.cpp:439] loss <- fc1000
I0630 02:09:40.646930 29777 net.cpp:439] loss <- label
I0630 02:09:40.646935 29777 net.cpp:413] loss -> loss
I0630 02:09:40.646944 29777 layer_factory.hpp:77] Creating layer loss
I0630 02:09:40.647111 29777 net.cpp:148] Setting up loss
I0630 02:09:40.647119 29777 net.cpp:155] Top shape: (1)
I0630 02:09:40.647120 29777 net.cpp:158]     with loss weight 1
I0630 02:09:40.647130 29777 net.cpp:163] Memory required for data: 866392300
I0630 02:09:40.647133 29777 net.cpp:224] loss needs backward computation.
I0630 02:09:40.647135 29777 net.cpp:224] fc1000 needs backward computation.
I0630 02:09:40.647137 29777 net.cpp:224] pool5 needs backward computation.
I0630 02:09:40.647140 29777 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 02:09:40.647141 29777 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 02:09:40.647143 29777 net.cpp:224] res5a_branch2b needs backward computation.
I0630 02:09:40.647145 29777 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 02:09:40.647146 29777 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 02:09:40.647150 29777 net.cpp:224] res5a_branch2a needs backward computation.
I0630 02:09:40.647151 29777 net.cpp:224] pool4 needs backward computation.
I0630 02:09:40.647155 29777 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 02:09:40.647156 29777 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 02:09:40.647158 29777 net.cpp:224] res4a_branch2b needs backward computation.
I0630 02:09:40.647161 29777 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 02:09:40.647163 29777 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 02:09:40.647166 29777 net.cpp:224] res4a_branch2a needs backward computation.
I0630 02:09:40.647168 29777 net.cpp:224] pool3 needs backward computation.
I0630 02:09:40.647171 29777 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 02:09:40.647173 29777 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 02:09:40.647176 29777 net.cpp:224] res3a_branch2b needs backward computation.
I0630 02:09:40.647178 29777 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 02:09:40.647181 29777 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 02:09:40.647184 29777 net.cpp:224] res3a_branch2a needs backward computation.
I0630 02:09:40.647188 29777 net.cpp:224] pool2 needs backward computation.
I0630 02:09:40.647192 29777 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 02:09:40.647195 29777 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 02:09:40.647199 29777 net.cpp:224] res2a_branch2b needs backward computation.
I0630 02:09:40.647213 29777 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 02:09:40.647217 29777 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 02:09:40.647219 29777 net.cpp:224] res2a_branch2a needs backward computation.
I0630 02:09:40.647222 29777 net.cpp:224] pool1 needs backward computation.
I0630 02:09:40.647223 29777 net.cpp:224] conv1b/relu needs backward computation.
I0630 02:09:40.647239 29777 net.cpp:224] conv1b/bn needs backward computation.
I0630 02:09:40.647244 29777 net.cpp:224] conv1b needs backward computation.
I0630 02:09:40.647246 29777 net.cpp:224] conv1a/relu needs backward computation.
I0630 02:09:40.647249 29777 net.cpp:224] conv1a/bn needs backward computation.
I0630 02:09:40.647254 29777 net.cpp:224] conv1a needs backward computation.
I0630 02:09:40.647258 29777 net.cpp:226] data/bias does not need backward computation.
I0630 02:09:40.647263 29777 net.cpp:226] data does not need backward computation.
I0630 02:09:40.647265 29777 net.cpp:268] This network produces output loss
I0630 02:09:40.647285 29777 net.cpp:288] Network initialization done.
I0630 02:09:40.647730 29777 solver.cpp:182] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/test.prototxt
I0630 02:09:40.647917 29777 net.cpp:56] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
    threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a/bn"
  top: "conv1a/bn"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a/bn"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b/bn"
  top: "conv1b/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2a/bn"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a/bn"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b/bn"
  top: "res2a_branch2b/bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b/bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2a/bn"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a/bn"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b/bn"
  top: "res3a_branch2b/bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b/bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2a/bn"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a/bn"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b/bn"
  top: "res4a_branch2b/bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b/bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2a/bn"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a/bn"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b/bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b/bn"
  top: "res5a_branch2b/bn"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b/bn"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0630 02:09:40.648015 29777 layer_factory.hpp:77] Creating layer data
I0630 02:09:40.648085 29777 net.cpp:98] Creating Layer data
I0630 02:09:40.648100 29777 net.cpp:413] data -> data
I0630 02:09:40.648113 29777 net.cpp:413] data -> label
I0630 02:09:40.663002 29818 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0630 02:09:40.664290 29777 data_layer.cpp:78] ReshapePrefetch 50, 3, 224, 224
I0630 02:09:40.664379 29777 data_layer.cpp:83] output data size: 50,3,224,224
I0630 02:09:40.695499 29777 net.cpp:148] Setting up data
I0630 02:09:40.695518 29777 net.cpp:155] Top shape: 50 3 224 224 (7526400)
I0630 02:09:40.695523 29777 net.cpp:155] Top shape: 50 (50)
I0630 02:09:40.695524 29777 net.cpp:163] Memory required for data: 30105800
I0630 02:09:40.695528 29777 layer_factory.hpp:77] Creating layer label_data_1_split
I0630 02:09:40.695538 29777 net.cpp:98] Creating Layer label_data_1_split
I0630 02:09:40.695539 29777 net.cpp:439] label_data_1_split <- label
I0630 02:09:40.695544 29777 net.cpp:413] label_data_1_split -> label_data_1_split_0
I0630 02:09:40.695550 29777 net.cpp:413] label_data_1_split -> label_data_1_split_1
I0630 02:09:40.695554 29777 net.cpp:413] label_data_1_split -> label_data_1_split_2
I0630 02:09:40.695716 29777 net.cpp:148] Setting up label_data_1_split
I0630 02:09:40.695726 29777 net.cpp:155] Top shape: 50 (50)
I0630 02:09:40.695729 29777 net.cpp:155] Top shape: 50 (50)
I0630 02:09:40.695731 29777 net.cpp:155] Top shape: 50 (50)
I0630 02:09:40.695734 29777 net.cpp:163] Memory required for data: 30106400
I0630 02:09:40.695735 29777 layer_factory.hpp:77] Creating layer data/bias
I0630 02:09:40.695741 29777 net.cpp:98] Creating Layer data/bias
I0630 02:09:40.695744 29777 net.cpp:439] data/bias <- data
I0630 02:09:40.695755 29777 net.cpp:413] data/bias -> data/bias
I0630 02:09:40.695916 29777 net.cpp:148] Setting up data/bias
I0630 02:09:40.695922 29777 net.cpp:155] Top shape: 50 3 224 224 (7526400)
I0630 02:09:40.695924 29777 net.cpp:163] Memory required for data: 60212000
I0630 02:09:40.695930 29777 layer_factory.hpp:77] Creating layer conv1a
I0630 02:09:40.695935 29777 net.cpp:98] Creating Layer conv1a
I0630 02:09:40.695936 29777 net.cpp:439] conv1a <- data/bias
I0630 02:09:40.695940 29777 net.cpp:413] conv1a -> conv1a
I0630 02:09:40.696461 29777 net.cpp:148] Setting up conv1a
I0630 02:09:40.696468 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.696470 29777 net.cpp:163] Memory required for data: 140493600
I0630 02:09:40.696475 29777 layer_factory.hpp:77] Creating layer conv1a/bn
I0630 02:09:40.696480 29777 net.cpp:98] Creating Layer conv1a/bn
I0630 02:09:40.696482 29777 net.cpp:439] conv1a/bn <- conv1a
I0630 02:09:40.696485 29777 net.cpp:413] conv1a/bn -> conv1a/bn
I0630 02:09:40.699566 29777 net.cpp:148] Setting up conv1a/bn
I0630 02:09:40.699574 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.699586 29777 net.cpp:163] Memory required for data: 220775200
I0630 02:09:40.699596 29777 layer_factory.hpp:77] Creating layer conv1a/relu
I0630 02:09:40.699601 29777 net.cpp:98] Creating Layer conv1a/relu
I0630 02:09:40.699604 29777 net.cpp:439] conv1a/relu <- conv1a/bn
I0630 02:09:40.699606 29777 net.cpp:400] conv1a/relu -> conv1a/bn (in-place)
I0630 02:09:40.699611 29777 net.cpp:148] Setting up conv1a/relu
I0630 02:09:40.699614 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.699615 29777 net.cpp:163] Memory required for data: 301056800
I0630 02:09:40.699617 29777 layer_factory.hpp:77] Creating layer conv1b
I0630 02:09:40.699621 29777 net.cpp:98] Creating Layer conv1b
I0630 02:09:40.699623 29777 net.cpp:439] conv1b <- conv1a/bn
I0630 02:09:40.699626 29777 net.cpp:413] conv1b -> conv1b
I0630 02:09:40.699985 29777 net.cpp:148] Setting up conv1b
I0630 02:09:40.699991 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.699995 29777 net.cpp:163] Memory required for data: 381338400
I0630 02:09:40.699998 29777 layer_factory.hpp:77] Creating layer conv1b/bn
I0630 02:09:40.700002 29777 net.cpp:98] Creating Layer conv1b/bn
I0630 02:09:40.700004 29777 net.cpp:439] conv1b/bn <- conv1b
I0630 02:09:40.700007 29777 net.cpp:413] conv1b/bn -> conv1b/bn
I0630 02:09:40.700743 29777 net.cpp:148] Setting up conv1b/bn
I0630 02:09:40.700750 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.700753 29777 net.cpp:163] Memory required for data: 461620000
I0630 02:09:40.700760 29777 layer_factory.hpp:77] Creating layer conv1b/relu
I0630 02:09:40.700764 29777 net.cpp:98] Creating Layer conv1b/relu
I0630 02:09:40.700767 29777 net.cpp:439] conv1b/relu <- conv1b/bn
I0630 02:09:40.700769 29777 net.cpp:400] conv1b/relu -> conv1b/bn (in-place)
I0630 02:09:40.700773 29777 net.cpp:148] Setting up conv1b/relu
I0630 02:09:40.700776 29777 net.cpp:155] Top shape: 50 32 112 112 (20070400)
I0630 02:09:40.700778 29777 net.cpp:163] Memory required for data: 541901600
I0630 02:09:40.700781 29777 layer_factory.hpp:77] Creating layer pool1
I0630 02:09:40.700785 29777 net.cpp:98] Creating Layer pool1
I0630 02:09:40.700788 29777 net.cpp:439] pool1 <- conv1b/bn
I0630 02:09:40.700789 29777 net.cpp:413] pool1 -> pool1
I0630 02:09:40.700826 29777 net.cpp:148] Setting up pool1
I0630 02:09:40.700831 29777 net.cpp:155] Top shape: 50 32 56 56 (5017600)
I0630 02:09:40.700834 29777 net.cpp:163] Memory required for data: 561972000
I0630 02:09:40.700835 29777 layer_factory.hpp:77] Creating layer res2a_branch2a
I0630 02:09:40.700847 29777 net.cpp:98] Creating Layer res2a_branch2a
I0630 02:09:40.700852 29777 net.cpp:439] res2a_branch2a <- pool1
I0630 02:09:40.700857 29777 net.cpp:413] res2a_branch2a -> res2a_branch2a
I0630 02:09:40.701581 29777 net.cpp:148] Setting up res2a_branch2a
I0630 02:09:40.701587 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.701591 29777 net.cpp:163] Memory required for data: 602112800
I0630 02:09:40.701596 29777 layer_factory.hpp:77] Creating layer res2a_branch2a/bn
I0630 02:09:40.701599 29777 net.cpp:98] Creating Layer res2a_branch2a/bn
I0630 02:09:40.701602 29777 net.cpp:439] res2a_branch2a/bn <- res2a_branch2a
I0630 02:09:40.701606 29777 net.cpp:413] res2a_branch2a/bn -> res2a_branch2a/bn
I0630 02:09:40.702350 29777 net.cpp:148] Setting up res2a_branch2a/bn
I0630 02:09:40.702356 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.702359 29777 net.cpp:163] Memory required for data: 642253600
I0630 02:09:40.702364 29777 layer_factory.hpp:77] Creating layer res2a_branch2a/relu
I0630 02:09:40.702368 29777 net.cpp:98] Creating Layer res2a_branch2a/relu
I0630 02:09:40.702370 29777 net.cpp:439] res2a_branch2a/relu <- res2a_branch2a/bn
I0630 02:09:40.702373 29777 net.cpp:400] res2a_branch2a/relu -> res2a_branch2a/bn (in-place)
I0630 02:09:40.702378 29777 net.cpp:148] Setting up res2a_branch2a/relu
I0630 02:09:40.702379 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.702381 29777 net.cpp:163] Memory required for data: 682394400
I0630 02:09:40.702390 29777 layer_factory.hpp:77] Creating layer res2a_branch2b
I0630 02:09:40.702395 29777 net.cpp:98] Creating Layer res2a_branch2b
I0630 02:09:40.702397 29777 net.cpp:439] res2a_branch2b <- res2a_branch2a/bn
I0630 02:09:40.702400 29777 net.cpp:413] res2a_branch2b -> res2a_branch2b
I0630 02:09:40.702908 29777 net.cpp:148] Setting up res2a_branch2b
I0630 02:09:40.702915 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.702919 29777 net.cpp:163] Memory required for data: 722535200
I0630 02:09:40.702922 29777 layer_factory.hpp:77] Creating layer res2a_branch2b/bn
I0630 02:09:40.702926 29777 net.cpp:98] Creating Layer res2a_branch2b/bn
I0630 02:09:40.702929 29777 net.cpp:439] res2a_branch2b/bn <- res2a_branch2b
I0630 02:09:40.702932 29777 net.cpp:413] res2a_branch2b/bn -> res2a_branch2b/bn
I0630 02:09:40.703675 29777 net.cpp:148] Setting up res2a_branch2b/bn
I0630 02:09:40.703681 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.703685 29777 net.cpp:163] Memory required for data: 762676000
I0630 02:09:40.703689 29777 layer_factory.hpp:77] Creating layer res2a_branch2b/relu
I0630 02:09:40.703692 29777 net.cpp:98] Creating Layer res2a_branch2b/relu
I0630 02:09:40.703696 29777 net.cpp:439] res2a_branch2b/relu <- res2a_branch2b/bn
I0630 02:09:40.703698 29777 net.cpp:400] res2a_branch2b/relu -> res2a_branch2b/bn (in-place)
I0630 02:09:40.703701 29777 net.cpp:148] Setting up res2a_branch2b/relu
I0630 02:09:40.703704 29777 net.cpp:155] Top shape: 50 64 56 56 (10035200)
I0630 02:09:40.703707 29777 net.cpp:163] Memory required for data: 802816800
I0630 02:09:40.703709 29777 layer_factory.hpp:77] Creating layer pool2
I0630 02:09:40.703712 29777 net.cpp:98] Creating Layer pool2
I0630 02:09:40.703716 29777 net.cpp:439] pool2 <- res2a_branch2b/bn
I0630 02:09:40.703717 29777 net.cpp:413] pool2 -> pool2
I0630 02:09:40.703757 29777 net.cpp:148] Setting up pool2
I0630 02:09:40.703760 29777 net.cpp:155] Top shape: 50 64 28 28 (2508800)
I0630 02:09:40.703763 29777 net.cpp:163] Memory required for data: 812852000
I0630 02:09:40.703765 29777 layer_factory.hpp:77] Creating layer res3a_branch2a
I0630 02:09:40.703769 29777 net.cpp:98] Creating Layer res3a_branch2a
I0630 02:09:40.703771 29777 net.cpp:439] res3a_branch2a <- pool2
I0630 02:09:40.703775 29777 net.cpp:413] res3a_branch2a -> res3a_branch2a
I0630 02:09:40.706461 29777 net.cpp:148] Setting up res3a_branch2a
I0630 02:09:40.706470 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.706472 29777 net.cpp:163] Memory required for data: 832922400
I0630 02:09:40.706477 29777 layer_factory.hpp:77] Creating layer res3a_branch2a/bn
I0630 02:09:40.706481 29777 net.cpp:98] Creating Layer res3a_branch2a/bn
I0630 02:09:40.706485 29777 net.cpp:439] res3a_branch2a/bn <- res3a_branch2a
I0630 02:09:40.706488 29777 net.cpp:413] res3a_branch2a/bn -> res3a_branch2a/bn
I0630 02:09:40.707192 29777 net.cpp:148] Setting up res3a_branch2a/bn
I0630 02:09:40.707200 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.707201 29777 net.cpp:163] Memory required for data: 852992800
I0630 02:09:40.707208 29777 layer_factory.hpp:77] Creating layer res3a_branch2a/relu
I0630 02:09:40.707214 29777 net.cpp:98] Creating Layer res3a_branch2a/relu
I0630 02:09:40.707216 29777 net.cpp:439] res3a_branch2a/relu <- res3a_branch2a/bn
I0630 02:09:40.707219 29777 net.cpp:400] res3a_branch2a/relu -> res3a_branch2a/bn (in-place)
I0630 02:09:40.707222 29777 net.cpp:148] Setting up res3a_branch2a/relu
I0630 02:09:40.707226 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.707227 29777 net.cpp:163] Memory required for data: 873063200
I0630 02:09:40.707229 29777 layer_factory.hpp:77] Creating layer res3a_branch2b
I0630 02:09:40.707233 29777 net.cpp:98] Creating Layer res3a_branch2b
I0630 02:09:40.707235 29777 net.cpp:439] res3a_branch2b <- res3a_branch2a/bn
I0630 02:09:40.707238 29777 net.cpp:413] res3a_branch2b -> res3a_branch2b
I0630 02:09:40.708278 29777 net.cpp:148] Setting up res3a_branch2b
I0630 02:09:40.708294 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.708297 29777 net.cpp:163] Memory required for data: 893133600
I0630 02:09:40.708299 29777 layer_factory.hpp:77] Creating layer res3a_branch2b/bn
I0630 02:09:40.708304 29777 net.cpp:98] Creating Layer res3a_branch2b/bn
I0630 02:09:40.708307 29777 net.cpp:439] res3a_branch2b/bn <- res3a_branch2b
I0630 02:09:40.708310 29777 net.cpp:413] res3a_branch2b/bn -> res3a_branch2b/bn
I0630 02:09:40.708988 29777 net.cpp:148] Setting up res3a_branch2b/bn
I0630 02:09:40.708994 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.708997 29777 net.cpp:163] Memory required for data: 913204000
I0630 02:09:40.709002 29777 layer_factory.hpp:77] Creating layer res3a_branch2b/relu
I0630 02:09:40.709008 29777 net.cpp:98] Creating Layer res3a_branch2b/relu
I0630 02:09:40.709010 29777 net.cpp:439] res3a_branch2b/relu <- res3a_branch2b/bn
I0630 02:09:40.709012 29777 net.cpp:400] res3a_branch2b/relu -> res3a_branch2b/bn (in-place)
I0630 02:09:40.709017 29777 net.cpp:148] Setting up res3a_branch2b/relu
I0630 02:09:40.709018 29777 net.cpp:155] Top shape: 50 128 28 28 (5017600)
I0630 02:09:40.709020 29777 net.cpp:163] Memory required for data: 933274400
I0630 02:09:40.709022 29777 layer_factory.hpp:77] Creating layer pool3
I0630 02:09:40.709025 29777 net.cpp:98] Creating Layer pool3
I0630 02:09:40.709028 29777 net.cpp:439] pool3 <- res3a_branch2b/bn
I0630 02:09:40.709033 29777 net.cpp:413] pool3 -> pool3
I0630 02:09:40.709074 29777 net.cpp:148] Setting up pool3
I0630 02:09:40.709077 29777 net.cpp:155] Top shape: 50 128 14 14 (1254400)
I0630 02:09:40.709079 29777 net.cpp:163] Memory required for data: 938292000
I0630 02:09:40.709081 29777 layer_factory.hpp:77] Creating layer res4a_branch2a
I0630 02:09:40.709086 29777 net.cpp:98] Creating Layer res4a_branch2a
I0630 02:09:40.709089 29777 net.cpp:439] res4a_branch2a <- pool3
I0630 02:09:40.709091 29777 net.cpp:413] res4a_branch2a -> res4a_branch2a
I0630 02:09:40.715198 29777 net.cpp:148] Setting up res4a_branch2a
I0630 02:09:40.715204 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.715207 29777 net.cpp:163] Memory required for data: 948327200
I0630 02:09:40.715211 29777 layer_factory.hpp:77] Creating layer res4a_branch2a/bn
I0630 02:09:40.715215 29777 net.cpp:98] Creating Layer res4a_branch2a/bn
I0630 02:09:40.715217 29777 net.cpp:439] res4a_branch2a/bn <- res4a_branch2a
I0630 02:09:40.715221 29777 net.cpp:413] res4a_branch2a/bn -> res4a_branch2a/bn
I0630 02:09:40.715937 29777 net.cpp:148] Setting up res4a_branch2a/bn
I0630 02:09:40.715945 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.715947 29777 net.cpp:163] Memory required for data: 958362400
I0630 02:09:40.715952 29777 layer_factory.hpp:77] Creating layer res4a_branch2a/relu
I0630 02:09:40.715955 29777 net.cpp:98] Creating Layer res4a_branch2a/relu
I0630 02:09:40.715957 29777 net.cpp:439] res4a_branch2a/relu <- res4a_branch2a/bn
I0630 02:09:40.715960 29777 net.cpp:400] res4a_branch2a/relu -> res4a_branch2a/bn (in-place)
I0630 02:09:40.715963 29777 net.cpp:148] Setting up res4a_branch2a/relu
I0630 02:09:40.715966 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.715968 29777 net.cpp:163] Memory required for data: 968397600
I0630 02:09:40.715970 29777 layer_factory.hpp:77] Creating layer res4a_branch2b
I0630 02:09:40.715975 29777 net.cpp:98] Creating Layer res4a_branch2b
I0630 02:09:40.715976 29777 net.cpp:439] res4a_branch2b <- res4a_branch2a/bn
I0630 02:09:40.715979 29777 net.cpp:413] res4a_branch2b -> res4a_branch2b
I0630 02:09:40.719264 29777 net.cpp:148] Setting up res4a_branch2b
I0630 02:09:40.719274 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.719277 29777 net.cpp:163] Memory required for data: 978432800
I0630 02:09:40.719283 29777 layer_factory.hpp:77] Creating layer res4a_branch2b/bn
I0630 02:09:40.719288 29777 net.cpp:98] Creating Layer res4a_branch2b/bn
I0630 02:09:40.719292 29777 net.cpp:439] res4a_branch2b/bn <- res4a_branch2b
I0630 02:09:40.719296 29777 net.cpp:413] res4a_branch2b/bn -> res4a_branch2b/bn
I0630 02:09:40.720229 29777 net.cpp:148] Setting up res4a_branch2b/bn
I0630 02:09:40.720240 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.720243 29777 net.cpp:163] Memory required for data: 988468000
I0630 02:09:40.720249 29777 layer_factory.hpp:77] Creating layer res4a_branch2b/relu
I0630 02:09:40.720254 29777 net.cpp:98] Creating Layer res4a_branch2b/relu
I0630 02:09:40.720257 29777 net.cpp:439] res4a_branch2b/relu <- res4a_branch2b/bn
I0630 02:09:40.720260 29777 net.cpp:400] res4a_branch2b/relu -> res4a_branch2b/bn (in-place)
I0630 02:09:40.720264 29777 net.cpp:148] Setting up res4a_branch2b/relu
I0630 02:09:40.720268 29777 net.cpp:155] Top shape: 50 256 14 14 (2508800)
I0630 02:09:40.720269 29777 net.cpp:163] Memory required for data: 998503200
I0630 02:09:40.720270 29777 layer_factory.hpp:77] Creating layer pool4
I0630 02:09:40.720274 29777 net.cpp:98] Creating Layer pool4
I0630 02:09:40.720276 29777 net.cpp:439] pool4 <- res4a_branch2b/bn
I0630 02:09:40.720278 29777 net.cpp:413] pool4 -> pool4
I0630 02:09:40.720333 29777 net.cpp:148] Setting up pool4
I0630 02:09:40.720340 29777 net.cpp:155] Top shape: 50 256 7 7 (627200)
I0630 02:09:40.720341 29777 net.cpp:163] Memory required for data: 1001012000
I0630 02:09:40.720343 29777 layer_factory.hpp:77] Creating layer res5a_branch2a
I0630 02:09:40.720350 29777 net.cpp:98] Creating Layer res5a_branch2a
I0630 02:09:40.720352 29777 net.cpp:439] res5a_branch2a <- pool4
I0630 02:09:40.720355 29777 net.cpp:413] res5a_branch2a -> res5a_branch2a
I0630 02:09:40.745447 29777 net.cpp:148] Setting up res5a_branch2a
I0630 02:09:40.745470 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.745472 29777 net.cpp:163] Memory required for data: 1006029600
I0630 02:09:40.745477 29777 layer_factory.hpp:77] Creating layer res5a_branch2a/bn
I0630 02:09:40.745487 29777 net.cpp:98] Creating Layer res5a_branch2a/bn
I0630 02:09:40.745491 29777 net.cpp:439] res5a_branch2a/bn <- res5a_branch2a
I0630 02:09:40.745496 29777 net.cpp:413] res5a_branch2a/bn -> res5a_branch2a/bn
I0630 02:09:40.746234 29777 net.cpp:148] Setting up res5a_branch2a/bn
I0630 02:09:40.746242 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.746243 29777 net.cpp:163] Memory required for data: 1011047200
I0630 02:09:40.746249 29777 layer_factory.hpp:77] Creating layer res5a_branch2a/relu
I0630 02:09:40.746258 29777 net.cpp:98] Creating Layer res5a_branch2a/relu
I0630 02:09:40.746260 29777 net.cpp:439] res5a_branch2a/relu <- res5a_branch2a/bn
I0630 02:09:40.746263 29777 net.cpp:400] res5a_branch2a/relu -> res5a_branch2a/bn (in-place)
I0630 02:09:40.746268 29777 net.cpp:148] Setting up res5a_branch2a/relu
I0630 02:09:40.746271 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.746274 29777 net.cpp:163] Memory required for data: 1016064800
I0630 02:09:40.746276 29777 layer_factory.hpp:77] Creating layer res5a_branch2b
I0630 02:09:40.746282 29777 net.cpp:98] Creating Layer res5a_branch2b
I0630 02:09:40.746284 29777 net.cpp:439] res5a_branch2b <- res5a_branch2a/bn
I0630 02:09:40.746287 29777 net.cpp:413] res5a_branch2b -> res5a_branch2b
I0630 02:09:40.759701 29777 net.cpp:148] Setting up res5a_branch2b
I0630 02:09:40.759719 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.759722 29777 net.cpp:163] Memory required for data: 1021082400
I0630 02:09:40.759729 29777 layer_factory.hpp:77] Creating layer res5a_branch2b/bn
I0630 02:09:40.759737 29777 net.cpp:98] Creating Layer res5a_branch2b/bn
I0630 02:09:40.759739 29777 net.cpp:439] res5a_branch2b/bn <- res5a_branch2b
I0630 02:09:40.759743 29777 net.cpp:413] res5a_branch2b/bn -> res5a_branch2b/bn
I0630 02:09:40.760496 29777 net.cpp:148] Setting up res5a_branch2b/bn
I0630 02:09:40.760504 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.760505 29777 net.cpp:163] Memory required for data: 1026100000
I0630 02:09:40.760511 29777 layer_factory.hpp:77] Creating layer res5a_branch2b/relu
I0630 02:09:40.760515 29777 net.cpp:98] Creating Layer res5a_branch2b/relu
I0630 02:09:40.760527 29777 net.cpp:439] res5a_branch2b/relu <- res5a_branch2b/bn
I0630 02:09:40.760530 29777 net.cpp:400] res5a_branch2b/relu -> res5a_branch2b/bn (in-place)
I0630 02:09:40.760535 29777 net.cpp:148] Setting up res5a_branch2b/relu
I0630 02:09:40.760537 29777 net.cpp:155] Top shape: 50 512 7 7 (1254400)
I0630 02:09:40.760540 29777 net.cpp:163] Memory required for data: 1031117600
I0630 02:09:40.760541 29777 layer_factory.hpp:77] Creating layer pool5
I0630 02:09:40.760546 29777 net.cpp:98] Creating Layer pool5
I0630 02:09:40.760548 29777 net.cpp:439] pool5 <- res5a_branch2b/bn
I0630 02:09:40.760551 29777 net.cpp:413] pool5 -> pool5
I0630 02:09:40.760576 29777 net.cpp:148] Setting up pool5
I0630 02:09:40.760581 29777 net.cpp:155] Top shape: 50 512 1 1 (25600)
I0630 02:09:40.760582 29777 net.cpp:163] Memory required for data: 1031220000
I0630 02:09:40.760584 29777 layer_factory.hpp:77] Creating layer fc1000
I0630 02:09:40.760587 29777 net.cpp:98] Creating Layer fc1000
I0630 02:09:40.760589 29777 net.cpp:439] fc1000 <- pool5
I0630 02:09:40.760592 29777 net.cpp:413] fc1000 -> fc1000
I0630 02:09:40.771718 29777 net.cpp:148] Setting up fc1000
I0630 02:09:40.771730 29777 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:09:40.771733 29777 net.cpp:163] Memory required for data: 1031420000
I0630 02:09:40.771737 29777 layer_factory.hpp:77] Creating layer fc1000_fc1000_0_split
I0630 02:09:40.771744 29777 net.cpp:98] Creating Layer fc1000_fc1000_0_split
I0630 02:09:40.771745 29777 net.cpp:439] fc1000_fc1000_0_split <- fc1000
I0630 02:09:40.771749 29777 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0630 02:09:40.771754 29777 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0630 02:09:40.771757 29777 net.cpp:413] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0630 02:09:40.771816 29777 net.cpp:148] Setting up fc1000_fc1000_0_split
I0630 02:09:40.771821 29777 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:09:40.771823 29777 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:09:40.771826 29777 net.cpp:155] Top shape: 50 1000 (50000)
I0630 02:09:40.771826 29777 net.cpp:163] Memory required for data: 1032020000
I0630 02:09:40.771829 29777 layer_factory.hpp:77] Creating layer loss
I0630 02:09:40.771832 29777 net.cpp:98] Creating Layer loss
I0630 02:09:40.771836 29777 net.cpp:439] loss <- fc1000_fc1000_0_split_0
I0630 02:09:40.771837 29777 net.cpp:439] loss <- label_data_1_split_0
I0630 02:09:40.771842 29777 net.cpp:413] loss -> loss
I0630 02:09:40.771845 29777 layer_factory.hpp:77] Creating layer loss
I0630 02:09:40.771991 29777 net.cpp:148] Setting up loss
I0630 02:09:40.771996 29777 net.cpp:155] Top shape: (1)
I0630 02:09:40.771998 29777 net.cpp:158]     with loss weight 1
I0630 02:09:40.772006 29777 net.cpp:163] Memory required for data: 1032020004
I0630 02:09:40.772007 29777 layer_factory.hpp:77] Creating layer accuracy/top1
I0630 02:09:40.772017 29777 net.cpp:98] Creating Layer accuracy/top1
I0630 02:09:40.772019 29777 net.cpp:439] accuracy/top1 <- fc1000_fc1000_0_split_1
I0630 02:09:40.772022 29777 net.cpp:439] accuracy/top1 <- label_data_1_split_1
I0630 02:09:40.772025 29777 net.cpp:413] accuracy/top1 -> accuracy/top1
I0630 02:09:40.772032 29777 net.cpp:148] Setting up accuracy/top1
I0630 02:09:40.772037 29777 net.cpp:155] Top shape: (1)
I0630 02:09:40.772042 29777 net.cpp:163] Memory required for data: 1032020008
I0630 02:09:40.772044 29777 layer_factory.hpp:77] Creating layer accuracy/top5
I0630 02:09:40.772054 29777 net.cpp:98] Creating Layer accuracy/top5
I0630 02:09:40.772058 29777 net.cpp:439] accuracy/top5 <- fc1000_fc1000_0_split_2
I0630 02:09:40.772061 29777 net.cpp:439] accuracy/top5 <- label_data_1_split_2
I0630 02:09:40.772068 29777 net.cpp:413] accuracy/top5 -> accuracy/top5
I0630 02:09:40.772074 29777 net.cpp:148] Setting up accuracy/top5
I0630 02:09:40.772079 29777 net.cpp:155] Top shape: (1)
I0630 02:09:40.772083 29777 net.cpp:163] Memory required for data: 1032020012
I0630 02:09:40.772086 29777 net.cpp:226] accuracy/top5 does not need backward computation.
I0630 02:09:40.772097 29777 net.cpp:226] accuracy/top1 does not need backward computation.
I0630 02:09:40.772101 29777 net.cpp:224] loss needs backward computation.
I0630 02:09:40.772105 29777 net.cpp:224] fc1000_fc1000_0_split needs backward computation.
I0630 02:09:40.772109 29777 net.cpp:224] fc1000 needs backward computation.
I0630 02:09:40.772112 29777 net.cpp:224] pool5 needs backward computation.
I0630 02:09:40.772116 29777 net.cpp:224] res5a_branch2b/relu needs backward computation.
I0630 02:09:40.772119 29777 net.cpp:224] res5a_branch2b/bn needs backward computation.
I0630 02:09:40.772123 29777 net.cpp:224] res5a_branch2b needs backward computation.
I0630 02:09:40.772127 29777 net.cpp:224] res5a_branch2a/relu needs backward computation.
I0630 02:09:40.772131 29777 net.cpp:224] res5a_branch2a/bn needs backward computation.
I0630 02:09:40.772135 29777 net.cpp:224] res5a_branch2a needs backward computation.
I0630 02:09:40.772138 29777 net.cpp:224] pool4 needs backward computation.
I0630 02:09:40.772142 29777 net.cpp:224] res4a_branch2b/relu needs backward computation.
I0630 02:09:40.772146 29777 net.cpp:224] res4a_branch2b/bn needs backward computation.
I0630 02:09:40.772150 29777 net.cpp:224] res4a_branch2b needs backward computation.
I0630 02:09:40.772155 29777 net.cpp:224] res4a_branch2a/relu needs backward computation.
I0630 02:09:40.772158 29777 net.cpp:224] res4a_branch2a/bn needs backward computation.
I0630 02:09:40.772163 29777 net.cpp:224] res4a_branch2a needs backward computation.
I0630 02:09:40.772167 29777 net.cpp:224] pool3 needs backward computation.
I0630 02:09:40.772171 29777 net.cpp:224] res3a_branch2b/relu needs backward computation.
I0630 02:09:40.772176 29777 net.cpp:224] res3a_branch2b/bn needs backward computation.
I0630 02:09:40.772179 29777 net.cpp:224] res3a_branch2b needs backward computation.
I0630 02:09:40.772183 29777 net.cpp:224] res3a_branch2a/relu needs backward computation.
I0630 02:09:40.772187 29777 net.cpp:224] res3a_branch2a/bn needs backward computation.
I0630 02:09:40.772192 29777 net.cpp:224] res3a_branch2a needs backward computation.
I0630 02:09:40.772195 29777 net.cpp:224] pool2 needs backward computation.
I0630 02:09:40.772199 29777 net.cpp:224] res2a_branch2b/relu needs backward computation.
I0630 02:09:40.772203 29777 net.cpp:224] res2a_branch2b/bn needs backward computation.
I0630 02:09:40.772207 29777 net.cpp:224] res2a_branch2b needs backward computation.
I0630 02:09:40.772212 29777 net.cpp:224] res2a_branch2a/relu needs backward computation.
I0630 02:09:40.772215 29777 net.cpp:224] res2a_branch2a/bn needs backward computation.
I0630 02:09:40.772219 29777 net.cpp:224] res2a_branch2a needs backward computation.
I0630 02:09:40.772225 29777 net.cpp:224] pool1 needs backward computation.
I0630 02:09:40.772229 29777 net.cpp:224] conv1b/relu needs backward computation.
I0630 02:09:40.772233 29777 net.cpp:224] conv1b/bn needs backward computation.
I0630 02:09:40.772238 29777 net.cpp:224] conv1b needs backward computation.
I0630 02:09:40.772241 29777 net.cpp:224] conv1a/relu needs backward computation.
I0630 02:09:40.772245 29777 net.cpp:224] conv1a/bn needs backward computation.
I0630 02:09:40.772249 29777 net.cpp:224] conv1a needs backward computation.
I0630 02:09:40.772253 29777 net.cpp:226] data/bias does not need backward computation.
I0630 02:09:40.772258 29777 net.cpp:226] label_data_1_split does not need backward computation.
I0630 02:09:40.772263 29777 net.cpp:226] data does not need backward computation.
I0630 02:09:40.772266 29777 net.cpp:268] This network produces output accuracy/top1
I0630 02:09:40.772270 29777 net.cpp:268] This network produces output accuracy/top5
I0630 02:09:40.772274 29777 net.cpp:268] This network produces output loss
I0630 02:09:40.772300 29777 net.cpp:288] Network initialization done.
I0630 02:09:40.772368 29777 solver.cpp:60] Solver scaffolding done.
I0630 02:09:40.775967 29777 caffe.cpp:145] Finetuning from training/imagenet_jacintonet11v2_2017-06-30_02-08-23/initial/imagenet_jacintonet11v2_iter_100.caffemodel
I0630 02:09:40.815187 29777 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:09:40.815277 29777 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:09:41.308568 29777 data_layer.cpp:78] ReshapePrefetch 42, 3, 224, 224
I0630 02:09:41.308657 29777 data_layer.cpp:83] output data size: 42,3,224,224
I0630 02:09:41.862990 29777 parallel.cpp:334] Starting Optimization
I0630 02:09:41.863044 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:09:41.874382 29777 solver.cpp:413] Solving jacintonet11v2_train
I0630 02:09:41.874397 29777 solver.cpp:414] Learning Rate Policy: poly
I0630 02:09:41.876631 29777 solver.cpp:471] Iteration 0, Testing net (#0)
I0630 02:09:42.012605 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:10:30.786938 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.609159
I0630 02:10:30.787006 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.832002
I0630 02:10:30.787014 29777 solver.cpp:544]     Test net output #2: loss = 1.33232 (* 1 = 1.33232 loss)
I0630 02:10:31.044181 29777 solver.cpp:290] Iteration 0 (0 iter/s, 49.1684s/100 iter), loss = 1.05952
I0630 02:10:31.044205 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:10:31.044214 29777 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0630 02:10:31.058009 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.01
I0630 02:10:31.161880 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:10:47.122442 29777 solver.cpp:290] Iteration 100 (6.21976 iter/s, 16.0778s/100 iter), loss = 1.07143
I0630 02:10:47.122467 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:10:47.122475 29777 sgd_solver.cpp:106] Iteration 100, lr = 0.00999687
I0630 02:11:03.078019 29777 solver.cpp:290] Iteration 200 (6.26759 iter/s, 15.9551s/100 iter), loss = 1.16667
I0630 02:11:03.078119 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 02:11:03.078130 29777 sgd_solver.cpp:106] Iteration 200, lr = 0.00999375
I0630 02:11:19.083906 29777 solver.cpp:290] Iteration 300 (6.24792 iter/s, 16.0053s/100 iter), loss = 1.04762
I0630 02:11:19.083933 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:11:19.083942 29777 sgd_solver.cpp:106] Iteration 300, lr = 0.00999062
I0630 02:11:35.040550 29777 solver.cpp:290] Iteration 400 (6.26717 iter/s, 15.9562s/100 iter), loss = 1.10714
I0630 02:11:35.040596 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 02:11:35.040603 29777 sgd_solver.cpp:106] Iteration 400, lr = 0.0099875
I0630 02:11:50.970609 29777 solver.cpp:290] Iteration 500 (6.27764 iter/s, 15.9296s/100 iter), loss = 0.988095
I0630 02:11:50.970640 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 02:11:50.970650 29777 sgd_solver.cpp:106] Iteration 500, lr = 0.00998437
I0630 02:12:06.887112 29777 solver.cpp:290] Iteration 600 (6.28297 iter/s, 15.916s/100 iter), loss = 0.857143
I0630 02:12:06.887166 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 02:12:06.887173 29777 sgd_solver.cpp:106] Iteration 600, lr = 0.00998125
I0630 02:12:22.887756 29777 solver.cpp:290] Iteration 700 (6.24994 iter/s, 16.0001s/100 iter), loss = 1.28571
I0630 02:12:22.887783 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 02:12:22.887828 29777 sgd_solver.cpp:106] Iteration 700, lr = 0.00997812
I0630 02:12:38.857633 29777 solver.cpp:290] Iteration 800 (6.26197 iter/s, 15.9694s/100 iter), loss = 1.15476
I0630 02:12:38.858592 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:12:38.858604 29777 sgd_solver.cpp:106] Iteration 800, lr = 0.009975
I0630 02:12:54.849405 29777 solver.cpp:290] Iteration 900 (6.25377 iter/s, 15.9904s/100 iter), loss = 0.928571
I0630 02:12:54.849427 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 02:12:54.849436 29777 sgd_solver.cpp:106] Iteration 900, lr = 0.00997187
I0630 02:13:10.719367 29777 solver.cpp:354] Sparsity after update:
I0630 02:13:10.742584 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:13:10.742599 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:13:10.742614 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:13:10.742617 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:13:10.742622 29777 net.cpp:1851] res2a_branch2a_param_0(0.00998) 
I0630 02:13:10.742626 29777 net.cpp:1851] res2a_branch2b_param_0(0.00998) 
I0630 02:13:10.742630 29777 net.cpp:1851] res3a_branch2a_param_0(0.01) 
I0630 02:13:10.742633 29777 net.cpp:1851] res3a_branch2b_param_0(0.00998) 
I0630 02:13:10.742636 29777 net.cpp:1851] res4a_branch2a_param_0(0.00999) 
I0630 02:13:10.742640 29777 net.cpp:1851] res4a_branch2b_param_0(0.00999) 
I0630 02:13:10.742642 29777 net.cpp:1851] res5a_branch2a_param_0(0.01) 
I0630 02:13:10.742645 29777 net.cpp:1851] res5a_branch2b_param_0(0.00997) 
I0630 02:13:10.742648 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (23474/2.86678e+06) 0.00819
I0630 02:13:10.898599 29777 solver.cpp:290] Iteration 1000 (6.23103 iter/s, 16.0487s/100 iter), loss = 1.55952
I0630 02:13:10.898624 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 02:13:10.898633 29777 sgd_solver.cpp:106] Iteration 1000, lr = 0.00996875
I0630 02:13:26.939337 29777 solver.cpp:290] Iteration 1100 (6.23431 iter/s, 16.0403s/100 iter), loss = 1.13095
I0630 02:13:26.939360 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:13:26.939366 29777 sgd_solver.cpp:106] Iteration 1100, lr = 0.00996562
I0630 02:13:42.892735 29777 solver.cpp:290] Iteration 1200 (6.26844 iter/s, 15.9529s/100 iter), loss = 1.34524
I0630 02:13:42.892846 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 02:13:42.892856 29777 sgd_solver.cpp:106] Iteration 1200, lr = 0.0099625
I0630 02:13:58.859582 29777 solver.cpp:290] Iteration 1300 (6.2632 iter/s, 15.9663s/100 iter), loss = 1.05952
I0630 02:13:58.859606 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 02:13:58.859612 29777 sgd_solver.cpp:106] Iteration 1300, lr = 0.00995938
I0630 02:14:14.896472 29777 solver.cpp:290] Iteration 1400 (6.23581 iter/s, 16.0364s/100 iter), loss = 0.857143
I0630 02:14:14.896580 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 02:14:14.896590 29777 sgd_solver.cpp:106] Iteration 1400, lr = 0.00995625
I0630 02:14:30.851013 29777 solver.cpp:290] Iteration 1500 (6.26802 iter/s, 15.954s/100 iter), loss = 1.42857
I0630 02:14:30.851037 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:14:30.851044 29777 sgd_solver.cpp:106] Iteration 1500, lr = 0.00995312
I0630 02:14:46.825736 29777 solver.cpp:290] Iteration 1600 (6.26007 iter/s, 15.9743s/100 iter), loss = 1.13095
I0630 02:14:46.825855 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 02:14:46.825865 29777 sgd_solver.cpp:106] Iteration 1600, lr = 0.00995
I0630 02:15:02.765061 29777 solver.cpp:290] Iteration 1700 (6.27401 iter/s, 15.9388s/100 iter), loss = 1.25
I0630 02:15:02.765085 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:15:02.765092 29777 sgd_solver.cpp:106] Iteration 1700, lr = 0.00994687
I0630 02:15:18.741606 29777 solver.cpp:290] Iteration 1800 (6.25936 iter/s, 15.9761s/100 iter), loss = 1.08333
I0630 02:15:18.741710 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:15:18.741719 29777 sgd_solver.cpp:106] Iteration 1800, lr = 0.00994375
I0630 02:15:34.634449 29777 solver.cpp:290] Iteration 1900 (6.29236 iter/s, 15.8923s/100 iter), loss = 1.5
I0630 02:15:34.634469 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 02:15:34.634476 29777 sgd_solver.cpp:106] Iteration 1900, lr = 0.00994062
I0630 02:15:50.467600 29777 solver.cpp:354] Sparsity after update:
I0630 02:15:50.468886 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:15:50.468894 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:15:50.468901 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:15:50.468904 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:15:50.468905 29777 net.cpp:1851] res2a_branch2a_param_0(0.00998) 
I0630 02:15:50.468909 29777 net.cpp:1851] res2a_branch2b_param_0(0.00998) 
I0630 02:15:50.468910 29777 net.cpp:1851] res3a_branch2a_param_0(0.01) 
I0630 02:15:50.468912 29777 net.cpp:1851] res3a_branch2b_param_0(0.00998) 
I0630 02:15:50.468914 29777 net.cpp:1851] res4a_branch2a_param_0(0.00999) 
I0630 02:15:50.468916 29777 net.cpp:1851] res4a_branch2b_param_0(0.00999) 
I0630 02:15:50.468919 29777 net.cpp:1851] res5a_branch2a_param_0(0.01) 
I0630 02:15:50.468920 29777 net.cpp:1851] res5a_branch2b_param_0(0.00997) 
I0630 02:15:50.468922 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (23474/2.86678e+06) 0.00819
I0630 02:15:50.469015 29777 solver.cpp:471] Iteration 2000, Testing net (#0)
I0630 02:15:50.781328 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:16:40.065588 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.52926
I0630 02:16:40.065696 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.773981
I0630 02:16:40.065706 29777 solver.cpp:544]     Test net output #2: loss = 1.7109 (* 1 = 1.7109 loss)
I0630 02:16:40.240593 29777 solver.cpp:290] Iteration 2000 (1.52429 iter/s, 65.6043s/100 iter), loss = 1.08333
I0630 02:16:40.240619 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:16:40.240629 29777 sgd_solver.cpp:106] Iteration 2000, lr = 0.0099375
I0630 02:16:40.241605 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.02
I0630 02:16:40.355955 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:16:56.325366 29777 solver.cpp:290] Iteration 2100 (6.21725 iter/s, 16.0843s/100 iter), loss = 1.36905
I0630 02:16:56.325392 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 02:16:56.325399 29777 sgd_solver.cpp:106] Iteration 2100, lr = 0.00993438
I0630 02:17:12.309878 29777 solver.cpp:290] Iteration 2200 (6.25624 iter/s, 15.984s/100 iter), loss = 1.05952
I0630 02:17:12.309969 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 02:17:12.309980 29777 sgd_solver.cpp:106] Iteration 2200, lr = 0.00993125
I0630 02:17:28.276195 29777 solver.cpp:290] Iteration 2300 (6.2634 iter/s, 15.9658s/100 iter), loss = 0.857143
I0630 02:17:28.276219 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 02:17:28.276226 29777 sgd_solver.cpp:106] Iteration 2300, lr = 0.00992812
I0630 02:17:44.194790 29777 solver.cpp:290] Iteration 2400 (6.28215 iter/s, 15.9181s/100 iter), loss = 1.20238
I0630 02:17:44.194887 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:17:44.194898 29777 sgd_solver.cpp:106] Iteration 2400, lr = 0.009925
I0630 02:18:00.217103 29777 solver.cpp:290] Iteration 2500 (6.24151 iter/s, 16.0218s/100 iter), loss = 0.833333
I0630 02:18:00.217128 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 02:18:00.217134 29777 sgd_solver.cpp:106] Iteration 2500, lr = 0.00992187
I0630 02:18:16.209833 29777 solver.cpp:290] Iteration 2600 (6.25303 iter/s, 15.9923s/100 iter), loss = 1.15476
I0630 02:18:16.209926 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 02:18:16.209938 29777 sgd_solver.cpp:106] Iteration 2600, lr = 0.00991875
I0630 02:18:32.188616 29777 solver.cpp:290] Iteration 2700 (6.25851 iter/s, 15.9782s/100 iter), loss = 1.22619
I0630 02:18:32.188638 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:18:32.188645 29777 sgd_solver.cpp:106] Iteration 2700, lr = 0.00991562
I0630 02:18:48.185770 29777 solver.cpp:290] Iteration 2800 (6.25129 iter/s, 15.9967s/100 iter), loss = 0.97619
I0630 02:18:48.185865 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:18:48.185876 29777 sgd_solver.cpp:106] Iteration 2800, lr = 0.0099125
I0630 02:19:04.162981 29777 solver.cpp:290] Iteration 2900 (6.25913 iter/s, 15.9767s/100 iter), loss = 0.940476
I0630 02:19:04.163009 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 02:19:04.163018 29777 sgd_solver.cpp:106] Iteration 2900, lr = 0.00990937
I0630 02:19:20.046272 29777 solver.cpp:354] Sparsity after update:
I0630 02:19:20.066694 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:19:20.066707 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:19:20.066715 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:19:20.066717 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:19:20.066720 29777 net.cpp:1851] res2a_branch2a_param_0(0.02) 
I0630 02:19:20.066722 29777 net.cpp:1851] res2a_branch2b_param_0(0.02) 
I0630 02:19:20.066725 29777 net.cpp:1851] res3a_branch2a_param_0(0.02) 
I0630 02:19:20.066726 29777 net.cpp:1851] res3a_branch2b_param_0(0.02) 
I0630 02:19:20.066728 29777 net.cpp:1851] res4a_branch2a_param_0(0.02) 
I0630 02:19:20.066730 29777 net.cpp:1851] res4a_branch2b_param_0(0.02) 
I0630 02:19:20.066732 29777 net.cpp:1851] res5a_branch2a_param_0(0.02) 
I0630 02:19:20.066735 29777 net.cpp:1851] res5a_branch2b_param_0(0.02) 
I0630 02:19:20.066736 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (46981/2.86678e+06) 0.0164
I0630 02:19:20.221180 29777 solver.cpp:290] Iteration 3000 (6.22753 iter/s, 16.0577s/100 iter), loss = 0.880952
I0630 02:19:20.221204 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 02:19:20.221215 29777 sgd_solver.cpp:106] Iteration 3000, lr = 0.00990625
I0630 02:19:36.279616 29777 solver.cpp:290] Iteration 3100 (6.22744 iter/s, 16.058s/100 iter), loss = 0.916667
I0630 02:19:36.279644 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 02:19:36.279652 29777 sgd_solver.cpp:106] Iteration 3100, lr = 0.00990312
I0630 02:19:52.220423 29777 solver.cpp:290] Iteration 3200 (6.27339 iter/s, 15.9403s/100 iter), loss = 1.20238
I0630 02:19:52.220530 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 02:19:52.220541 29777 sgd_solver.cpp:106] Iteration 3200, lr = 0.0099
I0630 02:20:08.236307 29777 solver.cpp:290] Iteration 3300 (6.24402 iter/s, 16.0153s/100 iter), loss = 1.17857
I0630 02:20:08.236332 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:20:08.236341 29777 sgd_solver.cpp:106] Iteration 3300, lr = 0.00989687
I0630 02:20:24.157477 29777 solver.cpp:290] Iteration 3400 (6.28113 iter/s, 15.9207s/100 iter), loss = 1.27381
I0630 02:20:24.157570 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:20:24.157582 29777 sgd_solver.cpp:106] Iteration 3400, lr = 0.00989375
I0630 02:20:40.178493 29777 solver.cpp:290] Iteration 3500 (6.24201 iter/s, 16.0205s/100 iter), loss = 0.785714
I0630 02:20:40.178520 29777 solver.cpp:309]     Train net output #0: loss = 0.47619 (* 1 = 0.47619 loss)
I0630 02:20:40.178529 29777 sgd_solver.cpp:106] Iteration 3500, lr = 0.00989062
I0630 02:20:56.164333 29777 solver.cpp:290] Iteration 3600 (6.25572 iter/s, 15.9854s/100 iter), loss = 1.28571
I0630 02:20:56.164425 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 02:20:56.164436 29777 sgd_solver.cpp:106] Iteration 3600, lr = 0.0098875
I0630 02:21:12.185576 29777 solver.cpp:290] Iteration 3700 (6.24192 iter/s, 16.0207s/100 iter), loss = 0.988095
I0630 02:21:12.185602 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:21:12.185617 29777 sgd_solver.cpp:106] Iteration 3700, lr = 0.00988437
I0630 02:21:28.191432 29777 solver.cpp:290] Iteration 3800 (6.2479 iter/s, 16.0054s/100 iter), loss = 1.21429
I0630 02:21:28.191519 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 02:21:28.191527 29777 sgd_solver.cpp:106] Iteration 3800, lr = 0.00988125
I0630 02:21:44.240229 29777 solver.cpp:290] Iteration 3900 (6.2312 iter/s, 16.0483s/100 iter), loss = 1.25
I0630 02:21:44.240252 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:21:44.240259 29777 sgd_solver.cpp:106] Iteration 3900, lr = 0.00987813
I0630 02:22:00.012027 29777 solver.cpp:354] Sparsity after update:
I0630 02:22:00.013463 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:22:00.013469 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:22:00.013476 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:22:00.013479 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:22:00.013481 29777 net.cpp:1851] res2a_branch2a_param_0(0.02) 
I0630 02:22:00.013484 29777 net.cpp:1851] res2a_branch2b_param_0(0.02) 
I0630 02:22:00.013486 29777 net.cpp:1851] res3a_branch2a_param_0(0.02) 
I0630 02:22:00.013489 29777 net.cpp:1851] res3a_branch2b_param_0(0.02) 
I0630 02:22:00.013491 29777 net.cpp:1851] res4a_branch2a_param_0(0.02) 
I0630 02:22:00.013494 29777 net.cpp:1851] res4a_branch2b_param_0(0.02) 
I0630 02:22:00.013496 29777 net.cpp:1851] res5a_branch2a_param_0(0.02) 
I0630 02:22:00.013499 29777 net.cpp:1851] res5a_branch2b_param_0(0.02) 
I0630 02:22:00.013500 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (46981/2.86678e+06) 0.0164
I0630 02:22:00.013589 29777 solver.cpp:471] Iteration 4000, Testing net (#0)
I0630 02:22:00.512575 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:22:48.904451 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.547739
I0630 02:22:48.904580 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.787981
I0630 02:22:48.904590 29777 solver.cpp:544]     Test net output #2: loss = 1.63662 (* 1 = 1.63662 loss)
I0630 02:22:49.083796 29777 solver.cpp:290] Iteration 4000 (1.54222 iter/s, 64.8418s/100 iter), loss = 1.17857
I0630 02:22:49.083822 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 02:22:49.083868 29777 sgd_solver.cpp:106] Iteration 4000, lr = 0.009875
I0630 02:22:49.084617 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.03
I0630 02:22:49.198292 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:23:05.181386 29777 solver.cpp:290] Iteration 4100 (6.21229 iter/s, 16.0971s/100 iter), loss = 0.785714
I0630 02:23:05.181409 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 02:23:05.181417 29777 sgd_solver.cpp:106] Iteration 4100, lr = 0.00987187
I0630 02:23:21.171454 29777 solver.cpp:290] Iteration 4200 (6.25407 iter/s, 15.9896s/100 iter), loss = 1.5
I0630 02:23:21.171546 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 02:23:21.171557 29777 sgd_solver.cpp:106] Iteration 4200, lr = 0.00986875
I0630 02:23:37.105128 29777 solver.cpp:290] Iteration 4300 (6.27623 iter/s, 15.9331s/100 iter), loss = 0.904762
I0630 02:23:37.105150 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 02:23:37.105157 29777 sgd_solver.cpp:106] Iteration 4300, lr = 0.00986562
I0630 02:23:53.059149 29777 solver.cpp:290] Iteration 4400 (6.2682 iter/s, 15.9536s/100 iter), loss = 1
I0630 02:23:53.059250 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:23:53.059262 29777 sgd_solver.cpp:106] Iteration 4400, lr = 0.0098625
I0630 02:24:09.100235 29777 solver.cpp:290] Iteration 4500 (6.2342 iter/s, 16.0405s/100 iter), loss = 1.02381
I0630 02:24:09.100261 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 02:24:09.100270 29777 sgd_solver.cpp:106] Iteration 4500, lr = 0.00985937
I0630 02:24:25.076942 29777 solver.cpp:290] Iteration 4600 (6.2593 iter/s, 15.9762s/100 iter), loss = 0.940476
I0630 02:24:25.077003 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 02:24:25.077010 29777 sgd_solver.cpp:106] Iteration 4600, lr = 0.00985625
I0630 02:24:41.100198 29777 solver.cpp:290] Iteration 4700 (6.24113 iter/s, 16.0228s/100 iter), loss = 1.25
I0630 02:24:41.100220 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 02:24:41.100227 29777 sgd_solver.cpp:106] Iteration 4700, lr = 0.00985312
I0630 02:24:57.122639 29777 solver.cpp:290] Iteration 4800 (6.24143 iter/s, 16.022s/100 iter), loss = 1.04762
I0630 02:24:57.122731 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:24:57.122743 29777 sgd_solver.cpp:106] Iteration 4800, lr = 0.00985
I0630 02:25:13.071058 29777 solver.cpp:290] Iteration 4900 (6.27042 iter/s, 15.9479s/100 iter), loss = 1.15476
I0630 02:25:13.071081 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:25:13.071089 29777 sgd_solver.cpp:106] Iteration 4900, lr = 0.00984687
I0630 02:25:28.873311 29777 solver.cpp:354] Sparsity after update:
I0630 02:25:28.893715 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:25:28.893752 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:25:28.893769 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:25:28.893777 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:25:28.893784 29777 net.cpp:1851] res2a_branch2a_param_0(0.0299) 
I0630 02:25:28.893793 29777 net.cpp:1851] res2a_branch2b_param_0(0.0299) 
I0630 02:25:28.893801 29777 net.cpp:1851] res3a_branch2a_param_0(0.03) 
I0630 02:25:28.893810 29777 net.cpp:1851] res3a_branch2b_param_0(0.03) 
I0630 02:25:28.893816 29777 net.cpp:1851] res4a_branch2a_param_0(0.03) 
I0630 02:25:28.893824 29777 net.cpp:1851] res4a_branch2b_param_0(0.03) 
I0630 02:25:28.893831 29777 net.cpp:1851] res5a_branch2a_param_0(0.03) 
I0630 02:25:28.893839 29777 net.cpp:1851] res5a_branch2b_param_0(0.03) 
I0630 02:25:28.893847 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (70472/2.86678e+06) 0.0246
I0630 02:25:29.055929 29777 solver.cpp:290] Iteration 5000 (6.2561 iter/s, 15.9844s/100 iter), loss = 0.952381
I0630 02:25:29.055953 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:25:29.055959 29777 sgd_solver.cpp:106] Iteration 5000, lr = 0.00984375
I0630 02:25:45.001849 29777 solver.cpp:290] Iteration 5100 (6.27138 iter/s, 15.9454s/100 iter), loss = 1.07143
I0630 02:25:45.001869 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:25:45.001876 29777 sgd_solver.cpp:106] Iteration 5100, lr = 0.00984062
I0630 02:26:00.990571 29777 solver.cpp:290] Iteration 5200 (6.25459 iter/s, 15.9883s/100 iter), loss = 1.19048
I0630 02:26:00.990648 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 02:26:00.990656 29777 sgd_solver.cpp:106] Iteration 5200, lr = 0.0098375
I0630 02:26:17.011343 29777 solver.cpp:290] Iteration 5300 (6.2421 iter/s, 16.0202s/100 iter), loss = 0.678571
I0630 02:26:17.011368 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 02:26:17.011374 29777 sgd_solver.cpp:106] Iteration 5300, lr = 0.00983437
I0630 02:26:33.056402 29777 solver.cpp:290] Iteration 5400 (6.23263 iter/s, 16.0446s/100 iter), loss = 1.2619
I0630 02:26:33.056509 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 02:26:33.056524 29777 sgd_solver.cpp:106] Iteration 5400, lr = 0.00983125
I0630 02:26:49.064081 29777 solver.cpp:290] Iteration 5500 (6.24722 iter/s, 16.0071s/100 iter), loss = 1.41667
I0630 02:26:49.064110 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 02:26:49.064119 29777 sgd_solver.cpp:106] Iteration 5500, lr = 0.00982813
I0630 02:27:05.011070 29777 solver.cpp:290] Iteration 5600 (6.27096 iter/s, 15.9465s/100 iter), loss = 1.21429
I0630 02:27:05.011160 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 02:27:05.011170 29777 sgd_solver.cpp:106] Iteration 5600, lr = 0.009825
I0630 02:27:20.998875 29777 solver.cpp:290] Iteration 5700 (6.25498 iter/s, 15.9873s/100 iter), loss = 0.833333
I0630 02:27:20.998899 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 02:27:20.998908 29777 sgd_solver.cpp:106] Iteration 5700, lr = 0.00982188
I0630 02:27:37.005162 29777 solver.cpp:290] Iteration 5800 (6.24773 iter/s, 16.0058s/100 iter), loss = 1.09524
I0630 02:27:37.005244 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:27:37.005255 29777 sgd_solver.cpp:106] Iteration 5800, lr = 0.00981875
I0630 02:27:53.079452 29777 solver.cpp:290] Iteration 5900 (6.22132 iter/s, 16.0738s/100 iter), loss = 1.10714
I0630 02:27:53.079476 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 02:27:53.079485 29777 sgd_solver.cpp:106] Iteration 5900, lr = 0.00981562
I0630 02:28:08.850757 29777 solver.cpp:354] Sparsity after update:
I0630 02:28:08.852033 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:28:08.852042 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:28:08.852048 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:28:08.852051 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:28:08.852053 29777 net.cpp:1851] res2a_branch2a_param_0(0.0299) 
I0630 02:28:08.852056 29777 net.cpp:1851] res2a_branch2b_param_0(0.0299) 
I0630 02:28:08.852058 29777 net.cpp:1851] res3a_branch2a_param_0(0.03) 
I0630 02:28:08.852061 29777 net.cpp:1851] res3a_branch2b_param_0(0.03) 
I0630 02:28:08.852063 29777 net.cpp:1851] res4a_branch2a_param_0(0.03) 
I0630 02:28:08.852066 29777 net.cpp:1851] res4a_branch2b_param_0(0.03) 
I0630 02:28:08.852068 29777 net.cpp:1851] res5a_branch2a_param_0(0.03) 
I0630 02:28:08.852071 29777 net.cpp:1851] res5a_branch2b_param_0(0.03) 
I0630 02:28:08.852073 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (70472/2.86678e+06) 0.0246
I0630 02:28:08.852170 29777 solver.cpp:471] Iteration 6000, Testing net (#0)
I0630 02:28:09.528820 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:28:57.098083 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5525
I0630 02:28:57.098186 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.792661
I0630 02:28:57.098194 29777 solver.cpp:544]     Test net output #2: loss = 1.599 (* 1 = 1.599 loss)
I0630 02:28:57.273607 29777 solver.cpp:290] Iteration 6000 (1.55782 iter/s, 64.1923s/100 iter), loss = 1.21429
I0630 02:28:57.273628 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:28:57.273635 29777 sgd_solver.cpp:106] Iteration 6000, lr = 0.0098125
I0630 02:28:57.274338 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.04
I0630 02:28:57.384799 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:29:13.441776 29777 solver.cpp:290] Iteration 6100 (6.18518 iter/s, 16.1677s/100 iter), loss = 1.41667
I0630 02:29:13.441798 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 02:29:13.441807 29777 sgd_solver.cpp:106] Iteration 6100, lr = 0.00980937
I0630 02:29:29.520517 29777 solver.cpp:290] Iteration 6200 (6.21958 iter/s, 16.0783s/100 iter), loss = 1.13095
I0630 02:29:29.520596 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 02:29:29.520606 29777 sgd_solver.cpp:106] Iteration 6200, lr = 0.00980625
I0630 02:29:45.548202 29777 solver.cpp:290] Iteration 6300 (6.23941 iter/s, 16.0272s/100 iter), loss = 1.10714
I0630 02:29:45.548228 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 02:29:45.548236 29777 sgd_solver.cpp:106] Iteration 6300, lr = 0.00980312
I0630 02:30:01.565382 29777 solver.cpp:290] Iteration 6400 (6.24348 iter/s, 16.0167s/100 iter), loss = 1.09524
I0630 02:30:01.565477 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:30:01.565488 29777 sgd_solver.cpp:106] Iteration 6400, lr = 0.0098
I0630 02:30:17.646778 29777 solver.cpp:290] Iteration 6500 (6.21858 iter/s, 16.0809s/100 iter), loss = 1.04762
I0630 02:30:17.646802 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:30:17.646808 29777 sgd_solver.cpp:106] Iteration 6500, lr = 0.00979687
I0630 02:30:33.646033 29777 solver.cpp:290] Iteration 6600 (6.25048 iter/s, 15.9988s/100 iter), loss = 1.2619
I0630 02:30:33.646152 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 02:30:33.646162 29777 sgd_solver.cpp:106] Iteration 6600, lr = 0.00979375
I0630 02:30:49.623831 29777 solver.cpp:290] Iteration 6700 (6.25891 iter/s, 15.9772s/100 iter), loss = 1.21429
I0630 02:30:49.623857 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 02:30:49.623867 29777 sgd_solver.cpp:106] Iteration 6700, lr = 0.00979062
I0630 02:31:05.495962 29777 solver.cpp:290] Iteration 6800 (6.30054 iter/s, 15.8717s/100 iter), loss = 1.21429
I0630 02:31:05.496037 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 02:31:05.496044 29777 sgd_solver.cpp:106] Iteration 6800, lr = 0.0097875
I0630 02:31:21.468224 29777 solver.cpp:290] Iteration 6900 (6.26106 iter/s, 15.9717s/100 iter), loss = 1.11905
I0630 02:31:21.468251 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:31:21.468261 29777 sgd_solver.cpp:106] Iteration 6900, lr = 0.00978437
I0630 02:31:37.292667 29777 solver.cpp:354] Sparsity after update:
I0630 02:31:37.313056 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:31:37.313092 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:31:37.313112 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:31:37.313123 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:31:37.313136 29777 net.cpp:1851] res2a_branch2a_param_0(0.0399) 
I0630 02:31:37.313144 29777 net.cpp:1851] res2a_branch2b_param_0(0.0399) 
I0630 02:31:37.313150 29777 net.cpp:1851] res3a_branch2a_param_0(0.04) 
I0630 02:31:37.313154 29777 net.cpp:1851] res3a_branch2b_param_0(0.04) 
I0630 02:31:37.313158 29777 net.cpp:1851] res4a_branch2a_param_0(0.04) 
I0630 02:31:37.313160 29777 net.cpp:1851] res4a_branch2b_param_0(0.04) 
I0630 02:31:37.313165 29777 net.cpp:1851] res5a_branch2a_param_0(0.04) 
I0630 02:31:37.313169 29777 net.cpp:1851] res5a_branch2b_param_0(0.04) 
I0630 02:31:37.313172 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (93969/2.86678e+06) 0.0328
I0630 02:31:37.469810 29777 solver.cpp:290] Iteration 7000 (6.24957 iter/s, 16.0011s/100 iter), loss = 0.809524
I0630 02:31:37.469837 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 02:31:37.469846 29777 sgd_solver.cpp:106] Iteration 7000, lr = 0.00978125
I0630 02:31:53.478783 29777 solver.cpp:290] Iteration 7100 (6.24668 iter/s, 16.0085s/100 iter), loss = 1.13095
I0630 02:31:53.478842 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 02:31:53.478852 29777 sgd_solver.cpp:106] Iteration 7100, lr = 0.00977813
I0630 02:32:09.499135 29777 solver.cpp:290] Iteration 7200 (6.24226 iter/s, 16.0198s/100 iter), loss = 1.14286
I0630 02:32:09.502990 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 02:32:09.503069 29777 sgd_solver.cpp:106] Iteration 7200, lr = 0.009775
I0630 02:32:25.462734 29777 solver.cpp:290] Iteration 7300 (6.26594 iter/s, 15.9593s/100 iter), loss = 1.29762
I0630 02:32:25.462759 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:32:25.462767 29777 sgd_solver.cpp:106] Iteration 7300, lr = 0.00977188
I0630 02:32:41.431506 29777 solver.cpp:290] Iteration 7400 (6.26241 iter/s, 15.9683s/100 iter), loss = 1.04762
I0630 02:32:41.431576 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 02:32:41.431596 29777 sgd_solver.cpp:106] Iteration 7400, lr = 0.00976875
I0630 02:32:57.480398 29777 solver.cpp:290] Iteration 7500 (6.23116 iter/s, 16.0484s/100 iter), loss = 1.34524
I0630 02:32:57.480424 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 02:32:57.480434 29777 sgd_solver.cpp:106] Iteration 7500, lr = 0.00976562
I0630 02:33:13.519101 29777 solver.cpp:290] Iteration 7600 (6.2351 iter/s, 16.0382s/100 iter), loss = 1.22619
I0630 02:33:13.519166 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 02:33:13.519174 29777 sgd_solver.cpp:106] Iteration 7600, lr = 0.0097625
I0630 02:33:29.435500 29777 solver.cpp:290] Iteration 7700 (6.28303 iter/s, 15.9159s/100 iter), loss = 1.22619
I0630 02:33:29.435524 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 02:33:29.435531 29777 sgd_solver.cpp:106] Iteration 7700, lr = 0.00975937
I0630 02:33:45.485832 29777 solver.cpp:290] Iteration 7800 (6.23059 iter/s, 16.0499s/100 iter), loss = 1.45238
I0630 02:33:45.485929 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 02:33:45.485939 29777 sgd_solver.cpp:106] Iteration 7800, lr = 0.00975625
I0630 02:34:01.404512 29777 solver.cpp:290] Iteration 7900 (6.28214 iter/s, 15.9181s/100 iter), loss = 1.25
I0630 02:34:01.404538 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:34:01.404547 29777 sgd_solver.cpp:106] Iteration 7900, lr = 0.00975312
I0630 02:34:17.318284 29777 solver.cpp:354] Sparsity after update:
I0630 02:34:17.319923 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:34:17.319931 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:34:17.319938 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:34:17.319941 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:34:17.319942 29777 net.cpp:1851] res2a_branch2a_param_0(0.0399) 
I0630 02:34:17.319946 29777 net.cpp:1851] res2a_branch2b_param_0(0.0399) 
I0630 02:34:17.319947 29777 net.cpp:1851] res3a_branch2a_param_0(0.04) 
I0630 02:34:17.319949 29777 net.cpp:1851] res3a_branch2b_param_0(0.04) 
I0630 02:34:17.319952 29777 net.cpp:1851] res4a_branch2a_param_0(0.04) 
I0630 02:34:17.319953 29777 net.cpp:1851] res4a_branch2b_param_0(0.04) 
I0630 02:34:17.319955 29777 net.cpp:1851] res5a_branch2a_param_0(0.04) 
I0630 02:34:17.319957 29777 net.cpp:1851] res5a_branch2b_param_0(0.04) 
I0630 02:34:17.319959 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (93969/2.86678e+06) 0.0328
I0630 02:34:17.320046 29777 solver.cpp:471] Iteration 8000, Testing net (#0)
I0630 02:34:18.189494 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:35:05.951143 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54464
I0630 02:35:05.951251 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.784161
I0630 02:35:05.951261 29777 solver.cpp:544]     Test net output #2: loss = 1.64854 (* 1 = 1.64854 loss)
I0630 02:35:06.129494 29777 solver.cpp:290] Iteration 8000 (1.54504 iter/s, 64.7232s/100 iter), loss = 1.02381
I0630 02:35:06.129520 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:35:06.129529 29777 sgd_solver.cpp:106] Iteration 8000, lr = 0.00975
I0630 02:35:06.130506 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.05
I0630 02:35:06.245388 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:35:22.352187 29777 solver.cpp:290] Iteration 8100 (6.16439 iter/s, 16.2222s/100 iter), loss = 1.45238
I0630 02:35:22.352210 29777 solver.cpp:309]     Train net output #0: loss = 1.71429 (* 1 = 1.71429 loss)
I0630 02:35:22.352217 29777 sgd_solver.cpp:106] Iteration 8100, lr = 0.00974687
I0630 02:35:38.291359 29777 solver.cpp:290] Iteration 8200 (6.27404 iter/s, 15.9387s/100 iter), loss = 1.2619
I0630 02:35:38.291465 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 02:35:38.291476 29777 sgd_solver.cpp:106] Iteration 8200, lr = 0.00974375
I0630 02:35:54.320405 29777 solver.cpp:290] Iteration 8300 (6.23889 iter/s, 16.0285s/100 iter), loss = 1.17857
I0630 02:35:54.320430 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 02:35:54.320439 29777 sgd_solver.cpp:106] Iteration 8300, lr = 0.00974062
I0630 02:36:10.296932 29777 solver.cpp:290] Iteration 8400 (6.25937 iter/s, 15.976s/100 iter), loss = 1.07143
I0630 02:36:10.297029 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:36:10.297044 29777 sgd_solver.cpp:106] Iteration 8400, lr = 0.0097375
I0630 02:36:26.363386 29777 solver.cpp:290] Iteration 8500 (6.22436 iter/s, 16.0659s/100 iter), loss = 1.09524
I0630 02:36:26.363411 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:36:26.363420 29777 sgd_solver.cpp:106] Iteration 8500, lr = 0.00973437
I0630 02:36:42.380946 29777 solver.cpp:290] Iteration 8600 (6.24333 iter/s, 16.0171s/100 iter), loss = 1.0119
I0630 02:36:42.381039 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:36:42.381050 29777 sgd_solver.cpp:106] Iteration 8600, lr = 0.00973125
I0630 02:36:58.413369 29777 solver.cpp:290] Iteration 8700 (6.23757 iter/s, 16.0319s/100 iter), loss = 1.13095
I0630 02:36:58.413395 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 02:36:58.413403 29777 sgd_solver.cpp:106] Iteration 8700, lr = 0.00972812
I0630 02:37:14.423337 29777 solver.cpp:290] Iteration 8800 (6.24629 iter/s, 16.0095s/100 iter), loss = 1.21429
I0630 02:37:14.423424 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:37:14.423435 29777 sgd_solver.cpp:106] Iteration 8800, lr = 0.009725
I0630 02:37:30.398186 29777 solver.cpp:290] Iteration 8900 (6.26005 iter/s, 15.9743s/100 iter), loss = 0.940476
I0630 02:37:30.398211 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 02:37:30.398217 29777 sgd_solver.cpp:106] Iteration 8900, lr = 0.00972188
I0630 02:37:46.299845 29777 solver.cpp:354] Sparsity after update:
I0630 02:37:46.320047 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:37:46.320061 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:37:46.320072 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:37:46.320076 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:37:46.320080 29777 net.cpp:1851] res2a_branch2a_param_0(0.05) 
I0630 02:37:46.320086 29777 net.cpp:1851] res2a_branch2b_param_0(0.0499) 
I0630 02:37:46.320088 29777 net.cpp:1851] res3a_branch2a_param_0(0.05) 
I0630 02:37:46.320091 29777 net.cpp:1851] res3a_branch2b_param_0(0.05) 
I0630 02:37:46.320094 29777 net.cpp:1851] res4a_branch2a_param_0(0.05) 
I0630 02:37:46.320098 29777 net.cpp:1851] res4a_branch2b_param_0(0.05) 
I0630 02:37:46.320109 29777 net.cpp:1851] res5a_branch2a_param_0(0.05) 
I0630 02:37:46.320116 29777 net.cpp:1851] res5a_branch2b_param_0(0.05) 
I0630 02:37:46.320121 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (117484/2.86678e+06) 0.041
I0630 02:37:46.475716 29777 solver.cpp:290] Iteration 9000 (6.22005 iter/s, 16.0771s/100 iter), loss = 1.27381
I0630 02:37:46.475742 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 02:37:46.475750 29777 sgd_solver.cpp:106] Iteration 9000, lr = 0.00971875
I0630 02:38:02.395467 29777 solver.cpp:290] Iteration 9100 (6.28169 iter/s, 15.9193s/100 iter), loss = 0.809524
I0630 02:38:02.395490 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 02:38:02.395498 29777 sgd_solver.cpp:106] Iteration 9100, lr = 0.00971563
I0630 02:38:18.391331 29777 solver.cpp:290] Iteration 9200 (6.2518 iter/s, 15.9954s/100 iter), loss = 1.10714
I0630 02:38:18.391435 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 02:38:18.391445 29777 sgd_solver.cpp:106] Iteration 9200, lr = 0.0097125
I0630 02:38:34.332414 29777 solver.cpp:290] Iteration 9300 (6.27331 iter/s, 15.9405s/100 iter), loss = 1.02381
I0630 02:38:34.332437 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 02:38:34.332443 29777 sgd_solver.cpp:106] Iteration 9300, lr = 0.00970937
I0630 02:38:50.290498 29777 solver.cpp:290] Iteration 9400 (6.2666 iter/s, 15.9576s/100 iter), loss = 1.55952
I0630 02:38:50.290566 29777 solver.cpp:309]     Train net output #0: loss = 1.92857 (* 1 = 1.92857 loss)
I0630 02:38:50.290575 29777 sgd_solver.cpp:106] Iteration 9400, lr = 0.00970625
I0630 02:39:06.416635 29777 solver.cpp:290] Iteration 9500 (6.20131 iter/s, 16.1256s/100 iter), loss = 1.2619
I0630 02:39:06.416661 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 02:39:06.416671 29777 sgd_solver.cpp:106] Iteration 9500, lr = 0.00970312
I0630 02:39:22.480839 29777 solver.cpp:290] Iteration 9600 (6.22521 iter/s, 16.0637s/100 iter), loss = 1.44048
I0630 02:39:22.480949 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 02:39:22.480959 29777 sgd_solver.cpp:106] Iteration 9600, lr = 0.0097
I0630 02:39:38.524018 29777 solver.cpp:290] Iteration 9700 (6.2334 iter/s, 16.0426s/100 iter), loss = 0.77381
I0630 02:39:38.524044 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 02:39:38.524054 29777 sgd_solver.cpp:106] Iteration 9700, lr = 0.00969687
I0630 02:39:54.471120 29777 solver.cpp:290] Iteration 9800 (6.27092 iter/s, 15.9466s/100 iter), loss = 1.17857
I0630 02:39:54.471195 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 02:39:54.471206 29777 sgd_solver.cpp:106] Iteration 9800, lr = 0.00969375
I0630 02:40:10.449753 29777 solver.cpp:290] Iteration 9900 (6.25856 iter/s, 15.9781s/100 iter), loss = 1.10714
I0630 02:40:10.449775 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 02:40:10.449781 29777 sgd_solver.cpp:106] Iteration 9900, lr = 0.00969062
I0630 02:40:26.297960 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_10000.caffemodel
I0630 02:40:26.386431 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_10000.solverstate
I0630 02:40:26.394994 29777 solver.cpp:354] Sparsity after update:
I0630 02:40:26.395985 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:40:26.395994 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:40:26.396005 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:40:26.396010 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:40:26.396013 29777 net.cpp:1851] res2a_branch2a_param_0(0.05) 
I0630 02:40:26.396018 29777 net.cpp:1851] res2a_branch2b_param_0(0.0499) 
I0630 02:40:26.396023 29777 net.cpp:1851] res3a_branch2a_param_0(0.05) 
I0630 02:40:26.396028 29777 net.cpp:1851] res3a_branch2b_param_0(0.05) 
I0630 02:40:26.396030 29777 net.cpp:1851] res4a_branch2a_param_0(0.05) 
I0630 02:40:26.396035 29777 net.cpp:1851] res4a_branch2b_param_0(0.05) 
I0630 02:40:26.396040 29777 net.cpp:1851] res5a_branch2a_param_0(0.05) 
I0630 02:40:26.396044 29777 net.cpp:1851] res5a_branch2b_param_0(0.05) 
I0630 02:40:26.396049 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (117484/2.86678e+06) 0.041
I0630 02:40:26.396150 29777 solver.cpp:471] Iteration 10000, Testing net (#0)
I0630 02:40:27.451498 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:41:15.115475 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.53622
I0630 02:41:15.115526 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.7789
I0630 02:41:15.115533 29777 solver.cpp:544]     Test net output #2: loss = 1.70066 (* 1 = 1.70066 loss)
I0630 02:41:15.303112 29777 solver.cpp:290] Iteration 10000 (1.54198 iter/s, 64.8515s/100 iter), loss = 0.892857
I0630 02:41:15.303135 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 02:41:15.303141 29777 sgd_solver.cpp:106] Iteration 10000, lr = 0.0096875
I0630 02:41:15.303835 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.06
I0630 02:41:15.415892 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:41:31.358265 29777 solver.cpp:290] Iteration 10100 (6.22871 iter/s, 16.0547s/100 iter), loss = 1.0119
I0630 02:41:31.358289 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 02:41:31.358296 29777 sgd_solver.cpp:106] Iteration 10100, lr = 0.00968437
I0630 02:41:47.327224 29777 solver.cpp:290] Iteration 10200 (6.26233 iter/s, 15.9685s/100 iter), loss = 1.25
I0630 02:41:47.327327 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:41:47.327334 29777 sgd_solver.cpp:106] Iteration 10200, lr = 0.00968125
I0630 02:42:03.345801 29777 solver.cpp:290] Iteration 10300 (6.24297 iter/s, 16.018s/100 iter), loss = 1.27381
I0630 02:42:03.345824 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 02:42:03.345830 29777 sgd_solver.cpp:106] Iteration 10300, lr = 0.00967812
I0630 02:42:19.352821 29777 solver.cpp:290] Iteration 10400 (6.24744 iter/s, 16.0065s/100 iter), loss = 0.952381
I0630 02:42:19.352928 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 02:42:19.352942 29777 sgd_solver.cpp:106] Iteration 10400, lr = 0.009675
I0630 02:42:35.309152 29777 solver.cpp:290] Iteration 10500 (6.26732 iter/s, 15.9558s/100 iter), loss = 1.22619
I0630 02:42:35.309175 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 02:42:35.309193 29777 sgd_solver.cpp:106] Iteration 10500, lr = 0.00967188
I0630 02:42:51.239629 29777 solver.cpp:290] Iteration 10600 (6.27746 iter/s, 15.93s/100 iter), loss = 1.03571
I0630 02:42:51.239701 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 02:42:51.239712 29777 sgd_solver.cpp:106] Iteration 10600, lr = 0.00966875
I0630 02:43:07.200438 29777 solver.cpp:290] Iteration 10700 (6.26555 iter/s, 15.9603s/100 iter), loss = 1.72619
I0630 02:43:07.200460 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 02:43:07.200467 29777 sgd_solver.cpp:106] Iteration 10700, lr = 0.00966563
I0630 02:43:23.207172 29777 solver.cpp:290] Iteration 10800 (6.24755 iter/s, 16.0063s/100 iter), loss = 1.40476
I0630 02:43:23.207279 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 02:43:23.207289 29777 sgd_solver.cpp:106] Iteration 10800, lr = 0.0096625
I0630 02:43:39.179239 29777 solver.cpp:290] Iteration 10900 (6.26115 iter/s, 15.9715s/100 iter), loss = 1.13095
I0630 02:43:39.179261 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:43:39.179267 29777 sgd_solver.cpp:106] Iteration 10900, lr = 0.00965938
I0630 02:43:55.115053 29777 solver.cpp:354] Sparsity after update:
I0630 02:43:55.135666 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:43:55.135711 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:43:55.135728 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:43:55.135736 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:43:55.135745 29777 net.cpp:1851] res2a_branch2a_param_0(0.06) 
I0630 02:43:55.135754 29777 net.cpp:1851] res2a_branch2b_param_0(0.0599) 
I0630 02:43:55.135762 29777 net.cpp:1851] res3a_branch2a_param_0(0.06) 
I0630 02:43:55.135771 29777 net.cpp:1851] res3a_branch2b_param_0(0.06) 
I0630 02:43:55.135779 29777 net.cpp:1851] res4a_branch2a_param_0(0.06) 
I0630 02:43:55.135788 29777 net.cpp:1851] res4a_branch2b_param_0(0.06) 
I0630 02:43:55.135797 29777 net.cpp:1851] res5a_branch2a_param_0(0.06) 
I0630 02:43:55.135804 29777 net.cpp:1851] res5a_branch2b_param_0(0.06) 
I0630 02:43:55.135812 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (140986/2.86678e+06) 0.0492
I0630 02:43:55.290863 29777 solver.cpp:290] Iteration 11000 (6.20688 iter/s, 16.1111s/100 iter), loss = 1.5
I0630 02:43:55.291105 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 02:43:55.291234 29777 sgd_solver.cpp:106] Iteration 11000, lr = 0.00965625
I0630 02:44:11.375176 29777 solver.cpp:290] Iteration 11100 (6.2175 iter/s, 16.0836s/100 iter), loss = 1.2381
I0630 02:44:11.375200 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 02:44:11.375206 29777 sgd_solver.cpp:106] Iteration 11100, lr = 0.00965312
I0630 02:44:27.391824 29777 solver.cpp:290] Iteration 11200 (6.24369 iter/s, 16.0162s/100 iter), loss = 0.964286
I0630 02:44:27.391890 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 02:44:27.391901 29777 sgd_solver.cpp:106] Iteration 11200, lr = 0.00965
I0630 02:44:43.482599 29777 solver.cpp:290] Iteration 11300 (6.21494 iter/s, 16.0903s/100 iter), loss = 1.30952
I0630 02:44:43.482621 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:44:43.482630 29777 sgd_solver.cpp:106] Iteration 11300, lr = 0.00964687
I0630 02:44:59.644758 29777 solver.cpp:290] Iteration 11400 (6.18747 iter/s, 16.1617s/100 iter), loss = 0.892857
I0630 02:44:59.644870 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 02:44:59.644881 29777 sgd_solver.cpp:106] Iteration 11400, lr = 0.00964375
I0630 02:45:15.717372 29777 solver.cpp:290] Iteration 11500 (6.22198 iter/s, 16.0721s/100 iter), loss = 1.16667
I0630 02:45:15.717397 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:45:15.717407 29777 sgd_solver.cpp:106] Iteration 11500, lr = 0.00964062
I0630 02:45:31.818399 29777 solver.cpp:290] Iteration 11600 (6.21096 iter/s, 16.1006s/100 iter), loss = 0.988095
I0630 02:45:31.818473 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:45:31.818482 29777 sgd_solver.cpp:106] Iteration 11600, lr = 0.0096375
I0630 02:45:47.922749 29777 solver.cpp:290] Iteration 11700 (6.2097 iter/s, 16.1038s/100 iter), loss = 1.30952
I0630 02:45:47.922777 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 02:45:47.922791 29777 sgd_solver.cpp:106] Iteration 11700, lr = 0.00963437
I0630 02:46:03.947202 29777 solver.cpp:290] Iteration 11800 (6.24065 iter/s, 16.024s/100 iter), loss = 1.36905
I0630 02:46:03.947283 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 02:46:03.947294 29777 sgd_solver.cpp:106] Iteration 11800, lr = 0.00963125
I0630 02:46:19.927386 29777 solver.cpp:290] Iteration 11900 (6.25795 iter/s, 15.9797s/100 iter), loss = 0.857143
I0630 02:46:19.927409 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 02:46:19.927415 29777 sgd_solver.cpp:106] Iteration 11900, lr = 0.00962812
I0630 02:46:35.744079 29777 solver.cpp:354] Sparsity after update:
I0630 02:46:35.745528 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:46:35.745537 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:46:35.745545 29777 net.cpp:1851] conv1b_param_0(0) 
I0630 02:46:35.745549 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:46:35.745554 29777 net.cpp:1851] res2a_branch2a_param_0(0.06) 
I0630 02:46:35.745560 29777 net.cpp:1851] res2a_branch2b_param_0(0.0599) 
I0630 02:46:35.745565 29777 net.cpp:1851] res3a_branch2a_param_0(0.06) 
I0630 02:46:35.745570 29777 net.cpp:1851] res3a_branch2b_param_0(0.06) 
I0630 02:46:35.745574 29777 net.cpp:1851] res4a_branch2a_param_0(0.06) 
I0630 02:46:35.745579 29777 net.cpp:1851] res4a_branch2b_param_0(0.06) 
I0630 02:46:35.745584 29777 net.cpp:1851] res5a_branch2a_param_0(0.06) 
I0630 02:46:35.745589 29777 net.cpp:1851] res5a_branch2b_param_0(0.06) 
I0630 02:46:35.745594 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (140986/2.86678e+06) 0.0492
I0630 02:46:35.745685 29777 solver.cpp:471] Iteration 12000, Testing net (#0)
I0630 02:46:36.969911 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:47:23.542265 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.552599
I0630 02:47:23.542367 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.791241
I0630 02:47:23.542381 29777 solver.cpp:544]     Test net output #2: loss = 1.59644 (* 1 = 1.59644 loss)
I0630 02:47:23.730800 29777 solver.cpp:290] Iteration 12000 (1.56736 iter/s, 63.8017s/100 iter), loss = 1.10714
I0630 02:47:23.730824 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 02:47:23.730830 29777 sgd_solver.cpp:106] Iteration 12000, lr = 0.009625
I0630 02:47:23.731518 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.07
I0630 02:47:23.860766 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:47:39.840665 29777 solver.cpp:290] Iteration 12100 (6.20756 iter/s, 16.1094s/100 iter), loss = 1.27381
I0630 02:47:39.840689 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 02:47:39.840697 29777 sgd_solver.cpp:106] Iteration 12100, lr = 0.00962188
I0630 02:47:55.848570 29777 solver.cpp:290] Iteration 12200 (6.2471 iter/s, 16.0074s/100 iter), loss = 1.14286
I0630 02:47:55.848687 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 02:47:55.848701 29777 sgd_solver.cpp:106] Iteration 12200, lr = 0.00961875
I0630 02:48:11.844678 29777 solver.cpp:290] Iteration 12300 (6.25174 iter/s, 15.9956s/100 iter), loss = 0.964286
I0630 02:48:11.844705 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:48:11.844717 29777 sgd_solver.cpp:106] Iteration 12300, lr = 0.00961563
I0630 02:48:27.870720 29777 solver.cpp:290] Iteration 12400 (6.24003 iter/s, 16.0256s/100 iter), loss = 0.904762
I0630 02:48:27.871044 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 02:48:27.871166 29777 sgd_solver.cpp:106] Iteration 12400, lr = 0.0096125
I0630 02:48:44.183939 29777 solver.cpp:290] Iteration 12500 (6.13029 iter/s, 16.3124s/100 iter), loss = 1.25
I0630 02:48:44.183961 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 02:48:44.183967 29777 sgd_solver.cpp:106] Iteration 12500, lr = 0.00960938
I0630 02:49:00.416286 29777 solver.cpp:290] Iteration 12600 (6.16072 iter/s, 16.2319s/100 iter), loss = 0.857143
I0630 02:49:00.416357 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 02:49:00.416368 29777 sgd_solver.cpp:106] Iteration 12600, lr = 0.00960625
I0630 02:49:16.664438 29777 solver.cpp:290] Iteration 12700 (6.15474 iter/s, 16.2476s/100 iter), loss = 1.22619
I0630 02:49:16.664463 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:49:16.664474 29777 sgd_solver.cpp:106] Iteration 12700, lr = 0.00960313
I0630 02:49:32.676111 29777 solver.cpp:290] Iteration 12800 (6.24563 iter/s, 16.0112s/100 iter), loss = 0.821429
I0630 02:49:32.676153 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:49:32.676161 29777 sgd_solver.cpp:106] Iteration 12800, lr = 0.0096
I0630 02:49:48.792279 29777 solver.cpp:290] Iteration 12900 (6.20513 iter/s, 16.1157s/100 iter), loss = 1.09524
I0630 02:49:48.792302 29777 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0630 02:49:48.792309 29777 sgd_solver.cpp:106] Iteration 12900, lr = 0.00959687
I0630 02:50:04.628621 29777 solver.cpp:354] Sparsity after update:
I0630 02:50:04.649134 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:50:04.649150 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:50:04.649159 29777 net.cpp:1851] conv1b_param_0(0.0699) 
I0630 02:50:04.649164 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:50:04.649176 29777 net.cpp:1851] res2a_branch2a_param_0(0.07) 
I0630 02:50:04.649186 29777 net.cpp:1851] res2a_branch2b_param_0(0.07) 
I0630 02:50:04.649194 29777 net.cpp:1851] res3a_branch2a_param_0(0.07) 
I0630 02:50:04.649204 29777 net.cpp:1851] res3a_branch2b_param_0(0.07) 
I0630 02:50:04.649217 29777 net.cpp:1851] res4a_branch2a_param_0(0.07) 
I0630 02:50:04.649224 29777 net.cpp:1851] res4a_branch2b_param_0(0.07) 
I0630 02:50:04.649232 29777 net.cpp:1851] res5a_branch2a_param_0(0.07) 
I0630 02:50:04.649242 29777 net.cpp:1851] res5a_branch2b_param_0(0.07) 
I0630 02:50:04.649247 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (164652/2.86678e+06) 0.0574
I0630 02:50:04.808748 29777 solver.cpp:290] Iteration 13000 (6.24375 iter/s, 16.016s/100 iter), loss = 1.64286
I0630 02:50:04.808773 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 02:50:04.808779 29777 sgd_solver.cpp:106] Iteration 13000, lr = 0.00959375
I0630 02:50:20.826068 29777 solver.cpp:290] Iteration 13100 (6.24342 iter/s, 16.0169s/100 iter), loss = 1.11905
I0630 02:50:20.826094 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 02:50:20.826103 29777 sgd_solver.cpp:106] Iteration 13100, lr = 0.00959062
I0630 02:50:36.823475 29777 solver.cpp:290] Iteration 13200 (6.25119 iter/s, 15.9969s/100 iter), loss = 0.952381
I0630 02:50:36.823560 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 02:50:36.823567 29777 sgd_solver.cpp:106] Iteration 13200, lr = 0.0095875
I0630 02:50:52.904510 29777 solver.cpp:290] Iteration 13300 (6.21871 iter/s, 16.0805s/100 iter), loss = 1.10714
I0630 02:50:52.904533 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:50:52.904541 29777 sgd_solver.cpp:106] Iteration 13300, lr = 0.00958437
I0630 02:51:08.828534 29777 solver.cpp:290] Iteration 13400 (6.28 iter/s, 15.9236s/100 iter), loss = 1.11905
I0630 02:51:08.828611 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:51:08.828624 29777 sgd_solver.cpp:106] Iteration 13400, lr = 0.00958125
I0630 02:51:24.923534 29777 solver.cpp:290] Iteration 13500 (6.21331 iter/s, 16.0945s/100 iter), loss = 0.964286
I0630 02:51:24.923557 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 02:51:24.923564 29777 sgd_solver.cpp:106] Iteration 13500, lr = 0.00957812
I0630 02:51:40.923938 29777 solver.cpp:290] Iteration 13600 (6.25002 iter/s, 15.9999s/100 iter), loss = 0.964286
I0630 02:51:40.924042 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 02:51:40.924052 29777 sgd_solver.cpp:106] Iteration 13600, lr = 0.009575
I0630 02:51:56.884902 29777 solver.cpp:290] Iteration 13700 (6.2655 iter/s, 15.9604s/100 iter), loss = 1.4881
I0630 02:51:56.885200 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 02:51:56.885336 29777 sgd_solver.cpp:106] Iteration 13700, lr = 0.00957187
I0630 02:52:12.895251 29777 solver.cpp:290] Iteration 13800 (6.24624 iter/s, 16.0096s/100 iter), loss = 0.702381
I0630 02:52:12.895303 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 02:52:12.895311 29777 sgd_solver.cpp:106] Iteration 13800, lr = 0.00956875
I0630 02:52:28.804695 29777 solver.cpp:290] Iteration 13900 (6.28577 iter/s, 15.909s/100 iter), loss = 1.19048
I0630 02:52:28.804718 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 02:52:28.804724 29777 sgd_solver.cpp:106] Iteration 13900, lr = 0.00956563
I0630 02:52:44.579962 29777 solver.cpp:354] Sparsity after update:
I0630 02:52:44.581421 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:52:44.581429 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:52:44.581439 29777 net.cpp:1851] conv1b_param_0(0.0699) 
I0630 02:52:44.581444 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:52:44.581449 29777 net.cpp:1851] res2a_branch2a_param_0(0.07) 
I0630 02:52:44.581454 29777 net.cpp:1851] res2a_branch2b_param_0(0.07) 
I0630 02:52:44.581457 29777 net.cpp:1851] res3a_branch2a_param_0(0.07) 
I0630 02:52:44.581461 29777 net.cpp:1851] res3a_branch2b_param_0(0.07) 
I0630 02:52:44.581465 29777 net.cpp:1851] res4a_branch2a_param_0(0.07) 
I0630 02:52:44.581470 29777 net.cpp:1851] res4a_branch2b_param_0(0.07) 
I0630 02:52:44.581473 29777 net.cpp:1851] res5a_branch2a_param_0(0.07) 
I0630 02:52:44.581477 29777 net.cpp:1851] res5a_branch2b_param_0(0.07) 
I0630 02:52:44.581481 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (164652/2.86678e+06) 0.0574
I0630 02:52:44.581573 29777 solver.cpp:471] Iteration 14000, Testing net (#0)
I0630 02:52:46.026688 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:53:34.087837 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54432
I0630 02:53:34.087963 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.785821
I0630 02:53:34.087976 29777 solver.cpp:544]     Test net output #2: loss = 1.63656 (* 1 = 1.63656 loss)
I0630 02:53:34.291817 29777 solver.cpp:290] Iteration 14000 (1.52706 iter/s, 65.4853s/100 iter), loss = 1.13095
I0630 02:53:34.291841 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 02:53:34.291849 29777 sgd_solver.cpp:106] Iteration 14000, lr = 0.0095625
I0630 02:53:34.292564 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.08
I0630 02:53:34.418615 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 02:53:50.466578 29777 solver.cpp:290] Iteration 14100 (6.18265 iter/s, 16.1743s/100 iter), loss = 1.13095
I0630 02:53:50.466601 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 02:53:50.466610 29777 sgd_solver.cpp:106] Iteration 14100, lr = 0.00955938
I0630 02:54:06.452538 29777 solver.cpp:290] Iteration 14200 (6.25567 iter/s, 15.9855s/100 iter), loss = 1.13095
I0630 02:54:06.452594 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 02:54:06.452615 29777 sgd_solver.cpp:106] Iteration 14200, lr = 0.00955625
I0630 02:54:22.632446 29777 solver.cpp:290] Iteration 14300 (6.1807 iter/s, 16.1794s/100 iter), loss = 0.880952
I0630 02:54:22.632469 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 02:54:22.632475 29777 sgd_solver.cpp:106] Iteration 14300, lr = 0.00955313
I0630 02:54:38.834691 29777 solver.cpp:290] Iteration 14400 (6.17216 iter/s, 16.2018s/100 iter), loss = 1.25
I0630 02:54:38.834802 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 02:54:38.834817 29777 sgd_solver.cpp:106] Iteration 14400, lr = 0.00955
I0630 02:54:54.903993 29777 solver.cpp:290] Iteration 14500 (6.22326 iter/s, 16.0688s/100 iter), loss = 0.892857
I0630 02:54:54.904027 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 02:54:54.904037 29777 sgd_solver.cpp:106] Iteration 14500, lr = 0.00954687
I0630 02:55:10.958890 29777 solver.cpp:290] Iteration 14600 (6.22881 iter/s, 16.0544s/100 iter), loss = 1.25
I0630 02:55:10.958963 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 02:55:10.958971 29777 sgd_solver.cpp:106] Iteration 14600, lr = 0.00954375
I0630 02:55:26.915038 29777 solver.cpp:290] Iteration 14700 (6.26738 iter/s, 15.9556s/100 iter), loss = 1.02381
I0630 02:55:26.915065 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 02:55:26.915073 29777 sgd_solver.cpp:106] Iteration 14700, lr = 0.00954062
I0630 02:55:43.015753 29777 solver.cpp:290] Iteration 14800 (6.21108 iter/s, 16.1002s/100 iter), loss = 1.36905
I0630 02:55:43.015830 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 02:55:43.015841 29777 sgd_solver.cpp:106] Iteration 14800, lr = 0.0095375
I0630 02:55:59.214376 29777 solver.cpp:290] Iteration 14900 (6.17356 iter/s, 16.1981s/100 iter), loss = 1.19048
I0630 02:55:59.214399 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 02:55:59.214406 29777 sgd_solver.cpp:106] Iteration 14900, lr = 0.00953437
I0630 02:56:14.996541 29777 solver.cpp:354] Sparsity after update:
I0630 02:56:15.016903 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:56:15.016919 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:56:15.016929 29777 net.cpp:1851] conv1b_param_0(0.0799) 
I0630 02:56:15.016933 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:56:15.016937 29777 net.cpp:1851] res2a_branch2a_param_0(0.0799) 
I0630 02:56:15.016940 29777 net.cpp:1851] res2a_branch2b_param_0(0.08) 
I0630 02:56:15.016944 29777 net.cpp:1851] res3a_branch2a_param_0(0.08) 
I0630 02:56:15.016947 29777 net.cpp:1851] res3a_branch2b_param_0(0.08) 
I0630 02:56:15.016950 29777 net.cpp:1851] res4a_branch2a_param_0(0.08) 
I0630 02:56:15.016953 29777 net.cpp:1851] res4a_branch2b_param_0(0.08) 
I0630 02:56:15.016957 29777 net.cpp:1851] res5a_branch2a_param_0(0.08) 
I0630 02:56:15.016960 29777 net.cpp:1851] res5a_branch2b_param_0(0.08) 
I0630 02:56:15.016963 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (188166/2.86678e+06) 0.0656
I0630 02:56:15.174706 29777 solver.cpp:290] Iteration 15000 (6.26572 iter/s, 15.9599s/100 iter), loss = 0.821429
I0630 02:56:15.174729 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 02:56:15.174736 29777 sgd_solver.cpp:106] Iteration 15000, lr = 0.00953125
I0630 02:56:31.191126 29777 solver.cpp:290] Iteration 15100 (6.24377 iter/s, 16.016s/100 iter), loss = 1.45238
I0630 02:56:31.191148 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 02:56:31.191154 29777 sgd_solver.cpp:106] Iteration 15100, lr = 0.00952812
I0630 02:56:47.123463 29777 solver.cpp:290] Iteration 15200 (6.27672 iter/s, 15.9319s/100 iter), loss = 0.988095
I0630 02:56:47.123534 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 02:56:47.123548 29777 sgd_solver.cpp:106] Iteration 15200, lr = 0.009525
I0630 02:57:03.084118 29777 solver.cpp:290] Iteration 15300 (6.26561 iter/s, 15.9601s/100 iter), loss = 0.952381
I0630 02:57:03.084141 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 02:57:03.084148 29777 sgd_solver.cpp:106] Iteration 15300, lr = 0.00952187
I0630 02:57:19.104481 29777 solver.cpp:290] Iteration 15400 (6.24224 iter/s, 16.0199s/100 iter), loss = 1.35714
I0630 02:57:19.104583 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 02:57:19.104593 29777 sgd_solver.cpp:106] Iteration 15400, lr = 0.00951875
I0630 02:57:35.128036 29777 solver.cpp:290] Iteration 15500 (6.24102 iter/s, 16.023s/100 iter), loss = 1.15476
I0630 02:57:35.128058 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 02:57:35.128064 29777 sgd_solver.cpp:106] Iteration 15500, lr = 0.00951563
I0630 02:57:51.040678 29777 solver.cpp:290] Iteration 15600 (6.28449 iter/s, 15.9122s/100 iter), loss = 1.04762
I0630 02:57:51.040765 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 02:57:51.040771 29777 sgd_solver.cpp:106] Iteration 15600, lr = 0.0095125
I0630 02:58:07.072262 29777 solver.cpp:290] Iteration 15700 (6.23789 iter/s, 16.0311s/100 iter), loss = 1.34524
I0630 02:58:07.072283 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 02:58:07.072290 29777 sgd_solver.cpp:106] Iteration 15700, lr = 0.00950938
I0630 02:58:23.183152 29777 solver.cpp:290] Iteration 15800 (6.20716 iter/s, 16.1104s/100 iter), loss = 0.916667
I0630 02:58:23.183254 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 02:58:23.183262 29777 sgd_solver.cpp:106] Iteration 15800, lr = 0.00950625
I0630 02:58:39.322104 29777 solver.cpp:290] Iteration 15900 (6.1964 iter/s, 16.1384s/100 iter), loss = 1.13095
I0630 02:58:39.322125 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 02:58:39.322134 29777 sgd_solver.cpp:106] Iteration 15900, lr = 0.00950312
I0630 02:58:55.185400 29777 solver.cpp:354] Sparsity after update:
I0630 02:58:55.186856 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 02:58:55.186862 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 02:58:55.186870 29777 net.cpp:1851] conv1b_param_0(0.0799) 
I0630 02:58:55.186873 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 02:58:55.186875 29777 net.cpp:1851] res2a_branch2a_param_0(0.0799) 
I0630 02:58:55.186877 29777 net.cpp:1851] res2a_branch2b_param_0(0.08) 
I0630 02:58:55.186880 29777 net.cpp:1851] res3a_branch2a_param_0(0.08) 
I0630 02:58:55.186882 29777 net.cpp:1851] res3a_branch2b_param_0(0.08) 
I0630 02:58:55.186884 29777 net.cpp:1851] res4a_branch2a_param_0(0.08) 
I0630 02:58:55.186887 29777 net.cpp:1851] res4a_branch2b_param_0(0.08) 
I0630 02:58:55.186888 29777 net.cpp:1851] res5a_branch2a_param_0(0.08) 
I0630 02:58:55.186892 29777 net.cpp:1851] res5a_branch2b_param_0(0.08) 
I0630 02:58:55.186893 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (188166/2.86678e+06) 0.0656
I0630 02:58:55.186980 29777 solver.cpp:471] Iteration 16000, Testing net (#0)
I0630 02:58:56.805533 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 02:59:44.197516 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54232
I0630 02:59:44.197633 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.783621
I0630 02:59:44.197643 29777 solver.cpp:544]     Test net output #2: loss = 1.63826 (* 1 = 1.63826 loss)
I0630 02:59:44.392650 29777 solver.cpp:290] Iteration 16000 (1.53684 iter/s, 65.0688s/100 iter), loss = 1.25
I0630 02:59:44.392675 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 02:59:44.392683 29777 sgd_solver.cpp:106] Iteration 16000, lr = 0.0095
I0630 02:59:44.393425 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.09
I0630 02:59:44.517319 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:00:00.642909 29777 solver.cpp:290] Iteration 16100 (6.15393 iter/s, 16.2498s/100 iter), loss = 1.10714
I0630 03:00:00.642931 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 03:00:00.642938 29777 sgd_solver.cpp:106] Iteration 16100, lr = 0.00949687
I0630 03:00:16.681254 29777 solver.cpp:290] Iteration 16200 (6.23524 iter/s, 16.0379s/100 iter), loss = 0.880952
I0630 03:00:16.681305 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:00:16.681313 29777 sgd_solver.cpp:106] Iteration 16200, lr = 0.00949375
I0630 03:00:32.685703 29777 solver.cpp:290] Iteration 16300 (6.24845 iter/s, 16.004s/100 iter), loss = 1.05952
I0630 03:00:32.685727 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 03:00:32.685734 29777 sgd_solver.cpp:106] Iteration 16300, lr = 0.00949063
I0630 03:00:48.633235 29777 solver.cpp:290] Iteration 16400 (6.27075 iter/s, 15.9471s/100 iter), loss = 1.10714
I0630 03:00:48.633327 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:00:48.633338 29777 sgd_solver.cpp:106] Iteration 16400, lr = 0.0094875
I0630 03:01:04.640962 29777 solver.cpp:290] Iteration 16500 (6.24719 iter/s, 16.0072s/100 iter), loss = 0.964286
I0630 03:01:04.640986 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:01:04.640993 29777 sgd_solver.cpp:106] Iteration 16500, lr = 0.00948437
I0630 03:01:20.629077 29777 solver.cpp:290] Iteration 16600 (6.25483 iter/s, 15.9876s/100 iter), loss = 1.02381
I0630 03:01:20.629163 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:01:20.629175 29777 sgd_solver.cpp:106] Iteration 16600, lr = 0.00948125
I0630 03:01:36.659951 29777 solver.cpp:290] Iteration 16700 (6.23817 iter/s, 16.0304s/100 iter), loss = 1.41667
I0630 03:01:36.659974 29777 solver.cpp:309]     Train net output #0: loss = 1.85714 (* 1 = 1.85714 loss)
I0630 03:01:36.659981 29777 sgd_solver.cpp:106] Iteration 16700, lr = 0.00947812
I0630 03:01:52.631623 29777 solver.cpp:290] Iteration 16800 (6.26127 iter/s, 15.9712s/100 iter), loss = 0.857143
I0630 03:01:52.631726 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:01:52.631741 29777 sgd_solver.cpp:106] Iteration 16800, lr = 0.009475
I0630 03:02:08.590171 29777 solver.cpp:290] Iteration 16900 (6.26645 iter/s, 15.958s/100 iter), loss = 0.630952
I0630 03:02:08.590195 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:02:08.590203 29777 sgd_solver.cpp:106] Iteration 16900, lr = 0.00947187
I0630 03:02:24.418458 29777 solver.cpp:354] Sparsity after update:
I0630 03:02:24.438814 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:02:24.438832 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:02:24.438846 29777 net.cpp:1851] conv1b_param_0(0.0898) 
I0630 03:02:24.438860 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:02:24.438869 29777 net.cpp:1851] res2a_branch2a_param_0(0.09) 
I0630 03:02:24.438879 29777 net.cpp:1851] res2a_branch2b_param_0(0.09) 
I0630 03:02:24.438890 29777 net.cpp:1851] res3a_branch2a_param_0(0.09) 
I0630 03:02:24.438896 29777 net.cpp:1851] res3a_branch2b_param_0(0.09) 
I0630 03:02:24.438905 29777 net.cpp:1851] res4a_branch2a_param_0(0.09) 
I0630 03:02:24.438915 29777 net.cpp:1851] res4a_branch2b_param_0(0.09) 
I0630 03:02:24.438920 29777 net.cpp:1851] res5a_branch2a_param_0(0.09) 
I0630 03:02:24.438925 29777 net.cpp:1851] res5a_branch2b_param_0(0.09) 
I0630 03:02:24.438932 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (211694/2.86678e+06) 0.0738
I0630 03:02:24.595706 29777 solver.cpp:290] Iteration 17000 (6.24802 iter/s, 16.0051s/100 iter), loss = 1
I0630 03:02:24.595729 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 03:02:24.595736 29777 sgd_solver.cpp:106] Iteration 17000, lr = 0.00946875
I0630 03:02:40.614715 29777 solver.cpp:290] Iteration 17100 (6.24276 iter/s, 16.0185s/100 iter), loss = 1.2381
I0630 03:02:40.614737 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:02:40.614744 29777 sgd_solver.cpp:106] Iteration 17100, lr = 0.00946563
I0630 03:02:56.543800 29777 solver.cpp:290] Iteration 17200 (6.27801 iter/s, 15.9286s/100 iter), loss = 1.20238
I0630 03:02:56.543895 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 03:02:56.543905 29777 sgd_solver.cpp:106] Iteration 17200, lr = 0.0094625
I0630 03:03:12.645879 29777 solver.cpp:290] Iteration 17300 (6.21058 iter/s, 16.1015s/100 iter), loss = 1.16667
I0630 03:03:12.645900 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:03:12.645906 29777 sgd_solver.cpp:106] Iteration 17300, lr = 0.00945937
I0630 03:03:28.623194 29777 solver.cpp:290] Iteration 17400 (6.25906 iter/s, 15.9768s/100 iter), loss = 0.833333
I0630 03:03:28.623330 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:03:28.623363 29777 sgd_solver.cpp:106] Iteration 17400, lr = 0.00945625
I0630 03:03:44.858052 29777 solver.cpp:290] Iteration 17500 (6.1598 iter/s, 16.2343s/100 iter), loss = 0.845238
I0630 03:03:44.858078 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:03:44.858085 29777 sgd_solver.cpp:106] Iteration 17500, lr = 0.00945312
I0630 03:04:00.970170 29777 solver.cpp:290] Iteration 17600 (6.20669 iter/s, 16.1116s/100 iter), loss = 0.988095
I0630 03:04:00.970283 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:04:00.970293 29777 sgd_solver.cpp:106] Iteration 17600, lr = 0.00945
I0630 03:04:17.207590 29777 solver.cpp:290] Iteration 17700 (6.15882 iter/s, 16.2369s/100 iter), loss = 1.07143
I0630 03:04:17.207613 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 03:04:17.207620 29777 sgd_solver.cpp:106] Iteration 17700, lr = 0.00944687
I0630 03:04:33.385439 29777 solver.cpp:290] Iteration 17800 (6.18147 iter/s, 16.1774s/100 iter), loss = 1.19048
I0630 03:04:33.385534 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:04:33.385545 29777 sgd_solver.cpp:106] Iteration 17800, lr = 0.00944375
I0630 03:04:49.386541 29777 solver.cpp:290] Iteration 17900 (6.24978 iter/s, 16.0006s/100 iter), loss = 1.17857
I0630 03:04:49.386565 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 03:04:49.386581 29777 sgd_solver.cpp:106] Iteration 17900, lr = 0.00944062
I0630 03:05:05.437439 29777 solver.cpp:354] Sparsity after update:
I0630 03:05:05.438724 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:05:05.438731 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:05:05.438738 29777 net.cpp:1851] conv1b_param_0(0.0898) 
I0630 03:05:05.438742 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:05:05.438745 29777 net.cpp:1851] res2a_branch2a_param_0(0.09) 
I0630 03:05:05.438747 29777 net.cpp:1851] res2a_branch2b_param_0(0.09) 
I0630 03:05:05.438750 29777 net.cpp:1851] res3a_branch2a_param_0(0.09) 
I0630 03:05:05.438752 29777 net.cpp:1851] res3a_branch2b_param_0(0.09) 
I0630 03:05:05.438755 29777 net.cpp:1851] res4a_branch2a_param_0(0.09) 
I0630 03:05:05.438757 29777 net.cpp:1851] res4a_branch2b_param_0(0.09) 
I0630 03:05:05.438760 29777 net.cpp:1851] res5a_branch2a_param_0(0.09) 
I0630 03:05:05.438762 29777 net.cpp:1851] res5a_branch2b_param_0(0.09) 
I0630 03:05:05.438765 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (211694/2.86678e+06) 0.0738
I0630 03:05:05.438855 29777 solver.cpp:471] Iteration 18000, Testing net (#0)
I0630 03:05:07.488678 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:05:55.181005 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.52388
I0630 03:05:55.181079 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.773161
I0630 03:05:55.181087 29777 solver.cpp:544]     Test net output #2: loss = 1.73908 (* 1 = 1.73908 loss)
I0630 03:05:55.356158 29777 solver.cpp:290] Iteration 18000 (1.51589 iter/s, 65.9678s/100 iter), loss = 1.20238
I0630 03:05:55.356182 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 03:05:55.356189 29777 sgd_solver.cpp:106] Iteration 18000, lr = 0.0094375
I0630 03:05:55.356865 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.1
I0630 03:05:55.483129 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:06:11.386868 29777 solver.cpp:290] Iteration 18100 (6.23821 iter/s, 16.0302s/100 iter), loss = 1.46429
I0630 03:06:11.386942 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 03:06:11.386970 29777 sgd_solver.cpp:106] Iteration 18100, lr = 0.00943437
I0630 03:06:27.347118 29777 solver.cpp:290] Iteration 18200 (6.26577 iter/s, 15.9597s/100 iter), loss = 1.28571
I0630 03:06:27.347208 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 03:06:27.347218 29777 sgd_solver.cpp:106] Iteration 18200, lr = 0.00943125
I0630 03:06:43.337422 29777 solver.cpp:290] Iteration 18300 (6.254 iter/s, 15.9898s/100 iter), loss = 0.845238
I0630 03:06:43.337445 29777 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0630 03:06:43.337452 29777 sgd_solver.cpp:106] Iteration 18300, lr = 0.00942812
I0630 03:06:59.284631 29777 solver.cpp:290] Iteration 18400 (6.27087 iter/s, 15.9467s/100 iter), loss = 0.761905
I0630 03:06:59.284744 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 03:06:59.284754 29777 sgd_solver.cpp:106] Iteration 18400, lr = 0.009425
I0630 03:07:15.320431 29777 solver.cpp:290] Iteration 18500 (6.23626 iter/s, 16.0352s/100 iter), loss = 1.2381
I0630 03:07:15.320457 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 03:07:15.320466 29777 sgd_solver.cpp:106] Iteration 18500, lr = 0.00942187
I0630 03:07:31.214617 29777 solver.cpp:290] Iteration 18600 (6.29179 iter/s, 15.8937s/100 iter), loss = 1.13095
I0630 03:07:31.214726 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:07:31.214735 29777 sgd_solver.cpp:106] Iteration 18600, lr = 0.00941875
I0630 03:07:47.153111 29777 solver.cpp:290] Iteration 18700 (6.27433 iter/s, 15.938s/100 iter), loss = 1.28571
I0630 03:07:47.153133 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:07:47.153141 29777 sgd_solver.cpp:106] Iteration 18700, lr = 0.00941562
I0630 03:08:03.119881 29777 solver.cpp:290] Iteration 18800 (6.26319 iter/s, 15.9663s/100 iter), loss = 1.03571
I0630 03:08:03.119945 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 03:08:03.119957 29777 sgd_solver.cpp:106] Iteration 18800, lr = 0.0094125
I0630 03:08:19.082633 29777 solver.cpp:290] Iteration 18900 (6.26478 iter/s, 15.9623s/100 iter), loss = 1.07143
I0630 03:08:19.082659 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:08:19.082667 29777 sgd_solver.cpp:106] Iteration 18900, lr = 0.00940937
I0630 03:08:34.896169 29777 solver.cpp:354] Sparsity after update:
I0630 03:08:34.916573 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:08:34.916585 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:08:34.916594 29777 net.cpp:1851] conv1b_param_0(0.0998) 
I0630 03:08:34.916596 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:08:34.916599 29777 net.cpp:1851] res2a_branch2a_param_0(0.1) 
I0630 03:08:34.916601 29777 net.cpp:1851] res2a_branch2b_param_0(0.0999) 
I0630 03:08:34.916604 29777 net.cpp:1851] res3a_branch2a_param_0(0.1) 
I0630 03:08:34.916605 29777 net.cpp:1851] res3a_branch2b_param_0(0.1) 
I0630 03:08:34.916607 29777 net.cpp:1851] res4a_branch2a_param_0(0.1) 
I0630 03:08:34.916616 29777 net.cpp:1851] res4a_branch2b_param_0(0.1) 
I0630 03:08:34.916618 29777 net.cpp:1851] res5a_branch2a_param_0(0.1) 
I0630 03:08:34.916620 29777 net.cpp:1851] res5a_branch2b_param_0(0.1) 
I0630 03:08:34.916622 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (235222/2.86678e+06) 0.0821
I0630 03:08:35.082058 29777 solver.cpp:290] Iteration 19000 (6.25041 iter/s, 15.999s/100 iter), loss = 1.95238
I0630 03:08:35.082082 29777 solver.cpp:309]     Train net output #0: loss = 2.66667 (* 1 = 2.66667 loss)
I0630 03:08:35.082088 29777 sgd_solver.cpp:106] Iteration 19000, lr = 0.00940625
I0630 03:08:51.118062 29777 solver.cpp:290] Iteration 19100 (6.23615 iter/s, 16.0355s/100 iter), loss = 0.97619
I0630 03:08:51.118085 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 03:08:51.118091 29777 sgd_solver.cpp:106] Iteration 19100, lr = 0.00940312
I0630 03:09:07.097332 29777 solver.cpp:290] Iteration 19200 (6.25829 iter/s, 15.9788s/100 iter), loss = 0.714286
I0630 03:09:07.097440 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 03:09:07.097450 29777 sgd_solver.cpp:106] Iteration 19200, lr = 0.0094
I0630 03:09:23.221707 29777 solver.cpp:290] Iteration 19300 (6.202 iter/s, 16.1238s/100 iter), loss = 0.988095
I0630 03:09:23.221735 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:09:23.221745 29777 sgd_solver.cpp:106] Iteration 19300, lr = 0.00939687
I0630 03:09:39.469307 29777 solver.cpp:290] Iteration 19400 (6.15494 iter/s, 16.2471s/100 iter), loss = 0.988095
I0630 03:09:39.469418 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:09:39.469439 29777 sgd_solver.cpp:106] Iteration 19400, lr = 0.00939375
I0630 03:09:55.434504 29777 solver.cpp:290] Iteration 19500 (6.26384 iter/s, 15.9647s/100 iter), loss = 1.10714
I0630 03:09:55.434526 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:09:55.434532 29777 sgd_solver.cpp:106] Iteration 19500, lr = 0.00939062
I0630 03:10:11.464148 29777 solver.cpp:290] Iteration 19600 (6.23862 iter/s, 16.0292s/100 iter), loss = 1.30952
I0630 03:10:11.464761 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 03:10:11.464771 29777 sgd_solver.cpp:106] Iteration 19600, lr = 0.0093875
I0630 03:10:27.414158 29777 solver.cpp:290] Iteration 19700 (6.27 iter/s, 15.949s/100 iter), loss = 0.916667
I0630 03:10:27.414182 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 03:10:27.414189 29777 sgd_solver.cpp:106] Iteration 19700, lr = 0.00938438
I0630 03:10:43.404683 29777 solver.cpp:290] Iteration 19800 (6.25388 iter/s, 15.9901s/100 iter), loss = 1.32143
I0630 03:10:43.404786 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:10:43.404795 29777 sgd_solver.cpp:106] Iteration 19800, lr = 0.00938125
I0630 03:10:59.346397 29777 solver.cpp:290] Iteration 19900 (6.27306 iter/s, 15.9412s/100 iter), loss = 1.33333
I0630 03:10:59.346420 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:10:59.346426 29777 sgd_solver.cpp:106] Iteration 19900, lr = 0.00937812
I0630 03:11:15.153998 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_20000.caffemodel
I0630 03:11:15.173892 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_20000.solverstate
I0630 03:11:15.182598 29777 solver.cpp:354] Sparsity after update:
I0630 03:11:15.183598 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:11:15.183606 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:11:15.183614 29777 net.cpp:1851] conv1b_param_0(0.0998) 
I0630 03:11:15.183616 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:11:15.183619 29777 net.cpp:1851] res2a_branch2a_param_0(0.1) 
I0630 03:11:15.183620 29777 net.cpp:1851] res2a_branch2b_param_0(0.0999) 
I0630 03:11:15.183622 29777 net.cpp:1851] res3a_branch2a_param_0(0.1) 
I0630 03:11:15.183624 29777 net.cpp:1851] res3a_branch2b_param_0(0.1) 
I0630 03:11:15.183626 29777 net.cpp:1851] res4a_branch2a_param_0(0.1) 
I0630 03:11:15.183629 29777 net.cpp:1851] res4a_branch2b_param_0(0.1) 
I0630 03:11:15.183630 29777 net.cpp:1851] res5a_branch2a_param_0(0.1) 
I0630 03:11:15.183632 29777 net.cpp:1851] res5a_branch2b_param_0(0.1) 
I0630 03:11:15.183634 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (235222/2.86678e+06) 0.0821
I0630 03:11:15.183728 29777 solver.cpp:471] Iteration 20000, Testing net (#0)
I0630 03:11:17.202011 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:12:05.602286 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.555359
I0630 03:12:05.602402 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.794901
I0630 03:12:05.602411 29777 solver.cpp:544]     Test net output #2: loss = 1.60594 (* 1 = 1.60594 loss)
I0630 03:12:05.785555 29777 solver.cpp:290] Iteration 20000 (1.50518 iter/s, 66.4373s/100 iter), loss = 1.57143
I0630 03:12:05.785583 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 03:12:05.785591 29777 sgd_solver.cpp:106] Iteration 20000, lr = 0.009375
I0630 03:12:05.786551 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.11
I0630 03:12:05.911828 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:12:21.849020 29777 solver.cpp:290] Iteration 20100 (6.22549 iter/s, 16.063s/100 iter), loss = 1.02381
I0630 03:12:21.849046 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 03:12:21.849056 29777 sgd_solver.cpp:106] Iteration 20100, lr = 0.00937187
I0630 03:12:37.851404 29777 solver.cpp:290] Iteration 20200 (6.24925 iter/s, 16.0019s/100 iter), loss = 0.97619
I0630 03:12:37.851506 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:12:37.851516 29777 sgd_solver.cpp:106] Iteration 20200, lr = 0.00936875
I0630 03:12:53.850611 29777 solver.cpp:290] Iteration 20300 (6.25052 iter/s, 15.9987s/100 iter), loss = 1.2381
I0630 03:12:53.850636 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 03:12:53.850643 29777 sgd_solver.cpp:106] Iteration 20300, lr = 0.00936562
I0630 03:13:09.748147 29777 solver.cpp:290] Iteration 20400 (6.29047 iter/s, 15.8971s/100 iter), loss = 1.04762
I0630 03:13:09.748224 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:13:09.748230 29777 sgd_solver.cpp:106] Iteration 20400, lr = 0.0093625
I0630 03:13:25.734309 29777 solver.cpp:290] Iteration 20500 (6.25561 iter/s, 15.9856s/100 iter), loss = 1.03571
I0630 03:13:25.734334 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:13:25.734344 29777 sgd_solver.cpp:106] Iteration 20500, lr = 0.00935937
I0630 03:13:41.739518 29777 solver.cpp:290] Iteration 20600 (6.24815 iter/s, 16.0047s/100 iter), loss = 1.08333
I0630 03:13:41.739632 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 03:13:41.739641 29777 sgd_solver.cpp:106] Iteration 20600, lr = 0.00935625
I0630 03:13:57.721748 29777 solver.cpp:290] Iteration 20700 (6.25717 iter/s, 15.9817s/100 iter), loss = 1.41667
I0630 03:13:57.721772 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:13:57.721779 29777 sgd_solver.cpp:106] Iteration 20700, lr = 0.00935312
I0630 03:14:13.908562 29777 solver.cpp:290] Iteration 20800 (6.17805 iter/s, 16.1863s/100 iter), loss = 1.41667
I0630 03:14:13.908658 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 03:14:13.908668 29777 sgd_solver.cpp:106] Iteration 20800, lr = 0.00935
I0630 03:14:30.046999 29777 solver.cpp:290] Iteration 20900 (6.19659 iter/s, 16.1379s/100 iter), loss = 1.25
I0630 03:14:30.047020 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 03:14:30.047027 29777 sgd_solver.cpp:106] Iteration 20900, lr = 0.00934687
I0630 03:14:46.006111 29777 solver.cpp:354] Sparsity after update:
I0630 03:14:46.026659 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:14:46.026676 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:14:46.026686 29777 net.cpp:1851] conv1b_param_0(0.11) 
I0630 03:14:46.026690 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:14:46.026693 29777 net.cpp:1851] res2a_branch2a_param_0(0.11) 
I0630 03:14:46.026697 29777 net.cpp:1851] res2a_branch2b_param_0(0.11) 
I0630 03:14:46.026700 29777 net.cpp:1851] res3a_branch2a_param_0(0.11) 
I0630 03:14:46.026705 29777 net.cpp:1851] res3a_branch2b_param_0(0.11) 
I0630 03:14:46.026707 29777 net.cpp:1851] res4a_branch2a_param_0(0.11) 
I0630 03:14:46.026710 29777 net.cpp:1851] res4a_branch2b_param_0(0.11) 
I0630 03:14:46.026713 29777 net.cpp:1851] res5a_branch2a_param_0(0.11) 
I0630 03:14:46.026717 29777 net.cpp:1851] res5a_branch2b_param_0(0.11) 
I0630 03:14:46.026721 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (258746/2.86678e+06) 0.0903
I0630 03:14:46.186498 29777 solver.cpp:290] Iteration 21000 (6.19616 iter/s, 16.139s/100 iter), loss = 1.0119
I0630 03:14:46.186522 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:14:46.186529 29777 sgd_solver.cpp:106] Iteration 21000, lr = 0.00934375
I0630 03:15:02.242038 29777 solver.cpp:290] Iteration 21100 (6.22856 iter/s, 16.0551s/100 iter), loss = 1.03571
I0630 03:15:02.242061 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:15:02.242069 29777 sgd_solver.cpp:106] Iteration 21100, lr = 0.00934062
I0630 03:15:18.436229 29777 solver.cpp:290] Iteration 21200 (6.17524 iter/s, 16.1937s/100 iter), loss = 1.20238
I0630 03:15:18.436322 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 03:15:18.436337 29777 sgd_solver.cpp:106] Iteration 21200, lr = 0.0093375
I0630 03:15:34.472939 29777 solver.cpp:290] Iteration 21300 (6.2359 iter/s, 16.0362s/100 iter), loss = 1
I0630 03:15:34.472965 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 03:15:34.472971 29777 sgd_solver.cpp:106] Iteration 21300, lr = 0.00933437
I0630 03:15:50.515130 29777 solver.cpp:290] Iteration 21400 (6.23374 iter/s, 16.0417s/100 iter), loss = 1.07143
I0630 03:15:50.515234 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:15:50.515244 29777 sgd_solver.cpp:106] Iteration 21400, lr = 0.00933125
I0630 03:16:06.530128 29777 solver.cpp:290] Iteration 21500 (6.24436 iter/s, 16.0145s/100 iter), loss = 1.08333
I0630 03:16:06.530153 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:16:06.530161 29777 sgd_solver.cpp:106] Iteration 21500, lr = 0.00932813
I0630 03:16:22.517165 29777 solver.cpp:290] Iteration 21600 (6.25525 iter/s, 15.9866s/100 iter), loss = 1.59524
I0630 03:16:22.517269 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 03:16:22.517282 29777 sgd_solver.cpp:106] Iteration 21600, lr = 0.009325
I0630 03:16:38.605515 29777 solver.cpp:290] Iteration 21700 (6.21589 iter/s, 16.0878s/100 iter), loss = 1.04762
I0630 03:16:38.605538 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:16:38.605545 29777 sgd_solver.cpp:106] Iteration 21700, lr = 0.00932187
I0630 03:16:54.538547 29777 solver.cpp:290] Iteration 21800 (6.27645 iter/s, 15.9326s/100 iter), loss = 1.05952
I0630 03:16:54.538622 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:16:54.538638 29777 sgd_solver.cpp:106] Iteration 21800, lr = 0.00931875
I0630 03:17:10.500855 29777 solver.cpp:290] Iteration 21900 (6.26496 iter/s, 15.9618s/100 iter), loss = 0.988095
I0630 03:17:10.500881 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:17:10.500890 29777 sgd_solver.cpp:106] Iteration 21900, lr = 0.00931562
I0630 03:17:26.370270 29777 solver.cpp:354] Sparsity after update:
I0630 03:17:26.371704 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:17:26.371713 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:17:26.371721 29777 net.cpp:1851] conv1b_param_0(0.11) 
I0630 03:17:26.371726 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:17:26.371731 29777 net.cpp:1851] res2a_branch2a_param_0(0.11) 
I0630 03:17:26.371736 29777 net.cpp:1851] res2a_branch2b_param_0(0.11) 
I0630 03:17:26.371739 29777 net.cpp:1851] res3a_branch2a_param_0(0.11) 
I0630 03:17:26.371744 29777 net.cpp:1851] res3a_branch2b_param_0(0.11) 
I0630 03:17:26.371748 29777 net.cpp:1851] res4a_branch2a_param_0(0.11) 
I0630 03:17:26.371752 29777 net.cpp:1851] res4a_branch2b_param_0(0.11) 
I0630 03:17:26.371757 29777 net.cpp:1851] res5a_branch2a_param_0(0.11) 
I0630 03:17:26.371762 29777 net.cpp:1851] res5a_branch2b_param_0(0.11) 
I0630 03:17:26.371765 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (258746/2.86678e+06) 0.0903
I0630 03:17:26.371904 29777 solver.cpp:471] Iteration 22000, Testing net (#0)
I0630 03:17:28.611560 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:18:15.730875 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55792
I0630 03:18:15.730931 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.795961
I0630 03:18:15.730938 29777 solver.cpp:544]     Test net output #2: loss = 1.56708 (* 1 = 1.56708 loss)
I0630 03:18:15.909557 29777 solver.cpp:290] Iteration 22000 (1.52889 iter/s, 65.4069s/100 iter), loss = 0.904762
I0630 03:18:15.909581 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 03:18:15.909588 29777 sgd_solver.cpp:106] Iteration 22000, lr = 0.0093125
I0630 03:18:15.910293 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.12
I0630 03:18:16.040550 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:18:31.911911 29777 solver.cpp:290] Iteration 22100 (6.24926 iter/s, 16.0019s/100 iter), loss = 1.08333
I0630 03:18:31.911934 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 03:18:31.911943 29777 sgd_solver.cpp:106] Iteration 22100, lr = 0.00930937
I0630 03:18:48.055186 29777 solver.cpp:290] Iteration 22200 (6.19471 iter/s, 16.1428s/100 iter), loss = 1.19048
I0630 03:18:48.055258 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:18:48.055265 29777 sgd_solver.cpp:106] Iteration 22200, lr = 0.00930625
I0630 03:19:04.105777 29777 solver.cpp:290] Iteration 22300 (6.2305 iter/s, 16.0501s/100 iter), loss = 0.916667
I0630 03:19:04.105799 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:19:04.105806 29777 sgd_solver.cpp:106] Iteration 22300, lr = 0.00930312
I0630 03:19:20.269294 29777 solver.cpp:290] Iteration 22400 (6.18695 iter/s, 16.163s/100 iter), loss = 1.20238
I0630 03:19:20.269403 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:19:20.269413 29777 sgd_solver.cpp:106] Iteration 22400, lr = 0.0093
I0630 03:19:36.277614 29777 solver.cpp:290] Iteration 22500 (6.24697 iter/s, 16.0078s/100 iter), loss = 0.916667
I0630 03:19:36.277642 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 03:19:36.277658 29777 sgd_solver.cpp:106] Iteration 22500, lr = 0.00929687
I0630 03:19:52.262001 29777 solver.cpp:290] Iteration 22600 (6.25629 iter/s, 15.9839s/100 iter), loss = 1.10714
I0630 03:19:52.262270 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:19:52.262280 29777 sgd_solver.cpp:106] Iteration 22600, lr = 0.00929375
I0630 03:20:08.266427 29777 solver.cpp:290] Iteration 22700 (6.24855 iter/s, 16.0037s/100 iter), loss = 0.964286
I0630 03:20:08.266454 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:20:08.266470 29777 sgd_solver.cpp:106] Iteration 22700, lr = 0.00929062
I0630 03:20:24.261739 29777 solver.cpp:290] Iteration 22800 (6.25201 iter/s, 15.9948s/100 iter), loss = 0.97619
I0630 03:20:24.261812 29777 solver.cpp:309]     Train net output #0: loss = 0.595238 (* 1 = 0.595238 loss)
I0630 03:20:24.261823 29777 sgd_solver.cpp:106] Iteration 22800, lr = 0.0092875
I0630 03:20:40.230296 29777 solver.cpp:290] Iteration 22900 (6.26251 iter/s, 15.968s/100 iter), loss = 0.892857
I0630 03:20:40.230320 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 03:20:40.230327 29777 sgd_solver.cpp:106] Iteration 22900, lr = 0.00928437
I0630 03:20:56.070777 29777 solver.cpp:354] Sparsity after update:
I0630 03:20:56.091576 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:20:56.091609 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:20:56.091626 29777 net.cpp:1851] conv1b_param_0(0.12) 
I0630 03:20:56.091635 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:20:56.091645 29777 net.cpp:1851] res2a_branch2a_param_0(0.12) 
I0630 03:20:56.091653 29777 net.cpp:1851] res2a_branch2b_param_0(0.12) 
I0630 03:20:56.091662 29777 net.cpp:1851] res3a_branch2a_param_0(0.12) 
I0630 03:20:56.091671 29777 net.cpp:1851] res3a_branch2b_param_0(0.12) 
I0630 03:20:56.091681 29777 net.cpp:1851] res4a_branch2a_param_0(0.12) 
I0630 03:20:56.091688 29777 net.cpp:1851] res4a_branch2b_param_0(0.12) 
I0630 03:20:56.091697 29777 net.cpp:1851] res5a_branch2a_param_0(0.12) 
I0630 03:20:56.091706 29777 net.cpp:1851] res5a_branch2b_param_0(0.12) 
I0630 03:20:56.091713 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (282275/2.86678e+06) 0.0985
I0630 03:20:56.251188 29777 solver.cpp:290] Iteration 23000 (6.24203 iter/s, 16.0204s/100 iter), loss = 1.15476
I0630 03:20:56.251212 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:20:56.251219 29777 sgd_solver.cpp:106] Iteration 23000, lr = 0.00928125
I0630 03:21:12.173712 29777 solver.cpp:290] Iteration 23100 (6.28059 iter/s, 15.9221s/100 iter), loss = 1.02381
I0630 03:21:12.173738 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:21:12.173746 29777 sgd_solver.cpp:106] Iteration 23100, lr = 0.00927813
I0630 03:21:28.152621 29777 solver.cpp:290] Iteration 23200 (6.25843 iter/s, 15.9784s/100 iter), loss = 1.08333
I0630 03:21:28.152699 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:21:28.152710 29777 sgd_solver.cpp:106] Iteration 23200, lr = 0.009275
I0630 03:21:44.199025 29777 solver.cpp:290] Iteration 23300 (6.23213 iter/s, 16.0459s/100 iter), loss = 0.904762
I0630 03:21:44.199048 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:21:44.199055 29777 sgd_solver.cpp:106] Iteration 23300, lr = 0.00927188
I0630 03:22:00.189292 29777 solver.cpp:290] Iteration 23400 (6.25399 iter/s, 15.9898s/100 iter), loss = 1.16667
I0630 03:22:00.189386 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 03:22:00.189398 29777 sgd_solver.cpp:106] Iteration 23400, lr = 0.00926875
I0630 03:22:16.191864 29777 solver.cpp:290] Iteration 23500 (6.2492 iter/s, 16.002s/100 iter), loss = 0.952381
I0630 03:22:16.191890 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 03:22:16.191896 29777 sgd_solver.cpp:106] Iteration 23500, lr = 0.00926562
I0630 03:22:32.245888 29777 solver.cpp:290] Iteration 23600 (6.22915 iter/s, 16.0536s/100 iter), loss = 0.595238
I0630 03:22:32.245990 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 03:22:32.246001 29777 sgd_solver.cpp:106] Iteration 23600, lr = 0.0092625
I0630 03:22:48.348256 29777 solver.cpp:290] Iteration 23700 (6.21048 iter/s, 16.1018s/100 iter), loss = 0.952381
I0630 03:22:48.348291 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:22:48.348347 29777 sgd_solver.cpp:106] Iteration 23700, lr = 0.00925937
I0630 03:23:04.521106 29777 solver.cpp:290] Iteration 23800 (6.18339 iter/s, 16.1724s/100 iter), loss = 0.976191
I0630 03:23:04.521236 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 03:23:04.521268 29777 sgd_solver.cpp:106] Iteration 23800, lr = 0.00925625
I0630 03:23:20.699692 29777 solver.cpp:290] Iteration 23900 (6.18123 iter/s, 16.178s/100 iter), loss = 1.20238
I0630 03:23:20.699714 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 03:23:20.699720 29777 sgd_solver.cpp:106] Iteration 23900, lr = 0.00925312
I0630 03:23:36.678570 29777 solver.cpp:354] Sparsity after update:
I0630 03:23:36.679839 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:23:36.679847 29777 net.cpp:1851] conv1a_param_0(0) 
I0630 03:23:36.679853 29777 net.cpp:1851] conv1b_param_0(0.12) 
I0630 03:23:36.679857 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:23:36.679858 29777 net.cpp:1851] res2a_branch2a_param_0(0.12) 
I0630 03:23:36.679860 29777 net.cpp:1851] res2a_branch2b_param_0(0.12) 
I0630 03:23:36.679862 29777 net.cpp:1851] res3a_branch2a_param_0(0.12) 
I0630 03:23:36.679864 29777 net.cpp:1851] res3a_branch2b_param_0(0.12) 
I0630 03:23:36.679867 29777 net.cpp:1851] res4a_branch2a_param_0(0.12) 
I0630 03:23:36.679868 29777 net.cpp:1851] res4a_branch2b_param_0(0.12) 
I0630 03:23:36.679870 29777 net.cpp:1851] res5a_branch2a_param_0(0.12) 
I0630 03:23:36.679872 29777 net.cpp:1851] res5a_branch2b_param_0(0.12) 
I0630 03:23:36.679874 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (282275/2.86678e+06) 0.0985
I0630 03:23:36.679960 29777 solver.cpp:471] Iteration 24000, Testing net (#0)
I0630 03:23:39.087311 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:24:36.234496 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55328
I0630 03:24:36.234539 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.793701
I0630 03:24:36.234544 29777 solver.cpp:544]     Test net output #2: loss = 1.59088 (* 1 = 1.59088 loss)
I0630 03:24:36.416792 29777 solver.cpp:290] Iteration 24000 (1.32074 iter/s, 75.715s/100 iter), loss = 1.40476
I0630 03:24:36.416816 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 03:24:36.416822 29777 sgd_solver.cpp:106] Iteration 24000, lr = 0.00925
I0630 03:24:36.417531 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.13
I0630 03:24:36.543941 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:24:52.543066 29777 solver.cpp:290] Iteration 24100 (6.20124 iter/s, 16.1258s/100 iter), loss = 1.20238
I0630 03:24:52.543087 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 03:24:52.543094 29777 sgd_solver.cpp:106] Iteration 24100, lr = 0.00924687
I0630 03:25:08.605882 29777 solver.cpp:290] Iteration 24200 (6.22574 iter/s, 16.0624s/100 iter), loss = 0.880952
I0630 03:25:08.605988 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:25:08.605998 29777 sgd_solver.cpp:106] Iteration 24200, lr = 0.00924375
I0630 03:25:24.646394 29777 solver.cpp:290] Iteration 24300 (6.23443 iter/s, 16.04s/100 iter), loss = 1.13095
I0630 03:25:24.646420 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:25:24.646430 29777 sgd_solver.cpp:106] Iteration 24300, lr = 0.00924062
I0630 03:25:40.661099 29777 solver.cpp:290] Iteration 24400 (6.24444 iter/s, 16.0142s/100 iter), loss = 1.07143
I0630 03:25:40.661206 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:25:40.661216 29777 sgd_solver.cpp:106] Iteration 24400, lr = 0.0092375
I0630 03:25:56.668419 29777 solver.cpp:290] Iteration 24500 (6.24735 iter/s, 16.0068s/100 iter), loss = 1.59524
I0630 03:25:56.668443 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 03:25:56.668450 29777 sgd_solver.cpp:106] Iteration 24500, lr = 0.00923437
I0630 03:26:12.639775 29777 solver.cpp:290] Iteration 24600 (6.26139 iter/s, 15.9709s/100 iter), loss = 1.21429
I0630 03:26:12.639873 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:26:12.639883 29777 sgd_solver.cpp:106] Iteration 24600, lr = 0.00923125
I0630 03:26:28.635112 29777 solver.cpp:290] Iteration 24700 (6.25203 iter/s, 15.9948s/100 iter), loss = 1.19048
I0630 03:26:28.635138 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 03:26:28.635146 29777 sgd_solver.cpp:106] Iteration 24700, lr = 0.00922813
I0630 03:26:44.552132 29777 solver.cpp:290] Iteration 24800 (6.28277 iter/s, 15.9166s/100 iter), loss = 1.29762
I0630 03:26:44.552232 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 03:26:44.552242 29777 sgd_solver.cpp:106] Iteration 24800, lr = 0.009225
I0630 03:27:00.530334 29777 solver.cpp:290] Iteration 24900 (6.25874 iter/s, 15.9777s/100 iter), loss = 0.702381
I0630 03:27:00.530357 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 03:27:00.530364 29777 sgd_solver.cpp:106] Iteration 24900, lr = 0.00922188
I0630 03:27:16.351887 29777 solver.cpp:354] Sparsity after update:
I0630 03:27:16.372227 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:27:16.372262 29777 net.cpp:1851] conv1a_param_0(0.0646) 
I0630 03:27:16.372282 29777 net.cpp:1851] conv1b_param_0(0.13) 
I0630 03:27:16.372292 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:27:16.372301 29777 net.cpp:1851] res2a_branch2a_param_0(0.13) 
I0630 03:27:16.372313 29777 net.cpp:1851] res2a_branch2b_param_0(0.13) 
I0630 03:27:16.372323 29777 net.cpp:1851] res3a_branch2a_param_0(0.13) 
I0630 03:27:16.372328 29777 net.cpp:1851] res3a_branch2b_param_0(0.13) 
I0630 03:27:16.372333 29777 net.cpp:1851] res4a_branch2a_param_0(0.13) 
I0630 03:27:16.372336 29777 net.cpp:1851] res4a_branch2b_param_0(0.13) 
I0630 03:27:16.372340 29777 net.cpp:1851] res5a_branch2a_param_0(0.13) 
I0630 03:27:16.372349 29777 net.cpp:1851] res5a_branch2b_param_0(0.13) 
I0630 03:27:16.372360 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (305946/2.86678e+06) 0.107
I0630 03:27:16.528233 29777 solver.cpp:290] Iteration 25000 (6.251 iter/s, 15.9974s/100 iter), loss = 1.25
I0630 03:27:16.528259 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:27:16.528267 29777 sgd_solver.cpp:106] Iteration 25000, lr = 0.00921875
I0630 03:27:32.638334 29777 solver.cpp:290] Iteration 25100 (6.20747 iter/s, 16.1096s/100 iter), loss = 1.05952
I0630 03:27:32.638357 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:27:32.638365 29777 sgd_solver.cpp:106] Iteration 25100, lr = 0.00921563
I0630 03:27:48.662513 29777 solver.cpp:290] Iteration 25200 (6.24075 iter/s, 16.0237s/100 iter), loss = 1.29762
I0630 03:27:48.662581 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 03:27:48.662590 29777 sgd_solver.cpp:106] Iteration 25200, lr = 0.0092125
I0630 03:28:04.686296 29777 solver.cpp:290] Iteration 25300 (6.24092 iter/s, 16.0233s/100 iter), loss = 0.964286
I0630 03:28:04.686321 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:28:04.686326 29777 sgd_solver.cpp:106] Iteration 25300, lr = 0.00920937
I0630 03:28:20.787437 29777 solver.cpp:290] Iteration 25400 (6.21092 iter/s, 16.1007s/100 iter), loss = 0.904762
I0630 03:28:20.787552 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:28:20.787564 29777 sgd_solver.cpp:106] Iteration 25400, lr = 0.00920625
I0630 03:28:37.551726 29777 solver.cpp:290] Iteration 25500 (5.96526 iter/s, 16.7637s/100 iter), loss = 1.10714
I0630 03:28:37.551753 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:28:37.551762 29777 sgd_solver.cpp:106] Iteration 25500, lr = 0.00920312
I0630 03:28:54.054370 29777 solver.cpp:290] Iteration 25600 (6.05981 iter/s, 16.5022s/100 iter), loss = 1.10714
I0630 03:28:54.054450 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 03:28:54.054461 29777 sgd_solver.cpp:106] Iteration 25600, lr = 0.0092
I0630 03:29:10.283329 29777 solver.cpp:290] Iteration 25700 (6.16202 iter/s, 16.2284s/100 iter), loss = 1.22619
I0630 03:29:10.283355 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 03:29:10.283365 29777 sgd_solver.cpp:106] Iteration 25700, lr = 0.00919687
I0630 03:29:26.576666 29777 solver.cpp:290] Iteration 25800 (6.13766 iter/s, 16.2929s/100 iter), loss = 0.869048
I0630 03:29:26.576716 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 03:29:26.576725 29777 sgd_solver.cpp:106] Iteration 25800, lr = 0.00919375
I0630 03:29:42.857398 29777 solver.cpp:290] Iteration 25900 (6.14242 iter/s, 16.2802s/100 iter), loss = 0.654762
I0630 03:29:42.857421 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:29:42.857429 29777 sgd_solver.cpp:106] Iteration 25900, lr = 0.00919062
I0630 03:29:59.148258 29777 solver.cpp:354] Sparsity after update:
I0630 03:29:59.149868 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:29:59.149875 29777 net.cpp:1851] conv1a_param_0(0.0646) 
I0630 03:29:59.149886 29777 net.cpp:1851] conv1b_param_0(0.13) 
I0630 03:29:59.149891 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:29:59.149895 29777 net.cpp:1851] res2a_branch2a_param_0(0.13) 
I0630 03:29:59.149899 29777 net.cpp:1851] res2a_branch2b_param_0(0.13) 
I0630 03:29:59.149904 29777 net.cpp:1851] res3a_branch2a_param_0(0.13) 
I0630 03:29:59.149907 29777 net.cpp:1851] res3a_branch2b_param_0(0.13) 
I0630 03:29:59.149911 29777 net.cpp:1851] res4a_branch2a_param_0(0.13) 
I0630 03:29:59.149915 29777 net.cpp:1851] res4a_branch2b_param_0(0.13) 
I0630 03:29:59.149919 29777 net.cpp:1851] res5a_branch2a_param_0(0.13) 
I0630 03:29:59.149924 29777 net.cpp:1851] res5a_branch2b_param_0(0.13) 
I0630 03:29:59.149927 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (305946/2.86678e+06) 0.107
I0630 03:29:59.150018 29777 solver.cpp:471] Iteration 26000, Testing net (#0)
I0630 03:30:02.349386 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:30:53.235837 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56438
I0630 03:30:53.235888 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.798901
I0630 03:30:53.235898 29777 solver.cpp:544]     Test net output #2: loss = 1.55636 (* 1 = 1.55636 loss)
I0630 03:30:53.407361 29777 solver.cpp:290] Iteration 26000 (1.41747 iter/s, 70.548s/100 iter), loss = 0.857143
I0630 03:30:53.407384 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 03:30:53.407390 29777 sgd_solver.cpp:106] Iteration 26000, lr = 0.0091875
I0630 03:30:53.408066 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.14
I0630 03:30:53.542979 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:31:09.435297 29777 solver.cpp:290] Iteration 26100 (6.23929 iter/s, 16.0275s/100 iter), loss = 1.19048
I0630 03:31:09.435322 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 03:31:09.435331 29777 sgd_solver.cpp:106] Iteration 26100, lr = 0.00918437
I0630 03:31:25.504246 29777 solver.cpp:290] Iteration 26200 (6.22336 iter/s, 16.0685s/100 iter), loss = 1.13095
I0630 03:31:25.504369 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:31:25.504379 29777 sgd_solver.cpp:106] Iteration 26200, lr = 0.00918125
I0630 03:31:41.498842 29777 solver.cpp:290] Iteration 26300 (6.25233 iter/s, 15.994s/100 iter), loss = 1.03571
I0630 03:31:41.498867 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:31:41.498872 29777 sgd_solver.cpp:106] Iteration 26300, lr = 0.00917812
I0630 03:31:57.430047 29777 solver.cpp:290] Iteration 26400 (6.27717 iter/s, 15.9307s/100 iter), loss = 1.13095
I0630 03:31:57.430136 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:31:57.430147 29777 sgd_solver.cpp:106] Iteration 26400, lr = 0.009175
I0630 03:32:13.451997 29777 solver.cpp:290] Iteration 26500 (6.24164 iter/s, 16.0214s/100 iter), loss = 0.952381
I0630 03:32:13.452019 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 03:32:13.452028 29777 sgd_solver.cpp:106] Iteration 26500, lr = 0.00917188
I0630 03:32:29.442997 29777 solver.cpp:290] Iteration 26600 (6.2537 iter/s, 15.9905s/100 iter), loss = 1.16667
I0630 03:32:29.443073 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 03:32:29.443081 29777 sgd_solver.cpp:106] Iteration 26600, lr = 0.00916875
I0630 03:32:45.363565 29777 solver.cpp:290] Iteration 26700 (6.28139 iter/s, 15.9201s/100 iter), loss = 0.964286
I0630 03:32:45.363590 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:32:45.363598 29777 sgd_solver.cpp:106] Iteration 26700, lr = 0.00916563
I0630 03:33:01.448293 29777 solver.cpp:290] Iteration 26800 (6.21726 iter/s, 16.0843s/100 iter), loss = 1.29762
I0630 03:33:01.448364 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 03:33:01.448371 29777 sgd_solver.cpp:106] Iteration 26800, lr = 0.0091625
I0630 03:33:17.585579 29777 solver.cpp:290] Iteration 26900 (6.19703 iter/s, 16.1368s/100 iter), loss = 1.04762
I0630 03:33:17.585605 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:33:17.585613 29777 sgd_solver.cpp:106] Iteration 26900, lr = 0.00915937
I0630 03:33:33.598153 29777 solver.cpp:354] Sparsity after update:
I0630 03:33:33.618401 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:33:33.618417 29777 net.cpp:1851] conv1a_param_0(0.0696) 
I0630 03:33:33.618428 29777 net.cpp:1851] conv1b_param_0(0.14) 
I0630 03:33:33.618432 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:33:33.618438 29777 net.cpp:1851] res2a_branch2a_param_0(0.14) 
I0630 03:33:33.618440 29777 net.cpp:1851] res2a_branch2b_param_0(0.14) 
I0630 03:33:33.618443 29777 net.cpp:1851] res3a_branch2a_param_0(0.14) 
I0630 03:33:33.618448 29777 net.cpp:1851] res3a_branch2b_param_0(0.14) 
I0630 03:33:33.618450 29777 net.cpp:1851] res4a_branch2a_param_0(0.14) 
I0630 03:33:33.618453 29777 net.cpp:1851] res4a_branch2b_param_0(0.14) 
I0630 03:33:33.618456 29777 net.cpp:1851] res5a_branch2a_param_0(0.14) 
I0630 03:33:33.618460 29777 net.cpp:1851] res5a_branch2b_param_0(0.14) 
I0630 03:33:33.618463 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (329481/2.86678e+06) 0.115
I0630 03:33:33.778237 29777 solver.cpp:290] Iteration 27000 (6.17582 iter/s, 16.1922s/100 iter), loss = 1.15476
I0630 03:33:33.778275 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 03:33:33.778285 29777 sgd_solver.cpp:106] Iteration 27000, lr = 0.00915625
I0630 03:33:50.055773 29777 solver.cpp:290] Iteration 27100 (6.14362 iter/s, 16.2771s/100 iter), loss = 1.04762
I0630 03:33:50.055799 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:33:50.055807 29777 sgd_solver.cpp:106] Iteration 27100, lr = 0.00915312
I0630 03:34:06.117333 29777 solver.cpp:290] Iteration 27200 (6.22623 iter/s, 16.0611s/100 iter), loss = 1.28571
I0630 03:34:06.117455 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 03:34:06.117465 29777 sgd_solver.cpp:106] Iteration 27200, lr = 0.00915
I0630 03:34:22.288080 29777 solver.cpp:290] Iteration 27300 (6.18422 iter/s, 16.1702s/100 iter), loss = 0.892857
I0630 03:34:22.288106 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:34:22.288113 29777 sgd_solver.cpp:106] Iteration 27300, lr = 0.00914687
I0630 03:34:38.656052 29777 solver.cpp:290] Iteration 27400 (6.10967 iter/s, 16.3675s/100 iter), loss = 1.13095
I0630 03:34:38.656142 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:34:38.656152 29777 sgd_solver.cpp:106] Iteration 27400, lr = 0.00914375
I0630 03:34:54.929719 29777 solver.cpp:290] Iteration 27500 (6.1451 iter/s, 16.2731s/100 iter), loss = 1.44048
I0630 03:34:54.929745 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 03:34:54.929754 29777 sgd_solver.cpp:106] Iteration 27500, lr = 0.00914062
I0630 03:35:11.052223 29777 solver.cpp:290] Iteration 27600 (6.2027 iter/s, 16.122s/100 iter), loss = 1.17857
I0630 03:35:11.052362 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:35:11.052407 29777 sgd_solver.cpp:106] Iteration 27600, lr = 0.0091375
I0630 03:35:27.187908 29777 solver.cpp:290] Iteration 27700 (6.19766 iter/s, 16.1351s/100 iter), loss = 1.16667
I0630 03:35:27.187932 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:35:27.187938 29777 sgd_solver.cpp:106] Iteration 27700, lr = 0.00913437
I0630 03:35:43.261410 29777 solver.cpp:290] Iteration 27800 (6.2216 iter/s, 16.073s/100 iter), loss = 1.22619
I0630 03:35:43.261504 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:35:43.261515 29777 sgd_solver.cpp:106] Iteration 27800, lr = 0.00913125
I0630 03:35:59.480319 29777 solver.cpp:290] Iteration 27900 (6.16585 iter/s, 16.2184s/100 iter), loss = 0.97619
I0630 03:35:59.480343 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:35:59.480353 29777 sgd_solver.cpp:106] Iteration 27900, lr = 0.00912812
I0630 03:36:15.534498 29777 solver.cpp:354] Sparsity after update:
I0630 03:36:15.536118 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:36:15.536125 29777 net.cpp:1851] conv1a_param_0(0.0696) 
I0630 03:36:15.536131 29777 net.cpp:1851] conv1b_param_0(0.14) 
I0630 03:36:15.536134 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:36:15.536136 29777 net.cpp:1851] res2a_branch2a_param_0(0.14) 
I0630 03:36:15.536139 29777 net.cpp:1851] res2a_branch2b_param_0(0.14) 
I0630 03:36:15.536140 29777 net.cpp:1851] res3a_branch2a_param_0(0.14) 
I0630 03:36:15.536142 29777 net.cpp:1851] res3a_branch2b_param_0(0.14) 
I0630 03:36:15.536144 29777 net.cpp:1851] res4a_branch2a_param_0(0.14) 
I0630 03:36:15.536146 29777 net.cpp:1851] res4a_branch2b_param_0(0.14) 
I0630 03:36:15.536147 29777 net.cpp:1851] res5a_branch2a_param_0(0.14) 
I0630 03:36:15.536149 29777 net.cpp:1851] res5a_branch2b_param_0(0.14) 
I0630 03:36:15.536152 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (329481/2.86678e+06) 0.115
I0630 03:36:15.536247 29777 solver.cpp:471] Iteration 28000, Testing net (#0)
I0630 03:36:18.550643 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:37:13.381738 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5643
I0630 03:37:13.381789 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.798461
I0630 03:37:13.381795 29777 solver.cpp:544]     Test net output #2: loss = 1.57284 (* 1 = 1.57284 loss)
I0630 03:37:13.560348 29777 solver.cpp:290] Iteration 28000 (1.34993 iter/s, 74.078s/100 iter), loss = 1.10714
I0630 03:37:13.560374 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:37:13.560382 29777 sgd_solver.cpp:106] Iteration 28000, lr = 0.009125
I0630 03:37:13.561390 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.15
I0630 03:37:13.699188 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:37:29.820039 29777 solver.cpp:290] Iteration 28100 (6.15036 iter/s, 16.2592s/100 iter), loss = 1.19048
I0630 03:37:29.820065 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 03:37:29.820073 29777 sgd_solver.cpp:106] Iteration 28100, lr = 0.00912188
I0630 03:37:45.824158 29777 solver.cpp:290] Iteration 28200 (6.24857 iter/s, 16.0037s/100 iter), loss = 1.10714
I0630 03:37:45.824282 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:37:45.824292 29777 sgd_solver.cpp:106] Iteration 28200, lr = 0.00911875
I0630 03:38:01.798598 29777 solver.cpp:290] Iteration 28300 (6.26022 iter/s, 15.9739s/100 iter), loss = 1.07143
I0630 03:38:01.798620 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:38:01.798627 29777 sgd_solver.cpp:106] Iteration 28300, lr = 0.00911563
I0630 03:38:18.119030 29777 solver.cpp:290] Iteration 28400 (6.12747 iter/s, 16.32s/100 iter), loss = 1.42857
I0630 03:38:18.119091 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:38:18.119102 29777 sgd_solver.cpp:106] Iteration 28400, lr = 0.0091125
I0630 03:38:34.254365 29777 solver.cpp:290] Iteration 28500 (6.19777 iter/s, 16.1348s/100 iter), loss = 0.97619
I0630 03:38:34.254532 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 03:38:34.254609 29777 sgd_solver.cpp:106] Iteration 28500, lr = 0.00910938
I0630 03:38:50.356402 29777 solver.cpp:290] Iteration 28600 (6.21063 iter/s, 16.1014s/100 iter), loss = 1.39286
I0630 03:38:50.356503 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 03:38:50.356513 29777 sgd_solver.cpp:106] Iteration 28600, lr = 0.00910625
I0630 03:39:06.409301 29777 solver.cpp:290] Iteration 28700 (6.22961 iter/s, 16.0524s/100 iter), loss = 1.10714
I0630 03:39:06.409327 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 03:39:06.409334 29777 sgd_solver.cpp:106] Iteration 28700, lr = 0.00910312
I0630 03:39:22.649255 29777 solver.cpp:290] Iteration 28800 (6.15783 iter/s, 16.2395s/100 iter), loss = 1.22619
I0630 03:39:22.649350 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:39:22.649361 29777 sgd_solver.cpp:106] Iteration 28800, lr = 0.0091
I0630 03:39:38.977210 29777 solver.cpp:290] Iteration 28900 (6.12467 iter/s, 16.3274s/100 iter), loss = 1.39286
I0630 03:39:38.977237 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 03:39:38.977252 29777 sgd_solver.cpp:106] Iteration 28900, lr = 0.00909687
I0630 03:39:55.298318 29777 solver.cpp:354] Sparsity after update:
I0630 03:39:55.323714 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:39:55.323736 29777 net.cpp:1851] conv1a_param_0(0.0746) 
I0630 03:39:55.323750 29777 net.cpp:1851] conv1b_param_0(0.15) 
I0630 03:39:55.323755 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:39:55.323758 29777 net.cpp:1851] res2a_branch2a_param_0(0.15) 
I0630 03:39:55.323762 29777 net.cpp:1851] res2a_branch2b_param_0(0.15) 
I0630 03:39:55.323766 29777 net.cpp:1851] res3a_branch2a_param_0(0.15) 
I0630 03:39:55.323770 29777 net.cpp:1851] res3a_branch2b_param_0(0.15) 
I0630 03:39:55.323773 29777 net.cpp:1851] res4a_branch2a_param_0(0.15) 
I0630 03:39:55.323777 29777 net.cpp:1851] res4a_branch2b_param_0(0.15) 
I0630 03:39:55.323784 29777 net.cpp:1851] res5a_branch2a_param_0(0.15) 
I0630 03:39:55.323791 29777 net.cpp:1851] res5a_branch2b_param_0(0.15) 
I0630 03:39:55.323796 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (353028/2.86678e+06) 0.123
I0630 03:39:55.478513 29777 solver.cpp:290] Iteration 29000 (6.0603 iter/s, 16.5008s/100 iter), loss = 1.09524
I0630 03:39:55.478538 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:39:55.478549 29777 sgd_solver.cpp:106] Iteration 29000, lr = 0.00909375
I0630 03:40:11.625998 29777 solver.cpp:290] Iteration 29100 (6.1931 iter/s, 16.147s/100 iter), loss = 0.916667
I0630 03:40:11.626214 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 03:40:11.628208 29777 sgd_solver.cpp:106] Iteration 29100, lr = 0.00909062
I0630 03:40:27.981209 29777 solver.cpp:290] Iteration 29200 (6.11525 iter/s, 16.3526s/100 iter), loss = 0.761905
I0630 03:40:27.981333 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:40:27.981341 29777 sgd_solver.cpp:106] Iteration 29200, lr = 0.0090875
I0630 03:40:44.194767 29777 solver.cpp:290] Iteration 29300 (6.1679 iter/s, 16.213s/100 iter), loss = 0.940476
I0630 03:40:44.195057 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:40:44.195197 29777 sgd_solver.cpp:106] Iteration 29300, lr = 0.00908437
I0630 03:41:00.740064 29777 solver.cpp:290] Iteration 29400 (6.04428 iter/s, 16.5446s/100 iter), loss = 1.14286
I0630 03:41:00.740157 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:41:00.740169 29777 sgd_solver.cpp:106] Iteration 29400, lr = 0.00908125
I0630 03:41:17.143558 29777 solver.cpp:290] Iteration 29500 (6.09646 iter/s, 16.403s/100 iter), loss = 1.07143
I0630 03:41:17.143581 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:41:17.143587 29777 sgd_solver.cpp:106] Iteration 29500, lr = 0.00907812
I0630 03:41:33.500082 29777 solver.cpp:290] Iteration 29600 (6.11395 iter/s, 16.356s/100 iter), loss = 1.13095
I0630 03:41:33.500342 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:41:33.500469 29777 sgd_solver.cpp:106] Iteration 29600, lr = 0.009075
I0630 03:41:49.821794 29777 solver.cpp:290] Iteration 29700 (6.12707 iter/s, 16.321s/100 iter), loss = 1.08333
I0630 03:41:49.821820 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:41:49.821826 29777 sgd_solver.cpp:106] Iteration 29700, lr = 0.00907188
I0630 03:42:06.392545 29777 solver.cpp:290] Iteration 29800 (6.03491 iter/s, 16.5702s/100 iter), loss = 1.14286
I0630 03:42:06.392714 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 03:42:06.392758 29777 sgd_solver.cpp:106] Iteration 29800, lr = 0.00906875
I0630 03:42:22.804392 29777 solver.cpp:290] Iteration 29900 (6.09339 iter/s, 16.4112s/100 iter), loss = 0.952381
I0630 03:42:22.804447 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 03:42:22.804471 29777 sgd_solver.cpp:106] Iteration 29900, lr = 0.00906563
I0630 03:42:38.802541 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_30000.caffemodel
I0630 03:42:38.822203 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_30000.solverstate
I0630 03:42:38.831228 29777 solver.cpp:354] Sparsity after update:
I0630 03:42:38.832204 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:42:38.832213 29777 net.cpp:1851] conv1a_param_0(0.0746) 
I0630 03:42:38.832221 29777 net.cpp:1851] conv1b_param_0(0.15) 
I0630 03:42:38.832222 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:42:38.832224 29777 net.cpp:1851] res2a_branch2a_param_0(0.15) 
I0630 03:42:38.832226 29777 net.cpp:1851] res2a_branch2b_param_0(0.15) 
I0630 03:42:38.832228 29777 net.cpp:1851] res3a_branch2a_param_0(0.15) 
I0630 03:42:38.832231 29777 net.cpp:1851] res3a_branch2b_param_0(0.15) 
I0630 03:42:38.832232 29777 net.cpp:1851] res4a_branch2a_param_0(0.15) 
I0630 03:42:38.832234 29777 net.cpp:1851] res4a_branch2b_param_0(0.15) 
I0630 03:42:38.832237 29777 net.cpp:1851] res5a_branch2a_param_0(0.15) 
I0630 03:42:38.832238 29777 net.cpp:1851] res5a_branch2b_param_0(0.15) 
I0630 03:42:38.832240 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (353028/2.86678e+06) 0.123
I0630 03:42:38.832335 29777 solver.cpp:471] Iteration 30000, Testing net (#0)
I0630 03:42:42.954138 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:43:45.913530 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55084
I0630 03:43:45.913589 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.791641
I0630 03:43:45.913595 29777 solver.cpp:544]     Test net output #2: loss = 1.61132 (* 1 = 1.61132 loss)
I0630 03:43:46.091377 29777 solver.cpp:290] Iteration 30000 (1.2007 iter/s, 83.2847s/100 iter), loss = 0.690476
I0630 03:43:46.091399 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 03:43:46.091405 29777 sgd_solver.cpp:106] Iteration 30000, lr = 0.0090625
I0630 03:43:46.092080 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.16
I0630 03:43:46.228162 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:44:02.637657 29777 solver.cpp:290] Iteration 30100 (6.04383 iter/s, 16.5458s/100 iter), loss = 0.797619
I0630 03:44:02.637687 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:44:02.637696 29777 sgd_solver.cpp:106] Iteration 30100, lr = 0.00905938
I0630 03:44:19.179137 29777 solver.cpp:290] Iteration 30200 (6.04559 iter/s, 16.541s/100 iter), loss = 1.22619
I0630 03:44:19.179229 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:44:19.179239 29777 sgd_solver.cpp:106] Iteration 30200, lr = 0.00905625
I0630 03:44:35.613289 29777 solver.cpp:290] Iteration 30300 (6.08509 iter/s, 16.4336s/100 iter), loss = 1.02381
I0630 03:44:35.613312 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 03:44:35.613319 29777 sgd_solver.cpp:106] Iteration 30300, lr = 0.00905313
I0630 03:44:51.910449 29777 solver.cpp:290] Iteration 30400 (6.13622 iter/s, 16.2967s/100 iter), loss = 0.964286
I0630 03:44:51.910554 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:44:51.910564 29777 sgd_solver.cpp:106] Iteration 30400, lr = 0.00905
I0630 03:45:08.189551 29777 solver.cpp:290] Iteration 30500 (6.14305 iter/s, 16.2786s/100 iter), loss = 1.16667
I0630 03:45:08.189574 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 03:45:08.189581 29777 sgd_solver.cpp:106] Iteration 30500, lr = 0.00904687
I0630 03:45:25.064513 29777 solver.cpp:290] Iteration 30600 (5.92611 iter/s, 16.8745s/100 iter), loss = 1.2619
I0630 03:45:25.064589 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:45:25.064610 29777 sgd_solver.cpp:106] Iteration 30600, lr = 0.00904375
I0630 03:45:41.453068 29777 solver.cpp:290] Iteration 30700 (6.10202 iter/s, 16.388s/100 iter), loss = 1.40476
I0630 03:45:41.453128 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 03:45:41.453161 29777 sgd_solver.cpp:106] Iteration 30700, lr = 0.00904062
I0630 03:45:57.450814 29777 solver.cpp:290] Iteration 30800 (6.25107 iter/s, 15.9973s/100 iter), loss = 0.97619
I0630 03:45:57.450875 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:45:57.450889 29777 sgd_solver.cpp:106] Iteration 30800, lr = 0.0090375
I0630 03:46:13.813745 29777 solver.cpp:290] Iteration 30900 (6.11157 iter/s, 16.3624s/100 iter), loss = 1.16667
I0630 03:46:13.813807 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:46:13.813822 29777 sgd_solver.cpp:106] Iteration 30900, lr = 0.00903437
I0630 03:46:30.283251 29777 solver.cpp:354] Sparsity after update:
I0630 03:46:30.303735 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:46:30.303752 29777 net.cpp:1851] conv1a_param_0(0.08) 
I0630 03:46:30.303763 29777 net.cpp:1851] conv1b_param_0(0.16) 
I0630 03:46:30.303767 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:46:30.303771 29777 net.cpp:1851] res2a_branch2a_param_0(0.16) 
I0630 03:46:30.303774 29777 net.cpp:1851] res2a_branch2b_param_0(0.16) 
I0630 03:46:30.303777 29777 net.cpp:1851] res3a_branch2a_param_0(0.16) 
I0630 03:46:30.303781 29777 net.cpp:1851] res3a_branch2b_param_0(0.16) 
I0630 03:46:30.303783 29777 net.cpp:1851] res4a_branch2a_param_0(0.16) 
I0630 03:46:30.303786 29777 net.cpp:1851] res4a_branch2b_param_0(0.16) 
I0630 03:46:30.303789 29777 net.cpp:1851] res5a_branch2a_param_0(0.16) 
I0630 03:46:30.303793 29777 net.cpp:1851] res5a_branch2b_param_0(0.16) 
I0630 03:46:30.303797 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (376557/2.86678e+06) 0.131
I0630 03:46:30.462828 29777 solver.cpp:290] Iteration 31000 (6.00652 iter/s, 16.6486s/100 iter), loss = 0.940476
I0630 03:46:30.462888 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 03:46:30.462898 29777 sgd_solver.cpp:106] Iteration 31000, lr = 0.00903125
I0630 03:46:46.863420 29777 solver.cpp:290] Iteration 31100 (6.09753 iter/s, 16.4001s/100 iter), loss = 1.10714
I0630 03:46:46.863445 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 03:46:46.863453 29777 sgd_solver.cpp:106] Iteration 31100, lr = 0.00902812
I0630 03:47:03.038067 29777 solver.cpp:290] Iteration 31200 (6.18269 iter/s, 16.1742s/100 iter), loss = 1.0119
I0630 03:47:03.038151 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:47:03.038161 29777 sgd_solver.cpp:106] Iteration 31200, lr = 0.009025
I0630 03:47:19.176632 29777 solver.cpp:290] Iteration 31300 (6.19654 iter/s, 16.138s/100 iter), loss = 1.39286
I0630 03:47:19.176659 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 03:47:19.176667 29777 sgd_solver.cpp:106] Iteration 31300, lr = 0.00902187
I0630 03:47:35.494935 29777 solver.cpp:290] Iteration 31400 (6.12827 iter/s, 16.3178s/100 iter), loss = 0.928571
I0630 03:47:35.495038 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 03:47:35.495052 29777 sgd_solver.cpp:106] Iteration 31400, lr = 0.00901875
I0630 03:47:51.980615 29777 solver.cpp:290] Iteration 31500 (6.06607 iter/s, 16.4851s/100 iter), loss = 0.97619
I0630 03:47:51.980641 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 03:47:51.980648 29777 sgd_solver.cpp:106] Iteration 31500, lr = 0.00901563
I0630 03:48:08.106639 29777 solver.cpp:290] Iteration 31600 (6.20134 iter/s, 16.1256s/100 iter), loss = 1.30952
I0630 03:48:08.106712 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 03:48:08.106720 29777 sgd_solver.cpp:106] Iteration 31600, lr = 0.0090125
I0630 03:48:24.265293 29777 solver.cpp:290] Iteration 31700 (6.18883 iter/s, 16.1581s/100 iter), loss = 1.03571
I0630 03:48:24.265317 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 03:48:24.265324 29777 sgd_solver.cpp:106] Iteration 31700, lr = 0.00900938
I0630 03:48:40.649991 29777 solver.cpp:290] Iteration 31800 (6.10343 iter/s, 16.3842s/100 iter), loss = 0.964286
I0630 03:48:40.650084 29777 solver.cpp:309]     Train net output #0: loss = 0.404762 (* 1 = 0.404762 loss)
I0630 03:48:40.650108 29777 sgd_solver.cpp:106] Iteration 31800, lr = 0.00900625
I0630 03:48:56.859874 29777 solver.cpp:290] Iteration 31900 (6.16928 iter/s, 16.2094s/100 iter), loss = 1.11905
I0630 03:48:56.859901 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:48:56.859910 29777 sgd_solver.cpp:106] Iteration 31900, lr = 0.00900312
I0630 03:49:12.934684 29777 solver.cpp:354] Sparsity after update:
I0630 03:49:12.936123 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:49:12.936131 29777 net.cpp:1851] conv1a_param_0(0.08) 
I0630 03:49:12.936138 29777 net.cpp:1851] conv1b_param_0(0.16) 
I0630 03:49:12.936141 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:49:12.936143 29777 net.cpp:1851] res2a_branch2a_param_0(0.16) 
I0630 03:49:12.936146 29777 net.cpp:1851] res2a_branch2b_param_0(0.16) 
I0630 03:49:12.936147 29777 net.cpp:1851] res3a_branch2a_param_0(0.16) 
I0630 03:49:12.936151 29777 net.cpp:1851] res3a_branch2b_param_0(0.16) 
I0630 03:49:12.936152 29777 net.cpp:1851] res4a_branch2a_param_0(0.16) 
I0630 03:49:12.936154 29777 net.cpp:1851] res4a_branch2b_param_0(0.16) 
I0630 03:49:12.936156 29777 net.cpp:1851] res5a_branch2a_param_0(0.16) 
I0630 03:49:12.936159 29777 net.cpp:1851] res5a_branch2b_param_0(0.16) 
I0630 03:49:12.936161 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (376557/2.86678e+06) 0.131
I0630 03:49:12.936250 29777 solver.cpp:471] Iteration 32000, Testing net (#0)
I0630 03:49:16.565232 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:50:13.470932 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56286
I0630 03:50:13.471000 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.796581
I0630 03:50:13.471007 29777 solver.cpp:544]     Test net output #2: loss = 1.57482 (* 1 = 1.57482 loss)
I0630 03:50:13.643936 29777 solver.cpp:290] Iteration 32000 (1.30239 iter/s, 76.782s/100 iter), loss = 1.2619
I0630 03:50:13.643962 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 03:50:13.643971 29777 sgd_solver.cpp:106] Iteration 32000, lr = 0.009
I0630 03:50:13.644950 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.17
I0630 03:50:13.817746 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:50:29.919770 29777 solver.cpp:290] Iteration 32100 (6.14426 iter/s, 16.2754s/100 iter), loss = 0.988095
I0630 03:50:29.919792 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 03:50:29.919800 29777 sgd_solver.cpp:106] Iteration 32100, lr = 0.00899688
I0630 03:50:45.947302 29777 solver.cpp:290] Iteration 32200 (6.23944 iter/s, 16.0271s/100 iter), loss = 1.15476
I0630 03:50:45.947376 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 03:50:45.947382 29777 sgd_solver.cpp:106] Iteration 32200, lr = 0.00899375
I0630 03:51:02.248486 29777 solver.cpp:290] Iteration 32300 (6.13472 iter/s, 16.3007s/100 iter), loss = 1.09524
I0630 03:51:02.248512 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 03:51:02.248522 29777 sgd_solver.cpp:106] Iteration 32300, lr = 0.00899062
I0630 03:51:18.370555 29777 solver.cpp:290] Iteration 32400 (6.20286 iter/s, 16.1216s/100 iter), loss = 1.07143
I0630 03:51:18.370658 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:51:18.370668 29777 sgd_solver.cpp:106] Iteration 32400, lr = 0.0089875
I0630 03:51:34.617399 29777 solver.cpp:290] Iteration 32500 (6.15525 iter/s, 16.2463s/100 iter), loss = 1.02381
I0630 03:51:34.617429 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 03:51:34.617440 29777 sgd_solver.cpp:106] Iteration 32500, lr = 0.00898437
I0630 03:51:50.764793 29777 solver.cpp:290] Iteration 32600 (6.19313 iter/s, 16.1469s/100 iter), loss = 1.02381
I0630 03:51:50.764888 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:51:50.764897 29777 sgd_solver.cpp:106] Iteration 32600, lr = 0.00898125
I0630 03:52:06.870379 29777 solver.cpp:290] Iteration 32700 (6.20923 iter/s, 16.105s/100 iter), loss = 0.916667
I0630 03:52:06.870412 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 03:52:06.870419 29777 sgd_solver.cpp:106] Iteration 32700, lr = 0.00897812
I0630 03:52:22.950608 29777 solver.cpp:290] Iteration 32800 (6.21901 iter/s, 16.0797s/100 iter), loss = 1.19048
I0630 03:52:22.950773 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:52:22.950810 29777 sgd_solver.cpp:106] Iteration 32800, lr = 0.008975
I0630 03:52:39.096552 29777 solver.cpp:290] Iteration 32900 (6.19374 iter/s, 16.1453s/100 iter), loss = 1.32143
I0630 03:52:39.096575 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:52:39.096581 29777 sgd_solver.cpp:106] Iteration 32900, lr = 0.00897187
I0630 03:52:54.988059 29777 solver.cpp:354] Sparsity after update:
I0630 03:52:55.008625 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:52:55.008641 29777 net.cpp:1851] conv1a_param_0(0.085) 
I0630 03:52:55.008651 29777 net.cpp:1851] conv1b_param_0(0.17) 
I0630 03:52:55.008652 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:52:55.008654 29777 net.cpp:1851] res2a_branch2a_param_0(0.17) 
I0630 03:52:55.008656 29777 net.cpp:1851] res2a_branch2b_param_0(0.17) 
I0630 03:52:55.008658 29777 net.cpp:1851] res3a_branch2a_param_0(0.17) 
I0630 03:52:55.008668 29777 net.cpp:1851] res3a_branch2b_param_0(0.17) 
I0630 03:52:55.008671 29777 net.cpp:1851] res4a_branch2a_param_0(0.17) 
I0630 03:52:55.008672 29777 net.cpp:1851] res4a_branch2b_param_0(0.17) 
I0630 03:52:55.008677 29777 net.cpp:1851] res5a_branch2a_param_0(0.17) 
I0630 03:52:55.008678 29777 net.cpp:1851] res5a_branch2b_param_0(0.17) 
I0630 03:52:55.008682 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (400093/2.86678e+06) 0.14
I0630 03:52:55.163780 29777 solver.cpp:290] Iteration 33000 (6.22403 iter/s, 16.0668s/100 iter), loss = 0.75
I0630 03:52:55.163803 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 03:52:55.163810 29777 sgd_solver.cpp:106] Iteration 33000, lr = 0.00896875
I0630 03:53:11.263727 29777 solver.cpp:290] Iteration 33100 (6.21138 iter/s, 16.0995s/100 iter), loss = 1.36905
I0630 03:53:11.263751 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 03:53:11.263756 29777 sgd_solver.cpp:106] Iteration 33100, lr = 0.00896563
I0630 03:53:27.484591 29777 solver.cpp:290] Iteration 33200 (6.16508 iter/s, 16.2204s/100 iter), loss = 1.27381
I0630 03:53:27.484663 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 03:53:27.484671 29777 sgd_solver.cpp:106] Iteration 33200, lr = 0.0089625
I0630 03:53:43.639612 29777 solver.cpp:290] Iteration 33300 (6.19022 iter/s, 16.1545s/100 iter), loss = 1.10714
I0630 03:53:43.639636 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 03:53:43.639642 29777 sgd_solver.cpp:106] Iteration 33300, lr = 0.00895937
I0630 03:53:59.659904 29777 solver.cpp:290] Iteration 33400 (6.24227 iter/s, 16.0198s/100 iter), loss = 1.39286
I0630 03:53:59.660009 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 03:53:59.660019 29777 sgd_solver.cpp:106] Iteration 33400, lr = 0.00895625
I0630 03:54:15.717109 29777 solver.cpp:290] Iteration 33500 (6.22795 iter/s, 16.0567s/100 iter), loss = 0.976191
I0630 03:54:15.717140 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 03:54:15.717150 29777 sgd_solver.cpp:106] Iteration 33500, lr = 0.00895312
I0630 03:54:32.057801 29777 solver.cpp:290] Iteration 33600 (6.11988 iter/s, 16.3402s/100 iter), loss = 0.964286
I0630 03:54:32.057909 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 03:54:32.057931 29777 sgd_solver.cpp:106] Iteration 33600, lr = 0.00895
I0630 03:54:48.239308 29777 solver.cpp:290] Iteration 33700 (6.1801 iter/s, 16.181s/100 iter), loss = 1.10714
I0630 03:54:48.239334 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 03:54:48.239343 29777 sgd_solver.cpp:106] Iteration 33700, lr = 0.00894688
I0630 03:55:04.359192 29777 solver.cpp:290] Iteration 33800 (6.2037 iter/s, 16.1194s/100 iter), loss = 1.28571
I0630 03:55:04.359292 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 03:55:04.359321 29777 sgd_solver.cpp:106] Iteration 33800, lr = 0.00894375
I0630 03:55:20.463482 29777 solver.cpp:290] Iteration 33900 (6.20973 iter/s, 16.1038s/100 iter), loss = 1.2381
I0630 03:55:20.463505 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 03:55:20.463512 29777 sgd_solver.cpp:106] Iteration 33900, lr = 0.00894063
I0630 03:55:36.361322 29777 solver.cpp:354] Sparsity after update:
I0630 03:55:36.362942 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:55:36.362952 29777 net.cpp:1851] conv1a_param_0(0.085) 
I0630 03:55:36.362960 29777 net.cpp:1851] conv1b_param_0(0.17) 
I0630 03:55:36.362962 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:55:36.362964 29777 net.cpp:1851] res2a_branch2a_param_0(0.17) 
I0630 03:55:36.362967 29777 net.cpp:1851] res2a_branch2b_param_0(0.17) 
I0630 03:55:36.362968 29777 net.cpp:1851] res3a_branch2a_param_0(0.17) 
I0630 03:55:36.362970 29777 net.cpp:1851] res3a_branch2b_param_0(0.17) 
I0630 03:55:36.362972 29777 net.cpp:1851] res4a_branch2a_param_0(0.17) 
I0630 03:55:36.362974 29777 net.cpp:1851] res4a_branch2b_param_0(0.17) 
I0630 03:55:36.362977 29777 net.cpp:1851] res5a_branch2a_param_0(0.17) 
I0630 03:55:36.362978 29777 net.cpp:1851] res5a_branch2b_param_0(0.17) 
I0630 03:55:36.362980 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (400093/2.86678e+06) 0.14
I0630 03:55:36.363071 29777 solver.cpp:471] Iteration 34000, Testing net (#0)
I0630 03:55:40.753731 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 03:56:44.617478 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54646
I0630 03:56:44.617561 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.788641
I0630 03:56:44.617571 29777 solver.cpp:544]     Test net output #2: loss = 1.64766 (* 1 = 1.64766 loss)
I0630 03:56:44.797288 29777 solver.cpp:290] Iteration 34000 (1.1858 iter/s, 84.3315s/100 iter), loss = 1.29762
I0630 03:56:44.797312 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 03:56:44.797319 29777 sgd_solver.cpp:106] Iteration 34000, lr = 0.0089375
I0630 03:56:44.798077 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.18
I0630 03:56:44.921867 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 03:57:01.287376 29777 solver.cpp:290] Iteration 34100 (6.06443 iter/s, 16.4896s/100 iter), loss = 0.916667
I0630 03:57:01.287437 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:57:01.287459 29777 sgd_solver.cpp:106] Iteration 34100, lr = 0.00893437
I0630 03:57:17.567765 29777 solver.cpp:290] Iteration 34200 (6.14255 iter/s, 16.2799s/100 iter), loss = 1.02381
I0630 03:57:17.567842 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 03:57:17.567852 29777 sgd_solver.cpp:106] Iteration 34200, lr = 0.00893125
I0630 03:57:33.886263 29777 solver.cpp:290] Iteration 34300 (6.12821 iter/s, 16.318s/100 iter), loss = 0.97619
I0630 03:57:33.886289 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 03:57:33.886298 29777 sgd_solver.cpp:106] Iteration 34300, lr = 0.00892812
I0630 03:57:49.957355 29777 solver.cpp:290] Iteration 34400 (6.22253 iter/s, 16.0706s/100 iter), loss = 0.952381
I0630 03:57:49.957461 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:57:49.957475 29777 sgd_solver.cpp:106] Iteration 34400, lr = 0.008925
I0630 03:58:06.444828 29777 solver.cpp:290] Iteration 34500 (6.06542 iter/s, 16.4869s/100 iter), loss = 0.892857
I0630 03:58:06.444916 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 03:58:06.444944 29777 sgd_solver.cpp:106] Iteration 34500, lr = 0.00892187
I0630 03:58:22.659430 29777 solver.cpp:290] Iteration 34600 (6.16748 iter/s, 16.2141s/100 iter), loss = 1.03571
I0630 03:58:22.659538 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 03:58:22.659548 29777 sgd_solver.cpp:106] Iteration 34600, lr = 0.00891875
I0630 03:58:39.116744 29777 solver.cpp:290] Iteration 34700 (6.07653 iter/s, 16.4568s/100 iter), loss = 1.09524
I0630 03:58:39.116768 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 03:58:39.116775 29777 sgd_solver.cpp:106] Iteration 34700, lr = 0.00891562
I0630 03:58:55.286936 29777 solver.cpp:290] Iteration 34800 (6.1844 iter/s, 16.1697s/100 iter), loss = 1.22619
I0630 03:58:55.287117 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 03:58:55.287139 29777 sgd_solver.cpp:106] Iteration 34800, lr = 0.0089125
I0630 03:59:11.672698 29777 solver.cpp:290] Iteration 34900 (6.10309 iter/s, 16.3851s/100 iter), loss = 1.32143
I0630 03:59:11.672791 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 03:59:11.672822 29777 sgd_solver.cpp:106] Iteration 34900, lr = 0.00890937
I0630 03:59:27.868269 29777 solver.cpp:354] Sparsity after update:
I0630 03:59:27.893358 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 03:59:27.893379 29777 net.cpp:1851] conv1a_param_0(0.09) 
I0630 03:59:27.893390 29777 net.cpp:1851] conv1b_param_0(0.18) 
I0630 03:59:27.893394 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 03:59:27.893398 29777 net.cpp:1851] res2a_branch2a_param_0(0.18) 
I0630 03:59:27.893400 29777 net.cpp:1851] res2a_branch2b_param_0(0.18) 
I0630 03:59:27.893411 29777 net.cpp:1851] res3a_branch2a_param_0(0.18) 
I0630 03:59:27.893430 29777 net.cpp:1851] res3a_branch2b_param_0(0.18) 
I0630 03:59:27.893445 29777 net.cpp:1851] res4a_branch2a_param_0(0.18) 
I0630 03:59:27.893450 29777 net.cpp:1851] res4a_branch2b_param_0(0.18) 
I0630 03:59:27.893453 29777 net.cpp:1851] res5a_branch2a_param_0(0.18) 
I0630 03:59:27.893465 29777 net.cpp:1851] res5a_branch2b_param_0(0.18) 
I0630 03:59:27.893471 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (423634/2.86678e+06) 0.148
I0630 03:59:28.050850 29777 solver.cpp:290] Iteration 35000 (6.1059 iter/s, 16.3776s/100 iter), loss = 1.34524
I0630 03:59:28.050876 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 03:59:28.050886 29777 sgd_solver.cpp:106] Iteration 35000, lr = 0.00890625
I0630 03:59:44.458290 29777 solver.cpp:290] Iteration 35100 (6.09497 iter/s, 16.407s/100 iter), loss = 0.75
I0630 03:59:44.458340 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 03:59:44.458364 29777 sgd_solver.cpp:106] Iteration 35100, lr = 0.00890312
I0630 04:00:00.934155 29777 solver.cpp:290] Iteration 35200 (6.06967 iter/s, 16.4754s/100 iter), loss = 1.17857
I0630 04:00:00.934229 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 04:00:00.934237 29777 sgd_solver.cpp:106] Iteration 35200, lr = 0.0089
I0630 04:00:17.028230 29777 solver.cpp:290] Iteration 35300 (6.21367 iter/s, 16.0936s/100 iter), loss = 1
I0630 04:00:17.028252 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 04:00:17.028259 29777 sgd_solver.cpp:106] Iteration 35300, lr = 0.00889687
I0630 04:00:33.304472 29777 solver.cpp:290] Iteration 35400 (6.1441 iter/s, 16.2758s/100 iter), loss = 1.28571
I0630 04:00:33.304543 29777 solver.cpp:309]     Train net output #0: loss = 1.85714 (* 1 = 1.85714 loss)
I0630 04:00:33.304553 29777 sgd_solver.cpp:106] Iteration 35400, lr = 0.00889375
I0630 04:00:49.832002 29777 solver.cpp:290] Iteration 35500 (6.0507 iter/s, 16.527s/100 iter), loss = 1.09524
I0630 04:00:49.832029 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 04:00:49.832038 29777 sgd_solver.cpp:106] Iteration 35500, lr = 0.00889063
I0630 04:01:05.928761 29777 solver.cpp:290] Iteration 35600 (6.21261 iter/s, 16.0963s/100 iter), loss = 1.21429
I0630 04:01:05.928825 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:01:05.928833 29777 sgd_solver.cpp:106] Iteration 35600, lr = 0.0088875
I0630 04:01:22.679471 29777 solver.cpp:290] Iteration 35700 (5.97008 iter/s, 16.7502s/100 iter), loss = 1.19048
I0630 04:01:22.679496 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 04:01:22.679502 29777 sgd_solver.cpp:106] Iteration 35700, lr = 0.00888437
I0630 04:01:39.123715 29777 solver.cpp:290] Iteration 35800 (6.08133 iter/s, 16.4438s/100 iter), loss = 1.29762
I0630 04:01:39.123813 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 04:01:39.123821 29777 sgd_solver.cpp:106] Iteration 35800, lr = 0.00888125
I0630 04:01:55.443732 29777 solver.cpp:290] Iteration 35900 (6.12765 iter/s, 16.3195s/100 iter), loss = 0.952381
I0630 04:01:55.443758 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 04:01:55.443766 29777 sgd_solver.cpp:106] Iteration 35900, lr = 0.00887812
I0630 04:02:11.412854 29777 solver.cpp:354] Sparsity after update:
I0630 04:02:11.414500 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:02:11.414513 29777 net.cpp:1851] conv1a_param_0(0.09) 
I0630 04:02:11.414522 29777 net.cpp:1851] conv1b_param_0(0.18) 
I0630 04:02:11.414527 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:02:11.414531 29777 net.cpp:1851] res2a_branch2a_param_0(0.18) 
I0630 04:02:11.414535 29777 net.cpp:1851] res2a_branch2b_param_0(0.18) 
I0630 04:02:11.414538 29777 net.cpp:1851] res3a_branch2a_param_0(0.18) 
I0630 04:02:11.414542 29777 net.cpp:1851] res3a_branch2b_param_0(0.18) 
I0630 04:02:11.414546 29777 net.cpp:1851] res4a_branch2a_param_0(0.18) 
I0630 04:02:11.414548 29777 net.cpp:1851] res4a_branch2b_param_0(0.18) 
I0630 04:02:11.414551 29777 net.cpp:1851] res5a_branch2a_param_0(0.18) 
I0630 04:02:11.414556 29777 net.cpp:1851] res5a_branch2b_param_0(0.18) 
I0630 04:02:11.414558 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (423634/2.86678e+06) 0.148
I0630 04:02:11.414687 29777 solver.cpp:471] Iteration 36000, Testing net (#0)
I0630 04:02:14.709843 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:03:17.265198 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.554479
I0630 04:03:17.265255 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.796002
I0630 04:03:17.265261 29777 solver.cpp:544]     Test net output #2: loss = 1.58688 (* 1 = 1.58688 loss)
I0630 04:03:17.448673 29777 solver.cpp:290] Iteration 36000 (1.21947 iter/s, 82.0027s/100 iter), loss = 1.0119
I0630 04:03:17.448695 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 04:03:17.448703 29777 sgd_solver.cpp:106] Iteration 36000, lr = 0.008875
I0630 04:03:17.449451 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.19
I0630 04:03:17.680459 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:03:33.739944 29777 solver.cpp:290] Iteration 36100 (6.13843 iter/s, 16.2908s/100 iter), loss = 1.09524
I0630 04:03:33.739969 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 04:03:33.739975 29777 sgd_solver.cpp:106] Iteration 36100, lr = 0.00887187
I0630 04:03:49.892568 29777 solver.cpp:290] Iteration 36200 (6.19113 iter/s, 16.1521s/100 iter), loss = 0.809524
I0630 04:03:49.892660 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 04:03:49.892684 29777 sgd_solver.cpp:106] Iteration 36200, lr = 0.00886875
I0630 04:04:06.157912 29777 solver.cpp:290] Iteration 36300 (6.14824 iter/s, 16.2648s/100 iter), loss = 0.892857
I0630 04:04:06.157935 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:04:06.157943 29777 sgd_solver.cpp:106] Iteration 36300, lr = 0.00886562
I0630 04:04:22.481402 29777 solver.cpp:290] Iteration 36400 (6.12632 iter/s, 16.323s/100 iter), loss = 1.29762
I0630 04:04:22.481483 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 04:04:22.481494 29777 sgd_solver.cpp:106] Iteration 36400, lr = 0.0088625
I0630 04:04:38.624049 29777 solver.cpp:290] Iteration 36500 (6.19497 iter/s, 16.1421s/100 iter), loss = 1.47619
I0630 04:04:38.624075 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 04:04:38.624084 29777 sgd_solver.cpp:106] Iteration 36500, lr = 0.00885937
I0630 04:04:54.778462 29777 solver.cpp:290] Iteration 36600 (6.19044 iter/s, 16.1539s/100 iter), loss = 1.11905
I0630 04:04:54.778600 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:04:54.778610 29777 sgd_solver.cpp:106] Iteration 36600, lr = 0.00885625
I0630 04:05:11.150753 29777 solver.cpp:290] Iteration 36700 (6.1081 iter/s, 16.3717s/100 iter), loss = 1.05952
I0630 04:05:11.150776 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:05:11.150784 29777 sgd_solver.cpp:106] Iteration 36700, lr = 0.00885312
I0630 04:05:27.486974 29777 solver.cpp:290] Iteration 36800 (6.12155 iter/s, 16.3357s/100 iter), loss = 0.928571
I0630 04:05:27.487063 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 04:05:27.487074 29777 sgd_solver.cpp:106] Iteration 36800, lr = 0.00885
I0630 04:05:43.677691 29777 solver.cpp:290] Iteration 36900 (6.17658 iter/s, 16.1902s/100 iter), loss = 0.928571
I0630 04:05:43.677716 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 04:05:43.677728 29777 sgd_solver.cpp:106] Iteration 36900, lr = 0.00884687
I0630 04:05:59.627213 29777 solver.cpp:354] Sparsity after update:
I0630 04:05:59.651159 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:05:59.651232 29777 net.cpp:1851] conv1a_param_0(0.095) 
I0630 04:05:59.651257 29777 net.cpp:1851] conv1b_param_0(0.19) 
I0630 04:05:59.651269 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:05:59.651283 29777 net.cpp:1851] res2a_branch2a_param_0(0.19) 
I0630 04:05:59.651294 29777 net.cpp:1851] res2a_branch2b_param_0(0.19) 
I0630 04:05:59.651306 29777 net.cpp:1851] res3a_branch2a_param_0(0.19) 
I0630 04:05:59.651319 29777 net.cpp:1851] res3a_branch2b_param_0(0.19) 
I0630 04:05:59.651331 29777 net.cpp:1851] res4a_branch2a_param_0(0.19) 
I0630 04:05:59.651355 29777 net.cpp:1851] res4a_branch2b_param_0(0.19) 
I0630 04:05:59.651367 29777 net.cpp:1851] res5a_branch2a_param_0(0.19) 
I0630 04:05:59.651379 29777 net.cpp:1851] res5a_branch2b_param_0(0.19) 
I0630 04:05:59.651391 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (447171/2.86678e+06) 0.156
I0630 04:05:59.817381 29777 solver.cpp:290] Iteration 37000 (6.19609 iter/s, 16.1392s/100 iter), loss = 0.785714
I0630 04:05:59.817405 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 04:05:59.817412 29777 sgd_solver.cpp:106] Iteration 37000, lr = 0.00884375
I0630 04:06:16.070508 29777 solver.cpp:290] Iteration 37100 (6.15284 iter/s, 16.2527s/100 iter), loss = 1.13095
I0630 04:06:16.070530 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 04:06:16.070538 29777 sgd_solver.cpp:106] Iteration 37100, lr = 0.00884063
I0630 04:06:32.291038 29777 solver.cpp:290] Iteration 37200 (6.16521 iter/s, 16.2201s/100 iter), loss = 1.13095
I0630 04:06:32.291132 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 04:06:32.291143 29777 sgd_solver.cpp:106] Iteration 37200, lr = 0.0088375
I0630 04:06:48.478322 29777 solver.cpp:290] Iteration 37300 (6.17789 iter/s, 16.1867s/100 iter), loss = 1.08333
I0630 04:06:48.478346 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 04:06:48.478355 29777 sgd_solver.cpp:106] Iteration 37300, lr = 0.00883438
I0630 04:07:04.541342 29777 solver.cpp:290] Iteration 37400 (6.22566 iter/s, 16.0626s/100 iter), loss = 1.16667
I0630 04:07:04.541432 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:07:04.541443 29777 sgd_solver.cpp:106] Iteration 37400, lr = 0.00883125
I0630 04:07:20.847949 29777 solver.cpp:290] Iteration 37500 (6.13268 iter/s, 16.3061s/100 iter), loss = 1.40476
I0630 04:07:20.847972 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 04:07:20.847980 29777 sgd_solver.cpp:106] Iteration 37500, lr = 0.00882812
I0630 04:07:37.024722 29777 solver.cpp:290] Iteration 37600 (6.18188 iter/s, 16.1763s/100 iter), loss = 0.97619
I0630 04:07:37.024829 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:07:37.024848 29777 sgd_solver.cpp:106] Iteration 37600, lr = 0.008825
I0630 04:07:53.197958 29777 solver.cpp:290] Iteration 37700 (6.18326 iter/s, 16.1727s/100 iter), loss = 1.02381
I0630 04:07:53.197985 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:07:53.197994 29777 sgd_solver.cpp:106] Iteration 37700, lr = 0.00882187
I0630 04:08:09.294817 29777 solver.cpp:290] Iteration 37800 (6.21257 iter/s, 16.0964s/100 iter), loss = 1.07143
I0630 04:08:09.294926 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 04:08:09.294937 29777 sgd_solver.cpp:106] Iteration 37800, lr = 0.00881875
I0630 04:08:25.498790 29777 solver.cpp:290] Iteration 37900 (6.17154 iter/s, 16.2034s/100 iter), loss = 1.5
I0630 04:08:25.498817 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 04:08:25.498827 29777 sgd_solver.cpp:106] Iteration 37900, lr = 0.00881562
I0630 04:08:41.384981 29777 solver.cpp:354] Sparsity after update:
I0630 04:08:41.386425 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:08:41.386431 29777 net.cpp:1851] conv1a_param_0(0.095) 
I0630 04:08:41.386442 29777 net.cpp:1851] conv1b_param_0(0.19) 
I0630 04:08:41.386447 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:08:41.386452 29777 net.cpp:1851] res2a_branch2a_param_0(0.19) 
I0630 04:08:41.386456 29777 net.cpp:1851] res2a_branch2b_param_0(0.19) 
I0630 04:08:41.386461 29777 net.cpp:1851] res3a_branch2a_param_0(0.19) 
I0630 04:08:41.386466 29777 net.cpp:1851] res3a_branch2b_param_0(0.19) 
I0630 04:08:41.386469 29777 net.cpp:1851] res4a_branch2a_param_0(0.19) 
I0630 04:08:41.386473 29777 net.cpp:1851] res4a_branch2b_param_0(0.19) 
I0630 04:08:41.386478 29777 net.cpp:1851] res5a_branch2a_param_0(0.19) 
I0630 04:08:41.386482 29777 net.cpp:1851] res5a_branch2b_param_0(0.19) 
I0630 04:08:41.386487 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (447171/2.86678e+06) 0.156
I0630 04:08:41.386576 29777 solver.cpp:471] Iteration 38000, Testing net (#0)
I0630 04:08:45.586392 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:09:39.520534 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56184
I0630 04:09:39.520635 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.797021
I0630 04:09:39.520645 29777 solver.cpp:544]     Test net output #2: loss = 1.55784 (* 1 = 1.55784 loss)
I0630 04:09:39.708645 29777 solver.cpp:290] Iteration 38000 (1.34757 iter/s, 74.2078s/100 iter), loss = 0.690476
I0630 04:09:39.708672 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 04:09:39.708681 29777 sgd_solver.cpp:106] Iteration 38000, lr = 0.0088125
I0630 04:09:39.709666 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.2
I0630 04:09:39.854768 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:09:56.000033 29777 solver.cpp:290] Iteration 38100 (6.13839 iter/s, 16.2909s/100 iter), loss = 0.988095
I0630 04:09:56.000084 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 04:09:56.000108 29777 sgd_solver.cpp:106] Iteration 38100, lr = 0.00880937
I0630 04:10:12.189398 29777 solver.cpp:290] Iteration 38200 (6.17709 iter/s, 16.1889s/100 iter), loss = 1.13095
I0630 04:10:12.189544 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:10:12.189574 29777 sgd_solver.cpp:106] Iteration 38200, lr = 0.00880625
I0630 04:10:28.304299 29777 solver.cpp:290] Iteration 38300 (6.20567 iter/s, 16.1143s/100 iter), loss = 0.964286
I0630 04:10:28.304365 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 04:10:28.304385 29777 sgd_solver.cpp:106] Iteration 38300, lr = 0.00880312
I0630 04:10:44.377141 29777 solver.cpp:290] Iteration 38400 (6.22187 iter/s, 16.0723s/100 iter), loss = 1.09524
I0630 04:10:44.377246 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:10:44.377259 29777 sgd_solver.cpp:106] Iteration 38400, lr = 0.0088
I0630 04:11:00.461158 29777 solver.cpp:290] Iteration 38500 (6.21756 iter/s, 16.0835s/100 iter), loss = 1.05952
I0630 04:11:00.461181 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 04:11:00.461191 29777 sgd_solver.cpp:106] Iteration 38500, lr = 0.00879687
I0630 04:11:16.578414 29777 solver.cpp:290] Iteration 38600 (6.20471 iter/s, 16.1168s/100 iter), loss = 0.869048
I0630 04:11:16.578495 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 04:11:16.578503 29777 sgd_solver.cpp:106] Iteration 38600, lr = 0.00879375
I0630 04:11:32.666998 29777 solver.cpp:290] Iteration 38700 (6.21579 iter/s, 16.0881s/100 iter), loss = 0.809524
I0630 04:11:32.667026 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 04:11:32.667042 29777 sgd_solver.cpp:106] Iteration 38700, lr = 0.00879063
I0630 04:11:48.727879 29777 solver.cpp:290] Iteration 38800 (6.22649 iter/s, 16.0604s/100 iter), loss = 0.797619
I0630 04:11:48.727988 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:11:48.728003 29777 sgd_solver.cpp:106] Iteration 38800, lr = 0.0087875
I0630 04:12:04.861155 29777 solver.cpp:290] Iteration 38900 (6.19858 iter/s, 16.1327s/100 iter), loss = 1.13095
I0630 04:12:04.861179 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:12:04.861186 29777 sgd_solver.cpp:106] Iteration 38900, lr = 0.00878438
I0630 04:12:20.847887 29777 solver.cpp:354] Sparsity after update:
I0630 04:12:20.868929 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:12:20.868950 29777 net.cpp:1851] conv1a_param_0(0.1) 
I0630 04:12:20.868959 29777 net.cpp:1851] conv1b_param_0(0.2) 
I0630 04:12:20.868963 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:12:20.868966 29777 net.cpp:1851] res2a_branch2a_param_0(0.2) 
I0630 04:12:20.868969 29777 net.cpp:1851] res2a_branch2b_param_0(0.2) 
I0630 04:12:20.868973 29777 net.cpp:1851] res3a_branch2a_param_0(0.2) 
I0630 04:12:20.868986 29777 net.cpp:1851] res3a_branch2b_param_0(0.2) 
I0630 04:12:20.868989 29777 net.cpp:1851] res4a_branch2a_param_0(0.2) 
I0630 04:12:20.868993 29777 net.cpp:1851] res4a_branch2b_param_0(0.2) 
I0630 04:12:20.868995 29777 net.cpp:1851] res5a_branch2a_param_0(0.2) 
I0630 04:12:20.868999 29777 net.cpp:1851] res5a_branch2b_param_0(0.2) 
I0630 04:12:20.869002 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (470700/2.86678e+06) 0.164
I0630 04:12:21.022718 29777 solver.cpp:290] Iteration 39000 (6.1877 iter/s, 16.1611s/100 iter), loss = 0.904762
I0630 04:12:21.022810 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 04:12:21.022855 29777 sgd_solver.cpp:106] Iteration 39000, lr = 0.00878125
I0630 04:12:37.488791 29777 solver.cpp:290] Iteration 39100 (6.0733 iter/s, 16.4655s/100 iter), loss = 1.02381
I0630 04:12:37.488888 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 04:12:37.488917 29777 sgd_solver.cpp:106] Iteration 39100, lr = 0.00877813
I0630 04:12:53.574532 29777 solver.cpp:290] Iteration 39200 (6.21689 iter/s, 16.0852s/100 iter), loss = 1.08333
I0630 04:12:53.574620 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:12:53.574630 29777 sgd_solver.cpp:106] Iteration 39200, lr = 0.008775
I0630 04:13:09.734421 29777 solver.cpp:290] Iteration 39300 (6.18836 iter/s, 16.1594s/100 iter), loss = 1.05952
I0630 04:13:09.734446 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 04:13:09.734452 29777 sgd_solver.cpp:106] Iteration 39300, lr = 0.00877187
I0630 04:13:26.155921 29777 solver.cpp:290] Iteration 39400 (6.08976 iter/s, 16.421s/100 iter), loss = 0.964286
I0630 04:13:26.156042 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:13:26.156061 29777 sgd_solver.cpp:106] Iteration 39400, lr = 0.00876875
I0630 04:13:42.472317 29777 solver.cpp:290] Iteration 39500 (6.12902 iter/s, 16.3158s/100 iter), loss = 1.27381
I0630 04:13:42.472344 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 04:13:42.472353 29777 sgd_solver.cpp:106] Iteration 39500, lr = 0.00876562
I0630 04:13:58.734464 29777 solver.cpp:290] Iteration 39600 (6.14943 iter/s, 16.2617s/100 iter), loss = 1.19048
I0630 04:13:58.734578 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:13:58.734589 29777 sgd_solver.cpp:106] Iteration 39600, lr = 0.0087625
I0630 04:14:14.981557 29777 solver.cpp:290] Iteration 39700 (6.15516 iter/s, 16.2465s/100 iter), loss = 1.44048
I0630 04:14:14.981580 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 04:14:14.981586 29777 sgd_solver.cpp:106] Iteration 39700, lr = 0.00875937
I0630 04:14:31.312531 29777 solver.cpp:290] Iteration 39800 (6.12351 iter/s, 16.3305s/100 iter), loss = 0.952381
I0630 04:14:31.312624 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 04:14:31.312636 29777 sgd_solver.cpp:106] Iteration 39800, lr = 0.00875625
I0630 04:14:47.668221 29777 solver.cpp:290] Iteration 39900 (6.11428 iter/s, 16.3551s/100 iter), loss = 0.988095
I0630 04:14:47.668242 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 04:14:47.668249 29777 sgd_solver.cpp:106] Iteration 39900, lr = 0.00875312
I0630 04:15:03.858249 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_40000.caffemodel
I0630 04:15:03.878159 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_40000.solverstate
I0630 04:15:03.886739 29777 solver.cpp:354] Sparsity after update:
I0630 04:15:03.887707 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:15:03.887717 29777 net.cpp:1851] conv1a_param_0(0.1) 
I0630 04:15:03.887724 29777 net.cpp:1851] conv1b_param_0(0.2) 
I0630 04:15:03.887727 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:15:03.887730 29777 net.cpp:1851] res2a_branch2a_param_0(0.2) 
I0630 04:15:03.887733 29777 net.cpp:1851] res2a_branch2b_param_0(0.2) 
I0630 04:15:03.887737 29777 net.cpp:1851] res3a_branch2a_param_0(0.2) 
I0630 04:15:03.887738 29777 net.cpp:1851] res3a_branch2b_param_0(0.2) 
I0630 04:15:03.887740 29777 net.cpp:1851] res4a_branch2a_param_0(0.2) 
I0630 04:15:03.887742 29777 net.cpp:1851] res4a_branch2b_param_0(0.2) 
I0630 04:15:03.887744 29777 net.cpp:1851] res5a_branch2a_param_0(0.2) 
I0630 04:15:03.887748 29777 net.cpp:1851] res5a_branch2b_param_0(0.2) 
I0630 04:15:03.887749 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (470700/2.86678e+06) 0.164
I0630 04:15:03.887847 29777 solver.cpp:471] Iteration 40000, Testing net (#0)
I0630 04:15:08.760001 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:16:11.910348 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55972
I0630 04:16:11.910490 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.79596
I0630 04:16:11.910509 29777 solver.cpp:544]     Test net output #2: loss = 1.5758 (* 1 = 1.5758 loss)
I0630 04:16:12.159060 29777 solver.cpp:290] Iteration 40000 (1.18359 iter/s, 84.4885s/100 iter), loss = 0.988095
I0630 04:16:12.159107 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 04:16:12.159123 29777 sgd_solver.cpp:106] Iteration 40000, lr = 0.00875
I0630 04:16:12.160686 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.21
I0630 04:16:12.419412 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:16:28.510962 29777 solver.cpp:290] Iteration 40100 (6.11568 iter/s, 16.3514s/100 iter), loss = 1.17857
I0630 04:16:28.510984 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 04:16:28.510990 29777 sgd_solver.cpp:106] Iteration 40100, lr = 0.00874687
I0630 04:16:44.741191 29777 solver.cpp:290] Iteration 40200 (6.16152 iter/s, 16.2298s/100 iter), loss = 1.15476
I0630 04:16:44.741297 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 04:16:44.741307 29777 sgd_solver.cpp:106] Iteration 40200, lr = 0.00874375
I0630 04:17:01.068835 29777 solver.cpp:290] Iteration 40300 (6.12479 iter/s, 16.3271s/100 iter), loss = 1.03571
I0630 04:17:01.068857 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:17:01.068864 29777 sgd_solver.cpp:106] Iteration 40300, lr = 0.00874062
I0630 04:17:17.316555 29777 solver.cpp:290] Iteration 40400 (6.15489 iter/s, 16.2472s/100 iter), loss = 1.20238
I0630 04:17:17.318898 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 04:17:17.318925 29777 sgd_solver.cpp:106] Iteration 40400, lr = 0.0087375
I0630 04:17:33.543649 29777 solver.cpp:290] Iteration 40500 (6.16359 iter/s, 16.2243s/100 iter), loss = 1.05952
I0630 04:17:33.543716 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:17:33.543740 29777 sgd_solver.cpp:106] Iteration 40500, lr = 0.00873438
I0630 04:17:49.880261 29777 solver.cpp:290] Iteration 40600 (6.12141 iter/s, 16.3361s/100 iter), loss = 0.857143
I0630 04:17:49.880347 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:17:49.880355 29777 sgd_solver.cpp:106] Iteration 40600, lr = 0.00873125
I0630 04:18:06.516165 29777 solver.cpp:290] Iteration 40700 (6.0113 iter/s, 16.6353s/100 iter), loss = 0.77381
I0630 04:18:06.516432 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 04:18:06.516552 29777 sgd_solver.cpp:106] Iteration 40700, lr = 0.00872813
I0630 04:18:23.404144 29777 solver.cpp:290] Iteration 40800 (5.92162 iter/s, 16.8873s/100 iter), loss = 1.39286
I0630 04:18:23.404214 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 04:18:23.404225 29777 sgd_solver.cpp:106] Iteration 40800, lr = 0.008725
I0630 04:18:39.503809 29777 solver.cpp:290] Iteration 40900 (6.21151 iter/s, 16.0992s/100 iter), loss = 1.2619
I0630 04:18:39.503834 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 04:18:39.503840 29777 sgd_solver.cpp:106] Iteration 40900, lr = 0.00872188
I0630 04:18:55.535756 29777 solver.cpp:354] Sparsity after update:
I0630 04:18:55.556022 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:18:55.556044 29777 net.cpp:1851] conv1a_param_0(0.105) 
I0630 04:18:55.556056 29777 net.cpp:1851] conv1b_param_0(0.21) 
I0630 04:18:55.556061 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:18:55.556063 29777 net.cpp:1851] res2a_branch2a_param_0(0.21) 
I0630 04:18:55.556066 29777 net.cpp:1851] res2a_branch2b_param_0(0.21) 
I0630 04:18:55.556071 29777 net.cpp:1851] res3a_branch2a_param_0(0.21) 
I0630 04:18:55.556078 29777 net.cpp:1851] res3a_branch2b_param_0(0.21) 
I0630 04:18:55.556084 29777 net.cpp:1851] res4a_branch2a_param_0(0.21) 
I0630 04:18:55.556089 29777 net.cpp:1851] res4a_branch2b_param_0(0.21) 
I0630 04:18:55.556093 29777 net.cpp:1851] res5a_branch2a_param_0(0.21) 
I0630 04:18:55.556098 29777 net.cpp:1851] res5a_branch2b_param_0(0.21) 
I0630 04:18:55.556103 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (494241/2.86678e+06) 0.172
I0630 04:18:55.724050 29777 solver.cpp:290] Iteration 41000 (6.16532 iter/s, 16.2198s/100 iter), loss = 1.14286
I0630 04:18:55.724104 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 04:18:55.724128 29777 sgd_solver.cpp:106] Iteration 41000, lr = 0.00871875
I0630 04:19:12.116008 29777 solver.cpp:290] Iteration 41100 (6.10074 iter/s, 16.3915s/100 iter), loss = 1.27381
I0630 04:19:12.116055 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 04:19:12.116091 29777 sgd_solver.cpp:106] Iteration 41100, lr = 0.00871562
I0630 04:19:28.380409 29777 solver.cpp:290] Iteration 41200 (6.14858 iter/s, 16.2639s/100 iter), loss = 0.702381
I0630 04:19:28.380523 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 04:19:28.380533 29777 sgd_solver.cpp:106] Iteration 41200, lr = 0.0087125
I0630 04:19:44.542665 29777 solver.cpp:290] Iteration 41300 (6.18747 iter/s, 16.1617s/100 iter), loss = 0.809524
I0630 04:19:44.542690 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 04:19:44.542698 29777 sgd_solver.cpp:106] Iteration 41300, lr = 0.00870937
I0630 04:20:00.680043 29777 solver.cpp:290] Iteration 41400 (6.19697 iter/s, 16.1369s/100 iter), loss = 1.11905
I0630 04:20:00.680155 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:20:00.680171 29777 sgd_solver.cpp:106] Iteration 41400, lr = 0.00870625
I0630 04:20:16.893708 29777 solver.cpp:290] Iteration 41500 (6.16785 iter/s, 16.2131s/100 iter), loss = 1.14286
I0630 04:20:16.893733 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:20:16.893739 29777 sgd_solver.cpp:106] Iteration 41500, lr = 0.00870312
I0630 04:20:33.191035 29777 solver.cpp:290] Iteration 41600 (6.13615 iter/s, 16.2969s/100 iter), loss = 1.20238
I0630 04:20:33.191125 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 04:20:33.191136 29777 sgd_solver.cpp:106] Iteration 41600, lr = 0.0087
I0630 04:20:49.405822 29777 solver.cpp:290] Iteration 41700 (6.16741 iter/s, 16.2143s/100 iter), loss = 1.10714
I0630 04:20:49.405844 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:20:49.405851 29777 sgd_solver.cpp:106] Iteration 41700, lr = 0.00869687
I0630 04:21:05.656167 29777 solver.cpp:290] Iteration 41800 (6.15389 iter/s, 16.2499s/100 iter), loss = 1.03571
I0630 04:21:05.656242 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:21:05.656250 29777 sgd_solver.cpp:106] Iteration 41800, lr = 0.00869375
I0630 04:21:21.960932 29777 solver.cpp:290] Iteration 41900 (6.13337 iter/s, 16.3042s/100 iter), loss = 1.19048
I0630 04:21:21.960957 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:21:21.960963 29777 sgd_solver.cpp:106] Iteration 41900, lr = 0.00869062
I0630 04:21:38.094594 29777 solver.cpp:354] Sparsity after update:
I0630 04:21:38.095868 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:21:38.095876 29777 net.cpp:1851] conv1a_param_0(0.105) 
I0630 04:21:38.095883 29777 net.cpp:1851] conv1b_param_0(0.21) 
I0630 04:21:38.095885 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:21:38.095887 29777 net.cpp:1851] res2a_branch2a_param_0(0.21) 
I0630 04:21:38.095890 29777 net.cpp:1851] res2a_branch2b_param_0(0.21) 
I0630 04:21:38.095891 29777 net.cpp:1851] res3a_branch2a_param_0(0.21) 
I0630 04:21:38.095893 29777 net.cpp:1851] res3a_branch2b_param_0(0.21) 
I0630 04:21:38.095896 29777 net.cpp:1851] res4a_branch2a_param_0(0.21) 
I0630 04:21:38.095897 29777 net.cpp:1851] res4a_branch2b_param_0(0.21) 
I0630 04:21:38.095899 29777 net.cpp:1851] res5a_branch2a_param_0(0.21) 
I0630 04:21:38.095901 29777 net.cpp:1851] res5a_branch2b_param_0(0.21) 
I0630 04:21:38.095903 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (494241/2.86678e+06) 0.172
I0630 04:21:38.095994 29777 solver.cpp:471] Iteration 42000, Testing net (#0)
I0630 04:21:43.651549 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:22:39.943482 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56654
I0630 04:22:39.943528 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.798922
I0630 04:22:39.943536 29777 solver.cpp:544]     Test net output #2: loss = 1.5711 (* 1 = 1.5711 loss)
I0630 04:22:40.128012 29777 solver.cpp:290] Iteration 42000 (1.27935 iter/s, 78.1649s/100 iter), loss = 1.25
I0630 04:22:40.128036 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:22:40.128042 29777 sgd_solver.cpp:106] Iteration 42000, lr = 0.0086875
I0630 04:22:40.128787 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.22
I0630 04:22:40.286159 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:22:56.466037 29777 solver.cpp:290] Iteration 42100 (6.12087 iter/s, 16.3375s/100 iter), loss = 1.02381
I0630 04:22:56.466060 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:22:56.466066 29777 sgd_solver.cpp:106] Iteration 42100, lr = 0.00868438
I0630 04:23:12.629448 29777 solver.cpp:290] Iteration 42200 (6.18699 iter/s, 16.1629s/100 iter), loss = 1.02381
I0630 04:23:12.629554 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:23:12.629565 29777 sgd_solver.cpp:106] Iteration 42200, lr = 0.00868125
I0630 04:23:28.604027 29777 solver.cpp:290] Iteration 42300 (6.26016 iter/s, 15.974s/100 iter), loss = 1.32143
I0630 04:23:28.604054 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 04:23:28.604063 29777 sgd_solver.cpp:106] Iteration 42300, lr = 0.00867813
I0630 04:23:44.820602 29777 solver.cpp:290] Iteration 42400 (6.16671 iter/s, 16.2161s/100 iter), loss = 0.928571
I0630 04:23:44.820675 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 04:23:44.820686 29777 sgd_solver.cpp:106] Iteration 42400, lr = 0.008675
I0630 04:24:01.015074 29777 solver.cpp:290] Iteration 42500 (6.17514 iter/s, 16.194s/100 iter), loss = 1.28571
I0630 04:24:01.015100 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 04:24:01.015108 29777 sgd_solver.cpp:106] Iteration 42500, lr = 0.00867188
I0630 04:24:17.253263 29777 solver.cpp:290] Iteration 42600 (6.1585 iter/s, 16.2377s/100 iter), loss = 1.25
I0630 04:24:17.253600 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:24:17.253609 29777 sgd_solver.cpp:106] Iteration 42600, lr = 0.00866875
I0630 04:24:33.453022 29777 solver.cpp:290] Iteration 42700 (6.17323 iter/s, 16.199s/100 iter), loss = 1.32143
I0630 04:24:33.453055 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 04:24:33.453065 29777 sgd_solver.cpp:106] Iteration 42700, lr = 0.00866563
I0630 04:24:49.597627 29777 solver.cpp:290] Iteration 42800 (6.1942 iter/s, 16.1441s/100 iter), loss = 0.928571
I0630 04:24:49.597756 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 04:24:49.597774 29777 sgd_solver.cpp:106] Iteration 42800, lr = 0.0086625
I0630 04:25:05.976855 29777 solver.cpp:290] Iteration 42900 (6.10551 iter/s, 16.3787s/100 iter), loss = 1.20238
I0630 04:25:05.976891 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:25:05.976902 29777 sgd_solver.cpp:106] Iteration 42900, lr = 0.00865937
I0630 04:25:22.036689 29777 solver.cpp:354] Sparsity after update:
I0630 04:25:22.056932 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:25:22.056967 29777 net.cpp:1851] conv1a_param_0(0.11) 
I0630 04:25:22.056999 29777 net.cpp:1851] conv1b_param_0(0.22) 
I0630 04:25:22.057014 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:25:22.057026 29777 net.cpp:1851] res2a_branch2a_param_0(0.22) 
I0630 04:25:22.057035 29777 net.cpp:1851] res2a_branch2b_param_0(0.22) 
I0630 04:25:22.057044 29777 net.cpp:1851] res3a_branch2a_param_0(0.22) 
I0630 04:25:22.057051 29777 net.cpp:1851] res3a_branch2b_param_0(0.22) 
I0630 04:25:22.057060 29777 net.cpp:1851] res4a_branch2a_param_0(0.22) 
I0630 04:25:22.057067 29777 net.cpp:1851] res4a_branch2b_param_0(0.22) 
I0630 04:25:22.057075 29777 net.cpp:1851] res5a_branch2a_param_0(0.22) 
I0630 04:25:22.057083 29777 net.cpp:1851] res5a_branch2b_param_0(0.22) 
I0630 04:25:22.057091 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (517776/2.86678e+06) 0.181
I0630 04:25:22.219544 29777 solver.cpp:290] Iteration 43000 (6.1568 iter/s, 16.2422s/100 iter), loss = 0.797619
I0630 04:25:22.219574 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 04:25:22.219583 29777 sgd_solver.cpp:106] Iteration 43000, lr = 0.00865625
I0630 04:25:38.518622 29777 solver.cpp:290] Iteration 43100 (6.1355 iter/s, 16.2986s/100 iter), loss = 1.13095
I0630 04:25:38.518645 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 04:25:38.518652 29777 sgd_solver.cpp:106] Iteration 43100, lr = 0.00865312
I0630 04:25:54.546969 29777 solver.cpp:290] Iteration 43200 (6.23913 iter/s, 16.0279s/100 iter), loss = 1.15476
I0630 04:25:54.547379 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 04:25:54.547389 29777 sgd_solver.cpp:106] Iteration 43200, lr = 0.00865
I0630 04:26:10.577729 29777 solver.cpp:290] Iteration 43300 (6.23834 iter/s, 16.0299s/100 iter), loss = 1.41667
I0630 04:26:10.577751 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 04:26:10.577757 29777 sgd_solver.cpp:106] Iteration 43300, lr = 0.00864687
I0630 04:26:26.814250 29777 solver.cpp:290] Iteration 43400 (6.15913 iter/s, 16.2361s/100 iter), loss = 1.36905
I0630 04:26:26.814359 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 04:26:26.814369 29777 sgd_solver.cpp:106] Iteration 43400, lr = 0.00864375
I0630 04:26:43.079380 29777 solver.cpp:290] Iteration 43500 (6.14833 iter/s, 16.2646s/100 iter), loss = 1.09524
I0630 04:26:43.079408 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 04:26:43.079417 29777 sgd_solver.cpp:106] Iteration 43500, lr = 0.00864062
I0630 04:26:59.085940 29777 solver.cpp:290] Iteration 43600 (6.24762 iter/s, 16.0061s/100 iter), loss = 0.869048
I0630 04:26:59.086011 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 04:26:59.086019 29777 sgd_solver.cpp:106] Iteration 43600, lr = 0.0086375
I0630 04:27:15.397831 29777 solver.cpp:290] Iteration 43700 (6.13069 iter/s, 16.3114s/100 iter), loss = 0.821429
I0630 04:27:15.397855 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 04:27:15.397862 29777 sgd_solver.cpp:106] Iteration 43700, lr = 0.00863438
I0630 04:27:31.456531 29777 solver.cpp:290] Iteration 43800 (6.22733 iter/s, 16.0582s/100 iter), loss = 1.15476
I0630 04:27:31.456601 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 04:27:31.456609 29777 sgd_solver.cpp:106] Iteration 43800, lr = 0.00863125
I0630 04:27:47.645931 29777 solver.cpp:290] Iteration 43900 (6.17708 iter/s, 16.1889s/100 iter), loss = 1.34524
I0630 04:27:47.645956 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:27:47.645961 29777 sgd_solver.cpp:106] Iteration 43900, lr = 0.00862813
I0630 04:28:03.540266 29777 solver.cpp:354] Sparsity after update:
I0630 04:28:03.541708 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:28:03.541715 29777 net.cpp:1851] conv1a_param_0(0.11) 
I0630 04:28:03.541723 29777 net.cpp:1851] conv1b_param_0(0.22) 
I0630 04:28:03.541725 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:28:03.541728 29777 net.cpp:1851] res2a_branch2a_param_0(0.22) 
I0630 04:28:03.541730 29777 net.cpp:1851] res2a_branch2b_param_0(0.22) 
I0630 04:28:03.541733 29777 net.cpp:1851] res3a_branch2a_param_0(0.22) 
I0630 04:28:03.541733 29777 net.cpp:1851] res3a_branch2b_param_0(0.22) 
I0630 04:28:03.541735 29777 net.cpp:1851] res4a_branch2a_param_0(0.22) 
I0630 04:28:03.541738 29777 net.cpp:1851] res4a_branch2b_param_0(0.22) 
I0630 04:28:03.541739 29777 net.cpp:1851] res5a_branch2a_param_0(0.22) 
I0630 04:28:03.541741 29777 net.cpp:1851] res5a_branch2b_param_0(0.22) 
I0630 04:28:03.541743 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (517776/2.86678e+06) 0.181
I0630 04:28:03.541836 29777 solver.cpp:471] Iteration 44000, Testing net (#0)
I0630 04:28:07.863615 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:29:07.743731 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56572
I0630 04:29:07.743850 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801101
I0630 04:29:07.743860 29777 solver.cpp:544]     Test net output #2: loss = 1.56068 (* 1 = 1.56068 loss)
I0630 04:29:07.923477 29777 solver.cpp:290] Iteration 44000 (1.24571 iter/s, 80.2754s/100 iter), loss = 0.809524
I0630 04:29:07.923501 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 04:29:07.923507 29777 sgd_solver.cpp:106] Iteration 44000, lr = 0.008625
I0630 04:29:07.924203 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.23
I0630 04:29:08.081575 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:29:24.062317 29777 solver.cpp:290] Iteration 44100 (6.19641 iter/s, 16.1384s/100 iter), loss = 0.77381
I0630 04:29:24.062369 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 04:29:24.062382 29777 sgd_solver.cpp:106] Iteration 44100, lr = 0.00862188
I0630 04:29:40.269203 29777 solver.cpp:290] Iteration 44200 (6.17041 iter/s, 16.2064s/100 iter), loss = 0.964286
I0630 04:29:40.269294 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 04:29:40.269305 29777 sgd_solver.cpp:106] Iteration 44200, lr = 0.00861875
I0630 04:29:56.713963 29777 solver.cpp:290] Iteration 44300 (6.08116 iter/s, 16.4442s/100 iter), loss = 0.845238
I0630 04:29:56.713989 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:29:56.713997 29777 sgd_solver.cpp:106] Iteration 44300, lr = 0.00861563
I0630 04:30:13.610903 29777 solver.cpp:290] Iteration 44400 (5.9184 iter/s, 16.8965s/100 iter), loss = 1.07143
I0630 04:30:13.610958 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 04:30:13.610966 29777 sgd_solver.cpp:106] Iteration 44400, lr = 0.0086125
I0630 04:30:29.832273 29777 solver.cpp:290] Iteration 44500 (6.1649 iter/s, 16.2209s/100 iter), loss = 1.05952
I0630 04:30:29.832298 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:30:29.832304 29777 sgd_solver.cpp:106] Iteration 44500, lr = 0.00860937
I0630 04:30:46.269273 29777 solver.cpp:290] Iteration 44600 (6.08401 iter/s, 16.4365s/100 iter), loss = 1.0119
I0630 04:30:46.269556 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:30:46.269676 29777 sgd_solver.cpp:106] Iteration 44600, lr = 0.00860625
I0630 04:31:02.710292 29777 solver.cpp:290] Iteration 44700 (6.08262 iter/s, 16.4403s/100 iter), loss = 1.44048
I0630 04:31:02.710510 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 04:31:02.710634 29777 sgd_solver.cpp:106] Iteration 44700, lr = 0.00860312
I0630 04:31:18.954835 29777 solver.cpp:290] Iteration 44800 (6.15617 iter/s, 16.2439s/100 iter), loss = 1.2619
I0630 04:31:18.954932 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 04:31:18.954941 29777 sgd_solver.cpp:106] Iteration 44800, lr = 0.0086
I0630 04:31:35.031038 29777 solver.cpp:290] Iteration 44900 (6.22058 iter/s, 16.0757s/100 iter), loss = 1.35714
I0630 04:31:35.031061 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:31:35.031070 29777 sgd_solver.cpp:106] Iteration 44900, lr = 0.00859687
I0630 04:31:51.096997 29777 solver.cpp:354] Sparsity after update:
I0630 04:31:51.117339 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:31:51.117363 29777 net.cpp:1851] conv1a_param_0(0.115) 
I0630 04:31:51.117377 29777 net.cpp:1851] conv1b_param_0(0.23) 
I0630 04:31:51.117380 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:31:51.117384 29777 net.cpp:1851] res2a_branch2a_param_0(0.23) 
I0630 04:31:51.117388 29777 net.cpp:1851] res2a_branch2b_param_0(0.23) 
I0630 04:31:51.117400 29777 net.cpp:1851] res3a_branch2a_param_0(0.23) 
I0630 04:31:51.117406 29777 net.cpp:1851] res3a_branch2b_param_0(0.23) 
I0630 04:31:51.117411 29777 net.cpp:1851] res4a_branch2a_param_0(0.23) 
I0630 04:31:51.117418 29777 net.cpp:1851] res4a_branch2b_param_0(0.23) 
I0630 04:31:51.117420 29777 net.cpp:1851] res5a_branch2a_param_0(0.23) 
I0630 04:31:51.117424 29777 net.cpp:1851] res5a_branch2b_param_0(0.23) 
I0630 04:31:51.117427 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (541310/2.86678e+06) 0.189
I0630 04:31:51.279862 29777 solver.cpp:290] Iteration 45000 (6.15447 iter/s, 16.2483s/100 iter), loss = 0.988095
I0630 04:31:51.279911 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:31:51.279929 29777 sgd_solver.cpp:106] Iteration 45000, lr = 0.00859375
I0630 04:32:07.798758 29777 solver.cpp:290] Iteration 45100 (6.05386 iter/s, 16.5184s/100 iter), loss = 1.10714
I0630 04:32:07.798804 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 04:32:07.798844 29777 sgd_solver.cpp:106] Iteration 45100, lr = 0.00859062
I0630 04:32:24.145495 29777 solver.cpp:290] Iteration 45200 (6.11761 iter/s, 16.3462s/100 iter), loss = 0.77381
I0630 04:32:24.145607 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 04:32:24.145617 29777 sgd_solver.cpp:106] Iteration 45200, lr = 0.0085875
I0630 04:32:40.466820 29777 solver.cpp:290] Iteration 45300 (6.12716 iter/s, 16.3208s/100 iter), loss = 1.15476
I0630 04:32:40.466848 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:32:40.466856 29777 sgd_solver.cpp:106] Iteration 45300, lr = 0.00858437
I0630 04:32:56.800904 29777 solver.cpp:290] Iteration 45400 (6.12235 iter/s, 16.3336s/100 iter), loss = 1
I0630 04:32:56.800997 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:32:56.801009 29777 sgd_solver.cpp:106] Iteration 45400, lr = 0.00858125
I0630 04:33:13.182462 29777 solver.cpp:290] Iteration 45500 (6.10463 iter/s, 16.381s/100 iter), loss = 1.2381
I0630 04:33:13.182485 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 04:33:13.182494 29777 sgd_solver.cpp:106] Iteration 45500, lr = 0.00857813
I0630 04:33:29.466867 29777 solver.cpp:290] Iteration 45600 (6.14102 iter/s, 16.2839s/100 iter), loss = 0.77381
I0630 04:33:29.466953 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 04:33:29.466966 29777 sgd_solver.cpp:106] Iteration 45600, lr = 0.008575
I0630 04:33:45.824398 29777 solver.cpp:290] Iteration 45700 (6.11359 iter/s, 16.357s/100 iter), loss = 1.08333
I0630 04:33:45.824424 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 04:33:45.824432 29777 sgd_solver.cpp:106] Iteration 45700, lr = 0.00857188
I0630 04:34:01.990056 29777 solver.cpp:290] Iteration 45800 (6.18613 iter/s, 16.1652s/100 iter), loss = 0.940476
I0630 04:34:01.990139 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 04:34:01.990149 29777 sgd_solver.cpp:106] Iteration 45800, lr = 0.00856875
I0630 04:34:18.829054 29777 solver.cpp:290] Iteration 45900 (5.93879 iter/s, 16.8385s/100 iter), loss = 1.13095
I0630 04:34:18.829079 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 04:34:18.829088 29777 sgd_solver.cpp:106] Iteration 45900, lr = 0.00856563
I0630 04:34:34.891396 29777 solver.cpp:354] Sparsity after update:
I0630 04:34:34.892837 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:34:34.892843 29777 net.cpp:1851] conv1a_param_0(0.115) 
I0630 04:34:34.892850 29777 net.cpp:1851] conv1b_param_0(0.23) 
I0630 04:34:34.892853 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:34:34.892854 29777 net.cpp:1851] res2a_branch2a_param_0(0.23) 
I0630 04:34:34.892856 29777 net.cpp:1851] res2a_branch2b_param_0(0.23) 
I0630 04:34:34.892858 29777 net.cpp:1851] res3a_branch2a_param_0(0.23) 
I0630 04:34:34.892860 29777 net.cpp:1851] res3a_branch2b_param_0(0.23) 
I0630 04:34:34.892863 29777 net.cpp:1851] res4a_branch2a_param_0(0.23) 
I0630 04:34:34.892864 29777 net.cpp:1851] res4a_branch2b_param_0(0.23) 
I0630 04:34:34.892866 29777 net.cpp:1851] res5a_branch2a_param_0(0.23) 
I0630 04:34:34.892868 29777 net.cpp:1851] res5a_branch2b_param_0(0.23) 
I0630 04:34:34.892870 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (541310/2.86678e+06) 0.189
I0630 04:34:34.892956 29777 solver.cpp:471] Iteration 46000, Testing net (#0)
I0630 04:34:40.761488 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:35:43.134003 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.565259
I0630 04:35:43.134126 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.800741
I0630 04:35:43.134136 29777 solver.cpp:544]     Test net output #2: loss = 1.53432 (* 1 = 1.53432 loss)
I0630 04:35:43.313621 29777 solver.cpp:290] Iteration 46000 (1.18368 iter/s, 84.4822s/100 iter), loss = 0.916667
I0630 04:35:43.313643 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:35:43.313649 29777 sgd_solver.cpp:106] Iteration 46000, lr = 0.0085625
I0630 04:35:43.314358 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.24
I0630 04:35:43.489681 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:35:59.746204 29777 solver.cpp:290] Iteration 46100 (6.08565 iter/s, 16.4321s/100 iter), loss = 0.916667
I0630 04:35:59.746253 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:35:59.746268 29777 sgd_solver.cpp:106] Iteration 46100, lr = 0.00855938
I0630 04:36:15.877315 29777 solver.cpp:290] Iteration 46200 (6.19939 iter/s, 16.1306s/100 iter), loss = 1.2619
I0630 04:36:15.877446 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:36:15.877481 29777 sgd_solver.cpp:106] Iteration 46200, lr = 0.00855625
I0630 04:36:31.983208 29777 solver.cpp:290] Iteration 46300 (6.20913 iter/s, 16.1053s/100 iter), loss = 0.833333
I0630 04:36:31.983234 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:36:31.983242 29777 sgd_solver.cpp:106] Iteration 46300, lr = 0.00855312
I0630 04:36:48.173192 29777 solver.cpp:290] Iteration 46400 (6.17684 iter/s, 16.1895s/100 iter), loss = 1.15476
I0630 04:36:48.173297 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 04:36:48.173307 29777 sgd_solver.cpp:106] Iteration 46400, lr = 0.00855
I0630 04:37:04.314734 29777 solver.cpp:290] Iteration 46500 (6.19541 iter/s, 16.141s/100 iter), loss = 1.36905
I0630 04:37:04.314759 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 04:37:04.314765 29777 sgd_solver.cpp:106] Iteration 46500, lr = 0.00854687
I0630 04:37:20.455193 29777 solver.cpp:290] Iteration 46600 (6.19579 iter/s, 16.14s/100 iter), loss = 0.869048
I0630 04:37:20.455265 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 04:37:20.455276 29777 sgd_solver.cpp:106] Iteration 46600, lr = 0.00854375
I0630 04:37:36.645431 29777 solver.cpp:290] Iteration 46700 (6.17676 iter/s, 16.1897s/100 iter), loss = 0.964286
I0630 04:37:36.645457 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:37:36.645476 29777 sgd_solver.cpp:106] Iteration 46700, lr = 0.00854062
I0630 04:37:52.993628 29777 solver.cpp:290] Iteration 46800 (6.11706 iter/s, 16.3477s/100 iter), loss = 1.03571
I0630 04:37:52.993732 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:37:52.993742 29777 sgd_solver.cpp:106] Iteration 46800, lr = 0.0085375
I0630 04:38:09.156746 29777 solver.cpp:290] Iteration 46900 (6.18713 iter/s, 16.1626s/100 iter), loss = 0.916667
I0630 04:38:09.156770 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 04:38:09.156777 29777 sgd_solver.cpp:106] Iteration 46900, lr = 0.00853437
I0630 04:38:25.241323 29777 solver.cpp:354] Sparsity after update:
I0630 04:38:25.261468 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:38:25.261530 29777 net.cpp:1851] conv1a_param_0(0.12) 
I0630 04:38:25.261571 29777 net.cpp:1851] conv1b_param_0(0.24) 
I0630 04:38:25.261591 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:38:25.261610 29777 net.cpp:1851] res2a_branch2a_param_0(0.24) 
I0630 04:38:25.261626 29777 net.cpp:1851] res2a_branch2b_param_0(0.24) 
I0630 04:38:25.261641 29777 net.cpp:1851] res3a_branch2a_param_0(0.24) 
I0630 04:38:25.261656 29777 net.cpp:1851] res3a_branch2b_param_0(0.24) 
I0630 04:38:25.261672 29777 net.cpp:1851] res4a_branch2a_param_0(0.24) 
I0630 04:38:25.261687 29777 net.cpp:1851] res4a_branch2b_param_0(0.24) 
I0630 04:38:25.261703 29777 net.cpp:1851] res5a_branch2a_param_0(0.24) 
I0630 04:38:25.261718 29777 net.cpp:1851] res5a_branch2b_param_0(0.24) 
I0630 04:38:25.261735 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (564847/2.86678e+06) 0.197
I0630 04:38:25.418718 29777 solver.cpp:290] Iteration 47000 (6.14949 iter/s, 16.2615s/100 iter), loss = 0.75
I0630 04:38:25.418740 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 04:38:25.418747 29777 sgd_solver.cpp:106] Iteration 47000, lr = 0.00853125
I0630 04:38:41.565496 29777 solver.cpp:290] Iteration 47100 (6.19336 iter/s, 16.1463s/100 iter), loss = 0.869048
I0630 04:38:41.565522 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 04:38:41.565531 29777 sgd_solver.cpp:106] Iteration 47100, lr = 0.00852813
I0630 04:38:57.840775 29777 solver.cpp:290] Iteration 47200 (6.14447 iter/s, 16.2748s/100 iter), loss = 1.40476
I0630 04:38:57.840838 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 04:38:57.840847 29777 sgd_solver.cpp:106] Iteration 47200, lr = 0.008525
I0630 04:39:13.931324 29777 solver.cpp:290] Iteration 47300 (6.21502 iter/s, 16.09s/100 iter), loss = 1.11905
I0630 04:39:13.931346 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:39:13.931354 29777 sgd_solver.cpp:106] Iteration 47300, lr = 0.00852188
I0630 04:39:30.030982 29777 solver.cpp:290] Iteration 47400 (6.21149 iter/s, 16.0992s/100 iter), loss = 0.964286
I0630 04:39:30.031097 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:39:30.031122 29777 sgd_solver.cpp:106] Iteration 47400, lr = 0.00851875
I0630 04:39:46.002210 29777 solver.cpp:290] Iteration 47500 (6.26148 iter/s, 15.9707s/100 iter), loss = 0.964286
I0630 04:39:46.002236 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 04:39:46.002245 29777 sgd_solver.cpp:106] Iteration 47500, lr = 0.00851563
I0630 04:40:02.155885 29777 solver.cpp:290] Iteration 47600 (6.19072 iter/s, 16.1532s/100 iter), loss = 1
I0630 04:40:02.155990 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 04:40:02.156002 29777 sgd_solver.cpp:106] Iteration 47600, lr = 0.0085125
I0630 04:40:18.290607 29777 solver.cpp:290] Iteration 47700 (6.19802 iter/s, 16.1342s/100 iter), loss = 0.869048
I0630 04:40:18.290634 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 04:40:18.290643 29777 sgd_solver.cpp:106] Iteration 47700, lr = 0.00850937
I0630 04:40:34.433589 29777 solver.cpp:290] Iteration 47800 (6.19482 iter/s, 16.1425s/100 iter), loss = 0.869048
I0630 04:40:34.433969 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 04:40:34.433980 29777 sgd_solver.cpp:106] Iteration 47800, lr = 0.00850625
I0630 04:40:50.762356 29777 solver.cpp:290] Iteration 47900 (6.12447 iter/s, 16.3279s/100 iter), loss = 1.10714
I0630 04:40:50.762378 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 04:40:50.762384 29777 sgd_solver.cpp:106] Iteration 47900, lr = 0.00850312
I0630 04:41:06.759085 29777 solver.cpp:354] Sparsity after update:
I0630 04:41:06.760677 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:41:06.760685 29777 net.cpp:1851] conv1a_param_0(0.12) 
I0630 04:41:06.760692 29777 net.cpp:1851] conv1b_param_0(0.24) 
I0630 04:41:06.760694 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:41:06.760696 29777 net.cpp:1851] res2a_branch2a_param_0(0.24) 
I0630 04:41:06.760699 29777 net.cpp:1851] res2a_branch2b_param_0(0.24) 
I0630 04:41:06.760701 29777 net.cpp:1851] res3a_branch2a_param_0(0.24) 
I0630 04:41:06.760702 29777 net.cpp:1851] res3a_branch2b_param_0(0.24) 
I0630 04:41:06.760704 29777 net.cpp:1851] res4a_branch2a_param_0(0.24) 
I0630 04:41:06.760706 29777 net.cpp:1851] res4a_branch2b_param_0(0.24) 
I0630 04:41:06.760709 29777 net.cpp:1851] res5a_branch2a_param_0(0.24) 
I0630 04:41:06.760710 29777 net.cpp:1851] res5a_branch2b_param_0(0.24) 
I0630 04:41:06.760712 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (564847/2.86678e+06) 0.197
I0630 04:41:06.760798 29777 solver.cpp:471] Iteration 48000, Testing net (#0)
I0630 04:41:11.772408 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:42:08.044862 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55774
I0630 04:42:08.044947 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.798461
I0630 04:42:08.044957 29777 solver.cpp:544]     Test net output #2: loss = 1.56562 (* 1 = 1.56562 loss)
I0630 04:42:08.220387 29777 solver.cpp:290] Iteration 48000 (1.29106 iter/s, 77.4559s/100 iter), loss = 0.928571
I0630 04:42:08.220410 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:42:08.220417 29777 sgd_solver.cpp:106] Iteration 48000, lr = 0.0085
I0630 04:42:08.221120 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.25
I0630 04:42:08.385107 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:42:23.752986 29777 solver.cpp:290] Iteration 48100 (6.43826 iter/s, 15.5321s/100 iter), loss = 1.27381
I0630 04:42:23.753010 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:42:23.753020 29777 sgd_solver.cpp:106] Iteration 48100, lr = 0.00849687
I0630 04:42:39.886415 29777 solver.cpp:290] Iteration 48200 (6.19849 iter/s, 16.133s/100 iter), loss = 1.42857
I0630 04:42:39.886514 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 04:42:39.886523 29777 sgd_solver.cpp:106] Iteration 48200, lr = 0.00849375
I0630 04:42:56.082432 29777 solver.cpp:290] Iteration 48300 (6.17457 iter/s, 16.1955s/100 iter), loss = 1.25
I0630 04:42:56.082631 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:42:56.082737 29777 sgd_solver.cpp:106] Iteration 48300, lr = 0.00849062
I0630 04:43:12.221740 29777 solver.cpp:290] Iteration 48400 (6.1963 iter/s, 16.1387s/100 iter), loss = 0.809524
I0630 04:43:12.221844 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 04:43:12.221853 29777 sgd_solver.cpp:106] Iteration 48400, lr = 0.0084875
I0630 04:43:28.421361 29777 solver.cpp:290] Iteration 48500 (6.17319 iter/s, 16.1991s/100 iter), loss = 0.797619
I0630 04:43:28.421387 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 04:43:28.421396 29777 sgd_solver.cpp:106] Iteration 48500, lr = 0.00848437
I0630 04:43:44.479920 29777 solver.cpp:290] Iteration 48600 (6.22739 iter/s, 16.0581s/100 iter), loss = 0.904762
I0630 04:43:44.480013 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:43:44.480024 29777 sgd_solver.cpp:106] Iteration 48600, lr = 0.00848125
I0630 04:44:00.560290 29777 solver.cpp:290] Iteration 48700 (6.21897 iter/s, 16.0798s/100 iter), loss = 0.809524
I0630 04:44:00.560312 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 04:44:00.560319 29777 sgd_solver.cpp:106] Iteration 48700, lr = 0.00847813
I0630 04:44:16.771867 29777 solver.cpp:290] Iteration 48800 (6.16861 iter/s, 16.2111s/100 iter), loss = 1.38095
I0630 04:44:16.771920 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 04:44:16.771930 29777 sgd_solver.cpp:106] Iteration 48800, lr = 0.008475
I0630 04:44:32.986497 29777 solver.cpp:290] Iteration 48900 (6.16746 iter/s, 16.2141s/100 iter), loss = 1.35714
I0630 04:44:32.986523 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 04:44:32.986532 29777 sgd_solver.cpp:106] Iteration 48900, lr = 0.00847188
I0630 04:44:48.930455 29777 solver.cpp:354] Sparsity after update:
I0630 04:44:48.952240 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:44:48.952256 29777 net.cpp:1851] conv1a_param_0(0.125) 
I0630 04:44:48.952267 29777 net.cpp:1851] conv1b_param_0(0.25) 
I0630 04:44:48.952271 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:44:48.952276 29777 net.cpp:1851] res2a_branch2a_param_0(0.25) 
I0630 04:44:48.952281 29777 net.cpp:1851] res2a_branch2b_param_0(0.25) 
I0630 04:44:48.952285 29777 net.cpp:1851] res3a_branch2a_param_0(0.25) 
I0630 04:44:48.952287 29777 net.cpp:1851] res3a_branch2b_param_0(0.25) 
I0630 04:44:48.952291 29777 net.cpp:1851] res4a_branch2a_param_0(0.25) 
I0630 04:44:48.952294 29777 net.cpp:1851] res4a_branch2b_param_0(0.25) 
I0630 04:44:48.952298 29777 net.cpp:1851] res5a_branch2a_param_0(0.25) 
I0630 04:44:48.952302 29777 net.cpp:1851] res5a_branch2b_param_0(0.25) 
I0630 04:44:48.952307 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (588394/2.86678e+06) 0.205
I0630 04:44:49.137440 29777 solver.cpp:290] Iteration 49000 (6.19177 iter/s, 16.1505s/100 iter), loss = 1.02381
I0630 04:44:49.137490 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:44:49.137509 29777 sgd_solver.cpp:106] Iteration 49000, lr = 0.00846875
I0630 04:45:05.219895 29777 solver.cpp:290] Iteration 49100 (6.21814 iter/s, 16.082s/100 iter), loss = 0.857143
I0630 04:45:05.219918 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 04:45:05.219925 29777 sgd_solver.cpp:106] Iteration 49100, lr = 0.00846562
I0630 04:45:21.479049 29777 solver.cpp:290] Iteration 49200 (6.15056 iter/s, 16.2587s/100 iter), loss = 1.27381
I0630 04:45:21.479152 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 04:45:21.479162 29777 sgd_solver.cpp:106] Iteration 49200, lr = 0.0084625
I0630 04:45:37.996572 29777 solver.cpp:290] Iteration 49300 (6.05438 iter/s, 16.517s/100 iter), loss = 1.02381
I0630 04:45:37.996596 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:45:37.996605 29777 sgd_solver.cpp:106] Iteration 49300, lr = 0.00845937
I0630 04:45:54.264950 29777 solver.cpp:290] Iteration 49400 (6.14707 iter/s, 16.2679s/100 iter), loss = 1.21429
I0630 04:45:54.265008 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 04:45:54.265017 29777 sgd_solver.cpp:106] Iteration 49400, lr = 0.00845625
I0630 04:46:10.626422 29777 solver.cpp:290] Iteration 49500 (6.11211 iter/s, 16.361s/100 iter), loss = 0.940476
I0630 04:46:10.626447 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 04:46:10.626456 29777 sgd_solver.cpp:106] Iteration 49500, lr = 0.00845312
I0630 04:46:27.040093 29777 solver.cpp:290] Iteration 49600 (6.09266 iter/s, 16.4132s/100 iter), loss = 1.07143
I0630 04:46:27.040160 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 04:46:27.040170 29777 sgd_solver.cpp:106] Iteration 49600, lr = 0.00845
I0630 04:46:43.375452 29777 solver.cpp:290] Iteration 49700 (6.12188 iter/s, 16.3348s/100 iter), loss = 0.916667
I0630 04:46:43.375478 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 04:46:43.375485 29777 sgd_solver.cpp:106] Iteration 49700, lr = 0.00844688
I0630 04:46:59.567055 29777 solver.cpp:290] Iteration 49800 (6.17622 iter/s, 16.1911s/100 iter), loss = 1.40476
I0630 04:46:59.567178 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:46:59.567193 29777 sgd_solver.cpp:106] Iteration 49800, lr = 0.00844375
I0630 04:47:15.928985 29777 solver.cpp:290] Iteration 49900 (6.11196 iter/s, 16.3614s/100 iter), loss = 1.15476
I0630 04:47:15.929013 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 04:47:15.929028 29777 sgd_solver.cpp:106] Iteration 49900, lr = 0.00844062
I0630 04:47:32.103340 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_50000.caffemodel
I0630 04:47:32.122853 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_50000.solverstate
I0630 04:47:32.131590 29777 solver.cpp:354] Sparsity after update:
I0630 04:47:32.132553 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:47:32.132562 29777 net.cpp:1851] conv1a_param_0(0.125) 
I0630 04:47:32.132570 29777 net.cpp:1851] conv1b_param_0(0.25) 
I0630 04:47:32.132572 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:47:32.132575 29777 net.cpp:1851] res2a_branch2a_param_0(0.25) 
I0630 04:47:32.132576 29777 net.cpp:1851] res2a_branch2b_param_0(0.25) 
I0630 04:47:32.132578 29777 net.cpp:1851] res3a_branch2a_param_0(0.25) 
I0630 04:47:32.132580 29777 net.cpp:1851] res3a_branch2b_param_0(0.25) 
I0630 04:47:32.132582 29777 net.cpp:1851] res4a_branch2a_param_0(0.25) 
I0630 04:47:32.132585 29777 net.cpp:1851] res4a_branch2b_param_0(0.25) 
I0630 04:47:32.132586 29777 net.cpp:1851] res5a_branch2a_param_0(0.25) 
I0630 04:47:32.132589 29777 net.cpp:1851] res5a_branch2b_param_0(0.25) 
I0630 04:47:32.132593 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (588394/2.86678e+06) 0.205
I0630 04:47:32.132696 29777 solver.cpp:471] Iteration 50000, Testing net (#0)
I0630 04:47:39.136782 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:48:38.582655 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55672
I0630 04:48:38.582725 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.792541
I0630 04:48:38.582731 29777 solver.cpp:544]     Test net output #2: loss = 1.593 (* 1 = 1.593 loss)
I0630 04:48:38.772855 29777 solver.cpp:290] Iteration 50000 (1.20712 iter/s, 82.8416s/100 iter), loss = 1.10714
I0630 04:48:38.772879 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 04:48:38.772886 29777 sgd_solver.cpp:106] Iteration 50000, lr = 0.0084375
I0630 04:48:38.773610 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.26
I0630 04:48:38.951961 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:48:54.698387 29777 solver.cpp:290] Iteration 50100 (6.27941 iter/s, 15.9251s/100 iter), loss = 1.27381
I0630 04:48:54.698412 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 04:48:54.698421 29777 sgd_solver.cpp:106] Iteration 50100, lr = 0.00843437
I0630 04:49:10.784447 29777 solver.cpp:290] Iteration 50200 (6.21674 iter/s, 16.0856s/100 iter), loss = 0.642857
I0630 04:49:10.784499 29777 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0630 04:49:10.784507 29777 sgd_solver.cpp:106] Iteration 50200, lr = 0.00843125
I0630 04:49:26.993710 29777 solver.cpp:290] Iteration 50300 (6.1695 iter/s, 16.2088s/100 iter), loss = 1.03571
I0630 04:49:26.993734 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:49:26.993741 29777 sgd_solver.cpp:106] Iteration 50300, lr = 0.00842812
I0630 04:49:43.263438 29777 solver.cpp:290] Iteration 50400 (6.14656 iter/s, 16.2693s/100 iter), loss = 1.14286
I0630 04:49:43.263550 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 04:49:43.263567 29777 sgd_solver.cpp:106] Iteration 50400, lr = 0.008425
I0630 04:49:59.637393 29777 solver.cpp:290] Iteration 50500 (6.10747 iter/s, 16.3734s/100 iter), loss = 1.07143
I0630 04:49:59.637419 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 04:49:59.637428 29777 sgd_solver.cpp:106] Iteration 50500, lr = 0.00842187
I0630 04:50:16.024164 29777 solver.cpp:290] Iteration 50600 (6.10266 iter/s, 16.3863s/100 iter), loss = 1.15476
I0630 04:50:16.024238 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:50:16.024245 29777 sgd_solver.cpp:106] Iteration 50600, lr = 0.00841875
I0630 04:50:32.394675 29777 solver.cpp:290] Iteration 50700 (6.10874 iter/s, 16.37s/100 iter), loss = 1.22619
I0630 04:50:32.394726 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 04:50:32.394740 29777 sgd_solver.cpp:106] Iteration 50700, lr = 0.00841562
I0630 04:50:48.497213 29777 solver.cpp:290] Iteration 50800 (6.21039 iter/s, 16.102s/100 iter), loss = 1.10714
I0630 04:50:48.497349 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:50:48.497367 29777 sgd_solver.cpp:106] Iteration 50800, lr = 0.0084125
I0630 04:51:05.109000 29777 solver.cpp:290] Iteration 50900 (6.02003 iter/s, 16.6112s/100 iter), loss = 1.02381
I0630 04:51:05.109025 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 04:51:05.109032 29777 sgd_solver.cpp:106] Iteration 50900, lr = 0.00840937
I0630 04:51:21.563814 29777 solver.cpp:354] Sparsity after update:
I0630 04:51:21.583976 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:51:21.583992 29777 net.cpp:1851] conv1a_param_0(0.13) 
I0630 04:51:21.584002 29777 net.cpp:1851] conv1b_param_0(0.26) 
I0630 04:51:21.584005 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:51:21.584009 29777 net.cpp:1851] res2a_branch2a_param_0(0.26) 
I0630 04:51:21.584020 29777 net.cpp:1851] res2a_branch2b_param_0(0.26) 
I0630 04:51:21.584026 29777 net.cpp:1851] res3a_branch2a_param_0(0.26) 
I0630 04:51:21.584031 29777 net.cpp:1851] res3a_branch2b_param_0(0.26) 
I0630 04:51:21.584038 29777 net.cpp:1851] res4a_branch2a_param_0(0.26) 
I0630 04:51:21.584043 29777 net.cpp:1851] res4a_branch2b_param_0(0.26) 
I0630 04:51:21.584048 29777 net.cpp:1851] res5a_branch2a_param_0(0.26) 
I0630 04:51:21.584051 29777 net.cpp:1851] res5a_branch2b_param_0(0.26) 
I0630 04:51:21.584055 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (611919/2.86678e+06) 0.213
I0630 04:51:21.743706 29777 solver.cpp:290] Iteration 51000 (6.0117 iter/s, 16.6342s/100 iter), loss = 1.08333
I0630 04:51:21.743729 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:51:21.743736 29777 sgd_solver.cpp:106] Iteration 51000, lr = 0.00840625
I0630 04:51:37.844169 29777 solver.cpp:290] Iteration 51100 (6.21118 iter/s, 16.1s/100 iter), loss = 1.35714
I0630 04:51:37.844194 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 04:51:37.844202 29777 sgd_solver.cpp:106] Iteration 51100, lr = 0.00840312
I0630 04:51:53.970340 29777 solver.cpp:290] Iteration 51200 (6.20128 iter/s, 16.1257s/100 iter), loss = 1.15476
I0630 04:51:53.970435 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 04:51:53.970460 29777 sgd_solver.cpp:106] Iteration 51200, lr = 0.0084
I0630 04:52:10.231788 29777 solver.cpp:290] Iteration 51300 (6.14971 iter/s, 16.2609s/100 iter), loss = 0.904762
I0630 04:52:10.231815 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 04:52:10.231824 29777 sgd_solver.cpp:106] Iteration 51300, lr = 0.00839687
I0630 04:52:26.694619 29777 solver.cpp:290] Iteration 51400 (6.07446 iter/s, 16.4624s/100 iter), loss = 1
I0630 04:52:26.694715 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:52:26.694726 29777 sgd_solver.cpp:106] Iteration 51400, lr = 0.00839375
I0630 04:52:42.801697 29777 solver.cpp:290] Iteration 51500 (6.20866 iter/s, 16.1065s/100 iter), loss = 1.5
I0630 04:52:42.801718 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 04:52:42.801725 29777 sgd_solver.cpp:106] Iteration 51500, lr = 0.00839063
I0630 04:52:58.918469 29777 solver.cpp:290] Iteration 51600 (6.2049 iter/s, 16.1163s/100 iter), loss = 1.0119
I0630 04:52:58.918555 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:52:58.918596 29777 sgd_solver.cpp:106] Iteration 51600, lr = 0.0083875
I0630 04:53:15.238268 29777 solver.cpp:290] Iteration 51700 (6.12773 iter/s, 16.3193s/100 iter), loss = 1.2381
I0630 04:53:15.238364 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 04:53:15.238399 29777 sgd_solver.cpp:106] Iteration 51700, lr = 0.00838437
I0630 04:53:31.525868 29777 solver.cpp:290] Iteration 51800 (6.13984 iter/s, 16.2871s/100 iter), loss = 0.821429
I0630 04:53:31.525984 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 04:53:31.525993 29777 sgd_solver.cpp:106] Iteration 51800, lr = 0.00838125
I0630 04:53:47.708698 29777 solver.cpp:290] Iteration 51900 (6.1796 iter/s, 16.1823s/100 iter), loss = 1.05952
I0630 04:53:47.708739 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:53:47.708751 29777 sgd_solver.cpp:106] Iteration 51900, lr = 0.00837812
I0630 04:54:03.647191 29777 solver.cpp:354] Sparsity after update:
I0630 04:54:03.648450 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:54:03.648459 29777 net.cpp:1851] conv1a_param_0(0.13) 
I0630 04:54:03.648466 29777 net.cpp:1851] conv1b_param_0(0.26) 
I0630 04:54:03.648469 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:54:03.648471 29777 net.cpp:1851] res2a_branch2a_param_0(0.26) 
I0630 04:54:03.648474 29777 net.cpp:1851] res2a_branch2b_param_0(0.26) 
I0630 04:54:03.648476 29777 net.cpp:1851] res3a_branch2a_param_0(0.26) 
I0630 04:54:03.648479 29777 net.cpp:1851] res3a_branch2b_param_0(0.26) 
I0630 04:54:03.648481 29777 net.cpp:1851] res4a_branch2a_param_0(0.26) 
I0630 04:54:03.648483 29777 net.cpp:1851] res4a_branch2b_param_0(0.26) 
I0630 04:54:03.648486 29777 net.cpp:1851] res5a_branch2a_param_0(0.26) 
I0630 04:54:03.648488 29777 net.cpp:1851] res5a_branch2b_param_0(0.26) 
I0630 04:54:03.648490 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (611919/2.86678e+06) 0.213
I0630 04:54:03.648581 29777 solver.cpp:471] Iteration 52000, Testing net (#0)
I0630 04:54:10.380851 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 04:55:07.970446 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.564379
I0630 04:55:07.970504 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.799021
I0630 04:55:07.970512 29777 solver.cpp:544]     Test net output #2: loss = 1.56632 (* 1 = 1.56632 loss)
I0630 04:55:08.151274 29777 solver.cpp:290] Iteration 52000 (1.24316 iter/s, 80.4404s/100 iter), loss = 0.821429
I0630 04:55:08.151299 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 04:55:08.151306 29777 sgd_solver.cpp:106] Iteration 52000, lr = 0.008375
I0630 04:55:08.152019 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.27
I0630 04:55:08.325037 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 04:55:23.817401 29777 solver.cpp:290] Iteration 52100 (6.38339 iter/s, 15.6657s/100 iter), loss = 0.785714
I0630 04:55:23.817459 29777 solver.cpp:309]     Train net output #0: loss = 0.595238 (* 1 = 0.595238 loss)
I0630 04:55:23.817481 29777 sgd_solver.cpp:106] Iteration 52100, lr = 0.00837187
I0630 04:55:39.929255 29777 solver.cpp:290] Iteration 52200 (6.2068 iter/s, 16.1114s/100 iter), loss = 0.97619
I0630 04:55:39.929332 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:55:39.929342 29777 sgd_solver.cpp:106] Iteration 52200, lr = 0.00836875
I0630 04:55:56.243973 29777 solver.cpp:290] Iteration 52300 (6.12963 iter/s, 16.3142s/100 iter), loss = 0.964286
I0630 04:55:56.243998 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 04:55:56.244004 29777 sgd_solver.cpp:106] Iteration 52300, lr = 0.00836562
I0630 04:56:12.464828 29777 solver.cpp:290] Iteration 52400 (6.16508 iter/s, 16.2204s/100 iter), loss = 0.797619
I0630 04:56:12.464905 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 04:56:12.464913 29777 sgd_solver.cpp:106] Iteration 52400, lr = 0.0083625
I0630 04:56:28.771872 29777 solver.cpp:290] Iteration 52500 (6.13252 iter/s, 16.3065s/100 iter), loss = 1.14286
I0630 04:56:28.771898 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 04:56:28.771908 29777 sgd_solver.cpp:106] Iteration 52500, lr = 0.00835937
I0630 04:56:44.898391 29777 solver.cpp:290] Iteration 52600 (6.20115 iter/s, 16.126s/100 iter), loss = 1
I0630 04:56:44.898551 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:56:44.898576 29777 sgd_solver.cpp:106] Iteration 52600, lr = 0.00835625
I0630 04:57:01.165017 29777 solver.cpp:290] Iteration 52700 (6.14778 iter/s, 16.266s/100 iter), loss = 0.940476
I0630 04:57:01.165042 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 04:57:01.165051 29777 sgd_solver.cpp:106] Iteration 52700, lr = 0.00835312
I0630 04:57:17.317651 29777 solver.cpp:290] Iteration 52800 (6.19112 iter/s, 16.1522s/100 iter), loss = 0.821429
I0630 04:57:17.317762 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 04:57:17.317773 29777 sgd_solver.cpp:106] Iteration 52800, lr = 0.00835
I0630 04:57:33.405092 29777 solver.cpp:290] Iteration 52900 (6.21624 iter/s, 16.0869s/100 iter), loss = 1.42857
I0630 04:57:33.405120 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 04:57:33.405129 29777 sgd_solver.cpp:106] Iteration 52900, lr = 0.00834687
I0630 04:57:49.503479 29777 solver.cpp:354] Sparsity after update:
I0630 04:57:49.523887 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 04:57:49.523903 29777 net.cpp:1851] conv1a_param_0(0.135) 
I0630 04:57:49.523911 29777 net.cpp:1851] conv1b_param_0(0.27) 
I0630 04:57:49.523913 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 04:57:49.523916 29777 net.cpp:1851] res2a_branch2a_param_0(0.27) 
I0630 04:57:49.523918 29777 net.cpp:1851] res2a_branch2b_param_0(0.27) 
I0630 04:57:49.523921 29777 net.cpp:1851] res3a_branch2a_param_0(0.27) 
I0630 04:57:49.523922 29777 net.cpp:1851] res3a_branch2b_param_0(0.27) 
I0630 04:57:49.523924 29777 net.cpp:1851] res4a_branch2a_param_0(0.27) 
I0630 04:57:49.523926 29777 net.cpp:1851] res4a_branch2b_param_0(0.27) 
I0630 04:57:49.523927 29777 net.cpp:1851] res5a_branch2a_param_0(0.27) 
I0630 04:57:49.523931 29777 net.cpp:1851] res5a_branch2b_param_0(0.27) 
I0630 04:57:49.523932 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (635461/2.86678e+06) 0.222
I0630 04:57:49.678022 29777 solver.cpp:290] Iteration 53000 (6.14535 iter/s, 16.2725s/100 iter), loss = 0.785714
I0630 04:57:49.678048 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 04:57:49.678056 29777 sgd_solver.cpp:106] Iteration 53000, lr = 0.00834375
I0630 04:58:05.818056 29777 solver.cpp:290] Iteration 53100 (6.19595 iter/s, 16.1396s/100 iter), loss = 1.15476
I0630 04:58:05.818150 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 04:58:05.818186 29777 sgd_solver.cpp:106] Iteration 53100, lr = 0.00834063
I0630 04:58:22.014003 29777 solver.cpp:290] Iteration 53200 (6.17459 iter/s, 16.1954s/100 iter), loss = 0.77381
I0630 04:58:22.014111 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 04:58:22.014120 29777 sgd_solver.cpp:106] Iteration 53200, lr = 0.0083375
I0630 04:58:38.211182 29777 solver.cpp:290] Iteration 53300 (6.17413 iter/s, 16.1966s/100 iter), loss = 0.77381
I0630 04:58:38.211232 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 04:58:38.211249 29777 sgd_solver.cpp:106] Iteration 53300, lr = 0.00833437
I0630 04:58:54.382899 29777 solver.cpp:290] Iteration 53400 (6.18383 iter/s, 16.1712s/100 iter), loss = 0.940476
I0630 04:58:54.383033 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 04:58:54.383066 29777 sgd_solver.cpp:106] Iteration 53400, lr = 0.00833125
I0630 04:59:10.789826 29777 solver.cpp:290] Iteration 53500 (6.0952 iter/s, 16.4063s/100 iter), loss = 1.2619
I0630 04:59:10.789855 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 04:59:10.789863 29777 sgd_solver.cpp:106] Iteration 53500, lr = 0.00832812
I0630 04:59:27.073099 29777 solver.cpp:290] Iteration 53600 (6.14145 iter/s, 16.2828s/100 iter), loss = 1.15476
I0630 04:59:27.073185 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 04:59:27.073194 29777 sgd_solver.cpp:106] Iteration 53600, lr = 0.008325
I0630 04:59:43.228124 29777 solver.cpp:290] Iteration 53700 (6.19023 iter/s, 16.1545s/100 iter), loss = 0.821429
I0630 04:59:43.228219 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:59:43.228255 29777 sgd_solver.cpp:106] Iteration 53700, lr = 0.00832187
I0630 04:59:59.255550 29777 solver.cpp:290] Iteration 53800 (6.23951 iter/s, 16.0269s/100 iter), loss = 1.13095
I0630 04:59:59.255635 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 04:59:59.255642 29777 sgd_solver.cpp:106] Iteration 53800, lr = 0.00831875
I0630 05:00:15.417161 29777 solver.cpp:290] Iteration 53900 (6.1877 iter/s, 16.1611s/100 iter), loss = 1.05952
I0630 05:00:15.417192 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:00:15.417202 29777 sgd_solver.cpp:106] Iteration 53900, lr = 0.00831562
I0630 05:00:31.371332 29777 solver.cpp:354] Sparsity after update:
I0630 05:00:31.372993 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:00:31.373001 29777 net.cpp:1851] conv1a_param_0(0.135) 
I0630 05:00:31.373008 29777 net.cpp:1851] conv1b_param_0(0.27) 
I0630 05:00:31.373010 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:00:31.373013 29777 net.cpp:1851] res2a_branch2a_param_0(0.27) 
I0630 05:00:31.373015 29777 net.cpp:1851] res2a_branch2b_param_0(0.27) 
I0630 05:00:31.373016 29777 net.cpp:1851] res3a_branch2a_param_0(0.27) 
I0630 05:00:31.373018 29777 net.cpp:1851] res3a_branch2b_param_0(0.27) 
I0630 05:00:31.373020 29777 net.cpp:1851] res4a_branch2a_param_0(0.27) 
I0630 05:00:31.373023 29777 net.cpp:1851] res4a_branch2b_param_0(0.27) 
I0630 05:00:31.373024 29777 net.cpp:1851] res5a_branch2a_param_0(0.27) 
I0630 05:00:31.373026 29777 net.cpp:1851] res5a_branch2b_param_0(0.27) 
I0630 05:00:31.373028 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (635461/2.86678e+06) 0.222
I0630 05:00:31.373126 29777 solver.cpp:471] Iteration 54000, Testing net (#0)
I0630 05:00:37.095865 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:01:31.203810 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.570359
I0630 05:01:31.203935 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804982
I0630 05:01:31.203960 29777 solver.cpp:544]     Test net output #2: loss = 1.54 (* 1 = 1.54 loss)
I0630 05:01:31.413530 29777 solver.cpp:290] Iteration 54000 (1.31589 iter/s, 75.9943s/100 iter), loss = 1.05952
I0630 05:01:31.413574 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:01:31.413584 29777 sgd_solver.cpp:106] Iteration 54000, lr = 0.0083125
I0630 05:01:31.414944 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.28
I0630 05:01:31.737804 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:01:47.851517 29777 solver.cpp:290] Iteration 54100 (6.08365 iter/s, 16.4375s/100 iter), loss = 0.964286
I0630 05:01:47.851542 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:01:47.851550 29777 sgd_solver.cpp:106] Iteration 54100, lr = 0.00830937
I0630 05:02:04.060655 29777 solver.cpp:290] Iteration 54200 (6.16954 iter/s, 16.2087s/100 iter), loss = 0.976191
I0630 05:02:04.062906 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:02:04.062932 29777 sgd_solver.cpp:106] Iteration 54200, lr = 0.00830625
I0630 05:02:20.437620 29777 solver.cpp:290] Iteration 54300 (6.10714 iter/s, 16.3743s/100 iter), loss = 1.11905
I0630 05:02:20.437649 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:02:20.437659 29777 sgd_solver.cpp:106] Iteration 54300, lr = 0.00830312
I0630 05:02:36.973553 29777 solver.cpp:290] Iteration 54400 (6.04761 iter/s, 16.5355s/100 iter), loss = 1.11905
I0630 05:02:36.973659 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 05:02:36.973670 29777 sgd_solver.cpp:106] Iteration 54400, lr = 0.0083
I0630 05:02:53.265305 29777 solver.cpp:290] Iteration 54500 (6.13828 iter/s, 16.2912s/100 iter), loss = 1.07143
I0630 05:02:53.265332 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:02:53.265338 29777 sgd_solver.cpp:106] Iteration 54500, lr = 0.00829687
I0630 05:03:09.457733 29777 solver.cpp:290] Iteration 54600 (6.17591 iter/s, 16.192s/100 iter), loss = 1.13095
I0630 05:03:09.457834 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 05:03:09.457844 29777 sgd_solver.cpp:106] Iteration 54600, lr = 0.00829375
I0630 05:03:25.719650 29777 solver.cpp:290] Iteration 54700 (6.14954 iter/s, 16.2614s/100 iter), loss = 0.595238
I0630 05:03:25.719674 29777 solver.cpp:309]     Train net output #0: loss = 0.428571 (* 1 = 0.428571 loss)
I0630 05:03:25.719681 29777 sgd_solver.cpp:106] Iteration 54700, lr = 0.00829063
I0630 05:03:42.012815 29777 solver.cpp:290] Iteration 54800 (6.13772 iter/s, 16.2927s/100 iter), loss = 0.904762
I0630 05:03:42.012926 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:03:42.012936 29777 sgd_solver.cpp:106] Iteration 54800, lr = 0.0082875
I0630 05:03:58.519570 29777 solver.cpp:290] Iteration 54900 (6.05833 iter/s, 16.5062s/100 iter), loss = 0.952381
I0630 05:03:58.519592 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:03:58.519598 29777 sgd_solver.cpp:106] Iteration 54900, lr = 0.00828438
I0630 05:04:14.764194 29777 solver.cpp:354] Sparsity after update:
I0630 05:04:14.784940 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:04:14.784957 29777 net.cpp:1851] conv1a_param_0(0.14) 
I0630 05:04:14.784967 29777 net.cpp:1851] conv1b_param_0(0.28) 
I0630 05:04:14.784971 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:04:14.784974 29777 net.cpp:1851] res2a_branch2a_param_0(0.28) 
I0630 05:04:14.784978 29777 net.cpp:1851] res2a_branch2b_param_0(0.28) 
I0630 05:04:14.784991 29777 net.cpp:1851] res3a_branch2a_param_0(0.28) 
I0630 05:04:14.784996 29777 net.cpp:1851] res3a_branch2b_param_0(0.28) 
I0630 05:04:14.785001 29777 net.cpp:1851] res4a_branch2a_param_0(0.28) 
I0630 05:04:14.785006 29777 net.cpp:1851] res4a_branch2b_param_0(0.28) 
I0630 05:04:14.785010 29777 net.cpp:1851] res5a_branch2a_param_0(0.28) 
I0630 05:04:14.785014 29777 net.cpp:1851] res5a_branch2b_param_0(0.28) 
I0630 05:04:14.785019 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (658988/2.86678e+06) 0.23
I0630 05:04:14.942106 29777 solver.cpp:290] Iteration 55000 (6.08937 iter/s, 16.4221s/100 iter), loss = 0.988095
I0630 05:04:14.942129 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:04:14.942137 29777 sgd_solver.cpp:106] Iteration 55000, lr = 0.00828125
I0630 05:04:31.031431 29777 solver.cpp:290] Iteration 55100 (6.21548 iter/s, 16.0889s/100 iter), loss = 0.821429
I0630 05:04:31.031460 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 05:04:31.031466 29777 sgd_solver.cpp:106] Iteration 55100, lr = 0.00827812
I0630 05:04:47.246340 29777 solver.cpp:290] Iteration 55200 (6.16735 iter/s, 16.2144s/100 iter), loss = 1.03571
I0630 05:04:47.246397 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:04:47.246408 29777 sgd_solver.cpp:106] Iteration 55200, lr = 0.008275
I0630 05:05:03.703407 29777 solver.cpp:290] Iteration 55300 (6.07661 iter/s, 16.4566s/100 iter), loss = 0.75
I0630 05:05:03.703429 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 05:05:03.703436 29777 sgd_solver.cpp:106] Iteration 55300, lr = 0.00827187
I0630 05:05:19.962138 29777 solver.cpp:290] Iteration 55400 (6.15072 iter/s, 16.2583s/100 iter), loss = 1.11905
I0630 05:05:19.962241 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:05:19.962252 29777 sgd_solver.cpp:106] Iteration 55400, lr = 0.00826875
I0630 05:05:36.133003 29777 solver.cpp:290] Iteration 55500 (6.18417 iter/s, 16.1703s/100 iter), loss = 1.13095
I0630 05:05:36.133028 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:05:36.133038 29777 sgd_solver.cpp:106] Iteration 55500, lr = 0.00826562
I0630 05:05:52.739537 29777 solver.cpp:290] Iteration 55600 (6.0219 iter/s, 16.606s/100 iter), loss = 1.0119
I0630 05:05:52.739647 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:05:52.739676 29777 sgd_solver.cpp:106] Iteration 55600, lr = 0.0082625
I0630 05:06:09.117949 29777 solver.cpp:290] Iteration 55700 (6.10581 iter/s, 16.3779s/100 iter), loss = 1.08333
I0630 05:06:09.117972 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 05:06:09.117979 29777 sgd_solver.cpp:106] Iteration 55700, lr = 0.00825937
I0630 05:06:25.531023 29777 solver.cpp:290] Iteration 55800 (6.09288 iter/s, 16.4126s/100 iter), loss = 0.904762
I0630 05:06:25.531113 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 05:06:25.531126 29777 sgd_solver.cpp:106] Iteration 55800, lr = 0.00825625
I0630 05:06:41.636349 29777 solver.cpp:290] Iteration 55900 (6.20933 iter/s, 16.1048s/100 iter), loss = 0.821429
I0630 05:06:41.636375 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:06:41.636384 29777 sgd_solver.cpp:106] Iteration 55900, lr = 0.00825312
I0630 05:06:57.981808 29777 solver.cpp:354] Sparsity after update:
I0630 05:06:57.983289 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:06:57.983296 29777 net.cpp:1851] conv1a_param_0(0.14) 
I0630 05:06:57.983304 29777 net.cpp:1851] conv1b_param_0(0.28) 
I0630 05:06:57.983305 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:06:57.983307 29777 net.cpp:1851] res2a_branch2a_param_0(0.28) 
I0630 05:06:57.983309 29777 net.cpp:1851] res2a_branch2b_param_0(0.28) 
I0630 05:06:57.983311 29777 net.cpp:1851] res3a_branch2a_param_0(0.28) 
I0630 05:06:57.983314 29777 net.cpp:1851] res3a_branch2b_param_0(0.28) 
I0630 05:06:57.983315 29777 net.cpp:1851] res4a_branch2a_param_0(0.28) 
I0630 05:06:57.983317 29777 net.cpp:1851] res4a_branch2b_param_0(0.28) 
I0630 05:06:57.983319 29777 net.cpp:1851] res5a_branch2a_param_0(0.28) 
I0630 05:06:57.983321 29777 net.cpp:1851] res5a_branch2b_param_0(0.28) 
I0630 05:06:57.983324 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (658988/2.86678e+06) 0.23
I0630 05:06:57.983418 29777 solver.cpp:471] Iteration 56000, Testing net (#0)
I0630 05:07:05.359558 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:08:04.120538 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56848
I0630 05:08:04.120587 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.803662
I0630 05:08:04.120594 29777 solver.cpp:544]     Test net output #2: loss = 1.53788 (* 1 = 1.53788 loss)
I0630 05:08:04.299991 29777 solver.cpp:290] Iteration 56000 (1.20976 iter/s, 82.6613s/100 iter), loss = 1.17857
I0630 05:08:04.300019 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 05:08:04.300027 29777 sgd_solver.cpp:106] Iteration 56000, lr = 0.00825
I0630 05:08:04.301014 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.29
I0630 05:08:04.520175 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:08:20.784216 29777 solver.cpp:290] Iteration 56100 (6.06659 iter/s, 16.4837s/100 iter), loss = 1.02381
I0630 05:08:20.784243 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:08:20.784252 29777 sgd_solver.cpp:106] Iteration 56100, lr = 0.00824687
I0630 05:08:37.072357 29777 solver.cpp:290] Iteration 56200 (6.13962 iter/s, 16.2876s/100 iter), loss = 1.2381
I0630 05:08:37.072504 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:08:37.072537 29777 sgd_solver.cpp:106] Iteration 56200, lr = 0.00824375
I0630 05:08:53.377466 29777 solver.cpp:290] Iteration 56300 (6.13327 iter/s, 16.3045s/100 iter), loss = 1.07143
I0630 05:08:53.377490 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:08:53.377497 29777 sgd_solver.cpp:106] Iteration 56300, lr = 0.00824062
I0630 05:09:09.559407 29777 solver.cpp:290] Iteration 56400 (6.17991 iter/s, 16.1815s/100 iter), loss = 0.880952
I0630 05:09:09.559454 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:09:09.559463 29777 sgd_solver.cpp:106] Iteration 56400, lr = 0.0082375
I0630 05:09:25.741428 29777 solver.cpp:290] Iteration 56500 (6.17989 iter/s, 16.1815s/100 iter), loss = 1.04762
I0630 05:09:25.741451 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 05:09:25.741457 29777 sgd_solver.cpp:106] Iteration 56500, lr = 0.00823438
I0630 05:09:41.849153 29777 solver.cpp:290] Iteration 56600 (6.20838 iter/s, 16.1073s/100 iter), loss = 0.785714
I0630 05:09:41.849247 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 05:09:41.849258 29777 sgd_solver.cpp:106] Iteration 56600, lr = 0.00823125
I0630 05:09:58.279036 29777 solver.cpp:290] Iteration 56700 (6.08667 iter/s, 16.4293s/100 iter), loss = 1.11905
I0630 05:09:58.279059 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:09:58.279067 29777 sgd_solver.cpp:106] Iteration 56700, lr = 0.00822813
I0630 05:10:14.387305 29777 solver.cpp:290] Iteration 56800 (6.20817 iter/s, 16.1078s/100 iter), loss = 0.904762
I0630 05:10:14.387397 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 05:10:14.387406 29777 sgd_solver.cpp:106] Iteration 56800, lr = 0.008225
I0630 05:10:30.470862 29777 solver.cpp:290] Iteration 56900 (6.21774 iter/s, 16.083s/100 iter), loss = 1.20238
I0630 05:10:30.470890 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 05:10:30.470904 29777 sgd_solver.cpp:106] Iteration 56900, lr = 0.00822187
I0630 05:10:46.552045 29777 solver.cpp:354] Sparsity after update:
I0630 05:10:46.572372 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:10:46.572409 29777 net.cpp:1851] conv1a_param_0(0.145) 
I0630 05:10:46.572428 29777 net.cpp:1851] conv1b_param_0(0.29) 
I0630 05:10:46.572438 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:10:46.572446 29777 net.cpp:1851] res2a_branch2a_param_0(0.29) 
I0630 05:10:46.572451 29777 net.cpp:1851] res2a_branch2b_param_0(0.29) 
I0630 05:10:46.572454 29777 net.cpp:1851] res3a_branch2a_param_0(0.29) 
I0630 05:10:46.572458 29777 net.cpp:1851] res3a_branch2b_param_0(0.29) 
I0630 05:10:46.572463 29777 net.cpp:1851] res4a_branch2a_param_0(0.29) 
I0630 05:10:46.572466 29777 net.cpp:1851] res4a_branch2b_param_0(0.29) 
I0630 05:10:46.572470 29777 net.cpp:1851] res5a_branch2a_param_0(0.29) 
I0630 05:10:46.572474 29777 net.cpp:1851] res5a_branch2b_param_0(0.29) 
I0630 05:10:46.572482 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (682534/2.86678e+06) 0.238
I0630 05:10:46.731741 29777 solver.cpp:290] Iteration 57000 (6.14991 iter/s, 16.2604s/100 iter), loss = 0.869048
I0630 05:10:46.731817 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:10:46.731861 29777 sgd_solver.cpp:106] Iteration 57000, lr = 0.00821875
I0630 05:11:02.937239 29777 solver.cpp:290] Iteration 57100 (6.17094 iter/s, 16.205s/100 iter), loss = 0.72619
I0630 05:11:02.937266 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 05:11:02.937276 29777 sgd_solver.cpp:106] Iteration 57100, lr = 0.00821562
I0630 05:11:19.187510 29777 solver.cpp:290] Iteration 57200 (6.15393 iter/s, 16.2498s/100 iter), loss = 1.13095
I0630 05:11:19.187625 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 05:11:19.187635 29777 sgd_solver.cpp:106] Iteration 57200, lr = 0.0082125
I0630 05:11:35.366870 29777 solver.cpp:290] Iteration 57300 (6.18093 iter/s, 16.1788s/100 iter), loss = 1.11905
I0630 05:11:35.366896 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 05:11:35.366905 29777 sgd_solver.cpp:106] Iteration 57300, lr = 0.00820937
I0630 05:11:51.590668 29777 solver.cpp:290] Iteration 57400 (6.16397 iter/s, 16.2233s/100 iter), loss = 0.940476
I0630 05:11:51.590723 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:11:51.590741 29777 sgd_solver.cpp:106] Iteration 57400, lr = 0.00820625
I0630 05:12:07.807888 29777 solver.cpp:290] Iteration 57500 (6.16648 iter/s, 16.2167s/100 iter), loss = 0.964286
I0630 05:12:07.807934 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 05:12:07.807945 29777 sgd_solver.cpp:106] Iteration 57500, lr = 0.00820312
I0630 05:12:24.136198 29777 solver.cpp:290] Iteration 57600 (6.12452 iter/s, 16.3278s/100 iter), loss = 1.21429
I0630 05:12:24.136272 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:12:24.136281 29777 sgd_solver.cpp:106] Iteration 57600, lr = 0.0082
I0630 05:12:40.201326 29777 solver.cpp:290] Iteration 57700 (6.22486 iter/s, 16.0646s/100 iter), loss = 1.13095
I0630 05:12:40.201354 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:12:40.201369 29777 sgd_solver.cpp:106] Iteration 57700, lr = 0.00819687
I0630 05:12:56.370133 29777 solver.cpp:290] Iteration 57800 (6.18493 iter/s, 16.1683s/100 iter), loss = 1.09524
I0630 05:12:56.370216 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 05:12:56.370234 29777 sgd_solver.cpp:106] Iteration 57800, lr = 0.00819375
I0630 05:13:12.631819 29777 solver.cpp:290] Iteration 57900 (6.14962 iter/s, 16.2612s/100 iter), loss = 0.821429
I0630 05:13:12.631840 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:13:12.631846 29777 sgd_solver.cpp:106] Iteration 57900, lr = 0.00819062
I0630 05:13:28.777496 29777 solver.cpp:354] Sparsity after update:
I0630 05:13:28.779129 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:13:28.779139 29777 net.cpp:1851] conv1a_param_0(0.145) 
I0630 05:13:28.779148 29777 net.cpp:1851] conv1b_param_0(0.29) 
I0630 05:13:28.779150 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:13:28.779152 29777 net.cpp:1851] res2a_branch2a_param_0(0.29) 
I0630 05:13:28.779155 29777 net.cpp:1851] res2a_branch2b_param_0(0.29) 
I0630 05:13:28.779156 29777 net.cpp:1851] res3a_branch2a_param_0(0.29) 
I0630 05:13:28.779158 29777 net.cpp:1851] res3a_branch2b_param_0(0.29) 
I0630 05:13:28.779160 29777 net.cpp:1851] res4a_branch2a_param_0(0.29) 
I0630 05:13:28.779163 29777 net.cpp:1851] res4a_branch2b_param_0(0.29) 
I0630 05:13:28.779165 29777 net.cpp:1851] res5a_branch2a_param_0(0.29) 
I0630 05:13:28.779167 29777 net.cpp:1851] res5a_branch2b_param_0(0.29) 
I0630 05:13:28.779170 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (682534/2.86678e+06) 0.238
I0630 05:13:28.779263 29777 solver.cpp:471] Iteration 58000, Testing net (#0)
I0630 05:13:35.708022 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:14:32.205770 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56918
I0630 05:14:32.205880 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.803802
I0630 05:14:32.205890 29777 solver.cpp:544]     Test net output #2: loss = 1.523 (* 1 = 1.523 loss)
I0630 05:14:32.385406 29777 solver.cpp:290] Iteration 58000 (1.2539 iter/s, 79.7514s/100 iter), loss = 1.10714
I0630 05:14:32.385434 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:14:32.385443 29777 sgd_solver.cpp:106] Iteration 58000, lr = 0.0081875
I0630 05:14:32.386422 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.3
I0630 05:14:32.586091 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:14:48.194196 29777 solver.cpp:290] Iteration 58100 (6.32578 iter/s, 15.8083s/100 iter), loss = 1
I0630 05:14:48.194219 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:14:48.194226 29777 sgd_solver.cpp:106] Iteration 58100, lr = 0.00818438
I0630 05:15:04.193425 29777 solver.cpp:290] Iteration 58200 (6.25048 iter/s, 15.9988s/100 iter), loss = 1.04762
I0630 05:15:04.193545 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:15:04.193555 29777 sgd_solver.cpp:106] Iteration 58200, lr = 0.00818125
I0630 05:15:20.311866 29777 solver.cpp:290] Iteration 58300 (6.20429 iter/s, 16.1179s/100 iter), loss = 1.2619
I0630 05:15:20.311894 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 05:15:20.311903 29777 sgd_solver.cpp:106] Iteration 58300, lr = 0.00817813
I0630 05:15:36.727098 29777 solver.cpp:290] Iteration 58400 (6.09208 iter/s, 16.4147s/100 iter), loss = 1.38095
I0630 05:15:36.727180 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 05:15:36.727190 29777 sgd_solver.cpp:106] Iteration 58400, lr = 0.008175
I0630 05:15:52.965693 29777 solver.cpp:290] Iteration 58500 (6.15837 iter/s, 16.2381s/100 iter), loss = 1.21429
I0630 05:15:52.965745 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 05:15:52.965759 29777 sgd_solver.cpp:106] Iteration 58500, lr = 0.00817188
I0630 05:16:08.999169 29777 solver.cpp:290] Iteration 58600 (6.23714 iter/s, 16.033s/100 iter), loss = 1.2381
I0630 05:16:08.999214 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 05:16:08.999222 29777 sgd_solver.cpp:106] Iteration 58600, lr = 0.00816875
I0630 05:16:25.157897 29777 solver.cpp:290] Iteration 58700 (6.18879 iter/s, 16.1582s/100 iter), loss = 0.821429
I0630 05:16:25.157922 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:16:25.157929 29777 sgd_solver.cpp:106] Iteration 58700, lr = 0.00816562
I0630 05:16:41.223886 29777 solver.cpp:290] Iteration 58800 (6.22451 iter/s, 16.0655s/100 iter), loss = 1.15476
I0630 05:16:41.223971 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:16:41.223983 29777 sgd_solver.cpp:106] Iteration 58800, lr = 0.0081625
I0630 05:16:57.445137 29777 solver.cpp:290] Iteration 58900 (6.16496 iter/s, 16.2207s/100 iter), loss = 0.97619
I0630 05:16:57.445161 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:16:57.445170 29777 sgd_solver.cpp:106] Iteration 58900, lr = 0.00815937
I0630 05:17:13.444344 29777 solver.cpp:354] Sparsity after update:
I0630 05:17:13.464781 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:17:13.464795 29777 net.cpp:1851] conv1a_param_0(0.15) 
I0630 05:17:13.464807 29777 net.cpp:1851] conv1b_param_0(0.3) 
I0630 05:17:13.464810 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:17:13.464813 29777 net.cpp:1851] res2a_branch2a_param_0(0.3) 
I0630 05:17:13.464818 29777 net.cpp:1851] res2a_branch2b_param_0(0.3) 
I0630 05:17:13.464820 29777 net.cpp:1851] res3a_branch2a_param_0(0.3) 
I0630 05:17:13.464823 29777 net.cpp:1851] res3a_branch2b_param_0(0.3) 
I0630 05:17:13.464826 29777 net.cpp:1851] res4a_branch2a_param_0(0.3) 
I0630 05:17:13.464829 29777 net.cpp:1851] res4a_branch2b_param_0(0.3) 
I0630 05:17:13.464833 29777 net.cpp:1851] res5a_branch2a_param_0(0.3) 
I0630 05:17:13.464843 29777 net.cpp:1851] res5a_branch2b_param_0(0.3) 
I0630 05:17:13.464848 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (706063/2.86678e+06) 0.246
I0630 05:17:13.625425 29777 solver.cpp:290] Iteration 59000 (6.18054 iter/s, 16.1798s/100 iter), loss = 0.940476
I0630 05:17:13.625455 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 05:17:13.625465 29777 sgd_solver.cpp:106] Iteration 59000, lr = 0.00815625
I0630 05:17:29.707725 29777 solver.cpp:290] Iteration 59100 (6.2182 iter/s, 16.0818s/100 iter), loss = 1.25
I0630 05:17:29.707751 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 05:17:29.707759 29777 sgd_solver.cpp:106] Iteration 59100, lr = 0.00815312
I0630 05:17:46.109089 29777 solver.cpp:290] Iteration 59200 (6.09723 iter/s, 16.4009s/100 iter), loss = 1.20238
I0630 05:17:46.109197 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:17:46.109232 29777 sgd_solver.cpp:106] Iteration 59200, lr = 0.00815
I0630 05:18:02.425653 29777 solver.cpp:290] Iteration 59300 (6.12895 iter/s, 16.316s/100 iter), loss = 0.916667
I0630 05:18:02.425680 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 05:18:02.425689 29777 sgd_solver.cpp:106] Iteration 59300, lr = 0.00814687
I0630 05:18:18.778046 29777 solver.cpp:290] Iteration 59400 (6.11549 iter/s, 16.3519s/100 iter), loss = 1.05952
I0630 05:18:18.778095 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:18:18.778102 29777 sgd_solver.cpp:106] Iteration 59400, lr = 0.00814375
I0630 05:18:34.981899 29777 solver.cpp:290] Iteration 59500 (6.17156 iter/s, 16.2034s/100 iter), loss = 0.857143
I0630 05:18:34.981927 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 05:18:34.981936 29777 sgd_solver.cpp:106] Iteration 59500, lr = 0.00814062
I0630 05:18:51.428448 29777 solver.cpp:290] Iteration 59600 (6.08048 iter/s, 16.4461s/100 iter), loss = 1.36905
I0630 05:18:51.428501 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 05:18:51.428511 29777 sgd_solver.cpp:106] Iteration 59600, lr = 0.0081375
I0630 05:19:08.232545 29777 solver.cpp:290] Iteration 59700 (5.95112 iter/s, 16.8036s/100 iter), loss = 1.52381
I0630 05:19:08.232650 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 05:19:08.232692 29777 sgd_solver.cpp:106] Iteration 59700, lr = 0.00813438
I0630 05:19:24.592200 29777 solver.cpp:290] Iteration 59800 (6.1128 iter/s, 16.3591s/100 iter), loss = 1.14286
I0630 05:19:24.592306 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:19:24.592316 29777 sgd_solver.cpp:106] Iteration 59800, lr = 0.00813125
I0630 05:19:40.881265 29777 solver.cpp:290] Iteration 59900 (6.1393 iter/s, 16.2885s/100 iter), loss = 0.964286
I0630 05:19:40.881295 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 05:19:40.881304 29777 sgd_solver.cpp:106] Iteration 59900, lr = 0.00812813
I0630 05:19:57.069869 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_60000.caffemodel
I0630 05:19:57.089951 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_60000.solverstate
I0630 05:19:57.098562 29777 solver.cpp:354] Sparsity after update:
I0630 05:19:57.099535 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:19:57.099544 29777 net.cpp:1851] conv1a_param_0(0.15) 
I0630 05:19:57.099550 29777 net.cpp:1851] conv1b_param_0(0.3) 
I0630 05:19:57.099553 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:19:57.099555 29777 net.cpp:1851] res2a_branch2a_param_0(0.3) 
I0630 05:19:57.099557 29777 net.cpp:1851] res2a_branch2b_param_0(0.3) 
I0630 05:19:57.099560 29777 net.cpp:1851] res3a_branch2a_param_0(0.3) 
I0630 05:19:57.099561 29777 net.cpp:1851] res3a_branch2b_param_0(0.3) 
I0630 05:19:57.099563 29777 net.cpp:1851] res4a_branch2a_param_0(0.3) 
I0630 05:19:57.099565 29777 net.cpp:1851] res4a_branch2b_param_0(0.3) 
I0630 05:19:57.099567 29777 net.cpp:1851] res5a_branch2a_param_0(0.3) 
I0630 05:19:57.099570 29777 net.cpp:1851] res5a_branch2b_param_0(0.3) 
I0630 05:19:57.099571 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (706063/2.86678e+06) 0.246
I0630 05:19:57.099666 29777 solver.cpp:471] Iteration 60000, Testing net (#0)
I0630 05:20:05.472725 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:21:05.400691 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5674
I0630 05:21:05.400799 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.803521
I0630 05:21:05.400822 29777 solver.cpp:544]     Test net output #2: loss = 1.56204 (* 1 = 1.56204 loss)
I0630 05:21:05.576153 29777 solver.cpp:290] Iteration 60000 (1.18074 iter/s, 84.6925s/100 iter), loss = 1.16667
I0630 05:21:05.576223 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:21:05.576256 29777 sgd_solver.cpp:106] Iteration 60000, lr = 0.008125
I0630 05:21:05.578207 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.31
I0630 05:21:05.891165 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:21:21.531790 29777 solver.cpp:290] Iteration 60100 (6.26758 iter/s, 15.9551s/100 iter), loss = 1.10714
I0630 05:21:21.531821 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 05:21:21.531831 29777 sgd_solver.cpp:106] Iteration 60100, lr = 0.00812188
I0630 05:21:37.713980 29777 solver.cpp:290] Iteration 60200 (6.17982 iter/s, 16.1817s/100 iter), loss = 1.2619
I0630 05:21:37.714087 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 05:21:37.714097 29777 sgd_solver.cpp:106] Iteration 60200, lr = 0.00811875
I0630 05:21:53.923384 29777 solver.cpp:290] Iteration 60300 (6.16947 iter/s, 16.2088s/100 iter), loss = 1.14286
I0630 05:21:53.923408 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:21:53.923415 29777 sgd_solver.cpp:106] Iteration 60300, lr = 0.00811563
I0630 05:22:10.128101 29777 solver.cpp:290] Iteration 60400 (6.17122 iter/s, 16.2042s/100 iter), loss = 0.869048
I0630 05:22:10.128222 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:22:10.128237 29777 sgd_solver.cpp:106] Iteration 60400, lr = 0.0081125
I0630 05:22:26.566727 29777 solver.cpp:290] Iteration 60500 (6.08345 iter/s, 16.438s/100 iter), loss = 0.857143
I0630 05:22:26.566751 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:22:26.566758 29777 sgd_solver.cpp:106] Iteration 60500, lr = 0.00810937
I0630 05:22:42.759768 29777 solver.cpp:290] Iteration 60600 (6.17567 iter/s, 16.1926s/100 iter), loss = 0.761905
I0630 05:22:42.759882 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 05:22:42.759892 29777 sgd_solver.cpp:106] Iteration 60600, lr = 0.00810625
I0630 05:22:59.226130 29777 solver.cpp:290] Iteration 60700 (6.0732 iter/s, 16.4658s/100 iter), loss = 1.03571
I0630 05:22:59.226205 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 05:22:59.226227 29777 sgd_solver.cpp:106] Iteration 60700, lr = 0.00810312
I0630 05:23:15.392938 29777 solver.cpp:290] Iteration 60800 (6.18571 iter/s, 16.1663s/100 iter), loss = 0.964286
I0630 05:23:15.393033 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:23:15.393055 29777 sgd_solver.cpp:106] Iteration 60800, lr = 0.0081
I0630 05:23:31.668308 29777 solver.cpp:290] Iteration 60900 (6.14446 iter/s, 16.2748s/100 iter), loss = 1.16667
I0630 05:23:31.668357 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 05:23:31.668372 29777 sgd_solver.cpp:106] Iteration 60900, lr = 0.00809687
I0630 05:23:47.781945 29777 solver.cpp:354] Sparsity after update:
I0630 05:23:47.802371 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:23:47.802386 29777 net.cpp:1851] conv1a_param_0(0.155) 
I0630 05:23:47.802395 29777 net.cpp:1851] conv1b_param_0(0.31) 
I0630 05:23:47.802399 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:23:47.802408 29777 net.cpp:1851] res2a_branch2a_param_0(0.31) 
I0630 05:23:47.802412 29777 net.cpp:1851] res2a_branch2b_param_0(0.31) 
I0630 05:23:47.802417 29777 net.cpp:1851] res3a_branch2a_param_0(0.31) 
I0630 05:23:47.802419 29777 net.cpp:1851] res3a_branch2b_param_0(0.31) 
I0630 05:23:47.802424 29777 net.cpp:1851] res4a_branch2a_param_0(0.31) 
I0630 05:23:47.802429 29777 net.cpp:1851] res4a_branch2b_param_0(0.31) 
I0630 05:23:47.802434 29777 net.cpp:1851] res5a_branch2a_param_0(0.31) 
I0630 05:23:47.802439 29777 net.cpp:1851] res5a_branch2b_param_0(0.31) 
I0630 05:23:47.802444 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (729596/2.86678e+06) 0.254
I0630 05:23:47.958499 29777 solver.cpp:290] Iteration 61000 (6.13885 iter/s, 16.2897s/100 iter), loss = 0.738095
I0630 05:23:47.958525 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 05:23:47.958534 29777 sgd_solver.cpp:106] Iteration 61000, lr = 0.00809375
I0630 05:24:04.681843 29777 solver.cpp:290] Iteration 61100 (5.97984 iter/s, 16.7229s/100 iter), loss = 1.72619
I0630 05:24:04.681869 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 05:24:04.681877 29777 sgd_solver.cpp:106] Iteration 61100, lr = 0.00809062
I0630 05:24:21.129529 29777 solver.cpp:290] Iteration 61200 (6.08006 iter/s, 16.4472s/100 iter), loss = 1.2381
I0630 05:24:21.129611 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:24:21.129619 29777 sgd_solver.cpp:106] Iteration 61200, lr = 0.0080875
I0630 05:24:37.497675 29777 solver.cpp:290] Iteration 61300 (6.10963 iter/s, 16.3676s/100 iter), loss = 0.857143
I0630 05:24:37.497701 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 05:24:37.497710 29777 sgd_solver.cpp:106] Iteration 61300, lr = 0.00808437
I0630 05:24:53.800626 29777 solver.cpp:290] Iteration 61400 (6.13404 iter/s, 16.3025s/100 iter), loss = 0.988095
I0630 05:24:53.800727 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 05:24:53.800735 29777 sgd_solver.cpp:106] Iteration 61400, lr = 0.00808125
I0630 05:25:10.046016 29777 solver.cpp:290] Iteration 61500 (6.1558 iter/s, 16.2448s/100 iter), loss = 0.97619
I0630 05:25:10.046038 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 05:25:10.046046 29777 sgd_solver.cpp:106] Iteration 61500, lr = 0.00807813
I0630 05:25:26.403537 29777 solver.cpp:290] Iteration 61600 (6.11358 iter/s, 16.357s/100 iter), loss = 1.10714
I0630 05:25:26.403616 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:25:26.403627 29777 sgd_solver.cpp:106] Iteration 61600, lr = 0.008075
I0630 05:25:42.486711 29777 solver.cpp:290] Iteration 61700 (6.21788 iter/s, 16.0827s/100 iter), loss = 0.97619
I0630 05:25:42.486733 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:25:42.486740 29777 sgd_solver.cpp:106] Iteration 61700, lr = 0.00807188
I0630 05:25:58.638936 29777 solver.cpp:290] Iteration 61800 (6.19128 iter/s, 16.1518s/100 iter), loss = 1.0119
I0630 05:25:58.639040 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 05:25:58.639051 29777 sgd_solver.cpp:106] Iteration 61800, lr = 0.00806875
I0630 05:26:14.930058 29777 solver.cpp:290] Iteration 61900 (6.13852 iter/s, 16.2906s/100 iter), loss = 0.928571
I0630 05:26:14.930081 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:26:14.930088 29777 sgd_solver.cpp:106] Iteration 61900, lr = 0.00806563
I0630 05:26:30.977524 29777 solver.cpp:354] Sparsity after update:
I0630 05:26:30.978782 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:26:30.978790 29777 net.cpp:1851] conv1a_param_0(0.155) 
I0630 05:26:30.978797 29777 net.cpp:1851] conv1b_param_0(0.31) 
I0630 05:26:30.978801 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:26:30.978802 29777 net.cpp:1851] res2a_branch2a_param_0(0.31) 
I0630 05:26:30.978804 29777 net.cpp:1851] res2a_branch2b_param_0(0.31) 
I0630 05:26:30.978806 29777 net.cpp:1851] res3a_branch2a_param_0(0.31) 
I0630 05:26:30.978808 29777 net.cpp:1851] res3a_branch2b_param_0(0.31) 
I0630 05:26:30.978811 29777 net.cpp:1851] res4a_branch2a_param_0(0.31) 
I0630 05:26:30.978812 29777 net.cpp:1851] res4a_branch2b_param_0(0.31) 
I0630 05:26:30.978813 29777 net.cpp:1851] res5a_branch2a_param_0(0.31) 
I0630 05:26:30.978816 29777 net.cpp:1851] res5a_branch2b_param_0(0.31) 
I0630 05:26:30.978818 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (729596/2.86678e+06) 0.254
I0630 05:26:30.978945 29777 solver.cpp:471] Iteration 62000, Testing net (#0)
I0630 05:26:36.924193 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:27:37.237669 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.571079
I0630 05:27:37.237740 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.802861
I0630 05:27:37.237748 29777 solver.cpp:544]     Test net output #2: loss = 1.53324 (* 1 = 1.53324 loss)
I0630 05:27:37.419924 29777 solver.cpp:290] Iteration 62000 (1.2123 iter/s, 82.4876s/100 iter), loss = 0.952381
I0630 05:27:37.419948 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 05:27:37.419955 29777 sgd_solver.cpp:106] Iteration 62000, lr = 0.0080625
I0630 05:27:37.420610 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.32
I0630 05:27:37.673977 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:27:53.178243 29777 solver.cpp:290] Iteration 62100 (6.34604 iter/s, 15.7579s/100 iter), loss = 1.2381
I0630 05:27:53.178269 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:27:53.178277 29777 sgd_solver.cpp:106] Iteration 62100, lr = 0.00805937
I0630 05:28:09.296972 29777 solver.cpp:290] Iteration 62200 (6.20415 iter/s, 16.1182s/100 iter), loss = 0.77381
I0630 05:28:09.297078 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 05:28:09.297088 29777 sgd_solver.cpp:106] Iteration 62200, lr = 0.00805625
I0630 05:28:25.568265 29777 solver.cpp:290] Iteration 62300 (6.146 iter/s, 16.2707s/100 iter), loss = 0.952381
I0630 05:28:25.568289 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:28:25.568296 29777 sgd_solver.cpp:106] Iteration 62300, lr = 0.00805312
I0630 05:28:41.802789 29777 solver.cpp:290] Iteration 62400 (6.15989 iter/s, 16.234s/100 iter), loss = 1.34524
I0630 05:28:41.802860 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:28:41.802870 29777 sgd_solver.cpp:106] Iteration 62400, lr = 0.00805
I0630 05:28:57.818825 29777 solver.cpp:290] Iteration 62500 (6.24395 iter/s, 16.0155s/100 iter), loss = 1.08333
I0630 05:28:57.818917 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:28:57.818938 29777 sgd_solver.cpp:106] Iteration 62500, lr = 0.00804687
I0630 05:29:13.985005 29777 solver.cpp:290] Iteration 62600 (6.18596 iter/s, 16.1656s/100 iter), loss = 1.2619
I0630 05:29:13.985093 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 05:29:13.985105 29777 sgd_solver.cpp:106] Iteration 62600, lr = 0.00804375
I0630 05:29:30.186307 29777 solver.cpp:290] Iteration 62700 (6.17255 iter/s, 16.2008s/100 iter), loss = 1.19048
I0630 05:29:30.186331 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 05:29:30.186337 29777 sgd_solver.cpp:106] Iteration 62700, lr = 0.00804062
I0630 05:29:46.496214 29777 solver.cpp:290] Iteration 62800 (6.13142 iter/s, 16.3094s/100 iter), loss = 1.28571
I0630 05:29:46.496286 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:29:46.496294 29777 sgd_solver.cpp:106] Iteration 62800, lr = 0.0080375
I0630 05:30:02.686251 29777 solver.cpp:290] Iteration 62900 (6.17684 iter/s, 16.1895s/100 iter), loss = 0.738095
I0630 05:30:02.686273 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 05:30:02.686282 29777 sgd_solver.cpp:106] Iteration 62900, lr = 0.00803437
I0630 05:30:18.579928 29777 solver.cpp:354] Sparsity after update:
I0630 05:30:18.600260 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:30:18.600277 29777 net.cpp:1851] conv1a_param_0(0.16) 
I0630 05:30:18.600286 29777 net.cpp:1851] conv1b_param_0(0.32) 
I0630 05:30:18.600291 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:30:18.600294 29777 net.cpp:1851] res2a_branch2a_param_0(0.32) 
I0630 05:30:18.600297 29777 net.cpp:1851] res2a_branch2b_param_0(0.32) 
I0630 05:30:18.600301 29777 net.cpp:1851] res3a_branch2a_param_0(0.32) 
I0630 05:30:18.600304 29777 net.cpp:1851] res3a_branch2b_param_0(0.32) 
I0630 05:30:18.600307 29777 net.cpp:1851] res4a_branch2a_param_0(0.32) 
I0630 05:30:18.600311 29777 net.cpp:1851] res4a_branch2b_param_0(0.32) 
I0630 05:30:18.600313 29777 net.cpp:1851] res5a_branch2a_param_0(0.32) 
I0630 05:30:18.600317 29777 net.cpp:1851] res5a_branch2b_param_0(0.32) 
I0630 05:30:18.600327 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (753138/2.86678e+06) 0.263
I0630 05:30:18.756444 29777 solver.cpp:290] Iteration 63000 (6.22288 iter/s, 16.0697s/100 iter), loss = 0.904762
I0630 05:30:18.756474 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:30:18.756482 29777 sgd_solver.cpp:106] Iteration 63000, lr = 0.00803125
I0630 05:30:34.839946 29777 solver.cpp:290] Iteration 63100 (6.21773 iter/s, 16.083s/100 iter), loss = 1.08333
I0630 05:30:34.839972 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 05:30:34.839980 29777 sgd_solver.cpp:106] Iteration 63100, lr = 0.00802813
I0630 05:30:50.929953 29777 solver.cpp:290] Iteration 63200 (6.21522 iter/s, 16.0895s/100 iter), loss = 1.27381
I0630 05:30:50.930083 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 05:30:50.930125 29777 sgd_solver.cpp:106] Iteration 63200, lr = 0.008025
I0630 05:31:07.018976 29777 solver.cpp:290] Iteration 63300 (6.21564 iter/s, 16.0885s/100 iter), loss = 1.17857
I0630 05:31:07.019001 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:31:07.019011 29777 sgd_solver.cpp:106] Iteration 63300, lr = 0.00802188
I0630 05:31:23.154352 29777 solver.cpp:290] Iteration 63400 (6.19774 iter/s, 16.1349s/100 iter), loss = 0.797619
I0630 05:31:23.154425 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:31:23.154433 29777 sgd_solver.cpp:106] Iteration 63400, lr = 0.00801875
I0630 05:31:39.272320 29777 solver.cpp:290] Iteration 63500 (6.20446 iter/s, 16.1174s/100 iter), loss = 1.03571
I0630 05:31:39.272346 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:31:39.272361 29777 sgd_solver.cpp:106] Iteration 63500, lr = 0.00801562
I0630 05:31:55.484444 29777 solver.cpp:290] Iteration 63600 (6.1684 iter/s, 16.2116s/100 iter), loss = 0.940476
I0630 05:31:55.484536 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:31:55.484547 29777 sgd_solver.cpp:106] Iteration 63600, lr = 0.0080125
I0630 05:32:11.901114 29777 solver.cpp:290] Iteration 63700 (6.09157 iter/s, 16.4161s/100 iter), loss = 1.17857
I0630 05:32:11.901146 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:32:11.901155 29777 sgd_solver.cpp:106] Iteration 63700, lr = 0.00800938
I0630 05:32:28.029683 29777 solver.cpp:290] Iteration 63800 (6.20036 iter/s, 16.1281s/100 iter), loss = 1.28571
I0630 05:32:28.029804 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:32:28.029826 29777 sgd_solver.cpp:106] Iteration 63800, lr = 0.00800625
I0630 05:32:44.179368 29777 solver.cpp:290] Iteration 63900 (6.19229 iter/s, 16.1491s/100 iter), loss = 0.916667
I0630 05:32:44.179395 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 05:32:44.179404 29777 sgd_solver.cpp:106] Iteration 63900, lr = 0.00800312
I0630 05:33:00.217743 29777 solver.cpp:354] Sparsity after update:
I0630 05:33:00.219329 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:33:00.219339 29777 net.cpp:1851] conv1a_param_0(0.16) 
I0630 05:33:00.219352 29777 net.cpp:1851] conv1b_param_0(0.32) 
I0630 05:33:00.219355 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:33:00.219359 29777 net.cpp:1851] res2a_branch2a_param_0(0.32) 
I0630 05:33:00.219362 29777 net.cpp:1851] res2a_branch2b_param_0(0.32) 
I0630 05:33:00.219367 29777 net.cpp:1851] res3a_branch2a_param_0(0.32) 
I0630 05:33:00.219369 29777 net.cpp:1851] res3a_branch2b_param_0(0.32) 
I0630 05:33:00.219373 29777 net.cpp:1851] res4a_branch2a_param_0(0.32) 
I0630 05:33:00.219377 29777 net.cpp:1851] res4a_branch2b_param_0(0.32) 
I0630 05:33:00.219382 29777 net.cpp:1851] res5a_branch2a_param_0(0.32) 
I0630 05:33:00.219385 29777 net.cpp:1851] res5a_branch2b_param_0(0.32) 
I0630 05:33:00.219388 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (753138/2.86678e+06) 0.263
I0630 05:33:00.219518 29777 solver.cpp:471] Iteration 64000, Testing net (#0)
I0630 05:33:07.090535 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:34:00.842942 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57342
I0630 05:34:00.843026 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806721
I0630 05:34:00.843035 29777 solver.cpp:544]     Test net output #2: loss = 1.50864 (* 1 = 1.50864 loss)
I0630 05:34:01.031721 29777 solver.cpp:290] Iteration 64000 (1.30123 iter/s, 76.8502s/100 iter), loss = 0.761905
I0630 05:34:01.031755 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:34:01.031765 29777 sgd_solver.cpp:106] Iteration 64000, lr = 0.008
I0630 05:34:01.032480 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.33
I0630 05:34:01.484958 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:34:17.421885 29777 solver.cpp:290] Iteration 64100 (6.1014 iter/s, 16.3897s/100 iter), loss = 1.5119
I0630 05:34:17.421912 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 05:34:17.421921 29777 sgd_solver.cpp:106] Iteration 64100, lr = 0.00799687
I0630 05:34:33.756852 29777 solver.cpp:290] Iteration 64200 (6.12202 iter/s, 16.3345s/100 iter), loss = 1.02381
I0630 05:34:33.756959 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:34:33.756971 29777 sgd_solver.cpp:106] Iteration 64200, lr = 0.00799375
I0630 05:34:50.017091 29777 solver.cpp:290] Iteration 64300 (6.15018 iter/s, 16.2597s/100 iter), loss = 0.880952
I0630 05:34:50.017117 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:34:50.017125 29777 sgd_solver.cpp:106] Iteration 64300, lr = 0.00799062
I0630 05:35:06.158254 29777 solver.cpp:290] Iteration 64400 (6.19554 iter/s, 16.1406s/100 iter), loss = 0.880952
I0630 05:35:06.158445 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 05:35:06.158471 29777 sgd_solver.cpp:106] Iteration 64400, lr = 0.0079875
I0630 05:35:22.813314 29777 solver.cpp:290] Iteration 64500 (6.00442 iter/s, 16.6544s/100 iter), loss = 1.2381
I0630 05:35:22.813344 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 05:35:22.813352 29777 sgd_solver.cpp:106] Iteration 64500, lr = 0.00798437
I0630 05:35:39.505733 29777 solver.cpp:290] Iteration 64600 (5.99092 iter/s, 16.6919s/100 iter), loss = 1.08333
I0630 05:35:39.505991 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 05:35:39.506126 29777 sgd_solver.cpp:106] Iteration 64600, lr = 0.00798125
I0630 05:35:55.866629 29777 solver.cpp:290] Iteration 64700 (6.1124 iter/s, 16.3602s/100 iter), loss = 1.21429
I0630 05:35:55.866657 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:35:55.866667 29777 sgd_solver.cpp:106] Iteration 64700, lr = 0.00797813
I0630 05:36:12.151263 29777 solver.cpp:290] Iteration 64800 (6.14094 iter/s, 16.2842s/100 iter), loss = 1.13095
I0630 05:36:12.151358 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:36:12.151371 29777 sgd_solver.cpp:106] Iteration 64800, lr = 0.007975
I0630 05:36:28.652493 29777 solver.cpp:290] Iteration 64900 (6.06036 iter/s, 16.5007s/100 iter), loss = 0.904762
I0630 05:36:28.652545 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:36:28.652580 29777 sgd_solver.cpp:106] Iteration 64900, lr = 0.00797187
I0630 05:36:44.611688 29777 solver.cpp:354] Sparsity after update:
I0630 05:36:44.632334 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:36:44.632350 29777 net.cpp:1851] conv1a_param_0(0.165) 
I0630 05:36:44.632360 29777 net.cpp:1851] conv1b_param_0(0.33) 
I0630 05:36:44.632364 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:36:44.632367 29777 net.cpp:1851] res2a_branch2a_param_0(0.33) 
I0630 05:36:44.632372 29777 net.cpp:1851] res2a_branch2b_param_0(0.33) 
I0630 05:36:44.632375 29777 net.cpp:1851] res3a_branch2a_param_0(0.33) 
I0630 05:36:44.632378 29777 net.cpp:1851] res3a_branch2b_param_0(0.33) 
I0630 05:36:44.632382 29777 net.cpp:1851] res4a_branch2a_param_0(0.33) 
I0630 05:36:44.632385 29777 net.cpp:1851] res4a_branch2b_param_0(0.33) 
I0630 05:36:44.632388 29777 net.cpp:1851] res5a_branch2a_param_0(0.33) 
I0630 05:36:44.632391 29777 net.cpp:1851] res5a_branch2b_param_0(0.33) 
I0630 05:36:44.632395 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (776672/2.86678e+06) 0.271
I0630 05:36:44.792695 29777 solver.cpp:290] Iteration 65000 (6.1959 iter/s, 16.1397s/100 iter), loss = 1.63095
I0630 05:36:44.792721 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 05:36:44.792729 29777 sgd_solver.cpp:106] Iteration 65000, lr = 0.00796875
I0630 05:37:01.142014 29777 solver.cpp:290] Iteration 65100 (6.11664 iter/s, 16.3488s/100 iter), loss = 1.0119
I0630 05:37:01.142037 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 05:37:01.142045 29777 sgd_solver.cpp:106] Iteration 65100, lr = 0.00796562
I0630 05:37:17.294513 29777 solver.cpp:290] Iteration 65200 (6.19117 iter/s, 16.152s/100 iter), loss = 1.10714
I0630 05:37:17.305039 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 05:37:17.305061 29777 sgd_solver.cpp:106] Iteration 65200, lr = 0.0079625
I0630 05:37:33.581264 29777 solver.cpp:290] Iteration 65300 (6.1441 iter/s, 16.2758s/100 iter), loss = 1.27381
I0630 05:37:33.581286 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:37:33.581293 29777 sgd_solver.cpp:106] Iteration 65300, lr = 0.00795937
I0630 05:37:49.714903 29777 solver.cpp:290] Iteration 65400 (6.19841 iter/s, 16.1332s/100 iter), loss = 1.45238
I0630 05:37:49.714952 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 05:37:49.714962 29777 sgd_solver.cpp:106] Iteration 65400, lr = 0.00795625
I0630 05:38:06.191995 29777 solver.cpp:290] Iteration 65500 (6.06922 iter/s, 16.4766s/100 iter), loss = 0.833333
I0630 05:38:06.192020 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 05:38:06.192029 29777 sgd_solver.cpp:106] Iteration 65500, lr = 0.00795313
I0630 05:38:22.300556 29777 solver.cpp:290] Iteration 65600 (6.20806 iter/s, 16.1081s/100 iter), loss = 1.19048
I0630 05:38:22.300657 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 05:38:22.300689 29777 sgd_solver.cpp:106] Iteration 65600, lr = 0.00795
I0630 05:38:38.649194 29777 solver.cpp:290] Iteration 65700 (6.11692 iter/s, 16.3481s/100 iter), loss = 1.08333
I0630 05:38:38.649217 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:38:38.649224 29777 sgd_solver.cpp:106] Iteration 65700, lr = 0.00794687
I0630 05:38:55.108309 29777 solver.cpp:290] Iteration 65800 (6.07584 iter/s, 16.4586s/100 iter), loss = 0.809524
I0630 05:38:55.108415 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:38:55.108434 29777 sgd_solver.cpp:106] Iteration 65800, lr = 0.00794375
I0630 05:39:11.432003 29777 solver.cpp:290] Iteration 65900 (6.12627 iter/s, 16.3231s/100 iter), loss = 1.05952
I0630 05:39:11.432025 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:39:11.432032 29777 sgd_solver.cpp:106] Iteration 65900, lr = 0.00794062
I0630 05:39:27.506494 29777 solver.cpp:354] Sparsity after update:
I0630 05:39:27.507956 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:39:27.507964 29777 net.cpp:1851] conv1a_param_0(0.165) 
I0630 05:39:27.507972 29777 net.cpp:1851] conv1b_param_0(0.33) 
I0630 05:39:27.507973 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:39:27.507975 29777 net.cpp:1851] res2a_branch2a_param_0(0.33) 
I0630 05:39:27.507977 29777 net.cpp:1851] res2a_branch2b_param_0(0.33) 
I0630 05:39:27.507979 29777 net.cpp:1851] res3a_branch2a_param_0(0.33) 
I0630 05:39:27.507982 29777 net.cpp:1851] res3a_branch2b_param_0(0.33) 
I0630 05:39:27.507983 29777 net.cpp:1851] res4a_branch2a_param_0(0.33) 
I0630 05:39:27.507985 29777 net.cpp:1851] res4a_branch2b_param_0(0.33) 
I0630 05:39:27.507987 29777 net.cpp:1851] res5a_branch2a_param_0(0.33) 
I0630 05:39:27.507989 29777 net.cpp:1851] res5a_branch2b_param_0(0.33) 
I0630 05:39:27.507990 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (776672/2.86678e+06) 0.271
I0630 05:39:27.508082 29777 solver.cpp:471] Iteration 66000, Testing net (#0)
I0630 05:39:34.564610 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:40:34.491297 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56654
I0630 05:40:34.491348 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804281
I0630 05:40:34.491354 29777 solver.cpp:544]     Test net output #2: loss = 1.53276 (* 1 = 1.53276 loss)
I0630 05:40:34.669544 29777 solver.cpp:290] Iteration 66000 (1.20141 iter/s, 83.2352s/100 iter), loss = 1.04762
I0630 05:40:34.669566 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:40:34.669574 29777 sgd_solver.cpp:106] Iteration 66000, lr = 0.0079375
I0630 05:40:34.670271 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.34
I0630 05:40:34.893188 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:40:50.252248 29777 solver.cpp:290] Iteration 66100 (6.41756 iter/s, 15.5822s/100 iter), loss = 1.16667
I0630 05:40:50.252274 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 05:40:50.252282 29777 sgd_solver.cpp:106] Iteration 66100, lr = 0.00793437
I0630 05:41:07.219377 29777 solver.cpp:290] Iteration 66200 (5.89392 iter/s, 16.9666s/100 iter), loss = 1.13095
I0630 05:41:07.219429 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:41:07.219437 29777 sgd_solver.cpp:106] Iteration 66200, lr = 0.00793125
I0630 05:41:23.698922 29777 solver.cpp:290] Iteration 66300 (6.06832 iter/s, 16.479s/100 iter), loss = 1.09524
I0630 05:41:23.699028 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 05:41:23.699064 29777 sgd_solver.cpp:106] Iteration 66300, lr = 0.00792812
I0630 05:41:39.919354 29777 solver.cpp:290] Iteration 66400 (6.16527 iter/s, 16.2199s/100 iter), loss = 0.880952
I0630 05:41:39.919426 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:41:39.919433 29777 sgd_solver.cpp:106] Iteration 66400, lr = 0.007925
I0630 05:41:56.045202 29777 solver.cpp:290] Iteration 66500 (6.20142 iter/s, 16.1253s/100 iter), loss = 1.2381
I0630 05:41:56.045223 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 05:41:56.045230 29777 sgd_solver.cpp:106] Iteration 66500, lr = 0.00792187
I0630 05:42:12.345329 29777 solver.cpp:290] Iteration 66600 (6.1351 iter/s, 16.2997s/100 iter), loss = 0.821429
I0630 05:42:12.345432 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 05:42:12.345441 29777 sgd_solver.cpp:106] Iteration 66600, lr = 0.00791875
I0630 05:42:28.472012 29777 solver.cpp:290] Iteration 66700 (6.20111 iter/s, 16.1261s/100 iter), loss = 1.0119
I0630 05:42:28.472035 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 05:42:28.472041 29777 sgd_solver.cpp:106] Iteration 66700, lr = 0.00791562
I0630 05:42:44.704329 29777 solver.cpp:290] Iteration 66800 (6.16073 iter/s, 16.2318s/100 iter), loss = 0.916667
I0630 05:42:44.704432 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 05:42:44.704444 29777 sgd_solver.cpp:106] Iteration 66800, lr = 0.0079125
I0630 05:43:00.832502 29777 solver.cpp:290] Iteration 66900 (6.20054 iter/s, 16.1276s/100 iter), loss = 1.41667
I0630 05:43:00.832556 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:43:00.832590 29777 sgd_solver.cpp:106] Iteration 66900, lr = 0.00790937
I0630 05:43:16.823930 29777 solver.cpp:354] Sparsity after update:
I0630 05:43:16.845173 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:43:16.845360 29777 net.cpp:1851] conv1a_param_0(0.17) 
I0630 05:43:16.845376 29777 net.cpp:1851] conv1b_param_0(0.34) 
I0630 05:43:16.845379 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:43:16.845383 29777 net.cpp:1851] res2a_branch2a_param_0(0.34) 
I0630 05:43:16.845446 29777 net.cpp:1851] res2a_branch2b_param_0(0.34) 
I0630 05:43:16.845511 29777 net.cpp:1851] res3a_branch2a_param_0(0.34) 
I0630 05:43:16.845520 29777 net.cpp:1851] res3a_branch2b_param_0(0.34) 
I0630 05:43:16.845523 29777 net.cpp:1851] res4a_branch2a_param_0(0.34) 
I0630 05:43:16.845600 29777 net.cpp:1851] res4a_branch2b_param_0(0.34) 
I0630 05:43:16.845613 29777 net.cpp:1851] res5a_branch2a_param_0(0.34) 
I0630 05:43:16.845692 29777 net.cpp:1851] res5a_branch2b_param_0(0.34) 
I0630 05:43:16.845706 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (800210/2.86678e+06) 0.279
I0630 05:43:17.029714 29777 solver.cpp:290] Iteration 67000 (6.17409 iter/s, 16.1967s/100 iter), loss = 1.27381
I0630 05:43:17.029739 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 05:43:17.029747 29777 sgd_solver.cpp:106] Iteration 67000, lr = 0.00790625
I0630 05:43:33.156610 29777 solver.cpp:290] Iteration 67100 (6.201 iter/s, 16.1264s/100 iter), loss = 0.690476
I0630 05:43:33.156690 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 05:43:33.156718 29777 sgd_solver.cpp:106] Iteration 67100, lr = 0.00790313
I0630 05:43:49.432188 29777 solver.cpp:290] Iteration 67200 (6.14437 iter/s, 16.2751s/100 iter), loss = 0.678571
I0630 05:43:49.432263 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 05:43:49.432271 29777 sgd_solver.cpp:106] Iteration 67200, lr = 0.0079
I0630 05:44:05.660360 29777 solver.cpp:290] Iteration 67300 (6.16232 iter/s, 16.2276s/100 iter), loss = 1.08333
I0630 05:44:05.660382 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:44:05.660389 29777 sgd_solver.cpp:106] Iteration 67300, lr = 0.00789688
I0630 05:44:21.888247 29777 solver.cpp:290] Iteration 67400 (6.16241 iter/s, 16.2274s/100 iter), loss = 0.988095
I0630 05:44:21.888339 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 05:44:21.888350 29777 sgd_solver.cpp:106] Iteration 67400, lr = 0.00789375
I0630 05:44:38.115219 29777 solver.cpp:290] Iteration 67500 (6.16278 iter/s, 16.2264s/100 iter), loss = 1.08333
I0630 05:44:38.115242 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:44:38.115248 29777 sgd_solver.cpp:106] Iteration 67500, lr = 0.00789062
I0630 05:44:54.275766 29777 solver.cpp:290] Iteration 67600 (6.18809 iter/s, 16.1601s/100 iter), loss = 1.35714
I0630 05:44:54.275836 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 05:44:54.275843 29777 sgd_solver.cpp:106] Iteration 67600, lr = 0.0078875
I0630 05:45:10.528537 29777 solver.cpp:290] Iteration 67700 (6.15299 iter/s, 16.2523s/100 iter), loss = 1.27381
I0630 05:45:10.528561 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 05:45:10.528568 29777 sgd_solver.cpp:106] Iteration 67700, lr = 0.00788437
I0630 05:45:26.684849 29777 solver.cpp:290] Iteration 67800 (6.18971 iter/s, 16.1558s/100 iter), loss = 0.738095
I0630 05:45:26.684969 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 05:45:26.684979 29777 sgd_solver.cpp:106] Iteration 67800, lr = 0.00788125
I0630 05:45:42.860692 29777 solver.cpp:290] Iteration 67900 (6.18227 iter/s, 16.1753s/100 iter), loss = 0.738095
I0630 05:45:42.860713 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:45:42.860720 29777 sgd_solver.cpp:106] Iteration 67900, lr = 0.00787812
I0630 05:45:59.166110 29777 solver.cpp:354] Sparsity after update:
I0630 05:45:59.167131 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:45:59.167140 29777 net.cpp:1851] conv1a_param_0(0.17) 
I0630 05:45:59.167150 29777 net.cpp:1851] conv1b_param_0(0.34) 
I0630 05:45:59.167151 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:45:59.167153 29777 net.cpp:1851] res2a_branch2a_param_0(0.34) 
I0630 05:45:59.167156 29777 net.cpp:1851] res2a_branch2b_param_0(0.34) 
I0630 05:45:59.167158 29777 net.cpp:1851] res3a_branch2a_param_0(0.34) 
I0630 05:45:59.167160 29777 net.cpp:1851] res3a_branch2b_param_0(0.34) 
I0630 05:45:59.167162 29777 net.cpp:1851] res4a_branch2a_param_0(0.34) 
I0630 05:45:59.167165 29777 net.cpp:1851] res4a_branch2b_param_0(0.34) 
I0630 05:45:59.167166 29777 net.cpp:1851] res5a_branch2a_param_0(0.34) 
I0630 05:45:59.167168 29777 net.cpp:1851] res5a_branch2b_param_0(0.34) 
I0630 05:45:59.167171 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (800210/2.86678e+06) 0.279
I0630 05:45:59.167258 29777 solver.cpp:471] Iteration 68000, Testing net (#0)
I0630 05:46:07.570441 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:47:01.394939 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57304
I0630 05:47:01.395020 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.805981
I0630 05:47:01.395030 29777 solver.cpp:544]     Test net output #2: loss = 1.51236 (* 1 = 1.51236 loss)
I0630 05:47:01.570538 29777 solver.cpp:290] Iteration 68000 (1.27052 iter/s, 78.7077s/100 iter), loss = 1.19048
I0630 05:47:01.570562 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:47:01.570569 29777 sgd_solver.cpp:106] Iteration 68000, lr = 0.007875
I0630 05:47:01.571272 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.35
I0630 05:47:01.793678 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:47:17.477854 29777 solver.cpp:290] Iteration 68100 (6.2866 iter/s, 15.9069s/100 iter), loss = 0.928571
I0630 05:47:17.477880 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:47:17.477890 29777 sgd_solver.cpp:106] Iteration 68100, lr = 0.00787187
I0630 05:47:33.669076 29777 solver.cpp:290] Iteration 68200 (6.17637 iter/s, 16.1907s/100 iter), loss = 1.14286
I0630 05:47:33.669180 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 05:47:33.669190 29777 sgd_solver.cpp:106] Iteration 68200, lr = 0.00786875
I0630 05:47:49.728314 29777 solver.cpp:290] Iteration 68300 (6.22716 iter/s, 16.0587s/100 iter), loss = 1.15476
I0630 05:47:49.728339 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 05:47:49.728348 29777 sgd_solver.cpp:106] Iteration 68300, lr = 0.00786562
I0630 05:48:05.855743 29777 solver.cpp:290] Iteration 68400 (6.2008 iter/s, 16.127s/100 iter), loss = 1.53571
I0630 05:48:05.855814 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 05:48:05.855821 29777 sgd_solver.cpp:106] Iteration 68400, lr = 0.0078625
I0630 05:48:22.117815 29777 solver.cpp:290] Iteration 68500 (6.14948 iter/s, 16.2615s/100 iter), loss = 0.940476
I0630 05:48:22.117854 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 05:48:22.117866 29777 sgd_solver.cpp:106] Iteration 68500, lr = 0.00785937
I0630 05:48:38.310878 29777 solver.cpp:290] Iteration 68600 (6.17567 iter/s, 16.1926s/100 iter), loss = 1.39286
I0630 05:48:38.311132 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 05:48:38.311244 29777 sgd_solver.cpp:106] Iteration 68600, lr = 0.00785625
I0630 05:48:54.410362 29777 solver.cpp:290] Iteration 68700 (6.21165 iter/s, 16.0988s/100 iter), loss = 0.928571
I0630 05:48:54.410388 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 05:48:54.410398 29777 sgd_solver.cpp:106] Iteration 68700, lr = 0.00785313
I0630 05:49:10.480068 29777 solver.cpp:290] Iteration 68800 (6.22307 iter/s, 16.0692s/100 iter), loss = 0.72619
I0630 05:49:10.480162 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:49:10.480173 29777 sgd_solver.cpp:106] Iteration 68800, lr = 0.00785
I0630 05:49:26.772305 29777 solver.cpp:290] Iteration 68900 (6.1381 iter/s, 16.2917s/100 iter), loss = 1.03571
I0630 05:49:26.772334 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 05:49:26.772347 29777 sgd_solver.cpp:106] Iteration 68900, lr = 0.00784688
I0630 05:49:42.817756 29777 solver.cpp:354] Sparsity after update:
I0630 05:49:42.838160 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:49:42.838173 29777 net.cpp:1851] conv1a_param_0(0.175) 
I0630 05:49:42.838182 29777 net.cpp:1851] conv1b_param_0(0.35) 
I0630 05:49:42.838184 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:49:42.838186 29777 net.cpp:1851] res2a_branch2a_param_0(0.35) 
I0630 05:49:42.838188 29777 net.cpp:1851] res2a_branch2b_param_0(0.35) 
I0630 05:49:42.838191 29777 net.cpp:1851] res3a_branch2a_param_0(0.35) 
I0630 05:49:42.838192 29777 net.cpp:1851] res3a_branch2b_param_0(0.35) 
I0630 05:49:42.838194 29777 net.cpp:1851] res4a_branch2a_param_0(0.35) 
I0630 05:49:42.838196 29777 net.cpp:1851] res4a_branch2b_param_0(0.35) 
I0630 05:49:42.838201 29777 net.cpp:1851] res5a_branch2a_param_0(0.35) 
I0630 05:49:42.838203 29777 net.cpp:1851] res5a_branch2b_param_0(0.35) 
I0630 05:49:42.838205 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (823746/2.86678e+06) 0.287
I0630 05:49:42.990581 29777 solver.cpp:290] Iteration 69000 (6.16607 iter/s, 16.2178s/100 iter), loss = 1.25
I0630 05:49:42.990602 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 05:49:42.990608 29777 sgd_solver.cpp:106] Iteration 69000, lr = 0.00784375
I0630 05:49:59.154991 29777 solver.cpp:290] Iteration 69100 (6.18661 iter/s, 16.1639s/100 iter), loss = 1.17857
I0630 05:49:59.155020 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 05:49:59.155030 29777 sgd_solver.cpp:106] Iteration 69100, lr = 0.00784063
I0630 05:50:15.469106 29777 solver.cpp:290] Iteration 69200 (6.12984 iter/s, 16.3136s/100 iter), loss = 1.13095
I0630 05:50:15.469190 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:50:15.469198 29777 sgd_solver.cpp:106] Iteration 69200, lr = 0.0078375
I0630 05:50:31.620386 29777 solver.cpp:290] Iteration 69300 (6.19166 iter/s, 16.1507s/100 iter), loss = 1
I0630 05:50:31.620411 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 05:50:31.620419 29777 sgd_solver.cpp:106] Iteration 69300, lr = 0.00783437
I0630 05:50:47.993705 29777 solver.cpp:290] Iteration 69400 (6.10768 iter/s, 16.3728s/100 iter), loss = 1.33333
I0630 05:50:47.993801 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 05:50:47.993813 29777 sgd_solver.cpp:106] Iteration 69400, lr = 0.00783125
I0630 05:51:04.752816 29777 solver.cpp:290] Iteration 69500 (5.9671 iter/s, 16.7586s/100 iter), loss = 0.928571
I0630 05:51:04.752841 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 05:51:04.752851 29777 sgd_solver.cpp:106] Iteration 69500, lr = 0.00782812
I0630 05:51:21.054244 29777 solver.cpp:290] Iteration 69600 (6.13461 iter/s, 16.301s/100 iter), loss = 1.16667
I0630 05:51:21.054337 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 05:51:21.054347 29777 sgd_solver.cpp:106] Iteration 69600, lr = 0.007825
I0630 05:51:37.022455 29777 solver.cpp:290] Iteration 69700 (6.26265 iter/s, 15.9677s/100 iter), loss = 0.988095
I0630 05:51:37.022480 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 05:51:37.022490 29777 sgd_solver.cpp:106] Iteration 69700, lr = 0.00782187
I0630 05:51:53.019091 29777 solver.cpp:290] Iteration 69800 (6.2515 iter/s, 15.9962s/100 iter), loss = 0.97619
I0630 05:51:53.019194 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 05:51:53.019204 29777 sgd_solver.cpp:106] Iteration 69800, lr = 0.00781875
I0630 05:52:09.046422 29777 solver.cpp:290] Iteration 69900 (6.23955 iter/s, 16.0268s/100 iter), loss = 1.39286
I0630 05:52:09.046444 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 05:52:09.046452 29777 sgd_solver.cpp:106] Iteration 69900, lr = 0.00781562
I0630 05:52:25.098418 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_70000.caffemodel
I0630 05:52:25.117558 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_70000.solverstate
I0630 05:52:25.126152 29777 solver.cpp:354] Sparsity after update:
I0630 05:52:25.127122 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:52:25.127130 29777 net.cpp:1851] conv1a_param_0(0.175) 
I0630 05:52:25.127137 29777 net.cpp:1851] conv1b_param_0(0.35) 
I0630 05:52:25.127140 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:52:25.127141 29777 net.cpp:1851] res2a_branch2a_param_0(0.35) 
I0630 05:52:25.127143 29777 net.cpp:1851] res2a_branch2b_param_0(0.35) 
I0630 05:52:25.127146 29777 net.cpp:1851] res3a_branch2a_param_0(0.35) 
I0630 05:52:25.127147 29777 net.cpp:1851] res3a_branch2b_param_0(0.35) 
I0630 05:52:25.127149 29777 net.cpp:1851] res4a_branch2a_param_0(0.35) 
I0630 05:52:25.127151 29777 net.cpp:1851] res4a_branch2b_param_0(0.35) 
I0630 05:52:25.127153 29777 net.cpp:1851] res5a_branch2a_param_0(0.35) 
I0630 05:52:25.127156 29777 net.cpp:1851] res5a_branch2b_param_0(0.35) 
I0630 05:52:25.127158 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (823746/2.86678e+06) 0.287
I0630 05:52:25.127251 29777 solver.cpp:471] Iteration 70000, Testing net (#0)
I0630 05:52:31.240478 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:53:13.637768 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.564759
I0630 05:53:13.637822 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801401
I0630 05:53:13.637828 29777 solver.cpp:544]     Test net output #2: loss = 1.56544 (* 1 = 1.56544 loss)
I0630 05:53:13.814138 29777 solver.cpp:290] Iteration 70000 (1.54402 iter/s, 64.7659s/100 iter), loss = 0.476191
I0630 05:53:13.814163 29777 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0630 05:53:13.814170 29777 sgd_solver.cpp:106] Iteration 70000, lr = 0.0078125
I0630 05:53:13.814898 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.36
I0630 05:53:14.057551 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:53:30.148615 29777 solver.cpp:290] Iteration 70100 (6.1222 iter/s, 16.334s/100 iter), loss = 1.2619
I0630 05:53:30.148641 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 05:53:30.148650 29777 sgd_solver.cpp:106] Iteration 70100, lr = 0.00780937
I0630 05:53:46.203061 29777 solver.cpp:290] Iteration 70200 (6.22899 iter/s, 16.054s/100 iter), loss = 1.10714
I0630 05:53:46.203176 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 05:53:46.203186 29777 sgd_solver.cpp:106] Iteration 70200, lr = 0.00780625
I0630 05:54:02.356597 29777 solver.cpp:290] Iteration 70300 (6.19081 iter/s, 16.153s/100 iter), loss = 1.17857
I0630 05:54:02.356624 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 05:54:02.356634 29777 sgd_solver.cpp:106] Iteration 70300, lr = 0.00780312
I0630 05:54:18.394696 29777 solver.cpp:290] Iteration 70400 (6.23534 iter/s, 16.0376s/100 iter), loss = 1.46429
I0630 05:54:18.394799 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 05:54:18.394809 29777 sgd_solver.cpp:106] Iteration 70400, lr = 0.0078
I0630 05:54:34.437590 29777 solver.cpp:290] Iteration 70500 (6.2335 iter/s, 16.0423s/100 iter), loss = 1.71429
I0630 05:54:34.437618 29777 solver.cpp:309]     Train net output #0: loss = 1.90476 (* 1 = 1.90476 loss)
I0630 05:54:34.437626 29777 sgd_solver.cpp:106] Iteration 70500, lr = 0.00779688
I0630 05:54:50.548130 29777 solver.cpp:290] Iteration 70600 (6.2073 iter/s, 16.1101s/100 iter), loss = 1.25
I0630 05:54:50.548224 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 05:54:50.548235 29777 sgd_solver.cpp:106] Iteration 70600, lr = 0.00779375
I0630 05:55:06.809847 29777 solver.cpp:290] Iteration 70700 (6.14962 iter/s, 16.2612s/100 iter), loss = 1.36905
I0630 05:55:06.809870 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:55:06.809878 29777 sgd_solver.cpp:106] Iteration 70700, lr = 0.00779063
I0630 05:55:22.980314 29777 solver.cpp:290] Iteration 70800 (6.18429 iter/s, 16.17s/100 iter), loss = 1.2619
I0630 05:55:22.980414 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 05:55:22.980422 29777 sgd_solver.cpp:106] Iteration 70800, lr = 0.0077875
I0630 05:55:39.048033 29777 solver.cpp:290] Iteration 70900 (6.22387 iter/s, 16.0672s/100 iter), loss = 1.15476
I0630 05:55:39.048056 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 05:55:39.048063 29777 sgd_solver.cpp:106] Iteration 70900, lr = 0.00778437
I0630 05:55:55.052947 29777 solver.cpp:354] Sparsity after update:
I0630 05:55:55.073216 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:55:55.073230 29777 net.cpp:1851] conv1a_param_0(0.18) 
I0630 05:55:55.073241 29777 net.cpp:1851] conv1b_param_0(0.36) 
I0630 05:55:55.073246 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:55:55.073248 29777 net.cpp:1851] res2a_branch2a_param_0(0.36) 
I0630 05:55:55.073253 29777 net.cpp:1851] res2a_branch2b_param_0(0.36) 
I0630 05:55:55.073257 29777 net.cpp:1851] res3a_branch2a_param_0(0.36) 
I0630 05:55:55.073261 29777 net.cpp:1851] res3a_branch2b_param_0(0.36) 
I0630 05:55:55.073263 29777 net.cpp:1851] res4a_branch2a_param_0(0.36) 
I0630 05:55:55.073267 29777 net.cpp:1851] res4a_branch2b_param_0(0.36) 
I0630 05:55:55.073271 29777 net.cpp:1851] res5a_branch2a_param_0(0.36) 
I0630 05:55:55.073276 29777 net.cpp:1851] res5a_branch2b_param_0(0.36) 
I0630 05:55:55.073279 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (847283/2.86678e+06) 0.296
I0630 05:55:55.228878 29777 solver.cpp:290] Iteration 71000 (6.18033 iter/s, 16.1804s/100 iter), loss = 0.952381
I0630 05:55:55.228904 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 05:55:55.228912 29777 sgd_solver.cpp:106] Iteration 71000, lr = 0.00778125
I0630 05:56:11.297562 29777 solver.cpp:290] Iteration 71100 (6.22347 iter/s, 16.0682s/100 iter), loss = 0.97619
I0630 05:56:11.297586 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 05:56:11.297593 29777 sgd_solver.cpp:106] Iteration 71100, lr = 0.00777812
I0630 05:56:27.311363 29777 solver.cpp:290] Iteration 71200 (6.24479 iter/s, 16.0133s/100 iter), loss = 1.32143
I0630 05:56:27.311453 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 05:56:27.311463 29777 sgd_solver.cpp:106] Iteration 71200, lr = 0.007775
I0630 05:56:43.274574 29777 solver.cpp:290] Iteration 71300 (6.26461 iter/s, 15.9627s/100 iter), loss = 1.46429
I0630 05:56:43.274601 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 05:56:43.274610 29777 sgd_solver.cpp:106] Iteration 71300, lr = 0.00777187
I0630 05:56:59.290525 29777 solver.cpp:290] Iteration 71400 (6.24396 iter/s, 16.0155s/100 iter), loss = 0.928571
I0630 05:56:59.290588 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 05:56:59.290596 29777 sgd_solver.cpp:106] Iteration 71400, lr = 0.00776875
I0630 05:57:15.362407 29777 solver.cpp:290] Iteration 71500 (6.22224 iter/s, 16.0714s/100 iter), loss = 1.46429
I0630 05:57:15.362432 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 05:57:15.362437 29777 sgd_solver.cpp:106] Iteration 71500, lr = 0.00776563
I0630 05:57:31.510815 29777 solver.cpp:290] Iteration 71600 (6.19274 iter/s, 16.1479s/100 iter), loss = 0.928571
I0630 05:57:31.510901 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:57:31.510916 29777 sgd_solver.cpp:106] Iteration 71600, lr = 0.0077625
I0630 05:57:47.689947 29777 solver.cpp:290] Iteration 71700 (6.181 iter/s, 16.1786s/100 iter), loss = 1.35714
I0630 05:57:47.689973 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 05:57:47.689981 29777 sgd_solver.cpp:106] Iteration 71700, lr = 0.00775938
I0630 05:58:03.790956 29777 solver.cpp:290] Iteration 71800 (6.21097 iter/s, 16.1005s/100 iter), loss = 1.07143
I0630 05:58:03.791069 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 05:58:03.791079 29777 sgd_solver.cpp:106] Iteration 71800, lr = 0.00775625
I0630 05:58:20.042714 29777 solver.cpp:290] Iteration 71900 (6.15339 iter/s, 16.2512s/100 iter), loss = 1.45238
I0630 05:58:20.042735 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 05:58:20.042743 29777 sgd_solver.cpp:106] Iteration 71900, lr = 0.00775312
I0630 05:58:35.946403 29777 solver.cpp:354] Sparsity after update:
I0630 05:58:35.947840 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 05:58:35.947849 29777 net.cpp:1851] conv1a_param_0(0.18) 
I0630 05:58:35.947855 29777 net.cpp:1851] conv1b_param_0(0.36) 
I0630 05:58:35.947859 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 05:58:35.947860 29777 net.cpp:1851] res2a_branch2a_param_0(0.36) 
I0630 05:58:35.947863 29777 net.cpp:1851] res2a_branch2b_param_0(0.36) 
I0630 05:58:35.947865 29777 net.cpp:1851] res3a_branch2a_param_0(0.36) 
I0630 05:58:35.947867 29777 net.cpp:1851] res3a_branch2b_param_0(0.36) 
I0630 05:58:35.947870 29777 net.cpp:1851] res4a_branch2a_param_0(0.36) 
I0630 05:58:35.947872 29777 net.cpp:1851] res4a_branch2b_param_0(0.36) 
I0630 05:58:35.947875 29777 net.cpp:1851] res5a_branch2a_param_0(0.36) 
I0630 05:58:35.947876 29777 net.cpp:1851] res5a_branch2b_param_0(0.36) 
I0630 05:58:35.947880 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (847283/2.86678e+06) 0.296
I0630 05:58:35.947964 29777 solver.cpp:471] Iteration 72000, Testing net (#0)
I0630 05:58:42.345530 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 05:59:24.880152 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.571939
I0630 05:59:24.880259 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.805861
I0630 05:59:24.880269 29777 solver.cpp:544]     Test net output #2: loss = 1.51954 (* 1 = 1.51954 loss)
I0630 05:59:25.056967 29777 solver.cpp:290] Iteration 72000 (1.53817 iter/s, 65.0125s/100 iter), loss = 1.02381
I0630 05:59:25.056991 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 05:59:25.057000 29777 sgd_solver.cpp:106] Iteration 72000, lr = 0.00775
I0630 05:59:25.057981 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.37
I0630 05:59:25.304527 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 05:59:41.333969 29777 solver.cpp:290] Iteration 72100 (6.14382 iter/s, 16.2765s/100 iter), loss = 1.13095
I0630 05:59:41.333995 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 05:59:41.334008 29777 sgd_solver.cpp:106] Iteration 72100, lr = 0.00774688
I0630 05:59:57.426584 29777 solver.cpp:290] Iteration 72200 (6.21421 iter/s, 16.0921s/100 iter), loss = 0.75
I0630 05:59:57.426694 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 05:59:57.426705 29777 sgd_solver.cpp:106] Iteration 72200, lr = 0.00774375
I0630 06:00:13.558910 29777 solver.cpp:290] Iteration 72300 (6.19895 iter/s, 16.1318s/100 iter), loss = 1.28571
I0630 06:00:13.558935 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 06:00:13.558954 29777 sgd_solver.cpp:106] Iteration 72300, lr = 0.00774063
I0630 06:00:29.781744 29777 solver.cpp:290] Iteration 72400 (6.16433 iter/s, 16.2224s/100 iter), loss = 0.964286
I0630 06:00:29.783833 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 06:00:29.783854 29777 sgd_solver.cpp:106] Iteration 72400, lr = 0.0077375
I0630 06:00:45.917464 29777 solver.cpp:290] Iteration 72500 (6.1984 iter/s, 16.1332s/100 iter), loss = 1.17857
I0630 06:00:45.917488 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:00:45.917497 29777 sgd_solver.cpp:106] Iteration 72500, lr = 0.00773437
I0630 06:01:02.153213 29777 solver.cpp:290] Iteration 72600 (6.15943 iter/s, 16.2353s/100 iter), loss = 0.869048
I0630 06:01:02.153270 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 06:01:02.153278 29777 sgd_solver.cpp:106] Iteration 72600, lr = 0.00773125
I0630 06:01:18.296633 29777 solver.cpp:290] Iteration 72700 (6.19467 iter/s, 16.1429s/100 iter), loss = 1.61905
I0630 06:01:18.296659 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 06:01:18.296669 29777 sgd_solver.cpp:106] Iteration 72700, lr = 0.00772812
I0630 06:01:34.296741 29777 solver.cpp:290] Iteration 72800 (6.25014 iter/s, 15.9996s/100 iter), loss = 1.2619
I0630 06:01:34.296813 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:01:34.296820 29777 sgd_solver.cpp:106] Iteration 72800, lr = 0.007725
I0630 06:01:50.283690 29777 solver.cpp:290] Iteration 72900 (6.2553 iter/s, 15.9864s/100 iter), loss = 1.0119
I0630 06:01:50.283715 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:01:50.283725 29777 sgd_solver.cpp:106] Iteration 72900, lr = 0.00772187
I0630 06:02:06.194926 29777 solver.cpp:354] Sparsity after update:
I0630 06:02:06.215346 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:02:06.215382 29777 net.cpp:1851] conv1a_param_0(0.185) 
I0630 06:02:06.215399 29777 net.cpp:1851] conv1b_param_0(0.37) 
I0630 06:02:06.215406 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:02:06.215415 29777 net.cpp:1851] res2a_branch2a_param_0(0.37) 
I0630 06:02:06.215425 29777 net.cpp:1851] res2a_branch2b_param_0(0.37) 
I0630 06:02:06.215435 29777 net.cpp:1851] res3a_branch2a_param_0(0.37) 
I0630 06:02:06.215442 29777 net.cpp:1851] res3a_branch2b_param_0(0.37) 
I0630 06:02:06.215451 29777 net.cpp:1851] res4a_branch2a_param_0(0.37) 
I0630 06:02:06.215458 29777 net.cpp:1851] res4a_branch2b_param_0(0.37) 
I0630 06:02:06.215466 29777 net.cpp:1851] res5a_branch2a_param_0(0.37) 
I0630 06:02:06.215474 29777 net.cpp:1851] res5a_branch2b_param_0(0.37) 
I0630 06:02:06.215482 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (870817/2.86678e+06) 0.304
I0630 06:02:06.374341 29777 solver.cpp:290] Iteration 73000 (6.21497 iter/s, 16.0902s/100 iter), loss = 1.08333
I0630 06:02:06.374363 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 06:02:06.374370 29777 sgd_solver.cpp:106] Iteration 73000, lr = 0.00771875
I0630 06:02:22.420152 29777 solver.cpp:290] Iteration 73100 (6.23234 iter/s, 16.0453s/100 iter), loss = 1.13095
I0630 06:02:22.420176 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:02:22.420182 29777 sgd_solver.cpp:106] Iteration 73100, lr = 0.00771563
I0630 06:02:38.426194 29777 solver.cpp:290] Iteration 73200 (6.24782 iter/s, 16.0056s/100 iter), loss = 1
I0630 06:02:38.426285 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 06:02:38.426291 29777 sgd_solver.cpp:106] Iteration 73200, lr = 0.0077125
I0630 06:02:54.433547 29777 solver.cpp:290] Iteration 73300 (6.24734 iter/s, 16.0068s/100 iter), loss = 1.11905
I0630 06:02:54.433574 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:02:54.433583 29777 sgd_solver.cpp:106] Iteration 73300, lr = 0.00770937
I0630 06:03:10.396828 29777 solver.cpp:290] Iteration 73400 (6.26456 iter/s, 15.9628s/100 iter), loss = 1
I0630 06:03:10.396936 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:03:10.396946 29777 sgd_solver.cpp:106] Iteration 73400, lr = 0.00770625
I0630 06:03:26.480128 29777 solver.cpp:290] Iteration 73500 (6.21784 iter/s, 16.0827s/100 iter), loss = 1.13095
I0630 06:03:26.480155 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:03:26.480172 29777 sgd_solver.cpp:106] Iteration 73500, lr = 0.00770312
I0630 06:03:42.454568 29777 solver.cpp:290] Iteration 73600 (6.26018 iter/s, 15.974s/100 iter), loss = 1.03571
I0630 06:03:42.454638 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:03:42.454645 29777 sgd_solver.cpp:106] Iteration 73600, lr = 0.0077
I0630 06:03:58.477660 29777 solver.cpp:290] Iteration 73700 (6.24119 iter/s, 16.0226s/100 iter), loss = 1.22619
I0630 06:03:58.477710 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 06:03:58.477730 29777 sgd_solver.cpp:106] Iteration 73700, lr = 0.00769688
I0630 06:04:14.669879 29777 solver.cpp:290] Iteration 73800 (6.17599 iter/s, 16.1917s/100 iter), loss = 1.16667
I0630 06:04:14.669987 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 06:04:14.669997 29777 sgd_solver.cpp:106] Iteration 73800, lr = 0.00769375
I0630 06:04:30.751170 29777 solver.cpp:290] Iteration 73900 (6.21862 iter/s, 16.0807s/100 iter), loss = 1.04762
I0630 06:04:30.751197 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:04:30.751206 29777 sgd_solver.cpp:106] Iteration 73900, lr = 0.00769062
I0630 06:04:46.802836 29777 solver.cpp:354] Sparsity after update:
I0630 06:04:46.804098 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:04:46.804106 29777 net.cpp:1851] conv1a_param_0(0.185) 
I0630 06:04:46.804113 29777 net.cpp:1851] conv1b_param_0(0.37) 
I0630 06:04:46.804116 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:04:46.804118 29777 net.cpp:1851] res2a_branch2a_param_0(0.37) 
I0630 06:04:46.804121 29777 net.cpp:1851] res2a_branch2b_param_0(0.37) 
I0630 06:04:46.804122 29777 net.cpp:1851] res3a_branch2a_param_0(0.37) 
I0630 06:04:46.804124 29777 net.cpp:1851] res3a_branch2b_param_0(0.37) 
I0630 06:04:46.804126 29777 net.cpp:1851] res4a_branch2a_param_0(0.37) 
I0630 06:04:46.804128 29777 net.cpp:1851] res4a_branch2b_param_0(0.37) 
I0630 06:04:46.804131 29777 net.cpp:1851] res5a_branch2a_param_0(0.37) 
I0630 06:04:46.804132 29777 net.cpp:1851] res5a_branch2b_param_0(0.37) 
I0630 06:04:46.804134 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (870817/2.86678e+06) 0.304
I0630 06:04:46.804251 29777 solver.cpp:471] Iteration 74000, Testing net (#0)
I0630 06:04:54.446146 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:05:37.169081 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.567319
I0630 06:05:37.169133 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.802282
I0630 06:05:37.169139 29777 solver.cpp:544]     Test net output #2: loss = 1.54096 (* 1 = 1.54096 loss)
I0630 06:05:37.344485 29777 solver.cpp:290] Iteration 74000 (1.50169 iter/s, 66.5915s/100 iter), loss = 0.892857
I0630 06:05:37.344511 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:05:37.344519 29777 sgd_solver.cpp:106] Iteration 74000, lr = 0.0076875
I0630 06:05:37.345504 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.38
I0630 06:05:37.601541 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:05:53.510392 29777 solver.cpp:290] Iteration 74100 (6.18604 iter/s, 16.1654s/100 iter), loss = 0.940476
I0630 06:05:53.510414 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 06:05:53.510422 29777 sgd_solver.cpp:106] Iteration 74100, lr = 0.00768437
I0630 06:06:09.464521 29777 solver.cpp:290] Iteration 74200 (6.26815 iter/s, 15.9537s/100 iter), loss = 0.880952
I0630 06:06:09.464603 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 06:06:09.464612 29777 sgd_solver.cpp:106] Iteration 74200, lr = 0.00768125
I0630 06:06:25.432833 29777 solver.cpp:290] Iteration 74300 (6.26261 iter/s, 15.9678s/100 iter), loss = 0.619048
I0630 06:06:25.432857 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 06:06:25.432863 29777 sgd_solver.cpp:106] Iteration 74300, lr = 0.00767812
I0630 06:06:41.509405 29777 solver.cpp:290] Iteration 74400 (6.22041 iter/s, 16.0761s/100 iter), loss = 1.25
I0630 06:06:41.509524 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 06:06:41.509534 29777 sgd_solver.cpp:106] Iteration 74400, lr = 0.007675
I0630 06:06:57.502697 29777 solver.cpp:290] Iteration 74500 (6.25284 iter/s, 15.9927s/100 iter), loss = 0.738095
I0630 06:06:57.502724 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:06:57.502733 29777 sgd_solver.cpp:106] Iteration 74500, lr = 0.00767187
I0630 06:07:13.572283 29777 solver.cpp:290] Iteration 74600 (6.22312 iter/s, 16.0691s/100 iter), loss = 1.27381
I0630 06:07:13.572386 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 06:07:13.572396 29777 sgd_solver.cpp:106] Iteration 74600, lr = 0.00766875
I0630 06:07:29.659207 29777 solver.cpp:290] Iteration 74700 (6.21644 iter/s, 16.0864s/100 iter), loss = 1.0119
I0630 06:07:29.659234 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:07:29.659240 29777 sgd_solver.cpp:106] Iteration 74700, lr = 0.00766562
I0630 06:07:45.908524 29777 solver.cpp:290] Iteration 74800 (6.15429 iter/s, 16.2488s/100 iter), loss = 1.16667
I0630 06:07:45.908619 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 06:07:45.908637 29777 sgd_solver.cpp:106] Iteration 74800, lr = 0.0076625
I0630 06:08:02.080229 29777 solver.cpp:290] Iteration 74900 (6.18384 iter/s, 16.1712s/100 iter), loss = 1.09524
I0630 06:08:02.080255 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:08:02.080265 29777 sgd_solver.cpp:106] Iteration 74900, lr = 0.00765937
I0630 06:08:18.457754 29777 solver.cpp:354] Sparsity after update:
I0630 06:08:18.477988 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:08:18.478024 29777 net.cpp:1851] conv1a_param_0(0.19) 
I0630 06:08:18.478036 29777 net.cpp:1851] conv1b_param_0(0.38) 
I0630 06:08:18.478040 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:08:18.478045 29777 net.cpp:1851] res2a_branch2a_param_0(0.38) 
I0630 06:08:18.478049 29777 net.cpp:1851] res2a_branch2b_param_0(0.38) 
I0630 06:08:18.478052 29777 net.cpp:1851] res3a_branch2a_param_0(0.38) 
I0630 06:08:18.478055 29777 net.cpp:1851] res3a_branch2b_param_0(0.38) 
I0630 06:08:18.478060 29777 net.cpp:1851] res4a_branch2a_param_0(0.38) 
I0630 06:08:18.478062 29777 net.cpp:1851] res4a_branch2b_param_0(0.38) 
I0630 06:08:18.478065 29777 net.cpp:1851] res5a_branch2a_param_0(0.38) 
I0630 06:08:18.478068 29777 net.cpp:1851] res5a_branch2b_param_0(0.38) 
I0630 06:08:18.478072 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (894351/2.86678e+06) 0.312
I0630 06:08:18.637269 29777 solver.cpp:290] Iteration 75000 (6.0399 iter/s, 16.5566s/100 iter), loss = 0.892857
I0630 06:08:18.637292 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:08:18.637300 29777 sgd_solver.cpp:106] Iteration 75000, lr = 0.00765625
I0630 06:08:35.074187 29777 solver.cpp:290] Iteration 75100 (6.08404 iter/s, 16.4364s/100 iter), loss = 1.16667
I0630 06:08:35.074210 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:08:35.074218 29777 sgd_solver.cpp:106] Iteration 75100, lr = 0.00765312
I0630 06:08:51.274108 29777 solver.cpp:290] Iteration 75200 (6.17305 iter/s, 16.1994s/100 iter), loss = 0.892857
I0630 06:08:51.274471 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 06:08:51.274487 29777 sgd_solver.cpp:106] Iteration 75200, lr = 0.00765
I0630 06:09:07.400424 29777 solver.cpp:290] Iteration 75300 (6.20136 iter/s, 16.1255s/100 iter), loss = 1.04762
I0630 06:09:07.400524 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:09:07.400560 29777 sgd_solver.cpp:106] Iteration 75300, lr = 0.00764687
I0630 06:09:23.726533 29777 solver.cpp:290] Iteration 75400 (6.12536 iter/s, 16.3256s/100 iter), loss = 0.940476
I0630 06:09:23.726585 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:09:23.726593 29777 sgd_solver.cpp:106] Iteration 75400, lr = 0.00764375
I0630 06:09:39.967880 29777 solver.cpp:290] Iteration 75500 (6.15731 iter/s, 16.2408s/100 iter), loss = 0.904762
I0630 06:09:39.967905 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:09:39.967911 29777 sgd_solver.cpp:106] Iteration 75500, lr = 0.00764062
I0630 06:09:56.004814 29777 solver.cpp:290] Iteration 75600 (6.23579 iter/s, 16.0365s/100 iter), loss = 1.11905
I0630 06:09:56.004918 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 06:09:56.004928 29777 sgd_solver.cpp:106] Iteration 75600, lr = 0.0076375
I0630 06:10:12.032929 29777 solver.cpp:290] Iteration 75700 (6.23925 iter/s, 16.0276s/100 iter), loss = 1.40476
I0630 06:10:12.032953 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 06:10:12.032959 29777 sgd_solver.cpp:106] Iteration 75700, lr = 0.00763437
I0630 06:10:28.131887 29777 solver.cpp:290] Iteration 75800 (6.21176 iter/s, 16.0985s/100 iter), loss = 0.75
I0630 06:10:28.131989 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 06:10:28.131996 29777 sgd_solver.cpp:106] Iteration 75800, lr = 0.00763125
I0630 06:10:44.160990 29777 solver.cpp:290] Iteration 75900 (6.23886 iter/s, 16.0286s/100 iter), loss = 0.964286
I0630 06:10:44.161016 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 06:10:44.161026 29777 sgd_solver.cpp:106] Iteration 75900, lr = 0.00762812
I0630 06:11:00.111584 29777 solver.cpp:354] Sparsity after update:
I0630 06:11:00.113143 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:11:00.113152 29777 net.cpp:1851] conv1a_param_0(0.19) 
I0630 06:11:00.113160 29777 net.cpp:1851] conv1b_param_0(0.38) 
I0630 06:11:00.113163 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:11:00.113165 29777 net.cpp:1851] res2a_branch2a_param_0(0.38) 
I0630 06:11:00.113168 29777 net.cpp:1851] res2a_branch2b_param_0(0.38) 
I0630 06:11:00.113170 29777 net.cpp:1851] res3a_branch2a_param_0(0.38) 
I0630 06:11:00.113173 29777 net.cpp:1851] res3a_branch2b_param_0(0.38) 
I0630 06:11:00.113174 29777 net.cpp:1851] res4a_branch2a_param_0(0.38) 
I0630 06:11:00.113178 29777 net.cpp:1851] res4a_branch2b_param_0(0.38) 
I0630 06:11:00.113179 29777 net.cpp:1851] res5a_branch2a_param_0(0.38) 
I0630 06:11:00.113181 29777 net.cpp:1851] res5a_branch2b_param_0(0.38) 
I0630 06:11:00.113184 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (894351/2.86678e+06) 0.312
I0630 06:11:00.113271 29777 solver.cpp:471] Iteration 76000, Testing net (#0)
I0630 06:11:06.824879 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:11:48.616935 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56896
I0630 06:11:48.617012 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.803841
I0630 06:11:48.617019 29777 solver.cpp:544]     Test net output #2: loss = 1.5288 (* 1 = 1.5288 loss)
I0630 06:11:48.800097 29777 solver.cpp:290] Iteration 76000 (1.54709 iter/s, 64.6373s/100 iter), loss = 1.04762
I0630 06:11:48.800120 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:11:48.800127 29777 sgd_solver.cpp:106] Iteration 76000, lr = 0.007625
I0630 06:11:48.800801 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.39
I0630 06:11:49.065292 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:12:05.050587 29777 solver.cpp:290] Iteration 76100 (6.15384 iter/s, 16.25s/100 iter), loss = 0.964286
I0630 06:12:05.050621 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 06:12:05.050632 29777 sgd_solver.cpp:106] Iteration 76100, lr = 0.00762187
I0630 06:12:21.168040 29777 solver.cpp:290] Iteration 76200 (6.20464 iter/s, 16.117s/100 iter), loss = 1.32143
I0630 06:12:21.168148 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 06:12:21.168157 29777 sgd_solver.cpp:106] Iteration 76200, lr = 0.00761875
I0630 06:12:37.168347 29777 solver.cpp:290] Iteration 76300 (6.25009 iter/s, 15.9998s/100 iter), loss = 1.16667
I0630 06:12:37.168370 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 06:12:37.168376 29777 sgd_solver.cpp:106] Iteration 76300, lr = 0.00761562
I0630 06:12:53.189332 29777 solver.cpp:290] Iteration 76400 (6.242 iter/s, 16.0205s/100 iter), loss = 1.4881
I0630 06:12:53.189700 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 06:12:53.189713 29777 sgd_solver.cpp:106] Iteration 76400, lr = 0.0076125
I0630 06:13:09.146690 29777 solver.cpp:290] Iteration 76500 (6.26702 iter/s, 15.9565s/100 iter), loss = 1.04762
I0630 06:13:09.146715 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 06:13:09.146724 29777 sgd_solver.cpp:106] Iteration 76500, lr = 0.00760937
I0630 06:13:25.312368 29777 solver.cpp:290] Iteration 76600 (6.18613 iter/s, 16.1652s/100 iter), loss = 1
I0630 06:13:25.312476 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 06:13:25.312486 29777 sgd_solver.cpp:106] Iteration 76600, lr = 0.00760625
I0630 06:13:41.515457 29777 solver.cpp:290] Iteration 76700 (6.17187 iter/s, 16.2025s/100 iter), loss = 1.42857
I0630 06:13:41.515482 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 06:13:41.515491 29777 sgd_solver.cpp:106] Iteration 76700, lr = 0.00760312
I0630 06:13:57.922080 29777 solver.cpp:290] Iteration 76800 (6.09528 iter/s, 16.4061s/100 iter), loss = 0.714286
I0630 06:13:57.922186 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 06:13:57.922197 29777 sgd_solver.cpp:106] Iteration 76800, lr = 0.0076
I0630 06:14:14.119640 29777 solver.cpp:290] Iteration 76900 (6.17398 iter/s, 16.197s/100 iter), loss = 1
I0630 06:14:14.119663 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:14:14.119671 29777 sgd_solver.cpp:106] Iteration 76900, lr = 0.00759687
I0630 06:14:30.045660 29777 solver.cpp:354] Sparsity after update:
I0630 06:14:30.068601 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:14:30.068619 29777 net.cpp:1851] conv1a_param_0(0.195) 
I0630 06:14:30.068630 29777 net.cpp:1851] conv1b_param_0(0.39) 
I0630 06:14:30.068634 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:14:30.068637 29777 net.cpp:1851] res2a_branch2a_param_0(0.39) 
I0630 06:14:30.068644 29777 net.cpp:1851] res2a_branch2b_param_0(0.39) 
I0630 06:14:30.068646 29777 net.cpp:1851] res3a_branch2a_param_0(0.39) 
I0630 06:14:30.068650 29777 net.cpp:1851] res3a_branch2b_param_0(0.39) 
I0630 06:14:30.068652 29777 net.cpp:1851] res4a_branch2a_param_0(0.39) 
I0630 06:14:30.068656 29777 net.cpp:1851] res4a_branch2b_param_0(0.39) 
I0630 06:14:30.068660 29777 net.cpp:1851] res5a_branch2a_param_0(0.39) 
I0630 06:14:30.068661 29777 net.cpp:1851] res5a_branch2b_param_0(0.39) 
I0630 06:14:30.068665 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (917890/2.86678e+06) 0.32
I0630 06:14:30.226913 29777 solver.cpp:290] Iteration 77000 (6.20856 iter/s, 16.1068s/100 iter), loss = 1.15476
I0630 06:14:30.226936 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 06:14:30.226943 29777 sgd_solver.cpp:106] Iteration 77000, lr = 0.00759375
I0630 06:14:46.314347 29777 solver.cpp:290] Iteration 77100 (6.21621 iter/s, 16.087s/100 iter), loss = 0.714286
I0630 06:14:46.314371 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 06:14:46.314378 29777 sgd_solver.cpp:106] Iteration 77100, lr = 0.00759062
I0630 06:15:02.671041 29777 solver.cpp:290] Iteration 77200 (6.11388 iter/s, 16.3562s/100 iter), loss = 1.38095
I0630 06:15:02.671154 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:15:02.671161 29777 sgd_solver.cpp:106] Iteration 77200, lr = 0.0075875
I0630 06:15:18.816169 29777 solver.cpp:290] Iteration 77300 (6.19403 iter/s, 16.1446s/100 iter), loss = 0.678571
I0630 06:15:18.816195 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:15:18.816202 29777 sgd_solver.cpp:106] Iteration 77300, lr = 0.00758437
I0630 06:15:35.072160 29777 solver.cpp:290] Iteration 77400 (6.15176 iter/s, 16.2555s/100 iter), loss = 0.833333
I0630 06:15:35.072253 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 06:15:35.072265 29777 sgd_solver.cpp:106] Iteration 77400, lr = 0.00758125
I0630 06:15:51.123841 29777 solver.cpp:290] Iteration 77500 (6.23009 iter/s, 16.0511s/100 iter), loss = 0.97619
I0630 06:15:51.123868 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 06:15:51.123878 29777 sgd_solver.cpp:106] Iteration 77500, lr = 0.00757812
I0630 06:16:07.376058 29777 solver.cpp:290] Iteration 77600 (6.15319 iter/s, 16.2517s/100 iter), loss = 0.821429
I0630 06:16:07.376163 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 06:16:07.376173 29777 sgd_solver.cpp:106] Iteration 77600, lr = 0.007575
I0630 06:16:23.504421 29777 solver.cpp:290] Iteration 77700 (6.20047 iter/s, 16.1278s/100 iter), loss = 0.940476
I0630 06:16:23.504446 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 06:16:23.504452 29777 sgd_solver.cpp:106] Iteration 77700, lr = 0.00757187
I0630 06:16:39.788432 29777 solver.cpp:290] Iteration 77800 (6.14117 iter/s, 16.2835s/100 iter), loss = 1.0119
I0630 06:16:39.788539 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 06:16:39.788564 29777 sgd_solver.cpp:106] Iteration 77800, lr = 0.00756875
I0630 06:16:55.932598 29777 solver.cpp:290] Iteration 77900 (6.1944 iter/s, 16.1436s/100 iter), loss = 1.17857
I0630 06:16:55.932621 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:16:55.932627 29777 sgd_solver.cpp:106] Iteration 77900, lr = 0.00756562
I0630 06:17:11.893530 29777 solver.cpp:354] Sparsity after update:
I0630 06:17:11.895141 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:17:11.895149 29777 net.cpp:1851] conv1a_param_0(0.195) 
I0630 06:17:11.895156 29777 net.cpp:1851] conv1b_param_0(0.39) 
I0630 06:17:11.895159 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:17:11.895161 29777 net.cpp:1851] res2a_branch2a_param_0(0.39) 
I0630 06:17:11.895164 29777 net.cpp:1851] res2a_branch2b_param_0(0.39) 
I0630 06:17:11.895165 29777 net.cpp:1851] res3a_branch2a_param_0(0.39) 
I0630 06:17:11.895167 29777 net.cpp:1851] res3a_branch2b_param_0(0.39) 
I0630 06:17:11.895169 29777 net.cpp:1851] res4a_branch2a_param_0(0.39) 
I0630 06:17:11.895171 29777 net.cpp:1851] res4a_branch2b_param_0(0.39) 
I0630 06:17:11.895174 29777 net.cpp:1851] res5a_branch2a_param_0(0.39) 
I0630 06:17:11.895175 29777 net.cpp:1851] res5a_branch2b_param_0(0.39) 
I0630 06:17:11.895177 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (917890/2.86678e+06) 0.32
I0630 06:17:11.895263 29777 solver.cpp:471] Iteration 78000, Testing net (#0)
I0630 06:17:19.875638 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:18:10.950081 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57452
I0630 06:18:10.950206 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.807881
I0630 06:18:10.950215 29777 solver.cpp:544]     Test net output #2: loss = 1.49564 (* 1 = 1.49564 loss)
I0630 06:18:11.127274 29777 solver.cpp:290] Iteration 78000 (1.32992 iter/s, 75.1926s/100 iter), loss = 1.42857
I0630 06:18:11.127297 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:18:11.127303 29777 sgd_solver.cpp:106] Iteration 78000, lr = 0.0075625
I0630 06:18:11.128005 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.4
I0630 06:18:11.396749 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:18:27.496374 29777 solver.cpp:290] Iteration 78100 (6.10925 iter/s, 16.3686s/100 iter), loss = 1.11905
I0630 06:18:27.496400 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:18:27.496409 29777 sgd_solver.cpp:106] Iteration 78100, lr = 0.00755937
I0630 06:18:43.597479 29777 solver.cpp:290] Iteration 78200 (6.21094 iter/s, 16.1006s/100 iter), loss = 1.16667
I0630 06:18:43.597658 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 06:18:43.597669 29777 sgd_solver.cpp:106] Iteration 78200, lr = 0.00755625
I0630 06:18:59.742182 29777 solver.cpp:290] Iteration 78300 (6.19422 iter/s, 16.1441s/100 iter), loss = 0.928571
I0630 06:18:59.742208 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:18:59.742216 29777 sgd_solver.cpp:106] Iteration 78300, lr = 0.00755312
I0630 06:19:15.850533 29777 solver.cpp:290] Iteration 78400 (6.20814 iter/s, 16.1079s/100 iter), loss = 1
I0630 06:19:15.850646 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 06:19:15.850654 29777 sgd_solver.cpp:106] Iteration 78400, lr = 0.00755
I0630 06:19:31.915833 29777 solver.cpp:290] Iteration 78500 (6.22481 iter/s, 16.0647s/100 iter), loss = 0.904762
I0630 06:19:31.915856 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 06:19:31.915863 29777 sgd_solver.cpp:106] Iteration 78500, lr = 0.00754687
I0630 06:19:48.128402 29777 solver.cpp:290] Iteration 78600 (6.16823 iter/s, 16.2121s/100 iter), loss = 1.0119
I0630 06:19:48.128473 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:19:48.128480 29777 sgd_solver.cpp:106] Iteration 78600, lr = 0.00754375
I0630 06:20:04.300549 29777 solver.cpp:290] Iteration 78700 (6.18367 iter/s, 16.1716s/100 iter), loss = 0.952381
I0630 06:20:04.300572 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:20:04.300580 29777 sgd_solver.cpp:106] Iteration 78700, lr = 0.00754063
I0630 06:20:20.447013 29777 solver.cpp:290] Iteration 78800 (6.19349 iter/s, 16.146s/100 iter), loss = 1.10714
I0630 06:20:20.447082 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:20:20.447090 29777 sgd_solver.cpp:106] Iteration 78800, lr = 0.0075375
I0630 06:20:36.771998 29777 solver.cpp:290] Iteration 78900 (6.12577 iter/s, 16.3245s/100 iter), loss = 1.08333
I0630 06:20:36.772022 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 06:20:36.772029 29777 sgd_solver.cpp:106] Iteration 78900, lr = 0.00753437
I0630 06:20:52.792124 29777 solver.cpp:354] Sparsity after update:
I0630 06:20:52.812558 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:20:52.812572 29777 net.cpp:1851] conv1a_param_0(0.2) 
I0630 06:20:52.812582 29777 net.cpp:1851] conv1b_param_0(0.4) 
I0630 06:20:52.812585 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:20:52.812589 29777 net.cpp:1851] res2a_branch2a_param_0(0.4) 
I0630 06:20:52.812592 29777 net.cpp:1851] res2a_branch2b_param_0(0.4) 
I0630 06:20:52.812595 29777 net.cpp:1851] res3a_branch2a_param_0(0.4) 
I0630 06:20:52.812599 29777 net.cpp:1851] res3a_branch2b_param_0(0.4) 
I0630 06:20:52.812602 29777 net.cpp:1851] res4a_branch2a_param_0(0.4) 
I0630 06:20:52.812605 29777 net.cpp:1851] res4a_branch2b_param_0(0.4) 
I0630 06:20:52.812608 29777 net.cpp:1851] res5a_branch2a_param_0(0.4) 
I0630 06:20:52.812611 29777 net.cpp:1851] res5a_branch2b_param_0(0.4) 
I0630 06:20:52.812616 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (941426/2.86678e+06) 0.328
I0630 06:20:52.985693 29777 solver.cpp:290] Iteration 79000 (6.1678 iter/s, 16.2132s/100 iter), loss = 1.20238
I0630 06:20:52.985716 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 06:20:52.985724 29777 sgd_solver.cpp:106] Iteration 79000, lr = 0.00753125
I0630 06:21:09.210898 29777 solver.cpp:290] Iteration 79100 (6.16343 iter/s, 16.2247s/100 iter), loss = 1.44048
I0630 06:21:09.210947 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 06:21:09.210961 29777 sgd_solver.cpp:106] Iteration 79100, lr = 0.00752812
I0630 06:21:25.741720 29777 solver.cpp:290] Iteration 79200 (6.04949 iter/s, 16.5303s/100 iter), loss = 1.2381
I0630 06:21:25.741827 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:21:25.741837 29777 sgd_solver.cpp:106] Iteration 79200, lr = 0.007525
I0630 06:21:41.811091 29777 solver.cpp:290] Iteration 79300 (6.22323 iter/s, 16.0688s/100 iter), loss = 1.2619
I0630 06:21:41.811113 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:21:41.811120 29777 sgd_solver.cpp:106] Iteration 79300, lr = 0.00752187
I0630 06:21:58.590492 29777 solver.cpp:290] Iteration 79400 (5.95986 iter/s, 16.7789s/100 iter), loss = 1.22619
I0630 06:21:58.590593 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 06:21:58.590601 29777 sgd_solver.cpp:106] Iteration 79400, lr = 0.00751875
I0630 06:22:14.884452 29777 solver.cpp:290] Iteration 79500 (6.13745 iter/s, 16.2934s/100 iter), loss = 1.22619
I0630 06:22:14.884477 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:22:14.884485 29777 sgd_solver.cpp:106] Iteration 79500, lr = 0.00751562
I0630 06:22:31.618468 29777 solver.cpp:290] Iteration 79600 (5.97602 iter/s, 16.7335s/100 iter), loss = 0.964286
I0630 06:22:31.618572 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 06:22:31.618582 29777 sgd_solver.cpp:106] Iteration 79600, lr = 0.0075125
I0630 06:22:47.912135 29777 solver.cpp:290] Iteration 79700 (6.13756 iter/s, 16.2931s/100 iter), loss = 1.17857
I0630 06:22:47.912163 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 06:22:47.912173 29777 sgd_solver.cpp:106] Iteration 79700, lr = 0.00750937
I0630 06:23:04.103423 29777 solver.cpp:290] Iteration 79800 (6.17634 iter/s, 16.1908s/100 iter), loss = 1.07143
I0630 06:23:04.103513 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:23:04.103524 29777 sgd_solver.cpp:106] Iteration 79800, lr = 0.00750625
I0630 06:23:20.379906 29777 solver.cpp:290] Iteration 79900 (6.14404 iter/s, 16.2759s/100 iter), loss = 1.14286
I0630 06:23:20.379981 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:23:20.380004 29777 sgd_solver.cpp:106] Iteration 79900, lr = 0.00750312
I0630 06:23:36.685129 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_80000.caffemodel
I0630 06:23:36.708729 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_80000.solverstate
I0630 06:23:36.717552 29777 solver.cpp:354] Sparsity after update:
I0630 06:23:36.718611 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:23:36.718621 29777 net.cpp:1851] conv1a_param_0(0.2) 
I0630 06:23:36.718629 29777 net.cpp:1851] conv1b_param_0(0.4) 
I0630 06:23:36.718632 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:23:36.718636 29777 net.cpp:1851] res2a_branch2a_param_0(0.4) 
I0630 06:23:36.718639 29777 net.cpp:1851] res2a_branch2b_param_0(0.4) 
I0630 06:23:36.718641 29777 net.cpp:1851] res3a_branch2a_param_0(0.4) 
I0630 06:23:36.718644 29777 net.cpp:1851] res3a_branch2b_param_0(0.4) 
I0630 06:23:36.718647 29777 net.cpp:1851] res4a_branch2a_param_0(0.4) 
I0630 06:23:36.718648 29777 net.cpp:1851] res4a_branch2b_param_0(0.4) 
I0630 06:23:36.718650 29777 net.cpp:1851] res5a_branch2a_param_0(0.4) 
I0630 06:23:36.718653 29777 net.cpp:1851] res5a_branch2b_param_0(0.4) 
I0630 06:23:36.718655 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (941426/2.86678e+06) 0.328
I0630 06:23:36.718757 29777 solver.cpp:471] Iteration 80000, Testing net (#0)
I0630 06:23:45.855628 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:24:43.202711 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57586
I0630 06:24:43.202793 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.807101
I0630 06:24:43.202802 29777 solver.cpp:544]     Test net output #2: loss = 1.51202 (* 1 = 1.51202 loss)
I0630 06:24:43.397799 29777 solver.cpp:290] Iteration 80000 (1.20459 iter/s, 83.0156s/100 iter), loss = 0.797619
I0630 06:24:43.397857 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:24:43.397876 29777 sgd_solver.cpp:106] Iteration 80000, lr = 0.0075
I0630 06:24:43.399686 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.41
I0630 06:24:43.819041 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:25:00.232731 29777 solver.cpp:290] Iteration 80100 (5.94021 iter/s, 16.8344s/100 iter), loss = 1.39286
I0630 06:25:00.232756 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 06:25:00.232775 29777 sgd_solver.cpp:106] Iteration 80100, lr = 0.00749687
I0630 06:25:16.261931 29777 solver.cpp:290] Iteration 80200 (6.2388 iter/s, 16.0287s/100 iter), loss = 1.0119
I0630 06:25:16.262024 29777 solver.cpp:309]     Train net output #0: loss = 0.595238 (* 1 = 0.595238 loss)
I0630 06:25:16.262037 29777 sgd_solver.cpp:106] Iteration 80200, lr = 0.00749375
I0630 06:25:32.787369 29777 solver.cpp:290] Iteration 80300 (6.05148 iter/s, 16.5249s/100 iter), loss = 1
I0630 06:25:32.787394 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:25:32.787400 29777 sgd_solver.cpp:106] Iteration 80300, lr = 0.00749063
I0630 06:25:49.190680 29777 solver.cpp:290] Iteration 80400 (6.09651 iter/s, 16.4028s/100 iter), loss = 1.13095
I0630 06:25:49.190768 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:25:49.190775 29777 sgd_solver.cpp:106] Iteration 80400, lr = 0.0074875
I0630 06:26:05.451460 29777 solver.cpp:290] Iteration 80500 (6.14997 iter/s, 16.2602s/100 iter), loss = 0.892857
I0630 06:26:05.451490 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:26:05.451500 29777 sgd_solver.cpp:106] Iteration 80500, lr = 0.00748438
I0630 06:26:21.618427 29777 solver.cpp:290] Iteration 80600 (6.18563 iter/s, 16.1665s/100 iter), loss = 0.916667
I0630 06:26:21.618535 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:26:21.618546 29777 sgd_solver.cpp:106] Iteration 80600, lr = 0.00748125
I0630 06:26:37.840133 29777 solver.cpp:290] Iteration 80700 (6.16479 iter/s, 16.2212s/100 iter), loss = 0.988095
I0630 06:26:37.840159 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 06:26:37.840167 29777 sgd_solver.cpp:106] Iteration 80700, lr = 0.00747812
I0630 06:26:53.967936 29777 solver.cpp:290] Iteration 80800 (6.20065 iter/s, 16.1273s/100 iter), loss = 1.2619
I0630 06:26:53.968053 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 06:26:53.968065 29777 sgd_solver.cpp:106] Iteration 80800, lr = 0.007475
I0630 06:27:10.269810 29777 solver.cpp:290] Iteration 80900 (6.13448 iter/s, 16.3013s/100 iter), loss = 1.13095
I0630 06:27:10.269834 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:27:10.269840 29777 sgd_solver.cpp:106] Iteration 80900, lr = 0.00747187
I0630 06:27:26.262645 29777 solver.cpp:354] Sparsity after update:
I0630 06:27:26.282907 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:27:26.282946 29777 net.cpp:1851] conv1a_param_0(0.205) 
I0630 06:27:26.282966 29777 net.cpp:1851] conv1b_param_0(0.41) 
I0630 06:27:26.282977 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:27:26.282984 29777 net.cpp:1851] res2a_branch2a_param_0(0.41) 
I0630 06:27:26.282986 29777 net.cpp:1851] res2a_branch2b_param_0(0.41) 
I0630 06:27:26.282990 29777 net.cpp:1851] res3a_branch2a_param_0(0.41) 
I0630 06:27:26.282994 29777 net.cpp:1851] res3a_branch2b_param_0(0.41) 
I0630 06:27:26.283004 29777 net.cpp:1851] res4a_branch2a_param_0(0.41) 
I0630 06:27:26.283008 29777 net.cpp:1851] res4a_branch2b_param_0(0.41) 
I0630 06:27:26.283012 29777 net.cpp:1851] res5a_branch2a_param_0(0.41) 
I0630 06:27:26.283015 29777 net.cpp:1851] res5a_branch2b_param_0(0.41) 
I0630 06:27:26.283020 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (964961/2.86678e+06) 0.337
I0630 06:27:26.439648 29777 solver.cpp:290] Iteration 81000 (6.18453 iter/s, 16.1694s/100 iter), loss = 1.15476
I0630 06:27:26.439674 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 06:27:26.439683 29777 sgd_solver.cpp:106] Iteration 81000, lr = 0.00746875
I0630 06:27:42.710240 29777 solver.cpp:290] Iteration 81100 (6.14624 iter/s, 16.2701s/100 iter), loss = 1.10714
I0630 06:27:42.710333 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:27:42.710369 29777 sgd_solver.cpp:106] Iteration 81100, lr = 0.00746562
I0630 06:27:58.980336 29777 solver.cpp:290] Iteration 81200 (6.14645 iter/s, 16.2696s/100 iter), loss = 0.976191
I0630 06:27:58.980449 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:27:58.980459 29777 sgd_solver.cpp:106] Iteration 81200, lr = 0.0074625
I0630 06:28:15.337571 29777 solver.cpp:290] Iteration 81300 (6.11371 iter/s, 16.3567s/100 iter), loss = 1.04762
I0630 06:28:15.337597 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 06:28:15.337607 29777 sgd_solver.cpp:106] Iteration 81300, lr = 0.00745937
I0630 06:28:31.798763 29777 solver.cpp:290] Iteration 81400 (6.07507 iter/s, 16.4607s/100 iter), loss = 0.892857
I0630 06:28:31.798815 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:28:31.798822 29777 sgd_solver.cpp:106] Iteration 81400, lr = 0.00745625
I0630 06:28:48.212049 29777 solver.cpp:290] Iteration 81500 (6.09282 iter/s, 16.4128s/100 iter), loss = 1.08333
I0630 06:28:48.212138 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:28:48.212163 29777 sgd_solver.cpp:106] Iteration 81500, lr = 0.00745312
I0630 06:29:04.433792 29777 solver.cpp:290] Iteration 81600 (6.16477 iter/s, 16.2212s/100 iter), loss = 1.32143
I0630 06:29:04.433861 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:29:04.433868 29777 sgd_solver.cpp:106] Iteration 81600, lr = 0.00745
I0630 06:29:20.687135 29777 solver.cpp:290] Iteration 81700 (6.15278 iter/s, 16.2528s/100 iter), loss = 1.14286
I0630 06:29:20.687181 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:29:20.687203 29777 sgd_solver.cpp:106] Iteration 81700, lr = 0.00744687
I0630 06:29:36.924715 29777 solver.cpp:290] Iteration 81800 (6.15874 iter/s, 16.2371s/100 iter), loss = 0.761905
I0630 06:29:36.924878 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 06:29:36.924904 29777 sgd_solver.cpp:106] Iteration 81800, lr = 0.00744375
I0630 06:29:52.940383 29777 solver.cpp:290] Iteration 81900 (6.24412 iter/s, 16.0151s/100 iter), loss = 0.845238
I0630 06:29:52.940407 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:29:52.940414 29777 sgd_solver.cpp:106] Iteration 81900, lr = 0.00744063
I0630 06:30:09.122658 29777 solver.cpp:354] Sparsity after update:
I0630 06:30:09.124270 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:30:09.124279 29777 net.cpp:1851] conv1a_param_0(0.205) 
I0630 06:30:09.124285 29777 net.cpp:1851] conv1b_param_0(0.41) 
I0630 06:30:09.124289 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:30:09.124290 29777 net.cpp:1851] res2a_branch2a_param_0(0.41) 
I0630 06:30:09.124292 29777 net.cpp:1851] res2a_branch2b_param_0(0.41) 
I0630 06:30:09.124294 29777 net.cpp:1851] res3a_branch2a_param_0(0.41) 
I0630 06:30:09.124296 29777 net.cpp:1851] res3a_branch2b_param_0(0.41) 
I0630 06:30:09.124299 29777 net.cpp:1851] res4a_branch2a_param_0(0.41) 
I0630 06:30:09.124300 29777 net.cpp:1851] res4a_branch2b_param_0(0.41) 
I0630 06:30:09.124302 29777 net.cpp:1851] res5a_branch2a_param_0(0.41) 
I0630 06:30:09.124303 29777 net.cpp:1851] res5a_branch2b_param_0(0.41) 
I0630 06:30:09.124306 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (964961/2.86678e+06) 0.337
I0630 06:30:09.124392 29777 solver.cpp:471] Iteration 82000, Testing net (#0)
I0630 06:30:18.320488 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:31:11.702306 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.577419
I0630 06:31:11.702396 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.807662
I0630 06:31:11.702405 29777 solver.cpp:544]     Test net output #2: loss = 1.51882 (* 1 = 1.51882 loss)
I0630 06:31:11.939276 29777 solver.cpp:290] Iteration 82000 (1.26588 iter/s, 78.9967s/100 iter), loss = 0.833333
I0630 06:31:11.939321 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:31:11.939338 29777 sgd_solver.cpp:106] Iteration 82000, lr = 0.0074375
I0630 06:31:11.941112 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.42
I0630 06:31:12.359869 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:31:28.484802 29777 solver.cpp:290] Iteration 82100 (6.04411 iter/s, 16.545s/100 iter), loss = 0.857143
I0630 06:31:28.484830 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 06:31:28.484844 29777 sgd_solver.cpp:106] Iteration 82100, lr = 0.00743438
I0630 06:31:44.604691 29777 solver.cpp:290] Iteration 82200 (6.2037 iter/s, 16.1194s/100 iter), loss = 1.10714
I0630 06:31:44.604794 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:31:44.604804 29777 sgd_solver.cpp:106] Iteration 82200, lr = 0.00743125
I0630 06:32:00.788182 29777 solver.cpp:290] Iteration 82300 (6.17935 iter/s, 16.1829s/100 iter), loss = 1.38095
I0630 06:32:00.788205 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 06:32:00.788213 29777 sgd_solver.cpp:106] Iteration 82300, lr = 0.00742813
I0630 06:32:16.913143 29777 solver.cpp:290] Iteration 82400 (6.20175 iter/s, 16.1245s/100 iter), loss = 0.869048
I0630 06:32:16.913239 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:32:16.913249 29777 sgd_solver.cpp:106] Iteration 82400, lr = 0.007425
I0630 06:32:33.055394 29777 solver.cpp:290] Iteration 82500 (6.19513 iter/s, 16.1417s/100 iter), loss = 1.11905
I0630 06:32:33.055419 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:32:33.055429 29777 sgd_solver.cpp:106] Iteration 82500, lr = 0.00742187
I0630 06:32:49.310662 29777 solver.cpp:290] Iteration 82600 (6.15203 iter/s, 16.2548s/100 iter), loss = 1.04762
I0630 06:32:49.310768 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:32:49.310788 29777 sgd_solver.cpp:106] Iteration 82600, lr = 0.00741875
I0630 06:33:05.413328 29777 solver.cpp:290] Iteration 82700 (6.21036 iter/s, 16.1021s/100 iter), loss = 1.19048
I0630 06:33:05.413352 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 06:33:05.413359 29777 sgd_solver.cpp:106] Iteration 82700, lr = 0.00741562
I0630 06:33:21.642601 29777 solver.cpp:290] Iteration 82800 (6.16188 iter/s, 16.2288s/100 iter), loss = 1.0119
I0630 06:33:21.642696 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:33:21.642707 29777 sgd_solver.cpp:106] Iteration 82800, lr = 0.0074125
I0630 06:33:37.767966 29777 solver.cpp:290] Iteration 82900 (6.20162 iter/s, 16.1248s/100 iter), loss = 0.97619
I0630 06:33:37.767988 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:33:37.767994 29777 sgd_solver.cpp:106] Iteration 82900, lr = 0.00740937
I0630 06:33:53.642482 29777 solver.cpp:354] Sparsity after update:
I0630 06:33:53.662889 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:33:53.662907 29777 net.cpp:1851] conv1a_param_0(0.21) 
I0630 06:33:53.662916 29777 net.cpp:1851] conv1b_param_0(0.42) 
I0630 06:33:53.662919 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:33:53.662924 29777 net.cpp:1851] res2a_branch2a_param_0(0.42) 
I0630 06:33:53.662930 29777 net.cpp:1851] res2a_branch2b_param_0(0.42) 
I0630 06:33:53.662932 29777 net.cpp:1851] res3a_branch2a_param_0(0.42) 
I0630 06:33:53.662935 29777 net.cpp:1851] res3a_branch2b_param_0(0.42) 
I0630 06:33:53.662940 29777 net.cpp:1851] res4a_branch2a_param_0(0.42) 
I0630 06:33:53.662942 29777 net.cpp:1851] res4a_branch2b_param_0(0.42) 
I0630 06:33:53.662945 29777 net.cpp:1851] res5a_branch2a_param_0(0.42) 
I0630 06:33:53.662948 29777 net.cpp:1851] res5a_branch2b_param_0(0.42) 
I0630 06:33:53.662950 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (988493/2.86678e+06) 0.345
I0630 06:33:53.820355 29777 solver.cpp:290] Iteration 83000 (6.22978 iter/s, 16.0519s/100 iter), loss = 1.05952
I0630 06:33:53.820377 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:33:53.820384 29777 sgd_solver.cpp:106] Iteration 83000, lr = 0.00740625
I0630 06:34:09.952865 29777 solver.cpp:290] Iteration 83100 (6.19884 iter/s, 16.132s/100 iter), loss = 1.05952
I0630 06:34:09.952888 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:34:09.952895 29777 sgd_solver.cpp:106] Iteration 83100, lr = 0.00740312
I0630 06:34:26.148269 29777 solver.cpp:290] Iteration 83200 (6.17477 iter/s, 16.1949s/100 iter), loss = 1.2619
I0630 06:34:26.148325 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 06:34:26.148336 29777 sgd_solver.cpp:106] Iteration 83200, lr = 0.0074
I0630 06:34:42.265838 29777 solver.cpp:290] Iteration 83300 (6.2046 iter/s, 16.1171s/100 iter), loss = 0.702381
I0630 06:34:42.265924 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 06:34:42.265965 29777 sgd_solver.cpp:106] Iteration 83300, lr = 0.00739687
I0630 06:34:58.441809 29777 solver.cpp:290] Iteration 83400 (6.18221 iter/s, 16.1754s/100 iter), loss = 0.928571
I0630 06:34:58.441913 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 06:34:58.441923 29777 sgd_solver.cpp:106] Iteration 83400, lr = 0.00739375
I0630 06:35:14.569697 29777 solver.cpp:290] Iteration 83500 (6.20065 iter/s, 16.1273s/100 iter), loss = 0.72619
I0630 06:35:14.569721 29777 solver.cpp:309]     Train net output #0: loss = 0.595238 (* 1 = 0.595238 loss)
I0630 06:35:14.569727 29777 sgd_solver.cpp:106] Iteration 83500, lr = 0.00739062
I0630 06:35:30.684242 29777 solver.cpp:290] Iteration 83600 (6.20576 iter/s, 16.1141s/100 iter), loss = 1.09524
I0630 06:35:30.684356 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:35:30.684365 29777 sgd_solver.cpp:106] Iteration 83600, lr = 0.0073875
I0630 06:35:46.742591 29777 solver.cpp:290] Iteration 83700 (6.22751 iter/s, 16.0578s/100 iter), loss = 1.13095
I0630 06:35:46.742617 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:35:46.742626 29777 sgd_solver.cpp:106] Iteration 83700, lr = 0.00738438
I0630 06:36:02.858237 29777 solver.cpp:290] Iteration 83800 (6.20533 iter/s, 16.1152s/100 iter), loss = 0.952381
I0630 06:36:02.858330 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 06:36:02.858342 29777 sgd_solver.cpp:106] Iteration 83800, lr = 0.00738125
I0630 06:36:19.189333 29777 solver.cpp:290] Iteration 83900 (6.12349 iter/s, 16.3306s/100 iter), loss = 1.03571
I0630 06:36:19.189359 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 06:36:19.189368 29777 sgd_solver.cpp:106] Iteration 83900, lr = 0.00737813
I0630 06:36:35.244951 29777 solver.cpp:354] Sparsity after update:
I0630 06:36:35.246381 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:36:35.246388 29777 net.cpp:1851] conv1a_param_0(0.21) 
I0630 06:36:35.246397 29777 net.cpp:1851] conv1b_param_0(0.42) 
I0630 06:36:35.246399 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:36:35.246402 29777 net.cpp:1851] res2a_branch2a_param_0(0.42) 
I0630 06:36:35.246405 29777 net.cpp:1851] res2a_branch2b_param_0(0.42) 
I0630 06:36:35.246407 29777 net.cpp:1851] res3a_branch2a_param_0(0.42) 
I0630 06:36:35.246409 29777 net.cpp:1851] res3a_branch2b_param_0(0.42) 
I0630 06:36:35.246412 29777 net.cpp:1851] res4a_branch2a_param_0(0.42) 
I0630 06:36:35.246414 29777 net.cpp:1851] res4a_branch2b_param_0(0.42) 
I0630 06:36:35.246417 29777 net.cpp:1851] res5a_branch2a_param_0(0.42) 
I0630 06:36:35.246419 29777 net.cpp:1851] res5a_branch2b_param_0(0.42) 
I0630 06:36:35.246421 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (988493/2.86678e+06) 0.345
I0630 06:36:35.246508 29777 solver.cpp:471] Iteration 84000, Testing net (#0)
I0630 06:36:44.770190 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:37:46.528805 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.572639
I0630 06:37:46.528882 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806181
I0630 06:37:46.528897 29777 solver.cpp:544]     Test net output #2: loss = 1.52242 (* 1 = 1.52242 loss)
I0630 06:37:46.751307 29777 solver.cpp:290] Iteration 84000 (1.14208 iter/s, 87.5596s/100 iter), loss = 0.904762
I0630 06:37:46.751355 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 06:37:46.751389 29777 sgd_solver.cpp:106] Iteration 84000, lr = 0.007375
I0630 06:37:46.752627 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.43
I0630 06:37:47.289585 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:38:03.455045 29777 solver.cpp:290] Iteration 84100 (5.98686 iter/s, 16.7032s/100 iter), loss = 1.42857
I0630 06:38:03.455066 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 06:38:03.455073 29777 sgd_solver.cpp:106] Iteration 84100, lr = 0.00737187
I0630 06:38:19.781816 29777 solver.cpp:290] Iteration 84200 (6.12509 iter/s, 16.3263s/100 iter), loss = 0.833333
I0630 06:38:19.781929 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:38:19.781939 29777 sgd_solver.cpp:106] Iteration 84200, lr = 0.00736875
I0630 06:38:36.126260 29777 solver.cpp:290] Iteration 84300 (6.11851 iter/s, 16.3439s/100 iter), loss = 0.952381
I0630 06:38:36.126412 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:38:36.126479 29777 sgd_solver.cpp:106] Iteration 84300, lr = 0.00736562
I0630 06:38:52.744114 29777 solver.cpp:290] Iteration 84400 (6.01783 iter/s, 16.6173s/100 iter), loss = 0.857143
I0630 06:38:52.744197 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 06:38:52.744205 29777 sgd_solver.cpp:106] Iteration 84400, lr = 0.0073625
I0630 06:39:09.083123 29777 solver.cpp:290] Iteration 84500 (6.12052 iter/s, 16.3385s/100 iter), loss = 0.916667
I0630 06:39:09.083145 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:39:09.083153 29777 sgd_solver.cpp:106] Iteration 84500, lr = 0.00735937
I0630 06:39:25.290276 29777 solver.cpp:290] Iteration 84600 (6.1703 iter/s, 16.2067s/100 iter), loss = 1.04762
I0630 06:39:25.290459 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 06:39:25.290501 29777 sgd_solver.cpp:106] Iteration 84600, lr = 0.00735625
I0630 06:39:41.898582 29777 solver.cpp:290] Iteration 84700 (6.02131 iter/s, 16.6077s/100 iter), loss = 1.20238
I0630 06:39:41.898605 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:39:41.898612 29777 sgd_solver.cpp:106] Iteration 84700, lr = 0.00735312
I0630 06:39:58.346871 29777 solver.cpp:290] Iteration 84800 (6.07984 iter/s, 16.4478s/100 iter), loss = 0.857143
I0630 06:39:58.346966 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:39:58.346976 29777 sgd_solver.cpp:106] Iteration 84800, lr = 0.00735
I0630 06:40:14.547617 29777 solver.cpp:290] Iteration 84900 (6.17276 iter/s, 16.2002s/100 iter), loss = 0.821429
I0630 06:40:14.547642 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 06:40:14.547652 29777 sgd_solver.cpp:106] Iteration 84900, lr = 0.00734688
I0630 06:40:30.719399 29777 solver.cpp:354] Sparsity after update:
I0630 06:40:30.740253 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:40:30.740268 29777 net.cpp:1851] conv1a_param_0(0.215) 
I0630 06:40:30.740276 29777 net.cpp:1851] conv1b_param_0(0.43) 
I0630 06:40:30.740278 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:40:30.740280 29777 net.cpp:1851] res2a_branch2a_param_0(0.43) 
I0630 06:40:30.740283 29777 net.cpp:1851] res2a_branch2b_param_0(0.43) 
I0630 06:40:30.740285 29777 net.cpp:1851] res3a_branch2a_param_0(0.43) 
I0630 06:40:30.740294 29777 net.cpp:1851] res3a_branch2b_param_0(0.43) 
I0630 06:40:30.740296 29777 net.cpp:1851] res4a_branch2a_param_0(0.43) 
I0630 06:40:30.740298 29777 net.cpp:1851] res4a_branch2b_param_0(0.43) 
I0630 06:40:30.740300 29777 net.cpp:1851] res5a_branch2a_param_0(0.43) 
I0630 06:40:30.740303 29777 net.cpp:1851] res5a_branch2b_param_0(0.43) 
I0630 06:40:30.740304 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.01204e+06/2.86678e+06) 0.353
I0630 06:40:30.902043 29777 solver.cpp:290] Iteration 85000 (6.11473 iter/s, 16.354s/100 iter), loss = 1.2619
I0630 06:40:30.902072 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 06:40:30.902081 29777 sgd_solver.cpp:106] Iteration 85000, lr = 0.00734375
I0630 06:40:47.322499 29777 solver.cpp:290] Iteration 85100 (6.09015 iter/s, 16.42s/100 iter), loss = 0.940476
I0630 06:40:47.322546 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 06:40:47.322561 29777 sgd_solver.cpp:106] Iteration 85100, lr = 0.00734062
I0630 06:41:03.647415 29777 solver.cpp:290] Iteration 85200 (6.12579 iter/s, 16.3244s/100 iter), loss = 1.09524
I0630 06:41:03.647521 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 06:41:03.647529 29777 sgd_solver.cpp:106] Iteration 85200, lr = 0.0073375
I0630 06:41:20.045801 29777 solver.cpp:290] Iteration 85300 (6.09837 iter/s, 16.3978s/100 iter), loss = 1.46429
I0630 06:41:20.045825 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 06:41:20.045830 29777 sgd_solver.cpp:106] Iteration 85300, lr = 0.00733438
I0630 06:41:36.182952 29777 solver.cpp:290] Iteration 85400 (6.19706 iter/s, 16.1367s/100 iter), loss = 0.75
I0630 06:41:36.183069 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 06:41:36.183079 29777 sgd_solver.cpp:106] Iteration 85400, lr = 0.00733125
I0630 06:41:52.496016 29777 solver.cpp:290] Iteration 85500 (6.13027 iter/s, 16.3125s/100 iter), loss = 0.654762
I0630 06:41:52.496040 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 06:41:52.496047 29777 sgd_solver.cpp:106] Iteration 85500, lr = 0.00732813
I0630 06:42:08.739696 29777 solver.cpp:290] Iteration 85600 (6.15642 iter/s, 16.2432s/100 iter), loss = 1.05952
I0630 06:42:08.739811 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:42:08.739821 29777 sgd_solver.cpp:106] Iteration 85600, lr = 0.007325
I0630 06:42:25.089757 29777 solver.cpp:290] Iteration 85700 (6.1164 iter/s, 16.3495s/100 iter), loss = 1.09524
I0630 06:42:25.089781 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 06:42:25.089790 29777 sgd_solver.cpp:106] Iteration 85700, lr = 0.00732188
I0630 06:42:41.371026 29777 solver.cpp:290] Iteration 85800 (6.14221 iter/s, 16.2808s/100 iter), loss = 0.97619
I0630 06:42:41.371085 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:42:41.371093 29777 sgd_solver.cpp:106] Iteration 85800, lr = 0.00731875
I0630 06:42:57.687921 29777 solver.cpp:290] Iteration 85900 (6.12881 iter/s, 16.3164s/100 iter), loss = 1.11905
I0630 06:42:57.687968 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 06:42:57.687994 29777 sgd_solver.cpp:106] Iteration 85900, lr = 0.00731562
I0630 06:43:13.752717 29777 solver.cpp:354] Sparsity after update:
I0630 06:43:13.754958 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:43:13.754976 29777 net.cpp:1851] conv1a_param_0(0.215) 
I0630 06:43:13.755000 29777 net.cpp:1851] conv1b_param_0(0.43) 
I0630 06:43:13.755013 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:43:13.755023 29777 net.cpp:1851] res2a_branch2a_param_0(0.43) 
I0630 06:43:13.755036 29777 net.cpp:1851] res2a_branch2b_param_0(0.43) 
I0630 06:43:13.755048 29777 net.cpp:1851] res3a_branch2a_param_0(0.43) 
I0630 06:43:13.755058 29777 net.cpp:1851] res3a_branch2b_param_0(0.43) 
I0630 06:43:13.755066 29777 net.cpp:1851] res4a_branch2a_param_0(0.43) 
I0630 06:43:13.755076 29777 net.cpp:1851] res4a_branch2b_param_0(0.43) 
I0630 06:43:13.755080 29777 net.cpp:1851] res5a_branch2a_param_0(0.43) 
I0630 06:43:13.755090 29777 net.cpp:1851] res5a_branch2b_param_0(0.43) 
I0630 06:43:13.755100 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.01204e+06/2.86678e+06) 0.353
I0630 06:43:13.755388 29777 solver.cpp:471] Iteration 86000, Testing net (#0)
I0630 06:43:24.491957 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:44:21.584195 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57256
I0630 06:44:21.584285 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806822
I0630 06:44:21.584298 29777 solver.cpp:544]     Test net output #2: loss = 1.50944 (* 1 = 1.50944 loss)
I0630 06:44:21.771813 29777 solver.cpp:290] Iteration 86000 (1.18932 iter/s, 84.0816s/100 iter), loss = 0.940476
I0630 06:44:21.771867 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:44:21.771888 29777 sgd_solver.cpp:106] Iteration 86000, lr = 0.0073125
I0630 06:44:21.773881 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.44
I0630 06:44:22.237265 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:44:38.528652 29777 solver.cpp:290] Iteration 86100 (5.96789 iter/s, 16.7563s/100 iter), loss = 1.13095
I0630 06:44:38.528676 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 06:44:38.528686 29777 sgd_solver.cpp:106] Iteration 86100, lr = 0.00730937
I0630 06:44:54.913862 29777 solver.cpp:290] Iteration 86200 (6.10324 iter/s, 16.3847s/100 iter), loss = 1.33333
I0630 06:44:54.913946 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:44:54.913956 29777 sgd_solver.cpp:106] Iteration 86200, lr = 0.00730625
I0630 06:45:11.054575 29777 solver.cpp:290] Iteration 86300 (6.19572 iter/s, 16.1402s/100 iter), loss = 1.29762
I0630 06:45:11.054601 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 06:45:11.054610 29777 sgd_solver.cpp:106] Iteration 86300, lr = 0.00730312
I0630 06:45:27.311164 29777 solver.cpp:290] Iteration 86400 (6.15153 iter/s, 16.2561s/100 iter), loss = 1.22619
I0630 06:45:27.311247 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 06:45:27.311255 29777 sgd_solver.cpp:106] Iteration 86400, lr = 0.0073
I0630 06:45:44.277745 29777 solver.cpp:290] Iteration 86500 (5.89413 iter/s, 16.966s/100 iter), loss = 0.916667
I0630 06:45:44.277781 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 06:45:44.277792 29777 sgd_solver.cpp:106] Iteration 86500, lr = 0.00729688
I0630 06:46:00.556797 29777 solver.cpp:290] Iteration 86600 (6.14305 iter/s, 16.2786s/100 iter), loss = 0.916667
I0630 06:46:00.556888 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:46:00.556900 29777 sgd_solver.cpp:106] Iteration 86600, lr = 0.00729375
I0630 06:46:16.614493 29777 solver.cpp:290] Iteration 86700 (6.22775 iter/s, 16.0572s/100 iter), loss = 0.904762
I0630 06:46:16.614521 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 06:46:16.614529 29777 sgd_solver.cpp:106] Iteration 86700, lr = 0.00729063
I0630 06:46:32.887228 29777 solver.cpp:290] Iteration 86800 (6.14543 iter/s, 16.2723s/100 iter), loss = 1.11905
I0630 06:46:32.887325 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 06:46:32.887429 29777 sgd_solver.cpp:106] Iteration 86800, lr = 0.0072875
I0630 06:46:49.129099 29777 solver.cpp:290] Iteration 86900 (6.15713 iter/s, 16.2413s/100 iter), loss = 1.03571
I0630 06:46:49.129123 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:46:49.129130 29777 sgd_solver.cpp:106] Iteration 86900, lr = 0.00728438
I0630 06:47:05.173180 29777 solver.cpp:354] Sparsity after update:
I0630 06:47:05.193804 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:47:05.193819 29777 net.cpp:1851] conv1a_param_0(0.22) 
I0630 06:47:05.193827 29777 net.cpp:1851] conv1b_param_0(0.44) 
I0630 06:47:05.193830 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:47:05.193831 29777 net.cpp:1851] res2a_branch2a_param_0(0.44) 
I0630 06:47:05.193833 29777 net.cpp:1851] res2a_branch2b_param_0(0.44) 
I0630 06:47:05.193835 29777 net.cpp:1851] res3a_branch2a_param_0(0.44) 
I0630 06:47:05.193837 29777 net.cpp:1851] res3a_branch2b_param_0(0.44) 
I0630 06:47:05.193840 29777 net.cpp:1851] res4a_branch2a_param_0(0.44) 
I0630 06:47:05.193841 29777 net.cpp:1851] res4a_branch2b_param_0(0.44) 
I0630 06:47:05.193843 29777 net.cpp:1851] res5a_branch2a_param_0(0.44) 
I0630 06:47:05.193845 29777 net.cpp:1851] res5a_branch2b_param_0(0.44) 
I0630 06:47:05.193847 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.03557e+06/2.86678e+06) 0.361
I0630 06:47:05.351423 29777 solver.cpp:290] Iteration 87000 (6.16452 iter/s, 16.2219s/100 iter), loss = 1.02381
I0630 06:47:05.351449 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:47:05.351464 29777 sgd_solver.cpp:106] Iteration 87000, lr = 0.00728125
I0630 06:47:21.491919 29777 solver.cpp:290] Iteration 87100 (6.19578 iter/s, 16.14s/100 iter), loss = 0.809524
I0630 06:47:21.491945 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:47:21.491951 29777 sgd_solver.cpp:106] Iteration 87100, lr = 0.00727813
I0630 06:47:37.765035 29777 solver.cpp:290] Iteration 87200 (6.14529 iter/s, 16.2726s/100 iter), loss = 1.21429
I0630 06:47:37.765121 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 06:47:37.765141 29777 sgd_solver.cpp:106] Iteration 87200, lr = 0.007275
I0630 06:47:53.957363 29777 solver.cpp:290] Iteration 87300 (6.17597 iter/s, 16.1918s/100 iter), loss = 1.04762
I0630 06:47:53.957389 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 06:47:53.957398 29777 sgd_solver.cpp:106] Iteration 87300, lr = 0.00727188
I0630 06:48:10.105154 29777 solver.cpp:290] Iteration 87400 (6.19298 iter/s, 16.1473s/100 iter), loss = 1.19048
I0630 06:48:10.105265 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 06:48:10.105278 29777 sgd_solver.cpp:106] Iteration 87400, lr = 0.00726875
I0630 06:48:26.349705 29777 solver.cpp:290] Iteration 87500 (6.15612 iter/s, 16.244s/100 iter), loss = 1.05952
I0630 06:48:26.349730 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:48:26.349738 29777 sgd_solver.cpp:106] Iteration 87500, lr = 0.00726563
I0630 06:48:42.493671 29777 solver.cpp:290] Iteration 87600 (6.19444 iter/s, 16.1435s/100 iter), loss = 0.940476
I0630 06:48:42.493746 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 06:48:42.493754 29777 sgd_solver.cpp:106] Iteration 87600, lr = 0.0072625
I0630 06:48:58.754565 29777 solver.cpp:290] Iteration 87700 (6.14992 iter/s, 16.2604s/100 iter), loss = 1.42857
I0630 06:48:58.754596 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 06:48:58.754606 29777 sgd_solver.cpp:106] Iteration 87700, lr = 0.00725937
I0630 06:49:14.980186 29777 solver.cpp:290] Iteration 87800 (6.16328 iter/s, 16.2251s/100 iter), loss = 0.821429
I0630 06:49:14.980290 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:49:14.980316 29777 sgd_solver.cpp:106] Iteration 87800, lr = 0.00725625
I0630 06:49:31.195127 29777 solver.cpp:290] Iteration 87900 (6.16736 iter/s, 16.2144s/100 iter), loss = 1.36905
I0630 06:49:31.195152 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 06:49:31.195171 29777 sgd_solver.cpp:106] Iteration 87900, lr = 0.00725312
I0630 06:49:47.215178 29777 solver.cpp:354] Sparsity after update:
I0630 06:49:47.216609 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:49:47.216616 29777 net.cpp:1851] conv1a_param_0(0.22) 
I0630 06:49:47.216624 29777 net.cpp:1851] conv1b_param_0(0.44) 
I0630 06:49:47.216627 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:49:47.216629 29777 net.cpp:1851] res2a_branch2a_param_0(0.44) 
I0630 06:49:47.216631 29777 net.cpp:1851] res2a_branch2b_param_0(0.44) 
I0630 06:49:47.216634 29777 net.cpp:1851] res3a_branch2a_param_0(0.44) 
I0630 06:49:47.216635 29777 net.cpp:1851] res3a_branch2b_param_0(0.44) 
I0630 06:49:47.216639 29777 net.cpp:1851] res4a_branch2a_param_0(0.44) 
I0630 06:49:47.216640 29777 net.cpp:1851] res4a_branch2b_param_0(0.44) 
I0630 06:49:47.216642 29777 net.cpp:1851] res5a_branch2a_param_0(0.44) 
I0630 06:49:47.216645 29777 net.cpp:1851] res5a_branch2b_param_0(0.44) 
I0630 06:49:47.216646 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.03557e+06/2.86678e+06) 0.361
I0630 06:49:47.216733 29777 solver.cpp:471] Iteration 88000, Testing net (#0)
I0630 06:49:55.499549 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:50:46.897066 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57454
I0630 06:50:46.897111 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.807801
I0630 06:50:46.897119 29777 solver.cpp:544]     Test net output #2: loss = 1.5161 (* 1 = 1.5161 loss)
I0630 06:50:47.082335 29777 solver.cpp:290] Iteration 88000 (1.31778 iter/s, 75.8851s/100 iter), loss = 1.20238
I0630 06:50:47.082358 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 06:50:47.082365 29777 sgd_solver.cpp:106] Iteration 88000, lr = 0.00725
I0630 06:50:47.083067 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.45
I0630 06:50:47.385828 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:51:03.452255 29777 solver.cpp:290] Iteration 88100 (6.10895 iter/s, 16.3694s/100 iter), loss = 0.928571
I0630 06:51:03.452307 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 06:51:03.452325 29777 sgd_solver.cpp:106] Iteration 88100, lr = 0.00724687
I0630 06:51:19.628193 29777 solver.cpp:290] Iteration 88200 (6.18222 iter/s, 16.1754s/100 iter), loss = 1.47619
I0630 06:51:19.628473 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:51:19.628578 29777 sgd_solver.cpp:106] Iteration 88200, lr = 0.00724375
I0630 06:51:35.614503 29777 solver.cpp:290] Iteration 88300 (6.25563 iter/s, 15.9856s/100 iter), loss = 1.05952
I0630 06:51:35.614526 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 06:51:35.614533 29777 sgd_solver.cpp:106] Iteration 88300, lr = 0.00724062
I0630 06:51:51.727732 29777 solver.cpp:290] Iteration 88400 (6.20626 iter/s, 16.1128s/100 iter), loss = 1.25
I0630 06:51:51.727803 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 06:51:51.727811 29777 sgd_solver.cpp:106] Iteration 88400, lr = 0.0072375
I0630 06:52:07.837265 29777 solver.cpp:290] Iteration 88500 (6.2077 iter/s, 16.109s/100 iter), loss = 1.35714
I0630 06:52:07.837290 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 06:52:07.837296 29777 sgd_solver.cpp:106] Iteration 88500, lr = 0.00723437
I0630 06:52:23.904026 29777 solver.cpp:290] Iteration 88600 (6.22421 iter/s, 16.0663s/100 iter), loss = 0.952381
I0630 06:52:23.904469 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:52:23.904479 29777 sgd_solver.cpp:106] Iteration 88600, lr = 0.00723125
I0630 06:52:40.040081 29777 solver.cpp:290] Iteration 88700 (6.19764 iter/s, 16.1352s/100 iter), loss = 1.22619
I0630 06:52:40.040104 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:52:40.040113 29777 sgd_solver.cpp:106] Iteration 88700, lr = 0.00722813
I0630 06:52:56.157356 29777 solver.cpp:290] Iteration 88800 (6.20471 iter/s, 16.1168s/100 iter), loss = 1.30952
I0630 06:52:56.157449 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 06:52:56.157461 29777 sgd_solver.cpp:106] Iteration 88800, lr = 0.007225
I0630 06:53:12.314633 29777 solver.cpp:290] Iteration 88900 (6.18937 iter/s, 16.1567s/100 iter), loss = 0.904762
I0630 06:53:12.314687 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 06:53:12.314708 29777 sgd_solver.cpp:106] Iteration 88900, lr = 0.00722188
I0630 06:53:28.411833 29777 solver.cpp:354] Sparsity after update:
I0630 06:53:28.452571 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:53:28.452594 29777 net.cpp:1851] conv1a_param_0(0.225) 
I0630 06:53:28.452606 29777 net.cpp:1851] conv1b_param_0(0.45) 
I0630 06:53:28.452610 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:53:28.452613 29777 net.cpp:1851] res2a_branch2a_param_0(0.45) 
I0630 06:53:28.452616 29777 net.cpp:1851] res2a_branch2b_param_0(0.45) 
I0630 06:53:28.452620 29777 net.cpp:1851] res3a_branch2a_param_0(0.45) 
I0630 06:53:28.452622 29777 net.cpp:1851] res3a_branch2b_param_0(0.45) 
I0630 06:53:28.452626 29777 net.cpp:1851] res4a_branch2a_param_0(0.45) 
I0630 06:53:28.452630 29777 net.cpp:1851] res4a_branch2b_param_0(0.45) 
I0630 06:53:28.452632 29777 net.cpp:1851] res5a_branch2a_param_0(0.45) 
I0630 06:53:28.452636 29777 net.cpp:1851] res5a_branch2b_param_0(0.45) 
I0630 06:53:28.452638 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.0591e+06/2.86678e+06) 0.369
I0630 06:53:28.607592 29777 solver.cpp:290] Iteration 89000 (6.13781 iter/s, 16.2924s/100 iter), loss = 0.714286
I0630 06:53:28.607643 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 06:53:28.607661 29777 sgd_solver.cpp:106] Iteration 89000, lr = 0.00721875
I0630 06:53:45.044205 29777 solver.cpp:290] Iteration 89100 (6.08416 iter/s, 16.4361s/100 iter), loss = 0.869048
I0630 06:53:45.044229 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 06:53:45.044246 29777 sgd_solver.cpp:106] Iteration 89100, lr = 0.00721562
I0630 06:54:01.430315 29777 solver.cpp:290] Iteration 89200 (6.10291 iter/s, 16.3856s/100 iter), loss = 0.952381
I0630 06:54:01.430454 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:54:01.430479 29777 sgd_solver.cpp:106] Iteration 89200, lr = 0.0072125
I0630 06:54:17.749402 29777 solver.cpp:290] Iteration 89300 (6.12801 iter/s, 16.3185s/100 iter), loss = 0.97619
I0630 06:54:17.749426 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:54:17.749433 29777 sgd_solver.cpp:106] Iteration 89300, lr = 0.00720937
I0630 06:54:33.868598 29777 solver.cpp:290] Iteration 89400 (6.20396 iter/s, 16.1187s/100 iter), loss = 1.17857
I0630 06:54:33.868671 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 06:54:33.868680 29777 sgd_solver.cpp:106] Iteration 89400, lr = 0.00720625
I0630 06:54:50.338081 29777 solver.cpp:290] Iteration 89500 (6.07204 iter/s, 16.4689s/100 iter), loss = 1.2619
I0630 06:54:50.338140 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 06:54:50.338181 29777 sgd_solver.cpp:106] Iteration 89500, lr = 0.00720312
I0630 06:55:06.726348 29777 solver.cpp:290] Iteration 89600 (6.10212 iter/s, 16.3878s/100 iter), loss = 1.03571
I0630 06:55:06.726445 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 06:55:06.726455 29777 sgd_solver.cpp:106] Iteration 89600, lr = 0.0072
I0630 06:55:23.066794 29777 solver.cpp:290] Iteration 89700 (6.11999 iter/s, 16.3399s/100 iter), loss = 0.916667
I0630 06:55:23.066825 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 06:55:23.066843 29777 sgd_solver.cpp:106] Iteration 89700, lr = 0.00719687
I0630 06:55:39.161701 29777 solver.cpp:290] Iteration 89800 (6.21333 iter/s, 16.0944s/100 iter), loss = 1.21429
I0630 06:55:39.161811 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 06:55:39.161826 29777 sgd_solver.cpp:106] Iteration 89800, lr = 0.00719375
I0630 06:55:55.692869 29777 solver.cpp:290] Iteration 89900 (6.04939 iter/s, 16.5306s/100 iter), loss = 1.04762
I0630 06:55:55.692896 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:55:55.692906 29777 sgd_solver.cpp:106] Iteration 89900, lr = 0.00719062
I0630 06:56:11.979128 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_90000.caffemodel
I0630 06:56:11.999280 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_90000.solverstate
I0630 06:56:12.008086 29777 solver.cpp:354] Sparsity after update:
I0630 06:56:12.009048 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:56:12.009057 29777 net.cpp:1851] conv1a_param_0(0.225) 
I0630 06:56:12.009063 29777 net.cpp:1851] conv1b_param_0(0.45) 
I0630 06:56:12.009065 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:56:12.009068 29777 net.cpp:1851] res2a_branch2a_param_0(0.45) 
I0630 06:56:12.009069 29777 net.cpp:1851] res2a_branch2b_param_0(0.45) 
I0630 06:56:12.009071 29777 net.cpp:1851] res3a_branch2a_param_0(0.45) 
I0630 06:56:12.009073 29777 net.cpp:1851] res3a_branch2b_param_0(0.45) 
I0630 06:56:12.009075 29777 net.cpp:1851] res4a_branch2a_param_0(0.45) 
I0630 06:56:12.009078 29777 net.cpp:1851] res4a_branch2b_param_0(0.45) 
I0630 06:56:12.009079 29777 net.cpp:1851] res5a_branch2a_param_0(0.45) 
I0630 06:56:12.009081 29777 net.cpp:1851] res5a_branch2b_param_0(0.45) 
I0630 06:56:12.009083 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.0591e+06/2.86678e+06) 0.369
I0630 06:56:12.009178 29777 solver.cpp:471] Iteration 90000, Testing net (#0)
I0630 06:56:20.671902 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 06:57:01.753468 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56932
I0630 06:57:01.753597 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804682
I0630 06:57:01.753607 29777 solver.cpp:544]     Test net output #2: loss = 1.53104 (* 1 = 1.53104 loss)
I0630 06:57:01.941627 29777 solver.cpp:290] Iteration 90000 (1.5095 iter/s, 66.2469s/100 iter), loss = 1.25
I0630 06:57:01.941653 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 06:57:01.941660 29777 sgd_solver.cpp:106] Iteration 90000, lr = 0.0071875
I0630 06:57:01.942380 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.46
I0630 06:57:02.253700 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 06:57:18.227555 29777 solver.cpp:290] Iteration 90100 (6.14045 iter/s, 16.2854s/100 iter), loss = 0.809524
I0630 06:57:18.227581 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 06:57:18.227591 29777 sgd_solver.cpp:106] Iteration 90100, lr = 0.00718437
I0630 06:57:34.280931 29777 solver.cpp:290] Iteration 90200 (6.2294 iter/s, 16.0529s/100 iter), loss = 1.02381
I0630 06:57:34.280988 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 06:57:34.280997 29777 sgd_solver.cpp:106] Iteration 90200, lr = 0.00718125
I0630 06:57:50.340977 29777 solver.cpp:290] Iteration 90300 (6.22683 iter/s, 16.0595s/100 iter), loss = 0.761905
I0630 06:57:50.341081 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 06:57:50.341123 29777 sgd_solver.cpp:106] Iteration 90300, lr = 0.00717813
I0630 06:58:06.433862 29777 solver.cpp:290] Iteration 90400 (6.21414 iter/s, 16.0923s/100 iter), loss = 0.940476
I0630 06:58:06.433954 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 06:58:06.433965 29777 sgd_solver.cpp:106] Iteration 90400, lr = 0.007175
I0630 06:58:22.602619 29777 solver.cpp:290] Iteration 90500 (6.18497 iter/s, 16.1682s/100 iter), loss = 1.10714
I0630 06:58:22.602645 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 06:58:22.602654 29777 sgd_solver.cpp:106] Iteration 90500, lr = 0.00717187
I0630 06:58:38.615814 29777 solver.cpp:290] Iteration 90600 (6.24503 iter/s, 16.0127s/100 iter), loss = 0.845238
I0630 06:58:38.616080 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 06:58:38.616093 29777 sgd_solver.cpp:106] Iteration 90600, lr = 0.00716875
I0630 06:58:54.676383 29777 solver.cpp:290] Iteration 90700 (6.22671 iter/s, 16.0598s/100 iter), loss = 1.04762
I0630 06:58:54.676462 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 06:58:54.676491 29777 sgd_solver.cpp:106] Iteration 90700, lr = 0.00716562
I0630 06:59:10.893788 29777 solver.cpp:290] Iteration 90800 (6.16642 iter/s, 16.2169s/100 iter), loss = 0.880952
I0630 06:59:10.894075 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 06:59:10.894171 29777 sgd_solver.cpp:106] Iteration 90800, lr = 0.0071625
I0630 06:59:27.111131 29777 solver.cpp:290] Iteration 90900 (6.16652 iter/s, 16.2166s/100 iter), loss = 1.22619
I0630 06:59:27.111155 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 06:59:27.111161 29777 sgd_solver.cpp:106] Iteration 90900, lr = 0.00715937
I0630 06:59:43.008638 29777 solver.cpp:354] Sparsity after update:
I0630 06:59:43.029054 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 06:59:43.029090 29777 net.cpp:1851] conv1a_param_0(0.23) 
I0630 06:59:43.029115 29777 net.cpp:1851] conv1b_param_0(0.46) 
I0630 06:59:43.029129 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 06:59:43.029135 29777 net.cpp:1851] res2a_branch2a_param_0(0.46) 
I0630 06:59:43.029142 29777 net.cpp:1851] res2a_branch2b_param_0(0.46) 
I0630 06:59:43.029163 29777 net.cpp:1851] res3a_branch2a_param_0(0.46) 
I0630 06:59:43.029175 29777 net.cpp:1851] res3a_branch2b_param_0(0.46) 
I0630 06:59:43.029186 29777 net.cpp:1851] res4a_branch2a_param_0(0.46) 
I0630 06:59:43.029196 29777 net.cpp:1851] res4a_branch2b_param_0(0.46) 
I0630 06:59:43.029206 29777 net.cpp:1851] res5a_branch2a_param_0(0.46) 
I0630 06:59:43.029217 29777 net.cpp:1851] res5a_branch2b_param_0(0.46) 
I0630 06:59:43.029227 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.08264e+06/2.86678e+06) 0.378
I0630 06:59:43.189227 29777 solver.cpp:290] Iteration 91000 (6.21982 iter/s, 16.0776s/100 iter), loss = 0.940476
I0630 06:59:43.189254 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 06:59:43.189262 29777 sgd_solver.cpp:106] Iteration 91000, lr = 0.00715625
I0630 06:59:59.318253 29777 solver.cpp:290] Iteration 91100 (6.20019 iter/s, 16.1285s/100 iter), loss = 0.940476
I0630 06:59:59.318276 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 06:59:59.318284 29777 sgd_solver.cpp:106] Iteration 91100, lr = 0.00715312
I0630 07:00:15.403050 29777 solver.cpp:290] Iteration 91200 (6.21723 iter/s, 16.0843s/100 iter), loss = 0.797619
I0630 07:00:15.403146 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:00:15.403164 29777 sgd_solver.cpp:106] Iteration 91200, lr = 0.00715
I0630 07:00:31.409936 29777 solver.cpp:290] Iteration 91300 (6.24752 iter/s, 16.0063s/100 iter), loss = 0.952381
I0630 07:00:31.409962 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:00:31.409971 29777 sgd_solver.cpp:106] Iteration 91300, lr = 0.00714687
I0630 07:00:47.367290 29777 solver.cpp:290] Iteration 91400 (6.26689 iter/s, 15.9569s/100 iter), loss = 1.09524
I0630 07:00:47.367377 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 07:00:47.367388 29777 sgd_solver.cpp:106] Iteration 91400, lr = 0.00714375
I0630 07:01:03.329533 29777 solver.cpp:290] Iteration 91500 (6.26499 iter/s, 15.9617s/100 iter), loss = 1.03571
I0630 07:01:03.329560 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:01:03.329568 29777 sgd_solver.cpp:106] Iteration 91500, lr = 0.00714062
I0630 07:01:19.363656 29777 solver.cpp:290] Iteration 91600 (6.23688 iter/s, 16.0337s/100 iter), loss = 0.869048
I0630 07:01:19.363732 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 07:01:19.363739 29777 sgd_solver.cpp:106] Iteration 91600, lr = 0.0071375
I0630 07:01:35.400560 29777 solver.cpp:290] Iteration 91700 (6.23582 iter/s, 16.0364s/100 iter), loss = 1.21429
I0630 07:01:35.400586 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:01:35.400593 29777 sgd_solver.cpp:106] Iteration 91700, lr = 0.00713437
I0630 07:01:51.487488 29777 solver.cpp:290] Iteration 91800 (6.21641 iter/s, 16.0865s/100 iter), loss = 0.928571
I0630 07:01:51.487592 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 07:01:51.487602 29777 sgd_solver.cpp:106] Iteration 91800, lr = 0.00713125
I0630 07:02:07.508640 29777 solver.cpp:290] Iteration 91900 (6.24196 iter/s, 16.0206s/100 iter), loss = 0.797619
I0630 07:02:07.508663 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 07:02:07.508671 29777 sgd_solver.cpp:106] Iteration 91900, lr = 0.00712813
I0630 07:02:23.442005 29777 solver.cpp:354] Sparsity after update:
I0630 07:02:23.443478 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:02:23.443486 29777 net.cpp:1851] conv1a_param_0(0.23) 
I0630 07:02:23.443495 29777 net.cpp:1851] conv1b_param_0(0.46) 
I0630 07:02:23.443497 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:02:23.443500 29777 net.cpp:1851] res2a_branch2a_param_0(0.46) 
I0630 07:02:23.443502 29777 net.cpp:1851] res2a_branch2b_param_0(0.46) 
I0630 07:02:23.443505 29777 net.cpp:1851] res3a_branch2a_param_0(0.46) 
I0630 07:02:23.443506 29777 net.cpp:1851] res3a_branch2b_param_0(0.46) 
I0630 07:02:23.443508 29777 net.cpp:1851] res4a_branch2a_param_0(0.46) 
I0630 07:02:23.443511 29777 net.cpp:1851] res4a_branch2b_param_0(0.46) 
I0630 07:02:23.443512 29777 net.cpp:1851] res5a_branch2a_param_0(0.46) 
I0630 07:02:23.443514 29777 net.cpp:1851] res5a_branch2b_param_0(0.46) 
I0630 07:02:23.443517 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.08264e+06/2.86678e+06) 0.378
I0630 07:02:23.443604 29777 solver.cpp:471] Iteration 92000, Testing net (#0)
I0630 07:02:31.168041 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:03:11.781383 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.571899
I0630 07:03:11.781445 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806461
I0630 07:03:11.781455 29777 solver.cpp:544]     Test net output #2: loss = 1.5251 (* 1 = 1.5251 loss)
I0630 07:03:11.959621 29777 solver.cpp:290] Iteration 92000 (1.55161 iter/s, 64.4492s/100 iter), loss = 1.20238
I0630 07:03:11.959643 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 07:03:11.959662 29777 sgd_solver.cpp:106] Iteration 92000, lr = 0.007125
I0630 07:03:11.960363 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.47
I0630 07:03:12.263739 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:03:28.290139 29777 solver.cpp:290] Iteration 92100 (6.12368 iter/s, 16.33s/100 iter), loss = 1.04762
I0630 07:03:28.290163 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:03:28.290169 29777 sgd_solver.cpp:106] Iteration 92100, lr = 0.00712187
I0630 07:03:44.320260 29777 solver.cpp:290] Iteration 92200 (6.23844 iter/s, 16.0296s/100 iter), loss = 1.32143
I0630 07:03:44.320355 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 07:03:44.320366 29777 sgd_solver.cpp:106] Iteration 92200, lr = 0.00711875
I0630 07:04:00.386499 29777 solver.cpp:290] Iteration 92300 (6.22444 iter/s, 16.0657s/100 iter), loss = 1.05952
I0630 07:04:00.386525 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 07:04:00.386534 29777 sgd_solver.cpp:106] Iteration 92300, lr = 0.00711562
I0630 07:04:16.553071 29777 solver.cpp:290] Iteration 92400 (6.18579 iter/s, 16.1661s/100 iter), loss = 1.03571
I0630 07:04:16.553174 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:04:16.553184 29777 sgd_solver.cpp:106] Iteration 92400, lr = 0.0071125
I0630 07:04:32.627995 29777 solver.cpp:290] Iteration 92500 (6.22108 iter/s, 16.0744s/100 iter), loss = 1.15476
I0630 07:04:32.628018 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:04:32.628024 29777 sgd_solver.cpp:106] Iteration 92500, lr = 0.00710937
I0630 07:04:48.770323 29777 solver.cpp:290] Iteration 92600 (6.19508 iter/s, 16.1419s/100 iter), loss = 1.4881
I0630 07:04:48.770444 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 07:04:48.770459 29777 sgd_solver.cpp:106] Iteration 92600, lr = 0.00710625
I0630 07:05:04.854398 29777 solver.cpp:290] Iteration 92700 (6.21755 iter/s, 16.0835s/100 iter), loss = 1.65476
I0630 07:05:04.854430 29777 solver.cpp:309]     Train net output #0: loss = 1.85714 (* 1 = 1.85714 loss)
I0630 07:05:04.854441 29777 sgd_solver.cpp:106] Iteration 92700, lr = 0.00710312
I0630 07:05:20.835855 29777 solver.cpp:290] Iteration 92800 (6.25744 iter/s, 15.981s/100 iter), loss = 1.25
I0630 07:05:20.835927 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:05:20.835933 29777 sgd_solver.cpp:106] Iteration 92800, lr = 0.0071
I0630 07:05:36.821202 29777 solver.cpp:290] Iteration 92900 (6.25593 iter/s, 15.9848s/100 iter), loss = 1
I0630 07:05:36.821229 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:05:36.821238 29777 sgd_solver.cpp:106] Iteration 92900, lr = 0.00709687
I0630 07:05:52.757498 29777 solver.cpp:354] Sparsity after update:
I0630 07:05:52.779494 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:05:52.779510 29777 net.cpp:1851] conv1a_param_0(0.235) 
I0630 07:05:52.779517 29777 net.cpp:1851] conv1b_param_0(0.47) 
I0630 07:05:52.779520 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:05:52.779522 29777 net.cpp:1851] res2a_branch2a_param_0(0.47) 
I0630 07:05:52.779525 29777 net.cpp:1851] res2a_branch2b_param_0(0.47) 
I0630 07:05:52.779526 29777 net.cpp:1851] res3a_branch2a_param_0(0.47) 
I0630 07:05:52.779530 29777 net.cpp:1851] res3a_branch2b_param_0(0.47) 
I0630 07:05:52.779531 29777 net.cpp:1851] res4a_branch2a_param_0(0.47) 
I0630 07:05:52.779533 29777 net.cpp:1851] res4a_branch2b_param_0(0.47) 
I0630 07:05:52.779536 29777 net.cpp:1851] res5a_branch2a_param_0(0.47) 
I0630 07:05:52.779539 29777 net.cpp:1851] res5a_branch2b_param_0(0.47) 
I0630 07:05:52.779542 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.10618e+06/2.86678e+06) 0.386
I0630 07:05:52.937866 29777 solver.cpp:290] Iteration 93000 (6.20494 iter/s, 16.1162s/100 iter), loss = 0.904762
I0630 07:05:52.937889 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:05:52.937896 29777 sgd_solver.cpp:106] Iteration 93000, lr = 0.00709375
I0630 07:06:09.019920 29777 solver.cpp:290] Iteration 93100 (6.2183 iter/s, 16.0816s/100 iter), loss = 1.03571
I0630 07:06:09.019994 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:06:09.020018 29777 sgd_solver.cpp:106] Iteration 93100, lr = 0.00709062
I0630 07:06:25.073945 29777 solver.cpp:290] Iteration 93200 (6.22917 iter/s, 16.0535s/100 iter), loss = 0.916667
I0630 07:06:25.073989 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:06:25.073997 29777 sgd_solver.cpp:106] Iteration 93200, lr = 0.0070875
I0630 07:06:41.180604 29777 solver.cpp:290] Iteration 93300 (6.2088 iter/s, 16.1062s/100 iter), loss = 1.09524
I0630 07:06:41.180629 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:06:41.180637 29777 sgd_solver.cpp:106] Iteration 93300, lr = 0.00708437
I0630 07:06:57.187494 29777 solver.cpp:290] Iteration 93400 (6.24749 iter/s, 16.0064s/100 iter), loss = 0.785714
I0630 07:06:57.187566 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 07:06:57.187575 29777 sgd_solver.cpp:106] Iteration 93400, lr = 0.00708125
I0630 07:07:13.397532 29777 solver.cpp:290] Iteration 93500 (6.16922 iter/s, 16.2095s/100 iter), loss = 0.785714
I0630 07:07:13.397554 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:07:13.397562 29777 sgd_solver.cpp:106] Iteration 93500, lr = 0.00707812
I0630 07:07:29.643139 29777 solver.cpp:290] Iteration 93600 (6.15569 iter/s, 16.2451s/100 iter), loss = 0.738095
I0630 07:07:29.643251 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 07:07:29.643261 29777 sgd_solver.cpp:106] Iteration 93600, lr = 0.007075
I0630 07:07:45.599570 29777 solver.cpp:290] Iteration 93700 (6.26728 iter/s, 15.9559s/100 iter), loss = 1.22619
I0630 07:07:45.599596 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:07:45.599612 29777 sgd_solver.cpp:106] Iteration 93700, lr = 0.00707188
I0630 07:08:01.537533 29777 solver.cpp:290] Iteration 93800 (6.27451 iter/s, 15.9375s/100 iter), loss = 1.2381
I0630 07:08:01.537614 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:08:01.537623 29777 sgd_solver.cpp:106] Iteration 93800, lr = 0.00706875
I0630 07:08:17.567939 29777 solver.cpp:290] Iteration 93900 (6.23835 iter/s, 16.0299s/100 iter), loss = 0.97619
I0630 07:08:17.567961 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:08:17.567967 29777 sgd_solver.cpp:106] Iteration 93900, lr = 0.00706562
I0630 07:08:33.418453 29777 solver.cpp:354] Sparsity after update:
I0630 07:08:33.419890 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:08:33.419898 29777 net.cpp:1851] conv1a_param_0(0.235) 
I0630 07:08:33.419905 29777 net.cpp:1851] conv1b_param_0(0.47) 
I0630 07:08:33.419908 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:08:33.419909 29777 net.cpp:1851] res2a_branch2a_param_0(0.47) 
I0630 07:08:33.419911 29777 net.cpp:1851] res2a_branch2b_param_0(0.47) 
I0630 07:08:33.419914 29777 net.cpp:1851] res3a_branch2a_param_0(0.47) 
I0630 07:08:33.419915 29777 net.cpp:1851] res3a_branch2b_param_0(0.47) 
I0630 07:08:33.419917 29777 net.cpp:1851] res4a_branch2a_param_0(0.47) 
I0630 07:08:33.419919 29777 net.cpp:1851] res4a_branch2b_param_0(0.47) 
I0630 07:08:33.419921 29777 net.cpp:1851] res5a_branch2a_param_0(0.47) 
I0630 07:08:33.419922 29777 net.cpp:1851] res5a_branch2b_param_0(0.47) 
I0630 07:08:33.419925 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.10618e+06/2.86678e+06) 0.386
I0630 07:08:33.420011 29777 solver.cpp:471] Iteration 94000, Testing net (#0)
I0630 07:08:41.349144 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:09:22.296231 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5727
I0630 07:09:22.296303 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806361
I0630 07:09:22.296310 29777 solver.cpp:544]     Test net output #2: loss = 1.51912 (* 1 = 1.51912 loss)
I0630 07:09:22.469818 29777 solver.cpp:290] Iteration 94000 (1.54083 iter/s, 64.9001s/100 iter), loss = 0.77381
I0630 07:09:22.469841 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 07:09:22.469863 29777 sgd_solver.cpp:106] Iteration 94000, lr = 0.0070625
I0630 07:09:22.470576 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.48
I0630 07:09:22.780665 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:09:38.133929 29777 solver.cpp:290] Iteration 94100 (6.38421 iter/s, 15.6637s/100 iter), loss = 1.27381
I0630 07:09:38.133954 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:09:38.133960 29777 sgd_solver.cpp:106] Iteration 94100, lr = 0.00705937
I0630 07:09:54.005964 29777 solver.cpp:290] Iteration 94200 (6.30057 iter/s, 15.8716s/100 iter), loss = 1.30952
I0630 07:09:54.006053 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 07:09:54.006060 29777 sgd_solver.cpp:106] Iteration 94200, lr = 0.00705625
I0630 07:10:09.956017 29777 solver.cpp:290] Iteration 94300 (6.26978 iter/s, 15.9495s/100 iter), loss = 0.940476
I0630 07:10:09.956043 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 07:10:09.956053 29777 sgd_solver.cpp:106] Iteration 94300, lr = 0.00705312
I0630 07:10:26.047200 29777 solver.cpp:290] Iteration 94400 (6.21477 iter/s, 16.0907s/100 iter), loss = 1.05952
I0630 07:10:26.047291 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:10:26.047302 29777 sgd_solver.cpp:106] Iteration 94400, lr = 0.00705
I0630 07:10:42.099599 29777 solver.cpp:290] Iteration 94500 (6.22981 iter/s, 16.0519s/100 iter), loss = 1.20238
I0630 07:10:42.099623 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:10:42.099632 29777 sgd_solver.cpp:106] Iteration 94500, lr = 0.00704687
I0630 07:10:58.309980 29777 solver.cpp:290] Iteration 94600 (6.16908 iter/s, 16.2099s/100 iter), loss = 0.904762
I0630 07:10:58.312425 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:10:58.312608 29777 sgd_solver.cpp:106] Iteration 94600, lr = 0.00704375
I0630 07:11:14.906527 29777 solver.cpp:290] Iteration 94700 (6.02639 iter/s, 16.5937s/100 iter), loss = 1
I0630 07:11:14.906551 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 07:11:14.906560 29777 sgd_solver.cpp:106] Iteration 94700, lr = 0.00704062
I0630 07:11:31.201421 29777 solver.cpp:290] Iteration 94800 (6.13707 iter/s, 16.2944s/100 iter), loss = 0.904762
I0630 07:11:31.201478 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:11:31.201488 29777 sgd_solver.cpp:106] Iteration 94800, lr = 0.0070375
I0630 07:11:47.553442 29777 solver.cpp:290] Iteration 94900 (6.11564 iter/s, 16.3515s/100 iter), loss = 1
I0630 07:11:47.553468 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:11:47.553478 29777 sgd_solver.cpp:106] Iteration 94900, lr = 0.00703437
I0630 07:12:03.433233 29777 solver.cpp:354] Sparsity after update:
I0630 07:12:03.459612 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:12:03.459812 29777 net.cpp:1851] conv1a_param_0(0.24) 
I0630 07:12:03.459954 29777 net.cpp:1851] conv1b_param_0(0.48) 
I0630 07:12:03.460062 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:12:03.460162 29777 net.cpp:1851] res2a_branch2a_param_0(0.48) 
I0630 07:12:03.460263 29777 net.cpp:1851] res2a_branch2b_param_0(0.48) 
I0630 07:12:03.460372 29777 net.cpp:1851] res3a_branch2a_param_0(0.48) 
I0630 07:12:03.460477 29777 net.cpp:1851] res3a_branch2b_param_0(0.48) 
I0630 07:12:03.460582 29777 net.cpp:1851] res4a_branch2a_param_0(0.48) 
I0630 07:12:03.460690 29777 net.cpp:1851] res4a_branch2b_param_0(0.48) 
I0630 07:12:03.460718 29777 net.cpp:1851] res5a_branch2a_param_0(0.48) 
I0630 07:12:03.460739 29777 net.cpp:1851] res5a_branch2b_param_0(0.48) 
I0630 07:12:03.460747 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.12971e+06/2.86678e+06) 0.394
I0630 07:12:03.638916 29777 solver.cpp:290] Iteration 95000 (6.21697 iter/s, 16.085s/100 iter), loss = 0.916667
I0630 07:12:03.638942 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:12:03.638948 29777 sgd_solver.cpp:106] Iteration 95000, lr = 0.00703125
I0630 07:12:19.943042 29777 solver.cpp:290] Iteration 95100 (6.1336 iter/s, 16.3036s/100 iter), loss = 1.15476
I0630 07:12:19.943066 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 07:12:19.943073 29777 sgd_solver.cpp:106] Iteration 95100, lr = 0.00702812
I0630 07:12:36.273773 29777 solver.cpp:290] Iteration 95200 (6.1236 iter/s, 16.3303s/100 iter), loss = 1.25
I0630 07:12:36.273844 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:12:36.273851 29777 sgd_solver.cpp:106] Iteration 95200, lr = 0.007025
I0630 07:12:52.599480 29777 solver.cpp:290] Iteration 95300 (6.12551 iter/s, 16.3252s/100 iter), loss = 1.29762
I0630 07:12:52.599506 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:12:52.599515 29777 sgd_solver.cpp:106] Iteration 95300, lr = 0.00702188
I0630 07:13:08.887076 29777 solver.cpp:290] Iteration 95400 (6.13982 iter/s, 16.2871s/100 iter), loss = 1.14286
I0630 07:13:08.887156 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:13:08.887163 29777 sgd_solver.cpp:106] Iteration 95400, lr = 0.00701875
I0630 07:13:25.143143 29777 solver.cpp:290] Iteration 95500 (6.15175 iter/s, 16.2555s/100 iter), loss = 1
I0630 07:13:25.143168 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:13:25.143177 29777 sgd_solver.cpp:106] Iteration 95500, lr = 0.00701563
I0630 07:13:41.397339 29777 solver.cpp:290] Iteration 95600 (6.15244 iter/s, 16.2537s/100 iter), loss = 1.28571
I0630 07:13:41.397450 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 07:13:41.397461 29777 sgd_solver.cpp:106] Iteration 95600, lr = 0.0070125
I0630 07:13:57.454426 29777 solver.cpp:290] Iteration 95700 (6.22799 iter/s, 16.0565s/100 iter), loss = 0.988095
I0630 07:13:57.454461 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:13:57.454470 29777 sgd_solver.cpp:106] Iteration 95700, lr = 0.00700937
I0630 07:14:13.589856 29777 solver.cpp:290] Iteration 95800 (6.19773 iter/s, 16.1349s/100 iter), loss = 1.02381
I0630 07:14:13.589931 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 07:14:13.589942 29777 sgd_solver.cpp:106] Iteration 95800, lr = 0.00700625
I0630 07:14:29.892318 29777 solver.cpp:290] Iteration 95900 (6.13424 iter/s, 16.3019s/100 iter), loss = 0.845238
I0630 07:14:29.892349 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 07:14:29.892359 29777 sgd_solver.cpp:106] Iteration 95900, lr = 0.00700312
I0630 07:14:46.035542 29777 solver.cpp:354] Sparsity after update:
I0630 07:14:46.037170 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:14:46.037178 29777 net.cpp:1851] conv1a_param_0(0.24) 
I0630 07:14:46.037185 29777 net.cpp:1851] conv1b_param_0(0.48) 
I0630 07:14:46.037189 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:14:46.037190 29777 net.cpp:1851] res2a_branch2a_param_0(0.48) 
I0630 07:14:46.037192 29777 net.cpp:1851] res2a_branch2b_param_0(0.48) 
I0630 07:14:46.037194 29777 net.cpp:1851] res3a_branch2a_param_0(0.48) 
I0630 07:14:46.037196 29777 net.cpp:1851] res3a_branch2b_param_0(0.48) 
I0630 07:14:46.037199 29777 net.cpp:1851] res4a_branch2a_param_0(0.48) 
I0630 07:14:46.037200 29777 net.cpp:1851] res4a_branch2b_param_0(0.48) 
I0630 07:14:46.037202 29777 net.cpp:1851] res5a_branch2a_param_0(0.48) 
I0630 07:14:46.037204 29777 net.cpp:1851] res5a_branch2b_param_0(0.48) 
I0630 07:14:46.037206 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.12971e+06/2.86678e+06) 0.394
I0630 07:14:46.037302 29777 solver.cpp:471] Iteration 96000, Testing net (#0)
I0630 07:14:57.547770 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:15:51.573626 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5696
I0630 07:15:51.573704 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801901
I0630 07:15:51.573711 29777 solver.cpp:544]     Test net output #2: loss = 1.53412 (* 1 = 1.53412 loss)
I0630 07:15:51.753326 29777 solver.cpp:290] Iteration 96000 (1.22162 iter/s, 81.8587s/100 iter), loss = 1.19048
I0630 07:15:51.753350 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 07:15:51.753355 29777 sgd_solver.cpp:106] Iteration 96000, lr = 0.007
I0630 07:15:51.754076 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.49
I0630 07:15:52.084887 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:16:07.855725 29777 solver.cpp:290] Iteration 96100 (6.21044 iter/s, 16.1019s/100 iter), loss = 0.940476
I0630 07:16:07.855748 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:16:07.855756 29777 sgd_solver.cpp:106] Iteration 96100, lr = 0.00699687
I0630 07:16:24.268051 29777 solver.cpp:290] Iteration 96200 (6.09316 iter/s, 16.4118s/100 iter), loss = 1.21429
I0630 07:16:24.268155 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 07:16:24.268170 29777 sgd_solver.cpp:106] Iteration 96200, lr = 0.00699375
I0630 07:16:40.295428 29777 solver.cpp:290] Iteration 96300 (6.23954 iter/s, 16.0268s/100 iter), loss = 1.25
I0630 07:16:40.295449 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 07:16:40.295456 29777 sgd_solver.cpp:106] Iteration 96300, lr = 0.00699062
I0630 07:16:56.520004 29777 solver.cpp:290] Iteration 96400 (6.16367 iter/s, 16.2241s/100 iter), loss = 0.97619
I0630 07:16:56.520097 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:16:56.520107 29777 sgd_solver.cpp:106] Iteration 96400, lr = 0.0069875
I0630 07:17:13.086413 29777 solver.cpp:290] Iteration 96500 (6.03651 iter/s, 16.5659s/100 iter), loss = 0.928571
I0630 07:17:13.086447 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 07:17:13.086458 29777 sgd_solver.cpp:106] Iteration 96500, lr = 0.00698437
I0630 07:17:29.260211 29777 solver.cpp:290] Iteration 96600 (6.18302 iter/s, 16.1733s/100 iter), loss = 1.07143
I0630 07:17:29.260267 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:17:29.260277 29777 sgd_solver.cpp:106] Iteration 96600, lr = 0.00698125
I0630 07:17:45.819687 29777 solver.cpp:290] Iteration 96700 (6.03903 iter/s, 16.559s/100 iter), loss = 1.21429
I0630 07:17:45.819743 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:17:45.819763 29777 sgd_solver.cpp:106] Iteration 96700, lr = 0.00697812
I0630 07:18:02.080148 29777 solver.cpp:290] Iteration 96800 (6.15008 iter/s, 16.26s/100 iter), loss = 0.869048
I0630 07:18:02.080255 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 07:18:02.080266 29777 sgd_solver.cpp:106] Iteration 96800, lr = 0.006975
I0630 07:18:18.306888 29777 solver.cpp:290] Iteration 96900 (6.16288 iter/s, 16.2262s/100 iter), loss = 1.10714
I0630 07:18:18.306917 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 07:18:18.306927 29777 sgd_solver.cpp:106] Iteration 96900, lr = 0.00697188
I0630 07:18:34.318522 29777 solver.cpp:354] Sparsity after update:
I0630 07:18:34.338989 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:18:34.339005 29777 net.cpp:1851] conv1a_param_0(0.245) 
I0630 07:18:34.339016 29777 net.cpp:1851] conv1b_param_0(0.49) 
I0630 07:18:34.339020 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:18:34.339023 29777 net.cpp:1851] res2a_branch2a_param_0(0.49) 
I0630 07:18:34.339028 29777 net.cpp:1851] res2a_branch2b_param_0(0.49) 
I0630 07:18:34.339032 29777 net.cpp:1851] res3a_branch2a_param_0(0.49) 
I0630 07:18:34.339035 29777 net.cpp:1851] res3a_branch2b_param_0(0.49) 
I0630 07:18:34.339038 29777 net.cpp:1851] res4a_branch2a_param_0(0.49) 
I0630 07:18:34.339041 29777 net.cpp:1851] res4a_branch2b_param_0(0.49) 
I0630 07:18:34.339045 29777 net.cpp:1851] res5a_branch2a_param_0(0.49) 
I0630 07:18:34.339047 29777 net.cpp:1851] res5a_branch2b_param_0(0.49) 
I0630 07:18:34.339051 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.15324e+06/2.86678e+06) 0.402
I0630 07:18:34.497432 29777 solver.cpp:290] Iteration 97000 (6.17663 iter/s, 16.1901s/100 iter), loss = 1.4881
I0630 07:18:34.497459 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 07:18:34.497467 29777 sgd_solver.cpp:106] Iteration 97000, lr = 0.00696875
I0630 07:18:50.759623 29777 solver.cpp:290] Iteration 97100 (6.14941 iter/s, 16.2617s/100 iter), loss = 0.97619
I0630 07:18:50.759645 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:18:50.759652 29777 sgd_solver.cpp:106] Iteration 97100, lr = 0.00696563
I0630 07:19:06.828428 29777 solver.cpp:290] Iteration 97200 (6.22342 iter/s, 16.0683s/100 iter), loss = 1.30952
I0630 07:19:06.828558 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 07:19:06.828583 29777 sgd_solver.cpp:106] Iteration 97200, lr = 0.0069625
I0630 07:19:22.927889 29777 solver.cpp:290] Iteration 97300 (6.21161 iter/s, 16.0989s/100 iter), loss = 1.03571
I0630 07:19:22.927917 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 07:19:22.927927 29777 sgd_solver.cpp:106] Iteration 97300, lr = 0.00695937
I0630 07:19:39.138386 29777 solver.cpp:290] Iteration 97400 (6.16902 iter/s, 16.21s/100 iter), loss = 0.821429
I0630 07:19:39.138476 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:19:39.138487 29777 sgd_solver.cpp:106] Iteration 97400, lr = 0.00695625
I0630 07:19:55.381108 29777 solver.cpp:290] Iteration 97500 (6.15681 iter/s, 16.2422s/100 iter), loss = 1
I0630 07:19:55.381136 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 07:19:55.381146 29777 sgd_solver.cpp:106] Iteration 97500, lr = 0.00695312
I0630 07:20:11.444953 29777 solver.cpp:290] Iteration 97600 (6.22534 iter/s, 16.0634s/100 iter), loss = 0.940476
I0630 07:20:11.445060 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:20:11.445073 29777 sgd_solver.cpp:106] Iteration 97600, lr = 0.00695
I0630 07:20:27.710088 29777 solver.cpp:290] Iteration 97700 (6.14833 iter/s, 16.2646s/100 iter), loss = 1.5
I0630 07:20:27.710115 29777 solver.cpp:309]     Train net output #0: loss = 1.97619 (* 1 = 1.97619 loss)
I0630 07:20:27.710125 29777 sgd_solver.cpp:106] Iteration 97700, lr = 0.00694687
I0630 07:20:43.902027 29777 solver.cpp:290] Iteration 97800 (6.1761 iter/s, 16.1915s/100 iter), loss = 1.22619
I0630 07:20:43.902165 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:20:43.902182 29777 sgd_solver.cpp:106] Iteration 97800, lr = 0.00694375
I0630 07:21:00.107983 29777 solver.cpp:290] Iteration 97900 (6.17079 iter/s, 16.2054s/100 iter), loss = 1.25
I0630 07:21:00.108044 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 07:21:00.108065 29777 sgd_solver.cpp:106] Iteration 97900, lr = 0.00694062
I0630 07:21:15.956831 29777 solver.cpp:354] Sparsity after update:
I0630 07:21:15.960362 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:21:15.960376 29777 net.cpp:1851] conv1a_param_0(0.245) 
I0630 07:21:15.960387 29777 net.cpp:1851] conv1b_param_0(0.49) 
I0630 07:21:15.960392 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:21:15.960397 29777 net.cpp:1851] res2a_branch2a_param_0(0.49) 
I0630 07:21:15.960400 29777 net.cpp:1851] res2a_branch2b_param_0(0.49) 
I0630 07:21:15.960404 29777 net.cpp:1851] res3a_branch2a_param_0(0.49) 
I0630 07:21:15.960410 29777 net.cpp:1851] res3a_branch2b_param_0(0.49) 
I0630 07:21:15.960417 29777 net.cpp:1851] res4a_branch2a_param_0(0.49) 
I0630 07:21:15.960422 29777 net.cpp:1851] res4a_branch2b_param_0(0.49) 
I0630 07:21:15.960427 29777 net.cpp:1851] res5a_branch2a_param_0(0.49) 
I0630 07:21:15.960433 29777 net.cpp:1851] res5a_branch2b_param_0(0.49) 
I0630 07:21:15.960438 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.15324e+06/2.86678e+06) 0.402
I0630 07:21:15.960608 29777 solver.cpp:471] Iteration 98000, Testing net (#0)
I0630 07:21:25.056980 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:22:18.236917 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5747
I0630 07:22:18.236977 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806081
I0630 07:22:18.236987 29777 solver.cpp:544]     Test net output #2: loss = 1.51332 (* 1 = 1.51332 loss)
I0630 07:22:18.457389 29777 solver.cpp:290] Iteration 98000 (1.27637 iter/s, 78.3472s/100 iter), loss = 1.04762
I0630 07:22:18.457415 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:22:18.457423 29777 sgd_solver.cpp:106] Iteration 98000, lr = 0.0069375
I0630 07:22:18.458171 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.5
I0630 07:22:18.796192 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:22:34.223121 29777 solver.cpp:290] Iteration 98100 (6.34306 iter/s, 15.7653s/100 iter), loss = 1.45238
I0630 07:22:34.223147 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:22:34.223156 29777 sgd_solver.cpp:106] Iteration 98100, lr = 0.00693437
I0630 07:22:50.304414 29777 solver.cpp:290] Iteration 98200 (6.21859 iter/s, 16.0808s/100 iter), loss = 0.845238
I0630 07:22:50.304515 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:22:50.304527 29777 sgd_solver.cpp:106] Iteration 98200, lr = 0.00693125
I0630 07:23:06.415215 29777 solver.cpp:290] Iteration 98300 (6.20723 iter/s, 16.1103s/100 iter), loss = 1.08333
I0630 07:23:06.415237 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:23:06.415244 29777 sgd_solver.cpp:106] Iteration 98300, lr = 0.00692812
I0630 07:23:22.468160 29777 solver.cpp:290] Iteration 98400 (6.22957 iter/s, 16.0525s/100 iter), loss = 1.36905
I0630 07:23:22.468264 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 07:23:22.468273 29777 sgd_solver.cpp:106] Iteration 98400, lr = 0.006925
I0630 07:23:38.567101 29777 solver.cpp:290] Iteration 98500 (6.2118 iter/s, 16.0984s/100 iter), loss = 1.10714
I0630 07:23:38.567128 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:23:38.567137 29777 sgd_solver.cpp:106] Iteration 98500, lr = 0.00692187
I0630 07:23:54.707849 29777 solver.cpp:290] Iteration 98600 (6.19568 iter/s, 16.1403s/100 iter), loss = 0.714286
I0630 07:23:54.707979 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:23:54.707995 29777 sgd_solver.cpp:106] Iteration 98600, lr = 0.00691875
I0630 07:24:10.934453 29777 solver.cpp:290] Iteration 98700 (6.16294 iter/s, 16.226s/100 iter), loss = 1.11905
I0630 07:24:10.934478 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:24:10.934486 29777 sgd_solver.cpp:106] Iteration 98700, lr = 0.00691563
I0630 07:24:27.420579 29777 solver.cpp:290] Iteration 98800 (6.06588 iter/s, 16.4856s/100 iter), loss = 1.45238
I0630 07:24:27.420686 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 07:24:27.420696 29777 sgd_solver.cpp:106] Iteration 98800, lr = 0.0069125
I0630 07:24:43.760769 29777 solver.cpp:290] Iteration 98900 (6.12009 iter/s, 16.3396s/100 iter), loss = 1.10714
I0630 07:24:43.760794 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:24:43.760804 29777 sgd_solver.cpp:106] Iteration 98900, lr = 0.00690938
I0630 07:24:59.855713 29777 solver.cpp:354] Sparsity after update:
I0630 07:24:59.876938 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:24:59.876974 29777 net.cpp:1851] conv1a_param_0(0.25) 
I0630 07:24:59.876997 29777 net.cpp:1851] conv1b_param_0(0.5) 
I0630 07:24:59.877007 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:24:59.877017 29777 net.cpp:1851] res2a_branch2a_param_0(0.5) 
I0630 07:24:59.877025 29777 net.cpp:1851] res2a_branch2b_param_0(0.5) 
I0630 07:24:59.877037 29777 net.cpp:1851] res3a_branch2a_param_0(0.5) 
I0630 07:24:59.877044 29777 net.cpp:1851] res3a_branch2b_param_0(0.5) 
I0630 07:24:59.877053 29777 net.cpp:1851] res4a_branch2a_param_0(0.5) 
I0630 07:24:59.877061 29777 net.cpp:1851] res4a_branch2b_param_0(0.5) 
I0630 07:24:59.877069 29777 net.cpp:1851] res5a_branch2a_param_0(0.5) 
I0630 07:24:59.877079 29777 net.cpp:1851] res5a_branch2b_param_0(0.5) 
I0630 07:24:59.877086 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.17678e+06/2.86678e+06) 0.41
I0630 07:25:00.037503 29777 solver.cpp:290] Iteration 99000 (6.14392 iter/s, 16.2763s/100 iter), loss = 0.916667
I0630 07:25:00.037528 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:25:00.037537 29777 sgd_solver.cpp:106] Iteration 99000, lr = 0.00690625
I0630 07:25:16.300492 29777 solver.cpp:290] Iteration 99100 (6.14911 iter/s, 16.2625s/100 iter), loss = 1.04762
I0630 07:25:16.300513 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:25:16.300520 29777 sgd_solver.cpp:106] Iteration 99100, lr = 0.00690312
I0630 07:25:32.770664 29777 solver.cpp:290] Iteration 99200 (6.07176 iter/s, 16.4697s/100 iter), loss = 1.04762
I0630 07:25:32.770773 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:25:32.770782 29777 sgd_solver.cpp:106] Iteration 99200, lr = 0.0069
I0630 07:25:49.023319 29777 solver.cpp:290] Iteration 99300 (6.15305 iter/s, 16.2521s/100 iter), loss = 0.880952
I0630 07:25:49.023347 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:25:49.023356 29777 sgd_solver.cpp:106] Iteration 99300, lr = 0.00689687
I0630 07:26:05.158578 29777 solver.cpp:290] Iteration 99400 (6.19779 iter/s, 16.1348s/100 iter), loss = 1.10714
I0630 07:26:05.158640 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:26:05.158648 29777 sgd_solver.cpp:106] Iteration 99400, lr = 0.00689375
I0630 07:26:21.609359 29777 solver.cpp:290] Iteration 99500 (6.07893 iter/s, 16.4503s/100 iter), loss = 0.857143
I0630 07:26:21.609382 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 07:26:21.609401 29777 sgd_solver.cpp:106] Iteration 99500, lr = 0.00689062
I0630 07:26:37.972930 29777 solver.cpp:290] Iteration 99600 (6.11131 iter/s, 16.3631s/100 iter), loss = 0.833333
I0630 07:26:37.973026 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 07:26:37.973033 29777 sgd_solver.cpp:106] Iteration 99600, lr = 0.0068875
I0630 07:26:54.382437 29777 solver.cpp:290] Iteration 99700 (6.09423 iter/s, 16.409s/100 iter), loss = 1.02381
I0630 07:26:54.382470 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:26:54.382478 29777 sgd_solver.cpp:106] Iteration 99700, lr = 0.00688437
I0630 07:27:10.666761 29777 solver.cpp:290] Iteration 99800 (6.14106 iter/s, 16.2838s/100 iter), loss = 0.702381
I0630 07:27:10.666808 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:27:10.666816 29777 sgd_solver.cpp:106] Iteration 99800, lr = 0.00688125
I0630 07:27:27.015818 29777 solver.cpp:290] Iteration 99900 (6.11675 iter/s, 16.3486s/100 iter), loss = 1.2619
I0630 07:27:27.015844 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 07:27:27.015852 29777 sgd_solver.cpp:106] Iteration 99900, lr = 0.00687813
I0630 07:27:43.451939 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_100000.caffemodel
I0630 07:27:43.477591 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_100000.solverstate
I0630 07:27:43.486457 29777 solver.cpp:354] Sparsity after update:
I0630 07:27:43.487548 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:27:43.487558 29777 net.cpp:1851] conv1a_param_0(0.25) 
I0630 07:27:43.487567 29777 net.cpp:1851] conv1b_param_0(0.5) 
I0630 07:27:43.487570 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:27:43.487571 29777 net.cpp:1851] res2a_branch2a_param_0(0.5) 
I0630 07:27:43.487573 29777 net.cpp:1851] res2a_branch2b_param_0(0.5) 
I0630 07:27:43.487576 29777 net.cpp:1851] res3a_branch2a_param_0(0.5) 
I0630 07:27:43.487577 29777 net.cpp:1851] res3a_branch2b_param_0(0.5) 
I0630 07:27:43.487579 29777 net.cpp:1851] res4a_branch2a_param_0(0.5) 
I0630 07:27:43.487581 29777 net.cpp:1851] res4a_branch2b_param_0(0.5) 
I0630 07:27:43.487583 29777 net.cpp:1851] res5a_branch2a_param_0(0.5) 
I0630 07:27:43.487586 29777 net.cpp:1851] res5a_branch2b_param_0(0.5) 
I0630 07:27:43.487587 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.17678e+06/2.86678e+06) 0.41
I0630 07:27:43.487690 29777 solver.cpp:471] Iteration 100000, Testing net (#0)
I0630 07:27:54.503427 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:28:48.337787 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5721
I0630 07:28:48.337893 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804821
I0630 07:28:48.337903 29777 solver.cpp:544]     Test net output #2: loss = 1.509 (* 1 = 1.509 loss)
I0630 07:28:48.582720 29777 solver.cpp:290] Iteration 100000 (1.22602 iter/s, 81.5647s/100 iter), loss = 1.04762
I0630 07:28:48.582770 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:28:48.582784 29777 sgd_solver.cpp:106] Iteration 100000, lr = 0.006875
I0630 07:28:48.584121 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.51
I0630 07:28:49.276468 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:29:05.059249 29777 solver.cpp:290] Iteration 100100 (6.06943 iter/s, 16.476s/100 iter), loss = 1.30952
I0630 07:29:05.059274 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 07:29:05.059284 29777 sgd_solver.cpp:106] Iteration 100100, lr = 0.00687187
I0630 07:29:21.282745 29777 solver.cpp:290] Iteration 100200 (6.16408 iter/s, 16.223s/100 iter), loss = 1.10714
I0630 07:29:21.282819 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:29:21.282826 29777 sgd_solver.cpp:106] Iteration 100200, lr = 0.00686875
I0630 07:29:37.506414 29777 solver.cpp:290] Iteration 100300 (6.16403 iter/s, 16.2231s/100 iter), loss = 1.20238
I0630 07:29:37.506470 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 07:29:37.506494 29777 sgd_solver.cpp:106] Iteration 100300, lr = 0.00686563
I0630 07:29:53.816896 29777 solver.cpp:290] Iteration 100400 (6.13121 iter/s, 16.31s/100 iter), loss = 1.04762
I0630 07:29:53.817013 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 07:29:53.817023 29777 sgd_solver.cpp:106] Iteration 100400, lr = 0.0068625
I0630 07:30:10.165825 29777 solver.cpp:290] Iteration 100500 (6.11682 iter/s, 16.3484s/100 iter), loss = 1.28571
I0630 07:30:10.165848 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 07:30:10.165854 29777 sgd_solver.cpp:106] Iteration 100500, lr = 0.00685938
I0630 07:30:26.564766 29777 solver.cpp:290] Iteration 100600 (6.09814 iter/s, 16.3985s/100 iter), loss = 0.821429
I0630 07:30:26.564910 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:30:26.564950 29777 sgd_solver.cpp:106] Iteration 100600, lr = 0.00685625
I0630 07:30:42.780472 29777 solver.cpp:290] Iteration 100700 (6.16708 iter/s, 16.2151s/100 iter), loss = 1.16667
I0630 07:30:42.780498 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 07:30:42.780508 29777 sgd_solver.cpp:106] Iteration 100700, lr = 0.00685313
I0630 07:30:59.019151 29777 solver.cpp:290] Iteration 100800 (6.15832 iter/s, 16.2382s/100 iter), loss = 1.19048
I0630 07:30:59.019254 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:30:59.019264 29777 sgd_solver.cpp:106] Iteration 100800, lr = 0.00685
I0630 07:31:15.268990 29777 solver.cpp:290] Iteration 100900 (6.15411 iter/s, 16.2493s/100 iter), loss = 0.797619
I0630 07:31:15.269014 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:31:15.269023 29777 sgd_solver.cpp:106] Iteration 100900, lr = 0.00684687
I0630 07:31:31.463002 29777 solver.cpp:354] Sparsity after update:
I0630 07:31:31.483280 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:31:31.483297 29777 net.cpp:1851] conv1a_param_0(0.255) 
I0630 07:31:31.483309 29777 net.cpp:1851] conv1b_param_0(0.51) 
I0630 07:31:31.483314 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:31:31.483324 29777 net.cpp:1851] res2a_branch2a_param_0(0.51) 
I0630 07:31:31.483330 29777 net.cpp:1851] res2a_branch2b_param_0(0.51) 
I0630 07:31:31.483335 29777 net.cpp:1851] res3a_branch2a_param_0(0.51) 
I0630 07:31:31.483340 29777 net.cpp:1851] res3a_branch2b_param_0(0.51) 
I0630 07:31:31.483345 29777 net.cpp:1851] res4a_branch2a_param_0(0.51) 
I0630 07:31:31.483350 29777 net.cpp:1851] res4a_branch2b_param_0(0.51) 
I0630 07:31:31.483355 29777 net.cpp:1851] res5a_branch2a_param_0(0.51) 
I0630 07:31:31.483357 29777 net.cpp:1851] res5a_branch2b_param_0(0.51) 
I0630 07:31:31.483361 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.20032e+06/2.86678e+06) 0.419
I0630 07:31:31.704705 29777 solver.cpp:290] Iteration 101000 (6.08449 iter/s, 16.4352s/100 iter), loss = 1.19048
I0630 07:31:31.704758 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 07:31:31.704780 29777 sgd_solver.cpp:106] Iteration 101000, lr = 0.00684375
I0630 07:31:47.995200 29777 solver.cpp:290] Iteration 101100 (6.13874 iter/s, 16.29s/100 iter), loss = 0.797619
I0630 07:31:47.995227 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:31:47.995236 29777 sgd_solver.cpp:106] Iteration 101100, lr = 0.00684062
I0630 07:32:04.316638 29777 solver.cpp:290] Iteration 101200 (6.12709 iter/s, 16.321s/100 iter), loss = 1.2381
I0630 07:32:04.316689 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:32:04.316705 29777 sgd_solver.cpp:106] Iteration 101200, lr = 0.0068375
I0630 07:32:20.473383 29777 solver.cpp:290] Iteration 101300 (6.18956 iter/s, 16.1562s/100 iter), loss = 1.2381
I0630 07:32:20.473410 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 07:32:20.473418 29777 sgd_solver.cpp:106] Iteration 101300, lr = 0.00683437
I0630 07:32:36.688289 29777 solver.cpp:290] Iteration 101400 (6.16735 iter/s, 16.2144s/100 iter), loss = 1.27381
I0630 07:32:36.688407 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:32:36.688417 29777 sgd_solver.cpp:106] Iteration 101400, lr = 0.00683125
I0630 07:32:53.026412 29777 solver.cpp:290] Iteration 101500 (6.12087 iter/s, 16.3376s/100 iter), loss = 1.16667
I0630 07:32:53.026432 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 07:32:53.026439 29777 sgd_solver.cpp:106] Iteration 101500, lr = 0.00682813
I0630 07:33:09.079766 29777 solver.cpp:290] Iteration 101600 (6.22941 iter/s, 16.0529s/100 iter), loss = 0.857143
I0630 07:33:09.079874 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 07:33:09.079888 29777 sgd_solver.cpp:106] Iteration 101600, lr = 0.006825
I0630 07:33:25.285321 29777 solver.cpp:290] Iteration 101700 (6.17093 iter/s, 16.205s/100 iter), loss = 1.32143
I0630 07:33:25.285343 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 07:33:25.285351 29777 sgd_solver.cpp:106] Iteration 101700, lr = 0.00682187
I0630 07:33:42.128540 29777 solver.cpp:290] Iteration 101800 (5.93728 iter/s, 16.8427s/100 iter), loss = 0.97619
I0630 07:33:42.128618 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:33:42.128630 29777 sgd_solver.cpp:106] Iteration 101800, lr = 0.00681875
I0630 07:33:58.287410 29777 solver.cpp:290] Iteration 101900 (6.18875 iter/s, 16.1584s/100 iter), loss = 1.0119
I0630 07:33:58.287433 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 07:33:58.287441 29777 sgd_solver.cpp:106] Iteration 101900, lr = 0.00681563
I0630 07:34:14.157063 29777 solver.cpp:354] Sparsity after update:
I0630 07:34:14.158525 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:34:14.158534 29777 net.cpp:1851] conv1a_param_0(0.255) 
I0630 07:34:14.158540 29777 net.cpp:1851] conv1b_param_0(0.51) 
I0630 07:34:14.158541 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:34:14.158543 29777 net.cpp:1851] res2a_branch2a_param_0(0.51) 
I0630 07:34:14.158545 29777 net.cpp:1851] res2a_branch2b_param_0(0.51) 
I0630 07:34:14.158547 29777 net.cpp:1851] res3a_branch2a_param_0(0.51) 
I0630 07:34:14.158550 29777 net.cpp:1851] res3a_branch2b_param_0(0.51) 
I0630 07:34:14.158551 29777 net.cpp:1851] res4a_branch2a_param_0(0.51) 
I0630 07:34:14.158553 29777 net.cpp:1851] res4a_branch2b_param_0(0.51) 
I0630 07:34:14.158555 29777 net.cpp:1851] res5a_branch2a_param_0(0.51) 
I0630 07:34:14.158557 29777 net.cpp:1851] res5a_branch2b_param_0(0.51) 
I0630 07:34:14.158560 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.20032e+06/2.86678e+06) 0.419
I0630 07:34:14.158651 29777 solver.cpp:471] Iteration 102000, Testing net (#0)
I0630 07:34:24.705775 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:35:15.351846 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.571659
I0630 07:35:15.351949 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804861
I0630 07:35:15.351960 29777 solver.cpp:544]     Test net output #2: loss = 1.52482 (* 1 = 1.52482 loss)
I0630 07:35:15.532583 29777 solver.cpp:290] Iteration 102000 (1.29461 iter/s, 77.243s/100 iter), loss = 1.35714
I0630 07:35:15.532609 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 07:35:15.532618 29777 sgd_solver.cpp:106] Iteration 102000, lr = 0.0068125
I0630 07:35:15.533602 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.52
I0630 07:35:16.082391 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:35:31.587787 29777 solver.cpp:290] Iteration 102100 (6.22869 iter/s, 16.0547s/100 iter), loss = 1.32143
I0630 07:35:31.587810 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 07:35:31.587816 29777 sgd_solver.cpp:106] Iteration 102100, lr = 0.00680938
I0630 07:35:47.613355 29777 solver.cpp:290] Iteration 102200 (6.24021 iter/s, 16.0251s/100 iter), loss = 1.5
I0630 07:35:47.613481 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 07:35:47.613490 29777 sgd_solver.cpp:106] Iteration 102200, lr = 0.00680625
I0630 07:36:03.750735 29777 solver.cpp:290] Iteration 102300 (6.19701 iter/s, 16.1368s/100 iter), loss = 1.17857
I0630 07:36:03.750761 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:36:03.750766 29777 sgd_solver.cpp:106] Iteration 102300, lr = 0.00680313
I0630 07:36:20.077519 29777 solver.cpp:290] Iteration 102400 (6.12509 iter/s, 16.3263s/100 iter), loss = 1.15476
I0630 07:36:20.077628 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:36:20.077652 29777 sgd_solver.cpp:106] Iteration 102400, lr = 0.0068
I0630 07:36:36.115378 29777 solver.cpp:290] Iteration 102500 (6.23546 iter/s, 16.0373s/100 iter), loss = 1
I0630 07:36:36.115404 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:36:36.115413 29777 sgd_solver.cpp:106] Iteration 102500, lr = 0.00679688
I0630 07:36:52.219579 29777 solver.cpp:290] Iteration 102600 (6.20974 iter/s, 16.1037s/100 iter), loss = 1.04762
I0630 07:36:52.219652 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 07:36:52.219660 29777 sgd_solver.cpp:106] Iteration 102600, lr = 0.00679375
I0630 07:37:08.411275 29777 solver.cpp:290] Iteration 102700 (6.1762 iter/s, 16.1912s/100 iter), loss = 0.928571
I0630 07:37:08.411299 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 07:37:08.411306 29777 sgd_solver.cpp:106] Iteration 102700, lr = 0.00679062
I0630 07:37:24.610047 29777 solver.cpp:290] Iteration 102800 (6.17349 iter/s, 16.1983s/100 iter), loss = 0.904762
I0630 07:37:24.610121 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 07:37:24.610131 29777 sgd_solver.cpp:106] Iteration 102800, lr = 0.0067875
I0630 07:37:40.651485 29777 solver.cpp:290] Iteration 102900 (6.23406 iter/s, 16.0409s/100 iter), loss = 0.892857
I0630 07:37:40.651513 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 07:37:40.651522 29777 sgd_solver.cpp:106] Iteration 102900, lr = 0.00678437
I0630 07:37:56.640216 29777 solver.cpp:354] Sparsity after update:
I0630 07:37:56.660684 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:37:56.660697 29777 net.cpp:1851] conv1a_param_0(0.26) 
I0630 07:37:56.660708 29777 net.cpp:1851] conv1b_param_0(0.52) 
I0630 07:37:56.660712 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:37:56.660718 29777 net.cpp:1851] res2a_branch2a_param_0(0.52) 
I0630 07:37:56.660722 29777 net.cpp:1851] res2a_branch2b_param_0(0.52) 
I0630 07:37:56.660727 29777 net.cpp:1851] res3a_branch2a_param_0(0.52) 
I0630 07:37:56.660729 29777 net.cpp:1851] res3a_branch2b_param_0(0.52) 
I0630 07:37:56.660733 29777 net.cpp:1851] res4a_branch2a_param_0(0.52) 
I0630 07:37:56.660737 29777 net.cpp:1851] res4a_branch2b_param_0(0.52) 
I0630 07:37:56.660742 29777 net.cpp:1851] res5a_branch2a_param_0(0.52) 
I0630 07:37:56.660745 29777 net.cpp:1851] res5a_branch2b_param_0(0.52) 
I0630 07:37:56.660749 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.22386e+06/2.86678e+06) 0.427
I0630 07:37:56.816612 29777 solver.cpp:290] Iteration 103000 (6.18634 iter/s, 16.1647s/100 iter), loss = 0.892857
I0630 07:37:56.816637 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 07:37:56.816646 29777 sgd_solver.cpp:106] Iteration 103000, lr = 0.00678125
I0630 07:38:12.949226 29777 solver.cpp:290] Iteration 103100 (6.19881 iter/s, 16.1321s/100 iter), loss = 1.03571
I0630 07:38:12.949329 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:38:12.949363 29777 sgd_solver.cpp:106] Iteration 103100, lr = 0.00677812
I0630 07:38:29.257956 29777 solver.cpp:290] Iteration 103200 (6.13189 iter/s, 16.3082s/100 iter), loss = 1.03571
I0630 07:38:29.258092 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 07:38:29.258107 29777 sgd_solver.cpp:106] Iteration 103200, lr = 0.006775
I0630 07:38:45.199625 29777 solver.cpp:290] Iteration 103300 (6.27309 iter/s, 15.9411s/100 iter), loss = 0.845238
I0630 07:38:45.199651 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:38:45.199661 29777 sgd_solver.cpp:106] Iteration 103300, lr = 0.00677188
I0630 07:39:01.231135 29777 solver.cpp:290] Iteration 103400 (6.2379 iter/s, 16.031s/100 iter), loss = 1
I0630 07:39:01.231227 29777 solver.cpp:309]     Train net output #0: loss = 0.595238 (* 1 = 0.595238 loss)
I0630 07:39:01.231240 29777 sgd_solver.cpp:106] Iteration 103400, lr = 0.00676875
I0630 07:39:17.423539 29777 solver.cpp:290] Iteration 103500 (6.17594 iter/s, 16.1919s/100 iter), loss = 1.15476
I0630 07:39:17.423563 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:39:17.423569 29777 sgd_solver.cpp:106] Iteration 103500, lr = 0.00676562
I0630 07:39:33.627444 29777 solver.cpp:290] Iteration 103600 (6.17153 iter/s, 16.2034s/100 iter), loss = 1.10714
I0630 07:39:33.627516 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:39:33.627523 29777 sgd_solver.cpp:106] Iteration 103600, lr = 0.0067625
I0630 07:39:49.925143 29777 solver.cpp:290] Iteration 103700 (6.13603 iter/s, 16.2972s/100 iter), loss = 1
I0630 07:39:49.925173 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:39:49.925179 29777 sgd_solver.cpp:106] Iteration 103700, lr = 0.00675938
I0630 07:40:06.114267 29777 solver.cpp:290] Iteration 103800 (6.17717 iter/s, 16.1886s/100 iter), loss = 0.797619
I0630 07:40:06.114362 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 07:40:06.114373 29777 sgd_solver.cpp:106] Iteration 103800, lr = 0.00675625
I0630 07:40:22.753217 29777 solver.cpp:290] Iteration 103900 (6.01019 iter/s, 16.6384s/100 iter), loss = 1.32143
I0630 07:40:22.753240 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:40:22.753247 29777 sgd_solver.cpp:106] Iteration 103900, lr = 0.00675313
I0630 07:40:39.114748 29777 solver.cpp:354] Sparsity after update:
I0630 07:40:39.117218 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:40:39.117238 29777 net.cpp:1851] conv1a_param_0(0.26) 
I0630 07:40:39.117261 29777 net.cpp:1851] conv1b_param_0(0.52) 
I0630 07:40:39.117272 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:40:39.117281 29777 net.cpp:1851] res2a_branch2a_param_0(0.52) 
I0630 07:40:39.117290 29777 net.cpp:1851] res2a_branch2b_param_0(0.52) 
I0630 07:40:39.117300 29777 net.cpp:1851] res3a_branch2a_param_0(0.52) 
I0630 07:40:39.117308 29777 net.cpp:1851] res3a_branch2b_param_0(0.52) 
I0630 07:40:39.117317 29777 net.cpp:1851] res4a_branch2a_param_0(0.52) 
I0630 07:40:39.117326 29777 net.cpp:1851] res4a_branch2b_param_0(0.52) 
I0630 07:40:39.117334 29777 net.cpp:1851] res5a_branch2a_param_0(0.52) 
I0630 07:40:39.117342 29777 net.cpp:1851] res5a_branch2b_param_0(0.52) 
I0630 07:40:39.117352 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.22386e+06/2.86678e+06) 0.427
I0630 07:40:39.117529 29777 solver.cpp:471] Iteration 104000, Testing net (#0)
I0630 07:40:52.617594 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:41:48.303063 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57362
I0630 07:41:48.303138 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.805801
I0630 07:41:48.303145 29777 solver.cpp:544]     Test net output #2: loss = 1.51788 (* 1 = 1.51788 loss)
I0630 07:41:48.549633 29777 solver.cpp:290] Iteration 104000 (1.16558 iter/s, 85.794s/100 iter), loss = 0.964286
I0630 07:41:48.549676 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:41:48.549690 29777 sgd_solver.cpp:106] Iteration 104000, lr = 0.00675
I0630 07:41:48.551014 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.53
I0630 07:41:48.982612 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:42:04.553561 29777 solver.cpp:290] Iteration 104100 (6.24865 iter/s, 16.0034s/100 iter), loss = 1.03571
I0630 07:42:04.553583 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 07:42:04.553589 29777 sgd_solver.cpp:106] Iteration 104100, lr = 0.00674688
I0630 07:42:20.772212 29777 solver.cpp:290] Iteration 104200 (6.16592 iter/s, 16.2182s/100 iter), loss = 1.10714
I0630 07:42:20.772343 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 07:42:20.772357 29777 sgd_solver.cpp:106] Iteration 104200, lr = 0.00674375
I0630 07:42:36.914286 29777 solver.cpp:290] Iteration 104300 (6.19521 iter/s, 16.1415s/100 iter), loss = 1.30952
I0630 07:42:36.914311 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 07:42:36.914320 29777 sgd_solver.cpp:106] Iteration 104300, lr = 0.00674062
I0630 07:42:53.472534 29777 solver.cpp:290] Iteration 104400 (6.03946 iter/s, 16.5578s/100 iter), loss = 0.952381
I0630 07:42:53.472666 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 07:42:53.472687 29777 sgd_solver.cpp:106] Iteration 104400, lr = 0.0067375
I0630 07:43:09.990480 29777 solver.cpp:290] Iteration 104500 (6.05424 iter/s, 16.5174s/100 iter), loss = 0.892857
I0630 07:43:09.990530 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 07:43:09.990551 29777 sgd_solver.cpp:106] Iteration 104500, lr = 0.00673437
I0630 07:43:26.352824 29777 solver.cpp:290] Iteration 104600 (6.11178 iter/s, 16.3619s/100 iter), loss = 1.08333
I0630 07:43:26.352903 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 07:43:26.352913 29777 sgd_solver.cpp:106] Iteration 104600, lr = 0.00673125
I0630 07:43:42.606130 29777 solver.cpp:290] Iteration 104700 (6.1528 iter/s, 16.2528s/100 iter), loss = 1.13095
I0630 07:43:42.606209 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:43:42.606243 29777 sgd_solver.cpp:106] Iteration 104700, lr = 0.00672812
I0630 07:43:58.864976 29777 solver.cpp:290] Iteration 104800 (6.1507 iter/s, 16.2583s/100 iter), loss = 0.988095
I0630 07:43:58.865078 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:43:58.865101 29777 sgd_solver.cpp:106] Iteration 104800, lr = 0.006725
I0630 07:44:15.182354 29777 solver.cpp:290] Iteration 104900 (6.12864 iter/s, 16.3168s/100 iter), loss = 1.04762
I0630 07:44:15.182384 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:44:15.182395 29777 sgd_solver.cpp:106] Iteration 104900, lr = 0.00672187
I0630 07:44:31.304615 29777 solver.cpp:354] Sparsity after update:
I0630 07:44:31.325371 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:44:31.325400 29777 net.cpp:1851] conv1a_param_0(0.265) 
I0630 07:44:31.325412 29777 net.cpp:1851] conv1b_param_0(0.53) 
I0630 07:44:31.325417 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:44:31.325419 29777 net.cpp:1851] res2a_branch2a_param_0(0.53) 
I0630 07:44:31.325423 29777 net.cpp:1851] res2a_branch2b_param_0(0.53) 
I0630 07:44:31.325428 29777 net.cpp:1851] res3a_branch2a_param_0(0.53) 
I0630 07:44:31.325430 29777 net.cpp:1851] res3a_branch2b_param_0(0.53) 
I0630 07:44:31.325434 29777 net.cpp:1851] res4a_branch2a_param_0(0.53) 
I0630 07:44:31.325438 29777 net.cpp:1851] res4a_branch2b_param_0(0.53) 
I0630 07:44:31.325440 29777 net.cpp:1851] res5a_branch2a_param_0(0.53) 
I0630 07:44:31.325443 29777 net.cpp:1851] res5a_branch2b_param_0(0.53) 
I0630 07:44:31.325446 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.24739e+06/2.86678e+06) 0.435
I0630 07:44:31.487812 29777 solver.cpp:290] Iteration 105000 (6.1331 iter/s, 16.305s/100 iter), loss = 0.928571
I0630 07:44:31.487843 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:44:31.487851 29777 sgd_solver.cpp:106] Iteration 105000, lr = 0.00671875
I0630 07:44:47.665801 29777 solver.cpp:290] Iteration 105100 (6.18142 iter/s, 16.1775s/100 iter), loss = 1
I0630 07:44:47.665823 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:44:47.665830 29777 sgd_solver.cpp:106] Iteration 105100, lr = 0.00671562
I0630 07:45:03.852416 29777 solver.cpp:290] Iteration 105200 (6.17813 iter/s, 16.1861s/100 iter), loss = 1.25
I0630 07:45:03.852524 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:45:03.852553 29777 sgd_solver.cpp:106] Iteration 105200, lr = 0.0067125
I0630 07:45:20.080515 29777 solver.cpp:290] Iteration 105300 (6.16236 iter/s, 16.2276s/100 iter), loss = 1.09524
I0630 07:45:20.080538 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:45:20.080545 29777 sgd_solver.cpp:106] Iteration 105300, lr = 0.00670938
I0630 07:45:36.430857 29777 solver.cpp:290] Iteration 105400 (6.11626 iter/s, 16.3499s/100 iter), loss = 1.03571
I0630 07:45:36.430920 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:45:36.430928 29777 sgd_solver.cpp:106] Iteration 105400, lr = 0.00670625
I0630 07:45:52.795323 29777 solver.cpp:290] Iteration 105500 (6.11099 iter/s, 16.364s/100 iter), loss = 0.880952
I0630 07:45:52.795351 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 07:45:52.795359 29777 sgd_solver.cpp:106] Iteration 105500, lr = 0.00670313
I0630 07:46:08.991853 29777 solver.cpp:290] Iteration 105600 (6.17434 iter/s, 16.1961s/100 iter), loss = 1.20238
I0630 07:46:08.991961 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 07:46:08.991971 29777 sgd_solver.cpp:106] Iteration 105600, lr = 0.0067
I0630 07:46:25.340873 29777 solver.cpp:290] Iteration 105700 (6.11678 iter/s, 16.3485s/100 iter), loss = 1.04762
I0630 07:46:25.340896 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 07:46:25.340903 29777 sgd_solver.cpp:106] Iteration 105700, lr = 0.00669687
I0630 07:46:41.699932 29777 solver.cpp:290] Iteration 105800 (6.113 iter/s, 16.3586s/100 iter), loss = 0.833333
I0630 07:46:41.700059 29777 solver.cpp:309]     Train net output #0: loss = 0.47619 (* 1 = 0.47619 loss)
I0630 07:46:41.700080 29777 sgd_solver.cpp:106] Iteration 105800, lr = 0.00669375
I0630 07:46:58.056116 29777 solver.cpp:290] Iteration 105900 (6.11411 iter/s, 16.3556s/100 iter), loss = 1.2381
I0630 07:46:58.056138 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 07:46:58.056145 29777 sgd_solver.cpp:106] Iteration 105900, lr = 0.00669062
I0630 07:47:13.987532 29777 solver.cpp:354] Sparsity after update:
I0630 07:47:13.988951 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:47:13.988960 29777 net.cpp:1851] conv1a_param_0(0.265) 
I0630 07:47:13.988970 29777 net.cpp:1851] conv1b_param_0(0.53) 
I0630 07:47:13.988976 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:47:13.988979 29777 net.cpp:1851] res2a_branch2a_param_0(0.53) 
I0630 07:47:13.988983 29777 net.cpp:1851] res2a_branch2b_param_0(0.53) 
I0630 07:47:13.988988 29777 net.cpp:1851] res3a_branch2a_param_0(0.53) 
I0630 07:47:13.988992 29777 net.cpp:1851] res3a_branch2b_param_0(0.53) 
I0630 07:47:13.988996 29777 net.cpp:1851] res4a_branch2a_param_0(0.53) 
I0630 07:47:13.989001 29777 net.cpp:1851] res4a_branch2b_param_0(0.53) 
I0630 07:47:13.989004 29777 net.cpp:1851] res5a_branch2a_param_0(0.53) 
I0630 07:47:13.989008 29777 net.cpp:1851] res5a_branch2b_param_0(0.53) 
I0630 07:47:13.989012 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.24739e+06/2.86678e+06) 0.435
I0630 07:47:13.989104 29777 solver.cpp:471] Iteration 106000, Testing net (#0)
I0630 07:47:25.913780 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:48:18.647572 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57596
I0630 07:48:18.647644 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.807121
I0630 07:48:18.647651 29777 solver.cpp:544]     Test net output #2: loss = 1.51344 (* 1 = 1.51344 loss)
I0630 07:48:18.822662 29777 solver.cpp:290] Iteration 106000 (1.23817 iter/s, 80.7643s/100 iter), loss = 1
I0630 07:48:18.822693 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:48:18.822705 29777 sgd_solver.cpp:106] Iteration 106000, lr = 0.0066875
I0630 07:48:18.823801 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.54
I0630 07:48:19.196768 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:48:34.746918 29777 solver.cpp:290] Iteration 106100 (6.27992 iter/s, 15.9238s/100 iter), loss = 0.964286
I0630 07:48:34.747103 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:48:34.747213 29777 sgd_solver.cpp:106] Iteration 106100, lr = 0.00668437
I0630 07:48:51.189357 29777 solver.cpp:290] Iteration 106200 (6.08206 iter/s, 16.4418s/100 iter), loss = 0.904762
I0630 07:48:51.189410 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 07:48:51.189420 29777 sgd_solver.cpp:106] Iteration 106200, lr = 0.00668125
I0630 07:49:07.405514 29777 solver.cpp:290] Iteration 106300 (6.16688 iter/s, 16.2157s/100 iter), loss = 1.09524
I0630 07:49:07.405540 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:49:07.405550 29777 sgd_solver.cpp:106] Iteration 106300, lr = 0.00667812
I0630 07:49:23.568080 29777 solver.cpp:290] Iteration 106400 (6.18732 iter/s, 16.1621s/100 iter), loss = 1.09524
I0630 07:49:23.568163 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:49:23.568173 29777 sgd_solver.cpp:106] Iteration 106400, lr = 0.006675
I0630 07:49:39.726014 29777 solver.cpp:290] Iteration 106500 (6.18911 iter/s, 16.1574s/100 iter), loss = 0.869048
I0630 07:49:39.726039 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 07:49:39.726048 29777 sgd_solver.cpp:106] Iteration 106500, lr = 0.00667187
I0630 07:49:55.881134 29777 solver.cpp:290] Iteration 106600 (6.19017 iter/s, 16.1546s/100 iter), loss = 1.0119
I0630 07:49:55.881207 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 07:49:55.881214 29777 sgd_solver.cpp:106] Iteration 106600, lr = 0.00666875
I0630 07:50:12.071477 29777 solver.cpp:290] Iteration 106700 (6.17672 iter/s, 16.1898s/100 iter), loss = 1.47619
I0630 07:50:12.071502 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 07:50:12.071511 29777 sgd_solver.cpp:106] Iteration 106700, lr = 0.00666562
I0630 07:50:28.361138 29777 solver.cpp:290] Iteration 106800 (6.13904 iter/s, 16.2892s/100 iter), loss = 1.03571
I0630 07:50:28.361331 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:50:28.361344 29777 sgd_solver.cpp:106] Iteration 106800, lr = 0.0066625
I0630 07:50:44.728368 29777 solver.cpp:290] Iteration 106900 (6.11001 iter/s, 16.3666s/100 iter), loss = 1.04762
I0630 07:50:44.728390 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 07:50:44.728397 29777 sgd_solver.cpp:106] Iteration 106900, lr = 0.00665938
I0630 07:51:00.884335 29777 solver.cpp:354] Sparsity after update:
I0630 07:51:00.904899 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:51:00.904955 29777 net.cpp:1851] conv1a_param_0(0.27) 
I0630 07:51:00.904984 29777 net.cpp:1851] conv1b_param_0(0.54) 
I0630 07:51:00.905000 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:51:00.905015 29777 net.cpp:1851] res2a_branch2a_param_0(0.54) 
I0630 07:51:00.905040 29777 net.cpp:1851] res2a_branch2b_param_0(0.54) 
I0630 07:51:00.905051 29777 net.cpp:1851] res3a_branch2a_param_0(0.54) 
I0630 07:51:00.905064 29777 net.cpp:1851] res3a_branch2b_param_0(0.54) 
I0630 07:51:00.905071 29777 net.cpp:1851] res4a_branch2a_param_0(0.54) 
I0630 07:51:00.905079 29777 net.cpp:1851] res4a_branch2b_param_0(0.54) 
I0630 07:51:00.905093 29777 net.cpp:1851] res5a_branch2a_param_0(0.54) 
I0630 07:51:00.905108 29777 net.cpp:1851] res5a_branch2b_param_0(0.54) 
I0630 07:51:00.905122 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.27093e+06/2.86678e+06) 0.443
I0630 07:51:01.059376 29777 solver.cpp:290] Iteration 107000 (6.1235 iter/s, 16.3305s/100 iter), loss = 0.880952
I0630 07:51:01.059398 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 07:51:01.059406 29777 sgd_solver.cpp:106] Iteration 107000, lr = 0.00665625
I0630 07:51:17.102820 29777 solver.cpp:290] Iteration 107100 (6.23326 iter/s, 16.043s/100 iter), loss = 1.17857
I0630 07:51:17.102849 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 07:51:17.102856 29777 sgd_solver.cpp:106] Iteration 107100, lr = 0.00665312
I0630 07:51:33.288313 29777 solver.cpp:290] Iteration 107200 (6.17855 iter/s, 16.185s/100 iter), loss = 1.02381
I0630 07:51:33.288396 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 07:51:33.288408 29777 sgd_solver.cpp:106] Iteration 107200, lr = 0.00665
I0630 07:51:49.587514 29777 solver.cpp:290] Iteration 107300 (6.13547 iter/s, 16.2987s/100 iter), loss = 0.833333
I0630 07:51:49.587538 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 07:51:49.587543 29777 sgd_solver.cpp:106] Iteration 107300, lr = 0.00664687
I0630 07:52:05.816499 29777 solver.cpp:290] Iteration 107400 (6.162 iter/s, 16.2285s/100 iter), loss = 1.05952
I0630 07:52:05.816599 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 07:52:05.816630 29777 sgd_solver.cpp:106] Iteration 107400, lr = 0.00664375
I0630 07:52:22.142081 29777 solver.cpp:290] Iteration 107500 (6.12556 iter/s, 16.325s/100 iter), loss = 0.892857
I0630 07:52:22.142125 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 07:52:22.142138 29777 sgd_solver.cpp:106] Iteration 107500, lr = 0.00664062
I0630 07:52:38.270103 29777 solver.cpp:290] Iteration 107600 (6.20057 iter/s, 16.1275s/100 iter), loss = 0.964286
I0630 07:52:38.270213 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 07:52:38.270223 29777 sgd_solver.cpp:106] Iteration 107600, lr = 0.0066375
I0630 07:52:54.477495 29777 solver.cpp:290] Iteration 107700 (6.17023 iter/s, 16.2068s/100 iter), loss = 1.53571
I0630 07:52:54.477517 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 07:52:54.477524 29777 sgd_solver.cpp:106] Iteration 107700, lr = 0.00663437
I0630 07:53:10.646661 29777 solver.cpp:290] Iteration 107800 (6.18479 iter/s, 16.1687s/100 iter), loss = 1.0119
I0630 07:53:10.646739 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:53:10.646749 29777 sgd_solver.cpp:106] Iteration 107800, lr = 0.00663125
I0630 07:53:26.918864 29777 solver.cpp:290] Iteration 107900 (6.14565 iter/s, 16.2717s/100 iter), loss = 1.02381
I0630 07:53:26.918889 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 07:53:26.918898 29777 sgd_solver.cpp:106] Iteration 107900, lr = 0.00662812
I0630 07:53:42.908438 29777 solver.cpp:354] Sparsity after update:
I0630 07:53:42.909723 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:53:42.909730 29777 net.cpp:1851] conv1a_param_0(0.27) 
I0630 07:53:42.909736 29777 net.cpp:1851] conv1b_param_0(0.54) 
I0630 07:53:42.909739 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:53:42.909741 29777 net.cpp:1851] res2a_branch2a_param_0(0.54) 
I0630 07:53:42.909744 29777 net.cpp:1851] res2a_branch2b_param_0(0.54) 
I0630 07:53:42.909745 29777 net.cpp:1851] res3a_branch2a_param_0(0.54) 
I0630 07:53:42.909747 29777 net.cpp:1851] res3a_branch2b_param_0(0.54) 
I0630 07:53:42.909749 29777 net.cpp:1851] res4a_branch2a_param_0(0.54) 
I0630 07:53:42.909751 29777 net.cpp:1851] res4a_branch2b_param_0(0.54) 
I0630 07:53:42.909752 29777 net.cpp:1851] res5a_branch2a_param_0(0.54) 
I0630 07:53:42.909754 29777 net.cpp:1851] res5a_branch2b_param_0(0.54) 
I0630 07:53:42.909757 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.27093e+06/2.86678e+06) 0.443
I0630 07:53:42.909844 29777 solver.cpp:471] Iteration 108000, Testing net (#0)
I0630 07:53:53.836494 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 07:54:42.173295 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.567079
I0630 07:54:42.173467 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801862
I0630 07:54:42.173487 29777 solver.cpp:544]     Test net output #2: loss = 1.53852 (* 1 = 1.53852 loss)
I0630 07:54:42.354887 29777 solver.cpp:290] Iteration 108000 (1.32566 iter/s, 75.4339s/100 iter), loss = 0.892857
I0630 07:54:42.354964 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:54:42.354990 29777 sgd_solver.cpp:106] Iteration 108000, lr = 0.006625
I0630 07:54:42.356597 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.55
I0630 07:54:42.805866 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 07:54:58.271358 29777 solver.cpp:290] Iteration 108100 (6.283 iter/s, 15.916s/100 iter), loss = 1
I0630 07:54:58.271384 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 07:54:58.271394 29777 sgd_solver.cpp:106] Iteration 108100, lr = 0.00662187
I0630 07:55:14.461977 29777 solver.cpp:290] Iteration 108200 (6.1766 iter/s, 16.1901s/100 iter), loss = 1.03571
I0630 07:55:14.462090 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:55:14.462103 29777 sgd_solver.cpp:106] Iteration 108200, lr = 0.00661875
I0630 07:55:30.664628 29777 solver.cpp:290] Iteration 108300 (6.17204 iter/s, 16.2021s/100 iter), loss = 1.58333
I0630 07:55:30.664652 29777 solver.cpp:309]     Train net output #0: loss = 1.85714 (* 1 = 1.85714 loss)
I0630 07:55:30.664661 29777 sgd_solver.cpp:106] Iteration 108300, lr = 0.00661562
I0630 07:55:46.783730 29777 solver.cpp:290] Iteration 108400 (6.204 iter/s, 16.1186s/100 iter), loss = 1.08333
I0630 07:55:46.783826 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 07:55:46.783838 29777 sgd_solver.cpp:106] Iteration 108400, lr = 0.0066125
I0630 07:56:02.967479 29777 solver.cpp:290] Iteration 108500 (6.17924 iter/s, 16.1832s/100 iter), loss = 1.40476
I0630 07:56:02.967504 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 07:56:02.967510 29777 sgd_solver.cpp:106] Iteration 108500, lr = 0.00660937
I0630 07:56:19.194046 29777 solver.cpp:290] Iteration 108600 (6.16291 iter/s, 16.2261s/100 iter), loss = 1.28571
I0630 07:56:19.194141 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:56:19.194152 29777 sgd_solver.cpp:106] Iteration 108600, lr = 0.00660625
I0630 07:56:35.472362 29777 solver.cpp:290] Iteration 108700 (6.14335 iter/s, 16.2778s/100 iter), loss = 0.714286
I0630 07:56:35.472388 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 07:56:35.472396 29777 sgd_solver.cpp:106] Iteration 108700, lr = 0.00660313
I0630 07:56:52.050586 29777 solver.cpp:290] Iteration 108800 (6.03218 iter/s, 16.5777s/100 iter), loss = 1.09524
I0630 07:56:52.050689 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 07:56:52.050698 29777 sgd_solver.cpp:106] Iteration 108800, lr = 0.0066
I0630 07:57:08.463157 29777 solver.cpp:290] Iteration 108900 (6.0931 iter/s, 16.412s/100 iter), loss = 0.833333
I0630 07:57:08.463207 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 07:57:08.463222 29777 sgd_solver.cpp:106] Iteration 108900, lr = 0.00659687
I0630 07:57:24.768363 29777 solver.cpp:354] Sparsity after update:
I0630 07:57:24.788774 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 07:57:24.788790 29777 net.cpp:1851] conv1a_param_0(0.275) 
I0630 07:57:24.788801 29777 net.cpp:1851] conv1b_param_0(0.55) 
I0630 07:57:24.788805 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 07:57:24.788810 29777 net.cpp:1851] res2a_branch2a_param_0(0.55) 
I0630 07:57:24.788813 29777 net.cpp:1851] res2a_branch2b_param_0(0.55) 
I0630 07:57:24.788817 29777 net.cpp:1851] res3a_branch2a_param_0(0.55) 
I0630 07:57:24.788820 29777 net.cpp:1851] res3a_branch2b_param_0(0.55) 
I0630 07:57:24.788825 29777 net.cpp:1851] res4a_branch2a_param_0(0.55) 
I0630 07:57:24.788828 29777 net.cpp:1851] res4a_branch2b_param_0(0.55) 
I0630 07:57:24.788832 29777 net.cpp:1851] res5a_branch2a_param_0(0.55) 
I0630 07:57:24.788836 29777 net.cpp:1851] res5a_branch2b_param_0(0.55) 
I0630 07:57:24.788839 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.29446e+06/2.86678e+06) 0.452
I0630 07:57:24.951231 29777 solver.cpp:290] Iteration 109000 (6.06518 iter/s, 16.4876s/100 iter), loss = 1.2381
I0630 07:57:24.951298 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 07:57:24.951320 29777 sgd_solver.cpp:106] Iteration 109000, lr = 0.00659375
I0630 07:57:41.230401 29777 solver.cpp:290] Iteration 109100 (6.14301 iter/s, 16.2787s/100 iter), loss = 0.928571
I0630 07:57:41.230443 29777 solver.cpp:309]     Train net output #0: loss = 0.5 (* 1 = 0.5 loss)
I0630 07:57:41.230458 29777 sgd_solver.cpp:106] Iteration 109100, lr = 0.00659062
I0630 07:57:57.899016 29777 solver.cpp:290] Iteration 109200 (5.99948 iter/s, 16.6681s/100 iter), loss = 0.904762
I0630 07:57:57.899087 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 07:57:57.899096 29777 sgd_solver.cpp:106] Iteration 109200, lr = 0.0065875
I0630 07:58:14.129142 29777 solver.cpp:290] Iteration 109300 (6.16158 iter/s, 16.2296s/100 iter), loss = 0.869048
I0630 07:58:14.129190 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 07:58:14.129212 29777 sgd_solver.cpp:106] Iteration 109300, lr = 0.00658437
I0630 07:58:30.626194 29777 solver.cpp:290] Iteration 109400 (6.06187 iter/s, 16.4966s/100 iter), loss = 0.952381
I0630 07:58:30.626286 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:58:30.626296 29777 sgd_solver.cpp:106] Iteration 109400, lr = 0.00658125
I0630 07:58:46.840401 29777 solver.cpp:290] Iteration 109500 (6.16764 iter/s, 16.2137s/100 iter), loss = 1.08333
I0630 07:58:46.840427 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 07:58:46.840436 29777 sgd_solver.cpp:106] Iteration 109500, lr = 0.00657812
I0630 07:59:03.132642 29777 solver.cpp:290] Iteration 109600 (6.13807 iter/s, 16.2918s/100 iter), loss = 1.13095
I0630 07:59:03.132736 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 07:59:03.132747 29777 sgd_solver.cpp:106] Iteration 109600, lr = 0.006575
I0630 07:59:19.471849 29777 solver.cpp:290] Iteration 109700 (6.12045 iter/s, 16.3387s/100 iter), loss = 0.809524
I0630 07:59:19.471877 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 07:59:19.471884 29777 sgd_solver.cpp:106] Iteration 109700, lr = 0.00657187
I0630 07:59:35.788025 29777 solver.cpp:290] Iteration 109800 (6.12907 iter/s, 16.3157s/100 iter), loss = 0.821429
I0630 07:59:35.788137 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 07:59:35.788152 29777 sgd_solver.cpp:106] Iteration 109800, lr = 0.00656875
I0630 07:59:52.027007 29777 solver.cpp:290] Iteration 109900 (6.15823 iter/s, 16.2384s/100 iter), loss = 0.892857
I0630 07:59:52.027029 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 07:59:52.027036 29777 sgd_solver.cpp:106] Iteration 109900, lr = 0.00656562
I0630 08:00:07.993528 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_110000.caffemodel
I0630 08:00:08.012820 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_110000.solverstate
I0630 08:00:08.022315 29777 solver.cpp:354] Sparsity after update:
I0630 08:00:08.023484 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:00:08.023495 29777 net.cpp:1851] conv1a_param_0(0.275) 
I0630 08:00:08.023504 29777 net.cpp:1851] conv1b_param_0(0.55) 
I0630 08:00:08.023509 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:00:08.023511 29777 net.cpp:1851] res2a_branch2a_param_0(0.55) 
I0630 08:00:08.023515 29777 net.cpp:1851] res2a_branch2b_param_0(0.55) 
I0630 08:00:08.023519 29777 net.cpp:1851] res3a_branch2a_param_0(0.55) 
I0630 08:00:08.023521 29777 net.cpp:1851] res3a_branch2b_param_0(0.55) 
I0630 08:00:08.023525 29777 net.cpp:1851] res4a_branch2a_param_0(0.55) 
I0630 08:00:08.023528 29777 net.cpp:1851] res4a_branch2b_param_0(0.55) 
I0630 08:00:08.023531 29777 net.cpp:1851] res5a_branch2a_param_0(0.55) 
I0630 08:00:08.023543 29777 net.cpp:1851] res5a_branch2b_param_0(0.55) 
I0630 08:00:08.023546 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.29446e+06/2.86678e+06) 0.452
I0630 08:00:08.023684 29777 solver.cpp:471] Iteration 110000, Testing net (#0)
I0630 08:00:21.173820 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:01:12.191597 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57248
I0630 08:01:12.191653 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806001
I0630 08:01:12.191659 29777 solver.cpp:544]     Test net output #2: loss = 1.52902 (* 1 = 1.52902 loss)
I0630 08:01:12.386816 29777 solver.cpp:290] Iteration 110000 (1.24444 iter/s, 80.3576s/100 iter), loss = 0.892857
I0630 08:01:12.386903 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 08:01:12.386926 29777 sgd_solver.cpp:106] Iteration 110000, lr = 0.0065625
I0630 08:01:12.389011 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.56
I0630 08:01:12.829803 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:01:28.413211 29777 solver.cpp:290] Iteration 110100 (6.23991 iter/s, 16.0259s/100 iter), loss = 1.2381
I0630 08:01:28.413239 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 08:01:28.413247 29777 sgd_solver.cpp:106] Iteration 110100, lr = 0.00655937
I0630 08:01:44.568617 29777 solver.cpp:290] Iteration 110200 (6.19006 iter/s, 16.1549s/100 iter), loss = 0.952381
I0630 08:01:44.568703 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 08:01:44.568713 29777 sgd_solver.cpp:106] Iteration 110200, lr = 0.00655625
I0630 08:02:01.060174 29777 solver.cpp:290] Iteration 110300 (6.06391 iter/s, 16.491s/100 iter), loss = 0.988095
I0630 08:02:01.060204 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 08:02:01.060214 29777 sgd_solver.cpp:106] Iteration 110300, lr = 0.00655313
I0630 08:02:17.541973 29777 solver.cpp:290] Iteration 110400 (6.06748 iter/s, 16.4813s/100 iter), loss = 0.928571
I0630 08:02:17.542035 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 08:02:17.542045 29777 sgd_solver.cpp:106] Iteration 110400, lr = 0.00655
I0630 08:02:34.433809 29777 solver.cpp:290] Iteration 110500 (5.92021 iter/s, 16.8913s/100 iter), loss = 1.21429
I0630 08:02:34.433862 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 08:02:34.433886 29777 sgd_solver.cpp:106] Iteration 110500, lr = 0.00654687
I0630 08:02:51.393424 29777 solver.cpp:290] Iteration 110600 (5.89654 iter/s, 16.9591s/100 iter), loss = 1.08333
I0630 08:02:51.393501 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:02:51.393512 29777 sgd_solver.cpp:106] Iteration 110600, lr = 0.00654375
I0630 08:03:07.723445 29777 solver.cpp:290] Iteration 110700 (6.12389 iter/s, 16.3295s/100 iter), loss = 1.29762
I0630 08:03:07.723469 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:03:07.723476 29777 sgd_solver.cpp:106] Iteration 110700, lr = 0.00654062
I0630 08:03:23.784597 29777 solver.cpp:290] Iteration 110800 (6.22638 iter/s, 16.0607s/100 iter), loss = 0.857143
I0630 08:03:23.784704 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:03:23.784715 29777 sgd_solver.cpp:106] Iteration 110800, lr = 0.0065375
I0630 08:03:39.727510 29777 solver.cpp:290] Iteration 110900 (6.27259 iter/s, 15.9424s/100 iter), loss = 1.04762
I0630 08:03:39.727536 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 08:03:39.727550 29777 sgd_solver.cpp:106] Iteration 110900, lr = 0.00653437
I0630 08:03:55.577052 29777 solver.cpp:354] Sparsity after update:
I0630 08:03:55.597440 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:03:55.597455 29777 net.cpp:1851] conv1a_param_0(0.28) 
I0630 08:03:55.597466 29777 net.cpp:1851] conv1b_param_0(0.56) 
I0630 08:03:55.597470 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:03:55.597473 29777 net.cpp:1851] res2a_branch2a_param_0(0.56) 
I0630 08:03:55.597479 29777 net.cpp:1851] res2a_branch2b_param_0(0.56) 
I0630 08:03:55.597483 29777 net.cpp:1851] res3a_branch2a_param_0(0.56) 
I0630 08:03:55.597486 29777 net.cpp:1851] res3a_branch2b_param_0(0.56) 
I0630 08:03:55.597489 29777 net.cpp:1851] res4a_branch2a_param_0(0.56) 
I0630 08:03:55.597493 29777 net.cpp:1851] res4a_branch2b_param_0(0.56) 
I0630 08:03:55.597496 29777 net.cpp:1851] res5a_branch2a_param_0(0.56) 
I0630 08:03:55.597499 29777 net.cpp:1851] res5a_branch2b_param_0(0.56) 
I0630 08:03:55.597502 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.318e+06/2.86678e+06) 0.46
I0630 08:03:55.759356 29777 solver.cpp:290] Iteration 111000 (6.23777 iter/s, 16.0314s/100 iter), loss = 0.797619
I0630 08:03:55.759380 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 08:03:55.759387 29777 sgd_solver.cpp:106] Iteration 111000, lr = 0.00653125
I0630 08:04:11.803537 29777 solver.cpp:290] Iteration 111100 (6.23297 iter/s, 16.0437s/100 iter), loss = 1.36905
I0630 08:04:11.803560 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 08:04:11.803566 29777 sgd_solver.cpp:106] Iteration 111100, lr = 0.00652812
I0630 08:04:27.752033 29777 solver.cpp:290] Iteration 111200 (6.27036 iter/s, 15.948s/100 iter), loss = 1.13095
I0630 08:04:27.752110 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:04:27.752118 29777 sgd_solver.cpp:106] Iteration 111200, lr = 0.006525
I0630 08:04:43.904434 29777 solver.cpp:290] Iteration 111300 (6.19123 iter/s, 16.1519s/100 iter), loss = 0.97619
I0630 08:04:43.904458 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:04:43.904465 29777 sgd_solver.cpp:106] Iteration 111300, lr = 0.00652187
I0630 08:04:59.926144 29777 solver.cpp:290] Iteration 111400 (6.24171 iter/s, 16.0212s/100 iter), loss = 1.22619
I0630 08:04:59.926237 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 08:04:59.926249 29777 sgd_solver.cpp:106] Iteration 111400, lr = 0.00651875
I0630 08:05:15.942682 29777 solver.cpp:290] Iteration 111500 (6.24375 iter/s, 16.016s/100 iter), loss = 1.17857
I0630 08:05:15.942708 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 08:05:15.942718 29777 sgd_solver.cpp:106] Iteration 111500, lr = 0.00651562
I0630 08:05:32.107967 29777 solver.cpp:290] Iteration 111600 (6.18627 iter/s, 16.1648s/100 iter), loss = 0.940476
I0630 08:05:32.108042 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:05:32.108050 29777 sgd_solver.cpp:106] Iteration 111600, lr = 0.0065125
I0630 08:05:48.061496 29777 solver.cpp:290] Iteration 111700 (6.26841 iter/s, 15.953s/100 iter), loss = 1.28571
I0630 08:05:48.061520 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 08:05:48.061527 29777 sgd_solver.cpp:106] Iteration 111700, lr = 0.00650937
I0630 08:06:04.078338 29777 solver.cpp:290] Iteration 111800 (6.24361 iter/s, 16.0164s/100 iter), loss = 1.10714
I0630 08:06:04.078444 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:06:04.078455 29777 sgd_solver.cpp:106] Iteration 111800, lr = 0.00650625
I0630 08:06:20.016496 29777 solver.cpp:290] Iteration 111900 (6.27446 iter/s, 15.9376s/100 iter), loss = 1.52381
I0630 08:06:20.016518 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 08:06:20.016525 29777 sgd_solver.cpp:106] Iteration 111900, lr = 0.00650313
I0630 08:06:35.894642 29777 solver.cpp:354] Sparsity after update:
I0630 08:06:35.896075 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:06:35.896081 29777 net.cpp:1851] conv1a_param_0(0.28) 
I0630 08:06:35.896088 29777 net.cpp:1851] conv1b_param_0(0.56) 
I0630 08:06:35.896090 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:06:35.896093 29777 net.cpp:1851] res2a_branch2a_param_0(0.56) 
I0630 08:06:35.896095 29777 net.cpp:1851] res2a_branch2b_param_0(0.56) 
I0630 08:06:35.896097 29777 net.cpp:1851] res3a_branch2a_param_0(0.56) 
I0630 08:06:35.896100 29777 net.cpp:1851] res3a_branch2b_param_0(0.56) 
I0630 08:06:35.896100 29777 net.cpp:1851] res4a_branch2a_param_0(0.56) 
I0630 08:06:35.896102 29777 net.cpp:1851] res4a_branch2b_param_0(0.56) 
I0630 08:06:35.896105 29777 net.cpp:1851] res5a_branch2a_param_0(0.56) 
I0630 08:06:35.896106 29777 net.cpp:1851] res5a_branch2b_param_0(0.56) 
I0630 08:06:35.896108 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.318e+06/2.86678e+06) 0.46
I0630 08:06:35.896194 29777 solver.cpp:471] Iteration 112000, Testing net (#0)
I0630 08:06:44.722719 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:07:24.091167 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57388
I0630 08:07:24.091248 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806881
I0630 08:07:24.091259 29777 solver.cpp:544]     Test net output #2: loss = 1.51082 (* 1 = 1.51082 loss)
I0630 08:07:24.275326 29777 solver.cpp:290] Iteration 112000 (1.55625 iter/s, 64.2571s/100 iter), loss = 1.08333
I0630 08:07:24.275349 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 08:07:24.275357 29777 sgd_solver.cpp:106] Iteration 112000, lr = 0.0065
I0630 08:07:24.276048 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.57
I0630 08:07:24.688493 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:07:39.990787 29777 solver.cpp:290] Iteration 112100 (6.36335 iter/s, 15.715s/100 iter), loss = 1.2619
I0630 08:07:39.990808 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 08:07:39.990815 29777 sgd_solver.cpp:106] Iteration 112100, lr = 0.00649688
I0630 08:07:55.924131 29777 solver.cpp:290] Iteration 112200 (6.27633 iter/s, 15.9329s/100 iter), loss = 0.809524
I0630 08:07:55.924222 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 08:07:55.924233 29777 sgd_solver.cpp:106] Iteration 112200, lr = 0.00649375
I0630 08:08:12.153019 29777 solver.cpp:290] Iteration 112300 (6.16206 iter/s, 16.2284s/100 iter), loss = 1.04762
I0630 08:08:12.153043 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 08:08:12.153049 29777 sgd_solver.cpp:106] Iteration 112300, lr = 0.00649062
I0630 08:08:28.263257 29777 solver.cpp:290] Iteration 112400 (6.20741 iter/s, 16.1098s/100 iter), loss = 1.14286
I0630 08:08:28.263350 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:08:28.263360 29777 sgd_solver.cpp:106] Iteration 112400, lr = 0.0064875
I0630 08:08:44.286947 29777 solver.cpp:290] Iteration 112500 (6.24097 iter/s, 16.0232s/100 iter), loss = 1.02381
I0630 08:08:44.286980 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:08:44.286991 29777 sgd_solver.cpp:106] Iteration 112500, lr = 0.00648437
I0630 08:09:00.478353 29777 solver.cpp:290] Iteration 112600 (6.1763 iter/s, 16.1909s/100 iter), loss = 1.2619
I0630 08:09:00.478458 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 08:09:00.478471 29777 sgd_solver.cpp:106] Iteration 112600, lr = 0.00648125
I0630 08:09:16.485157 29777 solver.cpp:290] Iteration 112700 (6.24756 iter/s, 16.0063s/100 iter), loss = 1
I0630 08:09:16.485179 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:09:16.485186 29777 sgd_solver.cpp:106] Iteration 112700, lr = 0.00647812
I0630 08:09:32.604308 29777 solver.cpp:290] Iteration 112800 (6.20398 iter/s, 16.1187s/100 iter), loss = 1.20238
I0630 08:09:32.604405 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:09:32.604416 29777 sgd_solver.cpp:106] Iteration 112800, lr = 0.006475
I0630 08:09:48.644151 29777 solver.cpp:290] Iteration 112900 (6.23468 iter/s, 16.0393s/100 iter), loss = 1
I0630 08:09:48.644178 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:09:48.644192 29777 sgd_solver.cpp:106] Iteration 112900, lr = 0.00647187
I0630 08:10:04.541458 29777 solver.cpp:354] Sparsity after update:
I0630 08:10:04.561870 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:10:04.561885 29777 net.cpp:1851] conv1a_param_0(0.285) 
I0630 08:10:04.561893 29777 net.cpp:1851] conv1b_param_0(0.57) 
I0630 08:10:04.561897 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:10:04.561898 29777 net.cpp:1851] res2a_branch2a_param_0(0.57) 
I0630 08:10:04.561900 29777 net.cpp:1851] res2a_branch2b_param_0(0.57) 
I0630 08:10:04.561902 29777 net.cpp:1851] res3a_branch2a_param_0(0.57) 
I0630 08:10:04.561904 29777 net.cpp:1851] res3a_branch2b_param_0(0.57) 
I0630 08:10:04.561908 29777 net.cpp:1851] res4a_branch2a_param_0(0.57) 
I0630 08:10:04.561913 29777 net.cpp:1851] res4a_branch2b_param_0(0.57) 
I0630 08:10:04.561916 29777 net.cpp:1851] res5a_branch2a_param_0(0.57) 
I0630 08:10:04.561919 29777 net.cpp:1851] res5a_branch2b_param_0(0.57) 
I0630 08:10:04.561930 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.34154e+06/2.86678e+06) 0.468
I0630 08:10:04.718971 29777 solver.cpp:290] Iteration 113000 (6.22109 iter/s, 16.0744s/100 iter), loss = 1.20238
I0630 08:10:04.718997 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 08:10:04.719005 29777 sgd_solver.cpp:106] Iteration 113000, lr = 0.00646875
I0630 08:10:20.795873 29777 solver.cpp:290] Iteration 113100 (6.22029 iter/s, 16.0764s/100 iter), loss = 1.11905
I0630 08:10:20.795899 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:10:20.795908 29777 sgd_solver.cpp:106] Iteration 113100, lr = 0.00646562
I0630 08:10:36.730283 29777 solver.cpp:290] Iteration 113200 (6.27591 iter/s, 15.9339s/100 iter), loss = 1.10714
I0630 08:10:36.730368 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 08:10:36.730378 29777 sgd_solver.cpp:106] Iteration 113200, lr = 0.0064625
I0630 08:10:52.908241 29777 solver.cpp:290] Iteration 113300 (6.18145 iter/s, 16.1774s/100 iter), loss = 1.19048
I0630 08:10:52.908277 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:10:52.908287 29777 sgd_solver.cpp:106] Iteration 113300, lr = 0.00645937
I0630 08:11:08.928565 29777 solver.cpp:290] Iteration 113400 (6.24226 iter/s, 16.0198s/100 iter), loss = 1.41667
I0630 08:11:08.928649 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 08:11:08.928661 29777 sgd_solver.cpp:106] Iteration 113400, lr = 0.00645625
I0630 08:11:25.090379 29777 solver.cpp:290] Iteration 113500 (6.18763 iter/s, 16.1613s/100 iter), loss = 1.28571
I0630 08:11:25.090437 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 08:11:25.090461 29777 sgd_solver.cpp:106] Iteration 113500, lr = 0.00645312
I0630 08:11:41.240504 29777 solver.cpp:290] Iteration 113600 (6.19209 iter/s, 16.1496s/100 iter), loss = 1.41667
I0630 08:11:41.240615 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 08:11:41.240625 29777 sgd_solver.cpp:106] Iteration 113600, lr = 0.00645
I0630 08:11:57.618443 29777 solver.cpp:290] Iteration 113700 (6.10598 iter/s, 16.3774s/100 iter), loss = 1.05952
I0630 08:11:57.618468 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:11:57.618476 29777 sgd_solver.cpp:106] Iteration 113700, lr = 0.00644688
I0630 08:12:13.815795 29777 solver.cpp:290] Iteration 113800 (6.17403 iter/s, 16.1969s/100 iter), loss = 0.75
I0630 08:12:13.815853 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 08:12:13.815865 29777 sgd_solver.cpp:106] Iteration 113800, lr = 0.00644375
I0630 08:12:30.117985 29777 solver.cpp:290] Iteration 113900 (6.13435 iter/s, 16.3017s/100 iter), loss = 1
I0630 08:12:30.118125 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 08:12:30.118212 29777 sgd_solver.cpp:106] Iteration 113900, lr = 0.00644063
I0630 08:12:46.029978 29777 solver.cpp:354] Sparsity after update:
I0630 08:12:46.031255 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:12:46.031263 29777 net.cpp:1851] conv1a_param_0(0.285) 
I0630 08:12:46.031270 29777 net.cpp:1851] conv1b_param_0(0.57) 
I0630 08:12:46.031272 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:12:46.031275 29777 net.cpp:1851] res2a_branch2a_param_0(0.57) 
I0630 08:12:46.031276 29777 net.cpp:1851] res2a_branch2b_param_0(0.57) 
I0630 08:12:46.031278 29777 net.cpp:1851] res3a_branch2a_param_0(0.57) 
I0630 08:12:46.031280 29777 net.cpp:1851] res3a_branch2b_param_0(0.57) 
I0630 08:12:46.031282 29777 net.cpp:1851] res4a_branch2a_param_0(0.57) 
I0630 08:12:46.031285 29777 net.cpp:1851] res4a_branch2b_param_0(0.57) 
I0630 08:12:46.031286 29777 net.cpp:1851] res5a_branch2a_param_0(0.57) 
I0630 08:12:46.031288 29777 net.cpp:1851] res5a_branch2b_param_0(0.57) 
I0630 08:12:46.031291 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.34154e+06/2.86678e+06) 0.468
I0630 08:12:46.031375 29777 solver.cpp:471] Iteration 114000, Testing net (#0)
I0630 08:12:57.410655 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:13:43.401199 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57178
I0630 08:13:43.401283 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.806642
I0630 08:13:43.401291 29777 solver.cpp:544]     Test net output #2: loss = 1.51618 (* 1 = 1.51618 loss)
I0630 08:13:43.580051 29777 solver.cpp:290] Iteration 114000 (1.36129 iter/s, 73.46s/100 iter), loss = 0.892857
I0630 08:13:43.580077 29777 solver.cpp:309]     Train net output #0: loss = 0.547619 (* 1 = 0.547619 loss)
I0630 08:13:43.580086 29777 sgd_solver.cpp:106] Iteration 114000, lr = 0.0064375
I0630 08:13:43.581081 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.58
I0630 08:13:43.976541 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:13:59.220140 29777 solver.cpp:290] Iteration 114100 (6.39401 iter/s, 15.6396s/100 iter), loss = 1.2381
I0630 08:13:59.220163 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 08:13:59.220170 29777 sgd_solver.cpp:106] Iteration 114100, lr = 0.00643437
I0630 08:14:15.153630 29777 solver.cpp:290] Iteration 114200 (6.27627 iter/s, 15.933s/100 iter), loss = 0.678571
I0630 08:14:15.153674 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 08:14:15.153682 29777 sgd_solver.cpp:106] Iteration 114200, lr = 0.00643125
I0630 08:14:31.188549 29777 solver.cpp:290] Iteration 114300 (6.23658 iter/s, 16.0344s/100 iter), loss = 0.797619
I0630 08:14:31.188576 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 08:14:31.188585 29777 sgd_solver.cpp:106] Iteration 114300, lr = 0.00642812
I0630 08:14:47.175791 29777 solver.cpp:290] Iteration 114400 (6.25517 iter/s, 15.9868s/100 iter), loss = 1.17857
I0630 08:14:47.175899 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 08:14:47.175909 29777 sgd_solver.cpp:106] Iteration 114400, lr = 0.006425
I0630 08:15:03.148685 29777 solver.cpp:290] Iteration 114500 (6.26082 iter/s, 15.9724s/100 iter), loss = 1.04762
I0630 08:15:03.148708 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:15:03.148715 29777 sgd_solver.cpp:106] Iteration 114500, lr = 0.00642187
I0630 08:15:19.224300 29777 solver.cpp:290] Iteration 114600 (6.22078 iter/s, 16.0751s/100 iter), loss = 1.2619
I0630 08:15:19.224416 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 08:15:19.224426 29777 sgd_solver.cpp:106] Iteration 114600, lr = 0.00641875
I0630 08:15:35.249169 29777 solver.cpp:290] Iteration 114700 (6.24052 iter/s, 16.0243s/100 iter), loss = 1.42857
I0630 08:15:35.249195 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 08:15:35.249204 29777 sgd_solver.cpp:106] Iteration 114700, lr = 0.00641562
I0630 08:15:51.246506 29777 solver.cpp:290] Iteration 114800 (6.25122 iter/s, 15.9969s/100 iter), loss = 1.17857
I0630 08:15:51.246613 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:15:51.246623 29777 sgd_solver.cpp:106] Iteration 114800, lr = 0.0064125
I0630 08:16:07.293347 29777 solver.cpp:290] Iteration 114900 (6.23197 iter/s, 16.0463s/100 iter), loss = 1.05952
I0630 08:16:07.293375 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 08:16:07.293385 29777 sgd_solver.cpp:106] Iteration 114900, lr = 0.00640937
I0630 08:16:23.152521 29777 solver.cpp:354] Sparsity after update:
I0630 08:16:23.172767 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:16:23.172811 29777 net.cpp:1851] conv1a_param_0(0.29) 
I0630 08:16:23.172827 29777 net.cpp:1851] conv1b_param_0(0.58) 
I0630 08:16:23.172835 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:16:23.172844 29777 net.cpp:1851] res2a_branch2a_param_0(0.58) 
I0630 08:16:23.172852 29777 net.cpp:1851] res2a_branch2b_param_0(0.58) 
I0630 08:16:23.172860 29777 net.cpp:1851] res3a_branch2a_param_0(0.58) 
I0630 08:16:23.172868 29777 net.cpp:1851] res3a_branch2b_param_0(0.58) 
I0630 08:16:23.172876 29777 net.cpp:1851] res4a_branch2a_param_0(0.58) 
I0630 08:16:23.172884 29777 net.cpp:1851] res4a_branch2b_param_0(0.58) 
I0630 08:16:23.172893 29777 net.cpp:1851] res5a_branch2a_param_0(0.58) 
I0630 08:16:23.172900 29777 net.cpp:1851] res5a_branch2b_param_0(0.58) 
I0630 08:16:23.172909 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.36507e+06/2.86678e+06) 0.476
I0630 08:16:23.331513 29777 solver.cpp:290] Iteration 115000 (6.23531 iter/s, 16.0377s/100 iter), loss = 1.27381
I0630 08:16:23.331539 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 08:16:23.331548 29777 sgd_solver.cpp:106] Iteration 115000, lr = 0.00640625
I0630 08:16:39.305328 29777 solver.cpp:290] Iteration 115100 (6.26043 iter/s, 15.9734s/100 iter), loss = 1.5119
I0630 08:16:39.305351 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 08:16:39.305358 29777 sgd_solver.cpp:106] Iteration 115100, lr = 0.00640312
I0630 08:16:55.324610 29777 solver.cpp:290] Iteration 115200 (6.24266 iter/s, 16.0188s/100 iter), loss = 1.09524
I0630 08:16:55.324707 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 08:16:55.324717 29777 sgd_solver.cpp:106] Iteration 115200, lr = 0.0064
I0630 08:17:11.333113 29777 solver.cpp:290] Iteration 115300 (6.24689 iter/s, 16.008s/100 iter), loss = 1.40476
I0630 08:17:11.333137 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 08:17:11.333143 29777 sgd_solver.cpp:106] Iteration 115300, lr = 0.00639688
I0630 08:17:27.326900 29777 solver.cpp:290] Iteration 115400 (6.25261 iter/s, 15.9933s/100 iter), loss = 1.35714
I0630 08:17:27.327005 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 08:17:27.327018 29777 sgd_solver.cpp:106] Iteration 115400, lr = 0.00639375
I0630 08:17:43.320245 29777 solver.cpp:290] Iteration 115500 (6.25281 iter/s, 15.9928s/100 iter), loss = 0.72619
I0630 08:17:43.320269 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 08:17:43.320278 29777 sgd_solver.cpp:106] Iteration 115500, lr = 0.00639063
I0630 08:17:59.363898 29777 solver.cpp:290] Iteration 115600 (6.23318 iter/s, 16.0432s/100 iter), loss = 1.53571
I0630 08:17:59.364002 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 08:17:59.364012 29777 sgd_solver.cpp:106] Iteration 115600, lr = 0.0063875
I0630 08:18:15.410986 29777 solver.cpp:290] Iteration 115700 (6.23187 iter/s, 16.0465s/100 iter), loss = 1.42857
I0630 08:18:15.411015 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 08:18:15.411025 29777 sgd_solver.cpp:106] Iteration 115700, lr = 0.00638438
I0630 08:18:31.560508 29777 solver.cpp:290] Iteration 115800 (6.19232 iter/s, 16.149s/100 iter), loss = 1.19048
I0630 08:18:31.560583 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:18:31.560596 29777 sgd_solver.cpp:106] Iteration 115800, lr = 0.00638125
I0630 08:18:47.674118 29777 solver.cpp:290] Iteration 115900 (6.20613 iter/s, 16.1131s/100 iter), loss = 0.809524
I0630 08:18:47.674144 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 08:18:47.674155 29777 sgd_solver.cpp:106] Iteration 115900, lr = 0.00637812
I0630 08:19:03.791718 29777 solver.cpp:354] Sparsity after update:
I0630 08:19:03.793679 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:19:03.793696 29777 net.cpp:1851] conv1a_param_0(0.29) 
I0630 08:19:03.793714 29777 net.cpp:1851] conv1b_param_0(0.58) 
I0630 08:19:03.793720 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:19:03.793726 29777 net.cpp:1851] res2a_branch2a_param_0(0.58) 
I0630 08:19:03.793732 29777 net.cpp:1851] res2a_branch2b_param_0(0.58) 
I0630 08:19:03.793738 29777 net.cpp:1851] res3a_branch2a_param_0(0.58) 
I0630 08:19:03.793747 29777 net.cpp:1851] res3a_branch2b_param_0(0.58) 
I0630 08:19:03.793750 29777 net.cpp:1851] res4a_branch2a_param_0(0.58) 
I0630 08:19:03.793751 29777 net.cpp:1851] res4a_branch2b_param_0(0.58) 
I0630 08:19:03.793754 29777 net.cpp:1851] res5a_branch2a_param_0(0.58) 
I0630 08:19:03.793758 29777 net.cpp:1851] res5a_branch2b_param_0(0.58) 
I0630 08:19:03.793763 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.36507e+06/2.86678e+06) 0.476
I0630 08:19:03.793967 29777 solver.cpp:471] Iteration 116000, Testing net (#0)
I0630 08:19:16.224978 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:20:06.721899 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.570719
I0630 08:20:06.722421 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.802122
I0630 08:20:06.722477 29777 solver.cpp:544]     Test net output #2: loss = 1.53858 (* 1 = 1.53858 loss)
I0630 08:20:06.973714 29777 solver.cpp:290] Iteration 116000 (1.26108 iter/s, 79.2974s/100 iter), loss = 0.678571
I0630 08:20:06.973737 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 08:20:06.973744 29777 sgd_solver.cpp:106] Iteration 116000, lr = 0.006375
I0630 08:20:06.974421 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.59
I0630 08:20:07.390542 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:20:23.419039 29777 solver.cpp:290] Iteration 116100 (6.08093 iter/s, 16.4448s/100 iter), loss = 0.821429
I0630 08:20:23.419062 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:20:23.419070 29777 sgd_solver.cpp:106] Iteration 116100, lr = 0.00637187
I0630 08:20:39.618309 29777 solver.cpp:290] Iteration 116200 (6.1733 iter/s, 16.1988s/100 iter), loss = 1.05952
I0630 08:20:39.618412 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 08:20:39.618423 29777 sgd_solver.cpp:106] Iteration 116200, lr = 0.00636875
I0630 08:20:55.747448 29777 solver.cpp:290] Iteration 116300 (6.20017 iter/s, 16.1286s/100 iter), loss = 0.857143
I0630 08:20:55.747473 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:20:55.747483 29777 sgd_solver.cpp:106] Iteration 116300, lr = 0.00636562
I0630 08:21:11.865787 29777 solver.cpp:290] Iteration 116400 (6.2043 iter/s, 16.1179s/100 iter), loss = 0.952381
I0630 08:21:11.865890 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 08:21:11.865900 29777 sgd_solver.cpp:106] Iteration 116400, lr = 0.0063625
I0630 08:21:28.175535 29777 solver.cpp:290] Iteration 116500 (6.13151 iter/s, 16.3092s/100 iter), loss = 0.97619
I0630 08:21:28.175559 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 08:21:28.175566 29777 sgd_solver.cpp:106] Iteration 116500, lr = 0.00635938
I0630 08:21:44.338268 29777 solver.cpp:290] Iteration 116600 (6.18725 iter/s, 16.1623s/100 iter), loss = 0.97619
I0630 08:21:44.338373 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 08:21:44.338383 29777 sgd_solver.cpp:106] Iteration 116600, lr = 0.00635625
I0630 08:22:00.423683 29777 solver.cpp:290] Iteration 116700 (6.21702 iter/s, 16.0849s/100 iter), loss = 0.869048
I0630 08:22:00.423710 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 08:22:00.423719 29777 sgd_solver.cpp:106] Iteration 116700, lr = 0.00635312
I0630 08:22:16.444398 29777 solver.cpp:290] Iteration 116800 (6.2421 iter/s, 16.0202s/100 iter), loss = 1.19048
I0630 08:22:16.444484 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 08:22:16.444504 29777 sgd_solver.cpp:106] Iteration 116800, lr = 0.00635
I0630 08:22:32.645952 29777 solver.cpp:290] Iteration 116900 (6.17245 iter/s, 16.201s/100 iter), loss = 0.75
I0630 08:22:32.645977 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:22:32.645987 29777 sgd_solver.cpp:106] Iteration 116900, lr = 0.00634688
I0630 08:22:48.920500 29777 solver.cpp:354] Sparsity after update:
I0630 08:22:48.941114 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:22:48.941129 29777 net.cpp:1851] conv1a_param_0(0.295) 
I0630 08:22:48.941140 29777 net.cpp:1851] conv1b_param_0(0.59) 
I0630 08:22:48.941144 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:22:48.941148 29777 net.cpp:1851] res2a_branch2a_param_0(0.59) 
I0630 08:22:48.941153 29777 net.cpp:1851] res2a_branch2b_param_0(0.59) 
I0630 08:22:48.941155 29777 net.cpp:1851] res3a_branch2a_param_0(0.59) 
I0630 08:22:48.941159 29777 net.cpp:1851] res3a_branch2b_param_0(0.59) 
I0630 08:22:48.941162 29777 net.cpp:1851] res4a_branch2a_param_0(0.59) 
I0630 08:22:48.941165 29777 net.cpp:1851] res4a_branch2b_param_0(0.59) 
I0630 08:22:48.941170 29777 net.cpp:1851] res5a_branch2a_param_0(0.59) 
I0630 08:22:48.941174 29777 net.cpp:1851] res5a_branch2b_param_0(0.59) 
I0630 08:22:48.941177 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.3886e+06/2.86678e+06) 0.484
I0630 08:22:49.102000 29777 solver.cpp:290] Iteration 117000 (6.07697 iter/s, 16.4556s/100 iter), loss = 1.08333
I0630 08:22:49.102027 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:22:49.102036 29777 sgd_solver.cpp:106] Iteration 117000, lr = 0.00634375
I0630 08:23:05.308074 29777 solver.cpp:290] Iteration 117100 (6.17071 iter/s, 16.2056s/100 iter), loss = 0.964286
I0630 08:23:05.308101 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:23:05.308111 29777 sgd_solver.cpp:106] Iteration 117100, lr = 0.00634063
I0630 08:23:21.393532 29777 solver.cpp:290] Iteration 117200 (6.21698 iter/s, 16.085s/100 iter), loss = 1.21429
I0630 08:23:21.393637 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:23:21.393648 29777 sgd_solver.cpp:106] Iteration 117200, lr = 0.0063375
I0630 08:23:37.600213 29777 solver.cpp:290] Iteration 117300 (6.1705 iter/s, 16.2061s/100 iter), loss = 1.04762
I0630 08:23:37.600234 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:23:37.600241 29777 sgd_solver.cpp:106] Iteration 117300, lr = 0.00633438
I0630 08:23:53.681560 29777 solver.cpp:290] Iteration 117400 (6.21856 iter/s, 16.0809s/100 iter), loss = 1.09524
I0630 08:23:53.681638 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:23:53.681645 29777 sgd_solver.cpp:106] Iteration 117400, lr = 0.00633125
I0630 08:24:09.775118 29777 solver.cpp:290] Iteration 117500 (6.21387 iter/s, 16.093s/100 iter), loss = 1.13095
I0630 08:24:09.775141 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 08:24:09.775148 29777 sgd_solver.cpp:106] Iteration 117500, lr = 0.00632813
I0630 08:24:25.888612 29777 solver.cpp:290] Iteration 117600 (6.20616 iter/s, 16.113s/100 iter), loss = 1.13095
I0630 08:24:25.888716 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:24:25.888726 29777 sgd_solver.cpp:106] Iteration 117600, lr = 0.006325
I0630 08:24:41.987941 29777 solver.cpp:290] Iteration 117700 (6.21165 iter/s, 16.0988s/100 iter), loss = 1.21429
I0630 08:24:41.987965 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:24:41.987974 29777 sgd_solver.cpp:106] Iteration 117700, lr = 0.00632187
I0630 08:24:58.214001 29777 solver.cpp:290] Iteration 117800 (6.1631 iter/s, 16.2256s/100 iter), loss = 0.666667
I0630 08:24:58.214092 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 08:24:58.214103 29777 sgd_solver.cpp:106] Iteration 117800, lr = 0.00631875
I0630 08:25:14.323825 29777 solver.cpp:290] Iteration 117900 (6.2076 iter/s, 16.1093s/100 iter), loss = 1.03571
I0630 08:25:14.323873 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:25:14.323894 29777 sgd_solver.cpp:106] Iteration 117900, lr = 0.00631562
I0630 08:25:30.290593 29777 solver.cpp:354] Sparsity after update:
I0630 08:25:30.292053 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:25:30.292062 29777 net.cpp:1851] conv1a_param_0(0.295) 
I0630 08:25:30.292069 29777 net.cpp:1851] conv1b_param_0(0.59) 
I0630 08:25:30.292071 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:25:30.292073 29777 net.cpp:1851] res2a_branch2a_param_0(0.59) 
I0630 08:25:30.292075 29777 net.cpp:1851] res2a_branch2b_param_0(0.59) 
I0630 08:25:30.292078 29777 net.cpp:1851] res3a_branch2a_param_0(0.59) 
I0630 08:25:30.292079 29777 net.cpp:1851] res3a_branch2b_param_0(0.59) 
I0630 08:25:30.292081 29777 net.cpp:1851] res4a_branch2a_param_0(0.59) 
I0630 08:25:30.292083 29777 net.cpp:1851] res4a_branch2b_param_0(0.59) 
I0630 08:25:30.292085 29777 net.cpp:1851] res5a_branch2a_param_0(0.59) 
I0630 08:25:30.292086 29777 net.cpp:1851] res5a_branch2b_param_0(0.59) 
I0630 08:25:30.292088 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.3886e+06/2.86678e+06) 0.484
I0630 08:25:30.292182 29777 solver.cpp:471] Iteration 118000, Testing net (#0)
I0630 08:25:41.829180 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:26:33.348059 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56882
I0630 08:26:33.348166 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.803421
I0630 08:26:33.348176 29777 solver.cpp:544]     Test net output #2: loss = 1.5295 (* 1 = 1.5295 loss)
I0630 08:26:33.542799 29777 solver.cpp:290] Iteration 118000 (1.26236 iter/s, 79.2168s/100 iter), loss = 1.32143
I0630 08:26:33.542824 29777 solver.cpp:309]     Train net output #0: loss = 1.78571 (* 1 = 1.78571 loss)
I0630 08:26:33.542840 29777 sgd_solver.cpp:106] Iteration 118000, lr = 0.0063125
I0630 08:26:33.543828 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.6
I0630 08:26:33.968734 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:26:50.103344 29777 solver.cpp:290] Iteration 118100 (6.03862 iter/s, 16.5601s/100 iter), loss = 1.17857
I0630 08:26:50.103368 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:26:50.103374 29777 sgd_solver.cpp:106] Iteration 118100, lr = 0.00630937
I0630 08:27:06.355602 29777 solver.cpp:290] Iteration 118200 (6.15317 iter/s, 16.2518s/100 iter), loss = 0.928571
I0630 08:27:06.355684 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:27:06.355692 29777 sgd_solver.cpp:106] Iteration 118200, lr = 0.00630625
I0630 08:27:22.747236 29777 solver.cpp:290] Iteration 118300 (6.10087 iter/s, 16.3911s/100 iter), loss = 1.0119
I0630 08:27:22.747265 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 08:27:22.747273 29777 sgd_solver.cpp:106] Iteration 118300, lr = 0.00630313
I0630 08:27:39.019071 29777 solver.cpp:290] Iteration 118400 (6.14577 iter/s, 16.2714s/100 iter), loss = 1.25
I0630 08:27:39.019196 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 08:27:39.019210 29777 sgd_solver.cpp:106] Iteration 118400, lr = 0.0063
I0630 08:27:55.228672 29777 solver.cpp:290] Iteration 118500 (6.1694 iter/s, 16.209s/100 iter), loss = 1.19048
I0630 08:27:55.228698 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 08:27:55.228704 29777 sgd_solver.cpp:106] Iteration 118500, lr = 0.00629687
I0630 08:28:11.569475 29777 solver.cpp:290] Iteration 118600 (6.11983 iter/s, 16.3403s/100 iter), loss = 1.05952
I0630 08:28:11.569546 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 08:28:11.569555 29777 sgd_solver.cpp:106] Iteration 118600, lr = 0.00629375
I0630 08:28:27.824003 29777 solver.cpp:290] Iteration 118700 (6.15233 iter/s, 16.254s/100 iter), loss = 0.880952
I0630 08:28:27.824024 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:28:27.824031 29777 sgd_solver.cpp:106] Iteration 118700, lr = 0.00629063
I0630 08:28:43.954242 29777 solver.cpp:290] Iteration 118800 (6.19971 iter/s, 16.1298s/100 iter), loss = 0.75
I0630 08:28:43.954315 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:28:43.954324 29777 sgd_solver.cpp:106] Iteration 118800, lr = 0.0062875
I0630 08:29:00.247769 29777 solver.cpp:290] Iteration 118900 (6.13761 iter/s, 16.293s/100 iter), loss = 1.39286
I0630 08:29:00.247833 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 08:29:00.247856 29777 sgd_solver.cpp:106] Iteration 118900, lr = 0.00628438
I0630 08:29:16.440778 29777 solver.cpp:354] Sparsity after update:
I0630 08:29:16.461040 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:29:16.461063 29777 net.cpp:1851] conv1a_param_0(0.3) 
I0630 08:29:16.461076 29777 net.cpp:1851] conv1b_param_0(0.6) 
I0630 08:29:16.461081 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:29:16.461084 29777 net.cpp:1851] res2a_branch2a_param_0(0.6) 
I0630 08:29:16.461102 29777 net.cpp:1851] res2a_branch2b_param_0(0.6) 
I0630 08:29:16.461117 29777 net.cpp:1851] res3a_branch2a_param_0(0.6) 
I0630 08:29:16.461122 29777 net.cpp:1851] res3a_branch2b_param_0(0.6) 
I0630 08:29:16.461127 29777 net.cpp:1851] res4a_branch2a_param_0(0.6) 
I0630 08:29:16.461130 29777 net.cpp:1851] res4a_branch2b_param_0(0.6) 
I0630 08:29:16.461133 29777 net.cpp:1851] res5a_branch2a_param_0(0.6) 
I0630 08:29:16.461145 29777 net.cpp:1851] res5a_branch2b_param_0(0.6) 
I0630 08:29:16.461150 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.41214e+06/2.86678e+06) 0.493
I0630 08:29:16.618075 29777 solver.cpp:290] Iteration 119000 (6.10881 iter/s, 16.3698s/100 iter), loss = 0.97619
I0630 08:29:16.618098 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:29:16.618105 29777 sgd_solver.cpp:106] Iteration 119000, lr = 0.00628125
I0630 08:29:32.934602 29777 solver.cpp:290] Iteration 119100 (6.12893 iter/s, 16.3161s/100 iter), loss = 1.36905
I0630 08:29:32.934625 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 08:29:32.934631 29777 sgd_solver.cpp:106] Iteration 119100, lr = 0.00627813
I0630 08:29:49.086527 29777 solver.cpp:290] Iteration 119200 (6.19139 iter/s, 16.1515s/100 iter), loss = 1.21429
I0630 08:29:49.086630 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:29:49.086642 29777 sgd_solver.cpp:106] Iteration 119200, lr = 0.006275
I0630 08:30:05.380281 29777 solver.cpp:290] Iteration 119300 (6.13753 iter/s, 16.2932s/100 iter), loss = 1.07143
I0630 08:30:05.380372 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 08:30:05.380410 29777 sgd_solver.cpp:106] Iteration 119300, lr = 0.00627187
I0630 08:30:21.774119 29777 solver.cpp:290] Iteration 119400 (6.10005 iter/s, 16.3933s/100 iter), loss = 1.11905
I0630 08:30:21.774188 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 08:30:21.774196 29777 sgd_solver.cpp:106] Iteration 119400, lr = 0.00626875
I0630 08:30:37.998144 29777 solver.cpp:290] Iteration 119500 (6.16389 iter/s, 16.2235s/100 iter), loss = 1.14286
I0630 08:30:37.998169 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 08:30:37.998178 29777 sgd_solver.cpp:106] Iteration 119500, lr = 0.00626562
I0630 08:30:54.327968 29777 solver.cpp:290] Iteration 119600 (6.12395 iter/s, 16.3293s/100 iter), loss = 1
I0630 08:30:54.328045 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 08:30:54.328054 29777 sgd_solver.cpp:106] Iteration 119600, lr = 0.0062625
I0630 08:31:10.504844 29777 solver.cpp:290] Iteration 119700 (6.18186 iter/s, 16.1764s/100 iter), loss = 1.16667
I0630 08:31:10.504868 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 08:31:10.504874 29777 sgd_solver.cpp:106] Iteration 119700, lr = 0.00625937
I0630 08:31:26.913166 29777 solver.cpp:290] Iteration 119800 (6.09465 iter/s, 16.4078s/100 iter), loss = 1.17857
I0630 08:31:26.913307 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:31:26.913344 29777 sgd_solver.cpp:106] Iteration 119800, lr = 0.00625625
I0630 08:31:43.208776 29777 solver.cpp:290] Iteration 119900 (6.13684 iter/s, 16.295s/100 iter), loss = 1.04762
I0630 08:31:43.208802 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:31:43.208812 29777 sgd_solver.cpp:106] Iteration 119900, lr = 0.00625313
I0630 08:31:59.166673 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_120000.caffemodel
I0630 08:31:59.186028 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_120000.solverstate
I0630 08:31:59.194638 29777 solver.cpp:354] Sparsity after update:
I0630 08:31:59.195613 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:31:59.195622 29777 net.cpp:1851] conv1a_param_0(0.3) 
I0630 08:31:59.195632 29777 net.cpp:1851] conv1b_param_0(0.6) 
I0630 08:31:59.195637 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:31:59.195641 29777 net.cpp:1851] res2a_branch2a_param_0(0.6) 
I0630 08:31:59.195647 29777 net.cpp:1851] res2a_branch2b_param_0(0.6) 
I0630 08:31:59.195649 29777 net.cpp:1851] res3a_branch2a_param_0(0.6) 
I0630 08:31:59.195653 29777 net.cpp:1851] res3a_branch2b_param_0(0.6) 
I0630 08:31:59.195657 29777 net.cpp:1851] res4a_branch2a_param_0(0.6) 
I0630 08:31:59.195662 29777 net.cpp:1851] res4a_branch2b_param_0(0.6) 
I0630 08:31:59.195665 29777 net.cpp:1851] res5a_branch2a_param_0(0.6) 
I0630 08:31:59.195668 29777 net.cpp:1851] res5a_branch2b_param_0(0.6) 
I0630 08:31:59.195673 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.41214e+06/2.86678e+06) 0.493
I0630 08:31:59.195775 29777 solver.cpp:471] Iteration 120000, Testing net (#0)
I0630 08:32:12.745062 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:33:06.412230 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.565979
I0630 08:33:06.412398 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801382
I0630 08:33:06.412420 29777 solver.cpp:544]     Test net output #2: loss = 1.545 (* 1 = 1.545 loss)
I0630 08:33:06.668694 29777 solver.cpp:290] Iteration 120000 (1.19821 iter/s, 83.4576s/100 iter), loss = 1.15476
I0630 08:33:06.668802 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:33:06.668845 29777 sgd_solver.cpp:106] Iteration 120000, lr = 0.00625
I0630 08:33:06.670960 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.61
I0630 08:33:07.211007 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:33:23.595166 29777 solver.cpp:290] Iteration 120100 (5.9081 iter/s, 16.9259s/100 iter), loss = 1.44048
I0630 08:33:23.595190 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 08:33:23.595196 29777 sgd_solver.cpp:106] Iteration 120100, lr = 0.00624687
I0630 08:33:39.615950 29777 solver.cpp:290] Iteration 120200 (6.24207 iter/s, 16.0203s/100 iter), loss = 1.41667
I0630 08:33:39.616060 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:33:39.616080 29777 sgd_solver.cpp:106] Iteration 120200, lr = 0.00624375
I0630 08:33:56.018244 29777 solver.cpp:290] Iteration 120300 (6.09692 iter/s, 16.4017s/100 iter), loss = 1.35714
I0630 08:33:56.018270 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:33:56.018285 29777 sgd_solver.cpp:106] Iteration 120300, lr = 0.00624063
I0630 08:34:12.380879 29777 solver.cpp:290] Iteration 120400 (6.11166 iter/s, 16.3622s/100 iter), loss = 0.97619
I0630 08:34:12.380986 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 08:34:12.381000 29777 sgd_solver.cpp:106] Iteration 120400, lr = 0.0062375
I0630 08:34:28.684070 29777 solver.cpp:290] Iteration 120500 (6.13398 iter/s, 16.3026s/100 iter), loss = 0.77381
I0630 08:34:28.684096 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 08:34:28.684105 29777 sgd_solver.cpp:106] Iteration 120500, lr = 0.00623438
I0630 08:34:44.935412 29777 solver.cpp:290] Iteration 120600 (6.15352 iter/s, 16.2509s/100 iter), loss = 1.25
I0630 08:34:44.935495 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:34:44.935505 29777 sgd_solver.cpp:106] Iteration 120600, lr = 0.00623125
I0630 08:35:01.184883 29777 solver.cpp:290] Iteration 120700 (6.15425 iter/s, 16.2489s/100 iter), loss = 1.19048
I0630 08:35:01.184907 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 08:35:01.184916 29777 sgd_solver.cpp:106] Iteration 120700, lr = 0.00622813
I0630 08:35:17.353598 29777 solver.cpp:290] Iteration 120800 (6.18496 iter/s, 16.1682s/100 iter), loss = 1.17857
I0630 08:35:17.353700 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 08:35:17.353710 29777 sgd_solver.cpp:106] Iteration 120800, lr = 0.006225
I0630 08:35:33.426321 29777 solver.cpp:290] Iteration 120900 (6.22193 iter/s, 16.0722s/100 iter), loss = 1.07143
I0630 08:35:33.426347 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:35:33.426353 29777 sgd_solver.cpp:106] Iteration 120900, lr = 0.00622187
I0630 08:35:49.518206 29777 solver.cpp:354] Sparsity after update:
I0630 08:35:49.538476 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:35:49.538492 29777 net.cpp:1851] conv1a_param_0(0.305) 
I0630 08:35:49.538504 29777 net.cpp:1851] conv1b_param_0(0.61) 
I0630 08:35:49.538508 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:35:49.538511 29777 net.cpp:1851] res2a_branch2a_param_0(0.61) 
I0630 08:35:49.538516 29777 net.cpp:1851] res2a_branch2b_param_0(0.61) 
I0630 08:35:49.538518 29777 net.cpp:1851] res3a_branch2a_param_0(0.61) 
I0630 08:35:49.538522 29777 net.cpp:1851] res3a_branch2b_param_0(0.61) 
I0630 08:35:49.538524 29777 net.cpp:1851] res4a_branch2a_param_0(0.61) 
I0630 08:35:49.538528 29777 net.cpp:1851] res4a_branch2b_param_0(0.61) 
I0630 08:35:49.538532 29777 net.cpp:1851] res5a_branch2a_param_0(0.61) 
I0630 08:35:49.538534 29777 net.cpp:1851] res5a_branch2b_param_0(0.61) 
I0630 08:35:49.538537 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.43568e+06/2.86678e+06) 0.501
I0630 08:35:49.702041 29777 solver.cpp:290] Iteration 121000 (6.1443 iter/s, 16.2752s/100 iter), loss = 1.46429
I0630 08:35:49.702086 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 08:35:49.702098 29777 sgd_solver.cpp:106] Iteration 121000, lr = 0.00621875
I0630 08:36:05.873190 29777 solver.cpp:290] Iteration 121100 (6.18404 iter/s, 16.1707s/100 iter), loss = 0.916667
I0630 08:36:05.873214 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:36:05.873219 29777 sgd_solver.cpp:106] Iteration 121100, lr = 0.00621562
I0630 08:36:22.135720 29777 solver.cpp:290] Iteration 121200 (6.14928 iter/s, 16.2621s/100 iter), loss = 1.21429
I0630 08:36:22.135838 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:36:22.135848 29777 sgd_solver.cpp:106] Iteration 121200, lr = 0.0062125
I0630 08:36:38.361183 29777 solver.cpp:290] Iteration 121300 (6.16337 iter/s, 16.2249s/100 iter), loss = 1
I0630 08:36:38.361207 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:36:38.361214 29777 sgd_solver.cpp:106] Iteration 121300, lr = 0.00620937
I0630 08:36:54.503625 29777 solver.cpp:290] Iteration 121400 (6.19503 iter/s, 16.142s/100 iter), loss = 1.15476
I0630 08:36:54.503718 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 08:36:54.503729 29777 sgd_solver.cpp:106] Iteration 121400, lr = 0.00620625
I0630 08:37:10.702803 29777 solver.cpp:290] Iteration 121500 (6.17336 iter/s, 16.1986s/100 iter), loss = 1.11905
I0630 08:37:10.702829 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 08:37:10.702844 29777 sgd_solver.cpp:106] Iteration 121500, lr = 0.00620312
I0630 08:37:26.801235 29777 solver.cpp:290] Iteration 121600 (6.21197 iter/s, 16.098s/100 iter), loss = 1.15476
I0630 08:37:26.801342 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 08:37:26.801353 29777 sgd_solver.cpp:106] Iteration 121600, lr = 0.0062
I0630 08:37:42.937922 29777 solver.cpp:290] Iteration 121700 (6.19727 iter/s, 16.1361s/100 iter), loss = 0.928571
I0630 08:37:42.937943 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:37:42.937950 29777 sgd_solver.cpp:106] Iteration 121700, lr = 0.00619687
I0630 08:37:59.044009 29777 solver.cpp:290] Iteration 121800 (6.20901 iter/s, 16.1056s/100 iter), loss = 1.08333
I0630 08:37:59.044109 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:37:59.044117 29777 sgd_solver.cpp:106] Iteration 121800, lr = 0.00619375
I0630 08:38:15.083454 29777 solver.cpp:290] Iteration 121900 (6.23484 iter/s, 16.0389s/100 iter), loss = 1.14286
I0630 08:38:15.083479 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:38:15.083485 29777 sgd_solver.cpp:106] Iteration 121900, lr = 0.00619063
I0630 08:38:31.086170 29777 solver.cpp:354] Sparsity after update:
I0630 08:38:31.087604 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:38:31.087612 29777 net.cpp:1851] conv1a_param_0(0.305) 
I0630 08:38:31.087623 29777 net.cpp:1851] conv1b_param_0(0.61) 
I0630 08:38:31.087627 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:38:31.087631 29777 net.cpp:1851] res2a_branch2a_param_0(0.61) 
I0630 08:38:31.087635 29777 net.cpp:1851] res2a_branch2b_param_0(0.61) 
I0630 08:38:31.087641 29777 net.cpp:1851] res3a_branch2a_param_0(0.61) 
I0630 08:38:31.087646 29777 net.cpp:1851] res3a_branch2b_param_0(0.61) 
I0630 08:38:31.087649 29777 net.cpp:1851] res4a_branch2a_param_0(0.61) 
I0630 08:38:31.087653 29777 net.cpp:1851] res4a_branch2b_param_0(0.61) 
I0630 08:38:31.087657 29777 net.cpp:1851] res5a_branch2a_param_0(0.61) 
I0630 08:38:31.087661 29777 net.cpp:1851] res5a_branch2b_param_0(0.61) 
I0630 08:38:31.087666 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.43568e+06/2.86678e+06) 0.501
I0630 08:38:31.087761 29777 solver.cpp:471] Iteration 122000, Testing net (#0)
I0630 08:38:43.554365 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:39:34.559162 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.568719
I0630 08:39:34.559286 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804902
I0630 08:39:34.559296 29777 solver.cpp:544]     Test net output #2: loss = 1.52016 (* 1 = 1.52016 loss)
I0630 08:39:34.742465 29777 solver.cpp:290] Iteration 122000 (1.25539 iter/s, 79.6568s/100 iter), loss = 1.27381
I0630 08:39:34.742488 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 08:39:34.742494 29777 sgd_solver.cpp:106] Iteration 122000, lr = 0.0061875
I0630 08:39:34.743191 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.62
I0630 08:39:35.500141 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:39:51.824208 29777 solver.cpp:290] Iteration 122100 (5.85438 iter/s, 17.0812s/100 iter), loss = 1.39286
I0630 08:39:51.824283 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:39:51.824301 29777 sgd_solver.cpp:106] Iteration 122100, lr = 0.00618438
I0630 08:40:08.128087 29777 solver.cpp:290] Iteration 122200 (6.13371 iter/s, 16.3033s/100 iter), loss = 1.04762
I0630 08:40:08.128226 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:40:08.128243 29777 sgd_solver.cpp:106] Iteration 122200, lr = 0.00618125
I0630 08:40:24.170380 29777 solver.cpp:290] Iteration 122300 (6.23375 iter/s, 16.0417s/100 iter), loss = 1.39286
I0630 08:40:24.170403 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 08:40:24.170410 29777 sgd_solver.cpp:106] Iteration 122300, lr = 0.00617812
I0630 08:40:40.226912 29777 solver.cpp:290] Iteration 122400 (6.22818 iter/s, 16.0561s/100 iter), loss = 1.10714
I0630 08:40:40.227013 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:40:40.227022 29777 sgd_solver.cpp:106] Iteration 122400, lr = 0.006175
I0630 08:40:56.290544 29777 solver.cpp:290] Iteration 122500 (6.22545 iter/s, 16.0631s/100 iter), loss = 1.30952
I0630 08:40:56.290570 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 08:40:56.290580 29777 sgd_solver.cpp:106] Iteration 122500, lr = 0.00617187
I0630 08:41:12.373133 29777 solver.cpp:290] Iteration 122600 (6.21809 iter/s, 16.0821s/100 iter), loss = 1.16667
I0630 08:41:12.373236 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:41:12.373245 29777 sgd_solver.cpp:106] Iteration 122600, lr = 0.00616875
I0630 08:41:28.545722 29777 solver.cpp:290] Iteration 122700 (6.18351 iter/s, 16.172s/100 iter), loss = 1.22619
I0630 08:41:28.545745 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:41:28.545753 29777 sgd_solver.cpp:106] Iteration 122700, lr = 0.00616562
I0630 08:41:44.623886 29777 solver.cpp:290] Iteration 122800 (6.2198 iter/s, 16.0777s/100 iter), loss = 1.35714
I0630 08:41:44.623982 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 08:41:44.623992 29777 sgd_solver.cpp:106] Iteration 122800, lr = 0.0061625
I0630 08:42:00.737437 29777 solver.cpp:290] Iteration 122900 (6.20616 iter/s, 16.113s/100 iter), loss = 1
I0630 08:42:00.737463 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:42:00.737473 29777 sgd_solver.cpp:106] Iteration 122900, lr = 0.00615937
I0630 08:42:16.605516 29777 solver.cpp:354] Sparsity after update:
I0630 08:42:16.626008 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:42:16.626024 29777 net.cpp:1851] conv1a_param_0(0.31) 
I0630 08:42:16.626034 29777 net.cpp:1851] conv1b_param_0(0.62) 
I0630 08:42:16.626037 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:42:16.626040 29777 net.cpp:1851] res2a_branch2a_param_0(0.62) 
I0630 08:42:16.626056 29777 net.cpp:1851] res2a_branch2b_param_0(0.62) 
I0630 08:42:16.626065 29777 net.cpp:1851] res3a_branch2a_param_0(0.62) 
I0630 08:42:16.626073 29777 net.cpp:1851] res3a_branch2b_param_0(0.62) 
I0630 08:42:16.626080 29777 net.cpp:1851] res4a_branch2a_param_0(0.62) 
I0630 08:42:16.626088 29777 net.cpp:1851] res4a_branch2b_param_0(0.62) 
I0630 08:42:16.626096 29777 net.cpp:1851] res5a_branch2a_param_0(0.62) 
I0630 08:42:16.626104 29777 net.cpp:1851] res5a_branch2b_param_0(0.62) 
I0630 08:42:16.626111 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.45921e+06/2.86678e+06) 0.509
I0630 08:42:16.787721 29777 solver.cpp:290] Iteration 123000 (6.2306 iter/s, 16.0498s/100 iter), loss = 0.75
I0630 08:42:16.787747 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 08:42:16.787755 29777 sgd_solver.cpp:106] Iteration 123000, lr = 0.00615625
I0630 08:42:32.954603 29777 solver.cpp:290] Iteration 123100 (6.18567 iter/s, 16.1664s/100 iter), loss = 0.797619
I0630 08:42:32.954627 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 08:42:32.954634 29777 sgd_solver.cpp:106] Iteration 123100, lr = 0.00615312
I0630 08:42:49.056402 29777 solver.cpp:290] Iteration 123200 (6.21067 iter/s, 16.1013s/100 iter), loss = 1.14286
I0630 08:42:49.056506 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:42:49.056529 29777 sgd_solver.cpp:106] Iteration 123200, lr = 0.00615
I0630 08:43:05.325013 29777 solver.cpp:290] Iteration 123300 (6.14702 iter/s, 16.2681s/100 iter), loss = 0.857143
I0630 08:43:05.325073 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 08:43:05.325104 29777 sgd_solver.cpp:106] Iteration 123300, lr = 0.00614687
I0630 08:43:21.608083 29777 solver.cpp:290] Iteration 123400 (6.14154 iter/s, 16.2826s/100 iter), loss = 1.44048
I0630 08:43:21.614898 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 08:43:21.614922 29777 sgd_solver.cpp:106] Iteration 123400, lr = 0.00614375
I0630 08:43:37.889539 29777 solver.cpp:290] Iteration 123500 (6.14469 iter/s, 16.2742s/100 iter), loss = 0.97619
I0630 08:43:37.889564 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:43:37.889570 29777 sgd_solver.cpp:106] Iteration 123500, lr = 0.00614062
I0630 08:43:54.081073 29777 solver.cpp:290] Iteration 123600 (6.17628 iter/s, 16.191s/100 iter), loss = 1.14286
I0630 08:43:54.081444 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 08:43:54.081625 29777 sgd_solver.cpp:106] Iteration 123600, lr = 0.0061375
I0630 08:44:10.399248 29777 solver.cpp:290] Iteration 123700 (6.12842 iter/s, 16.3174s/100 iter), loss = 1.33333
I0630 08:44:10.399271 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 08:44:10.399278 29777 sgd_solver.cpp:106] Iteration 123700, lr = 0.00613437
I0630 08:44:26.913446 29777 solver.cpp:290] Iteration 123800 (6.05557 iter/s, 16.5137s/100 iter), loss = 1.40476
I0630 08:44:26.913606 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 08:44:26.913626 29777 sgd_solver.cpp:106] Iteration 123800, lr = 0.00613125
I0630 08:44:43.275666 29777 solver.cpp:290] Iteration 123900 (6.11187 iter/s, 16.3616s/100 iter), loss = 0.97619
I0630 08:44:43.275732 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:44:43.275769 29777 sgd_solver.cpp:106] Iteration 123900, lr = 0.00612812
I0630 08:44:59.363989 29777 solver.cpp:354] Sparsity after update:
I0630 08:44:59.365947 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:44:59.365963 29777 net.cpp:1851] conv1a_param_0(0.31) 
I0630 08:44:59.365980 29777 net.cpp:1851] conv1b_param_0(0.62) 
I0630 08:44:59.365986 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:44:59.365991 29777 net.cpp:1851] res2a_branch2a_param_0(0.62) 
I0630 08:44:59.365998 29777 net.cpp:1851] res2a_branch2b_param_0(0.62) 
I0630 08:44:59.366003 29777 net.cpp:1851] res3a_branch2a_param_0(0.62) 
I0630 08:44:59.366008 29777 net.cpp:1851] res3a_branch2b_param_0(0.62) 
I0630 08:44:59.366014 29777 net.cpp:1851] res4a_branch2a_param_0(0.62) 
I0630 08:44:59.366019 29777 net.cpp:1851] res4a_branch2b_param_0(0.62) 
I0630 08:44:59.366024 29777 net.cpp:1851] res5a_branch2a_param_0(0.62) 
I0630 08:44:59.366029 29777 net.cpp:1851] res5a_branch2b_param_0(0.62) 
I0630 08:44:59.366037 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.45921e+06/2.86678e+06) 0.509
I0630 08:44:59.366143 29777 solver.cpp:471] Iteration 124000, Testing net (#0)
I0630 08:45:15.595832 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:46:13.628177 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.57044
I0630 08:46:13.628262 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.804482
I0630 08:46:13.628278 29777 solver.cpp:544]     Test net output #2: loss = 1.53716 (* 1 = 1.53716 loss)
I0630 08:46:13.834507 29777 solver.cpp:290] Iteration 124000 (1.10429 iter/s, 90.5563s/100 iter), loss = 0.940476
I0630 08:46:13.834540 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 08:46:13.834552 29777 sgd_solver.cpp:106] Iteration 124000, lr = 0.006125
I0630 08:46:13.835953 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.63
I0630 08:46:14.589928 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:46:30.839817 29777 solver.cpp:290] Iteration 124100 (5.88069 iter/s, 17.0048s/100 iter), loss = 1.20238
I0630 08:46:30.839843 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:46:30.839849 29777 sgd_solver.cpp:106] Iteration 124100, lr = 0.00612187
I0630 08:46:47.378805 29777 solver.cpp:290] Iteration 124200 (6.04649 iter/s, 16.5385s/100 iter), loss = 1.21429
I0630 08:46:47.379110 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:46:47.379232 29777 sgd_solver.cpp:106] Iteration 124200, lr = 0.00611875
I0630 08:47:03.790946 29777 solver.cpp:290] Iteration 124300 (6.09333 iter/s, 16.4114s/100 iter), loss = 1.36905
I0630 08:47:03.790977 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 08:47:03.790987 29777 sgd_solver.cpp:106] Iteration 124300, lr = 0.00611562
I0630 08:47:20.036160 29777 solver.cpp:290] Iteration 124400 (6.15584 iter/s, 16.2447s/100 iter), loss = 0.97619
I0630 08:47:20.036263 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:47:20.036273 29777 sgd_solver.cpp:106] Iteration 124400, lr = 0.0061125
I0630 08:47:36.261740 29777 solver.cpp:290] Iteration 124500 (6.16331 iter/s, 16.225s/100 iter), loss = 1.04762
I0630 08:47:36.261770 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 08:47:36.261782 29777 sgd_solver.cpp:106] Iteration 124500, lr = 0.00610937
I0630 08:47:52.570355 29777 solver.cpp:290] Iteration 124600 (6.13191 iter/s, 16.3081s/100 iter), loss = 0.988095
I0630 08:47:52.570469 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 08:47:52.570497 29777 sgd_solver.cpp:106] Iteration 124600, lr = 0.00610625
I0630 08:48:08.837975 29777 solver.cpp:290] Iteration 124700 (6.14739 iter/s, 16.2671s/100 iter), loss = 1.32143
I0630 08:48:08.838006 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:48:08.838016 29777 sgd_solver.cpp:106] Iteration 124700, lr = 0.00610312
I0630 08:48:25.160842 29777 solver.cpp:290] Iteration 124800 (6.12655 iter/s, 16.3224s/100 iter), loss = 1.11905
I0630 08:48:25.160959 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 08:48:25.160969 29777 sgd_solver.cpp:106] Iteration 124800, lr = 0.0061
I0630 08:48:41.429492 29777 solver.cpp:290] Iteration 124900 (6.14701 iter/s, 16.2681s/100 iter), loss = 1.44048
I0630 08:48:41.429584 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 08:48:41.429616 29777 sgd_solver.cpp:106] Iteration 124900, lr = 0.00609687
I0630 08:48:57.484591 29777 solver.cpp:354] Sparsity after update:
I0630 08:48:57.504988 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:48:57.505003 29777 net.cpp:1851] conv1a_param_0(0.315) 
I0630 08:48:57.505013 29777 net.cpp:1851] conv1b_param_0(0.63) 
I0630 08:48:57.505017 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:48:57.505020 29777 net.cpp:1851] res2a_branch2a_param_0(0.63) 
I0630 08:48:57.505023 29777 net.cpp:1851] res2a_branch2b_param_0(0.63) 
I0630 08:48:57.505026 29777 net.cpp:1851] res3a_branch2a_param_0(0.63) 
I0630 08:48:57.505029 29777 net.cpp:1851] res3a_branch2b_param_0(0.63) 
I0630 08:48:57.505033 29777 net.cpp:1851] res4a_branch2a_param_0(0.63) 
I0630 08:48:57.505036 29777 net.cpp:1851] res4a_branch2b_param_0(0.63) 
I0630 08:48:57.505039 29777 net.cpp:1851] res5a_branch2a_param_0(0.63) 
I0630 08:48:57.505043 29777 net.cpp:1851] res5a_branch2b_param_0(0.63) 
I0630 08:48:57.505045 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.48275e+06/2.86678e+06) 0.517
I0630 08:48:57.662609 29777 solver.cpp:290] Iteration 125000 (6.16044 iter/s, 16.2326s/100 iter), loss = 1.14286
I0630 08:48:57.662636 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 08:48:57.662642 29777 sgd_solver.cpp:106] Iteration 125000, lr = 0.00609375
I0630 08:49:13.792953 29777 solver.cpp:290] Iteration 125100 (6.19967 iter/s, 16.1299s/100 iter), loss = 1.22619
I0630 08:49:13.792974 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:49:13.792982 29777 sgd_solver.cpp:106] Iteration 125100, lr = 0.00609062
I0630 08:49:30.143087 29777 solver.cpp:290] Iteration 125200 (6.11633 iter/s, 16.3497s/100 iter), loss = 0.928571
I0630 08:49:30.143174 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:49:30.143182 29777 sgd_solver.cpp:106] Iteration 125200, lr = 0.0060875
I0630 08:49:46.457427 29777 solver.cpp:290] Iteration 125300 (6.12978 iter/s, 16.3138s/100 iter), loss = 1.13095
I0630 08:49:46.457532 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:49:46.457572 29777 sgd_solver.cpp:106] Iteration 125300, lr = 0.00608438
I0630 08:50:02.671777 29777 solver.cpp:290] Iteration 125400 (6.16758 iter/s, 16.2138s/100 iter), loss = 1.38095
I0630 08:50:02.671916 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 08:50:02.671962 29777 sgd_solver.cpp:106] Iteration 125400, lr = 0.00608125
I0630 08:50:18.986888 29777 solver.cpp:290] Iteration 125500 (6.1295 iter/s, 16.3145s/100 iter), loss = 1.20238
I0630 08:50:18.986994 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:50:18.987028 29777 sgd_solver.cpp:106] Iteration 125500, lr = 0.00607812
I0630 08:50:35.308106 29777 solver.cpp:290] Iteration 125600 (6.1272 iter/s, 16.3207s/100 iter), loss = 1.11905
I0630 08:50:35.308181 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 08:50:35.308187 29777 sgd_solver.cpp:106] Iteration 125600, lr = 0.006075
I0630 08:50:51.730250 29777 solver.cpp:290] Iteration 125700 (6.08953 iter/s, 16.4216s/100 iter), loss = 0.821428
I0630 08:50:51.730306 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 08:50:51.730329 29777 sgd_solver.cpp:106] Iteration 125700, lr = 0.00607187
I0630 08:51:08.031261 29777 solver.cpp:290] Iteration 125800 (6.13477 iter/s, 16.3005s/100 iter), loss = 0.952381
I0630 08:51:08.031344 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 08:51:08.031352 29777 sgd_solver.cpp:106] Iteration 125800, lr = 0.00606875
I0630 08:51:24.167966 29777 solver.cpp:290] Iteration 125900 (6.19725 iter/s, 16.1362s/100 iter), loss = 1.0119
I0630 08:51:24.167992 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:51:24.167999 29777 sgd_solver.cpp:106] Iteration 125900, lr = 0.00606562
I0630 08:51:40.312041 29777 solver.cpp:354] Sparsity after update:
I0630 08:51:40.313486 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:51:40.313494 29777 net.cpp:1851] conv1a_param_0(0.315) 
I0630 08:51:40.313503 29777 net.cpp:1851] conv1b_param_0(0.63) 
I0630 08:51:40.313504 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:51:40.313508 29777 net.cpp:1851] res2a_branch2a_param_0(0.63) 
I0630 08:51:40.313509 29777 net.cpp:1851] res2a_branch2b_param_0(0.63) 
I0630 08:51:40.313511 29777 net.cpp:1851] res3a_branch2a_param_0(0.63) 
I0630 08:51:40.313514 29777 net.cpp:1851] res3a_branch2b_param_0(0.63) 
I0630 08:51:40.313516 29777 net.cpp:1851] res4a_branch2a_param_0(0.63) 
I0630 08:51:40.313519 29777 net.cpp:1851] res4a_branch2b_param_0(0.63) 
I0630 08:51:40.313521 29777 net.cpp:1851] res5a_branch2a_param_0(0.63) 
I0630 08:51:40.313524 29777 net.cpp:1851] res5a_branch2b_param_0(0.63) 
I0630 08:51:40.313525 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.48275e+06/2.86678e+06) 0.517
I0630 08:51:40.313612 29777 solver.cpp:471] Iteration 126000, Testing net (#0)
I0630 08:51:54.066119 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:52:45.013309 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5678
I0630 08:52:45.013412 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.802161
I0630 08:52:45.013422 29777 solver.cpp:544]     Test net output #2: loss = 1.53408 (* 1 = 1.53408 loss)
I0630 08:52:45.204396 29777 solver.cpp:290] Iteration 126000 (1.23405 iter/s, 81.0342s/100 iter), loss = 1
I0630 08:52:45.204432 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 08:52:45.204442 29777 sgd_solver.cpp:106] Iteration 126000, lr = 0.0060625
I0630 08:52:45.205538 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.64
I0630 08:52:45.733831 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:53:01.805825 29777 solver.cpp:290] Iteration 126100 (6.02376 iter/s, 16.6009s/100 iter), loss = 1.02381
I0630 08:53:01.805915 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 08:53:01.805946 29777 sgd_solver.cpp:106] Iteration 126100, lr = 0.00605937
I0630 08:53:17.981392 29777 solver.cpp:290] Iteration 126200 (6.18237 iter/s, 16.175s/100 iter), loss = 1.04762
I0630 08:53:17.981791 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 08:53:17.981801 29777 sgd_solver.cpp:106] Iteration 126200, lr = 0.00605625
I0630 08:53:34.086359 29777 solver.cpp:290] Iteration 126300 (6.20959 iter/s, 16.1041s/100 iter), loss = 1.07143
I0630 08:53:34.086381 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 08:53:34.086387 29777 sgd_solver.cpp:106] Iteration 126300, lr = 0.00605312
I0630 08:53:50.187671 29777 solver.cpp:290] Iteration 126400 (6.21085 iter/s, 16.1008s/100 iter), loss = 1.66667
I0630 08:53:50.187765 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 08:53:50.187777 29777 sgd_solver.cpp:106] Iteration 126400, lr = 0.00605
I0630 08:54:06.299789 29777 solver.cpp:290] Iteration 126500 (6.20671 iter/s, 16.1116s/100 iter), loss = 1.38095
I0630 08:54:06.299811 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 08:54:06.299818 29777 sgd_solver.cpp:106] Iteration 126500, lr = 0.00604687
I0630 08:54:22.445708 29777 solver.cpp:290] Iteration 126600 (6.19369 iter/s, 16.1455s/100 iter), loss = 1.10714
I0630 08:54:22.445787 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 08:54:22.445799 29777 sgd_solver.cpp:106] Iteration 126600, lr = 0.00604375
I0630 08:54:38.549582 29777 solver.cpp:290] Iteration 126700 (6.20989 iter/s, 16.1034s/100 iter), loss = 1.5
I0630 08:54:38.549607 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 08:54:38.549615 29777 sgd_solver.cpp:106] Iteration 126700, lr = 0.00604062
I0630 08:54:54.659253 29777 solver.cpp:290] Iteration 126800 (6.20763 iter/s, 16.1092s/100 iter), loss = 1.35714
I0630 08:54:54.659323 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 08:54:54.659332 29777 sgd_solver.cpp:106] Iteration 126800, lr = 0.0060375
I0630 08:55:10.901685 29777 solver.cpp:290] Iteration 126900 (6.15691 iter/s, 16.2419s/100 iter), loss = 0.988095
I0630 08:55:10.901715 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:55:10.901722 29777 sgd_solver.cpp:106] Iteration 126900, lr = 0.00603438
I0630 08:55:26.861246 29777 solver.cpp:354] Sparsity after update:
I0630 08:55:26.882738 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:55:26.882760 29777 net.cpp:1851] conv1a_param_0(0.32) 
I0630 08:55:26.882771 29777 net.cpp:1851] conv1b_param_0(0.64) 
I0630 08:55:26.882773 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:55:26.882777 29777 net.cpp:1851] res2a_branch2a_param_0(0.64) 
I0630 08:55:26.882783 29777 net.cpp:1851] res2a_branch2b_param_0(0.64) 
I0630 08:55:26.882786 29777 net.cpp:1851] res3a_branch2a_param_0(0.64) 
I0630 08:55:26.882789 29777 net.cpp:1851] res3a_branch2b_param_0(0.64) 
I0630 08:55:26.882792 29777 net.cpp:1851] res4a_branch2a_param_0(0.64) 
I0630 08:55:26.882797 29777 net.cpp:1851] res4a_branch2b_param_0(0.64) 
I0630 08:55:26.882800 29777 net.cpp:1851] res5a_branch2a_param_0(0.64) 
I0630 08:55:26.882804 29777 net.cpp:1851] res5a_branch2b_param_0(0.64) 
I0630 08:55:26.882808 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.50629e+06/2.86678e+06) 0.525
I0630 08:55:27.050297 29777 solver.cpp:290] Iteration 127000 (6.19266 iter/s, 16.1481s/100 iter), loss = 1.07143
I0630 08:55:27.050323 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 08:55:27.050331 29777 sgd_solver.cpp:106] Iteration 127000, lr = 0.00603125
I0630 08:55:43.114858 29777 solver.cpp:290] Iteration 127100 (6.22506 iter/s, 16.0641s/100 iter), loss = 0.952381
I0630 08:55:43.114881 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 08:55:43.114887 29777 sgd_solver.cpp:106] Iteration 127100, lr = 0.00602813
I0630 08:55:59.792313 29777 solver.cpp:290] Iteration 127200 (5.99629 iter/s, 16.677s/100 iter), loss = 1.53571
I0630 08:55:59.798913 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 08:55:59.798943 29777 sgd_solver.cpp:106] Iteration 127200, lr = 0.006025
I0630 08:56:15.943640 29777 solver.cpp:290] Iteration 127300 (6.19414 iter/s, 16.1443s/100 iter), loss = 1.34524
I0630 08:56:15.943665 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:56:15.943671 29777 sgd_solver.cpp:106] Iteration 127300, lr = 0.00602187
I0630 08:56:32.055953 29777 solver.cpp:290] Iteration 127400 (6.20661 iter/s, 16.1118s/100 iter), loss = 1.61905
I0630 08:56:32.056066 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 08:56:32.056076 29777 sgd_solver.cpp:106] Iteration 127400, lr = 0.00601875
I0630 08:56:48.160037 29777 solver.cpp:290] Iteration 127500 (6.20982 iter/s, 16.1035s/100 iter), loss = 1.07143
I0630 08:56:48.160073 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 08:56:48.160082 29777 sgd_solver.cpp:106] Iteration 127500, lr = 0.00601562
I0630 08:57:04.178724 29777 solver.cpp:290] Iteration 127600 (6.24289 iter/s, 16.0182s/100 iter), loss = 1.02381
I0630 08:57:04.178856 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 08:57:04.178874 29777 sgd_solver.cpp:106] Iteration 127600, lr = 0.0060125
I0630 08:57:20.130977 29777 solver.cpp:290] Iteration 127700 (6.26893 iter/s, 15.9517s/100 iter), loss = 0.821428
I0630 08:57:20.131001 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 08:57:20.131011 29777 sgd_solver.cpp:106] Iteration 127700, lr = 0.00600937
I0630 08:57:36.282450 29777 solver.cpp:290] Iteration 127800 (6.19157 iter/s, 16.151s/100 iter), loss = 1.04762
I0630 08:57:36.282546 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 08:57:36.282567 29777 sgd_solver.cpp:106] Iteration 127800, lr = 0.00600625
I0630 08:57:52.302196 29777 solver.cpp:290] Iteration 127900 (6.2425 iter/s, 16.0192s/100 iter), loss = 1
I0630 08:57:52.302227 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 08:57:52.302234 29777 sgd_solver.cpp:106] Iteration 127900, lr = 0.00600312
I0630 08:58:08.301021 29777 solver.cpp:354] Sparsity after update:
I0630 08:58:08.302662 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 08:58:08.302670 29777 net.cpp:1851] conv1a_param_0(0.32) 
I0630 08:58:08.302677 29777 net.cpp:1851] conv1b_param_0(0.64) 
I0630 08:58:08.302680 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 08:58:08.302682 29777 net.cpp:1851] res2a_branch2a_param_0(0.64) 
I0630 08:58:08.302685 29777 net.cpp:1851] res2a_branch2b_param_0(0.64) 
I0630 08:58:08.302686 29777 net.cpp:1851] res3a_branch2a_param_0(0.64) 
I0630 08:58:08.302688 29777 net.cpp:1851] res3a_branch2b_param_0(0.64) 
I0630 08:58:08.302691 29777 net.cpp:1851] res4a_branch2a_param_0(0.64) 
I0630 08:58:08.302693 29777 net.cpp:1851] res4a_branch2b_param_0(0.64) 
I0630 08:58:08.302695 29777 net.cpp:1851] res5a_branch2a_param_0(0.64) 
I0630 08:58:08.302698 29777 net.cpp:1851] res5a_branch2b_param_0(0.64) 
I0630 08:58:08.302700 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.50629e+06/2.86678e+06) 0.525
I0630 08:58:08.302788 29777 solver.cpp:471] Iteration 128000, Testing net (#0)
I0630 08:58:20.508844 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 08:59:08.896580 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5667
I0630 08:59:08.896620 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801702
I0630 08:59:08.896625 29777 solver.cpp:544]     Test net output #2: loss = 1.53722 (* 1 = 1.53722 loss)
I0630 08:59:09.070977 29777 solver.cpp:290] Iteration 128000 (1.30265 iter/s, 76.7667s/100 iter), loss = 1.53571
I0630 08:59:09.071008 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 08:59:09.071015 29777 sgd_solver.cpp:106] Iteration 128000, lr = 0.006
I0630 08:59:09.071756 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.65
I0630 08:59:09.548189 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 08:59:25.609868 29777 solver.cpp:290] Iteration 128100 (6.04653 iter/s, 16.5384s/100 iter), loss = 1.07143
I0630 08:59:25.609895 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 08:59:25.609941 29777 sgd_solver.cpp:106] Iteration 128100, lr = 0.00599687
I0630 08:59:41.600159 29777 solver.cpp:290] Iteration 128200 (6.25398 iter/s, 15.9898s/100 iter), loss = 1.35714
I0630 08:59:41.600215 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 08:59:41.600227 29777 sgd_solver.cpp:106] Iteration 128200, lr = 0.00599375
I0630 08:59:57.669185 29777 solver.cpp:290] Iteration 128300 (6.22334 iter/s, 16.0685s/100 iter), loss = 1.25
I0630 08:59:57.669214 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 08:59:57.669224 29777 sgd_solver.cpp:106] Iteration 128300, lr = 0.00599062
I0630 09:00:13.805974 29777 solver.cpp:290] Iteration 128400 (6.1972 iter/s, 16.1363s/100 iter), loss = 1.34524
I0630 09:00:13.806088 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 09:00:13.806100 29777 sgd_solver.cpp:106] Iteration 128400, lr = 0.0059875
I0630 09:00:30.023108 29777 solver.cpp:290] Iteration 128500 (6.16653 iter/s, 16.2166s/100 iter), loss = 1.05952
I0630 09:00:30.023130 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 09:00:30.023140 29777 sgd_solver.cpp:106] Iteration 128500, lr = 0.00598437
I0630 09:00:46.249060 29777 solver.cpp:290] Iteration 128600 (6.16315 iter/s, 16.2255s/100 iter), loss = 1.02381
I0630 09:00:46.249135 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 09:00:46.249147 29777 sgd_solver.cpp:106] Iteration 128600, lr = 0.00598125
I0630 09:01:02.726933 29777 solver.cpp:290] Iteration 128700 (6.06894 iter/s, 16.4774s/100 iter), loss = 0.97619
I0630 09:01:02.726955 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 09:01:02.726963 29777 sgd_solver.cpp:106] Iteration 128700, lr = 0.00597813
I0630 09:01:18.912879 29777 solver.cpp:290] Iteration 128800 (6.17838 iter/s, 16.1855s/100 iter), loss = 1.22619
I0630 09:01:18.912938 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:01:18.912950 29777 sgd_solver.cpp:106] Iteration 128800, lr = 0.005975
I0630 09:01:34.927116 29777 solver.cpp:290] Iteration 128900 (6.24464 iter/s, 16.0137s/100 iter), loss = 1.15476
I0630 09:01:34.927140 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:01:34.927147 29777 sgd_solver.cpp:106] Iteration 128900, lr = 0.00597188
I0630 09:01:51.060925 29777 solver.cpp:354] Sparsity after update:
I0630 09:01:51.081272 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:01:51.081288 29777 net.cpp:1851] conv1a_param_0(0.325) 
I0630 09:01:51.081298 29777 net.cpp:1851] conv1b_param_0(0.65) 
I0630 09:01:51.081302 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:01:51.081305 29777 net.cpp:1851] res2a_branch2a_param_0(0.65) 
I0630 09:01:51.081310 29777 net.cpp:1851] res2a_branch2b_param_0(0.65) 
I0630 09:01:51.081312 29777 net.cpp:1851] res3a_branch2a_param_0(0.65) 
I0630 09:01:51.081315 29777 net.cpp:1851] res3a_branch2b_param_0(0.65) 
I0630 09:01:51.081320 29777 net.cpp:1851] res4a_branch2a_param_0(0.65) 
I0630 09:01:51.081322 29777 net.cpp:1851] res4a_branch2b_param_0(0.65) 
I0630 09:01:51.081326 29777 net.cpp:1851] res5a_branch2a_param_0(0.65) 
I0630 09:01:51.081329 29777 net.cpp:1851] res5a_branch2b_param_0(0.65) 
I0630 09:01:51.081332 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.52982e+06/2.86678e+06) 0.534
I0630 09:01:51.242887 29777 solver.cpp:290] Iteration 129000 (6.12922 iter/s, 16.3153s/100 iter), loss = 1.47619
I0630 09:01:51.243005 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 09:01:51.243058 29777 sgd_solver.cpp:106] Iteration 129000, lr = 0.00596875
I0630 09:02:07.666628 29777 solver.cpp:290] Iteration 129100 (6.08895 iter/s, 16.4232s/100 iter), loss = 1.33333
I0630 09:02:07.666693 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:02:07.666713 29777 sgd_solver.cpp:106] Iteration 129100, lr = 0.00596562
I0630 09:02:24.151291 29777 solver.cpp:290] Iteration 129200 (6.06643 iter/s, 16.4842s/100 iter), loss = 1
I0630 09:02:24.151396 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:02:24.151406 29777 sgd_solver.cpp:106] Iteration 129200, lr = 0.0059625
I0630 09:02:40.207111 29777 solver.cpp:290] Iteration 129300 (6.22848 iter/s, 16.0553s/100 iter), loss = 0.928571
I0630 09:02:40.207144 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 09:02:40.207154 29777 sgd_solver.cpp:106] Iteration 129300, lr = 0.00595937
I0630 09:02:56.455726 29777 solver.cpp:290] Iteration 129400 (6.15455 iter/s, 16.2481s/100 iter), loss = 1.27381
I0630 09:02:56.455843 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:02:56.455853 29777 sgd_solver.cpp:106] Iteration 129400, lr = 0.00595625
I0630 09:03:12.853202 29777 solver.cpp:290] Iteration 129500 (6.09871 iter/s, 16.3969s/100 iter), loss = 1.02381
I0630 09:03:12.853226 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:03:12.853233 29777 sgd_solver.cpp:106] Iteration 129500, lr = 0.00595312
I0630 09:03:29.299922 29777 solver.cpp:290] Iteration 129600 (6.08042 iter/s, 16.4462s/100 iter), loss = 0.916667
I0630 09:03:29.300027 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:03:29.300040 29777 sgd_solver.cpp:106] Iteration 129600, lr = 0.00595
I0630 09:03:45.425953 29777 solver.cpp:290] Iteration 129700 (6.20136 iter/s, 16.1255s/100 iter), loss = 1.36905
I0630 09:03:45.425978 29777 solver.cpp:309]     Train net output #0: loss = 2.04762 (* 1 = 2.04762 loss)
I0630 09:03:45.425987 29777 sgd_solver.cpp:106] Iteration 129700, lr = 0.00594687
I0630 09:04:01.646579 29777 solver.cpp:290] Iteration 129800 (6.16517 iter/s, 16.2202s/100 iter), loss = 1.13095
I0630 09:04:01.646684 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:04:01.646694 29777 sgd_solver.cpp:106] Iteration 129800, lr = 0.00594375
I0630 09:04:17.787869 29777 solver.cpp:290] Iteration 129900 (6.1955 iter/s, 16.1407s/100 iter), loss = 1.21429
I0630 09:04:17.787894 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:04:17.787900 29777 sgd_solver.cpp:106] Iteration 129900, lr = 0.00594062
I0630 09:04:33.992607 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_130000.caffemodel
I0630 09:04:34.011883 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_130000.solverstate
I0630 09:04:34.020962 29777 solver.cpp:354] Sparsity after update:
I0630 09:04:34.021946 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:04:34.021955 29777 net.cpp:1851] conv1a_param_0(0.325) 
I0630 09:04:34.021961 29777 net.cpp:1851] conv1b_param_0(0.65) 
I0630 09:04:34.021965 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:04:34.021966 29777 net.cpp:1851] res2a_branch2a_param_0(0.65) 
I0630 09:04:34.021968 29777 net.cpp:1851] res2a_branch2b_param_0(0.65) 
I0630 09:04:34.021970 29777 net.cpp:1851] res3a_branch2a_param_0(0.65) 
I0630 09:04:34.021972 29777 net.cpp:1851] res3a_branch2b_param_0(0.65) 
I0630 09:04:34.021975 29777 net.cpp:1851] res4a_branch2a_param_0(0.65) 
I0630 09:04:34.021976 29777 net.cpp:1851] res4a_branch2b_param_0(0.65) 
I0630 09:04:34.021977 29777 net.cpp:1851] res5a_branch2a_param_0(0.65) 
I0630 09:04:34.021980 29777 net.cpp:1851] res5a_branch2b_param_0(0.65) 
I0630 09:04:34.021982 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.52982e+06/2.86678e+06) 0.534
I0630 09:04:34.022084 29777 solver.cpp:471] Iteration 130000, Testing net (#0)
I0630 09:04:48.376539 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:05:42.467036 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.56354
I0630 09:05:42.467134 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.801322
I0630 09:05:42.467159 29777 solver.cpp:544]     Test net output #2: loss = 1.5496 (* 1 = 1.5496 loss)
I0630 09:05:42.704638 29777 solver.cpp:290] Iteration 130000 (1.17766 iter/s, 84.9144s/100 iter), loss = 1.08333
I0630 09:05:42.704701 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 09:05:42.704720 29777 sgd_solver.cpp:106] Iteration 130000, lr = 0.0059375
I0630 09:05:42.706704 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.66
I0630 09:05:43.382153 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:05:59.733119 29777 solver.cpp:290] Iteration 130100 (5.87269 iter/s, 17.028s/100 iter), loss = 1.30952
I0630 09:05:59.733141 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 09:05:59.733148 29777 sgd_solver.cpp:106] Iteration 130100, lr = 0.00593437
I0630 09:06:15.899345 29777 solver.cpp:290] Iteration 130200 (6.18591 iter/s, 16.1658s/100 iter), loss = 1.02381
I0630 09:06:15.899443 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 09:06:15.899452 29777 sgd_solver.cpp:106] Iteration 130200, lr = 0.00593125
I0630 09:06:32.407945 29777 solver.cpp:290] Iteration 130300 (6.05765 iter/s, 16.508s/100 iter), loss = 1.25
I0630 09:06:32.407971 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:06:32.407980 29777 sgd_solver.cpp:106] Iteration 130300, lr = 0.00592813
I0630 09:06:48.678009 29777 solver.cpp:290] Iteration 130400 (6.14644 iter/s, 16.2696s/100 iter), loss = 0.833333
I0630 09:06:48.678133 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 09:06:48.678156 29777 sgd_solver.cpp:106] Iteration 130400, lr = 0.005925
I0630 09:07:04.787436 29777 solver.cpp:290] Iteration 130500 (6.20776 iter/s, 16.1089s/100 iter), loss = 1.17857
I0630 09:07:04.787461 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:07:04.787469 29777 sgd_solver.cpp:106] Iteration 130500, lr = 0.00592188
I0630 09:07:20.874743 29777 solver.cpp:290] Iteration 130600 (6.21626 iter/s, 16.0868s/100 iter), loss = 0.880952
I0630 09:07:20.874876 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 09:07:20.874897 29777 sgd_solver.cpp:106] Iteration 130600, lr = 0.00591875
I0630 09:07:37.012239 29777 solver.cpp:290] Iteration 130700 (6.19697 iter/s, 16.1369s/100 iter), loss = 1.53571
I0630 09:07:37.012265 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 09:07:37.012274 29777 sgd_solver.cpp:106] Iteration 130700, lr = 0.00591563
I0630 09:07:53.199587 29777 solver.cpp:290] Iteration 130800 (6.17784 iter/s, 16.1869s/100 iter), loss = 1.21429
I0630 09:07:53.199678 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:07:53.199689 29777 sgd_solver.cpp:106] Iteration 130800, lr = 0.0059125
I0630 09:08:09.310163 29777 solver.cpp:290] Iteration 130900 (6.20731 iter/s, 16.11s/100 iter), loss = 0.940476
I0630 09:08:09.310189 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:08:09.310195 29777 sgd_solver.cpp:106] Iteration 130900, lr = 0.00590937
I0630 09:08:25.320837 29777 solver.cpp:354] Sparsity after update:
I0630 09:08:25.341207 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:08:25.341223 29777 net.cpp:1851] conv1a_param_0(0.33) 
I0630 09:08:25.341233 29777 net.cpp:1851] conv1b_param_0(0.66) 
I0630 09:08:25.341236 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:08:25.341240 29777 net.cpp:1851] res2a_branch2a_param_0(0.66) 
I0630 09:08:25.341243 29777 net.cpp:1851] res2a_branch2b_param_0(0.66) 
I0630 09:08:25.341246 29777 net.cpp:1851] res3a_branch2a_param_0(0.66) 
I0630 09:08:25.341250 29777 net.cpp:1851] res3a_branch2b_param_0(0.66) 
I0630 09:08:25.341254 29777 net.cpp:1851] res4a_branch2a_param_0(0.66) 
I0630 09:08:25.341258 29777 net.cpp:1851] res4a_branch2b_param_0(0.66) 
I0630 09:08:25.341260 29777 net.cpp:1851] res5a_branch2a_param_0(0.66) 
I0630 09:08:25.341264 29777 net.cpp:1851] res5a_branch2b_param_0(0.66) 
I0630 09:08:25.341266 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.55336e+06/2.86678e+06) 0.542
I0630 09:08:25.497954 29777 solver.cpp:290] Iteration 131000 (6.17767 iter/s, 16.1873s/100 iter), loss = 1.0119
I0630 09:08:25.497982 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 09:08:25.497990 29777 sgd_solver.cpp:106] Iteration 131000, lr = 0.00590625
I0630 09:08:41.597138 29777 solver.cpp:290] Iteration 131100 (6.21168 iter/s, 16.0987s/100 iter), loss = 0.833333
I0630 09:08:41.597265 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 09:08:41.597303 29777 sgd_solver.cpp:106] Iteration 131100, lr = 0.00590312
I0630 09:08:57.795806 29777 solver.cpp:290] Iteration 131200 (6.17356 iter/s, 16.1981s/100 iter), loss = 1.36905
I0630 09:08:57.795891 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 09:08:57.795898 29777 sgd_solver.cpp:106] Iteration 131200, lr = 0.0059
I0630 09:09:14.127984 29777 solver.cpp:290] Iteration 131300 (6.12308 iter/s, 16.3316s/100 iter), loss = 1.22619
I0630 09:09:14.128031 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 09:09:14.128060 29777 sgd_solver.cpp:106] Iteration 131300, lr = 0.00589687
I0630 09:09:30.177973 29777 solver.cpp:290] Iteration 131400 (6.23072 iter/s, 16.0495s/100 iter), loss = 0.916667
I0630 09:09:30.178045 29777 solver.cpp:309]     Train net output #0: loss = 0.619048 (* 1 = 0.619048 loss)
I0630 09:09:30.178052 29777 sgd_solver.cpp:106] Iteration 131400, lr = 0.00589375
I0630 09:09:46.272634 29777 solver.cpp:290] Iteration 131500 (6.21344 iter/s, 16.0942s/100 iter), loss = 0.904762
I0630 09:09:46.272660 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 09:09:46.272670 29777 sgd_solver.cpp:106] Iteration 131500, lr = 0.00589063
I0630 09:10:02.421627 29777 solver.cpp:290] Iteration 131600 (6.19251 iter/s, 16.1485s/100 iter), loss = 0.988095
I0630 09:10:02.421720 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 09:10:02.421731 29777 sgd_solver.cpp:106] Iteration 131600, lr = 0.0058875
I0630 09:10:18.451019 29777 solver.cpp:290] Iteration 131700 (6.23875 iter/s, 16.0289s/100 iter), loss = 1.21429
I0630 09:10:18.451045 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 09:10:18.451055 29777 sgd_solver.cpp:106] Iteration 131700, lr = 0.00588437
I0630 09:10:34.595127 29777 solver.cpp:290] Iteration 131800 (6.19439 iter/s, 16.1436s/100 iter), loss = 1.38095
I0630 09:10:34.595232 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 09:10:34.595242 29777 sgd_solver.cpp:106] Iteration 131800, lr = 0.00588125
I0630 09:10:50.614478 29777 solver.cpp:290] Iteration 131900 (6.24266 iter/s, 16.0188s/100 iter), loss = 1.14286
I0630 09:10:50.614504 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:10:50.614512 29777 sgd_solver.cpp:106] Iteration 131900, lr = 0.00587813
I0630 09:11:06.651406 29777 solver.cpp:354] Sparsity after update:
I0630 09:11:06.652858 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:11:06.652865 29777 net.cpp:1851] conv1a_param_0(0.33) 
I0630 09:11:06.652873 29777 net.cpp:1851] conv1b_param_0(0.66) 
I0630 09:11:06.652874 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:11:06.652876 29777 net.cpp:1851] res2a_branch2a_param_0(0.66) 
I0630 09:11:06.652878 29777 net.cpp:1851] res2a_branch2b_param_0(0.66) 
I0630 09:11:06.652880 29777 net.cpp:1851] res3a_branch2a_param_0(0.66) 
I0630 09:11:06.652882 29777 net.cpp:1851] res3a_branch2b_param_0(0.66) 
I0630 09:11:06.652884 29777 net.cpp:1851] res4a_branch2a_param_0(0.66) 
I0630 09:11:06.652886 29777 net.cpp:1851] res4a_branch2b_param_0(0.66) 
I0630 09:11:06.652889 29777 net.cpp:1851] res5a_branch2a_param_0(0.66) 
I0630 09:11:06.652890 29777 net.cpp:1851] res5a_branch2b_param_0(0.66) 
I0630 09:11:06.652892 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.55336e+06/2.86678e+06) 0.542
I0630 09:11:06.652978 29777 solver.cpp:471] Iteration 132000, Testing net (#0)
I0630 09:11:19.244792 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:12:07.736179 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.565259
I0630 09:12:07.736325 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.800361
I0630 09:12:07.736344 29777 solver.cpp:544]     Test net output #2: loss = 1.54672 (* 1 = 1.54672 loss)
I0630 09:12:07.918881 29777 solver.cpp:290] Iteration 132000 (1.29362 iter/s, 77.3023s/100 iter), loss = 0.630952
I0630 09:12:07.919172 29777 solver.cpp:309]     Train net output #0: loss = 0.404762 (* 1 = 0.404762 loss)
I0630 09:12:07.919309 29777 sgd_solver.cpp:106] Iteration 132000, lr = 0.005875
I0630 09:12:07.921347 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.67
I0630 09:12:08.540423 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:12:24.768144 29777 solver.cpp:290] Iteration 132100 (5.93524 iter/s, 16.8485s/100 iter), loss = 0.797619
I0630 09:12:24.768169 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 09:12:24.768179 29777 sgd_solver.cpp:106] Iteration 132100, lr = 0.00587188
I0630 09:12:40.887068 29777 solver.cpp:290] Iteration 132200 (6.20407 iter/s, 16.1185s/100 iter), loss = 1.14286
I0630 09:12:40.887166 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:12:40.887176 29777 sgd_solver.cpp:106] Iteration 132200, lr = 0.00586875
I0630 09:12:57.493207 29777 solver.cpp:290] Iteration 132300 (6.02207 iter/s, 16.6056s/100 iter), loss = 1.39286
I0630 09:12:57.493232 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 09:12:57.493242 29777 sgd_solver.cpp:106] Iteration 132300, lr = 0.00586563
I0630 09:13:13.539386 29777 solver.cpp:290] Iteration 132400 (6.23219 iter/s, 16.0457s/100 iter), loss = 1.38095
I0630 09:13:13.539494 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 09:13:13.539504 29777 sgd_solver.cpp:106] Iteration 132400, lr = 0.0058625
I0630 09:13:29.627353 29777 solver.cpp:290] Iteration 132500 (6.21604 iter/s, 16.0874s/100 iter), loss = 1.86905
I0630 09:13:29.627379 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 09:13:29.627389 29777 sgd_solver.cpp:106] Iteration 132500, lr = 0.00585938
I0630 09:13:45.590751 29777 solver.cpp:290] Iteration 132600 (6.26451 iter/s, 15.9629s/100 iter), loss = 1.20238
I0630 09:13:45.590848 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 09:13:45.590857 29777 sgd_solver.cpp:106] Iteration 132600, lr = 0.00585625
I0630 09:14:01.533146 29777 solver.cpp:290] Iteration 132700 (6.27279 iter/s, 15.9419s/100 iter), loss = 1.32143
I0630 09:14:01.533171 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:14:01.533180 29777 sgd_solver.cpp:106] Iteration 132700, lr = 0.00585312
I0630 09:14:17.513208 29777 solver.cpp:290] Iteration 132800 (6.25798 iter/s, 15.9796s/100 iter), loss = 1.36905
I0630 09:14:17.513288 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:14:17.513296 29777 sgd_solver.cpp:106] Iteration 132800, lr = 0.00585
I0630 09:14:33.800808 29777 solver.cpp:290] Iteration 132900 (6.13984 iter/s, 16.2871s/100 iter), loss = 1.27381
I0630 09:14:33.800830 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 09:14:33.800837 29777 sgd_solver.cpp:106] Iteration 132900, lr = 0.00584687
I0630 09:14:49.814072 29777 solver.cpp:354] Sparsity after update:
I0630 09:14:49.834440 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:14:49.834455 29777 net.cpp:1851] conv1a_param_0(0.335) 
I0630 09:14:49.834465 29777 net.cpp:1851] conv1b_param_0(0.67) 
I0630 09:14:49.834470 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:14:49.834473 29777 net.cpp:1851] res2a_branch2a_param_0(0.67) 
I0630 09:14:49.834483 29777 net.cpp:1851] res2a_branch2b_param_0(0.67) 
I0630 09:14:49.834488 29777 net.cpp:1851] res3a_branch2a_param_0(0.67) 
I0630 09:14:49.834493 29777 net.cpp:1851] res3a_branch2b_param_0(0.67) 
I0630 09:14:49.834498 29777 net.cpp:1851] res4a_branch2a_param_0(0.67) 
I0630 09:14:49.834502 29777 net.cpp:1851] res4a_branch2b_param_0(0.67) 
I0630 09:14:49.834507 29777 net.cpp:1851] res5a_branch2a_param_0(0.67) 
I0630 09:14:49.834511 29777 net.cpp:1851] res5a_branch2b_param_0(0.67) 
I0630 09:14:49.834516 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.57689e+06/2.86678e+06) 0.55
I0630 09:14:49.991252 29777 solver.cpp:290] Iteration 133000 (6.17666 iter/s, 16.19s/100 iter), loss = 1.15476
I0630 09:14:49.991281 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:14:49.991289 29777 sgd_solver.cpp:106] Iteration 133000, lr = 0.00584375
I0630 09:15:06.073607 29777 solver.cpp:290] Iteration 133100 (6.21817 iter/s, 16.0819s/100 iter), loss = 1.25
I0630 09:15:06.073632 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:15:06.073640 29777 sgd_solver.cpp:106] Iteration 133100, lr = 0.00584062
I0630 09:15:22.213333 29777 solver.cpp:290] Iteration 133200 (6.19607 iter/s, 16.1393s/100 iter), loss = 1.46429
I0630 09:15:22.213460 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 09:15:22.213469 29777 sgd_solver.cpp:106] Iteration 133200, lr = 0.0058375
I0630 09:15:38.215041 29777 solver.cpp:290] Iteration 133300 (6.24955 iter/s, 16.0011s/100 iter), loss = 1.39286
I0630 09:15:38.215068 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 09:15:38.215085 29777 sgd_solver.cpp:106] Iteration 133300, lr = 0.00583438
I0630 09:15:54.198822 29777 solver.cpp:290] Iteration 133400 (6.25652 iter/s, 15.9833s/100 iter), loss = 1.38095
I0630 09:15:54.198896 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 09:15:54.198904 29777 sgd_solver.cpp:106] Iteration 133400, lr = 0.00583125
I0630 09:16:10.434185 29777 solver.cpp:290] Iteration 133500 (6.15959 iter/s, 16.2348s/100 iter), loss = 1.19048
I0630 09:16:10.434208 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:16:10.434216 29777 sgd_solver.cpp:106] Iteration 133500, lr = 0.00582812
I0630 09:16:26.653506 29777 solver.cpp:290] Iteration 133600 (6.16566 iter/s, 16.2189s/100 iter), loss = 1.19048
I0630 09:16:26.653615 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 09:16:26.653630 29777 sgd_solver.cpp:106] Iteration 133600, lr = 0.005825
I0630 09:16:42.779341 29777 solver.cpp:290] Iteration 133700 (6.20144 iter/s, 16.1253s/100 iter), loss = 1.15476
I0630 09:16:42.779369 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:16:42.779378 29777 sgd_solver.cpp:106] Iteration 133700, lr = 0.00582188
I0630 09:16:59.048053 29777 solver.cpp:290] Iteration 133800 (6.14695 iter/s, 16.2682s/100 iter), loss = 0.773809
I0630 09:16:59.048158 29777 solver.cpp:309]     Train net output #0: loss = 0.571429 (* 1 = 0.571429 loss)
I0630 09:16:59.048168 29777 sgd_solver.cpp:106] Iteration 133800, lr = 0.00581875
I0630 09:17:15.349735 29777 solver.cpp:290] Iteration 133900 (6.13454 iter/s, 16.3011s/100 iter), loss = 1.22619
I0630 09:17:15.349769 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:17:15.349781 29777 sgd_solver.cpp:106] Iteration 133900, lr = 0.00581563
I0630 09:17:31.370638 29777 solver.cpp:354] Sparsity after update:
I0630 09:17:31.372298 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:17:31.372306 29777 net.cpp:1851] conv1a_param_0(0.335) 
I0630 09:17:31.372314 29777 net.cpp:1851] conv1b_param_0(0.67) 
I0630 09:17:31.372318 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:17:31.372319 29777 net.cpp:1851] res2a_branch2a_param_0(0.67) 
I0630 09:17:31.372321 29777 net.cpp:1851] res2a_branch2b_param_0(0.67) 
I0630 09:17:31.372323 29777 net.cpp:1851] res3a_branch2a_param_0(0.67) 
I0630 09:17:31.372325 29777 net.cpp:1851] res3a_branch2b_param_0(0.67) 
I0630 09:17:31.372328 29777 net.cpp:1851] res4a_branch2a_param_0(0.67) 
I0630 09:17:31.372328 29777 net.cpp:1851] res4a_branch2b_param_0(0.67) 
I0630 09:17:31.372330 29777 net.cpp:1851] res5a_branch2a_param_0(0.67) 
I0630 09:17:31.372333 29777 net.cpp:1851] res5a_branch2b_param_0(0.67) 
I0630 09:17:31.372334 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.57689e+06/2.86678e+06) 0.55
I0630 09:17:31.372433 29777 solver.cpp:471] Iteration 134000, Testing net (#0)
I0630 09:17:44.840793 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:18:40.456619 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.561479
I0630 09:18:40.456677 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.797582
I0630 09:18:40.456684 29777 solver.cpp:544]     Test net output #2: loss = 1.55842 (* 1 = 1.55842 loss)
I0630 09:18:40.637398 29777 solver.cpp:290] Iteration 134000 (1.17253 iter/s, 85.2853s/100 iter), loss = 1.15476
I0630 09:18:40.637425 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:18:40.637435 29777 sgd_solver.cpp:106] Iteration 134000, lr = 0.0058125
I0630 09:18:40.638427 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.68
I0630 09:18:41.138677 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:18:57.310595 29777 solver.cpp:290] Iteration 134100 (5.99782 iter/s, 16.6727s/100 iter), loss = 1.45238
I0630 09:18:57.310618 29777 solver.cpp:309]     Train net output #0: loss = 1.85714 (* 1 = 1.85714 loss)
I0630 09:18:57.310626 29777 sgd_solver.cpp:106] Iteration 134100, lr = 0.00580938
I0630 09:19:13.505194 29777 solver.cpp:290] Iteration 134200 (6.17508 iter/s, 16.1941s/100 iter), loss = 1.29762
I0630 09:19:13.505287 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 09:19:13.505298 29777 sgd_solver.cpp:106] Iteration 134200, lr = 0.00580625
I0630 09:19:30.162317 29777 solver.cpp:290] Iteration 134300 (6.00364 iter/s, 16.6566s/100 iter), loss = 1.09524
I0630 09:19:30.162339 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 09:19:30.162346 29777 sgd_solver.cpp:106] Iteration 134300, lr = 0.00580312
I0630 09:19:46.745518 29777 solver.cpp:290] Iteration 134400 (6.03037 iter/s, 16.5827s/100 iter), loss = 1.60714
I0630 09:19:46.745602 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 09:19:46.745613 29777 sgd_solver.cpp:106] Iteration 134400, lr = 0.0058
I0630 09:20:02.877579 29777 solver.cpp:290] Iteration 134500 (6.19904 iter/s, 16.1315s/100 iter), loss = 1.2619
I0630 09:20:02.877604 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:20:02.877612 29777 sgd_solver.cpp:106] Iteration 134500, lr = 0.00579687
I0630 09:20:18.965355 29777 solver.cpp:290] Iteration 134600 (6.21608 iter/s, 16.0873s/100 iter), loss = 1.0119
I0630 09:20:18.965461 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:20:18.965471 29777 sgd_solver.cpp:106] Iteration 134600, lr = 0.00579375
I0630 09:20:35.127043 29777 solver.cpp:290] Iteration 134700 (6.18768 iter/s, 16.1611s/100 iter), loss = 1.07143
I0630 09:20:35.127066 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:20:35.127074 29777 sgd_solver.cpp:106] Iteration 134700, lr = 0.00579062
I0630 09:20:51.430505 29777 solver.cpp:290] Iteration 134800 (6.13384 iter/s, 16.303s/100 iter), loss = 1.27381
I0630 09:20:51.430572 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 09:20:51.430580 29777 sgd_solver.cpp:106] Iteration 134800, lr = 0.0057875
I0630 09:21:07.692463 29777 solver.cpp:290] Iteration 134900 (6.14951 iter/s, 16.2615s/100 iter), loss = 1.13095
I0630 09:21:07.692492 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:21:07.692499 29777 sgd_solver.cpp:106] Iteration 134900, lr = 0.00578438
I0630 09:21:23.641304 29777 solver.cpp:354] Sparsity after update:
I0630 09:21:23.660159 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:21:23.660185 29777 net.cpp:1851] conv1a_param_0(0.34) 
I0630 09:21:23.660207 29777 net.cpp:1851] conv1b_param_0(0.68) 
I0630 09:21:23.660213 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:21:23.660219 29777 net.cpp:1851] res2a_branch2a_param_0(0.68) 
I0630 09:21:23.660226 29777 net.cpp:1851] res2a_branch2b_param_0(0.68) 
I0630 09:21:23.660233 29777 net.cpp:1851] res3a_branch2a_param_0(0.68) 
I0630 09:21:23.660238 29777 net.cpp:1851] res3a_branch2b_param_0(0.68) 
I0630 09:21:23.660243 29777 net.cpp:1851] res4a_branch2a_param_0(0.68) 
I0630 09:21:23.660248 29777 net.cpp:1851] res4a_branch2b_param_0(0.68) 
I0630 09:21:23.660254 29777 net.cpp:1851] res5a_branch2a_param_0(0.68) 
I0630 09:21:23.660260 29777 net.cpp:1851] res5a_branch2b_param_0(0.68) 
I0630 09:21:23.660266 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.60043e+06/2.86678e+06) 0.558
I0630 09:21:23.823943 29777 solver.cpp:290] Iteration 135000 (6.19924 iter/s, 16.131s/100 iter), loss = 1.2381
I0630 09:21:23.823987 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:21:23.824004 29777 sgd_solver.cpp:106] Iteration 135000, lr = 0.00578125
I0630 09:21:39.999841 29777 solver.cpp:290] Iteration 135100 (6.18222 iter/s, 16.1754s/100 iter), loss = 1.30952
I0630 09:21:39.999866 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:21:39.999873 29777 sgd_solver.cpp:106] Iteration 135100, lr = 0.00577813
I0630 09:21:56.203161 29777 solver.cpp:290] Iteration 135200 (6.17175 iter/s, 16.2029s/100 iter), loss = 1.10714
I0630 09:21:56.203279 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:21:56.203289 29777 sgd_solver.cpp:106] Iteration 135200, lr = 0.005775
I0630 09:22:12.359628 29777 solver.cpp:290] Iteration 135300 (6.18968 iter/s, 16.1559s/100 iter), loss = 1.38095
I0630 09:22:12.359653 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 09:22:12.359663 29777 sgd_solver.cpp:106] Iteration 135300, lr = 0.00577188
I0630 09:22:28.533769 29777 solver.cpp:290] Iteration 135400 (6.18289 iter/s, 16.1737s/100 iter), loss = 1.19048
I0630 09:22:28.534308 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:22:28.534318 29777 sgd_solver.cpp:106] Iteration 135400, lr = 0.00576875
I0630 09:22:44.689162 29777 solver.cpp:290] Iteration 135500 (6.19026 iter/s, 16.1544s/100 iter), loss = 1.10714
I0630 09:22:44.689185 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:22:44.689194 29777 sgd_solver.cpp:106] Iteration 135500, lr = 0.00576563
I0630 09:23:00.894497 29777 solver.cpp:290] Iteration 135600 (6.17099 iter/s, 16.2049s/100 iter), loss = 1.11905
I0630 09:23:00.894548 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:23:00.894558 29777 sgd_solver.cpp:106] Iteration 135600, lr = 0.0057625
I0630 09:23:17.195624 29777 solver.cpp:290] Iteration 135700 (6.13473 iter/s, 16.3006s/100 iter), loss = 1.15476
I0630 09:23:17.195647 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 09:23:17.195654 29777 sgd_solver.cpp:106] Iteration 135700, lr = 0.00575938
I0630 09:23:33.328140 29777 solver.cpp:290] Iteration 135800 (6.19884 iter/s, 16.1321s/100 iter), loss = 1.02381
I0630 09:23:33.328240 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 09:23:33.328250 29777 sgd_solver.cpp:106] Iteration 135800, lr = 0.00575625
I0630 09:23:49.456189 29777 solver.cpp:290] Iteration 135900 (6.20058 iter/s, 16.1275s/100 iter), loss = 1.67857
I0630 09:23:49.456213 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:23:49.456223 29777 sgd_solver.cpp:106] Iteration 135900, lr = 0.00575312
I0630 09:24:05.446089 29777 solver.cpp:354] Sparsity after update:
I0630 09:24:05.447788 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:24:05.447799 29777 net.cpp:1851] conv1a_param_0(0.34) 
I0630 09:24:05.447808 29777 net.cpp:1851] conv1b_param_0(0.68) 
I0630 09:24:05.447809 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:24:05.447811 29777 net.cpp:1851] res2a_branch2a_param_0(0.68) 
I0630 09:24:05.447813 29777 net.cpp:1851] res2a_branch2b_param_0(0.68) 
I0630 09:24:05.447815 29777 net.cpp:1851] res3a_branch2a_param_0(0.68) 
I0630 09:24:05.447818 29777 net.cpp:1851] res3a_branch2b_param_0(0.68) 
I0630 09:24:05.447819 29777 net.cpp:1851] res4a_branch2a_param_0(0.68) 
I0630 09:24:05.447821 29777 net.cpp:1851] res4a_branch2b_param_0(0.68) 
I0630 09:24:05.447824 29777 net.cpp:1851] res5a_branch2a_param_0(0.68) 
I0630 09:24:05.447826 29777 net.cpp:1851] res5a_branch2b_param_0(0.68) 
I0630 09:24:05.447829 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.60043e+06/2.86678e+06) 0.558
I0630 09:24:05.447966 29777 solver.cpp:471] Iteration 136000, Testing net (#0)
I0630 09:24:19.663147 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:25:08.257068 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.563079
I0630 09:25:08.257241 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.798141
I0630 09:25:08.257261 29777 solver.cpp:544]     Test net output #2: loss = 1.5569 (* 1 = 1.5569 loss)
I0630 09:25:08.469457 29777 solver.cpp:290] Iteration 136000 (1.26564 iter/s, 79.0111s/100 iter), loss = 1.09524
I0630 09:25:08.469480 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:25:08.469487 29777 sgd_solver.cpp:106] Iteration 136000, lr = 0.00575
I0630 09:25:08.470211 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.69
I0630 09:25:09.314415 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:25:25.513217 29777 solver.cpp:290] Iteration 136100 (5.86742 iter/s, 17.0433s/100 iter), loss = 1.32143
I0630 09:25:25.513273 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:25:25.513294 29777 sgd_solver.cpp:106] Iteration 136100, lr = 0.00574687
I0630 09:25:41.740330 29777 solver.cpp:290] Iteration 136200 (6.16271 iter/s, 16.2266s/100 iter), loss = 0.642857
I0630 09:25:41.740382 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 09:25:41.740391 29777 sgd_solver.cpp:106] Iteration 136200, lr = 0.00574375
I0630 09:25:57.878613 29777 solver.cpp:290] Iteration 136300 (6.19664 iter/s, 16.1378s/100 iter), loss = 1.2619
I0630 09:25:57.878639 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:25:57.878648 29777 sgd_solver.cpp:106] Iteration 136300, lr = 0.00574062
I0630 09:26:13.928861 29777 solver.cpp:290] Iteration 136400 (6.23063 iter/s, 16.0497s/100 iter), loss = 1.58333
I0630 09:26:13.929002 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 09:26:13.929039 29777 sgd_solver.cpp:106] Iteration 136400, lr = 0.0057375
I0630 09:26:30.137477 29777 solver.cpp:290] Iteration 136500 (6.16978 iter/s, 16.208s/100 iter), loss = 1.35714
I0630 09:26:30.137508 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:26:30.137518 29777 sgd_solver.cpp:106] Iteration 136500, lr = 0.00573438
I0630 09:26:46.160846 29777 solver.cpp:290] Iteration 136600 (6.24107 iter/s, 16.0229s/100 iter), loss = 1.58333
I0630 09:26:46.160918 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 09:26:46.160926 29777 sgd_solver.cpp:106] Iteration 136600, lr = 0.00573125
I0630 09:27:02.212064 29777 solver.cpp:290] Iteration 136700 (6.23026 iter/s, 16.0507s/100 iter), loss = 1.02381
I0630 09:27:02.212090 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:27:02.212100 29777 sgd_solver.cpp:106] Iteration 136700, lr = 0.00572812
I0630 09:27:18.185240 29777 solver.cpp:290] Iteration 136800 (6.26068 iter/s, 15.9727s/100 iter), loss = 1.27381
I0630 09:27:18.185318 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 09:27:18.185329 29777 sgd_solver.cpp:106] Iteration 136800, lr = 0.005725
I0630 09:27:34.343789 29777 solver.cpp:290] Iteration 136900 (6.18887 iter/s, 16.158s/100 iter), loss = 1.29762
I0630 09:27:34.343816 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:27:34.343832 29777 sgd_solver.cpp:106] Iteration 136900, lr = 0.00572188
I0630 09:27:50.289688 29777 solver.cpp:354] Sparsity after update:
I0630 09:27:50.309926 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:27:50.309942 29777 net.cpp:1851] conv1a_param_0(0.345) 
I0630 09:27:50.309955 29777 net.cpp:1851] conv1b_param_0(0.69) 
I0630 09:27:50.309959 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:27:50.309963 29777 net.cpp:1851] res2a_branch2a_param_0(0.69) 
I0630 09:27:50.309967 29777 net.cpp:1851] res2a_branch2b_param_0(0.69) 
I0630 09:27:50.309972 29777 net.cpp:1851] res3a_branch2a_param_0(0.69) 
I0630 09:27:50.309975 29777 net.cpp:1851] res3a_branch2b_param_0(0.69) 
I0630 09:27:50.309979 29777 net.cpp:1851] res4a_branch2a_param_0(0.69) 
I0630 09:27:50.309983 29777 net.cpp:1851] res4a_branch2b_param_0(0.69) 
I0630 09:27:50.309988 29777 net.cpp:1851] res5a_branch2a_param_0(0.69) 
I0630 09:27:50.309990 29777 net.cpp:1851] res5a_branch2b_param_0(0.69) 
I0630 09:27:50.309994 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.62397e+06/2.86678e+06) 0.566
I0630 09:27:50.478109 29777 solver.cpp:290] Iteration 137000 (6.19815 iter/s, 16.1339s/100 iter), loss = 1.35714
I0630 09:27:50.478132 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 09:27:50.478139 29777 sgd_solver.cpp:106] Iteration 137000, lr = 0.00571875
I0630 09:28:06.544859 29777 solver.cpp:290] Iteration 137100 (6.22421 iter/s, 16.0663s/100 iter), loss = 1.08333
I0630 09:28:06.544881 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:28:06.544888 29777 sgd_solver.cpp:106] Iteration 137100, lr = 0.00571563
I0630 09:28:22.558109 29777 solver.cpp:290] Iteration 137200 (6.24501 iter/s, 16.0128s/100 iter), loss = 1.14286
I0630 09:28:22.558223 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:28:22.558238 29777 sgd_solver.cpp:106] Iteration 137200, lr = 0.0057125
I0630 09:28:38.703881 29777 solver.cpp:290] Iteration 137300 (6.19378 iter/s, 16.1452s/100 iter), loss = 0.964286
I0630 09:28:38.703907 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 09:28:38.703912 29777 sgd_solver.cpp:106] Iteration 137300, lr = 0.00570937
I0630 09:28:55.361989 29777 solver.cpp:290] Iteration 137400 (6.00326 iter/s, 16.6576s/100 iter), loss = 1.14286
I0630 09:28:55.362084 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:28:55.362095 29777 sgd_solver.cpp:106] Iteration 137400, lr = 0.00570625
I0630 09:29:11.403564 29777 solver.cpp:290] Iteration 137500 (6.23401 iter/s, 16.041s/100 iter), loss = 1
I0630 09:29:11.403590 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:29:11.403599 29777 sgd_solver.cpp:106] Iteration 137500, lr = 0.00570312
I0630 09:29:27.578222 29777 solver.cpp:290] Iteration 137600 (6.18269 iter/s, 16.1742s/100 iter), loss = 1.44048
I0630 09:29:27.578327 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 09:29:27.578337 29777 sgd_solver.cpp:106] Iteration 137600, lr = 0.0057
I0630 09:29:43.601927 29777 solver.cpp:290] Iteration 137700 (6.24097 iter/s, 16.0232s/100 iter), loss = 1.15476
I0630 09:29:43.601956 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 09:29:43.601965 29777 sgd_solver.cpp:106] Iteration 137700, lr = 0.00569687
I0630 09:29:59.602347 29777 solver.cpp:290] Iteration 137800 (6.25002 iter/s, 16s/100 iter), loss = 1.05952
I0630 09:29:59.602424 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 09:29:59.602432 29777 sgd_solver.cpp:106] Iteration 137800, lr = 0.00569375
I0630 09:30:15.692628 29777 solver.cpp:290] Iteration 137900 (6.21513 iter/s, 16.0898s/100 iter), loss = 1.36905
I0630 09:30:15.692659 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 09:30:15.692669 29777 sgd_solver.cpp:106] Iteration 137900, lr = 0.00569062
I0630 09:30:31.556931 29777 solver.cpp:354] Sparsity after update:
I0630 09:30:31.558547 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:30:31.558554 29777 net.cpp:1851] conv1a_param_0(0.345) 
I0630 09:30:31.558562 29777 net.cpp:1851] conv1b_param_0(0.69) 
I0630 09:30:31.558564 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:30:31.558567 29777 net.cpp:1851] res2a_branch2a_param_0(0.69) 
I0630 09:30:31.558568 29777 net.cpp:1851] res2a_branch2b_param_0(0.69) 
I0630 09:30:31.558570 29777 net.cpp:1851] res3a_branch2a_param_0(0.69) 
I0630 09:30:31.558573 29777 net.cpp:1851] res3a_branch2b_param_0(0.69) 
I0630 09:30:31.558574 29777 net.cpp:1851] res4a_branch2a_param_0(0.69) 
I0630 09:30:31.558576 29777 net.cpp:1851] res4a_branch2b_param_0(0.69) 
I0630 09:30:31.558578 29777 net.cpp:1851] res5a_branch2a_param_0(0.69) 
I0630 09:30:31.558580 29777 net.cpp:1851] res5a_branch2b_param_0(0.69) 
I0630 09:30:31.558583 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.62397e+06/2.86678e+06) 0.566
I0630 09:30:31.558670 29777 solver.cpp:471] Iteration 138000, Testing net (#0)
I0630 09:30:44.488788 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:31:33.372510 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.561619
I0630 09:31:33.372568 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.796681
I0630 09:31:33.372575 29777 solver.cpp:544]     Test net output #2: loss = 1.5555 (* 1 = 1.5555 loss)
I0630 09:31:33.547799 29777 solver.cpp:290] Iteration 138000 (1.28447 iter/s, 77.853s/100 iter), loss = 1.2619
I0630 09:31:33.547825 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:31:33.547833 29777 sgd_solver.cpp:106] Iteration 138000, lr = 0.0056875
I0630 09:31:33.548812 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.7
I0630 09:31:34.132237 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:31:50.137717 29777 solver.cpp:290] Iteration 138100 (6.02793 iter/s, 16.5894s/100 iter), loss = 1.4881
I0630 09:31:50.137744 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 09:31:50.137753 29777 sgd_solver.cpp:106] Iteration 138100, lr = 0.00568437
I0630 09:32:06.116412 29777 solver.cpp:290] Iteration 138200 (6.25852 iter/s, 15.9782s/100 iter), loss = 1.04762
I0630 09:32:06.116554 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:32:06.116583 29777 sgd_solver.cpp:106] Iteration 138200, lr = 0.00568125
I0630 09:32:22.307919 29777 solver.cpp:290] Iteration 138300 (6.1763 iter/s, 16.1909s/100 iter), loss = 1.08333
I0630 09:32:22.307945 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 09:32:22.307951 29777 sgd_solver.cpp:106] Iteration 138300, lr = 0.00567812
I0630 09:32:38.623220 29777 solver.cpp:290] Iteration 138400 (6.12939 iter/s, 16.3148s/100 iter), loss = 0.77381
I0630 09:32:38.623325 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 09:32:38.623335 29777 sgd_solver.cpp:106] Iteration 138400, lr = 0.005675
I0630 09:32:54.680619 29777 solver.cpp:290] Iteration 138500 (6.22787 iter/s, 16.0569s/100 iter), loss = 0.916667
I0630 09:32:54.680644 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:32:54.680652 29777 sgd_solver.cpp:106] Iteration 138500, lr = 0.00567187
I0630 09:33:10.938160 29777 solver.cpp:290] Iteration 138600 (6.15117 iter/s, 16.2571s/100 iter), loss = 1.27381
I0630 09:33:10.938269 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 09:33:10.938279 29777 sgd_solver.cpp:106] Iteration 138600, lr = 0.00566875
I0630 09:33:27.239873 29777 solver.cpp:290] Iteration 138700 (6.13453 iter/s, 16.3012s/100 iter), loss = 1.41667
I0630 09:33:27.239897 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 09:33:27.239905 29777 sgd_solver.cpp:106] Iteration 138700, lr = 0.00566562
I0630 09:33:43.583907 29777 solver.cpp:290] Iteration 138800 (6.11862 iter/s, 16.3436s/100 iter), loss = 1.25
I0630 09:33:43.584055 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 09:33:43.584075 29777 sgd_solver.cpp:106] Iteration 138800, lr = 0.0056625
I0630 09:33:59.751896 29777 solver.cpp:290] Iteration 138900 (6.18528 iter/s, 16.1674s/100 iter), loss = 1.21429
I0630 09:33:59.751929 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:33:59.751941 29777 sgd_solver.cpp:106] Iteration 138900, lr = 0.00565937
I0630 09:34:15.934825 29777 solver.cpp:354] Sparsity after update:
I0630 09:34:15.955112 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:34:15.955129 29777 net.cpp:1851] conv1a_param_0(0.35) 
I0630 09:34:15.955142 29777 net.cpp:1851] conv1b_param_0(0.7) 
I0630 09:34:15.955147 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:34:15.955149 29777 net.cpp:1851] res2a_branch2a_param_0(0.7) 
I0630 09:34:15.955153 29777 net.cpp:1851] res2a_branch2b_param_0(0.7) 
I0630 09:34:15.955157 29777 net.cpp:1851] res3a_branch2a_param_0(0.7) 
I0630 09:34:15.955159 29777 net.cpp:1851] res3a_branch2b_param_0(0.7) 
I0630 09:34:15.955163 29777 net.cpp:1851] res4a_branch2a_param_0(0.7) 
I0630 09:34:15.955165 29777 net.cpp:1851] res4a_branch2b_param_0(0.7) 
I0630 09:34:15.955169 29777 net.cpp:1851] res5a_branch2a_param_0(0.7) 
I0630 09:34:15.955173 29777 net.cpp:1851] res5a_branch2b_param_0(0.7) 
I0630 09:34:15.955175 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.6475e+06/2.86678e+06) 0.575
I0630 09:34:16.113108 29777 solver.cpp:290] Iteration 139000 (6.11219 iter/s, 16.3607s/100 iter), loss = 1.13095
I0630 09:34:16.113131 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 09:34:16.113138 29777 sgd_solver.cpp:106] Iteration 139000, lr = 0.00565625
I0630 09:34:32.188415 29777 solver.cpp:290] Iteration 139100 (6.22091 iter/s, 16.0748s/100 iter), loss = 1.03571
I0630 09:34:32.188525 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:34:32.188575 29777 sgd_solver.cpp:106] Iteration 139100, lr = 0.00565312
I0630 09:34:48.473958 29777 solver.cpp:290] Iteration 139200 (6.14062 iter/s, 16.285s/100 iter), loss = 0.964286
I0630 09:34:48.474040 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 09:34:48.474054 29777 sgd_solver.cpp:106] Iteration 139200, lr = 0.00565
I0630 09:35:04.602993 29777 solver.cpp:290] Iteration 139300 (6.2002 iter/s, 16.1285s/100 iter), loss = 1.38095
I0630 09:35:04.603044 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:35:04.603068 29777 sgd_solver.cpp:106] Iteration 139300, lr = 0.00564687
I0630 09:35:20.780688 29777 solver.cpp:290] Iteration 139400 (6.18154 iter/s, 16.1772s/100 iter), loss = 1.05952
I0630 09:35:20.780760 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 09:35:20.780766 29777 sgd_solver.cpp:106] Iteration 139400, lr = 0.00564375
I0630 09:35:36.918231 29777 solver.cpp:290] Iteration 139500 (6.19693 iter/s, 16.137s/100 iter), loss = 1.19048
I0630 09:35:36.918253 29777 solver.cpp:309]     Train net output #0: loss = 0.690476 (* 1 = 0.690476 loss)
I0630 09:35:36.918262 29777 sgd_solver.cpp:106] Iteration 139500, lr = 0.00564062
I0630 09:35:53.036064 29777 solver.cpp:290] Iteration 139600 (6.20449 iter/s, 16.1174s/100 iter), loss = 1
I0630 09:35:53.036115 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 09:35:53.036126 29777 sgd_solver.cpp:106] Iteration 139600, lr = 0.0056375
I0630 09:36:09.435600 29777 solver.cpp:290] Iteration 139700 (6.09792 iter/s, 16.399s/100 iter), loss = 1.04762
I0630 09:36:09.435654 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:36:09.435676 29777 sgd_solver.cpp:106] Iteration 139700, lr = 0.00563437
I0630 09:36:25.791177 29777 solver.cpp:290] Iteration 139800 (6.11431 iter/s, 16.3551s/100 iter), loss = 1.39286
I0630 09:36:25.791291 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 09:36:25.791299 29777 sgd_solver.cpp:106] Iteration 139800, lr = 0.00563125
I0630 09:36:41.901000 29777 solver.cpp:290] Iteration 139900 (6.20761 iter/s, 16.1093s/100 iter), loss = 1
I0630 09:36:41.901027 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:36:41.901056 29777 sgd_solver.cpp:106] Iteration 139900, lr = 0.00562812
I0630 09:36:57.872534 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_140000.caffemodel
I0630 09:36:57.892005 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_140000.solverstate
I0630 09:36:57.900665 29777 solver.cpp:354] Sparsity after update:
I0630 09:36:57.901618 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:36:57.901625 29777 net.cpp:1851] conv1a_param_0(0.35) 
I0630 09:36:57.901633 29777 net.cpp:1851] conv1b_param_0(0.7) 
I0630 09:36:57.901635 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:36:57.901638 29777 net.cpp:1851] res2a_branch2a_param_0(0.7) 
I0630 09:36:57.901640 29777 net.cpp:1851] res2a_branch2b_param_0(0.7) 
I0630 09:36:57.901641 29777 net.cpp:1851] res3a_branch2a_param_0(0.7) 
I0630 09:36:57.901643 29777 net.cpp:1851] res3a_branch2b_param_0(0.7) 
I0630 09:36:57.901645 29777 net.cpp:1851] res4a_branch2a_param_0(0.7) 
I0630 09:36:57.901648 29777 net.cpp:1851] res4a_branch2b_param_0(0.7) 
I0630 09:36:57.901649 29777 net.cpp:1851] res5a_branch2a_param_0(0.7) 
I0630 09:36:57.901651 29777 net.cpp:1851] res5a_branch2b_param_0(0.7) 
I0630 09:36:57.901654 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.6475e+06/2.86678e+06) 0.575
I0630 09:36:57.901749 29777 solver.cpp:471] Iteration 140000, Testing net (#0)
I0630 09:37:14.295258 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:38:04.797722 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5604
I0630 09:38:04.797842 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.796201
I0630 09:38:04.797868 29777 solver.cpp:544]     Test net output #2: loss = 1.56316 (* 1 = 1.56316 loss)
I0630 09:38:05.016595 29777 solver.cpp:290] Iteration 140000 (1.20318 iter/s, 83.1133s/100 iter), loss = 1.2619
I0630 09:38:05.016618 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 09:38:05.016625 29777 sgd_solver.cpp:106] Iteration 140000, lr = 0.005625
I0630 09:38:05.017287 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.71
I0630 09:38:05.674437 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:38:21.983137 29777 solver.cpp:290] Iteration 140100 (5.89412 iter/s, 16.9661s/100 iter), loss = 0.988095
I0630 09:38:21.983162 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 09:38:21.983186 29777 sgd_solver.cpp:106] Iteration 140100, lr = 0.00562187
I0630 09:38:38.190757 29777 solver.cpp:290] Iteration 140200 (6.17012 iter/s, 16.2072s/100 iter), loss = 1.35714
I0630 09:38:38.190826 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 09:38:38.190840 29777 sgd_solver.cpp:106] Iteration 140200, lr = 0.00561875
I0630 09:38:54.334029 29777 solver.cpp:290] Iteration 140300 (6.19473 iter/s, 16.1428s/100 iter), loss = 1.27381
I0630 09:38:54.334053 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 09:38:54.334059 29777 sgd_solver.cpp:106] Iteration 140300, lr = 0.00561563
I0630 09:39:10.400801 29777 solver.cpp:290] Iteration 140400 (6.22421 iter/s, 16.0663s/100 iter), loss = 1.0119
I0630 09:39:10.400910 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 09:39:10.400941 29777 sgd_solver.cpp:106] Iteration 140400, lr = 0.0056125
I0630 09:39:26.627302 29777 solver.cpp:290] Iteration 140500 (6.16297 iter/s, 16.2259s/100 iter), loss = 0.916667
I0630 09:39:26.627331 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 09:39:26.627341 29777 sgd_solver.cpp:106] Iteration 140500, lr = 0.00560937
I0630 09:39:42.932924 29777 solver.cpp:290] Iteration 140600 (6.13303 iter/s, 16.3051s/100 iter), loss = 1.28571
I0630 09:39:42.933035 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 09:39:42.933046 29777 sgd_solver.cpp:106] Iteration 140600, lr = 0.00560625
I0630 09:39:58.944522 29777 solver.cpp:290] Iteration 140700 (6.24569 iter/s, 16.0111s/100 iter), loss = 1.09524
I0630 09:39:58.944547 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:39:58.944556 29777 sgd_solver.cpp:106] Iteration 140700, lr = 0.00560312
I0630 09:40:15.015307 29777 solver.cpp:290] Iteration 140800 (6.22265 iter/s, 16.0703s/100 iter), loss = 1.13095
I0630 09:40:15.015529 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 09:40:15.015557 29777 sgd_solver.cpp:106] Iteration 140800, lr = 0.0056
I0630 09:40:31.121309 29777 solver.cpp:290] Iteration 140900 (6.20912 iter/s, 16.1053s/100 iter), loss = 1.14286
I0630 09:40:31.121332 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 09:40:31.121338 29777 sgd_solver.cpp:106] Iteration 140900, lr = 0.00559687
I0630 09:40:46.882495 29777 solver.cpp:354] Sparsity after update:
I0630 09:40:46.903064 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:40:46.903077 29777 net.cpp:1851] conv1a_param_0(0.355) 
I0630 09:40:46.903085 29777 net.cpp:1851] conv1b_param_0(0.71) 
I0630 09:40:46.903089 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:40:46.903090 29777 net.cpp:1851] res2a_branch2a_param_0(0.71) 
I0630 09:40:46.903092 29777 net.cpp:1851] res2a_branch2b_param_0(0.71) 
I0630 09:40:46.903095 29777 net.cpp:1851] res3a_branch2a_param_0(0.71) 
I0630 09:40:46.903096 29777 net.cpp:1851] res3a_branch2b_param_0(0.71) 
I0630 09:40:46.903098 29777 net.cpp:1851] res4a_branch2a_param_0(0.71) 
I0630 09:40:46.903100 29777 net.cpp:1851] res4a_branch2b_param_0(0.71) 
I0630 09:40:46.903102 29777 net.cpp:1851] res5a_branch2a_param_0(0.71) 
I0630 09:40:46.903105 29777 net.cpp:1851] res5a_branch2b_param_0(0.71) 
I0630 09:40:46.903106 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.67104e+06/2.86678e+06) 0.583
I0630 09:40:47.060039 29777 solver.cpp:290] Iteration 141000 (6.27421 iter/s, 15.9383s/100 iter), loss = 1.32143
I0630 09:40:47.060062 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 09:40:47.060068 29777 sgd_solver.cpp:106] Iteration 141000, lr = 0.00559375
I0630 09:41:03.104647 29777 solver.cpp:290] Iteration 141100 (6.2328 iter/s, 16.0441s/100 iter), loss = 1.25
I0630 09:41:03.104673 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 09:41:03.104682 29777 sgd_solver.cpp:106] Iteration 141100, lr = 0.00559062
I0630 09:41:19.145864 29777 solver.cpp:290] Iteration 141200 (6.23412 iter/s, 16.0408s/100 iter), loss = 1.07143
I0630 09:41:19.145954 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 09:41:19.145965 29777 sgd_solver.cpp:106] Iteration 141200, lr = 0.0055875
I0630 09:41:35.128746 29777 solver.cpp:290] Iteration 141300 (6.2569 iter/s, 15.9824s/100 iter), loss = 1.19048
I0630 09:41:35.128772 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 09:41:35.128782 29777 sgd_solver.cpp:106] Iteration 141300, lr = 0.00558437
I0630 09:41:51.060901 29777 solver.cpp:290] Iteration 141400 (6.2768 iter/s, 15.9317s/100 iter), loss = 1.33333
I0630 09:41:51.061005 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:41:51.061014 29777 sgd_solver.cpp:106] Iteration 141400, lr = 0.00558125
I0630 09:42:07.152451 29777 solver.cpp:290] Iteration 141500 (6.21465 iter/s, 16.091s/100 iter), loss = 1.34524
I0630 09:42:07.152474 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 09:42:07.152480 29777 sgd_solver.cpp:106] Iteration 141500, lr = 0.00557812
I0630 09:42:23.303364 29777 solver.cpp:290] Iteration 141600 (6.19178 iter/s, 16.1504s/100 iter), loss = 1.04762
I0630 09:42:23.303459 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:42:23.303470 29777 sgd_solver.cpp:106] Iteration 141600, lr = 0.005575
I0630 09:42:39.234614 29777 solver.cpp:290] Iteration 141700 (6.27718 iter/s, 15.9307s/100 iter), loss = 1.67857
I0630 09:42:39.234637 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 09:42:39.234652 29777 sgd_solver.cpp:106] Iteration 141700, lr = 0.00557187
I0630 09:42:55.225003 29777 solver.cpp:290] Iteration 141800 (6.25394 iter/s, 15.9899s/100 iter), loss = 1.5119
I0630 09:42:55.225075 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:42:55.225085 29777 sgd_solver.cpp:106] Iteration 141800, lr = 0.00556875
I0630 09:43:11.152107 29777 solver.cpp:290] Iteration 141900 (6.2788 iter/s, 15.9266s/100 iter), loss = 1.19048
I0630 09:43:11.152133 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 09:43:11.152143 29777 sgd_solver.cpp:106] Iteration 141900, lr = 0.00556563
I0630 09:43:26.976514 29777 solver.cpp:354] Sparsity after update:
I0630 09:43:26.977957 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:43:26.977963 29777 net.cpp:1851] conv1a_param_0(0.355) 
I0630 09:43:26.977972 29777 net.cpp:1851] conv1b_param_0(0.71) 
I0630 09:43:26.977973 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:43:26.977977 29777 net.cpp:1851] res2a_branch2a_param_0(0.71) 
I0630 09:43:26.977978 29777 net.cpp:1851] res2a_branch2b_param_0(0.71) 
I0630 09:43:26.977980 29777 net.cpp:1851] res3a_branch2a_param_0(0.71) 
I0630 09:43:26.977982 29777 net.cpp:1851] res3a_branch2b_param_0(0.71) 
I0630 09:43:26.977984 29777 net.cpp:1851] res4a_branch2a_param_0(0.71) 
I0630 09:43:26.977988 29777 net.cpp:1851] res4a_branch2b_param_0(0.71) 
I0630 09:43:26.977989 29777 net.cpp:1851] res5a_branch2a_param_0(0.71) 
I0630 09:43:26.977991 29777 net.cpp:1851] res5a_branch2b_param_0(0.71) 
I0630 09:43:26.977993 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.67104e+06/2.86678e+06) 0.583
I0630 09:43:26.978081 29777 solver.cpp:471] Iteration 142000, Testing net (#0)
I0630 09:43:38.118890 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:44:15.749691 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5545
I0630 09:44:15.749758 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.792361
I0630 09:44:15.749768 29777 solver.cpp:544]     Test net output #2: loss = 1.58894 (* 1 = 1.58894 loss)
I0630 09:44:15.924554 29777 solver.cpp:290] Iteration 142000 (1.54391 iter/s, 64.7707s/100 iter), loss = 1.64286
I0630 09:44:15.924582 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 09:44:15.924590 29777 sgd_solver.cpp:106] Iteration 142000, lr = 0.0055625
I0630 09:44:15.925572 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.72
I0630 09:44:16.487495 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:44:32.438103 29777 solver.cpp:290] Iteration 142100 (6.05581 iter/s, 16.5131s/100 iter), loss = 1.20238
I0630 09:44:32.438128 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 09:44:32.438135 29777 sgd_solver.cpp:106] Iteration 142100, lr = 0.00555938
I0630 09:44:48.412338 29777 solver.cpp:290] Iteration 142200 (6.26026 iter/s, 15.9738s/100 iter), loss = 1.11905
I0630 09:44:48.412417 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 09:44:48.412425 29777 sgd_solver.cpp:106] Iteration 142200, lr = 0.00555625
I0630 09:45:04.491364 29777 solver.cpp:290] Iteration 142300 (6.21948 iter/s, 16.0785s/100 iter), loss = 1.33333
I0630 09:45:04.491389 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:45:04.491395 29777 sgd_solver.cpp:106] Iteration 142300, lr = 0.00555312
I0630 09:45:20.536253 29777 solver.cpp:290] Iteration 142400 (6.2327 iter/s, 16.0444s/100 iter), loss = 1.34524
I0630 09:45:20.536381 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:45:20.536391 29777 sgd_solver.cpp:106] Iteration 142400, lr = 0.00555
I0630 09:45:36.514550 29777 solver.cpp:290] Iteration 142500 (6.25871 iter/s, 15.9777s/100 iter), loss = 1.64286
I0630 09:45:36.514575 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 09:45:36.514585 29777 sgd_solver.cpp:106] Iteration 142500, lr = 0.00554687
I0630 09:45:52.612013 29777 solver.cpp:290] Iteration 142600 (6.21234 iter/s, 16.097s/100 iter), loss = 1.19048
I0630 09:45:52.612085 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 09:45:52.612095 29777 sgd_solver.cpp:106] Iteration 142600, lr = 0.00554375
I0630 09:46:08.608492 29777 solver.cpp:290] Iteration 142700 (6.25157 iter/s, 15.996s/100 iter), loss = 1.15476
I0630 09:46:08.608515 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:46:08.608522 29777 sgd_solver.cpp:106] Iteration 142700, lr = 0.00554062
I0630 09:46:24.709108 29777 solver.cpp:290] Iteration 142800 (6.21112 iter/s, 16.1002s/100 iter), loss = 1.29762
I0630 09:46:24.709170 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:46:24.709182 29777 sgd_solver.cpp:106] Iteration 142800, lr = 0.0055375
I0630 09:46:40.742142 29777 solver.cpp:290] Iteration 142900 (6.23732 iter/s, 16.0325s/100 iter), loss = 1.22619
I0630 09:46:40.742169 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:46:40.742179 29777 sgd_solver.cpp:106] Iteration 142900, lr = 0.00553437
I0630 09:46:56.577419 29777 solver.cpp:354] Sparsity after update:
I0630 09:46:56.597921 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:46:56.597937 29777 net.cpp:1851] conv1a_param_0(0.36) 
I0630 09:46:56.597947 29777 net.cpp:1851] conv1b_param_0(0.715) 
I0630 09:46:56.597951 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:46:56.597955 29777 net.cpp:1851] res2a_branch2a_param_0(0.72) 
I0630 09:46:56.597960 29777 net.cpp:1851] res2a_branch2b_param_0(0.72) 
I0630 09:46:56.597964 29777 net.cpp:1851] res3a_branch2a_param_0(0.72) 
I0630 09:46:56.597966 29777 net.cpp:1851] res3a_branch2b_param_0(0.72) 
I0630 09:46:56.597970 29777 net.cpp:1851] res4a_branch2a_param_0(0.72) 
I0630 09:46:56.597973 29777 net.cpp:1851] res4a_branch2b_param_0(0.72) 
I0630 09:46:56.597976 29777 net.cpp:1851] res5a_branch2a_param_0(0.72) 
I0630 09:46:56.597980 29777 net.cpp:1851] res5a_branch2b_param_0(0.72) 
I0630 09:46:56.597983 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.69456e+06/2.86678e+06) 0.591
I0630 09:46:56.754029 29777 solver.cpp:290] Iteration 143000 (6.24554 iter/s, 16.0114s/100 iter), loss = 1.82143
I0630 09:46:56.754051 29777 solver.cpp:309]     Train net output #0: loss = 2.07143 (* 1 = 2.07143 loss)
I0630 09:46:56.754060 29777 sgd_solver.cpp:106] Iteration 143000, lr = 0.00553125
I0630 09:47:12.773581 29777 solver.cpp:290] Iteration 143100 (6.24255 iter/s, 16.0191s/100 iter), loss = 1.15476
I0630 09:47:12.773605 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 09:47:12.773614 29777 sgd_solver.cpp:106] Iteration 143100, lr = 0.00552812
I0630 09:47:28.847419 29777 solver.cpp:290] Iteration 143200 (6.22147 iter/s, 16.0734s/100 iter), loss = 1.21429
I0630 09:47:28.847527 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:47:28.847537 29777 sgd_solver.cpp:106] Iteration 143200, lr = 0.005525
I0630 09:47:44.988567 29777 solver.cpp:290] Iteration 143300 (6.19556 iter/s, 16.1406s/100 iter), loss = 1.4881
I0630 09:47:44.988590 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 09:47:44.988597 29777 sgd_solver.cpp:106] Iteration 143300, lr = 0.00552187
I0630 09:48:01.018296 29777 solver.cpp:290] Iteration 143400 (6.23859 iter/s, 16.0293s/100 iter), loss = 1.61905
I0630 09:48:01.018370 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 09:48:01.018383 29777 sgd_solver.cpp:106] Iteration 143400, lr = 0.00551875
I0630 09:48:17.067549 29777 solver.cpp:290] Iteration 143500 (6.23102 iter/s, 16.0487s/100 iter), loss = 1.47619
I0630 09:48:17.067575 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 09:48:17.067584 29777 sgd_solver.cpp:106] Iteration 143500, lr = 0.00551562
I0630 09:48:33.154450 29777 solver.cpp:290] Iteration 143600 (6.21642 iter/s, 16.0864s/100 iter), loss = 0.904762
I0630 09:48:33.154525 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:48:33.154534 29777 sgd_solver.cpp:106] Iteration 143600, lr = 0.0055125
I0630 09:48:49.197538 29777 solver.cpp:290] Iteration 143700 (6.23341 iter/s, 16.0426s/100 iter), loss = 1.5119
I0630 09:48:49.197587 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:48:49.197602 29777 sgd_solver.cpp:106] Iteration 143700, lr = 0.00550938
I0630 09:49:05.186848 29777 solver.cpp:290] Iteration 143800 (6.25437 iter/s, 15.9888s/100 iter), loss = 1.42857
I0630 09:49:05.186940 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 09:49:05.186961 29777 sgd_solver.cpp:106] Iteration 143800, lr = 0.00550625
I0630 09:49:21.317437 29777 solver.cpp:290] Iteration 143900 (6.1996 iter/s, 16.1301s/100 iter), loss = 1.16667
I0630 09:49:21.317461 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:49:21.317467 29777 sgd_solver.cpp:106] Iteration 143900, lr = 0.00550313
I0630 09:49:37.214335 29777 solver.cpp:354] Sparsity after update:
I0630 09:49:37.216246 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:49:37.216262 29777 net.cpp:1851] conv1a_param_0(0.36) 
I0630 09:49:37.216274 29777 net.cpp:1851] conv1b_param_0(0.715) 
I0630 09:49:37.216277 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:49:37.216279 29777 net.cpp:1851] res2a_branch2a_param_0(0.72) 
I0630 09:49:37.216282 29777 net.cpp:1851] res2a_branch2b_param_0(0.72) 
I0630 09:49:37.216285 29777 net.cpp:1851] res3a_branch2a_param_0(0.72) 
I0630 09:49:37.216289 29777 net.cpp:1851] res3a_branch2b_param_0(0.72) 
I0630 09:49:37.216291 29777 net.cpp:1851] res4a_branch2a_param_0(0.72) 
I0630 09:49:37.216295 29777 net.cpp:1851] res4a_branch2b_param_0(0.72) 
I0630 09:49:37.216296 29777 net.cpp:1851] res5a_branch2a_param_0(0.72) 
I0630 09:49:37.216297 29777 net.cpp:1851] res5a_branch2b_param_0(0.72) 
I0630 09:49:37.216300 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.69456e+06/2.86678e+06) 0.591
I0630 09:49:37.216406 29777 solver.cpp:471] Iteration 144000, Testing net (#0)
I0630 09:49:50.949750 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:50:29.207171 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55906
I0630 09:50:29.207281 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.794261
I0630 09:50:29.207293 29777 solver.cpp:544]     Test net output #2: loss = 1.56848 (* 1 = 1.56848 loss)
I0630 09:50:29.390657 29777 solver.cpp:290] Iteration 144000 (1.46905 iter/s, 68.0714s/100 iter), loss = 0.904762
I0630 09:50:29.390682 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 09:50:29.390691 29777 sgd_solver.cpp:106] Iteration 144000, lr = 0.0055
I0630 09:50:29.391404 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.73
I0630 09:50:29.950243 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:50:45.935781 29777 solver.cpp:290] Iteration 144100 (6.04425 iter/s, 16.5446s/100 iter), loss = 1.44048
I0630 09:50:45.935806 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 09:50:45.935811 29777 sgd_solver.cpp:106] Iteration 144100, lr = 0.00549687
I0630 09:51:02.125020 29777 solver.cpp:290] Iteration 144200 (6.17712 iter/s, 16.1888s/100 iter), loss = 1.2619
I0630 09:51:02.125113 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 09:51:02.125124 29777 sgd_solver.cpp:106] Iteration 144200, lr = 0.00549375
I0630 09:51:18.287909 29777 solver.cpp:290] Iteration 144300 (6.18722 iter/s, 16.1624s/100 iter), loss = 1.53571
I0630 09:51:18.287932 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 09:51:18.287938 29777 sgd_solver.cpp:106] Iteration 144300, lr = 0.00549062
I0630 09:51:34.489845 29777 solver.cpp:290] Iteration 144400 (6.17228 iter/s, 16.2015s/100 iter), loss = 1.47619
I0630 09:51:34.489943 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 09:51:34.489976 29777 sgd_solver.cpp:106] Iteration 144400, lr = 0.0054875
I0630 09:51:50.501173 29777 solver.cpp:290] Iteration 144500 (6.24578 iter/s, 16.0108s/100 iter), loss = 0.916667
I0630 09:51:50.501196 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 09:51:50.501204 29777 sgd_solver.cpp:106] Iteration 144500, lr = 0.00548437
I0630 09:52:06.516988 29777 solver.cpp:290] Iteration 144600 (6.24401 iter/s, 16.0154s/100 iter), loss = 1.2381
I0630 09:52:06.517091 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 09:52:06.517101 29777 sgd_solver.cpp:106] Iteration 144600, lr = 0.00548125
I0630 09:52:22.488925 29777 solver.cpp:290] Iteration 144700 (6.26119 iter/s, 15.9714s/100 iter), loss = 1.11905
I0630 09:52:22.488947 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 09:52:22.488955 29777 sgd_solver.cpp:106] Iteration 144700, lr = 0.00547812
I0630 09:52:38.405555 29777 solver.cpp:290] Iteration 144800 (6.28292 iter/s, 15.9162s/100 iter), loss = 1.30952
I0630 09:52:38.405614 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 09:52:38.405625 29777 sgd_solver.cpp:106] Iteration 144800, lr = 0.005475
I0630 09:52:54.549932 29777 solver.cpp:290] Iteration 144900 (6.1943 iter/s, 16.1439s/100 iter), loss = 1.36905
I0630 09:52:54.549955 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 09:52:54.549962 29777 sgd_solver.cpp:106] Iteration 144900, lr = 0.00547187
I0630 09:53:10.424510 29777 solver.cpp:354] Sparsity after update:
I0630 09:53:10.445008 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:53:10.445062 29777 net.cpp:1851] conv1a_param_0(0.365) 
I0630 09:53:10.445088 29777 net.cpp:1851] conv1b_param_0(0.717) 
I0630 09:53:10.445101 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:53:10.445111 29777 net.cpp:1851] res2a_branch2a_param_0(0.73) 
I0630 09:53:10.445123 29777 net.cpp:1851] res2a_branch2b_param_0(0.73) 
I0630 09:53:10.445133 29777 net.cpp:1851] res3a_branch2a_param_0(0.73) 
I0630 09:53:10.445143 29777 net.cpp:1851] res3a_branch2b_param_0(0.73) 
I0630 09:53:10.445154 29777 net.cpp:1851] res4a_branch2a_param_0(0.73) 
I0630 09:53:10.445163 29777 net.cpp:1851] res4a_branch2b_param_0(0.73) 
I0630 09:53:10.445174 29777 net.cpp:1851] res5a_branch2a_param_0(0.73) 
I0630 09:53:10.445184 29777 net.cpp:1851] res5a_branch2b_param_0(0.73) 
I0630 09:53:10.445195 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.71808e+06/2.86678e+06) 0.599
I0630 09:53:10.661783 29777 solver.cpp:290] Iteration 145000 (6.20679 iter/s, 16.1114s/100 iter), loss = 0.976191
I0630 09:53:10.661809 29777 solver.cpp:309]     Train net output #0: loss = 0.52381 (* 1 = 0.52381 loss)
I0630 09:53:10.661815 29777 sgd_solver.cpp:106] Iteration 145000, lr = 0.00546875
I0630 09:53:26.730996 29777 solver.cpp:290] Iteration 145100 (6.22326 iter/s, 16.0688s/100 iter), loss = 1.38095
I0630 09:53:26.731019 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 09:53:26.731026 29777 sgd_solver.cpp:106] Iteration 145100, lr = 0.00546562
I0630 09:53:42.833976 29777 solver.cpp:290] Iteration 145200 (6.21021 iter/s, 16.1025s/100 iter), loss = 1.15476
I0630 09:53:42.834058 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 09:53:42.834065 29777 sgd_solver.cpp:106] Iteration 145200, lr = 0.0054625
I0630 09:53:58.837447 29777 solver.cpp:290] Iteration 145300 (6.24885 iter/s, 16.003s/100 iter), loss = 0.916667
I0630 09:53:58.837471 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 09:53:58.837476 29777 sgd_solver.cpp:106] Iteration 145300, lr = 0.00545938
I0630 09:54:14.763298 29777 solver.cpp:290] Iteration 145400 (6.27928 iter/s, 15.9254s/100 iter), loss = 1.39286
I0630 09:54:14.763357 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 09:54:14.763368 29777 sgd_solver.cpp:106] Iteration 145400, lr = 0.00545625
I0630 09:54:30.863906 29777 solver.cpp:290] Iteration 145500 (6.21114 iter/s, 16.1001s/100 iter), loss = 1.4881
I0630 09:54:30.863930 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 09:54:30.863937 29777 sgd_solver.cpp:106] Iteration 145500, lr = 0.00545313
I0630 09:54:46.871554 29777 solver.cpp:290] Iteration 145600 (6.24719 iter/s, 16.0072s/100 iter), loss = 1.14286
I0630 09:54:46.871659 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:54:46.871667 29777 sgd_solver.cpp:106] Iteration 145600, lr = 0.00545
I0630 09:55:03.037358 29777 solver.cpp:290] Iteration 145700 (6.18611 iter/s, 16.1653s/100 iter), loss = 1.35714
I0630 09:55:03.037380 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 09:55:03.037387 29777 sgd_solver.cpp:106] Iteration 145700, lr = 0.00544688
I0630 09:55:19.064007 29777 solver.cpp:290] Iteration 145800 (6.23979 iter/s, 16.0262s/100 iter), loss = 1.03571
I0630 09:55:19.064110 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 09:55:19.064119 29777 sgd_solver.cpp:106] Iteration 145800, lr = 0.00544375
I0630 09:55:35.141397 29777 solver.cpp:290] Iteration 145900 (6.22012 iter/s, 16.0768s/100 iter), loss = 0.785714
I0630 09:55:35.141419 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 09:55:35.141425 29777 sgd_solver.cpp:106] Iteration 145900, lr = 0.00544062
I0630 09:55:50.917417 29777 solver.cpp:354] Sparsity after update:
I0630 09:55:50.919719 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:55:50.919832 29777 net.cpp:1851] conv1a_param_0(0.365) 
I0630 09:55:50.919919 29777 net.cpp:1851] conv1b_param_0(0.717) 
I0630 09:55:50.919991 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:55:50.920063 29777 net.cpp:1851] res2a_branch2a_param_0(0.73) 
I0630 09:55:50.920135 29777 net.cpp:1851] res2a_branch2b_param_0(0.73) 
I0630 09:55:50.920210 29777 net.cpp:1851] res3a_branch2a_param_0(0.73) 
I0630 09:55:50.920287 29777 net.cpp:1851] res3a_branch2b_param_0(0.73) 
I0630 09:55:50.920361 29777 net.cpp:1851] res4a_branch2a_param_0(0.73) 
I0630 09:55:50.920435 29777 net.cpp:1851] res4a_branch2b_param_0(0.73) 
I0630 09:55:50.920509 29777 net.cpp:1851] res5a_branch2a_param_0(0.73) 
I0630 09:55:50.920583 29777 net.cpp:1851] res5a_branch2b_param_0(0.73) 
I0630 09:55:50.920657 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.71808e+06/2.86678e+06) 0.599
I0630 09:55:50.921016 29777 solver.cpp:471] Iteration 146000, Testing net (#0)
I0630 09:56:02.880383 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 09:56:40.294417 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5558
I0630 09:56:40.294463 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.793021
I0630 09:56:40.294471 29777 solver.cpp:544]     Test net output #2: loss = 1.59158 (* 1 = 1.59158 loss)
I0630 09:56:40.473960 29777 solver.cpp:290] Iteration 146000 (1.53067 iter/s, 65.3308s/100 iter), loss = 1.16667
I0630 09:56:40.473991 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 09:56:40.474001 29777 sgd_solver.cpp:106] Iteration 146000, lr = 0.0054375
I0630 09:56:40.475139 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.74
I0630 09:56:41.047827 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 09:56:56.958389 29777 solver.cpp:290] Iteration 146100 (6.06651 iter/s, 16.4839s/100 iter), loss = 1.13095
I0630 09:56:56.958413 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 09:56:56.958422 29777 sgd_solver.cpp:106] Iteration 146100, lr = 0.00543437
I0630 09:57:12.982522 29777 solver.cpp:290] Iteration 146200 (6.24077 iter/s, 16.0237s/100 iter), loss = 1.45238
I0630 09:57:12.982643 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 09:57:12.982653 29777 sgd_solver.cpp:106] Iteration 146200, lr = 0.00543125
I0630 09:57:29.010248 29777 solver.cpp:290] Iteration 146300 (6.23941 iter/s, 16.0272s/100 iter), loss = 1.36905
I0630 09:57:29.010277 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 09:57:29.010287 29777 sgd_solver.cpp:106] Iteration 146300, lr = 0.00542812
I0630 09:57:45.020198 29777 solver.cpp:290] Iteration 146400 (6.2463 iter/s, 16.0095s/100 iter), loss = 1.13095
I0630 09:57:45.020308 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 09:57:45.020326 29777 sgd_solver.cpp:106] Iteration 146400, lr = 0.005425
I0630 09:58:01.105541 29777 solver.cpp:290] Iteration 146500 (6.21705 iter/s, 16.0848s/100 iter), loss = 1.42857
I0630 09:58:01.105563 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 09:58:01.105571 29777 sgd_solver.cpp:106] Iteration 146500, lr = 0.00542188
I0630 09:58:17.100450 29777 solver.cpp:290] Iteration 146600 (6.25217 iter/s, 15.9944s/100 iter), loss = 1.44048
I0630 09:58:17.100499 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 09:58:17.100507 29777 sgd_solver.cpp:106] Iteration 146600, lr = 0.00541875
I0630 09:58:33.140748 29777 solver.cpp:290] Iteration 146700 (6.23449 iter/s, 16.0398s/100 iter), loss = 1.58333
I0630 09:58:33.140789 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 09:58:33.140800 29777 sgd_solver.cpp:106] Iteration 146700, lr = 0.00541562
I0630 09:58:49.152766 29777 solver.cpp:290] Iteration 146800 (6.2455 iter/s, 16.0115s/100 iter), loss = 1.16667
I0630 09:58:49.152869 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 09:58:49.152879 29777 sgd_solver.cpp:106] Iteration 146800, lr = 0.0054125
I0630 09:59:05.173409 29777 solver.cpp:290] Iteration 146900 (6.24216 iter/s, 16.0201s/100 iter), loss = 1.2619
I0630 09:59:05.173436 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 09:59:05.173454 29777 sgd_solver.cpp:106] Iteration 146900, lr = 0.00540938
I0630 09:59:21.014077 29777 solver.cpp:354] Sparsity after update:
I0630 09:59:21.034693 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 09:59:21.034713 29777 net.cpp:1851] conv1a_param_0(0.37) 
I0630 09:59:21.034723 29777 net.cpp:1851] conv1b_param_0(0.72) 
I0630 09:59:21.034728 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 09:59:21.034730 29777 net.cpp:1851] res2a_branch2a_param_0(0.74) 
I0630 09:59:21.034734 29777 net.cpp:1851] res2a_branch2b_param_0(0.74) 
I0630 09:59:21.034741 29777 net.cpp:1851] res3a_branch2a_param_0(0.74) 
I0630 09:59:21.034746 29777 net.cpp:1851] res3a_branch2b_param_0(0.74) 
I0630 09:59:21.034751 29777 net.cpp:1851] res4a_branch2a_param_0(0.74) 
I0630 09:59:21.034756 29777 net.cpp:1851] res4a_branch2b_param_0(0.74) 
I0630 09:59:21.034761 29777 net.cpp:1851] res5a_branch2a_param_0(0.74) 
I0630 09:59:21.034766 29777 net.cpp:1851] res5a_branch2b_param_0(0.74) 
I0630 09:59:21.034770 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.7416e+06/2.86678e+06) 0.608
I0630 09:59:21.191740 29777 solver.cpp:290] Iteration 147000 (6.24303 iter/s, 16.0179s/100 iter), loss = 0.928571
I0630 09:59:21.191763 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 09:59:21.191769 29777 sgd_solver.cpp:106] Iteration 147000, lr = 0.00540625
I0630 09:59:37.301872 29777 solver.cpp:290] Iteration 147100 (6.20745 iter/s, 16.1097s/100 iter), loss = 1.38095
I0630 09:59:37.301894 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 09:59:37.301901 29777 sgd_solver.cpp:106] Iteration 147100, lr = 0.00540313
I0630 09:59:53.365015 29777 solver.cpp:290] Iteration 147200 (6.22561 iter/s, 16.0627s/100 iter), loss = 1.14286
I0630 09:59:53.365131 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 09:59:53.365142 29777 sgd_solver.cpp:106] Iteration 147200, lr = 0.0054
I0630 10:00:09.277881 29777 solver.cpp:290] Iteration 147300 (6.28444 iter/s, 15.9123s/100 iter), loss = 1.46429
I0630 10:00:09.277907 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:00:09.277923 29777 sgd_solver.cpp:106] Iteration 147300, lr = 0.00539688
I0630 10:00:25.316447 29777 solver.cpp:290] Iteration 147400 (6.23515 iter/s, 16.0381s/100 iter), loss = 1.22619
I0630 10:00:25.316504 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 10:00:25.316514 29777 sgd_solver.cpp:106] Iteration 147400, lr = 0.00539375
I0630 10:00:41.264178 29777 solver.cpp:290] Iteration 147500 (6.27068 iter/s, 15.9472s/100 iter), loss = 1.58333
I0630 10:00:41.264205 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:00:41.264214 29777 sgd_solver.cpp:106] Iteration 147500, lr = 0.00539062
I0630 10:00:57.221186 29777 solver.cpp:290] Iteration 147600 (6.26702 iter/s, 15.9565s/100 iter), loss = 1.19048
I0630 10:00:57.221293 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 10:00:57.221303 29777 sgd_solver.cpp:106] Iteration 147600, lr = 0.0053875
I0630 10:01:13.285178 29777 solver.cpp:290] Iteration 147700 (6.22531 iter/s, 16.0634s/100 iter), loss = 1.2381
I0630 10:01:13.285202 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:01:13.285208 29777 sgd_solver.cpp:106] Iteration 147700, lr = 0.00538437
I0630 10:01:29.275897 29777 solver.cpp:290] Iteration 147800 (6.25381 iter/s, 15.9903s/100 iter), loss = 1.35714
I0630 10:01:29.276008 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 10:01:29.276017 29777 sgd_solver.cpp:106] Iteration 147800, lr = 0.00538125
I0630 10:01:45.502769 29777 solver.cpp:290] Iteration 147900 (6.16283 iter/s, 16.2263s/100 iter), loss = 1.05952
I0630 10:01:45.502792 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 10:01:45.502799 29777 sgd_solver.cpp:106] Iteration 147900, lr = 0.00537812
I0630 10:02:01.323433 29777 solver.cpp:354] Sparsity after update:
I0630 10:02:01.324715 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:02:01.324723 29777 net.cpp:1851] conv1a_param_0(0.37) 
I0630 10:02:01.324729 29777 net.cpp:1851] conv1b_param_0(0.72) 
I0630 10:02:01.324731 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:02:01.324733 29777 net.cpp:1851] res2a_branch2a_param_0(0.74) 
I0630 10:02:01.324735 29777 net.cpp:1851] res2a_branch2b_param_0(0.74) 
I0630 10:02:01.324738 29777 net.cpp:1851] res3a_branch2a_param_0(0.74) 
I0630 10:02:01.324739 29777 net.cpp:1851] res3a_branch2b_param_0(0.74) 
I0630 10:02:01.324741 29777 net.cpp:1851] res4a_branch2a_param_0(0.74) 
I0630 10:02:01.324743 29777 net.cpp:1851] res4a_branch2b_param_0(0.74) 
I0630 10:02:01.324745 29777 net.cpp:1851] res5a_branch2a_param_0(0.74) 
I0630 10:02:01.324748 29777 net.cpp:1851] res5a_branch2b_param_0(0.74) 
I0630 10:02:01.324749 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.7416e+06/2.86678e+06) 0.608
I0630 10:02:01.324836 29777 solver.cpp:471] Iteration 148000, Testing net (#0)
I0630 10:02:13.386930 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:02:49.851163 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55324
I0630 10:02:49.851287 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.792421
I0630 10:02:49.851297 29777 solver.cpp:544]     Test net output #2: loss = 1.58856 (* 1 = 1.58856 loss)
I0630 10:02:50.027214 29777 solver.cpp:290] Iteration 148000 (1.54984 iter/s, 64.5227s/100 iter), loss = 1.03571
I0630 10:02:50.027236 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:02:50.027243 29777 sgd_solver.cpp:106] Iteration 148000, lr = 0.005375
I0630 10:02:50.028033 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.75
I0630 10:02:50.595365 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:03:06.509083 29777 solver.cpp:290] Iteration 148100 (6.06745 iter/s, 16.4814s/100 iter), loss = 1.35714
I0630 10:03:06.509109 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 10:03:06.509117 29777 sgd_solver.cpp:106] Iteration 148100, lr = 0.00537187
I0630 10:03:22.497797 29777 solver.cpp:290] Iteration 148200 (6.25459 iter/s, 15.9883s/100 iter), loss = 1.0119
I0630 10:03:22.497920 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 10:03:22.497936 29777 sgd_solver.cpp:106] Iteration 148200, lr = 0.00536875
I0630 10:03:38.526119 29777 solver.cpp:290] Iteration 148300 (6.23917 iter/s, 16.0278s/100 iter), loss = 1.09524
I0630 10:03:38.526144 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 10:03:38.526152 29777 sgd_solver.cpp:106] Iteration 148300, lr = 0.00536563
I0630 10:03:54.655853 29777 solver.cpp:290] Iteration 148400 (6.19991 iter/s, 16.1293s/100 iter), loss = 1.2619
I0630 10:03:54.655956 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 10:03:54.655966 29777 sgd_solver.cpp:106] Iteration 148400, lr = 0.0053625
I0630 10:04:10.641510 29777 solver.cpp:290] Iteration 148500 (6.25582 iter/s, 15.9851s/100 iter), loss = 1.2619
I0630 10:04:10.641532 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 10:04:10.641540 29777 sgd_solver.cpp:106] Iteration 148500, lr = 0.00535937
I0630 10:04:26.609143 29777 solver.cpp:290] Iteration 148600 (6.26285 iter/s, 15.9672s/100 iter), loss = 1.42857
I0630 10:04:26.609222 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 10:04:26.609233 29777 sgd_solver.cpp:106] Iteration 148600, lr = 0.00535625
I0630 10:04:42.559481 29777 solver.cpp:290] Iteration 148700 (6.26966 iter/s, 15.9498s/100 iter), loss = 1.07143
I0630 10:04:42.559507 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:04:42.559515 29777 sgd_solver.cpp:106] Iteration 148700, lr = 0.00535313
I0630 10:04:58.598582 29777 solver.cpp:290] Iteration 148800 (6.23494 iter/s, 16.0386s/100 iter), loss = 0.964286
I0630 10:04:58.598646 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 10:04:58.598659 29777 sgd_solver.cpp:106] Iteration 148800, lr = 0.00535
I0630 10:05:14.471549 29777 solver.cpp:290] Iteration 148900 (6.30022 iter/s, 15.8725s/100 iter), loss = 1.34524
I0630 10:05:14.471570 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 10:05:14.471577 29777 sgd_solver.cpp:106] Iteration 148900, lr = 0.00534688
I0630 10:05:30.319589 29777 solver.cpp:354] Sparsity after update:
I0630 10:05:30.340821 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:05:30.340836 29777 net.cpp:1851] conv1a_param_0(0.375) 
I0630 10:05:30.340845 29777 net.cpp:1851] conv1b_param_0(0.72) 
I0630 10:05:30.340848 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:05:30.340852 29777 net.cpp:1851] res2a_branch2a_param_0(0.75) 
I0630 10:05:30.340855 29777 net.cpp:1851] res2a_branch2b_param_0(0.75) 
I0630 10:05:30.340865 29777 net.cpp:1851] res3a_branch2a_param_0(0.75) 
I0630 10:05:30.340870 29777 net.cpp:1851] res3a_branch2b_param_0(0.75) 
I0630 10:05:30.340874 29777 net.cpp:1851] res4a_branch2a_param_0(0.75) 
I0630 10:05:30.340878 29777 net.cpp:1851] res4a_branch2b_param_0(0.75) 
I0630 10:05:30.340881 29777 net.cpp:1851] res5a_branch2a_param_0(0.75) 
I0630 10:05:30.340886 29777 net.cpp:1851] res5a_branch2b_param_0(0.75) 
I0630 10:05:30.340891 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.76511e+06/2.86678e+06) 0.616
I0630 10:05:30.497732 29777 solver.cpp:290] Iteration 149000 (6.23997 iter/s, 16.0257s/100 iter), loss = 1.47619
I0630 10:05:30.497757 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:05:30.497766 29777 sgd_solver.cpp:106] Iteration 149000, lr = 0.00534375
I0630 10:05:46.620770 29777 solver.cpp:290] Iteration 149100 (6.20249 iter/s, 16.1226s/100 iter), loss = 1.40476
I0630 10:05:46.620857 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 10:05:46.620883 29777 sgd_solver.cpp:106] Iteration 149100, lr = 0.00534063
I0630 10:06:02.704632 29777 solver.cpp:290] Iteration 149200 (6.21761 iter/s, 16.0833s/100 iter), loss = 1.04762
I0630 10:06:02.704738 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:06:02.704746 29777 sgd_solver.cpp:106] Iteration 149200, lr = 0.0053375
I0630 10:06:18.775022 29777 solver.cpp:290] Iteration 149300 (6.22283 iter/s, 16.0698s/100 iter), loss = 1.22619
I0630 10:06:18.775044 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 10:06:18.775051 29777 sgd_solver.cpp:106] Iteration 149300, lr = 0.00533437
I0630 10:06:34.832060 29777 solver.cpp:290] Iteration 149400 (6.22798 iter/s, 16.0566s/100 iter), loss = 1.15476
I0630 10:06:34.832134 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 10:06:34.832141 29777 sgd_solver.cpp:106] Iteration 149400, lr = 0.00533125
I0630 10:06:50.951056 29777 solver.cpp:290] Iteration 149500 (6.20406 iter/s, 16.1185s/100 iter), loss = 1.29762
I0630 10:06:50.951081 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:06:50.951086 29777 sgd_solver.cpp:106] Iteration 149500, lr = 0.00532812
I0630 10:07:07.041116 29777 solver.cpp:290] Iteration 149600 (6.2152 iter/s, 16.0896s/100 iter), loss = 1.32143
I0630 10:07:07.041223 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 10:07:07.041232 29777 sgd_solver.cpp:106] Iteration 149600, lr = 0.005325
I0630 10:07:23.097823 29777 solver.cpp:290] Iteration 149700 (6.22814 iter/s, 16.0562s/100 iter), loss = 1.08333
I0630 10:07:23.097852 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 10:07:23.097860 29777 sgd_solver.cpp:106] Iteration 149700, lr = 0.00532187
I0630 10:07:39.182751 29777 solver.cpp:290] Iteration 149800 (6.21718 iter/s, 16.0845s/100 iter), loss = 1.41667
I0630 10:07:39.182821 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:07:39.182828 29777 sgd_solver.cpp:106] Iteration 149800, lr = 0.00531875
I0630 10:07:55.247972 29777 solver.cpp:290] Iteration 149900 (6.22482 iter/s, 16.0647s/100 iter), loss = 1.47619
I0630 10:07:55.247994 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:07:55.248001 29777 sgd_solver.cpp:106] Iteration 149900, lr = 0.00531563
I0630 10:08:11.138454 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_150000.caffemodel
I0630 10:08:11.158221 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_150000.solverstate
I0630 10:08:11.166895 29777 solver.cpp:354] Sparsity after update:
I0630 10:08:11.167876 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:08:11.167884 29777 net.cpp:1851] conv1a_param_0(0.375) 
I0630 10:08:11.167892 29777 net.cpp:1851] conv1b_param_0(0.72) 
I0630 10:08:11.167894 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:08:11.167897 29777 net.cpp:1851] res2a_branch2a_param_0(0.75) 
I0630 10:08:11.167899 29777 net.cpp:1851] res2a_branch2b_param_0(0.75) 
I0630 10:08:11.167901 29777 net.cpp:1851] res3a_branch2a_param_0(0.75) 
I0630 10:08:11.167903 29777 net.cpp:1851] res3a_branch2b_param_0(0.75) 
I0630 10:08:11.167906 29777 net.cpp:1851] res4a_branch2a_param_0(0.75) 
I0630 10:08:11.167906 29777 net.cpp:1851] res4a_branch2b_param_0(0.75) 
I0630 10:08:11.167908 29777 net.cpp:1851] res5a_branch2a_param_0(0.75) 
I0630 10:08:11.167910 29777 net.cpp:1851] res5a_branch2b_param_0(0.75) 
I0630 10:08:11.167912 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.76511e+06/2.86678e+06) 0.616
I0630 10:08:11.168009 29777 solver.cpp:471] Iteration 150000, Testing net (#0)
I0630 10:08:23.452693 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:08:59.359616 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55572
I0630 10:08:59.359745 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.790761
I0630 10:08:59.359755 29777 solver.cpp:544]     Test net output #2: loss = 1.59656 (* 1 = 1.59656 loss)
I0630 10:08:59.535370 29777 solver.cpp:290] Iteration 150000 (1.55556 iter/s, 64.2856s/100 iter), loss = 1.34524
I0630 10:08:59.535395 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 10:08:59.535401 29777 sgd_solver.cpp:106] Iteration 150000, lr = 0.0053125
I0630 10:08:59.536097 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.76
I0630 10:09:00.145678 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:09:16.038522 29777 solver.cpp:290] Iteration 150100 (6.05962 iter/s, 16.5027s/100 iter), loss = 1.02381
I0630 10:09:16.038545 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 10:09:16.038552 29777 sgd_solver.cpp:106] Iteration 150100, lr = 0.00530938
I0630 10:09:32.113008 29777 solver.cpp:290] Iteration 150200 (6.22122 iter/s, 16.074s/100 iter), loss = 1.47619
I0630 10:09:32.113116 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 10:09:32.113126 29777 sgd_solver.cpp:106] Iteration 150200, lr = 0.00530625
I0630 10:09:48.186712 29777 solver.cpp:290] Iteration 150300 (6.22155 iter/s, 16.0732s/100 iter), loss = 1.03571
I0630 10:09:48.186738 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 10:09:48.186748 29777 sgd_solver.cpp:106] Iteration 150300, lr = 0.00530313
I0630 10:10:04.265913 29777 solver.cpp:290] Iteration 150400 (6.2194 iter/s, 16.0787s/100 iter), loss = 1.09524
I0630 10:10:04.266008 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:10:04.266019 29777 sgd_solver.cpp:106] Iteration 150400, lr = 0.0053
I0630 10:10:20.298063 29777 solver.cpp:290] Iteration 150500 (6.23767 iter/s, 16.0316s/100 iter), loss = 1.72619
I0630 10:10:20.298087 29777 solver.cpp:309]     Train net output #0: loss = 1.97619 (* 1 = 1.97619 loss)
I0630 10:10:20.298096 29777 sgd_solver.cpp:106] Iteration 150500, lr = 0.00529688
I0630 10:10:36.355993 29777 solver.cpp:290] Iteration 150600 (6.22763 iter/s, 16.0575s/100 iter), loss = 1.29762
I0630 10:10:36.356083 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:10:36.356094 29777 sgd_solver.cpp:106] Iteration 150600, lr = 0.00529375
I0630 10:10:52.373821 29777 solver.cpp:290] Iteration 150700 (6.24325 iter/s, 16.0173s/100 iter), loss = 1.16667
I0630 10:10:52.373847 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 10:10:52.373855 29777 sgd_solver.cpp:106] Iteration 150700, lr = 0.00529063
I0630 10:11:08.287565 29777 solver.cpp:290] Iteration 150800 (6.28406 iter/s, 15.9133s/100 iter), loss = 1.08333
I0630 10:11:08.287674 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:11:08.287683 29777 sgd_solver.cpp:106] Iteration 150800, lr = 0.0052875
I0630 10:11:24.541869 29777 solver.cpp:290] Iteration 150900 (6.15243 iter/s, 16.2537s/100 iter), loss = 1.09524
I0630 10:11:24.541894 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 10:11:24.541903 29777 sgd_solver.cpp:106] Iteration 150900, lr = 0.00528438
I0630 10:11:40.440045 29777 solver.cpp:354] Sparsity after update:
I0630 10:11:40.460494 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:11:40.460513 29777 net.cpp:1851] conv1a_param_0(0.38) 
I0630 10:11:40.460525 29777 net.cpp:1851] conv1b_param_0(0.721) 
I0630 10:11:40.460527 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:11:40.460531 29777 net.cpp:1851] res2a_branch2a_param_0(0.76) 
I0630 10:11:40.460537 29777 net.cpp:1851] res2a_branch2b_param_0(0.76) 
I0630 10:11:40.460541 29777 net.cpp:1851] res3a_branch2a_param_0(0.76) 
I0630 10:11:40.460544 29777 net.cpp:1851] res3a_branch2b_param_0(0.76) 
I0630 10:11:40.460547 29777 net.cpp:1851] res4a_branch2a_param_0(0.76) 
I0630 10:11:40.460551 29777 net.cpp:1851] res4a_branch2b_param_0(0.76) 
I0630 10:11:40.460556 29777 net.cpp:1851] res5a_branch2a_param_0(0.76) 
I0630 10:11:40.460559 29777 net.cpp:1851] res5a_branch2b_param_0(0.76) 
I0630 10:11:40.460562 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.78863e+06/2.86678e+06) 0.624
I0630 10:11:40.617455 29777 solver.cpp:290] Iteration 151000 (6.22079 iter/s, 16.0751s/100 iter), loss = 1.39286
I0630 10:11:40.617478 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:11:40.617485 29777 sgd_solver.cpp:106] Iteration 151000, lr = 0.00528125
I0630 10:11:56.651868 29777 solver.cpp:290] Iteration 151100 (6.23677 iter/s, 16.0339s/100 iter), loss = 1.45238
I0630 10:11:56.651895 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:11:56.651904 29777 sgd_solver.cpp:106] Iteration 151100, lr = 0.00527812
I0630 10:12:12.617372 29777 solver.cpp:290] Iteration 151200 (6.26369 iter/s, 15.965s/100 iter), loss = 1.30952
I0630 10:12:12.617465 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 10:12:12.617476 29777 sgd_solver.cpp:106] Iteration 151200, lr = 0.005275
I0630 10:12:28.726431 29777 solver.cpp:290] Iteration 151300 (6.20789 iter/s, 16.1085s/100 iter), loss = 1.28571
I0630 10:12:28.726456 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 10:12:28.726465 29777 sgd_solver.cpp:106] Iteration 151300, lr = 0.00527187
I0630 10:12:44.650995 29777 solver.cpp:290] Iteration 151400 (6.27979 iter/s, 15.9241s/100 iter), loss = 1.58333
I0630 10:12:44.651067 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 10:12:44.651075 29777 sgd_solver.cpp:106] Iteration 151400, lr = 0.00526875
I0630 10:13:00.632557 29777 solver.cpp:290] Iteration 151500 (6.25741 iter/s, 15.9811s/100 iter), loss = 0.988095
I0630 10:13:00.632583 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:13:00.632592 29777 sgd_solver.cpp:106] Iteration 151500, lr = 0.00526563
I0630 10:13:16.553815 29777 solver.cpp:290] Iteration 151600 (6.28109 iter/s, 15.9208s/100 iter), loss = 1.08333
I0630 10:13:16.553860 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 10:13:16.553869 29777 sgd_solver.cpp:106] Iteration 151600, lr = 0.0052625
I0630 10:13:32.643013 29777 solver.cpp:290] Iteration 151700 (6.21554 iter/s, 16.0887s/100 iter), loss = 0.904762
I0630 10:13:32.643036 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:13:32.643043 29777 sgd_solver.cpp:106] Iteration 151700, lr = 0.00525938
I0630 10:13:48.589253 29777 solver.cpp:290] Iteration 151800 (6.27125 iter/s, 15.9458s/100 iter), loss = 1.69048
I0630 10:13:48.589334 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 10:13:48.589344 29777 sgd_solver.cpp:106] Iteration 151800, lr = 0.00525625
I0630 10:14:04.560622 29777 solver.cpp:290] Iteration 151900 (6.26141 iter/s, 15.9709s/100 iter), loss = 1.46429
I0630 10:14:04.560647 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 10:14:04.560654 29777 sgd_solver.cpp:106] Iteration 151900, lr = 0.00525313
I0630 10:14:20.432607 29777 solver.cpp:354] Sparsity after update:
I0630 10:14:20.433876 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:14:20.433883 29777 net.cpp:1851] conv1a_param_0(0.38) 
I0630 10:14:20.433890 29777 net.cpp:1851] conv1b_param_0(0.721) 
I0630 10:14:20.433892 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:14:20.433895 29777 net.cpp:1851] res2a_branch2a_param_0(0.76) 
I0630 10:14:20.433897 29777 net.cpp:1851] res2a_branch2b_param_0(0.76) 
I0630 10:14:20.433899 29777 net.cpp:1851] res3a_branch2a_param_0(0.76) 
I0630 10:14:20.433900 29777 net.cpp:1851] res3a_branch2b_param_0(0.76) 
I0630 10:14:20.433902 29777 net.cpp:1851] res4a_branch2a_param_0(0.76) 
I0630 10:14:20.433904 29777 net.cpp:1851] res4a_branch2b_param_0(0.76) 
I0630 10:14:20.433907 29777 net.cpp:1851] res5a_branch2a_param_0(0.76) 
I0630 10:14:20.433908 29777 net.cpp:1851] res5a_branch2b_param_0(0.76) 
I0630 10:14:20.433910 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.78863e+06/2.86678e+06) 0.624
I0630 10:14:20.434026 29777 solver.cpp:471] Iteration 152000, Testing net (#0)
I0630 10:14:32.651437 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:15:08.872351 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.55262
I0630 10:15:08.872438 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.788501
I0630 10:15:08.872447 29777 solver.cpp:544]     Test net output #2: loss = 1.6017 (* 1 = 1.6017 loss)
I0630 10:15:09.042445 29777 solver.cpp:290] Iteration 152000 (1.55087 iter/s, 64.4801s/100 iter), loss = 1.39286
I0630 10:15:09.042471 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 10:15:09.042480 29777 sgd_solver.cpp:106] Iteration 152000, lr = 0.00525
I0630 10:15:09.043460 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.77
I0630 10:15:09.644316 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:15:25.634402 29777 solver.cpp:290] Iteration 152100 (6.02719 iter/s, 16.5915s/100 iter), loss = 1.2381
I0630 10:15:25.634429 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:15:25.634438 29777 sgd_solver.cpp:106] Iteration 152100, lr = 0.00524688
I0630 10:15:41.618468 29777 solver.cpp:290] Iteration 152200 (6.25641 iter/s, 15.9836s/100 iter), loss = 1.07143
I0630 10:15:41.618580 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 10:15:41.618594 29777 sgd_solver.cpp:106] Iteration 152200, lr = 0.00524375
I0630 10:15:57.638623 29777 solver.cpp:290] Iteration 152300 (6.24235 iter/s, 16.0196s/100 iter), loss = 1.16667
I0630 10:15:57.638646 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:15:57.638654 29777 sgd_solver.cpp:106] Iteration 152300, lr = 0.00524063
I0630 10:16:13.600672 29777 solver.cpp:290] Iteration 152400 (6.26504 iter/s, 15.9616s/100 iter), loss = 1.40476
I0630 10:16:13.600765 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:16:13.600777 29777 sgd_solver.cpp:106] Iteration 152400, lr = 0.0052375
I0630 10:16:29.626588 29777 solver.cpp:290] Iteration 152500 (6.2401 iter/s, 16.0254s/100 iter), loss = 1.4881
I0630 10:16:29.626615 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 10:16:29.626624 29777 sgd_solver.cpp:106] Iteration 152500, lr = 0.00523437
I0630 10:16:45.826342 29777 solver.cpp:290] Iteration 152600 (6.17311 iter/s, 16.1993s/100 iter), loss = 1.08333
I0630 10:16:45.826380 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 10:16:45.826387 29777 sgd_solver.cpp:106] Iteration 152600, lr = 0.00523125
I0630 10:17:01.870028 29777 solver.cpp:290] Iteration 152700 (6.23317 iter/s, 16.0432s/100 iter), loss = 1.5119
I0630 10:17:01.870090 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 10:17:01.870110 29777 sgd_solver.cpp:106] Iteration 152700, lr = 0.00522812
I0630 10:17:17.873430 29777 solver.cpp:290] Iteration 152800 (6.24886 iter/s, 16.0029s/100 iter), loss = 1.65476
I0630 10:17:17.873553 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 10:17:17.873566 29777 sgd_solver.cpp:106] Iteration 152800, lr = 0.005225
I0630 10:17:33.914526 29777 solver.cpp:290] Iteration 152900 (6.2342 iter/s, 16.0405s/100 iter), loss = 1.38095
I0630 10:17:33.914551 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 10:17:33.914561 29777 sgd_solver.cpp:106] Iteration 152900, lr = 0.00522187
I0630 10:17:49.830705 29777 solver.cpp:354] Sparsity after update:
I0630 10:17:49.851135 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:17:49.851150 29777 net.cpp:1851] conv1a_param_0(0.385) 
I0630 10:17:49.851162 29777 net.cpp:1851] conv1b_param_0(0.723) 
I0630 10:17:49.851166 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:17:49.851177 29777 net.cpp:1851] res2a_branch2a_param_0(0.77) 
I0630 10:17:49.851181 29777 net.cpp:1851] res2a_branch2b_param_0(0.77) 
I0630 10:17:49.851186 29777 net.cpp:1851] res3a_branch2a_param_0(0.77) 
I0630 10:17:49.851191 29777 net.cpp:1851] res3a_branch2b_param_0(0.77) 
I0630 10:17:49.851197 29777 net.cpp:1851] res4a_branch2a_param_0(0.77) 
I0630 10:17:49.851202 29777 net.cpp:1851] res4a_branch2b_param_0(0.77) 
I0630 10:17:49.851207 29777 net.cpp:1851] res5a_branch2a_param_0(0.77) 
I0630 10:17:49.851212 29777 net.cpp:1851] res5a_branch2b_param_0(0.77) 
I0630 10:17:49.851214 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.81214e+06/2.86678e+06) 0.632
I0630 10:17:50.012084 29777 solver.cpp:290] Iteration 153000 (6.2123 iter/s, 16.0971s/100 iter), loss = 1.16667
I0630 10:17:50.012106 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:17:50.012114 29777 sgd_solver.cpp:106] Iteration 153000, lr = 0.00521875
I0630 10:18:06.062115 29777 solver.cpp:290] Iteration 153100 (6.2307 iter/s, 16.0496s/100 iter), loss = 1.40476
I0630 10:18:06.062139 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:18:06.062147 29777 sgd_solver.cpp:106] Iteration 153100, lr = 0.00521562
I0630 10:18:22.053290 29777 solver.cpp:290] Iteration 153200 (6.25363 iter/s, 15.9907s/100 iter), loss = 1.35714
I0630 10:18:22.064286 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 10:18:22.064327 29777 sgd_solver.cpp:106] Iteration 153200, lr = 0.0052125
I0630 10:18:38.090785 29777 solver.cpp:290] Iteration 153300 (6.23983 iter/s, 16.0261s/100 iter), loss = 1.10714
I0630 10:18:38.090809 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 10:18:38.090817 29777 sgd_solver.cpp:106] Iteration 153300, lr = 0.00520937
I0630 10:18:54.189734 29777 solver.cpp:290] Iteration 153400 (6.21177 iter/s, 16.0985s/100 iter), loss = 1.14286
I0630 10:18:54.189813 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 10:18:54.189824 29777 sgd_solver.cpp:106] Iteration 153400, lr = 0.00520625
I0630 10:19:10.104131 29777 solver.cpp:290] Iteration 153500 (6.28382 iter/s, 15.9139s/100 iter), loss = 1.34524
I0630 10:19:10.104154 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 10:19:10.104161 29777 sgd_solver.cpp:106] Iteration 153500, lr = 0.00520312
I0630 10:19:26.141939 29777 solver.cpp:290] Iteration 153600 (6.23545 iter/s, 16.0373s/100 iter), loss = 1.25
I0630 10:19:26.142045 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:19:26.142055 29777 sgd_solver.cpp:106] Iteration 153600, lr = 0.0052
I0630 10:19:42.178843 29777 solver.cpp:290] Iteration 153700 (6.23583 iter/s, 16.0364s/100 iter), loss = 1.28571
I0630 10:19:42.178866 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:19:42.178872 29777 sgd_solver.cpp:106] Iteration 153700, lr = 0.00519688
I0630 10:19:58.211697 29777 solver.cpp:290] Iteration 153800 (6.23737 iter/s, 16.0324s/100 iter), loss = 1.25
I0630 10:19:58.211781 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:19:58.211788 29777 sgd_solver.cpp:106] Iteration 153800, lr = 0.00519375
I0630 10:20:14.147678 29777 solver.cpp:290] Iteration 153900 (6.27531 iter/s, 15.9355s/100 iter), loss = 0.928571
I0630 10:20:14.147702 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 10:20:14.147708 29777 sgd_solver.cpp:106] Iteration 153900, lr = 0.00519062
I0630 10:20:30.021332 29777 solver.cpp:354] Sparsity after update:
I0630 10:20:30.022819 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:20:30.022827 29777 net.cpp:1851] conv1a_param_0(0.385) 
I0630 10:20:30.022841 29777 net.cpp:1851] conv1b_param_0(0.723) 
I0630 10:20:30.022845 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:20:30.022847 29777 net.cpp:1851] res2a_branch2a_param_0(0.77) 
I0630 10:20:30.022851 29777 net.cpp:1851] res2a_branch2b_param_0(0.77) 
I0630 10:20:30.022855 29777 net.cpp:1851] res3a_branch2a_param_0(0.77) 
I0630 10:20:30.022856 29777 net.cpp:1851] res3a_branch2b_param_0(0.77) 
I0630 10:20:30.022858 29777 net.cpp:1851] res4a_branch2a_param_0(0.77) 
I0630 10:20:30.022862 29777 net.cpp:1851] res4a_branch2b_param_0(0.77) 
I0630 10:20:30.022864 29777 net.cpp:1851] res5a_branch2a_param_0(0.77) 
I0630 10:20:30.022866 29777 net.cpp:1851] res5a_branch2b_param_0(0.77) 
I0630 10:20:30.022868 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.81214e+06/2.86678e+06) 0.632
I0630 10:20:30.022958 29777 solver.cpp:471] Iteration 154000, Testing net (#0)
I0630 10:20:42.628768 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:21:19.032301 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5499
I0630 10:21:19.032407 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.787041
I0630 10:21:19.032418 29777 solver.cpp:544]     Test net output #2: loss = 1.6187 (* 1 = 1.6187 loss)
I0630 10:21:19.215479 29777 solver.cpp:290] Iteration 154000 (1.5369 iter/s, 65.066s/100 iter), loss = 1.2619
I0630 10:21:19.215502 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 10:21:19.215508 29777 sgd_solver.cpp:106] Iteration 154000, lr = 0.0051875
I0630 10:21:19.216224 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.78
I0630 10:21:19.826805 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:21:35.772130 29777 solver.cpp:290] Iteration 154100 (6.04004 iter/s, 16.5562s/100 iter), loss = 1.30952
I0630 10:21:35.772155 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 10:21:35.772163 29777 sgd_solver.cpp:106] Iteration 154100, lr = 0.00518437
I0630 10:21:52.038074 29777 solver.cpp:290] Iteration 154200 (6.14799 iter/s, 16.2655s/100 iter), loss = 1.17857
I0630 10:21:52.038166 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 10:21:52.038177 29777 sgd_solver.cpp:106] Iteration 154200, lr = 0.00518125
I0630 10:22:08.104444 29777 solver.cpp:290] Iteration 154300 (6.22439 iter/s, 16.0658s/100 iter), loss = 1.0119
I0630 10:22:08.104470 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 10:22:08.104478 29777 sgd_solver.cpp:106] Iteration 154300, lr = 0.00517812
I0630 10:22:24.150056 29777 solver.cpp:290] Iteration 154400 (6.23241 iter/s, 16.0451s/100 iter), loss = 1.25
I0630 10:22:24.150161 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 10:22:24.150171 29777 sgd_solver.cpp:106] Iteration 154400, lr = 0.005175
I0630 10:22:40.215025 29777 solver.cpp:290] Iteration 154500 (6.22493 iter/s, 16.0644s/100 iter), loss = 1.15476
I0630 10:22:40.215050 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:22:40.215056 29777 sgd_solver.cpp:106] Iteration 154500, lr = 0.00517187
I0630 10:22:56.214934 29777 solver.cpp:290] Iteration 154600 (6.25022 iter/s, 15.9994s/100 iter), loss = 1.32143
I0630 10:22:56.215049 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 10:22:56.215059 29777 sgd_solver.cpp:106] Iteration 154600, lr = 0.00516875
I0630 10:23:12.244137 29777 solver.cpp:290] Iteration 154700 (6.23883 iter/s, 16.0287s/100 iter), loss = 0.964286
I0630 10:23:12.244163 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 10:23:12.244173 29777 sgd_solver.cpp:106] Iteration 154700, lr = 0.00516562
I0630 10:23:28.307354 29777 solver.cpp:290] Iteration 154800 (6.22558 iter/s, 16.0628s/100 iter), loss = 1.04762
I0630 10:23:28.307464 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 10:23:28.307478 29777 sgd_solver.cpp:106] Iteration 154800, lr = 0.0051625
I0630 10:23:44.366080 29777 solver.cpp:290] Iteration 154900 (6.22736 iter/s, 16.0582s/100 iter), loss = 1.4881
I0630 10:23:44.366102 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 10:23:44.366108 29777 sgd_solver.cpp:106] Iteration 154900, lr = 0.00515937
I0630 10:24:00.164317 29777 solver.cpp:354] Sparsity after update:
I0630 10:24:00.184420 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:24:00.184439 29777 net.cpp:1851] conv1a_param_0(0.39) 
I0630 10:24:00.184449 29777 net.cpp:1851] conv1b_param_0(0.723) 
I0630 10:24:00.184453 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:24:00.184465 29777 net.cpp:1851] res2a_branch2a_param_0(0.78) 
I0630 10:24:00.184474 29777 net.cpp:1851] res2a_branch2b_param_0(0.78) 
I0630 10:24:00.184485 29777 net.cpp:1851] res3a_branch2a_param_0(0.78) 
I0630 10:24:00.184491 29777 net.cpp:1851] res3a_branch2b_param_0(0.78) 
I0630 10:24:00.184495 29777 net.cpp:1851] res4a_branch2a_param_0(0.78) 
I0630 10:24:00.184504 29777 net.cpp:1851] res4a_branch2b_param_0(0.78) 
I0630 10:24:00.184512 29777 net.cpp:1851] res5a_branch2a_param_0(0.78) 
I0630 10:24:00.184518 29777 net.cpp:1851] res5a_branch2b_param_0(0.78) 
I0630 10:24:00.184522 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.83566e+06/2.86678e+06) 0.64
I0630 10:24:00.343108 29777 solver.cpp:290] Iteration 155000 (6.25917 iter/s, 15.9766s/100 iter), loss = 1.28571
I0630 10:24:00.343132 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 10:24:00.343142 29777 sgd_solver.cpp:106] Iteration 155000, lr = 0.00515625
I0630 10:24:16.354801 29777 solver.cpp:290] Iteration 155100 (6.24562 iter/s, 16.0112s/100 iter), loss = 1.54762
I0630 10:24:16.354823 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 10:24:16.354830 29777 sgd_solver.cpp:106] Iteration 155100, lr = 0.00515312
I0630 10:24:32.517768 29777 solver.cpp:290] Iteration 155200 (6.18716 iter/s, 16.1625s/100 iter), loss = 1.16667
I0630 10:24:32.517825 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 10:24:32.517835 29777 sgd_solver.cpp:106] Iteration 155200, lr = 0.00515
I0630 10:24:48.619030 29777 solver.cpp:290] Iteration 155300 (6.21089 iter/s, 16.1008s/100 iter), loss = 1.33333
I0630 10:24:48.619053 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:24:48.619060 29777 sgd_solver.cpp:106] Iteration 155300, lr = 0.00514688
I0630 10:25:04.749992 29777 solver.cpp:290] Iteration 155400 (6.19944 iter/s, 16.1305s/100 iter), loss = 0.928571
I0630 10:25:04.750068 29777 solver.cpp:309]     Train net output #0: loss = 0.642857 (* 1 = 0.642857 loss)
I0630 10:25:04.750078 29777 sgd_solver.cpp:106] Iteration 155400, lr = 0.00514375
I0630 10:25:20.808483 29777 solver.cpp:290] Iteration 155500 (6.22744 iter/s, 16.058s/100 iter), loss = 1.14286
I0630 10:25:20.808535 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 10:25:20.808545 29777 sgd_solver.cpp:106] Iteration 155500, lr = 0.00514062
I0630 10:25:36.899405 29777 solver.cpp:290] Iteration 155600 (6.21487 iter/s, 16.0904s/100 iter), loss = 1.25
I0630 10:25:36.899488 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 10:25:36.899497 29777 sgd_solver.cpp:106] Iteration 155600, lr = 0.0051375
I0630 10:25:52.920020 29777 solver.cpp:290] Iteration 155700 (6.24216 iter/s, 16.0201s/100 iter), loss = 1.22619
I0630 10:25:52.920044 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:25:52.920051 29777 sgd_solver.cpp:106] Iteration 155700, lr = 0.00513437
I0630 10:26:08.922111 29777 solver.cpp:290] Iteration 155800 (6.24936 iter/s, 16.0016s/100 iter), loss = 1.28571
I0630 10:26:08.922183 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 10:26:08.922191 29777 sgd_solver.cpp:106] Iteration 155800, lr = 0.00513125
I0630 10:26:24.946848 29777 solver.cpp:290] Iteration 155900 (6.24055 iter/s, 16.0242s/100 iter), loss = 1.11905
I0630 10:26:24.946873 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 10:26:24.946882 29777 sgd_solver.cpp:106] Iteration 155900, lr = 0.00512812
I0630 10:26:40.794594 29777 solver.cpp:354] Sparsity after update:
I0630 10:26:40.795979 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:26:40.795994 29777 net.cpp:1851] conv1a_param_0(0.39) 
I0630 10:26:40.796001 29777 net.cpp:1851] conv1b_param_0(0.723) 
I0630 10:26:40.796005 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:26:40.796006 29777 net.cpp:1851] res2a_branch2a_param_0(0.78) 
I0630 10:26:40.796008 29777 net.cpp:1851] res2a_branch2b_param_0(0.78) 
I0630 10:26:40.796010 29777 net.cpp:1851] res3a_branch2a_param_0(0.78) 
I0630 10:26:40.796012 29777 net.cpp:1851] res3a_branch2b_param_0(0.78) 
I0630 10:26:40.796015 29777 net.cpp:1851] res4a_branch2a_param_0(0.78) 
I0630 10:26:40.796016 29777 net.cpp:1851] res4a_branch2b_param_0(0.78) 
I0630 10:26:40.796018 29777 net.cpp:1851] res5a_branch2a_param_0(0.78) 
I0630 10:26:40.796020 29777 net.cpp:1851] res5a_branch2b_param_0(0.78) 
I0630 10:26:40.796022 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.83566e+06/2.86678e+06) 0.64
I0630 10:26:40.796134 29777 solver.cpp:471] Iteration 156000, Testing net (#0)
I0630 10:26:53.922366 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:27:30.209213 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54306
I0630 10:27:30.209314 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.783901
I0630 10:27:30.209324 29777 solver.cpp:544]     Test net output #2: loss = 1.638 (* 1 = 1.638 loss)
I0630 10:27:30.389008 29777 solver.cpp:290] Iteration 156000 (1.52811 iter/s, 65.4404s/100 iter), loss = 1.03571
I0630 10:27:30.389031 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 10:27:30.389039 29777 sgd_solver.cpp:106] Iteration 156000, lr = 0.005125
I0630 10:27:30.389770 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.79
I0630 10:27:31.015298 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:27:46.905560 29777 solver.cpp:290] Iteration 156100 (6.05471 iter/s, 16.5161s/100 iter), loss = 1.36905
I0630 10:27:46.905589 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:27:46.905598 29777 sgd_solver.cpp:106] Iteration 156100, lr = 0.00512187
I0630 10:28:02.912519 29777 solver.cpp:290] Iteration 156200 (6.24747 iter/s, 16.0065s/100 iter), loss = 1.10714
I0630 10:28:02.912626 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:28:02.912652 29777 sgd_solver.cpp:106] Iteration 156200, lr = 0.00511875
I0630 10:28:18.975527 29777 solver.cpp:290] Iteration 156300 (6.22572 iter/s, 16.0624s/100 iter), loss = 1.55952
I0630 10:28:18.975746 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 10:28:18.975841 29777 sgd_solver.cpp:106] Iteration 156300, lr = 0.00511562
I0630 10:28:34.936666 29777 solver.cpp:290] Iteration 156400 (6.26547 iter/s, 15.9605s/100 iter), loss = 1.60714
I0630 10:28:34.936753 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:28:34.936761 29777 sgd_solver.cpp:106] Iteration 156400, lr = 0.0051125
I0630 10:28:50.927079 29777 solver.cpp:290] Iteration 156500 (6.25395 iter/s, 15.9899s/100 iter), loss = 1.71429
I0630 10:28:50.927103 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:28:50.927109 29777 sgd_solver.cpp:106] Iteration 156500, lr = 0.00510937
I0630 10:29:07.020639 29777 solver.cpp:290] Iteration 156600 (6.21385 iter/s, 16.0931s/100 iter), loss = 1.5
I0630 10:29:07.020743 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:29:07.020752 29777 sgd_solver.cpp:106] Iteration 156600, lr = 0.00510625
I0630 10:29:23.017369 29777 solver.cpp:290] Iteration 156700 (6.25149 iter/s, 15.9962s/100 iter), loss = 1.61905
I0630 10:29:23.017396 29777 solver.cpp:309]     Train net output #0: loss = 1.69048 (* 1 = 1.69048 loss)
I0630 10:29:23.017418 29777 sgd_solver.cpp:106] Iteration 156700, lr = 0.00510312
I0630 10:29:39.074558 29777 solver.cpp:290] Iteration 156800 (6.22792 iter/s, 16.0567s/100 iter), loss = 1.33333
I0630 10:29:39.074659 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:29:39.074669 29777 sgd_solver.cpp:106] Iteration 156800, lr = 0.0051
I0630 10:29:55.216855 29777 solver.cpp:290] Iteration 156900 (6.19511 iter/s, 16.1418s/100 iter), loss = 1.45238
I0630 10:29:55.216878 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 10:29:55.216884 29777 sgd_solver.cpp:106] Iteration 156900, lr = 0.00509688
I0630 10:30:11.120019 29777 solver.cpp:354] Sparsity after update:
I0630 10:30:11.140383 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:30:11.140398 29777 net.cpp:1851] conv1a_param_0(0.395) 
I0630 10:30:11.140408 29777 net.cpp:1851] conv1b_param_0(0.724) 
I0630 10:30:11.140413 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:30:11.140422 29777 net.cpp:1851] res2a_branch2a_param_0(0.79) 
I0630 10:30:11.140427 29777 net.cpp:1851] res2a_branch2b_param_0(0.79) 
I0630 10:30:11.140430 29777 net.cpp:1851] res3a_branch2a_param_0(0.79) 
I0630 10:30:11.140437 29777 net.cpp:1851] res3a_branch2b_param_0(0.79) 
I0630 10:30:11.140442 29777 net.cpp:1851] res4a_branch2a_param_0(0.79) 
I0630 10:30:11.140447 29777 net.cpp:1851] res4a_branch2b_param_0(0.79) 
I0630 10:30:11.140452 29777 net.cpp:1851] res5a_branch2a_param_0(0.79) 
I0630 10:30:11.140456 29777 net.cpp:1851] res5a_branch2b_param_0(0.79) 
I0630 10:30:11.140460 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.85917e+06/2.86678e+06) 0.649
I0630 10:30:11.298322 29777 solver.cpp:290] Iteration 157000 (6.21852 iter/s, 16.081s/100 iter), loss = 1.27381
I0630 10:30:11.298346 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 10:30:11.298354 29777 sgd_solver.cpp:106] Iteration 157000, lr = 0.00509375
I0630 10:30:27.313750 29777 solver.cpp:290] Iteration 157100 (6.24416 iter/s, 16.015s/100 iter), loss = 0.952381
I0630 10:30:27.313776 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:30:27.313786 29777 sgd_solver.cpp:106] Iteration 157100, lr = 0.00509063
I0630 10:30:43.304684 29777 solver.cpp:290] Iteration 157200 (6.25372 iter/s, 15.9905s/100 iter), loss = 1.5119
I0630 10:30:43.304762 29777 solver.cpp:309]     Train net output #0: loss = 2 (* 1 = 2 loss)
I0630 10:30:43.304770 29777 sgd_solver.cpp:106] Iteration 157200, lr = 0.0050875
I0630 10:30:59.428436 29777 solver.cpp:290] Iteration 157300 (6.20223 iter/s, 16.1232s/100 iter), loss = 1.28571
I0630 10:30:59.428462 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:30:59.428468 29777 sgd_solver.cpp:106] Iteration 157300, lr = 0.00508437
I0630 10:31:15.418639 29777 solver.cpp:290] Iteration 157400 (6.25401 iter/s, 15.9897s/100 iter), loss = 1.30952
I0630 10:31:15.418742 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 10:31:15.418753 29777 sgd_solver.cpp:106] Iteration 157400, lr = 0.00508125
I0630 10:31:31.443712 29777 solver.cpp:290] Iteration 157500 (6.24043 iter/s, 16.0245s/100 iter), loss = 1.30952
I0630 10:31:31.443732 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:31:31.443739 29777 sgd_solver.cpp:106] Iteration 157500, lr = 0.00507812
I0630 10:31:47.539150 29777 solver.cpp:290] Iteration 157600 (6.21312 iter/s, 16.095s/100 iter), loss = 1.39286
I0630 10:31:47.539257 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 10:31:47.539266 29777 sgd_solver.cpp:106] Iteration 157600, lr = 0.005075
I0630 10:32:03.511286 29777 solver.cpp:290] Iteration 157700 (6.26111 iter/s, 15.9716s/100 iter), loss = 1.35714
I0630 10:32:03.511308 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 10:32:03.511315 29777 sgd_solver.cpp:106] Iteration 157700, lr = 0.00507187
I0630 10:32:19.440987 29777 solver.cpp:290] Iteration 157800 (6.27776 iter/s, 15.9292s/100 iter), loss = 1.57143
I0630 10:32:19.441057 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 10:32:19.441066 29777 sgd_solver.cpp:106] Iteration 157800, lr = 0.00506875
I0630 10:32:35.501801 29777 solver.cpp:290] Iteration 157900 (6.22653 iter/s, 16.0603s/100 iter), loss = 1.30952
I0630 10:32:35.501827 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 10:32:35.501834 29777 sgd_solver.cpp:106] Iteration 157900, lr = 0.00506562
I0630 10:32:51.520088 29777 solver.cpp:354] Sparsity after update:
I0630 10:32:51.522500 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:32:51.522514 29777 net.cpp:1851] conv1a_param_0(0.395) 
I0630 10:32:51.522537 29777 net.cpp:1851] conv1b_param_0(0.724) 
I0630 10:32:51.522548 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:32:51.522558 29777 net.cpp:1851] res2a_branch2a_param_0(0.79) 
I0630 10:32:51.522568 29777 net.cpp:1851] res2a_branch2b_param_0(0.79) 
I0630 10:32:51.522578 29777 net.cpp:1851] res3a_branch2a_param_0(0.79) 
I0630 10:32:51.522588 29777 net.cpp:1851] res3a_branch2b_param_0(0.79) 
I0630 10:32:51.522596 29777 net.cpp:1851] res4a_branch2a_param_0(0.79) 
I0630 10:32:51.522605 29777 net.cpp:1851] res4a_branch2b_param_0(0.79) 
I0630 10:32:51.522614 29777 net.cpp:1851] res5a_branch2a_param_0(0.79) 
I0630 10:32:51.522622 29777 net.cpp:1851] res5a_branch2b_param_0(0.79) 
I0630 10:32:51.522631 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.85917e+06/2.86678e+06) 0.649
I0630 10:32:51.522847 29777 solver.cpp:471] Iteration 158000, Testing net (#0)
I0630 10:33:09.507359 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:33:58.029201 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54332
I0630 10:33:58.029325 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.783981
I0630 10:33:58.029345 29777 solver.cpp:544]     Test net output #2: loss = 1.64274 (* 1 = 1.64274 loss)
I0630 10:33:58.244833 29777 solver.cpp:290] Iteration 158000 (1.20859 iter/s, 82.7408s/100 iter), loss = 1.70238
I0630 10:33:58.244860 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 10:33:58.244869 29777 sgd_solver.cpp:106] Iteration 158000, lr = 0.0050625
I0630 10:33:58.245867 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.8
I0630 10:33:58.892460 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:34:15.097195 29777 solver.cpp:290] Iteration 158100 (5.93406 iter/s, 16.8519s/100 iter), loss = 1.32143
I0630 10:34:15.097219 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 10:34:15.097228 29777 sgd_solver.cpp:106] Iteration 158100, lr = 0.00505937
I0630 10:34:31.317203 29777 solver.cpp:290] Iteration 158200 (6.1654 iter/s, 16.2195s/100 iter), loss = 1.08333
I0630 10:34:31.317320 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 10:34:31.317330 29777 sgd_solver.cpp:106] Iteration 158200, lr = 0.00505625
I0630 10:34:47.407727 29777 solver.cpp:290] Iteration 158300 (6.21505 iter/s, 16.09s/100 iter), loss = 1.28571
I0630 10:34:47.407773 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:34:47.407788 29777 sgd_solver.cpp:106] Iteration 158300, lr = 0.00505312
I0630 10:35:03.549024 29777 solver.cpp:290] Iteration 158400 (6.19548 iter/s, 16.1408s/100 iter), loss = 1.38095
I0630 10:35:03.549123 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 10:35:03.549151 29777 sgd_solver.cpp:106] Iteration 158400, lr = 0.00505
I0630 10:35:19.730125 29777 solver.cpp:290] Iteration 158500 (6.18025 iter/s, 16.1806s/100 iter), loss = 1.72619
I0630 10:35:19.730149 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:35:19.730155 29777 sgd_solver.cpp:106] Iteration 158500, lr = 0.00504687
I0630 10:35:36.127668 29777 solver.cpp:290] Iteration 158600 (6.09865 iter/s, 16.3971s/100 iter), loss = 1.15476
I0630 10:35:36.127737 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 10:35:36.127743 29777 sgd_solver.cpp:106] Iteration 158600, lr = 0.00504375
I0630 10:35:52.185997 29777 solver.cpp:290] Iteration 158700 (6.22749 iter/s, 16.0578s/100 iter), loss = 1.03571
I0630 10:35:52.186019 29777 solver.cpp:309]     Train net output #0: loss = 0.738095 (* 1 = 0.738095 loss)
I0630 10:35:52.186027 29777 sgd_solver.cpp:106] Iteration 158700, lr = 0.00504063
I0630 10:36:08.375013 29777 solver.cpp:290] Iteration 158800 (6.17721 iter/s, 16.1886s/100 iter), loss = 1.42857
I0630 10:36:08.375083 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:36:08.375090 29777 sgd_solver.cpp:106] Iteration 158800, lr = 0.0050375
I0630 10:36:24.687595 29777 solver.cpp:290] Iteration 158900 (6.13043 iter/s, 16.3121s/100 iter), loss = 1.40476
I0630 10:36:24.687621 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 10:36:24.687630 29777 sgd_solver.cpp:106] Iteration 158900, lr = 0.00503438
I0630 10:36:40.746436 29777 solver.cpp:354] Sparsity after update:
I0630 10:36:40.770929 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:36:40.770956 29777 net.cpp:1851] conv1a_param_0(0.4) 
I0630 10:36:40.770977 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:36:40.770992 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:36:40.771001 29777 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0630 10:36:40.771009 29777 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0630 10:36:40.771018 29777 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0630 10:36:40.771026 29777 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0630 10:36:40.771034 29777 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0630 10:36:40.771041 29777 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0630 10:36:40.771050 29777 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0630 10:36:40.771057 29777 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0630 10:36:40.771064 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88269e+06/2.86678e+06) 0.657
I0630 10:36:40.938520 29777 solver.cpp:290] Iteration 159000 (6.15367 iter/s, 16.2505s/100 iter), loss = 1.2381
I0630 10:36:40.938544 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 10:36:40.938562 29777 sgd_solver.cpp:106] Iteration 159000, lr = 0.00503125
I0630 10:36:57.121991 29777 solver.cpp:290] Iteration 159100 (6.17932 iter/s, 16.183s/100 iter), loss = 1.15476
I0630 10:36:57.122016 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 10:36:57.122023 29777 sgd_solver.cpp:106] Iteration 159100, lr = 0.00502812
I0630 10:37:13.141692 29777 solver.cpp:290] Iteration 159200 (6.24249 iter/s, 16.0192s/100 iter), loss = 1.5119
I0630 10:37:13.141798 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 10:37:13.141808 29777 sgd_solver.cpp:106] Iteration 159200, lr = 0.005025
I0630 10:37:29.114895 29777 solver.cpp:290] Iteration 159300 (6.2607 iter/s, 15.9727s/100 iter), loss = 1.16667
I0630 10:37:29.114917 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 10:37:29.114924 29777 sgd_solver.cpp:106] Iteration 159300, lr = 0.00502187
I0630 10:37:45.432468 29777 solver.cpp:290] Iteration 159400 (6.12854 iter/s, 16.3171s/100 iter), loss = 1.16667
I0630 10:37:45.432585 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 10:37:45.432595 29777 sgd_solver.cpp:106] Iteration 159400, lr = 0.00501875
I0630 10:38:01.580978 29777 solver.cpp:290] Iteration 159500 (6.19273 iter/s, 16.148s/100 iter), loss = 1.2619
I0630 10:38:01.581019 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:38:01.581028 29777 sgd_solver.cpp:106] Iteration 159500, lr = 0.00501562
I0630 10:38:17.790410 29777 solver.cpp:290] Iteration 159600 (6.16943 iter/s, 16.209s/100 iter), loss = 1.30952
I0630 10:38:17.790484 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 10:38:17.790493 29777 sgd_solver.cpp:106] Iteration 159600, lr = 0.0050125
I0630 10:38:34.048342 29777 solver.cpp:290] Iteration 159700 (6.15104 iter/s, 16.2574s/100 iter), loss = 1.19048
I0630 10:38:34.048364 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 10:38:34.048372 29777 sgd_solver.cpp:106] Iteration 159700, lr = 0.00500937
I0630 10:38:50.155164 29777 solver.cpp:290] Iteration 159800 (6.20873 iter/s, 16.1064s/100 iter), loss = 1.29762
I0630 10:38:50.155237 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 10:38:50.155248 29777 sgd_solver.cpp:106] Iteration 159800, lr = 0.00500625
I0630 10:39:06.267529 29777 solver.cpp:290] Iteration 159900 (6.20661 iter/s, 16.1119s/100 iter), loss = 1.45238
I0630 10:39:06.267552 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:39:06.267560 29777 sgd_solver.cpp:106] Iteration 159900, lr = 0.00500312
I0630 10:39:22.274595 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_160000.caffemodel
I0630 10:39:22.307953 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_160000.solverstate
I0630 10:39:22.316609 29777 solver.cpp:354] Sparsity after update:
I0630 10:39:22.317569 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:39:22.317577 29777 net.cpp:1851] conv1a_param_0(0.4) 
I0630 10:39:22.317589 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:39:22.317595 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:39:22.317598 29777 net.cpp:1851] res2a_branch2a_param_0(0.8) 
I0630 10:39:22.317602 29777 net.cpp:1851] res2a_branch2b_param_0(0.8) 
I0630 10:39:22.317605 29777 net.cpp:1851] res3a_branch2a_param_0(0.8) 
I0630 10:39:22.317610 29777 net.cpp:1851] res3a_branch2b_param_0(0.8) 
I0630 10:39:22.317615 29777 net.cpp:1851] res4a_branch2a_param_0(0.8) 
I0630 10:39:22.317620 29777 net.cpp:1851] res4a_branch2b_param_0(0.8) 
I0630 10:39:22.317622 29777 net.cpp:1851] res5a_branch2a_param_0(0.8) 
I0630 10:39:22.317627 29777 net.cpp:1851] res5a_branch2b_param_0(0.8) 
I0630 10:39:22.317631 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.88269e+06/2.86678e+06) 0.657
I0630 10:39:22.317730 29777 solver.cpp:471] Iteration 160000, Testing net (#0)
I0630 10:39:36.737339 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:40:12.551654 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.536839
I0630 10:40:12.551767 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.777721
I0630 10:40:12.551776 29777 solver.cpp:544]     Test net output #2: loss = 1.65744 (* 1 = 1.65744 loss)
I0630 10:40:12.731901 29777 solver.cpp:290] Iteration 160000 (1.50461 iter/s, 66.4626s/100 iter), loss = 1.5
I0630 10:40:12.731927 29777 solver.cpp:309]     Train net output #0: loss = 2.14286 (* 1 = 2.14286 loss)
I0630 10:40:12.731936 29777 sgd_solver.cpp:106] Iteration 160000, lr = 0.005
I0630 10:40:12.732722 29777 solver.cpp:376] Finding and applying thresholds. Target sparsity = 0.81
I0630 10:40:13.376741 29777 net.cpp:1824] All zero weights of convolution layers are frozen
I0630 10:40:29.373914 29777 solver.cpp:290] Iteration 160100 (6.00906 iter/s, 16.6415s/100 iter), loss = 1.45238
I0630 10:40:29.373937 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:40:29.373944 29777 sgd_solver.cpp:106] Iteration 160100, lr = 0.00499687
I0630 10:40:45.333282 29777 solver.cpp:290] Iteration 160200 (6.26609 iter/s, 15.9589s/100 iter), loss = 1.03571
I0630 10:40:45.333413 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 10:40:45.333423 29777 sgd_solver.cpp:106] Iteration 160200, lr = 0.00499375
I0630 10:41:01.380261 29777 solver.cpp:290] Iteration 160300 (6.23192 iter/s, 16.0464s/100 iter), loss = 1.14286
I0630 10:41:01.380285 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:41:01.380291 29777 sgd_solver.cpp:106] Iteration 160300, lr = 0.00499062
I0630 10:41:17.363517 29777 solver.cpp:290] Iteration 160400 (6.25673 iter/s, 15.9828s/100 iter), loss = 1.88095
I0630 10:41:17.363602 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 10:41:17.363610 29777 sgd_solver.cpp:106] Iteration 160400, lr = 0.0049875
I0630 10:41:33.357611 29777 solver.cpp:290] Iteration 160500 (6.25251 iter/s, 15.9936s/100 iter), loss = 1.7381
I0630 10:41:33.357637 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 10:41:33.357645 29777 sgd_solver.cpp:106] Iteration 160500, lr = 0.00498438
I0630 10:41:49.285326 29777 solver.cpp:290] Iteration 160600 (6.27855 iter/s, 15.9273s/100 iter), loss = 1.46429
I0630 10:41:49.285404 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 10:41:49.285415 29777 sgd_solver.cpp:106] Iteration 160600, lr = 0.00498125
I0630 10:42:05.315732 29777 solver.cpp:290] Iteration 160700 (6.23835 iter/s, 16.0299s/100 iter), loss = 1.47619
I0630 10:42:05.315755 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 10:42:05.315762 29777 sgd_solver.cpp:106] Iteration 160700, lr = 0.00497812
I0630 10:42:21.258358 29777 solver.cpp:290] Iteration 160800 (6.27267 iter/s, 15.9422s/100 iter), loss = 0.892857
I0630 10:42:21.258468 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 10:42:21.258483 29777 sgd_solver.cpp:106] Iteration 160800, lr = 0.004975
I0630 10:42:37.309499 29777 solver.cpp:290] Iteration 160900 (6.2303 iter/s, 16.0506s/100 iter), loss = 1.46429
I0630 10:42:37.309521 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:42:37.309528 29777 sgd_solver.cpp:106] Iteration 160900, lr = 0.00497187
I0630 10:42:53.104693 29777 solver.cpp:354] Sparsity after update:
I0630 10:42:53.125166 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:42:53.125211 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:42:53.125228 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:42:53.125237 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:42:53.125247 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:42:53.125252 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:42:53.125255 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:42:53.125258 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:42:53.125262 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:42:53.125267 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:42:53.125270 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:42:53.125274 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:42:53.125279 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:42:53.282583 29777 solver.cpp:290] Iteration 161000 (6.26071 iter/s, 15.9726s/100 iter), loss = 1.41667
I0630 10:42:53.282609 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 10:42:53.282618 29777 sgd_solver.cpp:106] Iteration 161000, lr = 0.00496875
I0630 10:43:09.302855 29777 solver.cpp:290] Iteration 161100 (6.24227 iter/s, 16.0198s/100 iter), loss = 1.42857
I0630 10:43:09.302881 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:43:09.302891 29777 sgd_solver.cpp:106] Iteration 161100, lr = 0.00496562
I0630 10:43:25.300101 29777 solver.cpp:290] Iteration 161200 (6.25126 iter/s, 15.9968s/100 iter), loss = 1.32143
I0630 10:43:25.300216 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 10:43:25.300231 29777 sgd_solver.cpp:106] Iteration 161200, lr = 0.0049625
I0630 10:43:41.270568 29777 solver.cpp:290] Iteration 161300 (6.26177 iter/s, 15.9699s/100 iter), loss = 0.880952
I0630 10:43:41.270591 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 10:43:41.270597 29777 sgd_solver.cpp:106] Iteration 161300, lr = 0.00495938
I0630 10:43:57.291651 29777 solver.cpp:290] Iteration 161400 (6.24195 iter/s, 16.0206s/100 iter), loss = 1.69048
I0630 10:43:57.291741 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 10:43:57.291751 29777 sgd_solver.cpp:106] Iteration 161400, lr = 0.00495625
I0630 10:44:13.325085 29777 solver.cpp:290] Iteration 161500 (6.23717 iter/s, 16.0329s/100 iter), loss = 1.09524
I0630 10:44:13.325108 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 10:44:13.325114 29777 sgd_solver.cpp:106] Iteration 161500, lr = 0.00495313
I0630 10:44:29.503792 29777 solver.cpp:290] Iteration 161600 (6.18114 iter/s, 16.1782s/100 iter), loss = 1.02381
I0630 10:44:29.503883 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 10:44:29.503891 29777 sgd_solver.cpp:106] Iteration 161600, lr = 0.00495
I0630 10:44:45.542359 29777 solver.cpp:290] Iteration 161700 (6.23518 iter/s, 16.038s/100 iter), loss = 1.57143
I0630 10:44:45.542385 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:44:45.542394 29777 sgd_solver.cpp:106] Iteration 161700, lr = 0.00494687
I0630 10:45:01.555516 29777 solver.cpp:290] Iteration 161800 (6.24505 iter/s, 16.0127s/100 iter), loss = 1.44048
I0630 10:45:01.555609 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 10:45:01.555620 29777 sgd_solver.cpp:106] Iteration 161800, lr = 0.00494375
I0630 10:45:17.692878 29777 solver.cpp:290] Iteration 161900 (6.197 iter/s, 16.1368s/100 iter), loss = 1.4881
I0630 10:45:17.692900 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 10:45:17.692906 29777 sgd_solver.cpp:106] Iteration 161900, lr = 0.00494062
I0630 10:45:33.553373 29777 solver.cpp:354] Sparsity after update:
I0630 10:45:33.554841 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:45:33.554848 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:45:33.554855 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:45:33.554857 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:45:33.554859 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:45:33.554862 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:45:33.554863 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:45:33.554865 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:45:33.554867 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:45:33.554869 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:45:33.554872 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:45:33.554873 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:45:33.554875 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:45:33.554961 29777 solver.cpp:471] Iteration 162000, Testing net (#0)
I0630 10:45:46.781530 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:46:21.914722 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5369
I0630 10:46:21.914858 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.778701
I0630 10:46:21.914868 29777 solver.cpp:544]     Test net output #2: loss = 1.66298 (* 1 = 1.66298 loss)
I0630 10:46:22.090438 29777 solver.cpp:290] Iteration 162000 (1.5529 iter/s, 64.3958s/100 iter), loss = 1.45238
I0630 10:46:22.090461 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:46:22.090467 29777 sgd_solver.cpp:106] Iteration 162000, lr = 0.0049375
I0630 10:46:38.216171 29777 solver.cpp:290] Iteration 162100 (6.20145 iter/s, 16.1253s/100 iter), loss = 1
I0630 10:46:38.216204 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 10:46:38.216213 29777 sgd_solver.cpp:106] Iteration 162100, lr = 0.00493438
I0630 10:46:54.325886 29777 solver.cpp:290] Iteration 162200 (6.20762 iter/s, 16.1092s/100 iter), loss = 1.28571
I0630 10:46:54.325968 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 10:46:54.325979 29777 sgd_solver.cpp:106] Iteration 162200, lr = 0.00493125
I0630 10:47:10.376444 29777 solver.cpp:290] Iteration 162300 (6.23052 iter/s, 16.05s/100 iter), loss = 1.13095
I0630 10:47:10.376468 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 10:47:10.376476 29777 sgd_solver.cpp:106] Iteration 162300, lr = 0.00492813
I0630 10:47:26.612850 29777 solver.cpp:290] Iteration 162400 (6.15918 iter/s, 16.2359s/100 iter), loss = 1.10714
I0630 10:47:26.612944 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 10:47:26.612957 29777 sgd_solver.cpp:106] Iteration 162400, lr = 0.004925
I0630 10:47:42.622613 29777 solver.cpp:290] Iteration 162500 (6.2464 iter/s, 16.0092s/100 iter), loss = 1.09524
I0630 10:47:42.622674 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 10:47:42.622694 29777 sgd_solver.cpp:106] Iteration 162500, lr = 0.00492187
I0630 10:47:58.731909 29777 solver.cpp:290] Iteration 162600 (6.20779 iter/s, 16.1088s/100 iter), loss = 1.25
I0630 10:47:58.732015 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:47:58.732023 29777 sgd_solver.cpp:106] Iteration 162600, lr = 0.00491875
I0630 10:48:14.843065 29777 solver.cpp:290] Iteration 162700 (6.20709 iter/s, 16.1106s/100 iter), loss = 1.29762
I0630 10:48:14.843089 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 10:48:14.843098 29777 sgd_solver.cpp:106] Iteration 162700, lr = 0.00491562
I0630 10:48:30.831351 29777 solver.cpp:290] Iteration 162800 (6.25476 iter/s, 15.9878s/100 iter), loss = 1.61905
I0630 10:48:30.831388 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:48:30.831395 29777 sgd_solver.cpp:106] Iteration 162800, lr = 0.0049125
I0630 10:48:46.932401 29777 solver.cpp:290] Iteration 162900 (6.21096 iter/s, 16.1006s/100 iter), loss = 1.39286
I0630 10:48:46.932428 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:48:46.932437 29777 sgd_solver.cpp:106] Iteration 162900, lr = 0.00490937
I0630 10:49:02.734346 29777 solver.cpp:354] Sparsity after update:
I0630 10:49:02.754874 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:49:02.754889 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:49:02.754900 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:49:02.754904 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:49:02.754909 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:49:02.754912 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:49:02.754915 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:49:02.754920 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:49:02.754925 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:49:02.754928 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:49:02.754931 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:49:02.754935 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:49:02.754937 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:49:02.914165 29777 solver.cpp:290] Iteration 163000 (6.25731 iter/s, 15.9813s/100 iter), loss = 0.940476
I0630 10:49:02.914189 29777 solver.cpp:309]     Train net output #0: loss = 0.809524 (* 1 = 0.809524 loss)
I0630 10:49:02.914198 29777 sgd_solver.cpp:106] Iteration 163000, lr = 0.00490625
I0630 10:49:18.902956 29777 solver.cpp:290] Iteration 163100 (6.25456 iter/s, 15.9883s/100 iter), loss = 1.72619
I0630 10:49:18.902981 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 10:49:18.902990 29777 sgd_solver.cpp:106] Iteration 163100, lr = 0.00490313
I0630 10:49:34.922690 29777 solver.cpp:290] Iteration 163200 (6.24248 iter/s, 16.0193s/100 iter), loss = 1.03571
I0630 10:49:34.922797 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 10:49:34.922808 29777 sgd_solver.cpp:106] Iteration 163200, lr = 0.0049
I0630 10:49:50.859683 29777 solver.cpp:290] Iteration 163300 (6.27492 iter/s, 15.9365s/100 iter), loss = 1.2619
I0630 10:49:50.859709 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:49:50.859721 29777 sgd_solver.cpp:106] Iteration 163300, lr = 0.00489688
I0630 10:50:06.876621 29777 solver.cpp:290] Iteration 163400 (6.24357 iter/s, 16.0165s/100 iter), loss = 1.38095
I0630 10:50:06.876691 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 10:50:06.876699 29777 sgd_solver.cpp:106] Iteration 163400, lr = 0.00489375
I0630 10:50:23.344045 29777 solver.cpp:290] Iteration 163500 (6.07279 iter/s, 16.4669s/100 iter), loss = 1.19048
I0630 10:50:23.344072 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 10:50:23.344081 29777 sgd_solver.cpp:106] Iteration 163500, lr = 0.00489062
I0630 10:50:39.696533 29777 solver.cpp:290] Iteration 163600 (6.11545 iter/s, 16.352s/100 iter), loss = 1.63095
I0630 10:50:39.696638 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 10:50:39.696648 29777 sgd_solver.cpp:106] Iteration 163600, lr = 0.0048875
I0630 10:50:55.916693 29777 solver.cpp:290] Iteration 163700 (6.16537 iter/s, 16.2196s/100 iter), loss = 1.29762
I0630 10:50:55.916723 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 10:50:55.916733 29777 sgd_solver.cpp:106] Iteration 163700, lr = 0.00488437
I0630 10:51:12.017515 29777 solver.cpp:290] Iteration 163800 (6.21104 iter/s, 16.1004s/100 iter), loss = 1.25
I0630 10:51:12.017622 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 10:51:12.017632 29777 sgd_solver.cpp:106] Iteration 163800, lr = 0.00488125
I0630 10:51:28.127074 29777 solver.cpp:290] Iteration 163900 (6.20771 iter/s, 16.109s/100 iter), loss = 1.35714
I0630 10:51:28.127100 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 10:51:28.127107 29777 sgd_solver.cpp:106] Iteration 163900, lr = 0.00487813
I0630 10:51:44.174103 29777 solver.cpp:354] Sparsity after update:
I0630 10:51:44.175534 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:51:44.175540 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:51:44.175549 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:51:44.175550 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:51:44.175554 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:51:44.175556 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:51:44.175559 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:51:44.175561 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:51:44.175564 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:51:44.175565 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:51:44.175567 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:51:44.175570 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:51:44.175571 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:51:44.175657 29777 solver.cpp:471] Iteration 164000, Testing net (#0)
I0630 10:52:03.818078 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:52:51.837007 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.53778
I0630 10:52:51.837134 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.780341
I0630 10:52:51.837144 29777 solver.cpp:544]     Test net output #2: loss = 1.66192 (* 1 = 1.66192 loss)
I0630 10:52:52.018946 29777 solver.cpp:290] Iteration 164000 (1.19204 iter/s, 83.8896s/100 iter), loss = 1.14286
I0630 10:52:52.018972 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:52:52.018982 29777 sgd_solver.cpp:106] Iteration 164000, lr = 0.004875
I0630 10:53:08.329767 29777 solver.cpp:290] Iteration 164100 (6.13108 iter/s, 16.3103s/100 iter), loss = 1.27381
I0630 10:53:08.329790 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 10:53:08.329797 29777 sgd_solver.cpp:106] Iteration 164100, lr = 0.00487188
I0630 10:53:24.475828 29777 solver.cpp:290] Iteration 164200 (6.19364 iter/s, 16.1456s/100 iter), loss = 0.988095
I0630 10:53:24.475936 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 10:53:24.475946 29777 sgd_solver.cpp:106] Iteration 164200, lr = 0.00486875
I0630 10:53:40.551874 29777 solver.cpp:290] Iteration 164300 (6.22065 iter/s, 16.0755s/100 iter), loss = 1.16667
I0630 10:53:40.551899 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 10:53:40.551908 29777 sgd_solver.cpp:106] Iteration 164300, lr = 0.00486562
I0630 10:53:56.679663 29777 solver.cpp:290] Iteration 164400 (6.20066 iter/s, 16.1273s/100 iter), loss = 1.47619
I0630 10:53:56.679752 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 10:53:56.679762 29777 sgd_solver.cpp:106] Iteration 164400, lr = 0.0048625
I0630 10:54:12.867516 29777 solver.cpp:290] Iteration 164500 (6.17767 iter/s, 16.1873s/100 iter), loss = 1.27381
I0630 10:54:12.867544 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 10:54:12.867553 29777 sgd_solver.cpp:106] Iteration 164500, lr = 0.00485937
I0630 10:54:29.077955 29777 solver.cpp:290] Iteration 164600 (6.16904 iter/s, 16.21s/100 iter), loss = 1.34524
I0630 10:54:29.078066 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 10:54:29.078083 29777 sgd_solver.cpp:106] Iteration 164600, lr = 0.00485625
I0630 10:54:45.287645 29777 solver.cpp:290] Iteration 164700 (6.16936 iter/s, 16.2091s/100 iter), loss = 1.2381
I0630 10:54:45.287670 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 10:54:45.287678 29777 sgd_solver.cpp:106] Iteration 164700, lr = 0.00485313
I0630 10:55:01.264015 29777 solver.cpp:290] Iteration 164800 (6.25942 iter/s, 15.9759s/100 iter), loss = 1.40476
I0630 10:55:01.264063 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:55:01.264070 29777 sgd_solver.cpp:106] Iteration 164800, lr = 0.00485
I0630 10:55:17.312141 29777 solver.cpp:290] Iteration 164900 (6.23145 iter/s, 16.0476s/100 iter), loss = 1.16667
I0630 10:55:17.312168 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:55:17.312181 29777 sgd_solver.cpp:106] Iteration 164900, lr = 0.00484688
I0630 10:55:33.252025 29777 solver.cpp:354] Sparsity after update:
I0630 10:55:33.272685 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:55:33.272701 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:55:33.272711 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:55:33.272716 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:55:33.272718 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:55:33.272722 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:55:33.272724 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:55:33.272728 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:55:33.272732 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:55:33.272734 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:55:33.272743 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:55:33.272749 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:55:33.272755 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:55:33.429479 29777 solver.cpp:290] Iteration 165000 (6.20468 iter/s, 16.1169s/100 iter), loss = 1.54762
I0630 10:55:33.429502 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 10:55:33.429508 29777 sgd_solver.cpp:106] Iteration 165000, lr = 0.00484375
I0630 10:55:49.515846 29777 solver.cpp:290] Iteration 165100 (6.21662 iter/s, 16.0859s/100 iter), loss = 1.72619
I0630 10:55:49.515869 29777 solver.cpp:309]     Train net output #0: loss = 1.97619 (* 1 = 1.97619 loss)
I0630 10:55:49.515878 29777 sgd_solver.cpp:106] Iteration 165100, lr = 0.00484062
I0630 10:56:05.589046 29777 solver.cpp:290] Iteration 165200 (6.22172 iter/s, 16.0727s/100 iter), loss = 1.88095
I0630 10:56:05.589162 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 10:56:05.589172 29777 sgd_solver.cpp:106] Iteration 165200, lr = 0.0048375
I0630 10:56:21.643632 29777 solver.cpp:290] Iteration 165300 (6.22896 iter/s, 16.054s/100 iter), loss = 1.13095
I0630 10:56:21.643657 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 10:56:21.643667 29777 sgd_solver.cpp:106] Iteration 165300, lr = 0.00483437
I0630 10:56:37.657533 29777 solver.cpp:290] Iteration 165400 (6.24475 iter/s, 16.0134s/100 iter), loss = 1.45238
I0630 10:56:37.657606 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 10:56:37.657614 29777 sgd_solver.cpp:106] Iteration 165400, lr = 0.00483125
I0630 10:56:53.574590 29777 solver.cpp:290] Iteration 165500 (6.28277 iter/s, 15.9165s/100 iter), loss = 1.2619
I0630 10:56:53.574615 29777 solver.cpp:309]     Train net output #0: loss = 1.59524 (* 1 = 1.59524 loss)
I0630 10:56:53.574622 29777 sgd_solver.cpp:106] Iteration 165500, lr = 0.00482813
I0630 10:57:09.522552 29777 solver.cpp:290] Iteration 165600 (6.27058 iter/s, 15.9475s/100 iter), loss = 1.27381
I0630 10:57:09.522634 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 10:57:09.522641 29777 sgd_solver.cpp:106] Iteration 165600, lr = 0.004825
I0630 10:57:25.583644 29777 solver.cpp:290] Iteration 165700 (6.22643 iter/s, 16.0606s/100 iter), loss = 1.25
I0630 10:57:25.583667 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 10:57:25.583674 29777 sgd_solver.cpp:106] Iteration 165700, lr = 0.00482188
I0630 10:57:41.569368 29777 solver.cpp:290] Iteration 165800 (6.25576 iter/s, 15.9853s/100 iter), loss = 1.54762
I0630 10:57:41.569461 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 10:57:41.569471 29777 sgd_solver.cpp:106] Iteration 165800, lr = 0.00481875
I0630 10:57:57.566126 29777 solver.cpp:290] Iteration 165900 (6.25147 iter/s, 15.9962s/100 iter), loss = 1.2619
I0630 10:57:57.566153 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 10:57:57.566161 29777 sgd_solver.cpp:106] Iteration 165900, lr = 0.00481563
I0630 10:58:13.379883 29777 solver.cpp:354] Sparsity after update:
I0630 10:58:13.381319 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 10:58:13.381326 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 10:58:13.381335 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 10:58:13.381336 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 10:58:13.381338 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 10:58:13.381340 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 10:58:13.381342 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 10:58:13.381345 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 10:58:13.381346 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 10:58:13.381348 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 10:58:13.381350 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 10:58:13.381351 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 10:58:13.381353 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 10:58:13.381440 29777 solver.cpp:471] Iteration 166000, Testing net (#0)
I0630 10:58:27.196679 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 10:59:02.996574 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54266
I0630 10:59:02.996695 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.781461
I0630 10:59:02.996706 29777 solver.cpp:544]     Test net output #2: loss = 1.63798 (* 1 = 1.63798 loss)
I0630 10:59:03.167307 29777 solver.cpp:290] Iteration 166000 (1.5244 iter/s, 65.5994s/100 iter), loss = 1.2381
I0630 10:59:03.167335 29777 solver.cpp:309]     Train net output #0: loss = 0.761905 (* 1 = 0.761905 loss)
I0630 10:59:03.167345 29777 sgd_solver.cpp:106] Iteration 166000, lr = 0.0048125
I0630 10:59:19.101447 29777 solver.cpp:290] Iteration 166100 (6.27602 iter/s, 15.9337s/100 iter), loss = 2.07143
I0630 10:59:19.101472 29777 solver.cpp:309]     Train net output #0: loss = 1.7381 (* 1 = 1.7381 loss)
I0630 10:59:19.101481 29777 sgd_solver.cpp:106] Iteration 166100, lr = 0.00480937
I0630 10:59:35.097266 29777 solver.cpp:290] Iteration 166200 (6.25181 iter/s, 15.9954s/100 iter), loss = 1.33333
I0630 10:59:35.097347 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 10:59:35.097358 29777 sgd_solver.cpp:106] Iteration 166200, lr = 0.00480625
I0630 10:59:50.988941 29777 solver.cpp:290] Iteration 166300 (6.29281 iter/s, 15.8912s/100 iter), loss = 1.45238
I0630 10:59:50.988963 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 10:59:50.988970 29777 sgd_solver.cpp:106] Iteration 166300, lr = 0.00480313
I0630 11:00:06.918673 29777 solver.cpp:290] Iteration 166400 (6.27775 iter/s, 15.9293s/100 iter), loss = 1.5119
I0630 11:00:06.919507 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 11:00:06.919520 29777 sgd_solver.cpp:106] Iteration 166400, lr = 0.0048
I0630 11:00:22.875365 29777 solver.cpp:290] Iteration 166500 (6.26746 iter/s, 15.9554s/100 iter), loss = 1.40476
I0630 11:00:22.875392 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 11:00:22.875401 29777 sgd_solver.cpp:106] Iteration 166500, lr = 0.00479688
I0630 11:00:38.892931 29777 solver.cpp:290] Iteration 166600 (6.24333 iter/s, 16.0171s/100 iter), loss = 1.2619
I0630 11:00:38.893004 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:00:38.893014 29777 sgd_solver.cpp:106] Iteration 166600, lr = 0.00479375
I0630 11:00:54.992002 29777 solver.cpp:290] Iteration 166700 (6.21174 iter/s, 16.0986s/100 iter), loss = 1.45238
I0630 11:00:54.992027 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 11:00:54.992036 29777 sgd_solver.cpp:106] Iteration 166700, lr = 0.00479063
I0630 11:01:10.939218 29777 solver.cpp:290] Iteration 166800 (6.27087 iter/s, 15.9468s/100 iter), loss = 1.54762
I0630 11:01:10.939769 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 11:01:10.939782 29777 sgd_solver.cpp:106] Iteration 166800, lr = 0.0047875
I0630 11:01:27.130517 29777 solver.cpp:290] Iteration 166900 (6.17653 iter/s, 16.1903s/100 iter), loss = 1.5119
I0630 11:01:27.130543 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:01:27.130551 29777 sgd_solver.cpp:106] Iteration 166900, lr = 0.00478437
I0630 11:01:43.086347 29777 solver.cpp:354] Sparsity after update:
I0630 11:01:43.106576 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:01:43.106592 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:01:43.106604 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:01:43.106608 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:01:43.106613 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:01:43.106617 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:01:43.106621 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:01:43.106626 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:01:43.106629 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:01:43.106632 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:01:43.106637 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:01:43.106640 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:01:43.106644 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:01:43.263917 29777 solver.cpp:290] Iteration 167000 (6.1985 iter/s, 16.1329s/100 iter), loss = 1.34524
I0630 11:01:43.263938 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:01:43.263944 29777 sgd_solver.cpp:106] Iteration 167000, lr = 0.00478125
I0630 11:01:59.411566 29777 solver.cpp:290] Iteration 167100 (6.19303 iter/s, 16.1472s/100 iter), loss = 1.39286
I0630 11:01:59.411613 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 11:01:59.411631 29777 sgd_solver.cpp:106] Iteration 167100, lr = 0.00477813
I0630 11:02:15.495504 29777 solver.cpp:290] Iteration 167200 (6.21757 iter/s, 16.0834s/100 iter), loss = 1.71429
I0630 11:02:15.495621 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 11:02:15.495649 29777 sgd_solver.cpp:106] Iteration 167200, lr = 0.004775
I0630 11:02:31.748473 29777 solver.cpp:290] Iteration 167300 (6.15293 iter/s, 16.2524s/100 iter), loss = 1.29762
I0630 11:02:31.748498 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 11:02:31.748505 29777 sgd_solver.cpp:106] Iteration 167300, lr = 0.00477188
I0630 11:02:47.940596 29777 solver.cpp:290] Iteration 167400 (6.17602 iter/s, 16.1917s/100 iter), loss = 1.32143
I0630 11:02:47.940685 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 11:02:47.940695 29777 sgd_solver.cpp:106] Iteration 167400, lr = 0.00476875
I0630 11:03:04.055630 29777 solver.cpp:290] Iteration 167500 (6.20559 iter/s, 16.1145s/100 iter), loss = 1.63095
I0630 11:03:04.055655 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:03:04.055662 29777 sgd_solver.cpp:106] Iteration 167500, lr = 0.00476563
I0630 11:03:20.085208 29777 solver.cpp:290] Iteration 167600 (6.23865 iter/s, 16.0291s/100 iter), loss = 1.53571
I0630 11:03:20.085299 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 11:03:20.085310 29777 sgd_solver.cpp:106] Iteration 167600, lr = 0.0047625
I0630 11:03:36.343724 29777 solver.cpp:290] Iteration 167700 (6.15083 iter/s, 16.258s/100 iter), loss = 1.16667
I0630 11:03:36.343761 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 11:03:36.343772 29777 sgd_solver.cpp:106] Iteration 167700, lr = 0.00475937
I0630 11:03:52.569447 29777 solver.cpp:290] Iteration 167800 (6.16323 iter/s, 16.2252s/100 iter), loss = 1.13095
I0630 11:03:52.569555 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 11:03:52.569566 29777 sgd_solver.cpp:106] Iteration 167800, lr = 0.00475625
I0630 11:04:09.387289 29777 solver.cpp:290] Iteration 167900 (5.94627 iter/s, 16.8173s/100 iter), loss = 1.25
I0630 11:04:09.387315 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 11:04:09.387323 29777 sgd_solver.cpp:106] Iteration 167900, lr = 0.00475312
I0630 11:04:25.319737 29777 solver.cpp:354] Sparsity after update:
I0630 11:04:25.321244 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:04:25.321256 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:04:25.321265 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:04:25.321270 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:04:25.321274 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:04:25.321277 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:04:25.321281 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:04:25.321285 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:04:25.321290 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:04:25.321292 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:04:25.321296 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:04:25.321300 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:04:25.321303 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:04:25.321401 29777 solver.cpp:471] Iteration 168000, Testing net (#0)
I0630 11:04:44.111032 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:05:30.587833 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54074
I0630 11:05:30.587941 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.780301
I0630 11:05:30.587951 29777 solver.cpp:544]     Test net output #2: loss = 1.6488 (* 1 = 1.6488 loss)
I0630 11:05:30.760341 29777 solver.cpp:290] Iteration 168000 (1.22894 iter/s, 81.3708s/100 iter), loss = 1.45238
I0630 11:05:30.760365 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 11:05:30.760371 29777 sgd_solver.cpp:106] Iteration 168000, lr = 0.00475
I0630 11:05:46.885792 29777 solver.cpp:290] Iteration 168100 (6.20156 iter/s, 16.125s/100 iter), loss = 1.59524
I0630 11:05:46.885818 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:05:46.885828 29777 sgd_solver.cpp:106] Iteration 168100, lr = 0.00474688
I0630 11:06:03.001209 29777 solver.cpp:290] Iteration 168200 (6.20542 iter/s, 16.115s/100 iter), loss = 1.41667
I0630 11:06:03.001314 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 11:06:03.001324 29777 sgd_solver.cpp:106] Iteration 168200, lr = 0.00474375
I0630 11:06:19.035120 29777 solver.cpp:290] Iteration 168300 (6.23699 iter/s, 16.0334s/100 iter), loss = 1.28571
I0630 11:06:19.035145 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 11:06:19.035159 29777 sgd_solver.cpp:106] Iteration 168300, lr = 0.00474062
I0630 11:06:35.190510 29777 solver.cpp:290] Iteration 168400 (6.19006 iter/s, 16.1549s/100 iter), loss = 1.02381
I0630 11:06:35.190608 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 11:06:35.190615 29777 sgd_solver.cpp:106] Iteration 168400, lr = 0.0047375
I0630 11:06:51.409592 29777 solver.cpp:290] Iteration 168500 (6.16578 iter/s, 16.2185s/100 iter), loss = 1.45238
I0630 11:06:51.409616 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:06:51.409624 29777 sgd_solver.cpp:106] Iteration 168500, lr = 0.00473437
I0630 11:07:07.618175 29777 solver.cpp:290] Iteration 168600 (6.16975 iter/s, 16.2081s/100 iter), loss = 1.14286
I0630 11:07:07.618273 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:07:07.618283 29777 sgd_solver.cpp:106] Iteration 168600, lr = 0.00473125
I0630 11:07:23.965733 29777 solver.cpp:290] Iteration 168700 (6.11732 iter/s, 16.347s/100 iter), loss = 1.32143
I0630 11:07:23.965761 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:07:23.966884 29777 sgd_solver.cpp:106] Iteration 168700, lr = 0.00472812
I0630 11:07:40.204485 29777 solver.cpp:290] Iteration 168800 (6.15829 iter/s, 16.2383s/100 iter), loss = 1.36905
I0630 11:07:40.204596 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 11:07:40.204605 29777 sgd_solver.cpp:106] Iteration 168800, lr = 0.004725
I0630 11:07:56.568235 29777 solver.cpp:290] Iteration 168900 (6.11128 iter/s, 16.3632s/100 iter), loss = 1.69048
I0630 11:07:56.568289 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 11:07:56.568310 29777 sgd_solver.cpp:106] Iteration 168900, lr = 0.00472188
I0630 11:08:12.585578 29777 solver.cpp:354] Sparsity after update:
I0630 11:08:12.605942 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:08:12.605968 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:08:12.605983 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:08:12.605990 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:08:12.605996 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:08:12.606001 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:08:12.606007 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:08:12.606014 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:08:12.606019 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:08:12.606026 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:08:12.606030 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:08:12.606036 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:08:12.606042 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:08:12.764094 29777 solver.cpp:290] Iteration 169000 (6.1746 iter/s, 16.1954s/100 iter), loss = 1.19048
I0630 11:08:12.764122 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:08:12.764130 29777 sgd_solver.cpp:106] Iteration 169000, lr = 0.00471875
I0630 11:08:29.005120 29777 solver.cpp:290] Iteration 169100 (6.15742 iter/s, 16.2406s/100 iter), loss = 1.22619
I0630 11:08:29.005151 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 11:08:29.005159 29777 sgd_solver.cpp:106] Iteration 169100, lr = 0.00471562
I0630 11:08:45.117099 29777 solver.cpp:290] Iteration 169200 (6.20674 iter/s, 16.1115s/100 iter), loss = 1.17857
I0630 11:08:45.117189 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 11:08:45.117200 29777 sgd_solver.cpp:106] Iteration 169200, lr = 0.0047125
I0630 11:09:01.095952 29777 solver.cpp:290] Iteration 169300 (6.25848 iter/s, 15.9783s/100 iter), loss = 1.54762
I0630 11:09:01.095971 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:09:01.095979 29777 sgd_solver.cpp:106] Iteration 169300, lr = 0.00470937
I0630 11:09:17.213794 29777 solver.cpp:290] Iteration 169400 (6.20448 iter/s, 16.1174s/100 iter), loss = 1.5119
I0630 11:09:17.213891 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 11:09:17.213898 29777 sgd_solver.cpp:106] Iteration 169400, lr = 0.00470625
I0630 11:09:33.392452 29777 solver.cpp:290] Iteration 169500 (6.18119 iter/s, 16.1781s/100 iter), loss = 1.22619
I0630 11:09:33.392478 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 11:09:33.392488 29777 sgd_solver.cpp:106] Iteration 169500, lr = 0.00470312
I0630 11:09:49.570617 29777 solver.cpp:290] Iteration 169600 (6.18135 iter/s, 16.1777s/100 iter), loss = 1.36905
I0630 11:09:49.570719 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 11:09:49.570730 29777 sgd_solver.cpp:106] Iteration 169600, lr = 0.0047
I0630 11:10:05.558758 29777 solver.cpp:290] Iteration 169700 (6.25484 iter/s, 15.9876s/100 iter), loss = 1.39286
I0630 11:10:05.558781 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 11:10:05.558789 29777 sgd_solver.cpp:106] Iteration 169700, lr = 0.00469687
I0630 11:10:21.636925 29777 solver.cpp:290] Iteration 169800 (6.21979 iter/s, 16.0777s/100 iter), loss = 1.27381
I0630 11:10:21.637043 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 11:10:21.637053 29777 sgd_solver.cpp:106] Iteration 169800, lr = 0.00469375
I0630 11:10:37.853076 29777 solver.cpp:290] Iteration 169900 (6.16691 iter/s, 16.2156s/100 iter), loss = 1.2381
I0630 11:10:37.853117 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:10:37.853132 29777 sgd_solver.cpp:106] Iteration 169900, lr = 0.00469062
I0630 11:10:53.772404 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_170000.caffemodel
I0630 11:10:53.791554 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_170000.solverstate
I0630 11:10:53.800323 29777 solver.cpp:354] Sparsity after update:
I0630 11:10:53.801352 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:10:53.801362 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:10:53.801368 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:10:53.801372 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:10:53.801373 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:10:53.801375 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:10:53.801378 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:10:53.801379 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:10:53.801381 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:10:53.801383 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:10:53.801384 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:10:53.801386 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:10:53.801388 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:10:53.801484 29777 solver.cpp:471] Iteration 170000, Testing net (#0)
I0630 11:11:10.222422 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:11:54.307220 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.53908
I0630 11:11:54.307309 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.780621
I0630 11:11:54.307324 29777 solver.cpp:544]     Test net output #2: loss = 1.65196 (* 1 = 1.65196 loss)
I0630 11:11:54.535126 29777 solver.cpp:290] Iteration 170000 (1.30412 iter/s, 76.6799s/100 iter), loss = 1.39286
I0630 11:11:54.535182 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 11:11:54.535200 29777 sgd_solver.cpp:106] Iteration 170000, lr = 0.0046875
I0630 11:12:10.582475 29777 solver.cpp:290] Iteration 170100 (6.23175 iter/s, 16.0469s/100 iter), loss = 1.34524
I0630 11:12:10.582497 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 11:12:10.582504 29777 sgd_solver.cpp:106] Iteration 170100, lr = 0.00468437
I0630 11:12:26.660698 29777 solver.cpp:290] Iteration 170200 (6.21977 iter/s, 16.0778s/100 iter), loss = 1.40476
I0630 11:12:26.660804 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:12:26.660814 29777 sgd_solver.cpp:106] Iteration 170200, lr = 0.00468125
I0630 11:12:42.701295 29777 solver.cpp:290] Iteration 170300 (6.23439 iter/s, 16.0401s/100 iter), loss = 1.05952
I0630 11:12:42.701321 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 11:12:42.701336 29777 sgd_solver.cpp:106] Iteration 170300, lr = 0.00467812
I0630 11:12:58.782986 29777 solver.cpp:290] Iteration 170400 (6.21843 iter/s, 16.0812s/100 iter), loss = 1.55952
I0630 11:12:58.783074 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:12:58.783084 29777 sgd_solver.cpp:106] Iteration 170400, lr = 0.004675
I0630 11:13:14.842877 29777 solver.cpp:290] Iteration 170500 (6.22689 iter/s, 16.0594s/100 iter), loss = 1.5
I0630 11:13:14.842902 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 11:13:14.842910 29777 sgd_solver.cpp:106] Iteration 170500, lr = 0.00467187
I0630 11:13:31.025617 29777 solver.cpp:290] Iteration 170600 (6.1796 iter/s, 16.1823s/100 iter), loss = 1.53571
I0630 11:13:31.025676 29777 solver.cpp:309]     Train net output #0: loss = 1.78571 (* 1 = 1.78571 loss)
I0630 11:13:31.025688 29777 sgd_solver.cpp:106] Iteration 170600, lr = 0.00466875
I0630 11:13:47.012461 29777 solver.cpp:290] Iteration 170700 (6.25533 iter/s, 15.9864s/100 iter), loss = 1.4881
I0630 11:13:47.012495 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:13:47.012503 29777 sgd_solver.cpp:106] Iteration 170700, lr = 0.00466562
I0630 11:14:02.977267 29777 solver.cpp:290] Iteration 170800 (6.26396 iter/s, 15.9643s/100 iter), loss = 1.16667
I0630 11:14:02.977349 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:14:02.977357 29777 sgd_solver.cpp:106] Iteration 170800, lr = 0.0046625
I0630 11:14:19.043007 29777 solver.cpp:290] Iteration 170900 (6.22463 iter/s, 16.0652s/100 iter), loss = 1.05952
I0630 11:14:19.043033 29777 solver.cpp:309]     Train net output #0: loss = 0.904762 (* 1 = 0.904762 loss)
I0630 11:14:19.043042 29777 sgd_solver.cpp:106] Iteration 170900, lr = 0.00465937
I0630 11:14:34.905124 29777 solver.cpp:354] Sparsity after update:
I0630 11:14:34.925470 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:14:34.925487 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:14:34.925498 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:14:34.925501 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:14:34.925504 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:14:34.925518 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:14:34.925523 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:14:34.925529 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:14:34.925534 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:14:34.925539 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:14:34.925544 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:14:34.925549 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:14:34.925551 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:14:35.083562 29777 solver.cpp:290] Iteration 171000 (6.23438 iter/s, 16.0401s/100 iter), loss = 1.14286
I0630 11:14:35.083587 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 11:14:35.083596 29777 sgd_solver.cpp:106] Iteration 171000, lr = 0.00465625
I0630 11:14:51.192147 29777 solver.cpp:290] Iteration 171100 (6.20805 iter/s, 16.1081s/100 iter), loss = 1.13095
I0630 11:14:51.192168 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:14:51.192175 29777 sgd_solver.cpp:106] Iteration 171100, lr = 0.00465312
I0630 11:15:07.217164 29777 solver.cpp:290] Iteration 171200 (6.24042 iter/s, 16.0246s/100 iter), loss = 1.21429
I0630 11:15:07.217260 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:15:07.217286 29777 sgd_solver.cpp:106] Iteration 171200, lr = 0.00465
I0630 11:15:23.173982 29777 solver.cpp:290] Iteration 171300 (6.26712 iter/s, 15.9563s/100 iter), loss = 1.2619
I0630 11:15:23.174036 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 11:15:23.174059 29777 sgd_solver.cpp:106] Iteration 171300, lr = 0.00464687
I0630 11:15:39.548784 29777 solver.cpp:290] Iteration 171400 (6.10713 iter/s, 16.3743s/100 iter), loss = 1.70238
I0630 11:15:39.548854 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:15:39.548861 29777 sgd_solver.cpp:106] Iteration 171400, lr = 0.00464375
I0630 11:15:55.667531 29777 solver.cpp:290] Iteration 171500 (6.20415 iter/s, 16.1182s/100 iter), loss = 1.2381
I0630 11:15:55.667562 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 11:15:55.667572 29777 sgd_solver.cpp:106] Iteration 171500, lr = 0.00464062
I0630 11:16:11.694209 29777 solver.cpp:290] Iteration 171600 (6.23978 iter/s, 16.0262s/100 iter), loss = 1.02381
I0630 11:16:11.694298 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 11:16:11.694308 29777 sgd_solver.cpp:106] Iteration 171600, lr = 0.0046375
I0630 11:16:27.974938 29777 solver.cpp:290] Iteration 171700 (6.14243 iter/s, 16.2802s/100 iter), loss = 1.2619
I0630 11:16:27.974967 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:16:27.974977 29777 sgd_solver.cpp:106] Iteration 171700, lr = 0.00463437
I0630 11:16:44.043372 29777 solver.cpp:290] Iteration 171800 (6.22356 iter/s, 16.068s/100 iter), loss = 1.19048
I0630 11:16:44.043453 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 11:16:44.043462 29777 sgd_solver.cpp:106] Iteration 171800, lr = 0.00463125
I0630 11:17:00.436560 29777 solver.cpp:290] Iteration 171900 (6.10029 iter/s, 16.3927s/100 iter), loss = 1.52381
I0630 11:17:00.436589 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 11:17:00.436595 29777 sgd_solver.cpp:106] Iteration 171900, lr = 0.00462812
I0630 11:17:16.364609 29777 solver.cpp:354] Sparsity after update:
I0630 11:17:16.366996 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:17:16.367013 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:17:16.367030 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:17:16.367036 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:17:16.367041 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:17:16.367048 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:17:16.367056 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:17:16.367063 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:17:16.367067 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:17:16.367074 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:17:16.367079 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:17:16.367084 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:17:16.367090 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:17:16.367295 29777 solver.cpp:471] Iteration 172000, Testing net (#0)
I0630 11:17:36.159358 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:18:25.823510 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54292
I0630 11:18:25.823617 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.78236
I0630 11:18:25.823627 29777 solver.cpp:544]     Test net output #2: loss = 1.64092 (* 1 = 1.64092 loss)
I0630 11:18:25.994895 29777 solver.cpp:290] Iteration 172000 (1.16883 iter/s, 85.556s/100 iter), loss = 1.2619
I0630 11:18:25.994923 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 11:18:25.994933 29777 sgd_solver.cpp:106] Iteration 172000, lr = 0.004625
I0630 11:18:42.249028 29777 solver.cpp:290] Iteration 172100 (6.15246 iter/s, 16.2537s/100 iter), loss = 1.40476
I0630 11:18:42.249061 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 11:18:42.249071 29777 sgd_solver.cpp:106] Iteration 172100, lr = 0.00462188
I0630 11:18:58.390177 29777 solver.cpp:290] Iteration 172200 (6.19553 iter/s, 16.1407s/100 iter), loss = 1.54762
I0630 11:18:58.390278 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 11:18:58.390297 29777 sgd_solver.cpp:106] Iteration 172200, lr = 0.00461875
I0630 11:19:14.600037 29777 solver.cpp:290] Iteration 172300 (6.16929 iter/s, 16.2093s/100 iter), loss = 1.2381
I0630 11:19:14.600067 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:19:14.600075 29777 sgd_solver.cpp:106] Iteration 172300, lr = 0.00461562
I0630 11:19:30.740658 29777 solver.cpp:290] Iteration 172400 (6.19573 iter/s, 16.1402s/100 iter), loss = 0.952381
I0630 11:19:30.740749 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 11:19:30.740759 29777 sgd_solver.cpp:106] Iteration 172400, lr = 0.0046125
I0630 11:19:46.850600 29777 solver.cpp:290] Iteration 172500 (6.20755 iter/s, 16.1094s/100 iter), loss = 1.35714
I0630 11:19:46.850627 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:19:46.850636 29777 sgd_solver.cpp:106] Iteration 172500, lr = 0.00460937
I0630 11:20:03.008889 29777 solver.cpp:290] Iteration 172600 (6.18895 iter/s, 16.1578s/100 iter), loss = 1.25
I0630 11:20:03.008999 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:20:03.009011 29777 sgd_solver.cpp:106] Iteration 172600, lr = 0.00460625
I0630 11:20:19.150060 29777 solver.cpp:290] Iteration 172700 (6.19555 iter/s, 16.1406s/100 iter), loss = 1.25
I0630 11:20:19.150087 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 11:20:19.150094 29777 sgd_solver.cpp:106] Iteration 172700, lr = 0.00460312
I0630 11:20:35.345355 29777 solver.cpp:290] Iteration 172800 (6.17481 iter/s, 16.1948s/100 iter), loss = 1.45238
I0630 11:20:35.345484 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:20:35.345515 29777 sgd_solver.cpp:106] Iteration 172800, lr = 0.0046
I0630 11:20:52.074048 29777 solver.cpp:290] Iteration 172900 (5.97796 iter/s, 16.7281s/100 iter), loss = 1.29762
I0630 11:20:52.074101 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 11:20:52.074122 29777 sgd_solver.cpp:106] Iteration 172900, lr = 0.00459687
I0630 11:21:08.631024 29777 solver.cpp:354] Sparsity after update:
I0630 11:21:08.651448 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:21:08.651491 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:21:08.651507 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:21:08.651517 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:21:08.651526 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:21:08.651535 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:21:08.651545 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:21:08.651553 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:21:08.651562 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:21:08.651571 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:21:08.651581 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:21:08.651589 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:21:08.651598 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:21:08.806525 29777 solver.cpp:290] Iteration 173000 (5.97658 iter/s, 16.732s/100 iter), loss = 1.58333
I0630 11:21:08.806550 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 11:21:08.806556 29777 sgd_solver.cpp:106] Iteration 173000, lr = 0.00459375
I0630 11:21:25.077198 29777 solver.cpp:290] Iteration 173100 (6.1462 iter/s, 16.2702s/100 iter), loss = 2.05952
I0630 11:21:25.077224 29777 solver.cpp:309]     Train net output #0: loss = 2.09524 (* 1 = 2.09524 loss)
I0630 11:21:25.077239 29777 sgd_solver.cpp:106] Iteration 173100, lr = 0.00459062
I0630 11:21:41.215838 29777 solver.cpp:290] Iteration 173200 (6.19649 iter/s, 16.1382s/100 iter), loss = 1.5119
I0630 11:21:41.215955 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 11:21:41.215970 29777 sgd_solver.cpp:106] Iteration 173200, lr = 0.0045875
I0630 11:21:57.333263 29777 solver.cpp:290] Iteration 173300 (6.20468 iter/s, 16.1169s/100 iter), loss = 1.47619
I0630 11:21:57.333290 29777 solver.cpp:309]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0630 11:21:57.333299 29777 sgd_solver.cpp:106] Iteration 173300, lr = 0.00458437
I0630 11:22:13.528096 29777 solver.cpp:290] Iteration 173400 (6.17499 iter/s, 16.1944s/100 iter), loss = 1.44048
I0630 11:22:13.528197 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 11:22:13.528220 29777 sgd_solver.cpp:106] Iteration 173400, lr = 0.00458125
I0630 11:22:29.686723 29777 solver.cpp:290] Iteration 173500 (6.18885 iter/s, 16.1581s/100 iter), loss = 1
I0630 11:22:29.686774 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 11:22:29.686805 29777 sgd_solver.cpp:106] Iteration 173500, lr = 0.00457812
I0630 11:22:45.842494 29777 solver.cpp:290] Iteration 173600 (6.18993 iter/s, 16.1553s/100 iter), loss = 1.46429
I0630 11:22:45.842577 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:22:45.842586 29777 sgd_solver.cpp:106] Iteration 173600, lr = 0.004575
I0630 11:23:01.927233 29777 solver.cpp:290] Iteration 173700 (6.21727 iter/s, 16.0842s/100 iter), loss = 0.940476
I0630 11:23:01.927260 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 11:23:01.927269 29777 sgd_solver.cpp:106] Iteration 173700, lr = 0.00457187
I0630 11:23:17.994873 29777 solver.cpp:290] Iteration 173800 (6.22387 iter/s, 16.0672s/100 iter), loss = 1.57143
I0630 11:23:17.994968 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:23:17.994981 29777 sgd_solver.cpp:106] Iteration 173800, lr = 0.00456875
I0630 11:23:34.296128 29777 solver.cpp:290] Iteration 173900 (6.1347 iter/s, 16.3007s/100 iter), loss = 1.25
I0630 11:23:34.296154 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 11:23:34.296164 29777 sgd_solver.cpp:106] Iteration 173900, lr = 0.00456562
I0630 11:23:50.343266 29777 solver.cpp:354] Sparsity after update:
I0630 11:23:50.344727 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:23:50.344734 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:23:50.344741 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:23:50.344743 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:23:50.344745 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:23:50.344748 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:23:50.344749 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:23:50.344751 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:23:50.344753 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:23:50.344755 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:23:50.344758 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:23:50.344759 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:23:50.344761 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:23:50.344847 29777 solver.cpp:471] Iteration 174000, Testing net (#0)
I0630 11:24:08.352706 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:24:55.087182 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54368
I0630 11:24:55.087306 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.784941
I0630 11:24:55.087327 29777 solver.cpp:544]     Test net output #2: loss = 1.62624 (* 1 = 1.62624 loss)
I0630 11:24:55.295344 29777 solver.cpp:290] Iteration 174000 (1.23461 iter/s, 80.997s/100 iter), loss = 1.44048
I0630 11:24:55.295384 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 11:24:55.295403 29777 sgd_solver.cpp:106] Iteration 174000, lr = 0.0045625
I0630 11:25:11.636245 29777 solver.cpp:290] Iteration 174100 (6.11979 iter/s, 16.3404s/100 iter), loss = 1.36905
I0630 11:25:11.636268 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:25:11.636274 29777 sgd_solver.cpp:106] Iteration 174100, lr = 0.00455937
I0630 11:25:27.769809 29777 solver.cpp:290] Iteration 174200 (6.19844 iter/s, 16.1331s/100 iter), loss = 1.39286
I0630 11:25:27.769891 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 11:25:27.769901 29777 sgd_solver.cpp:106] Iteration 174200, lr = 0.00455625
I0630 11:25:43.923708 29777 solver.cpp:290] Iteration 174300 (6.19066 iter/s, 16.1534s/100 iter), loss = 1.28571
I0630 11:25:43.923748 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:25:43.923763 29777 sgd_solver.cpp:106] Iteration 174300, lr = 0.00455312
I0630 11:26:00.023892 29777 solver.cpp:290] Iteration 174400 (6.21129 iter/s, 16.0997s/100 iter), loss = 1.02381
I0630 11:26:00.024081 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 11:26:00.024171 29777 sgd_solver.cpp:106] Iteration 174400, lr = 0.00455
I0630 11:26:16.253459 29777 solver.cpp:290] Iteration 174500 (6.16179 iter/s, 16.229s/100 iter), loss = 0.988096
I0630 11:26:16.253484 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 11:26:16.253494 29777 sgd_solver.cpp:106] Iteration 174500, lr = 0.00454687
I0630 11:26:32.470969 29777 solver.cpp:290] Iteration 174600 (6.16635 iter/s, 16.217s/100 iter), loss = 1.21429
I0630 11:26:32.471050 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:26:32.471060 29777 sgd_solver.cpp:106] Iteration 174600, lr = 0.00454375
I0630 11:26:48.429163 29777 solver.cpp:290] Iteration 174700 (6.26658 iter/s, 15.9577s/100 iter), loss = 1
I0630 11:26:48.429190 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 11:26:48.429199 29777 sgd_solver.cpp:106] Iteration 174700, lr = 0.00454063
I0630 11:27:04.618135 29777 solver.cpp:290] Iteration 174800 (6.17722 iter/s, 16.1885s/100 iter), loss = 1.52381
I0630 11:27:04.618216 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:27:04.618227 29777 sgd_solver.cpp:106] Iteration 174800, lr = 0.0045375
I0630 11:27:20.639051 29777 solver.cpp:290] Iteration 174900 (6.24204 iter/s, 16.0204s/100 iter), loss = 1.34524
I0630 11:27:20.639076 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 11:27:20.639086 29777 sgd_solver.cpp:106] Iteration 174900, lr = 0.00453437
I0630 11:27:36.589658 29777 solver.cpp:354] Sparsity after update:
I0630 11:27:36.610195 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:27:36.610211 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:27:36.610222 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:27:36.610226 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:27:36.610229 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:27:36.610232 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:27:36.610235 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:27:36.610239 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:27:36.610242 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:27:36.610245 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:27:36.610249 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:27:36.610251 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:27:36.610255 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:27:36.764014 29777 solver.cpp:290] Iteration 175000 (6.20175 iter/s, 16.1245s/100 iter), loss = 1.60714
I0630 11:27:36.764065 29777 solver.cpp:309]     Train net output #0: loss = 1.7619 (* 1 = 1.7619 loss)
I0630 11:27:36.764086 29777 sgd_solver.cpp:106] Iteration 175000, lr = 0.00453125
I0630 11:27:52.794682 29777 solver.cpp:290] Iteration 175100 (6.23823 iter/s, 16.0302s/100 iter), loss = 1.65476
I0630 11:27:52.794726 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 11:27:52.794736 29777 sgd_solver.cpp:106] Iteration 175100, lr = 0.00452812
I0630 11:28:08.956820 29777 solver.cpp:290] Iteration 175200 (6.18748 iter/s, 16.1617s/100 iter), loss = 1.16667
I0630 11:28:08.956894 29777 solver.cpp:309]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0630 11:28:08.956905 29777 sgd_solver.cpp:106] Iteration 175200, lr = 0.004525
I0630 11:28:25.106338 29777 solver.cpp:290] Iteration 175300 (6.19233 iter/s, 16.149s/100 iter), loss = 1.2381
I0630 11:28:25.106385 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 11:28:25.106403 29777 sgd_solver.cpp:106] Iteration 175300, lr = 0.00452187
I0630 11:28:41.205587 29777 solver.cpp:290] Iteration 175400 (6.21166 iter/s, 16.0988s/100 iter), loss = 0.869048
I0630 11:28:41.205687 29777 solver.cpp:309]     Train net output #0: loss = 0.666667 (* 1 = 0.666667 loss)
I0630 11:28:41.205698 29777 sgd_solver.cpp:106] Iteration 175400, lr = 0.00451875
I0630 11:28:57.202970 29777 solver.cpp:290] Iteration 175500 (6.25123 iter/s, 15.9969s/100 iter), loss = 1.32143
I0630 11:28:57.202993 29777 solver.cpp:309]     Train net output #0: loss = 0.880952 (* 1 = 0.880952 loss)
I0630 11:28:57.203001 29777 sgd_solver.cpp:106] Iteration 175500, lr = 0.00451563
I0630 11:29:13.223006 29777 solver.cpp:290] Iteration 175600 (6.24236 iter/s, 16.0196s/100 iter), loss = 1.71429
I0630 11:29:13.223129 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:29:13.223142 29777 sgd_solver.cpp:106] Iteration 175600, lr = 0.0045125
I0630 11:29:29.268057 29777 solver.cpp:290] Iteration 175700 (6.23267 iter/s, 16.0445s/100 iter), loss = 1.44048
I0630 11:29:29.268081 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:29:29.268088 29777 sgd_solver.cpp:106] Iteration 175700, lr = 0.00450937
I0630 11:29:45.309984 29777 solver.cpp:290] Iteration 175800 (6.23384 iter/s, 16.0415s/100 iter), loss = 1.34524
I0630 11:29:45.310065 29777 solver.cpp:309]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0630 11:29:45.310073 29777 sgd_solver.cpp:106] Iteration 175800, lr = 0.00450625
I0630 11:30:01.280839 29777 solver.cpp:290] Iteration 175900 (6.26161 iter/s, 15.9703s/100 iter), loss = 1.2381
I0630 11:30:01.280866 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 11:30:01.280875 29777 sgd_solver.cpp:106] Iteration 175900, lr = 0.00450312
I0630 11:30:17.155743 29777 solver.cpp:354] Sparsity after update:
I0630 11:30:17.157187 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:30:17.157194 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:30:17.157202 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:30:17.157204 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:30:17.157207 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:30:17.157209 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:30:17.157212 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:30:17.157214 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:30:17.157217 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:30:17.157219 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:30:17.157222 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:30:17.157224 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:30:17.157227 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:30:17.157312 29777 solver.cpp:471] Iteration 176000, Testing net (#0)
I0630 11:30:31.941349 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:31:06.793934 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54502
I0630 11:31:06.793992 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.783641
I0630 11:31:06.793999 29777 solver.cpp:544]     Test net output #2: loss = 1.63206 (* 1 = 1.63206 loss)
I0630 11:31:06.970237 29777 solver.cpp:290] Iteration 176000 (1.52236 iter/s, 65.6876s/100 iter), loss = 1.60714
I0630 11:31:06.970260 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 11:31:06.970266 29777 sgd_solver.cpp:106] Iteration 176000, lr = 0.0045
I0630 11:31:22.960647 29777 solver.cpp:290] Iteration 176100 (6.25393 iter/s, 15.9899s/100 iter), loss = 1.5
I0630 11:31:22.960670 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 11:31:22.960676 29777 sgd_solver.cpp:106] Iteration 176100, lr = 0.00449687
I0630 11:31:38.998368 29777 solver.cpp:290] Iteration 176200 (6.23548 iter/s, 16.0373s/100 iter), loss = 1.35714
I0630 11:31:39.000542 29777 solver.cpp:309]     Train net output #0: loss = 1.28571 (* 1 = 1.28571 loss)
I0630 11:31:39.000566 29777 sgd_solver.cpp:106] Iteration 176200, lr = 0.00449375
I0630 11:31:55.032958 29777 solver.cpp:290] Iteration 176300 (6.23753 iter/s, 16.032s/100 iter), loss = 0.988096
I0630 11:31:55.033020 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 11:31:55.033049 29777 sgd_solver.cpp:106] Iteration 176300, lr = 0.00449063
I0630 11:32:11.021749 29777 solver.cpp:290] Iteration 176400 (6.25458 iter/s, 15.9883s/100 iter), loss = 1.71429
I0630 11:32:11.022395 29777 solver.cpp:309]     Train net output #0: loss = 1.71429 (* 1 = 1.71429 loss)
I0630 11:32:11.022406 29777 sgd_solver.cpp:106] Iteration 176400, lr = 0.0044875
I0630 11:32:27.125950 29777 solver.cpp:290] Iteration 176500 (6.20998 iter/s, 16.1031s/100 iter), loss = 1.14286
I0630 11:32:27.125972 29777 solver.cpp:309]     Train net output #0: loss = 0.97619 (* 1 = 0.97619 loss)
I0630 11:32:27.125977 29777 sgd_solver.cpp:106] Iteration 176500, lr = 0.00448438
I0630 11:32:43.084329 29777 solver.cpp:290] Iteration 176600 (6.26648 iter/s, 15.9579s/100 iter), loss = 1.19048
I0630 11:32:43.084426 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:32:43.084439 29777 sgd_solver.cpp:106] Iteration 176600, lr = 0.00448125
I0630 11:32:59.055630 29777 solver.cpp:290] Iteration 176700 (6.26144 iter/s, 15.9708s/100 iter), loss = 1.38095
I0630 11:32:59.055655 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 11:32:59.055665 29777 sgd_solver.cpp:106] Iteration 176700, lr = 0.00447812
I0630 11:33:15.028695 29777 solver.cpp:290] Iteration 176800 (6.26072 iter/s, 15.9726s/100 iter), loss = 1.10714
I0630 11:33:15.028786 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:33:15.028800 29777 sgd_solver.cpp:106] Iteration 176800, lr = 0.004475
I0630 11:33:31.194072 29777 solver.cpp:290] Iteration 176900 (6.18626 iter/s, 16.1648s/100 iter), loss = 1.16667
I0630 11:33:31.194094 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:33:31.194102 29777 sgd_solver.cpp:106] Iteration 176900, lr = 0.00447187
I0630 11:33:47.183140 29777 solver.cpp:354] Sparsity after update:
I0630 11:33:47.203536 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:33:47.203553 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:33:47.203563 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:33:47.203567 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:33:47.203570 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:33:47.203573 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:33:47.203577 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:33:47.203580 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:33:47.203583 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:33:47.203588 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:33:47.203590 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:33:47.203593 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:33:47.203596 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:33:47.359843 29777 solver.cpp:290] Iteration 177000 (6.18609 iter/s, 16.1653s/100 iter), loss = 1.27381
I0630 11:33:47.359864 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 11:33:47.359871 29777 sgd_solver.cpp:106] Iteration 177000, lr = 0.00446875
I0630 11:34:03.396483 29777 solver.cpp:290] Iteration 177100 (6.2359 iter/s, 16.0362s/100 iter), loss = 1.78571
I0630 11:34:03.396507 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:34:03.396513 29777 sgd_solver.cpp:106] Iteration 177100, lr = 0.00446563
I0630 11:34:19.505506 29777 solver.cpp:290] Iteration 177200 (6.20788 iter/s, 16.1086s/100 iter), loss = 1.14286
I0630 11:34:19.505867 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:34:19.505878 29777 sgd_solver.cpp:106] Iteration 177200, lr = 0.0044625
I0630 11:34:35.605304 29777 solver.cpp:290] Iteration 177300 (6.21157 iter/s, 16.099s/100 iter), loss = 1.19048
I0630 11:34:35.605329 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 11:34:35.605339 29777 sgd_solver.cpp:106] Iteration 177300, lr = 0.00445938
I0630 11:34:51.616605 29777 solver.cpp:290] Iteration 177400 (6.24577 iter/s, 16.0108s/100 iter), loss = 1.60714
I0630 11:34:51.616708 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:34:51.616717 29777 sgd_solver.cpp:106] Iteration 177400, lr = 0.00445625
I0630 11:35:07.629328 29777 solver.cpp:290] Iteration 177500 (6.24524 iter/s, 16.0122s/100 iter), loss = 1.33333
I0630 11:35:07.629351 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:35:07.629359 29777 sgd_solver.cpp:106] Iteration 177500, lr = 0.00445312
I0630 11:35:23.677886 29777 solver.cpp:290] Iteration 177600 (6.23127 iter/s, 16.0481s/100 iter), loss = 1.25
I0630 11:35:23.677975 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 11:35:23.677983 29777 sgd_solver.cpp:106] Iteration 177600, lr = 0.00445
I0630 11:35:39.821091 29777 solver.cpp:290] Iteration 177700 (6.19476 iter/s, 16.1427s/100 iter), loss = 1.36905
I0630 11:35:39.821120 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 11:35:39.821128 29777 sgd_solver.cpp:106] Iteration 177700, lr = 0.00444687
I0630 11:35:55.831712 29777 solver.cpp:290] Iteration 177800 (6.24604 iter/s, 16.0102s/100 iter), loss = 1.39286
I0630 11:35:55.831804 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 11:35:55.831815 29777 sgd_solver.cpp:106] Iteration 177800, lr = 0.00444375
I0630 11:36:11.910784 29777 solver.cpp:290] Iteration 177900 (6.21947 iter/s, 16.0785s/100 iter), loss = 1.47619
I0630 11:36:11.910809 29777 solver.cpp:309]     Train net output #0: loss = 1.33333 (* 1 = 1.33333 loss)
I0630 11:36:11.910815 29777 sgd_solver.cpp:106] Iteration 177900, lr = 0.00444062
I0630 11:36:27.739439 29777 solver.cpp:354] Sparsity after update:
I0630 11:36:27.740921 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:36:27.740929 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:36:27.740941 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:36:27.740944 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:36:27.740947 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:36:27.740952 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:36:27.740955 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:36:27.740959 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:36:27.740963 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:36:27.740967 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:36:27.740972 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:36:27.740975 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:36:27.740980 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:36:27.741117 29777 solver.cpp:471] Iteration 178000, Testing net (#0)
I0630 11:36:42.541292 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:37:16.974917 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.543879
I0630 11:37:16.974959 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.783221
I0630 11:37:16.974966 29777 solver.cpp:544]     Test net output #2: loss = 1.63296 (* 1 = 1.63296 loss)
I0630 11:37:17.148187 29777 solver.cpp:290] Iteration 178000 (1.53291 iter/s, 65.2356s/100 iter), loss = 1.16667
I0630 11:37:17.148211 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:37:17.148217 29777 sgd_solver.cpp:106] Iteration 178000, lr = 0.0044375
I0630 11:37:33.153815 29777 solver.cpp:290] Iteration 178100 (6.24798 iter/s, 16.0052s/100 iter), loss = 1.13095
I0630 11:37:33.153839 29777 solver.cpp:309]     Train net output #0: loss = 1.16667 (* 1 = 1.16667 loss)
I0630 11:37:33.153846 29777 sgd_solver.cpp:106] Iteration 178100, lr = 0.00443438
I0630 11:37:49.100049 29777 solver.cpp:290] Iteration 178200 (6.27126 iter/s, 15.9458s/100 iter), loss = 1.09524
I0630 11:37:49.100159 29777 solver.cpp:309]     Train net output #0: loss = 0.928571 (* 1 = 0.928571 loss)
I0630 11:37:49.100168 29777 sgd_solver.cpp:106] Iteration 178200, lr = 0.00443125
I0630 11:38:05.283841 29777 solver.cpp:290] Iteration 178300 (6.17923 iter/s, 16.1832s/100 iter), loss = 1.52381
I0630 11:38:05.283864 29777 solver.cpp:309]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0630 11:38:05.283870 29777 sgd_solver.cpp:106] Iteration 178300, lr = 0.00442812
I0630 11:38:21.304919 29777 solver.cpp:290] Iteration 178400 (6.24196 iter/s, 16.0206s/100 iter), loss = 1.27381
I0630 11:38:21.305022 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 11:38:21.305033 29777 sgd_solver.cpp:106] Iteration 178400, lr = 0.004425
I0630 11:38:37.357851 29777 solver.cpp:290] Iteration 178500 (6.2296 iter/s, 16.0524s/100 iter), loss = 0.869048
I0630 11:38:37.357873 29777 solver.cpp:309]     Train net output #0: loss = 0.714286 (* 1 = 0.714286 loss)
I0630 11:38:37.357880 29777 sgd_solver.cpp:106] Iteration 178500, lr = 0.00442187
I0630 11:38:53.355039 29777 solver.cpp:290] Iteration 178600 (6.25128 iter/s, 15.9967s/100 iter), loss = 1.09524
I0630 11:38:53.355104 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:38:53.355116 29777 sgd_solver.cpp:106] Iteration 178600, lr = 0.00441875
I0630 11:39:09.448429 29777 solver.cpp:290] Iteration 178700 (6.21393 iter/s, 16.0929s/100 iter), loss = 1.57143
I0630 11:39:09.448456 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 11:39:09.448464 29777 sgd_solver.cpp:106] Iteration 178700, lr = 0.00441562
I0630 11:39:25.403528 29777 solver.cpp:290] Iteration 178800 (6.26777 iter/s, 15.9546s/100 iter), loss = 1.2619
I0630 11:39:25.403642 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 11:39:25.403651 29777 sgd_solver.cpp:106] Iteration 178800, lr = 0.0044125
I0630 11:39:41.393363 29777 solver.cpp:290] Iteration 178900 (6.25419 iter/s, 15.9893s/100 iter), loss = 1.35714
I0630 11:39:41.393386 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:39:41.393395 29777 sgd_solver.cpp:106] Iteration 178900, lr = 0.00440938
I0630 11:39:57.355361 29777 solver.cpp:354] Sparsity after update:
I0630 11:39:57.375777 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:39:57.375805 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:39:57.375838 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:39:57.375854 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:39:57.375870 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:39:57.375885 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:39:57.375900 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:39:57.375917 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:39:57.375932 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:39:57.375946 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:39:57.375964 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:39:57.375979 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:39:57.375995 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:39:57.530066 29777 solver.cpp:290] Iteration 179000 (6.19723 iter/s, 16.1362s/100 iter), loss = 1.2619
I0630 11:39:57.530120 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:39:57.530143 29777 sgd_solver.cpp:106] Iteration 179000, lr = 0.00440625
I0630 11:40:13.763413 29777 solver.cpp:290] Iteration 179100 (6.16035 iter/s, 16.2329s/100 iter), loss = 1.52381
I0630 11:40:13.763439 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 11:40:13.763453 29777 sgd_solver.cpp:106] Iteration 179100, lr = 0.00440313
I0630 11:40:29.843394 29777 solver.cpp:290] Iteration 179200 (6.2191 iter/s, 16.0795s/100 iter), loss = 1.72619
I0630 11:40:29.843508 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 11:40:29.843540 29777 sgd_solver.cpp:106] Iteration 179200, lr = 0.0044
I0630 11:40:45.867310 29777 solver.cpp:290] Iteration 179300 (6.24089 iter/s, 16.0234s/100 iter), loss = 1.20238
I0630 11:40:45.867373 29777 solver.cpp:309]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0630 11:40:45.867395 29777 sgd_solver.cpp:106] Iteration 179300, lr = 0.00439687
I0630 11:41:02.149670 29777 solver.cpp:290] Iteration 179400 (6.14181 iter/s, 16.2818s/100 iter), loss = 1.53571
I0630 11:41:02.149790 29777 solver.cpp:309]     Train net output #0: loss = 1.83333 (* 1 = 1.83333 loss)
I0630 11:41:02.149809 29777 sgd_solver.cpp:106] Iteration 179400, lr = 0.00439375
I0630 11:41:18.146337 29777 solver.cpp:290] Iteration 179500 (6.25152 iter/s, 15.9961s/100 iter), loss = 1.46429
I0630 11:41:18.146363 29777 solver.cpp:309]     Train net output #0: loss = 1.88095 (* 1 = 1.88095 loss)
I0630 11:41:18.146373 29777 sgd_solver.cpp:106] Iteration 179500, lr = 0.00439062
I0630 11:41:34.193557 29777 solver.cpp:290] Iteration 179600 (6.23179 iter/s, 16.0468s/100 iter), loss = 1.45238
I0630 11:41:34.193672 29777 solver.cpp:309]     Train net output #0: loss = 1.66667 (* 1 = 1.66667 loss)
I0630 11:41:34.193683 29777 sgd_solver.cpp:106] Iteration 179600, lr = 0.0043875
I0630 11:41:50.231928 29777 solver.cpp:290] Iteration 179700 (6.23526 iter/s, 16.0378s/100 iter), loss = 1.54762
I0630 11:41:50.231958 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:41:50.231967 29777 sgd_solver.cpp:106] Iteration 179700, lr = 0.00438438
I0630 11:42:06.398386 29777 solver.cpp:290] Iteration 179800 (6.18583 iter/s, 16.166s/100 iter), loss = 1.33333
I0630 11:42:06.398458 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:42:06.398465 29777 sgd_solver.cpp:106] Iteration 179800, lr = 0.00438125
I0630 11:42:22.497493 29777 solver.cpp:290] Iteration 179900 (6.21172 iter/s, 16.0986s/100 iter), loss = 1.29762
I0630 11:42:22.497516 29777 solver.cpp:309]     Train net output #0: loss = 1.02381 (* 1 = 1.02381 loss)
I0630 11:42:22.497524 29777 sgd_solver.cpp:106] Iteration 179900, lr = 0.00437813
I0630 11:42:38.419026 29777 solver.cpp:598] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_180000.caffemodel
I0630 11:42:38.438383 29777 sgd_solver.cpp:273] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-30_02-08-23/sparse/imagenet_jacintonet11v2_iter_180000.solverstate
I0630 11:42:38.447789 29777 solver.cpp:354] Sparsity after update:
I0630 11:42:38.448766 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:42:38.448776 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:42:38.448782 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:42:38.448786 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:42:38.448788 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:42:38.448791 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:42:38.448793 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:42:38.448796 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:42:38.448797 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:42:38.448799 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:42:38.448801 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:42:38.448803 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:42:38.448806 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:42:38.448902 29777 solver.cpp:471] Iteration 180000, Testing net (#0)
I0630 11:42:54.980329 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:43:35.511044 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.54628
I0630 11:43:35.511154 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.786281
I0630 11:43:35.511165 29777 solver.cpp:544]     Test net output #2: loss = 1.6174 (* 1 = 1.6174 loss)
I0630 11:43:35.744496 29777 solver.cpp:290] Iteration 180000 (1.36528 iter/s, 73.245s/100 iter), loss = 1.13095
I0630 11:43:35.744552 29777 solver.cpp:309]     Train net output #0: loss = 0.833333 (* 1 = 0.833333 loss)
I0630 11:43:35.744575 29777 sgd_solver.cpp:106] Iteration 180000, lr = 0.004375
I0630 11:43:51.852099 29777 solver.cpp:290] Iteration 180100 (6.20844 iter/s, 16.1071s/100 iter), loss = 1.39286
I0630 11:43:51.852136 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 11:43:51.852149 29777 sgd_solver.cpp:106] Iteration 180100, lr = 0.00437187
I0630 11:44:07.822502 29777 solver.cpp:290] Iteration 180200 (6.26177 iter/s, 15.9699s/100 iter), loss = 1.19048
I0630 11:44:07.822608 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:44:07.822620 29777 sgd_solver.cpp:106] Iteration 180200, lr = 0.00436875
I0630 11:44:23.875380 29777 solver.cpp:290] Iteration 180300 (6.22963 iter/s, 16.0523s/100 iter), loss = 1.4881
I0630 11:44:23.875404 29777 solver.cpp:309]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0630 11:44:23.875414 29777 sgd_solver.cpp:106] Iteration 180300, lr = 0.00436562
I0630 11:44:39.891939 29777 solver.cpp:290] Iteration 180400 (6.24372 iter/s, 16.0161s/100 iter), loss = 1.55952
I0630 11:44:39.891984 29777 solver.cpp:309]     Train net output #0: loss = 2.07143 (* 1 = 2.07143 loss)
I0630 11:44:39.891993 29777 sgd_solver.cpp:106] Iteration 180400, lr = 0.0043625
I0630 11:44:55.966861 29777 solver.cpp:290] Iteration 180500 (6.22106 iter/s, 16.0744s/100 iter), loss = 1.60714
I0630 11:44:55.966882 29777 solver.cpp:309]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I0630 11:44:55.966888 29777 sgd_solver.cpp:106] Iteration 180500, lr = 0.00435938
I0630 11:45:12.018780 29777 solver.cpp:290] Iteration 180600 (6.22997 iter/s, 16.0515s/100 iter), loss = 0.916667
I0630 11:45:12.018880 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 11:45:12.018894 29777 sgd_solver.cpp:106] Iteration 180600, lr = 0.00435625
I0630 11:45:28.088238 29777 solver.cpp:290] Iteration 180700 (6.22319 iter/s, 16.0689s/100 iter), loss = 1.21429
I0630 11:45:28.088260 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 11:45:28.088270 29777 sgd_solver.cpp:106] Iteration 180700, lr = 0.00435313
I0630 11:45:44.120739 29777 solver.cpp:290] Iteration 180800 (6.23751 iter/s, 16.032s/100 iter), loss = 1.59524
I0630 11:45:44.120828 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 11:45:44.120852 29777 sgd_solver.cpp:106] Iteration 180800, lr = 0.00435
I0630 11:46:00.169137 29777 solver.cpp:290] Iteration 180900 (6.23136 iter/s, 16.0479s/100 iter), loss = 1.25
I0630 11:46:00.169183 29777 solver.cpp:309]     Train net output #0: loss = 0.857143 (* 1 = 0.857143 loss)
I0630 11:46:00.169209 29777 sgd_solver.cpp:106] Iteration 180900, lr = 0.00434688
I0630 11:46:16.132161 29777 solver.cpp:354] Sparsity after update:
I0630 11:46:16.157310 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:46:16.157337 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:46:16.157354 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:46:16.157361 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:46:16.157367 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:46:16.157372 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:46:16.157377 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:46:16.157387 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:46:16.157392 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:46:16.157399 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:46:16.157405 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:46:16.157411 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:46:16.157418 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:46:16.316292 29777 solver.cpp:290] Iteration 181000 (6.19323 iter/s, 16.1467s/100 iter), loss = 1.34524
I0630 11:46:16.316315 29777 solver.cpp:309]     Train net output #0: loss = 1.47619 (* 1 = 1.47619 loss)
I0630 11:46:16.316323 29777 sgd_solver.cpp:106] Iteration 181000, lr = 0.00434375
I0630 11:46:32.371177 29777 solver.cpp:290] Iteration 181100 (6.22881 iter/s, 16.0544s/100 iter), loss = 1.19048
I0630 11:46:32.371199 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 11:46:32.371225 29777 sgd_solver.cpp:106] Iteration 181100, lr = 0.00434062
I0630 11:46:48.394492 29777 solver.cpp:290] Iteration 181200 (6.24109 iter/s, 16.0229s/100 iter), loss = 1.28571
I0630 11:46:48.394596 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:46:48.394608 29777 sgd_solver.cpp:106] Iteration 181200, lr = 0.0043375
I0630 11:47:04.624711 29777 solver.cpp:290] Iteration 181300 (6.16155 iter/s, 16.2297s/100 iter), loss = 1.58333
I0630 11:47:04.624739 29777 solver.cpp:309]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0630 11:47:04.624749 29777 sgd_solver.cpp:106] Iteration 181300, lr = 0.00433438
I0630 11:47:20.897552 29777 solver.cpp:290] Iteration 181400 (6.14539 iter/s, 16.2724s/100 iter), loss = 1
I0630 11:47:20.897797 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:47:20.897902 29777 sgd_solver.cpp:106] Iteration 181400, lr = 0.00433125
I0630 11:47:37.033638 29777 solver.cpp:290] Iteration 181500 (6.19755 iter/s, 16.1354s/100 iter), loss = 1.46429
I0630 11:47:37.033670 29777 solver.cpp:309]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0630 11:47:37.033681 29777 sgd_solver.cpp:106] Iteration 181500, lr = 0.00432813
I0630 11:47:53.098098 29777 solver.cpp:290] Iteration 181600 (6.2251 iter/s, 16.064s/100 iter), loss = 1.16667
I0630 11:47:53.098192 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:47:53.098203 29777 sgd_solver.cpp:106] Iteration 181600, lr = 0.004325
I0630 11:48:09.166232 29777 solver.cpp:290] Iteration 181700 (6.22371 iter/s, 16.0676s/100 iter), loss = 1.2619
I0630 11:48:09.166290 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:48:09.166438 29777 sgd_solver.cpp:106] Iteration 181700, lr = 0.00432188
I0630 11:48:25.311166 29777 solver.cpp:290] Iteration 181800 (6.19409 iter/s, 16.1444s/100 iter), loss = 1.40476
I0630 11:48:25.311264 29777 solver.cpp:309]     Train net output #0: loss = 1.30952 (* 1 = 1.30952 loss)
I0630 11:48:25.311280 29777 sgd_solver.cpp:106] Iteration 181800, lr = 0.00431875
I0630 11:48:41.454052 29777 solver.cpp:290] Iteration 181900 (6.19489 iter/s, 16.1423s/100 iter), loss = 1.20238
I0630 11:48:41.454082 29777 solver.cpp:309]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0630 11:48:41.454090 29777 sgd_solver.cpp:106] Iteration 181900, lr = 0.00431562
I0630 11:48:57.334683 29777 solver.cpp:354] Sparsity after update:
I0630 11:48:57.335964 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:48:57.335971 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:48:57.335978 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:48:57.335980 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:48:57.335983 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:48:57.335985 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:48:57.335986 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:48:57.335988 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:48:57.335990 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:48:57.335992 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:48:57.335994 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:48:57.335996 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:48:57.335999 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:48:57.336084 29777 solver.cpp:471] Iteration 182000, Testing net (#0)
I0630 11:49:18.064666 29777 blocking_queue.cpp:50] Data layer prefetch queue empty
I0630 11:50:03.034739 29777 solver.cpp:544]     Test net output #0: accuracy/top1 = 0.5457
I0630 11:50:03.034792 29777 solver.cpp:544]     Test net output #1: accuracy/top5 = 0.784201
I0630 11:50:03.034799 29777 solver.cpp:544]     Test net output #2: loss = 1.62252 (* 1 = 1.62252 loss)
I0630 11:50:03.213630 29777 solver.cpp:290] Iteration 182000 (1.22313 iter/s, 81.7573s/100 iter), loss = 1.13095
I0630 11:50:03.213654 29777 solver.cpp:309]     Train net output #0: loss = 1.2619 (* 1 = 1.2619 loss)
I0630 11:50:03.213663 29777 sgd_solver.cpp:106] Iteration 182000, lr = 0.0043125
I0630 11:50:19.403471 29777 solver.cpp:290] Iteration 182100 (6.17689 iter/s, 16.1894s/100 iter), loss = 1.33333
I0630 11:50:19.403508 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:50:19.403519 29777 sgd_solver.cpp:106] Iteration 182100, lr = 0.00430938
I0630 11:50:35.632084 29777 solver.cpp:290] Iteration 182200 (6.16214 iter/s, 16.2281s/100 iter), loss = 1.02381
I0630 11:50:35.632159 29777 solver.cpp:309]     Train net output #0: loss = 1 (* 1 = 1 loss)
I0630 11:50:35.632179 29777 sgd_solver.cpp:106] Iteration 182200, lr = 0.00430625
I0630 11:50:51.780714 29777 solver.cpp:290] Iteration 182300 (6.19267 iter/s, 16.1481s/100 iter), loss = 1.25
I0630 11:50:51.780740 29777 solver.cpp:309]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0630 11:50:51.780750 29777 sgd_solver.cpp:106] Iteration 182300, lr = 0.00430313
I0630 11:51:07.962760 29777 solver.cpp:290] Iteration 182400 (6.17987 iter/s, 16.1816s/100 iter), loss = 1.46429
I0630 11:51:07.962836 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:51:07.962844 29777 sgd_solver.cpp:106] Iteration 182400, lr = 0.0043
I0630 11:51:24.084724 29777 solver.cpp:290] Iteration 182500 (6.20291 iter/s, 16.1215s/100 iter), loss = 1.15476
I0630 11:51:24.084748 29777 solver.cpp:309]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0630 11:51:24.084754 29777 sgd_solver.cpp:106] Iteration 182500, lr = 0.00429688
I0630 11:51:40.185528 29777 solver.cpp:290] Iteration 182600 (6.21105 iter/s, 16.1003s/100 iter), loss = 1.67857
I0630 11:51:40.185614 29777 solver.cpp:309]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0630 11:51:40.185638 29777 sgd_solver.cpp:106] Iteration 182600, lr = 0.00429375
I0630 11:51:56.406200 29777 solver.cpp:290] Iteration 182700 (6.16517 iter/s, 16.2201s/100 iter), loss = 1.41667
I0630 11:51:56.406239 29777 solver.cpp:309]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0630 11:51:56.406249 29777 sgd_solver.cpp:106] Iteration 182700, lr = 0.00429062
I0630 11:52:12.474715 29777 solver.cpp:290] Iteration 182800 (6.22354 iter/s, 16.068s/100 iter), loss = 1.42857
I0630 11:52:12.474849 29777 solver.cpp:309]     Train net output #0: loss = 1.35714 (* 1 = 1.35714 loss)
I0630 11:52:12.474880 29777 sgd_solver.cpp:106] Iteration 182800, lr = 0.0042875
I0630 11:52:28.511916 29777 solver.cpp:290] Iteration 182900 (6.23572 iter/s, 16.0366s/100 iter), loss = 1.36905
I0630 11:52:28.511942 29777 solver.cpp:309]     Train net output #0: loss = 1.14286 (* 1 = 1.14286 loss)
I0630 11:52:28.511951 29777 sgd_solver.cpp:106] Iteration 182900, lr = 0.00428437
I0630 11:52:44.412593 29777 solver.cpp:354] Sparsity after update:
I0630 11:52:44.433193 29777 net.cpp:1842] Num Params(11), Sparsity (zero_weights/count): 
I0630 11:52:44.433239 29777 net.cpp:1851] conv1a_param_0(0.405) 
I0630 11:52:44.433280 29777 net.cpp:1851] conv1b_param_0(0.725) 
I0630 11:52:44.433300 29777 net.cpp:1851] fc1000_param_0(0) 
I0630 11:52:44.433310 29777 net.cpp:1851] res2a_branch2a_param_0(0.81) 
I0630 11:52:44.433317 29777 net.cpp:1851] res2a_branch2b_param_0(0.81) 
I0630 11:52:44.433324 29777 net.cpp:1851] res3a_branch2a_param_0(0.81) 
I0630 11:52:44.433331 29777 net.cpp:1851] res3a_branch2b_param_0(0.81) 
I0630 11:52:44.433338 29777 net.cpp:1851] res4a_branch2a_param_0(0.81) 
I0630 11:52:44.433348 29777 net.cpp:1851] res4a_branch2b_param_0(0.81) 
I0630 11:52:44.433360 29777 net.cpp:1851] res5a_branch2a_param_0(0.81) 
I0630 11:52:44.433375 29777 net.cpp:1851] res5a_branch2b_param_0(0.81) 
I0630 11:52:44.433392 29777 net.cpp:1853] Total Sparsity (zero_weights/count) =  (1.9062e+06/2.86678e+06) 0.665
I0630 11:52:44.595221 29777 solver.cpp:290] Iteration 183000 (6.21781 iter/s, 16.0828s/100 iter), loss = 1.40476
I0630 11:52:44.595244 29777 solver.cpp:309]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0630 11:52:44.595250 29777 sgd_solver.cpp:106] Iteration 183000, lr = 0.00428125
I0630 11:53:01.157851 29777 solver.cpp:290] Iteration 183100 (6.03786 iter/s, 16.5622s/100 iter), loss = 1.40476
I0630 11:53:01.157876 29777 solver.cpp:309]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0630 11:53:01.157884 29777 sgd_solver.cpp:106] Iteration 183100, lr = 0.00427813
I0630 11:53:17.090247 29777 solver.cpp:290] Iteration 183200 (6.27671 iter/s, 15.9319s/100 iter), loss = 1.02381
I0630 11:53:17.090528 29777 solver.cpp:309]     Train net output #0: loss = 0.785714 (* 1 = 0.785714 loss)
I0630 11:53:17.090636 29777 sgd_solver.cpp:106] Iteration 183200, lr = 0.004275
I0630 11:53:33.088322 29777 solver.cpp:290] Iteration 183300 (6.25103 iter/s, 15.9974s/100 iter), loss = 1.20238
I0630 11:53:33.088346 29777 solver.cpp:309]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0630 11:53:33.088353 29777 sgd_solver.cpp:106] Iteration 183300, lr = 0.00427188
I0630 11:53:49.043234 29777 solver.cpp:290] Iteration 183400 (6.26784 iter/s, 15.9545s/100 iter), loss = 1.09524
I0630 11:53:49.043336 29777 solver.cpp:309]     Train net output #0: loss = 0.952381 (* 1 = 0.952381 loss)
I0630 11:53:49.043346 29777 sgd_solver.cpp:106] Iteration 183400, lr = 0.00426875
I0630 11:54:05.122162 29777 solver.cpp:290] Iteration 183500 (6.21953 iter/s, 16.0784s/100 iter), loss = 1.38095
I0630 11:54:05.122189 29777 solver.cpp:309]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I0630 11:54:05.122198 29777 sgd_solver.cpp:106] Iteration 183500, lr = 0.00426562
