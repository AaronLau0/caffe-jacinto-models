I0802 04:41:54.744052 18523 caffe.cpp:608] This is NVCaffe 0.16.3 started at Wed Aug  2 04:41:53 2017
I0802 04:41:54.746682 18523 caffe.cpp:611] CuDNN version: 6021
I0802 04:41:54.746700 18523 caffe.cpp:612] CuBLAS version: 8000
I0802 04:41:54.746706 18523 caffe.cpp:613] CUDA version: 8000
I0802 04:41:54.746712 18523 caffe.cpp:614] CUDA driver version: 8000
I0802 04:41:55.035533 18523 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0802 04:41:55.036105 18523 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0802 04:41:55.036630 18523 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0802 04:41:55.037153 18523 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0802 04:41:55.037161 18523 caffe.cpp:208] Using GPUs 0, 1, 2
I0802 04:41:55.037487 18523 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0802 04:41:55.037814 18523 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0802 04:41:55.038141 18523 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0802 04:41:55.059761 18523 solver.cpp:42] Solver data type: FLOAT
I0802 04:41:55.059816 18523 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt"
test_iter: 1000
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 160000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
iter_size: 2
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.01
sparsity_step_iter: 1000
sparsity_start_iter: 20000
sparsity_start_factor: 0
I0802 04:41:55.081804 18523 solver.cpp:77] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/train.prototxt
I0802 04:41:55.096571 18523 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0802 04:41:55.096627 18523 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0802 04:41:55.096788 18523 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:55.097769 18523 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 43
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0802 04:41:55.098340 18523 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:55.098373 18523 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:55.098393 18523 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0802 04:41:55.098412 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.099833 18523 net.cpp:184] Created Layer data (0)
I0802 04:41:55.099934 18523 net.cpp:530] data -> data
I0802 04:41:55.100013 18523 net.cpp:530] data -> label
I0802 04:41:55.100126 18523 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:55.100205 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:55.118032 18597 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:55.126688 18523 data_layer.cpp:184] [0] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:55.127013 18523 data_layer.cpp:208] [0] Output data size: 43, 3, 224, 224
I0802 04:41:55.127043 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:55.127130 18523 net.cpp:245] Setting up data
I0802 04:41:55.127171 18523 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 3 224 224 (6472704)
I0802 04:41:55.127203 18523 net.cpp:252] TRAIN Top shape for layer 0 'data' 43 (43)
I0802 04:41:55.127239 18523 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0802 04:41:55.127264 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.127348 18523 net.cpp:184] Created Layer data/bias (1)
I0802 04:41:55.127373 18523 net.cpp:561] data/bias <- data
I0802 04:41:55.127410 18523 net.cpp:530] data/bias -> data/bias
I0802 04:41:55.134845 18523 net.cpp:245] Setting up data/bias
I0802 04:41:55.134898 18523 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 43 3 224 224 (6472704)
I0802 04:41:55.134945 18523 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0802 04:41:55.134970 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.135027 18523 net.cpp:184] Created Layer conv1a (2)
I0802 04:41:55.135048 18523 net.cpp:561] conv1a <- data/bias
I0802 04:41:55.135069 18523 net.cpp:530] conv1a -> conv1a
I0802 04:41:55.951262 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 7.97G, req 0G)
I0802 04:41:55.951337 18523 net.cpp:245] Setting up conv1a
I0802 04:41:55.951364 18523 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 43 32 112 112 (17260544)
I0802 04:41:55.951407 18523 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0802 04:41:55.951439 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.951493 18523 net.cpp:184] Created Layer conv1a/bn (3)
I0802 04:41:55.951516 18523 net.cpp:561] conv1a/bn <- conv1a
I0802 04:41:55.951532 18523 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0802 04:41:55.954481 18523 net.cpp:245] Setting up conv1a/bn
I0802 04:41:55.954524 18523 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 43 32 112 112 (17260544)
I0802 04:41:55.954560 18523 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0802 04:41:55.954576 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.954607 18523 net.cpp:184] Created Layer conv1a/relu (4)
I0802 04:41:55.954632 18523 net.cpp:561] conv1a/relu <- conv1a
I0802 04:41:55.954653 18523 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0802 04:41:55.954716 18523 net.cpp:245] Setting up conv1a/relu
I0802 04:41:55.954748 18523 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 43 32 112 112 (17260544)
I0802 04:41:55.954766 18523 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0802 04:41:55.954779 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.954815 18523 net.cpp:184] Created Layer conv1b (5)
I0802 04:41:55.954840 18523 net.cpp:561] conv1b <- conv1a
I0802 04:41:55.954862 18523 net.cpp:530] conv1b -> conv1b
I0802 04:41:55.991631 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0G)
I0802 04:41:55.991649 18523 net.cpp:245] Setting up conv1b
I0802 04:41:55.991654 18523 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 43 32 112 112 (17260544)
I0802 04:41:55.991662 18523 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0802 04:41:55.991680 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.991693 18523 net.cpp:184] Created Layer conv1b/bn (6)
I0802 04:41:55.991699 18523 net.cpp:561] conv1b/bn <- conv1b
I0802 04:41:55.991704 18523 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0802 04:41:55.992389 18523 net.cpp:245] Setting up conv1b/bn
I0802 04:41:55.992398 18523 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 43 32 112 112 (17260544)
I0802 04:41:55.992403 18523 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0802 04:41:55.992406 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992410 18523 net.cpp:184] Created Layer conv1b/relu (7)
I0802 04:41:55.992413 18523 net.cpp:561] conv1b/relu <- conv1b
I0802 04:41:55.992414 18523 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0802 04:41:55.992419 18523 net.cpp:245] Setting up conv1b/relu
I0802 04:41:55.992421 18523 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 43 32 112 112 (17260544)
I0802 04:41:55.992424 18523 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0802 04:41:55.992425 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992434 18523 net.cpp:184] Created Layer pool1 (8)
I0802 04:41:55.992439 18523 net.cpp:561] pool1 <- conv1b
I0802 04:41:55.992444 18523 net.cpp:530] pool1 -> pool1
I0802 04:41:55.992521 18523 net.cpp:245] Setting up pool1
I0802 04:41:55.992525 18523 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 43 32 56 56 (4315136)
I0802 04:41:55.992528 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0802 04:41:55.992532 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:55.992540 18523 net.cpp:184] Created Layer res2a_branch2a (9)
I0802 04:41:55.992543 18523 net.cpp:561] res2a_branch2a <- pool1
I0802 04:41:55.992545 18523 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0802 04:41:56.017033 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.71G, req 0G)
I0802 04:41:56.017055 18523 net.cpp:245] Setting up res2a_branch2a
I0802 04:41:56.017060 18523 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 43 64 56 56 (8630272)
I0802 04:41:56.017071 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.017073 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017082 18523 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0802 04:41:56.017086 18523 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0802 04:41:56.017091 18523 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0802 04:41:56.017776 18523 net.cpp:245] Setting up res2a_branch2a/bn
I0802 04:41:56.017784 18523 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 43 64 56 56 (8630272)
I0802 04:41:56.017791 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.017793 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017797 18523 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0802 04:41:56.017801 18523 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0802 04:41:56.017802 18523 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0802 04:41:56.017807 18523 net.cpp:245] Setting up res2a_branch2a/relu
I0802 04:41:56.017808 18523 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 43 64 56 56 (8630272)
I0802 04:41:56.017810 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0802 04:41:56.017813 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.017823 18523 net.cpp:184] Created Layer res2a_branch2b (12)
I0802 04:41:56.017828 18523 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0802 04:41:56.017832 18523 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0802 04:41:56.030603 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.64G, req 0G)
I0802 04:41:56.030617 18523 net.cpp:245] Setting up res2a_branch2b
I0802 04:41:56.030622 18523 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 43 64 56 56 (8630272)
I0802 04:41:56.030627 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.030629 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.030635 18523 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0802 04:41:56.030638 18523 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0802 04:41:56.030640 18523 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0802 04:41:56.031788 18523 net.cpp:245] Setting up res2a_branch2b/bn
I0802 04:41:56.031796 18523 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 43 64 56 56 (8630272)
I0802 04:41:56.031803 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.031806 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031810 18523 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0802 04:41:56.031811 18523 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0802 04:41:56.031814 18523 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0802 04:41:56.031818 18523 net.cpp:245] Setting up res2a_branch2b/relu
I0802 04:41:56.031821 18523 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 43 64 56 56 (8630272)
I0802 04:41:56.031822 18523 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0802 04:41:56.031826 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031831 18523 net.cpp:184] Created Layer pool2 (15)
I0802 04:41:56.031834 18523 net.cpp:561] pool2 <- res2a_branch2b
I0802 04:41:56.031838 18523 net.cpp:530] pool2 -> pool2
I0802 04:41:56.031901 18523 net.cpp:245] Setting up pool2
I0802 04:41:56.031906 18523 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 43 64 28 28 (2157568)
I0802 04:41:56.031909 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0802 04:41:56.031911 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.031980 18523 net.cpp:184] Created Layer res3a_branch2a (16)
I0802 04:41:56.031985 18523 net.cpp:561] res3a_branch2a <- pool2
I0802 04:41:56.031987 18523 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0802 04:41:56.054648 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.58G, req 0G)
I0802 04:41:56.054661 18523 net.cpp:245] Setting up res3a_branch2a
I0802 04:41:56.054666 18523 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 43 128 28 28 (4315136)
I0802 04:41:56.054672 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.054674 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.054679 18523 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0802 04:41:56.054682 18523 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0802 04:41:56.054685 18523 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0802 04:41:56.055346 18523 net.cpp:245] Setting up res3a_branch2a/bn
I0802 04:41:56.055353 18523 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 43 128 28 28 (4315136)
I0802 04:41:56.055361 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.055364 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.055367 18523 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0802 04:41:56.055369 18523 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0802 04:41:56.055372 18523 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0802 04:41:56.055385 18523 net.cpp:245] Setting up res3a_branch2a/relu
I0802 04:41:56.055390 18523 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 43 128 28 28 (4315136)
I0802 04:41:56.055394 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0802 04:41:56.055399 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.055408 18523 net.cpp:184] Created Layer res3a_branch2b (19)
I0802 04:41:56.055413 18523 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0802 04:41:56.055414 18523 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0802 04:41:56.063125 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.54G, req 0G)
I0802 04:41:56.063136 18523 net.cpp:245] Setting up res3a_branch2b
I0802 04:41:56.063140 18523 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 43 128 28 28 (4315136)
I0802 04:41:56.063145 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.063148 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063153 18523 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0802 04:41:56.063154 18523 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0802 04:41:56.063158 18523 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0802 04:41:56.063789 18523 net.cpp:245] Setting up res3a_branch2b/bn
I0802 04:41:56.063797 18523 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 43 128 28 28 (4315136)
I0802 04:41:56.063803 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.063805 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063809 18523 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0802 04:41:56.063812 18523 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0802 04:41:56.063813 18523 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0802 04:41:56.063817 18523 net.cpp:245] Setting up res3a_branch2b/relu
I0802 04:41:56.063819 18523 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 43 128 28 28 (4315136)
I0802 04:41:56.063822 18523 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0802 04:41:56.063824 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063829 18523 net.cpp:184] Created Layer pool3 (22)
I0802 04:41:56.063834 18523 net.cpp:561] pool3 <- res3a_branch2b
I0802 04:41:56.063838 18523 net.cpp:530] pool3 -> pool3
I0802 04:41:56.063910 18523 net.cpp:245] Setting up pool3
I0802 04:41:56.063915 18523 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 43 128 14 14 (1078784)
I0802 04:41:56.063917 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0802 04:41:56.063920 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.063925 18523 net.cpp:184] Created Layer res4a_branch2a (23)
I0802 04:41:56.063927 18523 net.cpp:561] res4a_branch2a <- pool3
I0802 04:41:56.063930 18523 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0802 04:41:56.089606 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.51G, req 0G)
I0802 04:41:56.089617 18523 net.cpp:245] Setting up res4a_branch2a
I0802 04:41:56.089622 18523 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 43 256 14 14 (2157568)
I0802 04:41:56.089627 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.089629 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.089638 18523 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0802 04:41:56.089642 18523 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0802 04:41:56.089644 18523 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0802 04:41:56.090286 18523 net.cpp:245] Setting up res4a_branch2a/bn
I0802 04:41:56.090301 18523 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 43 256 14 14 (2157568)
I0802 04:41:56.090308 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.090311 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.090313 18523 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0802 04:41:56.090317 18523 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0802 04:41:56.090318 18523 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0802 04:41:56.090322 18523 net.cpp:245] Setting up res4a_branch2a/relu
I0802 04:41:56.090324 18523 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 43 256 14 14 (2157568)
I0802 04:41:56.090327 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0802 04:41:56.090328 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.090334 18523 net.cpp:184] Created Layer res4a_branch2b (26)
I0802 04:41:56.090338 18523 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0802 04:41:56.090342 18523 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0802 04:41:56.099535 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.48G, req 0G)
I0802 04:41:56.099546 18523 net.cpp:245] Setting up res4a_branch2b
I0802 04:41:56.099550 18523 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 43 256 14 14 (2157568)
I0802 04:41:56.099555 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.099557 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.099561 18523 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0802 04:41:56.099565 18523 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0802 04:41:56.099566 18523 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0802 04:41:56.100215 18523 net.cpp:245] Setting up res4a_branch2b/bn
I0802 04:41:56.100224 18523 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 43 256 14 14 (2157568)
I0802 04:41:56.100229 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.100232 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100235 18523 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0802 04:41:56.100239 18523 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0802 04:41:56.100240 18523 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0802 04:41:56.100244 18523 net.cpp:245] Setting up res4a_branch2b/relu
I0802 04:41:56.100246 18523 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 43 256 14 14 (2157568)
I0802 04:41:56.100248 18523 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0802 04:41:56.100250 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100255 18523 net.cpp:184] Created Layer pool4 (29)
I0802 04:41:56.100257 18523 net.cpp:561] pool4 <- res4a_branch2b
I0802 04:41:56.100261 18523 net.cpp:530] pool4 -> pool4
I0802 04:41:56.100327 18523 net.cpp:245] Setting up pool4
I0802 04:41:56.100332 18523 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 43 256 7 7 (539392)
I0802 04:41:56.100334 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0802 04:41:56.100337 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.100348 18523 net.cpp:184] Created Layer res5a_branch2a (30)
I0802 04:41:56.100350 18523 net.cpp:561] res5a_branch2a <- pool4
I0802 04:41:56.100353 18523 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0802 04:41:56.154194 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.45G, req 0G)
I0802 04:41:56.154266 18523 net.cpp:245] Setting up res5a_branch2a
I0802 04:41:56.154291 18523 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 43 512 7 7 (1078784)
I0802 04:41:56.154379 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.154412 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.154455 18523 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0802 04:41:56.154481 18523 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0802 04:41:56.154497 18523 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0802 04:41:56.157847 18523 net.cpp:245] Setting up res5a_branch2a/bn
I0802 04:41:56.157892 18523 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 43 512 7 7 (1078784)
I0802 04:41:56.157922 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.157937 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.157960 18523 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0802 04:41:56.157986 18523 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0802 04:41:56.158011 18523 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0802 04:41:56.158046 18523 net.cpp:245] Setting up res5a_branch2a/relu
I0802 04:41:56.158071 18523 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 43 512 7 7 (1078784)
I0802 04:41:56.158092 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0802 04:41:56.158112 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.158140 18523 net.cpp:184] Created Layer res5a_branch2b (33)
I0802 04:41:56.158156 18523 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0802 04:41:56.158182 18523 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0802 04:41:56.197304 18523 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 7.44G, req 0G)
I0802 04:41:56.197321 18523 net.cpp:245] Setting up res5a_branch2b
I0802 04:41:56.197329 18523 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 43 512 7 7 (1078784)
I0802 04:41:56.197352 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.197358 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.197373 18523 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0802 04:41:56.197378 18523 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0802 04:41:56.197382 18523 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0802 04:41:56.198104 18523 net.cpp:245] Setting up res5a_branch2b/bn
I0802 04:41:56.198112 18523 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 43 512 7 7 (1078784)
I0802 04:41:56.198120 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.198127 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198132 18523 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0802 04:41:56.198137 18523 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0802 04:41:56.198140 18523 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0802 04:41:56.198148 18523 net.cpp:245] Setting up res5a_branch2b/relu
I0802 04:41:56.198153 18523 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 43 512 7 7 (1078784)
I0802 04:41:56.198158 18523 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0802 04:41:56.198163 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198169 18523 net.cpp:184] Created Layer pool5 (36)
I0802 04:41:56.198173 18523 net.cpp:561] pool5 <- res5a_branch2b
I0802 04:41:56.198176 18523 net.cpp:530] pool5 -> pool5
I0802 04:41:56.198207 18523 net.cpp:245] Setting up pool5
I0802 04:41:56.198213 18523 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 43 512 1 1 (22016)
I0802 04:41:56.198216 18523 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0802 04:41:56.198228 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.198238 18523 net.cpp:184] Created Layer fc1000 (37)
I0802 04:41:56.198242 18523 net.cpp:561] fc1000 <- pool5
I0802 04:41:56.198246 18523 net.cpp:530] fc1000 -> fc1000
I0802 04:41:56.209369 18523 net.cpp:245] Setting up fc1000
I0802 04:41:56.209381 18523 net.cpp:252] TRAIN Top shape for layer 37 'fc1000' 43 1000 (43000)
I0802 04:41:56.209389 18523 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0802 04:41:56.209394 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.209408 18523 net.cpp:184] Created Layer loss (38)
I0802 04:41:56.209412 18523 net.cpp:561] loss <- fc1000
I0802 04:41:56.209416 18523 net.cpp:561] loss <- label
I0802 04:41:56.209424 18523 net.cpp:530] loss -> loss
I0802 04:41:56.224781 18523 net.cpp:245] Setting up loss
I0802 04:41:56.224810 18523 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0802 04:41:56.224827 18523 net.cpp:256]     with loss weight 1
I0802 04:41:56.224839 18523 net.cpp:323] loss needs backward computation.
I0802 04:41:56.224848 18523 net.cpp:323] fc1000 needs backward computation.
I0802 04:41:56.224853 18523 net.cpp:323] pool5 needs backward computation.
I0802 04:41:56.224858 18523 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0802 04:41:56.224861 18523 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0802 04:41:56.224865 18523 net.cpp:323] res5a_branch2b needs backward computation.
I0802 04:41:56.224870 18523 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0802 04:41:56.224874 18523 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0802 04:41:56.224887 18523 net.cpp:323] res5a_branch2a needs backward computation.
I0802 04:41:56.224894 18523 net.cpp:323] pool4 needs backward computation.
I0802 04:41:56.224897 18523 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0802 04:41:56.224902 18523 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0802 04:41:56.224905 18523 net.cpp:323] res4a_branch2b needs backward computation.
I0802 04:41:56.224910 18523 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0802 04:41:56.224915 18523 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0802 04:41:56.224920 18523 net.cpp:323] res4a_branch2a needs backward computation.
I0802 04:41:56.224922 18523 net.cpp:323] pool3 needs backward computation.
I0802 04:41:56.224928 18523 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0802 04:41:56.224932 18523 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0802 04:41:56.224936 18523 net.cpp:323] res3a_branch2b needs backward computation.
I0802 04:41:56.224938 18523 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0802 04:41:56.224942 18523 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0802 04:41:56.224946 18523 net.cpp:323] res3a_branch2a needs backward computation.
I0802 04:41:56.224951 18523 net.cpp:323] pool2 needs backward computation.
I0802 04:41:56.224954 18523 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0802 04:41:56.224958 18523 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0802 04:41:56.224962 18523 net.cpp:323] res2a_branch2b needs backward computation.
I0802 04:41:56.224967 18523 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0802 04:41:56.224970 18523 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0802 04:41:56.224974 18523 net.cpp:323] res2a_branch2a needs backward computation.
I0802 04:41:56.224979 18523 net.cpp:323] pool1 needs backward computation.
I0802 04:41:56.224983 18523 net.cpp:323] conv1b/relu needs backward computation.
I0802 04:41:56.224987 18523 net.cpp:323] conv1b/bn needs backward computation.
I0802 04:41:56.224992 18523 net.cpp:323] conv1b needs backward computation.
I0802 04:41:56.224997 18523 net.cpp:323] conv1a/relu needs backward computation.
I0802 04:41:56.225000 18523 net.cpp:323] conv1a/bn needs backward computation.
I0802 04:41:56.225013 18523 net.cpp:323] conv1a needs backward computation.
I0802 04:41:56.225018 18523 net.cpp:325] data/bias does not need backward computation.
I0802 04:41:56.225023 18523 net.cpp:325] data does not need backward computation.
I0802 04:41:56.225028 18523 net.cpp:367] This network produces output loss
I0802 04:41:56.225066 18523 net.cpp:389] Top memory (TRAIN) required for data: 802615296 diff: 802615304
I0802 04:41:56.225070 18523 net.cpp:392] Bottom memory (TRAIN) required for data: 802615296 diff: 802615296
I0802 04:41:56.225073 18523 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 535076864 diff: 535076864
I0802 04:41:56.225077 18523 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0802 04:41:56.225081 18523 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0802 04:41:56.225085 18523 net.cpp:407] Network initialization done.
I0802 04:41:56.225637 18523 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:56.225692 18523 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:56.225821 18523 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0802 04:41:56.225949 18523 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.225955 18523 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.225960 18523 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0802 04:41:56.225965 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.225980 18523 net.cpp:184] Created Layer data (0)
I0802 04:41:56.225985 18523 net.cpp:530] data -> data
I0802 04:41:56.225989 18523 net.cpp:530] data -> label
I0802 04:41:56.225998 18523 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:56.226012 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.229346 18619 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:56.230068 18523 data_layer.cpp:184] (0) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:56.230159 18523 data_layer.cpp:208] (0) Output data size: 17, 3, 224, 224
I0802 04:41:56.230165 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.230185 18523 net.cpp:245] Setting up data
I0802 04:41:56.230191 18523 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 224 224 (2558976)
I0802 04:41:56.230195 18523 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0802 04:41:56.230199 18523 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0802 04:41:56.230214 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230226 18523 net.cpp:184] Created Layer label_data_1_split (1)
I0802 04:41:56.230231 18523 net.cpp:561] label_data_1_split <- label
I0802 04:41:56.230237 18523 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0802 04:41:56.230243 18523 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0802 04:41:56.230248 18523 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0802 04:41:56.230316 18523 net.cpp:245] Setting up label_data_1_split
I0802 04:41:56.230322 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230326 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230331 18523 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0802 04:41:56.230335 18523 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0802 04:41:56.230340 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230347 18523 net.cpp:184] Created Layer data/bias (2)
I0802 04:41:56.230350 18523 net.cpp:561] data/bias <- data
I0802 04:41:56.230355 18523 net.cpp:530] data/bias -> data/bias
I0802 04:41:56.230547 18523 net.cpp:245] Setting up data/bias
I0802 04:41:56.230556 18523 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 224 224 (2558976)
I0802 04:41:56.230563 18523 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0802 04:41:56.230567 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.230579 18523 net.cpp:184] Created Layer conv1a (3)
I0802 04:41:56.230583 18523 net.cpp:561] conv1a <- data/bias
I0802 04:41:56.230587 18523 net.cpp:530] conv1a -> conv1a
I0802 04:41:56.230909 18620 data_layer.cpp:97] (0) Parser threads: 1
I0802 04:41:56.230918 18620 data_layer.cpp:99] (0) Transformer threads: 1
I0802 04:41:56.237251 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.4G, req 0G)
I0802 04:41:56.237270 18523 net.cpp:245] Setting up conv1a
I0802 04:41:56.237277 18523 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 112 112 (6823936)
I0802 04:41:56.237289 18523 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0802 04:41:56.237304 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.237321 18523 net.cpp:184] Created Layer conv1a/bn (4)
I0802 04:41:56.237326 18523 net.cpp:561] conv1a/bn <- conv1a
I0802 04:41:56.237332 18523 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0802 04:41:56.238095 18523 net.cpp:245] Setting up conv1a/bn
I0802 04:41:56.238103 18523 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 112 112 (6823936)
I0802 04:41:56.238113 18523 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0802 04:41:56.238117 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.238123 18523 net.cpp:184] Created Layer conv1a/relu (5)
I0802 04:41:56.238127 18523 net.cpp:561] conv1a/relu <- conv1a
I0802 04:41:56.238132 18523 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0802 04:41:56.238138 18523 net.cpp:245] Setting up conv1a/relu
I0802 04:41:56.238143 18523 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 112 112 (6823936)
I0802 04:41:56.238147 18523 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0802 04:41:56.238152 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.238162 18523 net.cpp:184] Created Layer conv1b (6)
I0802 04:41:56.238165 18523 net.cpp:561] conv1b <- conv1a
I0802 04:41:56.238169 18523 net.cpp:530] conv1b -> conv1b
I0802 04:41:56.243749 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:56.243764 18523 net.cpp:245] Setting up conv1b
I0802 04:41:56.243772 18523 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 112 112 (6823936)
I0802 04:41:56.243790 18523 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0802 04:41:56.243795 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.243805 18523 net.cpp:184] Created Layer conv1b/bn (7)
I0802 04:41:56.243809 18523 net.cpp:561] conv1b/bn <- conv1b
I0802 04:41:56.243814 18523 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0802 04:41:56.244539 18523 net.cpp:245] Setting up conv1b/bn
I0802 04:41:56.244547 18523 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 112 112 (6823936)
I0802 04:41:56.244556 18523 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0802 04:41:56.244560 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244565 18523 net.cpp:184] Created Layer conv1b/relu (8)
I0802 04:41:56.244570 18523 net.cpp:561] conv1b/relu <- conv1b
I0802 04:41:56.244575 18523 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0802 04:41:56.244580 18523 net.cpp:245] Setting up conv1b/relu
I0802 04:41:56.244585 18523 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 112 112 (6823936)
I0802 04:41:56.244590 18523 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0802 04:41:56.244593 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244601 18523 net.cpp:184] Created Layer pool1 (9)
I0802 04:41:56.244604 18523 net.cpp:561] pool1 <- conv1b
I0802 04:41:56.244609 18523 net.cpp:530] pool1 -> pool1
I0802 04:41:56.244684 18523 net.cpp:245] Setting up pool1
I0802 04:41:56.244690 18523 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 56 56 (1705984)
I0802 04:41:56.244695 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0802 04:41:56.244700 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.244709 18523 net.cpp:184] Created Layer res2a_branch2a (10)
I0802 04:41:56.244712 18523 net.cpp:561] res2a_branch2a <- pool1
I0802 04:41:56.244716 18523 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0802 04:41:56.250139 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.34G, req 0G)
I0802 04:41:56.250156 18523 net.cpp:245] Setting up res2a_branch2a
I0802 04:41:56.250164 18523 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 56 56 (3411968)
I0802 04:41:56.250175 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.250190 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.250201 18523 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0802 04:41:56.250206 18523 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0802 04:41:56.250211 18523 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0802 04:41:56.252259 18523 net.cpp:245] Setting up res2a_branch2a/bn
I0802 04:41:56.252272 18523 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 56 56 (3411968)
I0802 04:41:56.252284 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.252288 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.252295 18523 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0802 04:41:56.252298 18523 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0802 04:41:56.252303 18523 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0802 04:41:56.252312 18523 net.cpp:245] Setting up res2a_branch2a/relu
I0802 04:41:56.252317 18523 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 56 56 (3411968)
I0802 04:41:56.252322 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0802 04:41:56.252326 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.252338 18523 net.cpp:184] Created Layer res2a_branch2b (13)
I0802 04:41:56.252351 18523 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0802 04:41:56.252355 18523 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0802 04:41:56.256112 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.32G, req 0G)
I0802 04:41:56.256129 18523 net.cpp:245] Setting up res2a_branch2b
I0802 04:41:56.256137 18523 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 56 56 (3411968)
I0802 04:41:56.256146 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.256151 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.256160 18523 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0802 04:41:56.256165 18523 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0802 04:41:56.256168 18523 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0802 04:41:56.256968 18523 net.cpp:245] Setting up res2a_branch2b/bn
I0802 04:41:56.256978 18523 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 56 56 (3411968)
I0802 04:41:56.256989 18523 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.256994 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.256999 18523 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0802 04:41:56.257004 18523 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0802 04:41:56.257007 18523 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0802 04:41:56.257014 18523 net.cpp:245] Setting up res2a_branch2b/relu
I0802 04:41:56.257019 18523 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 56 56 (3411968)
I0802 04:41:56.257025 18523 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0802 04:41:56.257028 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.257036 18523 net.cpp:184] Created Layer pool2 (16)
I0802 04:41:56.257040 18523 net.cpp:561] pool2 <- res2a_branch2b
I0802 04:41:56.257043 18523 net.cpp:530] pool2 -> pool2
I0802 04:41:56.257115 18523 net.cpp:245] Setting up pool2
I0802 04:41:56.257122 18523 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 28 28 (852992)
I0802 04:41:56.257127 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0802 04:41:56.257131 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.257141 18523 net.cpp:184] Created Layer res3a_branch2a (17)
I0802 04:41:56.257145 18523 net.cpp:561] res3a_branch2a <- pool2
I0802 04:41:56.257149 18523 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0802 04:41:56.264302 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.31G, req 0G)
I0802 04:41:56.264324 18523 net.cpp:245] Setting up res3a_branch2a
I0802 04:41:56.264333 18523 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 28 28 (1705984)
I0802 04:41:56.264343 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.264349 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.264360 18523 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0802 04:41:56.264366 18523 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0802 04:41:56.264371 18523 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0802 04:41:56.265467 18523 net.cpp:245] Setting up res3a_branch2a/bn
I0802 04:41:56.265480 18523 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 28 28 (1705984)
I0802 04:41:56.265493 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.265498 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.265504 18523 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0802 04:41:56.265509 18523 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0802 04:41:56.265513 18523 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0802 04:41:56.265533 18523 net.cpp:245] Setting up res3a_branch2a/relu
I0802 04:41:56.265540 18523 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 28 28 (1705984)
I0802 04:41:56.265544 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0802 04:41:56.265548 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.265560 18523 net.cpp:184] Created Layer res3a_branch2b (20)
I0802 04:41:56.265564 18523 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0802 04:41:56.265569 18523 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0802 04:41:56.269692 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.3G, req 0G)
I0802 04:41:56.269707 18523 net.cpp:245] Setting up res3a_branch2b
I0802 04:41:56.269714 18523 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 28 28 (1705984)
I0802 04:41:56.269721 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.269726 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.269743 18523 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0802 04:41:56.269749 18523 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0802 04:41:56.269754 18523 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0802 04:41:56.270772 18523 net.cpp:245] Setting up res3a_branch2b/bn
I0802 04:41:56.270784 18523 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 28 28 (1705984)
I0802 04:41:56.270794 18523 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.270799 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270805 18523 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0802 04:41:56.270809 18523 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0802 04:41:56.270813 18523 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0802 04:41:56.270822 18523 net.cpp:245] Setting up res3a_branch2b/relu
I0802 04:41:56.270826 18523 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 28 28 (1705984)
I0802 04:41:56.270831 18523 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0802 04:41:56.270835 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270843 18523 net.cpp:184] Created Layer pool3 (23)
I0802 04:41:56.270848 18523 net.cpp:561] pool3 <- res3a_branch2b
I0802 04:41:56.270853 18523 net.cpp:530] pool3 -> pool3
I0802 04:41:56.270957 18523 net.cpp:245] Setting up pool3
I0802 04:41:56.270967 18523 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 14 14 (426496)
I0802 04:41:56.270972 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0802 04:41:56.270975 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.270992 18523 net.cpp:184] Created Layer res4a_branch2a (24)
I0802 04:41:56.270997 18523 net.cpp:561] res4a_branch2a <- pool3
I0802 04:41:56.271003 18523 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0802 04:41:56.283207 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.29G, req 0G)
I0802 04:41:56.283224 18523 net.cpp:245] Setting up res4a_branch2a
I0802 04:41:56.283229 18523 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 14 14 (852992)
I0802 04:41:56.283236 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.283239 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.283247 18523 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0802 04:41:56.283251 18523 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0802 04:41:56.283253 18523 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0802 04:41:56.283978 18523 net.cpp:245] Setting up res4a_branch2a/bn
I0802 04:41:56.283996 18523 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 14 14 (852992)
I0802 04:41:56.284003 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.284004 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.284008 18523 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0802 04:41:56.284010 18523 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0802 04:41:56.284013 18523 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0802 04:41:56.284018 18523 net.cpp:245] Setting up res4a_branch2a/relu
I0802 04:41:56.284020 18523 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 14 14 (852992)
I0802 04:41:56.284023 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0802 04:41:56.284025 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.284031 18523 net.cpp:184] Created Layer res4a_branch2b (27)
I0802 04:41:56.284034 18523 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0802 04:41:56.284036 18523 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0802 04:41:56.290033 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.28G, req 0G)
I0802 04:41:56.290050 18523 net.cpp:245] Setting up res4a_branch2b
I0802 04:41:56.290056 18523 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 14 14 (852992)
I0802 04:41:56.290065 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.290068 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.290077 18523 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0802 04:41:56.290081 18523 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0802 04:41:56.290086 18523 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0802 04:41:56.290952 18523 net.cpp:245] Setting up res4a_branch2b/bn
I0802 04:41:56.290962 18523 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 14 14 (852992)
I0802 04:41:56.290968 18523 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.290973 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.290977 18523 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0802 04:41:56.290980 18523 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0802 04:41:56.290983 18523 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0802 04:41:56.290988 18523 net.cpp:245] Setting up res4a_branch2b/relu
I0802 04:41:56.290992 18523 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 14 14 (852992)
I0802 04:41:56.290994 18523 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0802 04:41:56.290997 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.291002 18523 net.cpp:184] Created Layer pool4 (30)
I0802 04:41:56.291004 18523 net.cpp:561] pool4 <- res4a_branch2b
I0802 04:41:56.291007 18523 net.cpp:530] pool4 -> pool4
I0802 04:41:56.291079 18523 net.cpp:245] Setting up pool4
I0802 04:41:56.291082 18523 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 7 7 (213248)
I0802 04:41:56.291085 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0802 04:41:56.291087 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.291095 18523 net.cpp:184] Created Layer res5a_branch2a (31)
I0802 04:41:56.291098 18523 net.cpp:561] res5a_branch2a <- pool4
I0802 04:41:56.291100 18523 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0802 04:41:56.321835 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.28G, req 0G)
I0802 04:41:56.321854 18523 net.cpp:245] Setting up res5a_branch2a
I0802 04:41:56.321861 18523 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 7 7 (426496)
I0802 04:41:56.321878 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0802 04:41:56.321883 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.321893 18523 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0802 04:41:56.321897 18523 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0802 04:41:56.321900 18523 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0802 04:41:56.322690 18523 net.cpp:245] Setting up res5a_branch2a/bn
I0802 04:41:56.322698 18523 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 7 7 (426496)
I0802 04:41:56.322705 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0802 04:41:56.322710 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.322713 18523 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0802 04:41:56.322716 18523 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0802 04:41:56.322718 18523 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0802 04:41:56.322723 18523 net.cpp:245] Setting up res5a_branch2a/relu
I0802 04:41:56.322726 18523 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 7 7 (426496)
I0802 04:41:56.322728 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0802 04:41:56.322731 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.322741 18523 net.cpp:184] Created Layer res5a_branch2b (34)
I0802 04:41:56.322744 18523 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0802 04:41:56.322747 18523 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0802 04:41:56.339610 18523 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.27G, req 0G)
I0802 04:41:56.339627 18523 net.cpp:245] Setting up res5a_branch2b
I0802 04:41:56.339632 18523 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 7 7 (426496)
I0802 04:41:56.339642 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0802 04:41:56.339645 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.339653 18523 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0802 04:41:56.339656 18523 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0802 04:41:56.339660 18523 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0802 04:41:56.340412 18523 net.cpp:245] Setting up res5a_branch2b/bn
I0802 04:41:56.340420 18523 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 7 7 (426496)
I0802 04:41:56.340426 18523 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0802 04:41:56.340430 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340438 18523 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0802 04:41:56.340441 18523 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0802 04:41:56.340443 18523 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0802 04:41:56.340447 18523 net.cpp:245] Setting up res5a_branch2b/relu
I0802 04:41:56.340451 18523 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 7 7 (426496)
I0802 04:41:56.340452 18523 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0802 04:41:56.340454 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340458 18523 net.cpp:184] Created Layer pool5 (37)
I0802 04:41:56.340461 18523 net.cpp:561] pool5 <- res5a_branch2b
I0802 04:41:56.340463 18523 net.cpp:530] pool5 -> pool5
I0802 04:41:56.340494 18523 net.cpp:245] Setting up pool5
I0802 04:41:56.340499 18523 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0802 04:41:56.340502 18523 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0802 04:41:56.340504 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.340519 18523 net.cpp:184] Created Layer fc1000 (38)
I0802 04:41:56.340522 18523 net.cpp:561] fc1000 <- pool5
I0802 04:41:56.340524 18523 net.cpp:530] fc1000 -> fc1000
I0802 04:41:56.351748 18523 net.cpp:245] Setting up fc1000
I0802 04:41:56.351769 18523 net.cpp:252] TEST Top shape for layer 38 'fc1000' 17 1000 (17000)
I0802 04:41:56.351778 18523 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0802 04:41:56.351780 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.351785 18523 net.cpp:184] Created Layer fc1000_fc1000_0_split (39)
I0802 04:41:56.351788 18523 net.cpp:561] fc1000_fc1000_0_split <- fc1000
I0802 04:41:56.351793 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0802 04:41:56.351795 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0802 04:41:56.351799 18523 net.cpp:530] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0802 04:41:56.351877 18523 net.cpp:245] Setting up fc1000_fc1000_0_split
I0802 04:41:56.351882 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351886 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351888 18523 net.cpp:252] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 17 1000 (17000)
I0802 04:41:56.351891 18523 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0802 04:41:56.351893 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.351900 18523 net.cpp:184] Created Layer loss (40)
I0802 04:41:56.351903 18523 net.cpp:561] loss <- fc1000_fc1000_0_split_0
I0802 04:41:56.351905 18523 net.cpp:561] loss <- label_data_1_split_0
I0802 04:41:56.351909 18523 net.cpp:530] loss -> loss
I0802 04:41:56.352123 18523 net.cpp:245] Setting up loss
I0802 04:41:56.352131 18523 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0802 04:41:56.352133 18523 net.cpp:256]     with loss weight 1
I0802 04:41:56.352139 18523 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0802 04:41:56.352143 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.352156 18523 net.cpp:184] Created Layer accuracy/top1 (41)
I0802 04:41:56.352160 18523 net.cpp:561] accuracy/top1 <- fc1000_fc1000_0_split_1
I0802 04:41:56.352165 18523 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0802 04:41:56.352169 18523 net.cpp:530] accuracy/top1 -> accuracy/top1
I0802 04:41:56.352174 18523 net.cpp:245] Setting up accuracy/top1
I0802 04:41:56.352176 18523 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0802 04:41:56.352180 18523 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0802 04:41:56.352181 18523 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0802 04:41:56.352187 18523 net.cpp:184] Created Layer accuracy/top5 (42)
I0802 04:41:56.352190 18523 net.cpp:561] accuracy/top5 <- fc1000_fc1000_0_split_2
I0802 04:41:56.352192 18523 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0802 04:41:56.352195 18523 net.cpp:530] accuracy/top5 -> accuracy/top5
I0802 04:41:56.352198 18523 net.cpp:245] Setting up accuracy/top5
I0802 04:41:56.352201 18523 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0802 04:41:56.352203 18523 net.cpp:325] accuracy/top5 does not need backward computation.
I0802 04:41:56.352206 18523 net.cpp:325] accuracy/top1 does not need backward computation.
I0802 04:41:56.352210 18523 net.cpp:323] loss needs backward computation.
I0802 04:41:56.352211 18523 net.cpp:323] fc1000_fc1000_0_split needs backward computation.
I0802 04:41:56.352214 18523 net.cpp:323] fc1000 needs backward computation.
I0802 04:41:56.352216 18523 net.cpp:323] pool5 needs backward computation.
I0802 04:41:56.352219 18523 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0802 04:41:56.352234 18523 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0802 04:41:56.352237 18523 net.cpp:323] res5a_branch2b needs backward computation.
I0802 04:41:56.352241 18523 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0802 04:41:56.352242 18523 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0802 04:41:56.352246 18523 net.cpp:323] res5a_branch2a needs backward computation.
I0802 04:41:56.352247 18523 net.cpp:323] pool4 needs backward computation.
I0802 04:41:56.352250 18523 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0802 04:41:56.352252 18523 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0802 04:41:56.352253 18523 net.cpp:323] res4a_branch2b needs backward computation.
I0802 04:41:56.352257 18523 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0802 04:41:56.352258 18523 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0802 04:41:56.352260 18523 net.cpp:323] res4a_branch2a needs backward computation.
I0802 04:41:56.352263 18523 net.cpp:323] pool3 needs backward computation.
I0802 04:41:56.352265 18523 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0802 04:41:56.352268 18523 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0802 04:41:56.352270 18523 net.cpp:323] res3a_branch2b needs backward computation.
I0802 04:41:56.352272 18523 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0802 04:41:56.352275 18523 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0802 04:41:56.352278 18523 net.cpp:323] res3a_branch2a needs backward computation.
I0802 04:41:56.352280 18523 net.cpp:323] pool2 needs backward computation.
I0802 04:41:56.352283 18523 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0802 04:41:56.352285 18523 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0802 04:41:56.352288 18523 net.cpp:323] res2a_branch2b needs backward computation.
I0802 04:41:56.352290 18523 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0802 04:41:56.352293 18523 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0802 04:41:56.352295 18523 net.cpp:323] res2a_branch2a needs backward computation.
I0802 04:41:56.352298 18523 net.cpp:323] pool1 needs backward computation.
I0802 04:41:56.352300 18523 net.cpp:323] conv1b/relu needs backward computation.
I0802 04:41:56.352303 18523 net.cpp:323] conv1b/bn needs backward computation.
I0802 04:41:56.352304 18523 net.cpp:323] conv1b needs backward computation.
I0802 04:41:56.352308 18523 net.cpp:323] conv1a/relu needs backward computation.
I0802 04:41:56.352309 18523 net.cpp:323] conv1a/bn needs backward computation.
I0802 04:41:56.352313 18523 net.cpp:323] conv1a needs backward computation.
I0802 04:41:56.352314 18523 net.cpp:325] data/bias does not need backward computation.
I0802 04:41:56.352319 18523 net.cpp:325] label_data_1_split does not need backward computation.
I0802 04:41:56.352321 18523 net.cpp:325] data does not need backward computation.
I0802 04:41:56.352322 18523 net.cpp:367] This network produces output accuracy/top1
I0802 04:41:56.352325 18523 net.cpp:367] This network produces output accuracy/top5
I0802 04:41:56.352327 18523 net.cpp:367] This network produces output loss
I0802 04:41:56.352365 18523 net.cpp:389] Top memory (TEST) required for data: 317313024 diff: 8
I0802 04:41:56.352368 18523 net.cpp:392] Bottom memory (TEST) required for data: 317313024 diff: 317313024
I0802 04:41:56.352370 18523 net.cpp:395] Shared (in-place) memory (TEST) by data: 211542016 diff: 211542016
I0802 04:41:56.352372 18523 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0802 04:41:56.352375 18523 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0802 04:41:56.352376 18523 net.cpp:407] Network initialization done.
I0802 04:41:56.352443 18523 solver.cpp:56] Solver scaffolding done.
I0802 04:41:56.356739 18523 caffe.cpp:137] Finetuning from training/imagenet_jacintonet11v2_2017-08-01_15-21-31/initial/imagenet_jacintonet11v2_iter_320000.caffemodel
I0802 04:41:56.362118 18523 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0802 04:41:56.362149 18523 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0802 04:41:56.362196 18523 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0802 04:41:56.362211 18523 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362540 18523 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0802 04:41:56.362545 18523 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0802 04:41:56.362553 18523 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362705 18523 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0802 04:41:56.362710 18523 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0802 04:41:56.362712 18523 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.362727 18523 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.362885 18523 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.362890 18523 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.362901 18523 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363047 18523 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363051 18523 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0802 04:41:56.363054 18523 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.363090 18523 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363229 18523 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.363234 18523 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.363255 18523 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363373 18523 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363376 18523 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0802 04:41:56.363379 18523 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.363488 18523 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363612 18523 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.363616 18523 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.363672 18523 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.363793 18523 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.363797 18523 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0802 04:41:56.363801 18523 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.364166 18523 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.364302 18523 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.364306 18523 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.364487 18523 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.364608 18523 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.364611 18523 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0802 04:41:56.364614 18523 net.cpp:1089] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0802 04:41:56.364732 18523 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0802 04:41:56.367926 18523 net.cpp:1089] Copying source layer data Type:Data #blobs=0
I0802 04:41:56.367944 18523 net.cpp:1089] Copying source layer data/bias Type:Bias #blobs=1
I0802 04:41:56.367967 18523 net.cpp:1089] Copying source layer conv1a Type:Convolution #blobs=2
I0802 04:41:56.367993 18523 net.cpp:1089] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368239 18523 net.cpp:1089] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0802 04:41:56.368243 18523 net.cpp:1089] Copying source layer conv1b Type:Convolution #blobs=2
I0802 04:41:56.368252 18523 net.cpp:1089] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368402 18523 net.cpp:1089] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0802 04:41:56.368407 18523 net.cpp:1089] Copying source layer pool1 Type:Pooling #blobs=0
I0802 04:41:56.368408 18523 net.cpp:1089] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.368424 18523 net.cpp:1089] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368576 18523 net.cpp:1089] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.368579 18523 net.cpp:1089] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.368592 18523 net.cpp:1089] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368734 18523 net.cpp:1089] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.368738 18523 net.cpp:1089] Copying source layer pool2 Type:Pooling #blobs=0
I0802 04:41:56.368741 18523 net.cpp:1089] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.368777 18523 net.cpp:1089] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.368927 18523 net.cpp:1089] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.368932 18523 net.cpp:1089] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.368953 18523 net.cpp:1089] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369074 18523 net.cpp:1089] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.369078 18523 net.cpp:1089] Copying source layer pool3 Type:Pooling #blobs=0
I0802 04:41:56.369081 18523 net.cpp:1089] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.369191 18523 net.cpp:1089] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369312 18523 net.cpp:1089] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.369316 18523 net.cpp:1089] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.369371 18523 net.cpp:1089] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369493 18523 net.cpp:1089] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.369496 18523 net.cpp:1089] Copying source layer pool4 Type:Pooling #blobs=0
I0802 04:41:56.369498 18523 net.cpp:1089] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0802 04:41:56.369860 18523 net.cpp:1089] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0802 04:41:56.369983 18523 net.cpp:1089] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0802 04:41:56.369987 18523 net.cpp:1089] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0802 04:41:56.370151 18523 net.cpp:1089] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0802 04:41:56.370267 18523 net.cpp:1089] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0802 04:41:56.370272 18523 net.cpp:1089] Copying source layer pool5 Type:Pooling #blobs=0
I0802 04:41:56.370275 18523 net.cpp:1089] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0802 04:41:56.370419 18523 net.cpp:1089] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0802 04:41:56.370479 18523 parallel.cpp:108] [0 - 0] P2pSync adding callback
I0802 04:41:56.370484 18523 parallel.cpp:108] [1 - 1] P2pSync adding callback
I0802 04:41:56.370487 18523 parallel.cpp:108] [2 - 2] P2pSync adding callback
I0802 04:41:56.370488 18523 parallel.cpp:61] Starting Optimization
I0802 04:41:56.370491 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0802 04:41:56.370517 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.370543 18523 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.371220 18636 device_alternate.hpp:116] NVML initialized on thread 139687390533376
I0802 04:41:56.399471 18636 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0802 04:41:56.399533 18637 device_alternate.hpp:116] NVML initialized on thread 139687382140672
I0802 04:41:56.400754 18637 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0802 04:41:56.400799 18638 device_alternate.hpp:116] NVML initialized on thread 139687373747968
I0802 04:41:56.401738 18638 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0802 04:41:56.405870 18637 solver.cpp:42] Solver data type: FLOAT
W0802 04:41:56.406304 18637 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:56.406393 18637 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.406399 18637 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.406435 18637 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:56.406450 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.410317 18638 solver.cpp:42] Solver data type: FLOAT
W0802 04:41:56.410688 18638 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 128 to 129
I0802 04:41:56.410758 18638 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:56.410761 18638 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:56.410786 18638 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 43
I0802 04:41:56.410797 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.411038 18639 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:56.411900 18640 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0802 04:41:56.413580 18637 data_layer.cpp:184] [1] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:56.413950 18638 data_layer.cpp:184] [2] ReshapePrefetch 43, 3, 224, 224
I0802 04:41:56.414046 18637 data_layer.cpp:208] [1] Output data size: 43, 3, 224, 224
I0802 04:41:56.414052 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:56.414108 18638 data_layer.cpp:208] [2] Output data size: 43, 3, 224, 224
I0802 04:41:56.414117 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:56.871357 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0802 04:41:56.899570 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.06G, req 0G)
I0802 04:41:56.900894 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0802 04:41:56.928280 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.92G, req 0G)
I0802 04:41:56.929008 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0802 04:41:56.945242 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0802 04:41:56.957072 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.81G, req 0G)
I0802 04:41:56.970396 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0802 04:41:56.972242 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.74G, req 0G)
I0802 04:41:56.980752 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.64G, req 0G)
I0802 04:41:56.998411 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.68G, req 0G)
I0802 04:41:57.013320 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.64G, req 0G)
I0802 04:41:57.013525 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.6G, req 0G)
I0802 04:41:57.024993 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0802 04:41:57.043541 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.6G, req 0G)
I0802 04:41:57.054344 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.58G, req 0G)
I0802 04:41:57.080781 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.55G, req 0G)
I0802 04:41:57.102641 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 1 1 3  (limit 7.53G, req 0G)
I0802 04:41:57.108036 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.55G, req 0G)
I0802 04:41:57.115304 18637 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:57.115365 18637 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:57.115460 18637 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:57.115468 18637 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:57.115489 18637 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:57.115504 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:57.116323 18657 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:57.116919 18637 data_layer.cpp:184] (1) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:57.117030 18637 data_layer.cpp:208] (1) Output data size: 17, 3, 224, 224
I0802 04:41:57.117035 18637 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0802 04:41:57.117722 18658 data_layer.cpp:97] (1) Parser threads: 1
I0802 04:41:57.117729 18658 data_layer.cpp:99] (1) Transformer threads: 1
I0802 04:41:57.124271 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0802 04:41:57.129130 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 7.53G, req 0G)
I0802 04:41:57.131852 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0802 04:41:57.138068 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.44G, req 0G)
I0802 04:41:57.142299 18638 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/test.prototxt
W0802 04:41:57.142350 18638 parallel.cpp:274] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0802 04:41:57.142467 18638 net.cpp:104] Using FLOAT as default forward math type
I0802 04:41:57.142474 18638 net.cpp:110] Using FLOAT as default backward math type
I0802 04:41:57.142498 18638 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0802 04:41:57.142505 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:57.144170 18659 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0802 04:41:57.144332 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0802 04:41:57.144973 18638 data_layer.cpp:184] (2) ReshapePrefetch 17, 3, 224, 224
I0802 04:41:57.145124 18638 data_layer.cpp:208] (2) Output data size: 17, 3, 224, 224
I0802 04:41:57.145133 18638 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0802 04:41:57.145910 18660 data_layer.cpp:97] (2) Parser threads: 1
I0802 04:41:57.145925 18660 data_layer.cpp:99] (2) Transformer threads: 1
I0802 04:41:57.154600 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.49G, req 0G)
I0802 04:41:57.156186 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0802 04:41:57.161520 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0802 04:41:57.161972 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.46G, req 0G)
I0802 04:41:57.169631 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.43G, req 0G)
I0802 04:41:57.174918 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0802 04:41:57.175720 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.42G, req 0G)
I0802 04:41:57.182627 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0802 04:41:57.185529 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.4G, req 0G)
I0802 04:41:57.191018 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.39G, req 0G)
I0802 04:41:57.206315 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.39G, req 0G)
I0802 04:41:57.215036 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.38G, req 0G)
I0802 04:41:57.223242 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0802 04:41:57.246142 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:57.256129 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.37G, req 0G)
I0802 04:41:57.261837 18637 solver.cpp:56] Solver scaffolding done.
I0802 04:41:57.277657 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.37G, req 0G)
I0802 04:41:57.290199 18638 solver.cpp:56] Solver scaffolding done.
I0802 04:41:57.334172 18637 parallel.cpp:164] [1 - 1] P2pSync adding callback
I0802 04:41:57.334193 18638 parallel.cpp:164] [2 - 2] P2pSync adding callback
I0802 04:41:57.334194 18636 parallel.cpp:164] [0 - 0] P2pSync adding callback
I0802 04:41:57.542634 18636 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 04:41:57.548943 18637 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.548959 18637 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.549031 18638 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.549038 18638 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.557137 18636 solver.cpp:479] Solving jacintonet11v2_train
I0802 04:41:57.557152 18636 solver.cpp:480] Learning Rate Policy: poly
I0802 04:41:57.566503 18637 solver.cpp:268] Starting Optimization on GPU 1
I0802 04:41:57.566504 18636 solver.cpp:268] Starting Optimization on GPU 0
I0802 04:41:57.566504 18638 solver.cpp:268] Starting Optimization on GPU 2
I0802 04:41:57.566668 18636 solver.cpp:550] Iteration 0, Testing net (#0)
I0802 04:41:57.566720 18663 device_alternate.hpp:116] NVML initialized on thread 139545555494656
I0802 04:41:57.566741 18663 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0802 04:41:57.566751 18661 device_alternate.hpp:116] NVML initialized on thread 139545547101952
I0802 04:41:57.566766 18661 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0802 04:41:57.566776 18662 device_alternate.hpp:116] NVML initialized on thread 139545538709248
I0802 04:41:57.566784 18662 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0802 04:41:57.576212 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.3G, req 0G)
I0802 04:41:57.578899 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.3G, req 0G)
I0802 04:41:57.585031 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.24G, req 0G)
I0802 04:41:57.587999 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.24G, req 0G)
I0802 04:41:57.598659 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.24G, req 0G)
I0802 04:41:57.600513 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.17G, req 0G)
I0802 04:41:57.601436 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.17G, req 0G)
I0802 04:41:57.607422 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.14G, req 0G)
I0802 04:41:57.608446 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.14G, req 0G)
I0802 04:41:57.610725 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 6  (limit 7.17G, req 0G)
I0802 04:41:57.615265 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.11G, req 0G)
I0802 04:41:57.615890 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.11G, req 0G)
I0802 04:41:57.620972 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0802 04:41:57.622221 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.09G, req 0G)
I0802 04:41:57.622462 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 1  (limit 7.1G, req 0G)
I0802 04:41:57.628850 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.629439 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.07G, req 0G)
I0802 04:41:57.631719 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.07G, req 0G)
I0802 04:41:57.634940 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.636811 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.07G, req 0G)
I0802 04:41:57.637799 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.04G, req 0G)
I0802 04:41:57.642558 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.02G, req 0G)
I0802 04:41:57.643242 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.06G, req 0G)
I0802 04:41:57.645154 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.06G, req 0G)
I0802 04:41:57.649615 18637 cudnn_conv_layer.cpp:1011] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.06G, req 0G)
I0802 04:41:57.650171 18638 cudnn_conv_layer.cpp:1011] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.06G, req 0G)
I0802 04:41:57.652117 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.01G, req 0G)
I0802 04:41:57.655248 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7G, req 0G)
I0802 04:41:57.661854 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 6.99G, req 0G)
I0802 04:41:57.666119 18636 cudnn_conv_layer.cpp:1011] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 6.99G, req 0G)
I0802 04:41:57.670177 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.411765
I0802 04:41:57.670189 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.529412
I0802 04:41:57.670194 18636 solver.cpp:635]     Test net output #2: loss = 2.68052 (* 1 = 2.68052 loss)
I0802 04:41:57.670212 18636 solver.cpp:295] [MultiGPU] Initial Test completed
I0802 04:41:57.670230 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 04:41:57.764883 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7G, req 0G)
I0802 04:41:57.766609 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7G, req 0G)
I0802 04:41:57.767659 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 6.93G, req 0G)
I0802 04:41:57.797825 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.86G, req 0G)
I0802 04:41:57.800348 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.86G, req 0G)
I0802 04:41:57.803140 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.79G, req 0G)
I0802 04:41:57.830986 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 6.7G, req 0G)
I0802 04:41:57.836990 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.7G, req 0G)
I0802 04:41:57.837196 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 6.63G, req 0G)
I0802 04:41:57.849103 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.63G, req 0G)
I0802 04:41:57.854073 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.63G, req 0G)
I0802 04:41:57.854231 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 6.56G, req 0G)
I0802 04:41:57.874125 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.55G, req 0G)
I0802 04:41:57.883646 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 6.48G, req 0G)
I0802 04:41:57.884027 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.51G, req 0G)
I0802 04:41:57.884508 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 6.55G, req 0G)
I0802 04:41:57.893481 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.44G, req 0G)
I0802 04:41:57.895653 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 6.51G, req 0G)
I0802 04:41:57.908303 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.47G, req 0G)
I0802 04:41:57.914922 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.39G, req 0G)
I0802 04:41:57.916596 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.45G, req 0G)
I0802 04:41:57.917002 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 6.47G, req 0G)
I0802 04:41:57.923189 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.37G, req 0G)
I0802 04:41:57.925855 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 6.45G, req 0G)
I0802 04:41:57.944221 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 3  (limit 6.42G, req 0G)
I0802 04:41:57.948272 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.34G, req 0G)
I0802 04:41:57.950654 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 6.42G, req 0G)
I0802 04:41:57.953498 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 6.41G, req 0G)
I0802 04:41:57.956415 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 3  (limit 6.33G, req 0G)
I0802 04:41:57.959470 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 1 1  (limit 6.41G, req 0G)
I0802 04:41:58.009326 18641 data_layer.cpp:97] [1] Parser threads: 1
I0802 04:41:58.009343 18641 data_layer.cpp:99] [1] Transformer threads: 1
I0802 04:41:58.012058 18598 data_layer.cpp:97] [0] Parser threads: 1
I0802 04:41:58.012068 18598 data_layer.cpp:99] [0] Transformer threads: 1
I0802 04:41:58.016244 18642 data_layer.cpp:97] [2] Parser threads: 1
I0802 04:41:58.016253 18642 data_layer.cpp:99] [2] Transformer threads: 1
I0802 04:41:58.161202 18636 solver.cpp:358] Iteration 0 (0.490953 s), loss = 1.14066
I0802 04:41:58.161224 18636 solver.cpp:375]     Train net output #0: loss = 1.13888 (* 1 = 1.13888 loss)
I0802 04:41:58.161229 18636 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0802 04:41:58.188468 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.4G, req 0G)
I0802 04:41:58.189609 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.31G, req 0G)
I0802 04:41:58.190129 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.71G/1 1 0 3  (limit 5.4G, req 0G)
I0802 04:41:58.258949 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.259146 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.259600 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.43G/2 6 4 3  (limit 4.6G, req 0G)
I0802 04:41:58.307332 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 3  (limit 4.6G, req 0G)
I0802 04:41:58.308959 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 1  (limit 4.69G, req 0G)
I0802 04:41:58.309664 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.43G/1 6 4 3  (limit 4.69G, req 0G)
I0802 04:41:58.326849 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.6G, req 0G)
I0802 04:41:58.330370 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.69G, req 0G)
I0802 04:41:58.332389 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.43G/2 6 4 0  (limit 4.69G, req 0G)
I0802 04:41:58.358510 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.365193 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.366474 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.376209 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 1 4 3  (limit 4.6G, req 0.06G)
I0802 04:41:58.379575 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.386618 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.43G/2 1 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.412219 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.418045 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.422755 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.43G/1 6 4 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.428756 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.6G, req 0.06G)
I0802 04:41:58.435308 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.439368 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.43G/2 6 4 3  (limit 4.69G, req 0.06G)
I0802 04:41:58.478915 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.491147 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.493398 18636 cudnn_conv_layer.cpp:1011] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 6 1 5  (limit 4.6G, req 0.06G)
I0802 04:41:58.494364 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.43G/1 7 5 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.504158 18638 cudnn_conv_layer.cpp:1011] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 7 1 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.506006 18637 cudnn_conv_layer.cpp:1011] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.43G/2 7 1 5  (limit 4.69G, req 0.06G)
I0802 04:41:58.535116 18636 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.547755 18638 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.549535 18637 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.43G -> 0.12G
I0802 04:41:58.632644 18636 solver.cpp:358] Iteration 1 (0.471423 s), loss = 1.05683
I0802 04:41:58.632673 18636 solver.cpp:375]     Train net output #0: loss = 1.29804 (* 1 = 1.29804 loss)
I0802 04:41:58.780123 18636 solver.cpp:358] Iteration 2 (0.147465 s), loss = 1.33586
I0802 04:41:58.780151 18636 solver.cpp:375]     Train net output #0: loss = 1.42587 (* 1 = 1.42587 loss)
I0802 04:42:12.300084 18636 solver.cpp:353] Iteration 100 (7.24874 iter/s, 13.5196s/98 iter), loss = 1.40792
I0802 04:42:12.300109 18636 solver.cpp:375]     Train net output #0: loss = 1.27096 (* 1 = 1.27096 loss)
I0802 04:42:12.300113 18636 sgd_solver.cpp:136] Iteration 100, lr = 0.00999375, m = 0.9
I0802 04:42:26.194919 18636 solver.cpp:353] Iteration 200 (7.19712 iter/s, 13.8945s/100 iter), loss = 1.4507
I0802 04:42:26.194984 18636 solver.cpp:375]     Train net output #0: loss = 1.43852 (* 1 = 1.43852 loss)
I0802 04:42:26.194991 18636 sgd_solver.cpp:136] Iteration 200, lr = 0.0099875, m = 0.9
I0802 04:42:40.100770 18636 solver.cpp:353] Iteration 300 (7.19142 iter/s, 13.9055s/100 iter), loss = 1.76461
I0802 04:42:40.100800 18636 solver.cpp:375]     Train net output #0: loss = 1.63631 (* 1 = 1.63631 loss)
I0802 04:42:40.100806 18636 sgd_solver.cpp:136] Iteration 300, lr = 0.00998125, m = 0.9
I0802 04:42:53.953501 18636 solver.cpp:353] Iteration 400 (7.21899 iter/s, 13.8524s/100 iter), loss = 1.49658
I0802 04:42:53.953527 18636 solver.cpp:375]     Train net output #0: loss = 1.63474 (* 1 = 1.63474 loss)
I0802 04:42:53.953532 18636 sgd_solver.cpp:136] Iteration 400, lr = 0.009975, m = 0.9
I0802 04:43:07.782989 18636 solver.cpp:353] Iteration 500 (7.23112 iter/s, 13.8291s/100 iter), loss = 1.39605
I0802 04:43:07.783044 18636 solver.cpp:375]     Train net output #0: loss = 1.23662 (* 1 = 1.23662 loss)
I0802 04:43:07.783049 18636 sgd_solver.cpp:136] Iteration 500, lr = 0.00996875, m = 0.9
I0802 04:43:21.711097 18636 solver.cpp:353] Iteration 600 (7.17992 iter/s, 13.9277s/100 iter), loss = 1.2038
I0802 04:43:21.711123 18636 solver.cpp:375]     Train net output #0: loss = 1.3082 (* 1 = 1.3082 loss)
I0802 04:43:21.711129 18636 sgd_solver.cpp:136] Iteration 600, lr = 0.0099625, m = 0.9
I0802 04:43:35.592906 18636 solver.cpp:353] Iteration 700 (7.20387 iter/s, 13.8814s/100 iter), loss = 1.25342
I0802 04:43:35.592932 18636 solver.cpp:375]     Train net output #0: loss = 1.41266 (* 1 = 1.41266 loss)
I0802 04:43:35.592937 18636 sgd_solver.cpp:136] Iteration 700, lr = 0.00995625, m = 0.9
I0802 04:43:49.510676 18636 solver.cpp:353] Iteration 800 (7.18525 iter/s, 13.9174s/100 iter), loss = 1.32427
I0802 04:43:49.510783 18636 solver.cpp:375]     Train net output #0: loss = 1.43607 (* 1 = 1.43607 loss)
I0802 04:43:49.510792 18636 sgd_solver.cpp:136] Iteration 800, lr = 0.00995, m = 0.9
I0802 04:44:03.318053 18636 solver.cpp:353] Iteration 900 (7.2427 iter/s, 13.807s/100 iter), loss = 1.33455
I0802 04:44:03.318084 18636 solver.cpp:375]     Train net output #0: loss = 1.57395 (* 1 = 1.57395 loss)
I0802 04:44:03.318089 18636 sgd_solver.cpp:136] Iteration 900, lr = 0.00994375, m = 0.9
I0802 04:44:17.025671 18636 solver.cpp:404] Sparsity after update:
I0802 04:44:17.036933 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:44:17.036975 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:44:17.036996 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:44:17.037008 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:44:17.037016 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:44:17.037025 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:44:17.037034 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:44:17.037045 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:44:17.037055 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:44:17.037062 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:44:17.037071 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:44:17.037080 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:44:17.037088 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:44:17.178385 18636 solver.cpp:353] Iteration 1000 (7.21503 iter/s, 13.86s/100 iter), loss = 1.47177
I0802 04:44:17.178416 18636 solver.cpp:375]     Train net output #0: loss = 1.28685 (* 1 = 1.28685 loss)
I0802 04:44:17.178422 18636 sgd_solver.cpp:136] Iteration 1000, lr = 0.0099375, m = 0.9
I0802 04:44:31.085815 18636 solver.cpp:353] Iteration 1100 (7.1906 iter/s, 13.9071s/100 iter), loss = 1.53807
I0802 04:44:31.086923 18636 solver.cpp:375]     Train net output #0: loss = 1.63114 (* 1 = 1.63114 loss)
I0802 04:44:31.086933 18636 sgd_solver.cpp:136] Iteration 1100, lr = 0.00993125, m = 0.9
I0802 04:44:44.993254 18636 solver.cpp:353] Iteration 1200 (7.19059 iter/s, 13.9071s/100 iter), loss = 1.5934
I0802 04:44:44.993284 18636 solver.cpp:375]     Train net output #0: loss = 1.63936 (* 1 = 1.63936 loss)
I0802 04:44:44.993290 18636 sgd_solver.cpp:136] Iteration 1200, lr = 0.009925, m = 0.9
I0802 04:44:58.837923 18636 solver.cpp:353] Iteration 1300 (7.22319 iter/s, 13.8443s/100 iter), loss = 1.30213
I0802 04:44:58.837947 18636 solver.cpp:375]     Train net output #0: loss = 1.04995 (* 1 = 1.04995 loss)
I0802 04:44:58.837951 18636 sgd_solver.cpp:136] Iteration 1300, lr = 0.00991875, m = 0.9
I0802 04:45:12.710419 18636 solver.cpp:353] Iteration 1400 (7.2087 iter/s, 13.8721s/100 iter), loss = 1.20778
I0802 04:45:12.710502 18636 solver.cpp:375]     Train net output #0: loss = 1.30892 (* 1 = 1.30892 loss)
I0802 04:45:12.710510 18636 sgd_solver.cpp:136] Iteration 1400, lr = 0.0099125, m = 0.9
I0802 04:45:26.571426 18636 solver.cpp:353] Iteration 1500 (7.21468 iter/s, 13.8606s/100 iter), loss = 1.49515
I0802 04:45:26.571455 18636 solver.cpp:375]     Train net output #0: loss = 1.64644 (* 1 = 1.64644 loss)
I0802 04:45:26.571461 18636 sgd_solver.cpp:136] Iteration 1500, lr = 0.00990625, m = 0.9
I0802 04:45:40.444102 18636 solver.cpp:353] Iteration 1600 (7.20861 iter/s, 13.8723s/100 iter), loss = 1.79271
I0802 04:45:40.444130 18636 solver.cpp:375]     Train net output #0: loss = 1.996 (* 1 = 1.996 loss)
I0802 04:45:40.444139 18636 sgd_solver.cpp:136] Iteration 1600, lr = 0.0099, m = 0.9
I0802 04:45:54.343536 18636 solver.cpp:353] Iteration 1700 (7.19473 iter/s, 13.8991s/100 iter), loss = 1.32072
I0802 04:45:54.343616 18636 solver.cpp:375]     Train net output #0: loss = 1.47131 (* 1 = 1.47131 loss)
I0802 04:45:54.343622 18636 sgd_solver.cpp:136] Iteration 1700, lr = 0.00989375, m = 0.9
I0802 04:46:08.220157 18636 solver.cpp:353] Iteration 1800 (7.20656 iter/s, 13.8762s/100 iter), loss = 1.50691
I0802 04:46:08.220247 18636 solver.cpp:375]     Train net output #0: loss = 1.57113 (* 1 = 1.57113 loss)
I0802 04:46:08.220265 18636 sgd_solver.cpp:136] Iteration 1800, lr = 0.0098875, m = 0.9
I0802 04:46:22.067145 18636 solver.cpp:353] Iteration 1900 (7.22198 iter/s, 13.8466s/100 iter), loss = 1.41145
I0802 04:46:22.067217 18636 solver.cpp:375]     Train net output #0: loss = 1.5441 (* 1 = 1.5441 loss)
I0802 04:46:22.067236 18636 sgd_solver.cpp:136] Iteration 1900, lr = 0.00988125, m = 0.9
I0802 04:46:35.831696 18636 solver.cpp:404] Sparsity after update:
I0802 04:46:35.844086 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:46:35.844106 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:46:35.844115 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:46:35.844117 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:46:35.844120 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:46:35.844123 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:46:35.844126 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:46:35.844137 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:46:35.844146 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:46:35.844154 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:46:35.844162 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:46:35.844172 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:46:35.844179 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:46:35.844202 18636 solver.cpp:550] Iteration 2000, Testing net (#0)
I0802 04:46:53.897833 18619 data_reader.cpp:264] Starting prefetch of epoch 1
I0802 04:46:55.213395 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.541824
I0802 04:46:55.213418 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.782175
I0802 04:46:55.213426 18636 solver.cpp:635]     Test net output #2: loss = 2.0454 (* 1 = 2.0454 loss)
I0802 04:46:55.213449 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3687s
I0802 04:46:55.365571 18636 solver.cpp:353] Iteration 2000 (3.00322 iter/s, 33.2975s/100 iter), loss = 1.5267
I0802 04:46:55.365595 18636 solver.cpp:375]     Train net output #0: loss = 1.77623 (* 1 = 1.77623 loss)
I0802 04:46:55.365599 18636 sgd_solver.cpp:136] Iteration 2000, lr = 0.009875, m = 0.9
I0802 04:47:09.262711 18636 solver.cpp:353] Iteration 2100 (7.19592 iter/s, 13.8968s/100 iter), loss = 1.31399
I0802 04:47:09.262951 18636 solver.cpp:375]     Train net output #0: loss = 1.44549 (* 1 = 1.44549 loss)
I0802 04:47:09.262959 18636 sgd_solver.cpp:136] Iteration 2100, lr = 0.00986875, m = 0.9
I0802 04:47:23.096982 18636 solver.cpp:353] Iteration 2200 (7.22862 iter/s, 13.8339s/100 iter), loss = 1.62425
I0802 04:47:23.097007 18636 solver.cpp:375]     Train net output #0: loss = 1.81043 (* 1 = 1.81043 loss)
I0802 04:47:23.097010 18636 sgd_solver.cpp:136] Iteration 2200, lr = 0.0098625, m = 0.9
I0802 04:47:36.935868 18636 solver.cpp:353] Iteration 2300 (7.22621 iter/s, 13.8385s/100 iter), loss = 1.37867
I0802 04:47:36.935897 18636 solver.cpp:375]     Train net output #0: loss = 1.36032 (* 1 = 1.36032 loss)
I0802 04:47:36.935904 18636 sgd_solver.cpp:136] Iteration 2300, lr = 0.00985625, m = 0.9
I0802 04:47:50.846935 18636 solver.cpp:353] Iteration 2400 (7.18872 iter/s, 13.9107s/100 iter), loss = 1.60656
I0802 04:47:50.846998 18636 solver.cpp:375]     Train net output #0: loss = 1.64311 (* 1 = 1.64311 loss)
I0802 04:47:50.847005 18636 sgd_solver.cpp:136] Iteration 2400, lr = 0.00985, m = 0.9
I0802 04:48:04.728579 18636 solver.cpp:353] Iteration 2500 (7.20395 iter/s, 13.8813s/100 iter), loss = 1.1758
I0802 04:48:04.728603 18636 solver.cpp:375]     Train net output #0: loss = 1.12295 (* 1 = 1.12295 loss)
I0802 04:48:04.728610 18636 sgd_solver.cpp:136] Iteration 2500, lr = 0.00984375, m = 0.9
I0802 04:48:18.610437 18636 solver.cpp:353] Iteration 2600 (7.20384 iter/s, 13.8815s/100 iter), loss = 1.74137
I0802 04:48:18.610463 18636 solver.cpp:375]     Train net output #0: loss = 1.81678 (* 1 = 1.81678 loss)
I0802 04:48:18.610469 18636 sgd_solver.cpp:136] Iteration 2600, lr = 0.0098375, m = 0.9
I0802 04:48:32.503883 18636 solver.cpp:353] Iteration 2700 (7.19783 iter/s, 13.8931s/100 iter), loss = 1.40645
I0802 04:48:32.504009 18636 solver.cpp:375]     Train net output #0: loss = 1.50965 (* 1 = 1.50965 loss)
I0802 04:48:32.504016 18636 sgd_solver.cpp:136] Iteration 2700, lr = 0.00983125, m = 0.9
I0802 04:48:46.338052 18636 solver.cpp:353] Iteration 2800 (7.22867 iter/s, 13.8338s/100 iter), loss = 1.46026
I0802 04:48:46.338083 18636 solver.cpp:375]     Train net output #0: loss = 1.59502 (* 1 = 1.59502 loss)
I0802 04:48:46.338088 18636 sgd_solver.cpp:136] Iteration 2800, lr = 0.009825, m = 0.9
I0802 04:49:00.181720 18636 solver.cpp:353] Iteration 2900 (7.22371 iter/s, 13.8433s/100 iter), loss = 1.42592
I0802 04:49:00.181746 18636 solver.cpp:375]     Train net output #0: loss = 1.30748 (* 1 = 1.30748 loss)
I0802 04:49:00.181751 18636 sgd_solver.cpp:136] Iteration 2900, lr = 0.00981875, m = 0.9
I0802 04:49:13.945041 18636 solver.cpp:404] Sparsity after update:
I0802 04:49:13.979758 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:49:13.979779 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:49:13.979786 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:49:13.979789 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:49:13.979792 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:49:13.979795 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:49:13.979799 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:49:13.979804 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:49:13.979806 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:49:13.979809 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:49:13.980067 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:49:13.980080 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:49:13.980166 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:49:14.109004 18636 solver.cpp:353] Iteration 3000 (7.18034 iter/s, 13.9269s/100 iter), loss = 1.66629
I0802 04:49:14.109028 18636 solver.cpp:375]     Train net output #0: loss = 1.92017 (* 1 = 1.92017 loss)
I0802 04:49:14.109035 18636 sgd_solver.cpp:136] Iteration 3000, lr = 0.0098125, m = 0.9
I0802 04:49:28.056218 18636 solver.cpp:353] Iteration 3100 (7.17009 iter/s, 13.9468s/100 iter), loss = 1.65539
I0802 04:49:28.056249 18636 solver.cpp:375]     Train net output #0: loss = 1.46319 (* 1 = 1.46319 loss)
I0802 04:49:28.056255 18636 sgd_solver.cpp:136] Iteration 3100, lr = 0.00980625, m = 0.9
I0802 04:49:41.921808 18636 solver.cpp:353] Iteration 3200 (7.21229 iter/s, 13.8652s/100 iter), loss = 1.57357
I0802 04:49:41.921834 18636 solver.cpp:375]     Train net output #0: loss = 1.8228 (* 1 = 1.8228 loss)
I0802 04:49:41.921838 18636 sgd_solver.cpp:136] Iteration 3200, lr = 0.0098, m = 0.9
I0802 04:49:55.893332 18636 solver.cpp:353] Iteration 3300 (7.15761 iter/s, 13.9712s/100 iter), loss = 1.44518
I0802 04:49:55.893416 18636 solver.cpp:375]     Train net output #0: loss = 1.50991 (* 1 = 1.50991 loss)
I0802 04:49:55.893424 18636 sgd_solver.cpp:136] Iteration 3300, lr = 0.00979375, m = 0.9
I0802 04:50:09.781358 18636 solver.cpp:353] Iteration 3400 (7.20064 iter/s, 13.8877s/100 iter), loss = 1.34996
I0802 04:50:09.781381 18636 solver.cpp:375]     Train net output #0: loss = 1.42667 (* 1 = 1.42667 loss)
I0802 04:50:09.781388 18636 sgd_solver.cpp:136] Iteration 3400, lr = 0.0097875, m = 0.9
I0802 04:50:23.670627 18636 solver.cpp:353] Iteration 3500 (7.2 iter/s, 13.8889s/100 iter), loss = 1.75447
I0802 04:50:23.670652 18636 solver.cpp:375]     Train net output #0: loss = 1.28846 (* 1 = 1.28846 loss)
I0802 04:50:23.670656 18636 sgd_solver.cpp:136] Iteration 3500, lr = 0.00978125, m = 0.9
I0802 04:50:37.614274 18636 solver.cpp:353] Iteration 3600 (7.17192 iter/s, 13.9433s/100 iter), loss = 1.41468
I0802 04:50:37.614353 18636 solver.cpp:375]     Train net output #0: loss = 1.50341 (* 1 = 1.50341 loss)
I0802 04:50:37.614361 18636 sgd_solver.cpp:136] Iteration 3600, lr = 0.009775, m = 0.9
I0802 04:50:51.499898 18636 solver.cpp:353] Iteration 3700 (7.20189 iter/s, 13.8852s/100 iter), loss = 1.63415
I0802 04:50:51.499925 18636 solver.cpp:375]     Train net output #0: loss = 2.341 (* 1 = 2.341 loss)
I0802 04:50:51.499933 18636 sgd_solver.cpp:136] Iteration 3700, lr = 0.00976875, m = 0.9
I0802 04:51:05.373553 18636 solver.cpp:353] Iteration 3800 (7.2081 iter/s, 13.8733s/100 iter), loss = 1.85738
I0802 04:51:05.373581 18636 solver.cpp:375]     Train net output #0: loss = 1.82473 (* 1 = 1.82473 loss)
I0802 04:51:05.373589 18636 sgd_solver.cpp:136] Iteration 3800, lr = 0.0097625, m = 0.9
I0802 04:51:19.194438 18636 solver.cpp:353] Iteration 3900 (7.23562 iter/s, 13.8205s/100 iter), loss = 1.5445
I0802 04:51:19.194538 18636 solver.cpp:375]     Train net output #0: loss = 1.46924 (* 1 = 1.46924 loss)
I0802 04:51:19.194546 18636 sgd_solver.cpp:136] Iteration 3900, lr = 0.00975625, m = 0.9
I0802 04:51:32.979055 18636 solver.cpp:404] Sparsity after update:
I0802 04:51:32.982990 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:51:32.983003 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:51:32.983011 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:51:32.983016 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:51:32.983031 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:51:32.983042 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:51:32.983052 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:51:32.983059 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:51:32.983068 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:51:32.983078 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:51:32.983085 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:51:32.983094 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:51:32.983103 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:51:32.983122 18636 solver.cpp:550] Iteration 4000, Testing net (#0)
I0802 04:51:52.276240 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.541118
I0802 04:51:52.276363 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.780409
I0802 04:51:52.276374 18636 solver.cpp:635]     Test net output #2: loss = 2.06271 (* 1 = 2.06271 loss)
I0802 04:51:52.276393 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2928s
I0802 04:51:52.418325 18636 solver.cpp:353] Iteration 4000 (3.00996 iter/s, 33.223s/100 iter), loss = 1.47225
I0802 04:51:52.418352 18636 solver.cpp:375]     Train net output #0: loss = 1.49732 (* 1 = 1.49732 loss)
I0802 04:51:52.418357 18636 sgd_solver.cpp:136] Iteration 4000, lr = 0.00975, m = 0.9
I0802 04:52:06.320499 18636 solver.cpp:353] Iteration 4100 (7.19331 iter/s, 13.9018s/100 iter), loss = 1.40722
I0802 04:52:06.320529 18636 solver.cpp:375]     Train net output #0: loss = 1.42812 (* 1 = 1.42812 loss)
I0802 04:52:06.320535 18636 sgd_solver.cpp:136] Iteration 4100, lr = 0.00974375, m = 0.9
I0802 04:52:20.297951 18636 solver.cpp:353] Iteration 4200 (7.15458 iter/s, 13.9771s/100 iter), loss = 1.27217
I0802 04:52:20.298018 18636 solver.cpp:375]     Train net output #0: loss = 1.32106 (* 1 = 1.32106 loss)
I0802 04:52:20.298032 18636 sgd_solver.cpp:136] Iteration 4200, lr = 0.0097375, m = 0.9
I0802 04:52:34.153208 18636 solver.cpp:353] Iteration 4300 (7.21767 iter/s, 13.8549s/100 iter), loss = 1.78682
I0802 04:52:34.153280 18636 solver.cpp:375]     Train net output #0: loss = 1.87984 (* 1 = 1.87984 loss)
I0802 04:52:34.153287 18636 sgd_solver.cpp:136] Iteration 4300, lr = 0.00973125, m = 0.9
I0802 04:52:48.078076 18636 solver.cpp:353] Iteration 4400 (7.18159 iter/s, 13.9245s/100 iter), loss = 1.65482
I0802 04:52:48.078105 18636 solver.cpp:375]     Train net output #0: loss = 1.87672 (* 1 = 1.87672 loss)
I0802 04:52:48.078111 18636 sgd_solver.cpp:136] Iteration 4400, lr = 0.009725, m = 0.9
I0802 04:53:01.875010 18636 solver.cpp:353] Iteration 4500 (7.24818 iter/s, 13.7966s/100 iter), loss = 1.5807
I0802 04:53:01.875039 18636 solver.cpp:375]     Train net output #0: loss = 1.69783 (* 1 = 1.69783 loss)
I0802 04:53:01.875046 18636 sgd_solver.cpp:136] Iteration 4500, lr = 0.00971875, m = 0.9
I0802 04:53:15.741317 18636 solver.cpp:353] Iteration 4600 (7.21192 iter/s, 13.8659s/100 iter), loss = 1.60366
I0802 04:53:15.741477 18636 solver.cpp:375]     Train net output #0: loss = 1.69297 (* 1 = 1.69297 loss)
I0802 04:53:15.741498 18636 sgd_solver.cpp:136] Iteration 4600, lr = 0.0097125, m = 0.9
I0802 04:53:29.565253 18636 solver.cpp:353] Iteration 4700 (7.23402 iter/s, 13.8236s/100 iter), loss = 1.98118
I0802 04:53:29.565281 18636 solver.cpp:375]     Train net output #0: loss = 1.79589 (* 1 = 1.79589 loss)
I0802 04:53:29.565287 18636 sgd_solver.cpp:136] Iteration 4700, lr = 0.00970625, m = 0.9
I0802 04:53:43.420809 18636 solver.cpp:353] Iteration 4800 (7.21752 iter/s, 13.8552s/100 iter), loss = 1.44386
I0802 04:53:43.420843 18636 solver.cpp:375]     Train net output #0: loss = 1.97463 (* 1 = 1.97463 loss)
I0802 04:53:43.420850 18636 sgd_solver.cpp:136] Iteration 4800, lr = 0.0097, m = 0.9
I0802 04:53:57.320909 18636 solver.cpp:353] Iteration 4900 (7.19439 iter/s, 13.8997s/100 iter), loss = 1.51961
I0802 04:53:57.320992 18636 solver.cpp:375]     Train net output #0: loss = 1.54783 (* 1 = 1.54783 loss)
I0802 04:53:57.321004 18636 sgd_solver.cpp:136] Iteration 4900, lr = 0.00969375, m = 0.9
I0802 04:54:11.059767 18636 solver.cpp:404] Sparsity after update:
I0802 04:54:11.070971 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:54:11.070986 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:54:11.070994 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:54:11.070997 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:54:11.071000 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:54:11.071003 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:54:11.071007 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:54:11.071009 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:54:11.071012 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:54:11.071015 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:54:11.071018 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:54:11.071022 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:54:11.071024 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:54:11.210940 18636 solver.cpp:353] Iteration 5000 (7.1996 iter/s, 13.8897s/100 iter), loss = 1.5357
I0802 04:54:11.210966 18636 solver.cpp:375]     Train net output #0: loss = 2.02582 (* 1 = 2.02582 loss)
I0802 04:54:11.210973 18636 sgd_solver.cpp:136] Iteration 5000, lr = 0.0096875, m = 0.9
I0802 04:54:25.051344 18636 solver.cpp:353] Iteration 5100 (7.22542 iter/s, 13.84s/100 iter), loss = 1.27904
I0802 04:54:25.051369 18636 solver.cpp:375]     Train net output #0: loss = 1.11084 (* 1 = 1.11084 loss)
I0802 04:54:25.051375 18636 sgd_solver.cpp:136] Iteration 5100, lr = 0.00968125, m = 0.9
I0802 04:54:38.944774 18636 solver.cpp:353] Iteration 5200 (7.19784 iter/s, 13.8931s/100 iter), loss = 1.32342
I0802 04:54:38.944840 18636 solver.cpp:375]     Train net output #0: loss = 1.34547 (* 1 = 1.34547 loss)
I0802 04:54:38.944847 18636 sgd_solver.cpp:136] Iteration 5200, lr = 0.009675, m = 0.9
I0802 04:54:52.763200 18636 solver.cpp:353] Iteration 5300 (7.23691 iter/s, 13.8181s/100 iter), loss = 1.48829
I0802 04:54:52.763227 18636 solver.cpp:375]     Train net output #0: loss = 1.49274 (* 1 = 1.49274 loss)
I0802 04:54:52.763234 18636 sgd_solver.cpp:136] Iteration 5300, lr = 0.00966875, m = 0.9
I0802 04:55:06.671777 18636 solver.cpp:353] Iteration 5400 (7.19 iter/s, 13.9082s/100 iter), loss = 1.49806
I0802 04:55:06.671829 18636 solver.cpp:375]     Train net output #0: loss = 1.83859 (* 1 = 1.83859 loss)
I0802 04:55:06.671841 18636 sgd_solver.cpp:136] Iteration 5400, lr = 0.0096625, m = 0.9
I0802 04:55:20.519006 18636 solver.cpp:353] Iteration 5500 (7.22186 iter/s, 13.8469s/100 iter), loss = 1.26795
I0802 04:55:20.519109 18636 solver.cpp:375]     Train net output #0: loss = 1.24585 (* 1 = 1.24585 loss)
I0802 04:55:20.519120 18636 sgd_solver.cpp:136] Iteration 5500, lr = 0.00965625, m = 0.9
I0802 04:55:34.392174 18636 solver.cpp:353] Iteration 5600 (7.20835 iter/s, 13.8728s/100 iter), loss = 1.65233
I0802 04:55:34.392202 18636 solver.cpp:375]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I0802 04:55:34.392208 18636 sgd_solver.cpp:136] Iteration 5600, lr = 0.00965, m = 0.9
I0802 04:55:48.339846 18636 solver.cpp:353] Iteration 5700 (7.16985 iter/s, 13.9473s/100 iter), loss = 1.83073
I0802 04:55:48.339875 18636 solver.cpp:375]     Train net output #0: loss = 1.81682 (* 1 = 1.81682 loss)
I0802 04:55:48.339881 18636 sgd_solver.cpp:136] Iteration 5700, lr = 0.00964375, m = 0.9
I0802 04:56:02.207470 18636 solver.cpp:353] Iteration 5800 (7.21123 iter/s, 13.8673s/100 iter), loss = 1.44008
I0802 04:56:02.207540 18636 solver.cpp:375]     Train net output #0: loss = 1.51265 (* 1 = 1.51265 loss)
I0802 04:56:02.207548 18636 sgd_solver.cpp:136] Iteration 5800, lr = 0.0096375, m = 0.9
I0802 04:56:16.144201 18636 solver.cpp:353] Iteration 5900 (7.17548 iter/s, 13.9364s/100 iter), loss = 1.26119
I0802 04:56:16.144228 18636 solver.cpp:375]     Train net output #0: loss = 1.20156 (* 1 = 1.20156 loss)
I0802 04:56:16.144232 18636 sgd_solver.cpp:136] Iteration 5900, lr = 0.00963125, m = 0.9
I0802 04:56:29.858077 18636 solver.cpp:404] Sparsity after update:
I0802 04:56:29.862864 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:56:29.862880 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:56:29.862888 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:56:29.862891 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:56:29.862895 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:56:29.862897 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:56:29.862900 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:56:29.862917 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:56:29.862931 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:56:29.862941 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:56:29.862949 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:56:29.862958 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:56:29.862967 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:56:29.862985 18636 solver.cpp:550] Iteration 6000, Testing net (#0)
I0802 04:56:49.047332 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.543
I0802 04:56:49.047427 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.785292
I0802 04:56:49.047436 18636 solver.cpp:635]     Test net output #2: loss = 2.02456 (* 1 = 2.02456 loss)
I0802 04:56:49.047456 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.184s
I0802 04:56:49.185627 18636 solver.cpp:353] Iteration 6000 (3.02658 iter/s, 33.0405s/100 iter), loss = 1.51495
I0802 04:56:49.185653 18636 solver.cpp:375]     Train net output #0: loss = 1.57783 (* 1 = 1.57783 loss)
I0802 04:56:49.185657 18636 sgd_solver.cpp:136] Iteration 6000, lr = 0.009625, m = 0.9
I0802 04:57:03.031970 18636 solver.cpp:353] Iteration 6100 (7.22232 iter/s, 13.846s/100 iter), loss = 1.48361
I0802 04:57:03.031998 18636 solver.cpp:375]     Train net output #0: loss = 1.42167 (* 1 = 1.42167 loss)
I0802 04:57:03.032004 18636 sgd_solver.cpp:136] Iteration 6100, lr = 0.00961875, m = 0.9
I0802 04:57:16.944602 18636 solver.cpp:353] Iteration 6200 (7.18791 iter/s, 13.9123s/100 iter), loss = 2.01327
I0802 04:57:16.944661 18636 solver.cpp:375]     Train net output #0: loss = 1.75674 (* 1 = 1.75674 loss)
I0802 04:57:16.944677 18636 sgd_solver.cpp:136] Iteration 6200, lr = 0.0096125, m = 0.9
I0802 04:57:30.874598 18636 solver.cpp:353] Iteration 6300 (7.17895 iter/s, 13.9296s/100 iter), loss = 1.34817
I0802 04:57:30.874694 18636 solver.cpp:375]     Train net output #0: loss = 1.42854 (* 1 = 1.42854 loss)
I0802 04:57:30.874701 18636 sgd_solver.cpp:136] Iteration 6300, lr = 0.00960625, m = 0.9
I0802 04:57:44.823580 18636 solver.cpp:353] Iteration 6400 (7.16918 iter/s, 13.9486s/100 iter), loss = 1.37892
I0802 04:57:44.823609 18636 solver.cpp:375]     Train net output #0: loss = 1.6996 (* 1 = 1.6996 loss)
I0802 04:57:44.823614 18636 sgd_solver.cpp:136] Iteration 6400, lr = 0.0096, m = 0.9
I0802 04:57:58.783347 18636 solver.cpp:353] Iteration 6500 (7.16364 iter/s, 13.9594s/100 iter), loss = 1.60807
I0802 04:57:58.783375 18636 solver.cpp:375]     Train net output #0: loss = 1.41555 (* 1 = 1.41555 loss)
I0802 04:57:58.783378 18636 sgd_solver.cpp:136] Iteration 6500, lr = 0.00959375, m = 0.9
I0802 04:58:12.718683 18636 solver.cpp:353] Iteration 6600 (7.17619 iter/s, 13.935s/100 iter), loss = 1.20525
I0802 04:58:12.718767 18636 solver.cpp:375]     Train net output #0: loss = 0.978498 (* 1 = 0.978498 loss)
I0802 04:58:12.718775 18636 sgd_solver.cpp:136] Iteration 6600, lr = 0.0095875, m = 0.9
I0802 04:58:26.586509 18636 solver.cpp:353] Iteration 6700 (7.21113 iter/s, 13.8675s/100 iter), loss = 1.47858
I0802 04:58:26.586536 18636 solver.cpp:375]     Train net output #0: loss = 1.37219 (* 1 = 1.37219 loss)
I0802 04:58:26.586542 18636 sgd_solver.cpp:136] Iteration 6700, lr = 0.00958125, m = 0.9
I0802 04:58:40.606501 18636 solver.cpp:353] Iteration 6800 (7.13286 iter/s, 14.0196s/100 iter), loss = 1.3588
I0802 04:58:40.606526 18636 solver.cpp:375]     Train net output #0: loss = 1.53007 (* 1 = 1.53007 loss)
I0802 04:58:40.606530 18636 sgd_solver.cpp:136] Iteration 6800, lr = 0.009575, m = 0.9
I0802 04:58:54.601866 18636 solver.cpp:353] Iteration 6900 (7.14542 iter/s, 13.995s/100 iter), loss = 1.37586
I0802 04:58:54.601939 18636 solver.cpp:375]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I0802 04:58:54.601948 18636 sgd_solver.cpp:136] Iteration 6900, lr = 0.00956875, m = 0.9
I0802 04:59:08.353750 18636 solver.cpp:404] Sparsity after update:
I0802 04:59:08.368100 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 04:59:08.368115 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 04:59:08.368124 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 04:59:08.368127 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 04:59:08.368130 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 04:59:08.368142 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 04:59:08.368151 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 04:59:08.368160 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 04:59:08.368168 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 04:59:08.368176 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 04:59:08.368185 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 04:59:08.368193 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 04:59:08.368201 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 04:59:08.499538 18636 solver.cpp:353] Iteration 7000 (7.19564 iter/s, 13.8973s/100 iter), loss = 1.53921
I0802 04:59:08.499567 18636 solver.cpp:375]     Train net output #0: loss = 1.38604 (* 1 = 1.38604 loss)
I0802 04:59:08.499574 18636 sgd_solver.cpp:136] Iteration 7000, lr = 0.0095625, m = 0.9
I0802 04:59:22.366319 18636 solver.cpp:353] Iteration 7100 (7.21167 iter/s, 13.8664s/100 iter), loss = 1.82688
I0802 04:59:22.366343 18636 solver.cpp:375]     Train net output #0: loss = 2.00839 (* 1 = 2.00839 loss)
I0802 04:59:22.366349 18636 sgd_solver.cpp:136] Iteration 7100, lr = 0.00955625, m = 0.9
I0802 04:59:36.192361 18636 solver.cpp:353] Iteration 7200 (7.23292 iter/s, 13.8257s/100 iter), loss = 1.91382
I0802 04:59:36.192446 18636 solver.cpp:375]     Train net output #0: loss = 1.89274 (* 1 = 1.89274 loss)
I0802 04:59:36.192453 18636 sgd_solver.cpp:136] Iteration 7200, lr = 0.00955, m = 0.9
I0802 04:59:50.109035 18636 solver.cpp:353] Iteration 7300 (7.18582 iter/s, 13.9163s/100 iter), loss = 1.17835
I0802 04:59:50.109063 18636 solver.cpp:375]     Train net output #0: loss = 0.990199 (* 1 = 0.990199 loss)
I0802 04:59:50.109069 18636 sgd_solver.cpp:136] Iteration 7300, lr = 0.00954375, m = 0.9
I0802 05:00:03.990999 18636 solver.cpp:353] Iteration 7400 (7.20378 iter/s, 13.8816s/100 iter), loss = 1.72353
I0802 05:00:03.991029 18636 solver.cpp:375]     Train net output #0: loss = 1.57782 (* 1 = 1.57782 loss)
I0802 05:00:03.991036 18636 sgd_solver.cpp:136] Iteration 7400, lr = 0.0095375, m = 0.9
I0802 05:00:17.855082 18636 solver.cpp:353] Iteration 7500 (7.21308 iter/s, 13.8637s/100 iter), loss = 1.7722
I0802 05:00:17.855155 18636 solver.cpp:375]     Train net output #0: loss = 2.17071 (* 1 = 2.17071 loss)
I0802 05:00:17.855162 18636 sgd_solver.cpp:136] Iteration 7500, lr = 0.00953125, m = 0.9
I0802 05:00:31.691184 18636 solver.cpp:353] Iteration 7600 (7.22766 iter/s, 13.8357s/100 iter), loss = 1.27205
I0802 05:00:31.691385 18636 solver.cpp:375]     Train net output #0: loss = 1.12413 (* 1 = 1.12413 loss)
I0802 05:00:31.691476 18636 sgd_solver.cpp:136] Iteration 7600, lr = 0.009525, m = 0.9
I0802 05:00:45.606993 18636 solver.cpp:353] Iteration 7700 (7.18626 iter/s, 13.9154s/100 iter), loss = 1.10668
I0802 05:00:45.607084 18636 solver.cpp:375]     Train net output #0: loss = 0.999282 (* 1 = 0.999282 loss)
I0802 05:00:45.607103 18636 sgd_solver.cpp:136] Iteration 7700, lr = 0.00951875, m = 0.9
I0802 05:00:59.428810 18636 solver.cpp:353] Iteration 7800 (7.23513 iter/s, 13.8214s/100 iter), loss = 1.4092
I0802 05:00:59.428995 18636 solver.cpp:375]     Train net output #0: loss = 1.54673 (* 1 = 1.54673 loss)
I0802 05:00:59.429013 18636 sgd_solver.cpp:136] Iteration 7800, lr = 0.0095125, m = 0.9
I0802 05:01:13.284245 18636 solver.cpp:353] Iteration 7900 (7.21758 iter/s, 13.8551s/100 iter), loss = 1.18931
I0802 05:01:13.284272 18636 solver.cpp:375]     Train net output #0: loss = 1.28331 (* 1 = 1.28331 loss)
I0802 05:01:13.284349 18636 sgd_solver.cpp:136] Iteration 7900, lr = 0.00950625, m = 0.9
I0802 05:01:27.037045 18636 solver.cpp:404] Sparsity after update:
I0802 05:01:27.041007 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:01:27.041033 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:01:27.041046 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:01:27.041055 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:01:27.041064 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:01:27.041071 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:01:27.041079 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:01:27.041087 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:01:27.041095 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:01:27.041102 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:01:27.041110 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:01:27.041118 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:01:27.041126 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:01:27.041141 18636 solver.cpp:550] Iteration 8000, Testing net (#0)
I0802 05:01:32.740919 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:01:46.241772 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.538059
I0802 05:01:46.241798 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.778174
I0802 05:01:46.241806 18636 solver.cpp:635]     Test net output #2: loss = 2.04737 (* 1 = 2.04737 loss)
I0802 05:01:46.241855 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2002s
I0802 05:01:46.379637 18636 solver.cpp:353] Iteration 8000 (3.02165 iter/s, 33.0945s/100 iter), loss = 1.46263
I0802 05:01:46.379667 18636 solver.cpp:375]     Train net output #0: loss = 1.29611 (* 1 = 1.29611 loss)
I0802 05:01:46.379673 18636 sgd_solver.cpp:136] Iteration 8000, lr = 0.0095, m = 0.9
I0802 05:02:00.218849 18636 solver.cpp:353] Iteration 8100 (7.22604 iter/s, 13.8388s/100 iter), loss = 1.59933
I0802 05:02:00.218880 18636 solver.cpp:375]     Train net output #0: loss = 1.64596 (* 1 = 1.64596 loss)
I0802 05:02:00.218886 18636 sgd_solver.cpp:136] Iteration 8100, lr = 0.00949375, m = 0.9
I0802 05:02:14.094224 18636 solver.cpp:353] Iteration 8200 (7.20721 iter/s, 13.875s/100 iter), loss = 1.54464
I0802 05:02:14.094290 18636 solver.cpp:375]     Train net output #0: loss = 1.54173 (* 1 = 1.54173 loss)
I0802 05:02:14.094295 18636 sgd_solver.cpp:136] Iteration 8200, lr = 0.0094875, m = 0.9
I0802 05:02:27.997720 18636 solver.cpp:353] Iteration 8300 (7.19263 iter/s, 13.9031s/100 iter), loss = 1.07007
I0802 05:02:27.997747 18636 solver.cpp:375]     Train net output #0: loss = 1.29533 (* 1 = 1.29533 loss)
I0802 05:02:27.997753 18636 sgd_solver.cpp:136] Iteration 8300, lr = 0.00948125, m = 0.9
I0802 05:02:41.856050 18636 solver.cpp:353] Iteration 8400 (7.21607 iter/s, 13.858s/100 iter), loss = 1.41191
I0802 05:02:41.856078 18636 solver.cpp:375]     Train net output #0: loss = 1.66202 (* 1 = 1.66202 loss)
I0802 05:02:41.856083 18636 sgd_solver.cpp:136] Iteration 8400, lr = 0.009475, m = 0.9
I0802 05:02:55.762964 18636 solver.cpp:353] Iteration 8500 (7.19086 iter/s, 13.9065s/100 iter), loss = 1.63513
I0802 05:02:55.763027 18636 solver.cpp:375]     Train net output #0: loss = 1.8706 (* 1 = 1.8706 loss)
I0802 05:02:55.763034 18636 sgd_solver.cpp:136] Iteration 8500, lr = 0.00946875, m = 0.9
I0802 05:03:09.755496 18636 solver.cpp:353] Iteration 8600 (7.14686 iter/s, 13.9922s/100 iter), loss = 1.66202
I0802 05:03:09.755594 18636 solver.cpp:375]     Train net output #0: loss = 1.79235 (* 1 = 1.79235 loss)
I0802 05:03:09.755612 18636 sgd_solver.cpp:136] Iteration 8600, lr = 0.0094625, m = 0.9
I0802 05:03:23.740362 18636 solver.cpp:353] Iteration 8700 (7.15078 iter/s, 13.9845s/100 iter), loss = 1.07931
I0802 05:03:23.740387 18636 solver.cpp:375]     Train net output #0: loss = 1.11741 (* 1 = 1.11741 loss)
I0802 05:03:23.740521 18636 sgd_solver.cpp:136] Iteration 8700, lr = 0.00945625, m = 0.9
I0802 05:03:37.691612 18636 solver.cpp:353] Iteration 8800 (7.16801 iter/s, 13.9509s/100 iter), loss = 1.35378
I0802 05:03:37.691671 18636 solver.cpp:375]     Train net output #0: loss = 1.63088 (* 1 = 1.63088 loss)
I0802 05:03:37.691678 18636 sgd_solver.cpp:136] Iteration 8800, lr = 0.00945, m = 0.9
I0802 05:03:51.675288 18636 solver.cpp:353] Iteration 8900 (7.15139 iter/s, 13.9833s/100 iter), loss = 1.612
I0802 05:03:51.675318 18636 solver.cpp:375]     Train net output #0: loss = 1.77736 (* 1 = 1.77736 loss)
I0802 05:03:51.675323 18636 sgd_solver.cpp:136] Iteration 8900, lr = 0.00944375, m = 0.9
I0802 05:04:05.455504 18636 solver.cpp:404] Sparsity after update:
I0802 05:04:05.468346 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:04:05.468366 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:04:05.468374 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:04:05.468377 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:04:05.468380 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:04:05.468384 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:04:05.468396 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:04:05.468405 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:04:05.468415 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:04:05.468422 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:04:05.468430 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:04:05.468438 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:04:05.468447 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:04:05.598258 18636 solver.cpp:353] Iteration 9000 (7.18257 iter/s, 13.9226s/100 iter), loss = 1.41228
I0802 05:04:05.598284 18636 solver.cpp:375]     Train net output #0: loss = 1.316 (* 1 = 1.316 loss)
I0802 05:04:05.598289 18636 sgd_solver.cpp:136] Iteration 9000, lr = 0.0094375, m = 0.9
I0802 05:04:19.507028 18636 solver.cpp:353] Iteration 9100 (7.1899 iter/s, 13.9084s/100 iter), loss = 1.38701
I0802 05:04:19.507084 18636 solver.cpp:375]     Train net output #0: loss = 1.01615 (* 1 = 1.01615 loss)
I0802 05:04:19.507091 18636 sgd_solver.cpp:136] Iteration 9100, lr = 0.00943125, m = 0.9
I0802 05:04:33.481158 18636 solver.cpp:353] Iteration 9200 (7.15627 iter/s, 13.9738s/100 iter), loss = 1.57483
I0802 05:04:33.481202 18636 solver.cpp:375]     Train net output #0: loss = 1.78519 (* 1 = 1.78519 loss)
I0802 05:04:33.481210 18636 sgd_solver.cpp:136] Iteration 9200, lr = 0.009425, m = 0.9
I0802 05:04:47.369740 18636 solver.cpp:353] Iteration 9300 (7.20035 iter/s, 13.8882s/100 iter), loss = 2.04938
I0802 05:04:47.369767 18636 solver.cpp:375]     Train net output #0: loss = 2.46906 (* 1 = 2.46906 loss)
I0802 05:04:47.369774 18636 sgd_solver.cpp:136] Iteration 9300, lr = 0.00941875, m = 0.9
I0802 05:05:01.274790 18636 solver.cpp:353] Iteration 9400 (7.19183 iter/s, 13.9047s/100 iter), loss = 1.33343
I0802 05:05:01.274926 18636 solver.cpp:375]     Train net output #0: loss = 1.10483 (* 1 = 1.10483 loss)
I0802 05:05:01.274945 18636 sgd_solver.cpp:136] Iteration 9400, lr = 0.0094125, m = 0.9
I0802 05:05:15.201956 18636 solver.cpp:353] Iteration 9500 (7.1804 iter/s, 13.9268s/100 iter), loss = 1.69231
I0802 05:05:15.201989 18636 solver.cpp:375]     Train net output #0: loss = 1.7673 (* 1 = 1.7673 loss)
I0802 05:05:15.201995 18636 sgd_solver.cpp:136] Iteration 9500, lr = 0.00940625, m = 0.9
I0802 05:05:29.111989 18636 solver.cpp:353] Iteration 9600 (7.18925 iter/s, 13.9097s/100 iter), loss = 1.74886
I0802 05:05:29.112013 18636 solver.cpp:375]     Train net output #0: loss = 1.96588 (* 1 = 1.96588 loss)
I0802 05:05:29.112017 18636 sgd_solver.cpp:136] Iteration 9600, lr = 0.0094, m = 0.9
I0802 05:05:43.043020 18636 solver.cpp:353] Iteration 9700 (7.17841 iter/s, 13.9307s/100 iter), loss = 1.45507
I0802 05:05:43.043102 18636 solver.cpp:375]     Train net output #0: loss = 1.66859 (* 1 = 1.66859 loss)
I0802 05:05:43.043109 18636 sgd_solver.cpp:136] Iteration 9700, lr = 0.00939375, m = 0.9
I0802 05:05:56.872213 18636 solver.cpp:353] Iteration 9800 (7.23127 iter/s, 13.8288s/100 iter), loss = 1.16169
I0802 05:05:56.872242 18636 solver.cpp:375]     Train net output #0: loss = 1.24524 (* 1 = 1.24524 loss)
I0802 05:05:56.872248 18636 sgd_solver.cpp:136] Iteration 9800, lr = 0.0093875, m = 0.9
I0802 05:06:10.794850 18636 solver.cpp:353] Iteration 9900 (7.18274 iter/s, 13.9223s/100 iter), loss = 1.06741
I0802 05:06:10.794876 18636 solver.cpp:375]     Train net output #0: loss = 1.09565 (* 1 = 1.09565 loss)
I0802 05:06:10.794880 18636 sgd_solver.cpp:136] Iteration 9900, lr = 0.00938125, m = 0.9
I0802 05:06:24.550987 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_10000.caffemodel
I0802 05:06:24.640632 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_10000.solverstate
I0802 05:06:24.646739 18636 solver.cpp:404] Sparsity after update:
I0802 05:06:24.648044 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:06:24.648053 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:06:24.648062 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:06:24.648066 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:06:24.648068 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:06:24.648072 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:06:24.648074 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:06:24.648077 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:06:24.648080 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:06:24.648083 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:06:24.648087 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:06:24.648092 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:06:24.648095 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:06:24.648105 18636 solver.cpp:550] Iteration 10000, Testing net (#0)
I0802 05:06:43.966737 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545176
I0802 05:06:43.966764 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786057
I0802 05:06:43.966769 18636 solver.cpp:635]     Test net output #2: loss = 2.0029 (* 1 = 2.0029 loss)
I0802 05:06:43.966817 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3182s
I0802 05:06:44.106503 18636 solver.cpp:353] Iteration 10000 (3.00203 iter/s, 33.3108s/100 iter), loss = 1.41626
I0802 05:06:44.106526 18636 solver.cpp:375]     Train net output #0: loss = 1.13567 (* 1 = 1.13567 loss)
I0802 05:06:44.106530 18636 sgd_solver.cpp:136] Iteration 10000, lr = 0.009375, m = 0.9
I0802 05:06:57.985812 18636 solver.cpp:353] Iteration 10100 (7.20516 iter/s, 13.8789s/100 iter), loss = 1.16987
I0802 05:06:57.985880 18636 solver.cpp:375]     Train net output #0: loss = 1.3719 (* 1 = 1.3719 loss)
I0802 05:06:57.985885 18636 sgd_solver.cpp:136] Iteration 10100, lr = 0.00936875, m = 0.9
I0802 05:07:11.778300 18636 solver.cpp:353] Iteration 10200 (7.25052 iter/s, 13.7921s/100 iter), loss = 1.40301
I0802 05:07:11.778326 18636 solver.cpp:375]     Train net output #0: loss = 1.35546 (* 1 = 1.35546 loss)
I0802 05:07:11.778331 18636 sgd_solver.cpp:136] Iteration 10200, lr = 0.0093625, m = 0.9
I0802 05:07:25.630964 18636 solver.cpp:353] Iteration 10300 (7.21902 iter/s, 13.8523s/100 iter), loss = 1.51182
I0802 05:07:25.630991 18636 solver.cpp:375]     Train net output #0: loss = 1.87202 (* 1 = 1.87202 loss)
I0802 05:07:25.630997 18636 sgd_solver.cpp:136] Iteration 10300, lr = 0.00935625, m = 0.9
I0802 05:07:39.563318 18636 solver.cpp:353] Iteration 10400 (7.17773 iter/s, 13.932s/100 iter), loss = 1.30222
I0802 05:07:39.568851 18636 solver.cpp:375]     Train net output #0: loss = 1.04902 (* 1 = 1.04902 loss)
I0802 05:07:39.568863 18636 sgd_solver.cpp:136] Iteration 10400, lr = 0.00935, m = 0.9
I0802 05:07:53.458145 18636 solver.cpp:353] Iteration 10500 (7.19712 iter/s, 13.8945s/100 iter), loss = 1.12604
I0802 05:07:53.458232 18636 solver.cpp:375]     Train net output #0: loss = 0.862887 (* 1 = 0.862887 loss)
I0802 05:07:53.458251 18636 sgd_solver.cpp:136] Iteration 10500, lr = 0.00934375, m = 0.9
I0802 05:08:07.426353 18636 solver.cpp:353] Iteration 10600 (7.15931 iter/s, 13.9678s/100 iter), loss = 1.68947
I0802 05:08:07.426378 18636 solver.cpp:375]     Train net output #0: loss = 1.88788 (* 1 = 1.88788 loss)
I0802 05:08:07.426384 18636 sgd_solver.cpp:136] Iteration 10600, lr = 0.0093375, m = 0.9
I0802 05:08:21.357084 18636 solver.cpp:353] Iteration 10700 (7.17857 iter/s, 13.9304s/100 iter), loss = 1.51223
I0802 05:08:21.357156 18636 solver.cpp:375]     Train net output #0: loss = 1.22732 (* 1 = 1.22732 loss)
I0802 05:08:21.357163 18636 sgd_solver.cpp:136] Iteration 10700, lr = 0.00933125, m = 0.9
I0802 05:08:35.277541 18636 solver.cpp:353] Iteration 10800 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.30428
I0802 05:08:35.277570 18636 solver.cpp:375]     Train net output #0: loss = 1.08756 (* 1 = 1.08756 loss)
I0802 05:08:35.277576 18636 sgd_solver.cpp:136] Iteration 10800, lr = 0.009325, m = 0.9
I0802 05:08:49.181172 18636 solver.cpp:353] Iteration 10900 (7.19256 iter/s, 13.9033s/100 iter), loss = 1.55089
I0802 05:08:49.181198 18636 solver.cpp:375]     Train net output #0: loss = 1.58958 (* 1 = 1.58958 loss)
I0802 05:08:49.181205 18636 sgd_solver.cpp:136] Iteration 10900, lr = 0.00931875, m = 0.9
I0802 05:09:02.917752 18636 solver.cpp:404] Sparsity after update:
I0802 05:09:02.932209 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:09:02.932262 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:09:02.932291 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:09:02.932304 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:09:02.932317 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:09:02.932329 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:09:02.932341 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:09:02.932354 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:09:02.932366 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:09:02.932379 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:09:02.932390 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:09:02.932402 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:09:02.932415 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:09:03.063855 18636 solver.cpp:353] Iteration 11000 (7.20341 iter/s, 13.8823s/100 iter), loss = 1.07035
I0802 05:09:03.063926 18636 solver.cpp:375]     Train net output #0: loss = 0.931263 (* 1 = 0.931263 loss)
I0802 05:09:03.063944 18636 sgd_solver.cpp:136] Iteration 11000, lr = 0.0093125, m = 0.9
I0802 05:09:16.951753 18636 solver.cpp:353] Iteration 11100 (7.20071 iter/s, 13.8875s/100 iter), loss = 1.65756
I0802 05:09:16.951779 18636 solver.cpp:375]     Train net output #0: loss = 1.47072 (* 1 = 1.47072 loss)
I0802 05:09:16.951786 18636 sgd_solver.cpp:136] Iteration 11100, lr = 0.00930625, m = 0.9
I0802 05:09:30.782676 18636 solver.cpp:353] Iteration 11200 (7.23037 iter/s, 13.8305s/100 iter), loss = 1.16568
I0802 05:09:30.782752 18636 solver.cpp:375]     Train net output #0: loss = 1.09341 (* 1 = 1.09341 loss)
I0802 05:09:30.782771 18636 sgd_solver.cpp:136] Iteration 11200, lr = 0.0093, m = 0.9
I0802 05:09:44.684280 18636 solver.cpp:353] Iteration 11300 (7.19361 iter/s, 13.9012s/100 iter), loss = 1.46043
I0802 05:09:44.684350 18636 solver.cpp:375]     Train net output #0: loss = 1.29646 (* 1 = 1.29646 loss)
I0802 05:09:44.684356 18636 sgd_solver.cpp:136] Iteration 11300, lr = 0.00929375, m = 0.9
I0802 05:09:58.617301 18636 solver.cpp:353] Iteration 11400 (7.17739 iter/s, 13.9326s/100 iter), loss = 1.7512
I0802 05:09:58.617326 18636 solver.cpp:375]     Train net output #0: loss = 1.82513 (* 1 = 1.82513 loss)
I0802 05:09:58.617331 18636 sgd_solver.cpp:136] Iteration 11400, lr = 0.0092875, m = 0.9
I0802 05:10:12.534874 18636 solver.cpp:353] Iteration 11500 (7.18535 iter/s, 13.9172s/100 iter), loss = 1.96538
I0802 05:10:12.534903 18636 solver.cpp:375]     Train net output #0: loss = 1.45159 (* 1 = 1.45159 loss)
I0802 05:10:12.534909 18636 sgd_solver.cpp:136] Iteration 11500, lr = 0.00928125, m = 0.9
I0802 05:10:26.456550 18636 solver.cpp:353] Iteration 11600 (7.18324 iter/s, 13.9213s/100 iter), loss = 1.10327
I0802 05:10:26.456692 18636 solver.cpp:375]     Train net output #0: loss = 1.00122 (* 1 = 1.00122 loss)
I0802 05:10:26.456712 18636 sgd_solver.cpp:136] Iteration 11600, lr = 0.009275, m = 0.9
I0802 05:10:40.368288 18636 solver.cpp:353] Iteration 11700 (7.18837 iter/s, 13.9114s/100 iter), loss = 1.24648
I0802 05:10:40.368381 18636 solver.cpp:375]     Train net output #0: loss = 1.36835 (* 1 = 1.36835 loss)
I0802 05:10:40.368399 18636 sgd_solver.cpp:136] Iteration 11700, lr = 0.00926875, m = 0.9
I0802 05:10:54.272001 18636 solver.cpp:353] Iteration 11800 (7.19252 iter/s, 13.9033s/100 iter), loss = 1.47204
I0802 05:10:54.272032 18636 solver.cpp:375]     Train net output #0: loss = 0.948505 (* 1 = 0.948505 loss)
I0802 05:10:54.272038 18636 sgd_solver.cpp:136] Iteration 11800, lr = 0.0092625, m = 0.9
I0802 05:11:08.282202 18636 solver.cpp:353] Iteration 11900 (7.13785 iter/s, 14.0098s/100 iter), loss = 1.8833
I0802 05:11:08.282285 18636 solver.cpp:375]     Train net output #0: loss = 2.25845 (* 1 = 2.25845 loss)
I0802 05:11:08.282294 18636 sgd_solver.cpp:136] Iteration 11900, lr = 0.00925625, m = 0.9
I0802 05:11:22.002900 18636 solver.cpp:404] Sparsity after update:
I0802 05:11:22.006853 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:11:22.006865 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:11:22.006873 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:11:22.006876 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:11:22.006882 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:11:22.006886 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:11:22.006889 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:11:22.006891 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:11:22.006894 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:11:22.006898 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:11:22.006901 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:11:22.006904 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:11:22.006908 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:11:22.006920 18636 solver.cpp:550] Iteration 12000, Testing net (#0)
I0802 05:11:41.183079 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.532176
I0802 05:11:41.183190 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.77441
I0802 05:11:41.183202 18636 solver.cpp:635]     Test net output #2: loss = 2.0914 (* 1 = 2.0914 loss)
I0802 05:11:41.183223 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1758s
I0802 05:11:41.324180 18636 solver.cpp:353] Iteration 12000 (3.02653 iter/s, 33.0411s/100 iter), loss = 1.46126
I0802 05:11:41.324257 18636 solver.cpp:375]     Train net output #0: loss = 1.36349 (* 1 = 1.36349 loss)
I0802 05:11:41.324278 18636 sgd_solver.cpp:136] Iteration 12000, lr = 0.00925, m = 0.9
I0802 05:11:55.258982 18636 solver.cpp:353] Iteration 12100 (7.17647 iter/s, 13.9344s/100 iter), loss = 1.66599
I0802 05:11:55.259007 18636 solver.cpp:375]     Train net output #0: loss = 1.67516 (* 1 = 1.67516 loss)
I0802 05:11:55.259012 18636 sgd_solver.cpp:136] Iteration 12100, lr = 0.00924375, m = 0.9
I0802 05:12:09.130162 18636 solver.cpp:353] Iteration 12200 (7.20939 iter/s, 13.8708s/100 iter), loss = 1.18156
I0802 05:12:09.130192 18636 solver.cpp:375]     Train net output #0: loss = 1.07089 (* 1 = 1.07089 loss)
I0802 05:12:09.130198 18636 sgd_solver.cpp:136] Iteration 12200, lr = 0.0092375, m = 0.9
I0802 05:12:23.062439 18636 solver.cpp:353] Iteration 12300 (7.17777 iter/s, 13.9319s/100 iter), loss = 0.940485
I0802 05:12:23.062511 18636 solver.cpp:375]     Train net output #0: loss = 1.1388 (* 1 = 1.1388 loss)
I0802 05:12:23.062518 18636 sgd_solver.cpp:136] Iteration 12300, lr = 0.00923125, m = 0.9
I0802 05:12:36.922199 18636 solver.cpp:353] Iteration 12400 (7.21533 iter/s, 13.8594s/100 iter), loss = 1.23913
I0802 05:12:36.922225 18636 solver.cpp:375]     Train net output #0: loss = 1.06177 (* 1 = 1.06177 loss)
I0802 05:12:36.922231 18636 sgd_solver.cpp:136] Iteration 12400, lr = 0.009225, m = 0.9
I0802 05:12:50.873733 18636 solver.cpp:353] Iteration 12500 (7.16786 iter/s, 13.9512s/100 iter), loss = 1.37424
I0802 05:12:50.873760 18636 solver.cpp:375]     Train net output #0: loss = 1.38143 (* 1 = 1.38143 loss)
I0802 05:12:50.873765 18636 sgd_solver.cpp:136] Iteration 12500, lr = 0.00921875, m = 0.9
I0802 05:13:04.864334 18636 solver.cpp:353] Iteration 12600 (7.14785 iter/s, 13.9902s/100 iter), loss = 1.94755
I0802 05:13:04.864398 18636 solver.cpp:375]     Train net output #0: loss = 1.61048 (* 1 = 1.61048 loss)
I0802 05:13:04.864403 18636 sgd_solver.cpp:136] Iteration 12600, lr = 0.0092125, m = 0.9
I0802 05:13:18.839527 18636 solver.cpp:353] Iteration 12700 (7.15573 iter/s, 13.9748s/100 iter), loss = 1.25097
I0802 05:13:18.839601 18636 solver.cpp:375]     Train net output #0: loss = 1.22904 (* 1 = 1.22904 loss)
I0802 05:13:18.839622 18636 sgd_solver.cpp:136] Iteration 12700, lr = 0.00920625, m = 0.9
I0802 05:13:32.800871 18636 solver.cpp:353] Iteration 12800 (7.16283 iter/s, 13.961s/100 iter), loss = 1.62802
I0802 05:13:32.800894 18636 solver.cpp:375]     Train net output #0: loss = 1.71379 (* 1 = 1.71379 loss)
I0802 05:13:32.800899 18636 sgd_solver.cpp:136] Iteration 12800, lr = 0.0092, m = 0.9
I0802 05:13:46.734324 18636 solver.cpp:353] Iteration 12900 (7.17716 iter/s, 13.9331s/100 iter), loss = 1.14665
I0802 05:13:46.734381 18636 solver.cpp:375]     Train net output #0: loss = 1.29307 (* 1 = 1.29307 loss)
I0802 05:13:46.734386 18636 sgd_solver.cpp:136] Iteration 12900, lr = 0.00919375, m = 0.9
I0802 05:14:00.555871 18636 solver.cpp:404] Sparsity after update:
I0802 05:14:00.566409 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:14:00.566428 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:14:00.566438 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:14:00.566442 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:14:00.566445 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:14:00.566449 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:14:00.566453 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:14:00.566457 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:14:00.566462 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:14:00.566465 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:14:00.566469 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:14:00.566473 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:14:00.566475 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:14:00.696218 18636 solver.cpp:353] Iteration 13000 (7.16254 iter/s, 13.9615s/100 iter), loss = 1.42068
I0802 05:14:00.696249 18636 solver.cpp:375]     Train net output #0: loss = 1.52428 (* 1 = 1.52428 loss)
I0802 05:14:00.696254 18636 sgd_solver.cpp:136] Iteration 13000, lr = 0.0091875, m = 0.9
I0802 05:14:14.671617 18636 solver.cpp:353] Iteration 13100 (7.15562 iter/s, 13.975s/100 iter), loss = 1.62978
I0802 05:14:14.671645 18636 solver.cpp:375]     Train net output #0: loss = 1.45921 (* 1 = 1.45921 loss)
I0802 05:14:14.671651 18636 sgd_solver.cpp:136] Iteration 13100, lr = 0.00918125, m = 0.9
I0802 05:14:28.610309 18636 solver.cpp:353] Iteration 13200 (7.17447 iter/s, 13.9383s/100 iter), loss = 1.71688
I0802 05:14:28.610536 18636 solver.cpp:375]     Train net output #0: loss = 1.55691 (* 1 = 1.55691 loss)
I0802 05:14:28.610543 18636 sgd_solver.cpp:136] Iteration 13200, lr = 0.009175, m = 0.9
I0802 05:14:42.569718 18636 solver.cpp:353] Iteration 13300 (7.16382 iter/s, 13.959s/100 iter), loss = 1.13932
I0802 05:14:42.569748 18636 solver.cpp:375]     Train net output #0: loss = 1.00764 (* 1 = 1.00764 loss)
I0802 05:14:42.569754 18636 sgd_solver.cpp:136] Iteration 13300, lr = 0.00916875, m = 0.9
I0802 05:14:56.490088 18636 solver.cpp:353] Iteration 13400 (7.18391 iter/s, 13.92s/100 iter), loss = 1.44258
I0802 05:14:56.490113 18636 solver.cpp:375]     Train net output #0: loss = 1.37717 (* 1 = 1.37717 loss)
I0802 05:14:56.490116 18636 sgd_solver.cpp:136] Iteration 13400, lr = 0.0091625, m = 0.9
I0802 05:15:10.515723 18636 solver.cpp:353] Iteration 13500 (7.12999 iter/s, 14.0253s/100 iter), loss = 1.18715
I0802 05:15:10.515806 18636 solver.cpp:375]     Train net output #0: loss = 1.2583 (* 1 = 1.2583 loss)
I0802 05:15:10.515813 18636 sgd_solver.cpp:136] Iteration 13500, lr = 0.00915625, m = 0.9
I0802 05:15:24.555548 18636 solver.cpp:353] Iteration 13600 (7.12279 iter/s, 14.0394s/100 iter), loss = 1.23433
I0802 05:15:24.555573 18636 solver.cpp:375]     Train net output #0: loss = 1.2649 (* 1 = 1.2649 loss)
I0802 05:15:24.555577 18636 sgd_solver.cpp:136] Iteration 13600, lr = 0.00915, m = 0.9
I0802 05:15:38.555088 18636 solver.cpp:353] Iteration 13700 (7.14328 iter/s, 13.9992s/100 iter), loss = 1.35563
I0802 05:15:38.555115 18636 solver.cpp:375]     Train net output #0: loss = 1.26144 (* 1 = 1.26144 loss)
I0802 05:15:38.555119 18636 sgd_solver.cpp:136] Iteration 13700, lr = 0.00914375, m = 0.9
I0802 05:15:52.474756 18636 solver.cpp:353] Iteration 13800 (7.18427 iter/s, 13.9193s/100 iter), loss = 1.32597
I0802 05:15:52.474840 18636 solver.cpp:375]     Train net output #0: loss = 1.14365 (* 1 = 1.14365 loss)
I0802 05:15:52.474848 18636 sgd_solver.cpp:136] Iteration 13800, lr = 0.0091375, m = 0.9
I0802 05:16:06.481912 18636 solver.cpp:353] Iteration 13900 (7.1394 iter/s, 14.0068s/100 iter), loss = 1.3844
I0802 05:16:06.481940 18636 solver.cpp:375]     Train net output #0: loss = 1.57618 (* 1 = 1.57618 loss)
I0802 05:16:06.481946 18636 sgd_solver.cpp:136] Iteration 13900, lr = 0.00913125, m = 0.9
I0802 05:16:20.316606 18636 solver.cpp:404] Sparsity after update:
I0802 05:16:20.321094 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:16:20.322137 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:16:20.322155 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:16:20.322264 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:16:20.322325 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:16:20.322391 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:16:20.322455 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:16:20.322470 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:16:20.322480 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:16:20.322489 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:16:20.322499 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:16:20.322515 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:16:20.322525 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:16:20.322544 18636 solver.cpp:550] Iteration 14000, Testing net (#0)
I0802 05:16:32.223212 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:16:40.104125 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.547941
I0802 05:16:40.104152 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786645
I0802 05:16:40.104159 18636 solver.cpp:635]     Test net output #2: loss = 2.02799 (* 1 = 2.02799 loss)
I0802 05:16:40.104177 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7811s
I0802 05:16:40.256855 18636 solver.cpp:353] Iteration 14000 (2.96085 iter/s, 33.774s/100 iter), loss = 1.47719
I0802 05:16:40.256886 18636 solver.cpp:375]     Train net output #0: loss = 1.68967 (* 1 = 1.68967 loss)
I0802 05:16:40.256893 18636 sgd_solver.cpp:136] Iteration 14000, lr = 0.009125, m = 0.9
I0802 05:16:54.166344 18636 solver.cpp:353] Iteration 14100 (7.18953 iter/s, 13.9091s/100 iter), loss = 1.7227
I0802 05:16:54.166373 18636 solver.cpp:375]     Train net output #0: loss = 2.12618 (* 1 = 2.12618 loss)
I0802 05:16:54.166378 18636 sgd_solver.cpp:136] Iteration 14100, lr = 0.00911875, m = 0.9
I0802 05:17:08.028828 18636 solver.cpp:353] Iteration 14200 (7.21391 iter/s, 13.8621s/100 iter), loss = 1.5752
I0802 05:17:08.028894 18636 solver.cpp:375]     Train net output #0: loss = 1.7972 (* 1 = 1.7972 loss)
I0802 05:17:08.028901 18636 sgd_solver.cpp:136] Iteration 14200, lr = 0.0091125, m = 0.9
I0802 05:17:21.887006 18636 solver.cpp:353] Iteration 14300 (7.21615 iter/s, 13.8578s/100 iter), loss = 1.41944
I0802 05:17:21.887030 18636 solver.cpp:375]     Train net output #0: loss = 1.46848 (* 1 = 1.46848 loss)
I0802 05:17:21.887035 18636 sgd_solver.cpp:136] Iteration 14300, lr = 0.00910625, m = 0.9
I0802 05:17:35.721982 18636 solver.cpp:353] Iteration 14400 (7.22825 iter/s, 13.8346s/100 iter), loss = 1.44828
I0802 05:17:35.722036 18636 solver.cpp:375]     Train net output #0: loss = 1.68453 (* 1 = 1.68453 loss)
I0802 05:17:35.722048 18636 sgd_solver.cpp:136] Iteration 14400, lr = 0.0091, m = 0.9
I0802 05:17:49.579622 18636 solver.cpp:353] Iteration 14500 (7.21643 iter/s, 13.8573s/100 iter), loss = 1.45777
I0802 05:17:49.579710 18636 solver.cpp:375]     Train net output #0: loss = 1.51019 (* 1 = 1.51019 loss)
I0802 05:17:49.579716 18636 sgd_solver.cpp:136] Iteration 14500, lr = 0.00909375, m = 0.9
I0802 05:18:03.532361 18636 solver.cpp:353] Iteration 14600 (7.16725 iter/s, 13.9524s/100 iter), loss = 1.42475
I0802 05:18:03.532410 18636 solver.cpp:375]     Train net output #0: loss = 1.02638 (* 1 = 1.02638 loss)
I0802 05:18:03.532519 18636 sgd_solver.cpp:136] Iteration 14600, lr = 0.0090875, m = 0.9
I0802 05:18:17.435036 18636 solver.cpp:353] Iteration 14700 (7.19305 iter/s, 13.9023s/100 iter), loss = 1.4453
I0802 05:18:17.435101 18636 solver.cpp:375]     Train net output #0: loss = 1.48259 (* 1 = 1.48259 loss)
I0802 05:18:17.435123 18636 sgd_solver.cpp:136] Iteration 14700, lr = 0.00908125, m = 0.9
I0802 05:18:31.393128 18636 solver.cpp:353] Iteration 14800 (7.1645 iter/s, 13.9577s/100 iter), loss = 1.27523
I0802 05:18:31.393191 18636 solver.cpp:375]     Train net output #0: loss = 1.34106 (* 1 = 1.34106 loss)
I0802 05:18:31.393200 18636 sgd_solver.cpp:136] Iteration 14800, lr = 0.009075, m = 0.9
I0802 05:18:45.321465 18636 solver.cpp:353] Iteration 14900 (7.1798 iter/s, 13.928s/100 iter), loss = 1.29844
I0802 05:18:45.321490 18636 solver.cpp:375]     Train net output #0: loss = 1.41953 (* 1 = 1.41953 loss)
I0802 05:18:45.321494 18636 sgd_solver.cpp:136] Iteration 14900, lr = 0.00906875, m = 0.9
I0802 05:18:59.043818 18636 solver.cpp:404] Sparsity after update:
I0802 05:18:59.058166 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:18:59.058182 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:18:59.058190 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:18:59.058193 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:18:59.058197 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:18:59.058200 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:18:59.058203 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:18:59.058207 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:18:59.058209 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:18:59.058212 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:18:59.058215 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:18:59.058218 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:18:59.058221 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:18:59.189627 18636 solver.cpp:353] Iteration 15000 (7.21095 iter/s, 13.8678s/100 iter), loss = 1.51539
I0802 05:18:59.189679 18636 solver.cpp:375]     Train net output #0: loss = 1.44726 (* 1 = 1.44726 loss)
I0802 05:18:59.189692 18636 sgd_solver.cpp:136] Iteration 15000, lr = 0.0090625, m = 0.9
I0802 05:19:13.094259 18636 solver.cpp:353] Iteration 15100 (7.19204 iter/s, 13.9043s/100 iter), loss = 1.27794
I0802 05:19:13.094334 18636 solver.cpp:375]     Train net output #0: loss = 1.15503 (* 1 = 1.15503 loss)
I0802 05:19:13.094341 18636 sgd_solver.cpp:136] Iteration 15100, lr = 0.00905625, m = 0.9
I0802 05:19:27.049186 18636 solver.cpp:353] Iteration 15200 (7.16612 iter/s, 13.9546s/100 iter), loss = 1.80617
I0802 05:19:27.049214 18636 solver.cpp:375]     Train net output #0: loss = 1.9514 (* 1 = 1.9514 loss)
I0802 05:19:27.049221 18636 sgd_solver.cpp:136] Iteration 15200, lr = 0.00905, m = 0.9
I0802 05:19:40.978282 18636 solver.cpp:353] Iteration 15300 (7.17941 iter/s, 13.9287s/100 iter), loss = 1.31917
I0802 05:19:40.978312 18636 solver.cpp:375]     Train net output #0: loss = 1.35257 (* 1 = 1.35257 loss)
I0802 05:19:40.978317 18636 sgd_solver.cpp:136] Iteration 15300, lr = 0.00904375, m = 0.9
I0802 05:19:54.872757 18636 solver.cpp:353] Iteration 15400 (7.1973 iter/s, 13.8941s/100 iter), loss = 1.35222
I0802 05:19:54.872864 18636 solver.cpp:375]     Train net output #0: loss = 1.56204 (* 1 = 1.56204 loss)
I0802 05:19:54.872884 18636 sgd_solver.cpp:136] Iteration 15400, lr = 0.0090375, m = 0.9
I0802 05:20:08.768571 18636 solver.cpp:353] Iteration 15500 (7.19661 iter/s, 13.8954s/100 iter), loss = 1.82378
I0802 05:20:08.768656 18636 solver.cpp:375]     Train net output #0: loss = 1.82336 (* 1 = 1.82336 loss)
I0802 05:20:08.768677 18636 sgd_solver.cpp:136] Iteration 15500, lr = 0.00903125, m = 0.9
I0802 05:20:22.630192 18636 solver.cpp:353] Iteration 15600 (7.21436 iter/s, 13.8612s/100 iter), loss = 1.52658
I0802 05:20:22.630218 18636 solver.cpp:375]     Train net output #0: loss = 1.53204 (* 1 = 1.53204 loss)
I0802 05:20:22.630223 18636 sgd_solver.cpp:136] Iteration 15600, lr = 0.009025, m = 0.9
I0802 05:20:36.547076 18636 solver.cpp:353] Iteration 15700 (7.18571 iter/s, 13.9165s/100 iter), loss = 1.7171
I0802 05:20:36.547139 18636 solver.cpp:375]     Train net output #0: loss = 1.62115 (* 1 = 1.62115 loss)
I0802 05:20:36.547145 18636 sgd_solver.cpp:136] Iteration 15700, lr = 0.00901875, m = 0.9
I0802 05:20:50.411113 18636 solver.cpp:353] Iteration 15800 (7.2131 iter/s, 13.8637s/100 iter), loss = 1.37406
I0802 05:20:50.411167 18636 solver.cpp:375]     Train net output #0: loss = 1.4155 (* 1 = 1.4155 loss)
I0802 05:20:50.411180 18636 sgd_solver.cpp:136] Iteration 15800, lr = 0.0090125, m = 0.9
I0802 05:21:04.226763 18636 solver.cpp:353] Iteration 15900 (7.23836 iter/s, 13.8153s/100 iter), loss = 1.49226
I0802 05:21:04.226855 18636 solver.cpp:375]     Train net output #0: loss = 1.47413 (* 1 = 1.47413 loss)
I0802 05:21:04.226874 18636 sgd_solver.cpp:136] Iteration 15900, lr = 0.00900625, m = 0.9
I0802 05:21:17.958263 18636 solver.cpp:404] Sparsity after update:
I0802 05:21:17.962703 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:21:17.962714 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:21:17.962723 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:21:17.962726 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:21:17.962918 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:21:17.962937 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:21:17.962949 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:21:17.962959 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:21:17.962968 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:21:17.962978 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:21:17.962988 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:21:17.963001 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:21:17.963011 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:21:17.963029 18636 solver.cpp:550] Iteration 16000, Testing net (#0)
I0802 05:21:33.436034 18619 data_reader.cpp:264] Starting prefetch of epoch 2
I0802 05:21:37.125027 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545118
I0802 05:21:37.125051 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.78835
I0802 05:21:37.125056 18636 solver.cpp:635]     Test net output #2: loss = 1.9818 (* 1 = 1.9818 loss)
I0802 05:21:37.125082 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1615s
I0802 05:21:37.273218 18636 solver.cpp:353] Iteration 16000 (3.02612 iter/s, 33.0456s/100 iter), loss = 1.10273
I0802 05:21:37.273247 18636 solver.cpp:375]     Train net output #0: loss = 1.12065 (* 1 = 1.12065 loss)
I0802 05:21:37.273252 18636 sgd_solver.cpp:136] Iteration 16000, lr = 0.009, m = 0.9
I0802 05:21:51.206502 18636 solver.cpp:353] Iteration 16100 (7.17725 iter/s, 13.9329s/100 iter), loss = 1.4361
I0802 05:21:51.206571 18636 solver.cpp:375]     Train net output #0: loss = 1.28775 (* 1 = 1.28775 loss)
I0802 05:21:51.206578 18636 sgd_solver.cpp:136] Iteration 16100, lr = 0.00899375, m = 0.9
I0802 05:22:05.070497 18636 solver.cpp:353] Iteration 16200 (7.21313 iter/s, 13.8636s/100 iter), loss = 1.25098
I0802 05:22:05.070524 18636 solver.cpp:375]     Train net output #0: loss = 1.44754 (* 1 = 1.44754 loss)
I0802 05:22:05.070529 18636 sgd_solver.cpp:136] Iteration 16200, lr = 0.0089875, m = 0.9
I0802 05:22:18.969538 18636 solver.cpp:353] Iteration 16300 (7.19494 iter/s, 13.8987s/100 iter), loss = 1.15624
I0802 05:22:18.969599 18636 solver.cpp:375]     Train net output #0: loss = 1.00725 (* 1 = 1.00725 loss)
I0802 05:22:18.969611 18636 sgd_solver.cpp:136] Iteration 16300, lr = 0.00898125, m = 0.9
I0802 05:22:32.839517 18636 solver.cpp:353] Iteration 16400 (7.21001 iter/s, 13.8696s/100 iter), loss = 1.36407
I0802 05:22:32.839642 18636 solver.cpp:375]     Train net output #0: loss = 1.1093 (* 1 = 1.1093 loss)
I0802 05:22:32.839661 18636 sgd_solver.cpp:136] Iteration 16400, lr = 0.008975, m = 0.9
I0802 05:22:46.722980 18636 solver.cpp:353] Iteration 16500 (7.20301 iter/s, 13.8831s/100 iter), loss = 1.5395
I0802 05:22:46.723057 18636 solver.cpp:375]     Train net output #0: loss = 1.88018 (* 1 = 1.88018 loss)
I0802 05:22:46.723079 18636 sgd_solver.cpp:136] Iteration 16500, lr = 0.00896875, m = 0.9
I0802 05:23:00.584707 18636 solver.cpp:353] Iteration 16600 (7.2143 iter/s, 13.8614s/100 iter), loss = 1.71827
I0802 05:23:00.584729 18636 solver.cpp:375]     Train net output #0: loss = 1.80719 (* 1 = 1.80719 loss)
I0802 05:23:00.584734 18636 sgd_solver.cpp:136] Iteration 16600, lr = 0.0089625, m = 0.9
I0802 05:23:14.442056 18636 solver.cpp:353] Iteration 16700 (7.21658 iter/s, 13.857s/100 iter), loss = 1.32967
I0802 05:23:14.442162 18636 solver.cpp:375]     Train net output #0: loss = 1.26811 (* 1 = 1.26811 loss)
I0802 05:23:14.442169 18636 sgd_solver.cpp:136] Iteration 16700, lr = 0.00895625, m = 0.9
I0802 05:23:28.317584 18636 solver.cpp:353] Iteration 16800 (7.20713 iter/s, 13.8752s/100 iter), loss = 1.22493
I0802 05:23:28.317606 18636 solver.cpp:375]     Train net output #0: loss = 1.2825 (* 1 = 1.2825 loss)
I0802 05:23:28.317611 18636 sgd_solver.cpp:136] Iteration 16800, lr = 0.00895, m = 0.9
I0802 05:23:42.258579 18636 solver.cpp:353] Iteration 16900 (7.17328 iter/s, 13.9406s/100 iter), loss = 1.30223
I0802 05:23:42.258604 18636 solver.cpp:375]     Train net output #0: loss = 1.3247 (* 1 = 1.3247 loss)
I0802 05:23:42.258607 18636 sgd_solver.cpp:136] Iteration 16900, lr = 0.00894375, m = 0.9
I0802 05:23:55.963856 18636 solver.cpp:404] Sparsity after update:
I0802 05:23:55.974319 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:23:55.974331 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:23:55.974339 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:23:55.974340 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:23:55.974342 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:23:55.974344 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:23:55.974346 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:23:55.974347 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:23:55.974349 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:23:55.974351 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:23:55.974356 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:23:55.974359 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:23:55.974360 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:23:56.103974 18636 solver.cpp:353] Iteration 17000 (7.22281 iter/s, 13.845s/100 iter), loss = 1.65736
I0802 05:23:56.104002 18636 solver.cpp:375]     Train net output #0: loss = 1.57223 (* 1 = 1.57223 loss)
I0802 05:23:56.104008 18636 sgd_solver.cpp:136] Iteration 17000, lr = 0.0089375, m = 0.9
I0802 05:24:09.986588 18636 solver.cpp:353] Iteration 17100 (7.20345 iter/s, 13.8822s/100 iter), loss = 1.40896
I0802 05:24:09.986611 18636 solver.cpp:375]     Train net output #0: loss = 1.29463 (* 1 = 1.29463 loss)
I0802 05:24:09.986615 18636 sgd_solver.cpp:136] Iteration 17100, lr = 0.00893125, m = 0.9
I0802 05:24:23.868880 18636 solver.cpp:353] Iteration 17200 (7.20362 iter/s, 13.8819s/100 iter), loss = 1.97233
I0802 05:24:23.868903 18636 solver.cpp:375]     Train net output #0: loss = 1.94361 (* 1 = 1.94361 loss)
I0802 05:24:23.868907 18636 sgd_solver.cpp:136] Iteration 17200, lr = 0.008925, m = 0.9
I0802 05:24:37.687897 18636 solver.cpp:353] Iteration 17300 (7.2366 iter/s, 13.8186s/100 iter), loss = 1.02718
I0802 05:24:37.687958 18636 solver.cpp:375]     Train net output #0: loss = 0.702612 (* 1 = 0.702612 loss)
I0802 05:24:37.687964 18636 sgd_solver.cpp:136] Iteration 17300, lr = 0.00891875, m = 0.9
I0802 05:24:51.606356 18636 solver.cpp:353] Iteration 17400 (7.1849 iter/s, 13.9181s/100 iter), loss = 1.46742
I0802 05:24:51.606386 18636 solver.cpp:375]     Train net output #0: loss = 1.74005 (* 1 = 1.74005 loss)
I0802 05:24:51.606393 18636 sgd_solver.cpp:136] Iteration 17400, lr = 0.0089125, m = 0.9
I0802 05:25:05.479851 18636 solver.cpp:353] Iteration 17500 (7.20818 iter/s, 13.8731s/100 iter), loss = 1.43945
I0802 05:25:05.479881 18636 solver.cpp:375]     Train net output #0: loss = 1.31185 (* 1 = 1.31185 loss)
I0802 05:25:05.479887 18636 sgd_solver.cpp:136] Iteration 17500, lr = 0.00890625, m = 0.9
I0802 05:25:19.436414 18636 solver.cpp:353] Iteration 17600 (7.16528 iter/s, 13.9562s/100 iter), loss = 1.35501
I0802 05:25:19.436532 18636 solver.cpp:375]     Train net output #0: loss = 1.54581 (* 1 = 1.54581 loss)
I0802 05:25:19.436553 18636 sgd_solver.cpp:136] Iteration 17600, lr = 0.0089, m = 0.9
I0802 05:25:33.349280 18636 solver.cpp:353] Iteration 17700 (7.18778 iter/s, 13.9125s/100 iter), loss = 1.5272
I0802 05:25:33.349306 18636 solver.cpp:375]     Train net output #0: loss = 1.83314 (* 1 = 1.83314 loss)
I0802 05:25:33.349313 18636 sgd_solver.cpp:136] Iteration 17700, lr = 0.00889375, m = 0.9
I0802 05:25:47.336400 18636 solver.cpp:353] Iteration 17800 (7.14963 iter/s, 13.9867s/100 iter), loss = 1.50605
I0802 05:25:47.336427 18636 solver.cpp:375]     Train net output #0: loss = 1.55337 (* 1 = 1.55337 loss)
I0802 05:25:47.336433 18636 sgd_solver.cpp:136] Iteration 17800, lr = 0.0088875, m = 0.9
I0802 05:26:01.240406 18636 solver.cpp:353] Iteration 17900 (7.19237 iter/s, 13.9036s/100 iter), loss = 1.09764
I0802 05:26:01.240574 18636 solver.cpp:375]     Train net output #0: loss = 0.732286 (* 1 = 0.732286 loss)
I0802 05:26:01.240597 18636 sgd_solver.cpp:136] Iteration 17900, lr = 0.00888125, m = 0.9
I0802 05:26:15.032248 18636 solver.cpp:404] Sparsity after update:
I0802 05:26:15.036761 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:26:15.036803 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:26:15.036834 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:26:15.036847 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:26:15.036860 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:26:15.036873 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:26:15.036885 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:26:15.036893 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:26:15.036901 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:26:15.036909 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:26:15.036918 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:26:15.036926 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:26:15.036936 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:26:15.036953 18636 solver.cpp:550] Iteration 18000, Testing net (#0)
I0802 05:26:34.076294 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.543764
I0802 05:26:34.076339 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.784057
I0802 05:26:34.076345 18636 solver.cpp:635]     Test net output #2: loss = 2.02545 (* 1 = 2.02545 loss)
I0802 05:26:34.076366 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.0389s
I0802 05:26:34.230080 18636 solver.cpp:353] Iteration 18000 (3.03133 iter/s, 32.9888s/100 iter), loss = 1.63438
I0802 05:26:34.230113 18636 solver.cpp:375]     Train net output #0: loss = 1.30954 (* 1 = 1.30954 loss)
I0802 05:26:34.230120 18636 sgd_solver.cpp:136] Iteration 18000, lr = 0.008875, m = 0.9
I0802 05:26:48.150887 18636 solver.cpp:353] Iteration 18100 (7.18369 iter/s, 13.9204s/100 iter), loss = 1.77469
I0802 05:26:48.150913 18636 solver.cpp:375]     Train net output #0: loss = 1.78332 (* 1 = 1.78332 loss)
I0802 05:26:48.150918 18636 sgd_solver.cpp:136] Iteration 18100, lr = 0.00886875, m = 0.9
I0802 05:27:02.079476 18636 solver.cpp:353] Iteration 18200 (7.17967 iter/s, 13.9282s/100 iter), loss = 1.61092
I0802 05:27:02.079502 18636 solver.cpp:375]     Train net output #0: loss = 1.32539 (* 1 = 1.32539 loss)
I0802 05:27:02.079507 18636 sgd_solver.cpp:136] Iteration 18200, lr = 0.0088625, m = 0.9
I0802 05:27:16.025403 18636 solver.cpp:353] Iteration 18300 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.56431
I0802 05:27:16.026970 18636 solver.cpp:375]     Train net output #0: loss = 1.54777 (* 1 = 1.54777 loss)
I0802 05:27:16.026978 18636 sgd_solver.cpp:136] Iteration 18300, lr = 0.00885625, m = 0.9
I0802 05:27:29.950011 18636 solver.cpp:353] Iteration 18400 (7.18173 iter/s, 13.9242s/100 iter), loss = 1.32837
I0802 05:27:29.950037 18636 solver.cpp:375]     Train net output #0: loss = 1.56175 (* 1 = 1.56175 loss)
I0802 05:27:29.950042 18636 sgd_solver.cpp:136] Iteration 18400, lr = 0.00885, m = 0.9
I0802 05:27:43.850275 18636 solver.cpp:353] Iteration 18500 (7.1943 iter/s, 13.8999s/100 iter), loss = 1.2
I0802 05:27:43.850301 18636 solver.cpp:375]     Train net output #0: loss = 1.47531 (* 1 = 1.47531 loss)
I0802 05:27:43.850306 18636 sgd_solver.cpp:136] Iteration 18500, lr = 0.00884375, m = 0.9
I0802 05:27:57.712074 18636 solver.cpp:353] Iteration 18600 (7.21427 iter/s, 13.8614s/100 iter), loss = 1.46373
I0802 05:27:57.712143 18636 solver.cpp:375]     Train net output #0: loss = 1.31826 (* 1 = 1.31826 loss)
I0802 05:27:57.712151 18636 sgd_solver.cpp:136] Iteration 18600, lr = 0.0088375, m = 0.9
I0802 05:28:11.706173 18636 solver.cpp:353] Iteration 18700 (7.14606 iter/s, 13.9937s/100 iter), loss = 1.51733
I0802 05:28:11.706198 18636 solver.cpp:375]     Train net output #0: loss = 1.68964 (* 1 = 1.68964 loss)
I0802 05:28:11.706203 18636 sgd_solver.cpp:136] Iteration 18700, lr = 0.00883125, m = 0.9
I0802 05:28:25.645344 18636 solver.cpp:353] Iteration 18800 (7.17422 iter/s, 13.9388s/100 iter), loss = 1.21066
I0802 05:28:25.645370 18636 solver.cpp:375]     Train net output #0: loss = 1.40112 (* 1 = 1.40112 loss)
I0802 05:28:25.645375 18636 sgd_solver.cpp:136] Iteration 18800, lr = 0.008825, m = 0.9
I0802 05:28:39.606240 18636 solver.cpp:353] Iteration 18900 (7.16306 iter/s, 13.9605s/100 iter), loss = 1.90997
I0802 05:28:39.606308 18636 solver.cpp:375]     Train net output #0: loss = 1.89836 (* 1 = 1.89836 loss)
I0802 05:28:39.606313 18636 sgd_solver.cpp:136] Iteration 18900, lr = 0.00881875, m = 0.9
I0802 05:28:53.388239 18636 solver.cpp:404] Sparsity after update:
I0802 05:28:53.401017 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:28:53.401028 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:28:53.401036 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:28:53.401041 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:28:53.401047 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:28:53.401053 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:28:53.401057 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:28:53.401062 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:28:53.401067 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:28:53.401072 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:28:53.401075 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:28:53.401078 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:28:53.401082 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:28:53.530748 18636 solver.cpp:353] Iteration 19000 (7.18178 iter/s, 13.9241s/100 iter), loss = 1.86526
I0802 05:28:53.530776 18636 solver.cpp:375]     Train net output #0: loss = 2.00912 (* 1 = 2.00912 loss)
I0802 05:28:53.530781 18636 sgd_solver.cpp:136] Iteration 19000, lr = 0.0088125, m = 0.9
I0802 05:29:07.538439 18636 solver.cpp:353] Iteration 19100 (7.13913 iter/s, 14.0073s/100 iter), loss = 1.29437
I0802 05:29:07.538466 18636 solver.cpp:375]     Train net output #0: loss = 1.05448 (* 1 = 1.05448 loss)
I0802 05:29:07.538473 18636 sgd_solver.cpp:136] Iteration 19100, lr = 0.00880625, m = 0.9
I0802 05:29:21.525013 18636 solver.cpp:353] Iteration 19200 (7.14991 iter/s, 13.9862s/100 iter), loss = 1.32729
I0802 05:29:21.525084 18636 solver.cpp:375]     Train net output #0: loss = 1.72308 (* 1 = 1.72308 loss)
I0802 05:29:21.525092 18636 sgd_solver.cpp:136] Iteration 19200, lr = 0.0088, m = 0.9
I0802 05:29:35.511768 18636 solver.cpp:353] Iteration 19300 (7.14981 iter/s, 13.9864s/100 iter), loss = 1.73863
I0802 05:29:35.511823 18636 solver.cpp:375]     Train net output #0: loss = 1.84331 (* 1 = 1.84331 loss)
I0802 05:29:35.511840 18636 sgd_solver.cpp:136] Iteration 19300, lr = 0.00879375, m = 0.9
I0802 05:29:49.495375 18636 solver.cpp:353] Iteration 19400 (7.15142 iter/s, 13.9832s/100 iter), loss = 1.44273
I0802 05:29:49.495401 18636 solver.cpp:375]     Train net output #0: loss = 1.18283 (* 1 = 1.18283 loss)
I0802 05:29:49.495406 18636 sgd_solver.cpp:136] Iteration 19400, lr = 0.0087875, m = 0.9
I0802 05:30:03.363842 18636 solver.cpp:353] Iteration 19500 (7.2108 iter/s, 13.8681s/100 iter), loss = 1.55155
I0802 05:30:03.363915 18636 solver.cpp:375]     Train net output #0: loss = 1.52163 (* 1 = 1.52163 loss)
I0802 05:30:03.363926 18636 sgd_solver.cpp:136] Iteration 19500, lr = 0.00878125, m = 0.9
I0802 05:30:17.429108 18636 solver.cpp:353] Iteration 19600 (7.1099 iter/s, 14.0649s/100 iter), loss = 1.16038
I0802 05:30:17.429162 18636 solver.cpp:375]     Train net output #0: loss = 1.10747 (* 1 = 1.10747 loss)
I0802 05:30:17.429173 18636 sgd_solver.cpp:136] Iteration 19600, lr = 0.008775, m = 0.9
I0802 05:30:31.384658 18636 solver.cpp:353] Iteration 19700 (7.1658 iter/s, 13.9552s/100 iter), loss = 1.33003
I0802 05:30:31.384692 18636 solver.cpp:375]     Train net output #0: loss = 1.29553 (* 1 = 1.29553 loss)
I0802 05:30:31.384697 18636 sgd_solver.cpp:136] Iteration 19700, lr = 0.00876875, m = 0.9
I0802 05:30:45.389739 18636 solver.cpp:353] Iteration 19800 (7.14046 iter/s, 14.0047s/100 iter), loss = 1.98333
I0802 05:30:45.389840 18636 solver.cpp:375]     Train net output #0: loss = 1.57004 (* 1 = 1.57004 loss)
I0802 05:30:45.389847 18636 sgd_solver.cpp:136] Iteration 19800, lr = 0.0087625, m = 0.9
I0802 05:30:59.528532 18636 solver.cpp:353] Iteration 19900 (7.07293 iter/s, 14.1384s/100 iter), loss = 1.59281
I0802 05:30:59.528555 18636 solver.cpp:375]     Train net output #0: loss = 1.43256 (* 1 = 1.43256 loss)
I0802 05:30:59.528559 18636 sgd_solver.cpp:136] Iteration 19900, lr = 0.00875625, m = 0.9
I0802 05:31:14.520417 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_20000.caffemodel
I0802 05:31:14.531327 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_20000.solverstate
I0802 05:31:14.535600 18636 solver.cpp:404] Sparsity after update:
I0802 05:31:14.536706 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:31:14.536715 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:31:14.536721 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:31:14.536723 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:31:14.536726 18636 net.cpp:2270] res2a_branch2a_param_0(0) 
I0802 05:31:14.536728 18636 net.cpp:2270] res2a_branch2b_param_0(0) 
I0802 05:31:14.536731 18636 net.cpp:2270] res3a_branch2a_param_0(0) 
I0802 05:31:14.536732 18636 net.cpp:2270] res3a_branch2b_param_0(0) 
I0802 05:31:14.536734 18636 net.cpp:2270] res4a_branch2a_param_0(0) 
I0802 05:31:14.536736 18636 net.cpp:2270] res4a_branch2b_param_0(0) 
I0802 05:31:14.536739 18636 net.cpp:2270] res5a_branch2a_param_0(0) 
I0802 05:31:14.536741 18636 net.cpp:2270] res5a_branch2b_param_0(0) 
I0802 05:31:14.536743 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (0/2.86678e+06) 0
I0802 05:31:14.536752 18636 solver.cpp:550] Iteration 20000, Testing net (#0)
I0802 05:31:32.045634 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:31:34.086845 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.558176
I0802 05:31:34.086870 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.791939
I0802 05:31:34.086876 18636 solver.cpp:635]     Test net output #2: loss = 1.94261 (* 1 = 1.94261 loss)
I0802 05:31:34.086894 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5496s
I0802 05:31:34.233956 18661 solver.cpp:450] Finding and applying sparsity: 0.01
I0802 05:31:53.233930 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:31:53.235826 18636 solver.cpp:353] Iteration 20000 (1.86199 iter/s, 53.7059s/100 iter), loss = 1.77072
I0802 05:31:53.235843 18636 solver.cpp:375]     Train net output #0: loss = 1.64473 (* 1 = 1.64473 loss)
I0802 05:31:53.235849 18636 sgd_solver.cpp:136] Iteration 20000, lr = 0.00875, m = 0.9
I0802 05:32:07.502239 18636 solver.cpp:353] Iteration 20100 (7.00966 iter/s, 14.266s/100 iter), loss = 1.30029
I0802 05:32:07.502324 18636 solver.cpp:375]     Train net output #0: loss = 1.37026 (* 1 = 1.37026 loss)
I0802 05:32:07.502337 18636 sgd_solver.cpp:136] Iteration 20100, lr = 0.00874375, m = 0.9
I0802 05:32:21.441437 18636 solver.cpp:353] Iteration 20200 (7.17421 iter/s, 13.9388s/100 iter), loss = 1.44786
I0802 05:32:21.441465 18636 solver.cpp:375]     Train net output #0: loss = 1.27863 (* 1 = 1.27863 loss)
I0802 05:32:21.441473 18636 sgd_solver.cpp:136] Iteration 20200, lr = 0.0087375, m = 0.9
I0802 05:32:35.303284 18636 solver.cpp:353] Iteration 20300 (7.21424 iter/s, 13.8615s/100 iter), loss = 1.73769
I0802 05:32:35.303310 18636 solver.cpp:375]     Train net output #0: loss = 2.13868 (* 1 = 2.13868 loss)
I0802 05:32:35.303314 18636 sgd_solver.cpp:136] Iteration 20300, lr = 0.00873125, m = 0.9
I0802 05:32:49.187461 18636 solver.cpp:353] Iteration 20400 (7.20264 iter/s, 13.8838s/100 iter), loss = 1.44267
I0802 05:32:49.187517 18636 solver.cpp:375]     Train net output #0: loss = 1.30583 (* 1 = 1.30583 loss)
I0802 05:32:49.187522 18636 sgd_solver.cpp:136] Iteration 20400, lr = 0.008725, m = 0.9
I0802 05:33:03.052575 18636 solver.cpp:353] Iteration 20500 (7.21254 iter/s, 13.8647s/100 iter), loss = 1.57031
I0802 05:33:03.052600 18636 solver.cpp:375]     Train net output #0: loss = 1.36288 (* 1 = 1.36288 loss)
I0802 05:33:03.052606 18636 sgd_solver.cpp:136] Iteration 20500, lr = 0.00871875, m = 0.9
I0802 05:33:16.929404 18636 solver.cpp:353] Iteration 20600 (7.20645 iter/s, 13.8765s/100 iter), loss = 1.42995
I0802 05:33:16.929430 18636 solver.cpp:375]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0802 05:33:16.929433 18636 sgd_solver.cpp:136] Iteration 20600, lr = 0.0087125, m = 0.9
I0802 05:33:30.788378 18636 solver.cpp:353] Iteration 20700 (7.21574 iter/s, 13.8586s/100 iter), loss = 1.68946
I0802 05:33:30.788456 18636 solver.cpp:375]     Train net output #0: loss = 1.33902 (* 1 = 1.33902 loss)
I0802 05:33:30.788463 18636 sgd_solver.cpp:136] Iteration 20700, lr = 0.00870625, m = 0.9
I0802 05:33:44.710747 18636 solver.cpp:353] Iteration 20800 (7.18288 iter/s, 13.922s/100 iter), loss = 1.30892
I0802 05:33:44.710777 18636 solver.cpp:375]     Train net output #0: loss = 1.53976 (* 1 = 1.53976 loss)
I0802 05:33:44.710783 18636 sgd_solver.cpp:136] Iteration 20800, lr = 0.0087, m = 0.9
I0802 05:33:58.547086 18636 solver.cpp:353] Iteration 20900 (7.22754 iter/s, 13.836s/100 iter), loss = 1.43676
I0802 05:33:58.547113 18636 solver.cpp:375]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I0802 05:33:58.547119 18636 sgd_solver.cpp:136] Iteration 20900, lr = 0.00869375, m = 0.9
I0802 05:34:12.294008 18636 solver.cpp:404] Sparsity after update:
I0802 05:34:12.304450 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:34:12.304484 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:34:12.304498 18636 net.cpp:2270] conv1b_param_0(0) 
I0802 05:34:12.304507 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:34:12.304514 18636 net.cpp:2270] res2a_branch2a_param_0(0.00694) 
I0802 05:34:12.304523 18636 net.cpp:2270] res2a_branch2b_param_0(0.00694) 
I0802 05:34:12.304532 18636 net.cpp:2270] res3a_branch2a_param_0(0.00868) 
I0802 05:34:12.304539 18636 net.cpp:2270] res3a_branch2b_param_0(0.00694) 
I0802 05:34:12.304548 18636 net.cpp:2270] res4a_branch2a_param_0(0.00955) 
I0802 05:34:12.304555 18636 net.cpp:2270] res4a_branch2b_param_0(0.00868) 
I0802 05:34:12.304563 18636 net.cpp:2270] res5a_branch2a_param_0(0.00998) 
I0802 05:34:12.304571 18636 net.cpp:2270] res5a_branch2b_param_0(0.00952) 
I0802 05:34:12.304579 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (22565/2.86678e+06) 0.00787
I0802 05:34:12.435575 18661 solver.cpp:450] Finding and applying sparsity: 0.02
I0802 05:34:31.476828 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:34:31.478734 18636 solver.cpp:353] Iteration 21000 (3.03667 iter/s, 32.9308s/100 iter), loss = 1.84803
I0802 05:34:31.478751 18636 solver.cpp:375]     Train net output #0: loss = 1.66258 (* 1 = 1.66258 loss)
I0802 05:34:31.478757 18636 sgd_solver.cpp:136] Iteration 21000, lr = 0.0086875, m = 0.9
I0802 05:34:45.866204 18636 solver.cpp:353] Iteration 21100 (6.95068 iter/s, 14.3871s/100 iter), loss = 1.78053
I0802 05:34:45.866266 18636 solver.cpp:375]     Train net output #0: loss = 1.20908 (* 1 = 1.20908 loss)
I0802 05:34:45.866272 18636 sgd_solver.cpp:136] Iteration 21100, lr = 0.00868125, m = 0.9
I0802 05:34:59.812415 18636 solver.cpp:353] Iteration 21200 (7.1706 iter/s, 13.9458s/100 iter), loss = 1.6
I0802 05:34:59.812443 18636 solver.cpp:375]     Train net output #0: loss = 1.84059 (* 1 = 1.84059 loss)
I0802 05:34:59.812448 18636 sgd_solver.cpp:136] Iteration 21200, lr = 0.008675, m = 0.9
I0802 05:35:13.676756 18636 solver.cpp:353] Iteration 21300 (7.21294 iter/s, 13.864s/100 iter), loss = 1.4402
I0802 05:35:13.676779 18636 solver.cpp:375]     Train net output #0: loss = 1.82637 (* 1 = 1.82637 loss)
I0802 05:35:13.676784 18636 sgd_solver.cpp:136] Iteration 21300, lr = 0.00866875, m = 0.9
I0802 05:35:27.512042 18636 solver.cpp:353] Iteration 21400 (7.22809 iter/s, 13.8349s/100 iter), loss = 1.5097
I0802 05:35:27.512140 18636 solver.cpp:375]     Train net output #0: loss = 1.25008 (* 1 = 1.25008 loss)
I0802 05:35:27.512146 18636 sgd_solver.cpp:136] Iteration 21400, lr = 0.0086625, m = 0.9
I0802 05:35:41.406788 18636 solver.cpp:353] Iteration 21500 (7.19716 iter/s, 13.8944s/100 iter), loss = 1.49853
I0802 05:35:41.406816 18636 solver.cpp:375]     Train net output #0: loss = 1.51946 (* 1 = 1.51946 loss)
I0802 05:35:41.406821 18636 sgd_solver.cpp:136] Iteration 21500, lr = 0.00865625, m = 0.9
I0802 05:35:55.255885 18636 solver.cpp:353] Iteration 21600 (7.22088 iter/s, 13.8487s/100 iter), loss = 1.65517
I0802 05:35:55.255981 18636 solver.cpp:375]     Train net output #0: loss = 1.47423 (* 1 = 1.47423 loss)
I0802 05:35:55.256003 18636 sgd_solver.cpp:136] Iteration 21600, lr = 0.00865, m = 0.9
I0802 05:36:09.270805 18636 solver.cpp:353] Iteration 21700 (7.13545 iter/s, 14.0145s/100 iter), loss = 1.58966
I0802 05:36:09.270908 18636 solver.cpp:375]     Train net output #0: loss = 1.60244 (* 1 = 1.60244 loss)
I0802 05:36:09.270915 18636 sgd_solver.cpp:136] Iteration 21700, lr = 0.00864375, m = 0.9
I0802 05:36:23.249799 18636 solver.cpp:353] Iteration 21800 (7.15378 iter/s, 13.9786s/100 iter), loss = 1.28478
I0802 05:36:23.249830 18636 solver.cpp:375]     Train net output #0: loss = 1.33883 (* 1 = 1.33883 loss)
I0802 05:36:23.249835 18636 sgd_solver.cpp:136] Iteration 21800, lr = 0.0086375, m = 0.9
I0802 05:36:37.201951 18636 solver.cpp:353] Iteration 21900 (7.16755 iter/s, 13.9518s/100 iter), loss = 1.37625
I0802 05:36:37.202050 18636 solver.cpp:375]     Train net output #0: loss = 1.80413 (* 1 = 1.80413 loss)
I0802 05:36:37.202071 18636 sgd_solver.cpp:136] Iteration 21900, lr = 0.00863125, m = 0.9
I0802 05:36:51.029222 18636 solver.cpp:404] Sparsity after update:
I0802 05:36:51.033460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:36:51.033471 18636 net.cpp:2270] conv1a_param_0(0) 
I0802 05:36:51.033480 18636 net.cpp:2270] conv1b_param_0(0.00694) 
I0802 05:36:51.033484 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:36:51.033488 18636 net.cpp:2270] res2a_branch2a_param_0(0.0174) 
I0802 05:36:51.033490 18636 net.cpp:2270] res2a_branch2b_param_0(0.0139) 
I0802 05:36:51.033493 18636 net.cpp:2270] res3a_branch2a_param_0(0.0191) 
I0802 05:36:51.033498 18636 net.cpp:2270] res3a_branch2b_param_0(0.0173) 
I0802 05:36:51.033500 18636 net.cpp:2270] res4a_branch2a_param_0(0.02) 
I0802 05:36:51.033504 18636 net.cpp:2270] res4a_branch2b_param_0(0.0191) 
I0802 05:36:51.033506 18636 net.cpp:2270] res5a_branch2a_param_0(0.02) 
I0802 05:36:51.033510 18636 net.cpp:2270] res5a_branch2b_param_0(0.0199) 
I0802 05:36:51.033514 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (46508/2.86678e+06) 0.0162
I0802 05:36:51.033526 18636 solver.cpp:550] Iteration 22000, Testing net (#0)
I0802 05:37:10.451876 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.545529
I0802 05:37:10.451902 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787174
I0802 05:37:10.451907 18636 solver.cpp:635]     Test net output #2: loss = 2.02181 (* 1 = 2.02181 loss)
I0802 05:37:10.451958 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4179s
I0802 05:37:10.599603 18661 solver.cpp:450] Finding and applying sparsity: 0.03
I0802 05:37:30.326567 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:37:30.328475 18636 solver.cpp:353] Iteration 22000 (1.88235 iter/s, 53.1251s/100 iter), loss = 1.8609
I0802 05:37:30.328493 18636 solver.cpp:375]     Train net output #0: loss = 1.55529 (* 1 = 1.55529 loss)
I0802 05:37:30.328500 18636 sgd_solver.cpp:136] Iteration 22000, lr = 0.008625, m = 0.9
I0802 05:37:44.710464 18636 solver.cpp:353] Iteration 22100 (6.95334 iter/s, 14.3816s/100 iter), loss = 1.64592
I0802 05:37:44.710536 18636 solver.cpp:375]     Train net output #0: loss = 1.55267 (* 1 = 1.55267 loss)
I0802 05:37:44.710548 18636 sgd_solver.cpp:136] Iteration 22100, lr = 0.00861875, m = 0.9
I0802 05:37:58.712465 18636 solver.cpp:353] Iteration 22200 (7.14203 iter/s, 14.0016s/100 iter), loss = 1.32659
I0802 05:37:58.712491 18636 solver.cpp:375]     Train net output #0: loss = 1.12278 (* 1 = 1.12278 loss)
I0802 05:37:58.712494 18636 sgd_solver.cpp:136] Iteration 22200, lr = 0.0086125, m = 0.9
I0802 05:38:12.669386 18636 solver.cpp:353] Iteration 22300 (7.1651 iter/s, 13.9565s/100 iter), loss = 1.36619
I0802 05:38:12.669463 18636 solver.cpp:375]     Train net output #0: loss = 1.31978 (* 1 = 1.31978 loss)
I0802 05:38:12.669468 18636 sgd_solver.cpp:136] Iteration 22300, lr = 0.00860625, m = 0.9
I0802 05:38:26.628396 18636 solver.cpp:353] Iteration 22400 (7.16403 iter/s, 13.9586s/100 iter), loss = 1.73878
I0802 05:38:26.628485 18636 solver.cpp:375]     Train net output #0: loss = 1.75981 (* 1 = 1.75981 loss)
I0802 05:38:26.628504 18636 sgd_solver.cpp:136] Iteration 22400, lr = 0.0086, m = 0.9
I0802 05:38:40.513186 18636 solver.cpp:353] Iteration 22500 (7.20232 iter/s, 13.8844s/100 iter), loss = 1.45458
I0802 05:38:40.513216 18636 solver.cpp:375]     Train net output #0: loss = 1.5517 (* 1 = 1.5517 loss)
I0802 05:38:40.513221 18636 sgd_solver.cpp:136] Iteration 22500, lr = 0.00859375, m = 0.9
I0802 05:38:54.448285 18636 solver.cpp:353] Iteration 22600 (7.17632 iter/s, 13.9347s/100 iter), loss = 1.46736
I0802 05:38:54.448354 18636 solver.cpp:375]     Train net output #0: loss = 0.847797 (* 1 = 0.847797 loss)
I0802 05:38:54.448360 18636 sgd_solver.cpp:136] Iteration 22600, lr = 0.0085875, m = 0.9
I0802 05:39:08.452394 18636 solver.cpp:353] Iteration 22700 (7.14095 iter/s, 14.0037s/100 iter), loss = 1.36274
I0802 05:39:08.452422 18636 solver.cpp:375]     Train net output #0: loss = 1.57267 (* 1 = 1.57267 loss)
I0802 05:39:08.452427 18636 sgd_solver.cpp:136] Iteration 22700, lr = 0.00858125, m = 0.9
I0802 05:39:22.309039 18636 solver.cpp:353] Iteration 22800 (7.21695 iter/s, 13.8563s/100 iter), loss = 1.47466
I0802 05:39:22.309070 18636 solver.cpp:375]     Train net output #0: loss = 1.54463 (* 1 = 1.54463 loss)
I0802 05:39:22.309077 18636 sgd_solver.cpp:136] Iteration 22800, lr = 0.008575, m = 0.9
I0802 05:39:36.221313 18636 solver.cpp:353] Iteration 22900 (7.18809 iter/s, 13.9119s/100 iter), loss = 1.52271
I0802 05:39:36.221393 18636 solver.cpp:375]     Train net output #0: loss = 1.36345 (* 1 = 1.36345 loss)
I0802 05:39:36.221400 18636 sgd_solver.cpp:136] Iteration 22900, lr = 0.00856875, m = 0.9
I0802 05:39:50.008510 18636 solver.cpp:404] Sparsity after update:
I0802 05:39:50.019078 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:39:50.019093 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:39:50.019103 18636 net.cpp:2270] conv1b_param_0(0.0139) 
I0802 05:39:50.019105 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:39:50.019109 18636 net.cpp:2270] res2a_branch2a_param_0(0.0277) 
I0802 05:39:50.019121 18636 net.cpp:2270] res2a_branch2b_param_0(0.0277) 
I0802 05:39:50.019130 18636 net.cpp:2270] res3a_branch2a_param_0(0.0295) 
I0802 05:39:50.019140 18636 net.cpp:2270] res3a_branch2b_param_0(0.0278) 
I0802 05:39:50.019155 18636 net.cpp:2270] res4a_branch2a_param_0(0.0295) 
I0802 05:39:50.019161 18636 net.cpp:2270] res4a_branch2b_param_0(0.0295) 
I0802 05:39:50.019165 18636 net.cpp:2270] res5a_branch2a_param_0(0.0299) 
I0802 05:39:50.019173 18636 net.cpp:2270] res5a_branch2b_param_0(0.0295) 
I0802 05:39:50.019178 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (69779/2.86678e+06) 0.0243
I0802 05:39:50.151249 18661 solver.cpp:450] Finding and applying sparsity: 0.04
I0802 05:40:09.475435 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:40:09.477368 18636 solver.cpp:353] Iteration 23000 (3.00705 iter/s, 33.2552s/100 iter), loss = 1.46279
I0802 05:40:09.477387 18636 solver.cpp:375]     Train net output #0: loss = 1.52898 (* 1 = 1.52898 loss)
I0802 05:40:09.477393 18636 sgd_solver.cpp:136] Iteration 23000, lr = 0.0085625, m = 0.9
I0802 05:40:23.920900 18636 solver.cpp:353] Iteration 23100 (6.92371 iter/s, 14.4431s/100 iter), loss = 1.76185
I0802 05:40:23.920974 18636 solver.cpp:375]     Train net output #0: loss = 1.82227 (* 1 = 1.82227 loss)
I0802 05:40:23.920990 18636 sgd_solver.cpp:136] Iteration 23100, lr = 0.00855625, m = 0.9
I0802 05:40:37.840987 18636 solver.cpp:353] Iteration 23200 (7.18406 iter/s, 13.9197s/100 iter), loss = 1.43151
I0802 05:40:37.841017 18636 solver.cpp:375]     Train net output #0: loss = 1.30827 (* 1 = 1.30827 loss)
I0802 05:40:37.841022 18636 sgd_solver.cpp:136] Iteration 23200, lr = 0.00855, m = 0.9
I0802 05:40:51.792546 18636 solver.cpp:353] Iteration 23300 (7.16785 iter/s, 13.9512s/100 iter), loss = 1.35608
I0802 05:40:51.792683 18636 solver.cpp:375]     Train net output #0: loss = 1.22174 (* 1 = 1.22174 loss)
I0802 05:40:51.792702 18636 sgd_solver.cpp:136] Iteration 23300, lr = 0.00854375, m = 0.9
I0802 05:41:05.734192 18636 solver.cpp:353] Iteration 23400 (7.17295 iter/s, 13.9413s/100 iter), loss = 1.49833
I0802 05:41:05.734221 18636 solver.cpp:375]     Train net output #0: loss = 1.50744 (* 1 = 1.50744 loss)
I0802 05:41:05.734266 18636 sgd_solver.cpp:136] Iteration 23400, lr = 0.0085375, m = 0.9
I0802 05:41:19.747889 18636 solver.cpp:353] Iteration 23500 (7.13607 iter/s, 14.0133s/100 iter), loss = 1.46401
I0802 05:41:19.747920 18636 solver.cpp:375]     Train net output #0: loss = 1.19949 (* 1 = 1.19949 loss)
I0802 05:41:19.747926 18636 sgd_solver.cpp:136] Iteration 23500, lr = 0.00853125, m = 0.9
I0802 05:41:33.629787 18636 solver.cpp:353] Iteration 23600 (7.20382 iter/s, 13.8815s/100 iter), loss = 1.50098
I0802 05:41:33.629858 18636 solver.cpp:375]     Train net output #0: loss = 1.70676 (* 1 = 1.70676 loss)
I0802 05:41:33.629868 18636 sgd_solver.cpp:136] Iteration 23600, lr = 0.008525, m = 0.9
I0802 05:41:47.520200 18636 solver.cpp:353] Iteration 23700 (7.1994 iter/s, 13.89s/100 iter), loss = 1.47679
I0802 05:41:47.520231 18636 solver.cpp:375]     Train net output #0: loss = 1.25338 (* 1 = 1.25338 loss)
I0802 05:41:47.520237 18636 sgd_solver.cpp:136] Iteration 23700, lr = 0.00851875, m = 0.9
I0802 05:42:01.480682 18636 solver.cpp:353] Iteration 23800 (7.16327 iter/s, 13.9601s/100 iter), loss = 1.55269
I0802 05:42:01.480711 18636 solver.cpp:375]     Train net output #0: loss = 1.70255 (* 1 = 1.70255 loss)
I0802 05:42:01.480717 18636 sgd_solver.cpp:136] Iteration 23800, lr = 0.0085125, m = 0.9
I0802 05:42:15.425860 18636 solver.cpp:353] Iteration 23900 (7.17113 iter/s, 13.9448s/100 iter), loss = 1.51883
I0802 05:42:15.425933 18636 solver.cpp:375]     Train net output #0: loss = 1.3618 (* 1 = 1.3618 loss)
I0802 05:42:15.425938 18636 sgd_solver.cpp:136] Iteration 23900, lr = 0.00850625, m = 0.9
I0802 05:42:29.300487 18636 solver.cpp:404] Sparsity after update:
I0802 05:42:29.304849 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:42:29.304862 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:42:29.304870 18636 net.cpp:2270] conv1b_param_0(0.0139) 
I0802 05:42:29.304874 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:42:29.304878 18636 net.cpp:2270] res2a_branch2a_param_0(0.0381) 
I0802 05:42:29.304883 18636 net.cpp:2270] res2a_branch2b_param_0(0.0347) 
I0802 05:42:29.304886 18636 net.cpp:2270] res3a_branch2a_param_0(0.0399) 
I0802 05:42:29.304890 18636 net.cpp:2270] res3a_branch2b_param_0(0.0382) 
I0802 05:42:29.304893 18636 net.cpp:2270] res4a_branch2a_param_0(0.0399) 
I0802 05:42:29.304896 18636 net.cpp:2270] res4a_branch2b_param_0(0.0399) 
I0802 05:42:29.304900 18636 net.cpp:2270] res5a_branch2a_param_0(0.0399) 
I0802 05:42:29.304903 18636 net.cpp:2270] res5a_branch2b_param_0(0.0399) 
I0802 05:42:29.304906 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (93725/2.86678e+06) 0.0327
I0802 05:42:29.304918 18636 solver.cpp:550] Iteration 24000, Testing net (#0)
I0802 05:42:48.555557 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.547529
I0802 05:42:48.555637 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787351
I0802 05:42:48.555647 18636 solver.cpp:635]     Test net output #2: loss = 2.00144 (* 1 = 2.00144 loss)
I0802 05:42:48.555667 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2502s
I0802 05:42:48.705113 18661 solver.cpp:450] Finding and applying sparsity: 0.05
I0802 05:43:07.848326 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:43:07.850229 18636 solver.cpp:353] Iteration 24000 (1.90756 iter/s, 52.423s/100 iter), loss = 1.35446
I0802 05:43:07.850253 18636 solver.cpp:375]     Train net output #0: loss = 1.30837 (* 1 = 1.30837 loss)
I0802 05:43:07.850262 18636 sgd_solver.cpp:136] Iteration 24000, lr = 0.0085, m = 0.9
I0802 05:43:22.167886 18636 solver.cpp:353] Iteration 24100 (6.98458 iter/s, 14.3173s/100 iter), loss = 1.49808
I0802 05:43:22.167974 18636 solver.cpp:375]     Train net output #0: loss = 1.36545 (* 1 = 1.36545 loss)
I0802 05:43:22.167981 18636 sgd_solver.cpp:136] Iteration 24100, lr = 0.00849375, m = 0.9
I0802 05:43:35.974591 18636 solver.cpp:353] Iteration 24200 (7.24306 iter/s, 13.8063s/100 iter), loss = 1.58167
I0802 05:43:35.974619 18636 solver.cpp:375]     Train net output #0: loss = 1.22837 (* 1 = 1.22837 loss)
I0802 05:43:35.974625 18636 sgd_solver.cpp:136] Iteration 24200, lr = 0.0084875, m = 0.9
I0802 05:43:49.875634 18636 solver.cpp:353] Iteration 24300 (7.1939 iter/s, 13.9007s/100 iter), loss = 1.07276
I0802 05:43:49.875710 18636 solver.cpp:375]     Train net output #0: loss = 1.21721 (* 1 = 1.21721 loss)
I0802 05:43:49.875722 18636 sgd_solver.cpp:136] Iteration 24300, lr = 0.00848125, m = 0.9
I0802 05:44:03.785732 18636 solver.cpp:353] Iteration 24400 (7.18922 iter/s, 13.9097s/100 iter), loss = 1.42349
I0802 05:44:03.785833 18636 solver.cpp:375]     Train net output #0: loss = 1.37992 (* 1 = 1.37992 loss)
I0802 05:44:03.785853 18636 sgd_solver.cpp:136] Iteration 24400, lr = 0.008475, m = 0.9
I0802 05:44:17.683492 18636 solver.cpp:353] Iteration 24500 (7.1956 iter/s, 13.8974s/100 iter), loss = 1.49714
I0802 05:44:17.683519 18636 solver.cpp:375]     Train net output #0: loss = 1.87334 (* 1 = 1.87334 loss)
I0802 05:44:17.683524 18636 sgd_solver.cpp:136] Iteration 24500, lr = 0.00846875, m = 0.9
I0802 05:44:31.504407 18636 solver.cpp:353] Iteration 24600 (7.23561 iter/s, 13.8205s/100 iter), loss = 1.58734
I0802 05:44:31.504436 18636 solver.cpp:375]     Train net output #0: loss = 1.29047 (* 1 = 1.29047 loss)
I0802 05:44:31.504443 18636 sgd_solver.cpp:136] Iteration 24600, lr = 0.0084625, m = 0.9
I0802 05:44:45.370369 18636 solver.cpp:353] Iteration 24700 (7.2121 iter/s, 13.8656s/100 iter), loss = 1.28708
I0802 05:44:45.370437 18636 solver.cpp:375]     Train net output #0: loss = 1.678 (* 1 = 1.678 loss)
I0802 05:44:45.370445 18636 sgd_solver.cpp:136] Iteration 24700, lr = 0.00845625, m = 0.9
I0802 05:44:59.292448 18636 solver.cpp:353] Iteration 24800 (7.18303 iter/s, 13.9217s/100 iter), loss = 1.20666
I0802 05:44:59.292516 18636 solver.cpp:375]     Train net output #0: loss = 1.29825 (* 1 = 1.29825 loss)
I0802 05:44:59.292536 18636 sgd_solver.cpp:136] Iteration 24800, lr = 0.00845, m = 0.9
I0802 05:45:13.152274 18636 solver.cpp:353] Iteration 24900 (7.21529 iter/s, 13.8595s/100 iter), loss = 1.3001
I0802 05:45:13.152299 18636 solver.cpp:375]     Train net output #0: loss = 1.30287 (* 1 = 1.30287 loss)
I0802 05:45:13.152304 18636 sgd_solver.cpp:136] Iteration 24900, lr = 0.00844375, m = 0.9
I0802 05:45:26.871785 18636 solver.cpp:404] Sparsity after update:
I0802 05:45:26.882943 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:45:26.882956 18636 net.cpp:2270] conv1a_param_0(0.0133) 
I0802 05:45:26.882966 18636 net.cpp:2270] conv1b_param_0(0.0208) 
I0802 05:45:26.882969 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:45:26.882973 18636 net.cpp:2270] res2a_branch2a_param_0(0.0486) 
I0802 05:45:26.882992 18636 net.cpp:2270] res2a_branch2b_param_0(0.0486) 
I0802 05:45:26.883002 18636 net.cpp:2270] res3a_branch2a_param_0(0.0486) 
I0802 05:45:26.883015 18636 net.cpp:2270] res3a_branch2b_param_0(0.0486) 
I0802 05:45:26.883024 18636 net.cpp:2270] res4a_branch2a_param_0(0.0495) 
I0802 05:45:26.883033 18636 net.cpp:2270] res4a_branch2b_param_0(0.0486) 
I0802 05:45:26.883043 18636 net.cpp:2270] res5a_branch2a_param_0(0.0499) 
I0802 05:45:26.883050 18636 net.cpp:2270] res5a_branch2b_param_0(0.0494) 
I0802 05:45:26.883059 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (116580/2.86678e+06) 0.0407
I0802 05:45:27.014031 18661 solver.cpp:450] Finding and applying sparsity: 0.06
I0802 05:45:46.455001 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:45:46.457041 18636 solver.cpp:353] Iteration 25000 (3.00265 iter/s, 33.3039s/100 iter), loss = 1.73484
I0802 05:45:46.457058 18636 solver.cpp:375]     Train net output #0: loss = 1.46269 (* 1 = 1.46269 loss)
I0802 05:45:46.457064 18636 sgd_solver.cpp:136] Iteration 25000, lr = 0.0084375, m = 0.9
I0802 05:46:00.759029 18636 solver.cpp:353] Iteration 25100 (6.99223 iter/s, 14.3016s/100 iter), loss = 1.72729
I0802 05:46:00.759104 18636 solver.cpp:375]     Train net output #0: loss = 1.93451 (* 1 = 1.93451 loss)
I0802 05:46:00.759109 18636 sgd_solver.cpp:136] Iteration 25100, lr = 0.00843125, m = 0.9
I0802 05:46:14.629340 18636 solver.cpp:353] Iteration 25200 (7.20984 iter/s, 13.8699s/100 iter), loss = 1.3077
I0802 05:46:14.629366 18636 solver.cpp:375]     Train net output #0: loss = 1.26359 (* 1 = 1.26359 loss)
I0802 05:46:14.629370 18636 sgd_solver.cpp:136] Iteration 25200, lr = 0.008425, m = 0.9
I0802 05:46:28.514237 18636 solver.cpp:353] Iteration 25300 (7.20227 iter/s, 13.8845s/100 iter), loss = 1.96846
I0802 05:46:28.514263 18636 solver.cpp:375]     Train net output #0: loss = 1.89946 (* 1 = 1.89946 loss)
I0802 05:46:28.514267 18636 sgd_solver.cpp:136] Iteration 25300, lr = 0.00841875, m = 0.9
I0802 05:46:42.354074 18636 solver.cpp:353] Iteration 25400 (7.22571 iter/s, 13.8395s/100 iter), loss = 1.4288
I0802 05:46:42.361017 18636 solver.cpp:375]     Train net output #0: loss = 1.10299 (* 1 = 1.10299 loss)
I0802 05:46:42.361032 18636 sgd_solver.cpp:136] Iteration 25400, lr = 0.0084125, m = 0.9
I0802 05:46:56.257583 18636 solver.cpp:353] Iteration 25500 (7.19262 iter/s, 13.9031s/100 iter), loss = 1.83777
I0802 05:46:56.257613 18636 solver.cpp:375]     Train net output #0: loss = 1.74782 (* 1 = 1.74782 loss)
I0802 05:46:56.257619 18636 sgd_solver.cpp:136] Iteration 25500, lr = 0.00840625, m = 0.9
I0802 05:47:10.093750 18636 solver.cpp:353] Iteration 25600 (7.22763 iter/s, 13.8358s/100 iter), loss = 1.6852
I0802 05:47:10.093776 18636 solver.cpp:375]     Train net output #0: loss = 1.55889 (* 1 = 1.55889 loss)
I0802 05:47:10.093783 18636 sgd_solver.cpp:136] Iteration 25600, lr = 0.0084, m = 0.9
I0802 05:47:23.930405 18636 solver.cpp:353] Iteration 25700 (7.22738 iter/s, 13.8363s/100 iter), loss = 1.44803
I0802 05:47:23.930495 18636 solver.cpp:375]     Train net output #0: loss = 1.24387 (* 1 = 1.24387 loss)
I0802 05:47:23.930502 18636 sgd_solver.cpp:136] Iteration 25700, lr = 0.00839375, m = 0.9
I0802 05:47:37.890206 18636 solver.cpp:353] Iteration 25800 (7.16362 iter/s, 13.9594s/100 iter), loss = 1.53797
I0802 05:47:37.890233 18636 solver.cpp:375]     Train net output #0: loss = 1.42731 (* 1 = 1.42731 loss)
I0802 05:47:37.890239 18636 sgd_solver.cpp:136] Iteration 25800, lr = 0.0083875, m = 0.9
I0802 05:47:51.944435 18636 solver.cpp:353] Iteration 25900 (7.11549 iter/s, 14.0539s/100 iter), loss = 1.48832
I0802 05:47:51.944465 18636 solver.cpp:375]     Train net output #0: loss = 1.76716 (* 1 = 1.76716 loss)
I0802 05:47:51.944471 18636 sgd_solver.cpp:136] Iteration 25900, lr = 0.00838125, m = 0.9
I0802 05:48:05.725561 18636 solver.cpp:404] Sparsity after update:
I0802 05:48:05.731585 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:48:05.731602 18636 net.cpp:2270] conv1a_param_0(0.0267) 
I0802 05:48:05.731611 18636 net.cpp:2270] conv1b_param_0(0.0278) 
I0802 05:48:05.731616 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:48:05.731618 18636 net.cpp:2270] res2a_branch2a_param_0(0.059) 
I0802 05:48:05.731621 18636 net.cpp:2270] res2a_branch2b_param_0(0.0556) 
I0802 05:48:05.731624 18636 net.cpp:2270] res3a_branch2a_param_0(0.059) 
I0802 05:48:05.731628 18636 net.cpp:2270] res3a_branch2b_param_0(0.059) 
I0802 05:48:05.731631 18636 net.cpp:2270] res4a_branch2a_param_0(0.0599) 
I0802 05:48:05.731634 18636 net.cpp:2270] res4a_branch2b_param_0(0.059) 
I0802 05:48:05.731637 18636 net.cpp:2270] res5a_branch2a_param_0(0.0599) 
I0802 05:48:05.731640 18636 net.cpp:2270] res5a_branch2b_param_0(0.0599) 
I0802 05:48:05.731644 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (140569/2.86678e+06) 0.049
I0802 05:48:05.731655 18636 solver.cpp:550] Iteration 26000, Testing net (#0)
I0802 05:48:25.378115 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.54547
I0802 05:48:25.378137 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.786527
I0802 05:48:25.378142 18636 solver.cpp:635]     Test net output #2: loss = 2.02239 (* 1 = 2.02239 loss)
I0802 05:48:25.378207 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.646s
I0802 05:48:25.527134 18661 solver.cpp:450] Finding and applying sparsity: 0.07
I0802 05:48:45.052001 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:48:45.053951 18636 solver.cpp:353] Iteration 26000 (1.88295 iter/s, 53.1081s/100 iter), loss = 1.15137
I0802 05:48:45.053970 18636 solver.cpp:375]     Train net output #0: loss = 1.26326 (* 1 = 1.26326 loss)
I0802 05:48:45.053977 18636 sgd_solver.cpp:136] Iteration 26000, lr = 0.008375, m = 0.9
I0802 05:48:59.539932 18636 solver.cpp:353] Iteration 26100 (6.90342 iter/s, 14.4856s/100 iter), loss = 1.65253
I0802 05:48:59.539968 18636 solver.cpp:375]     Train net output #0: loss = 1.65329 (* 1 = 1.65329 loss)
I0802 05:48:59.539974 18636 sgd_solver.cpp:136] Iteration 26100, lr = 0.00836875, m = 0.9
I0802 05:49:13.509402 18636 solver.cpp:353] Iteration 26200 (7.15866 iter/s, 13.9691s/100 iter), loss = 1.4452
I0802 05:49:13.509515 18636 solver.cpp:375]     Train net output #0: loss = 1.48456 (* 1 = 1.48456 loss)
I0802 05:49:13.509536 18636 sgd_solver.cpp:136] Iteration 26200, lr = 0.0083625, m = 0.9
I0802 05:49:27.490145 18636 solver.cpp:353] Iteration 26300 (7.15289 iter/s, 13.9804s/100 iter), loss = 1.64355
I0802 05:49:27.490244 18636 solver.cpp:375]     Train net output #0: loss = 2.07935 (* 1 = 2.07935 loss)
I0802 05:49:27.490263 18636 sgd_solver.cpp:136] Iteration 26300, lr = 0.00835625, m = 0.9
I0802 05:49:41.438264 18636 solver.cpp:353] Iteration 26400 (7.16962 iter/s, 13.9477s/100 iter), loss = 1.48892
I0802 05:49:41.438292 18636 solver.cpp:375]     Train net output #0: loss = 1.15364 (* 1 = 1.15364 loss)
I0802 05:49:41.438298 18636 sgd_solver.cpp:136] Iteration 26400, lr = 0.00835, m = 0.9
I0802 05:49:55.308226 18636 solver.cpp:353] Iteration 26500 (7.21002 iter/s, 13.8696s/100 iter), loss = 1.63855
I0802 05:49:55.308253 18636 solver.cpp:375]     Train net output #0: loss = 1.9412 (* 1 = 1.9412 loss)
I0802 05:49:55.308259 18636 sgd_solver.cpp:136] Iteration 26500, lr = 0.00834375, m = 0.9
I0802 05:50:09.280038 18636 solver.cpp:353] Iteration 26600 (7.15746 iter/s, 13.9714s/100 iter), loss = 1.47421
I0802 05:50:09.280107 18636 solver.cpp:375]     Train net output #0: loss = 1.54585 (* 1 = 1.54585 loss)
I0802 05:50:09.280113 18636 sgd_solver.cpp:136] Iteration 26600, lr = 0.0083375, m = 0.9
I0802 05:50:23.243505 18636 solver.cpp:353] Iteration 26700 (7.16174 iter/s, 13.9631s/100 iter), loss = 1.22211
I0802 05:50:23.243532 18636 solver.cpp:375]     Train net output #0: loss = 1.25101 (* 1 = 1.25101 loss)
I0802 05:50:23.243536 18636 sgd_solver.cpp:136] Iteration 26700, lr = 0.00833125, m = 0.9
I0802 05:50:37.131322 18636 solver.cpp:353] Iteration 26800 (7.20075 iter/s, 13.8874s/100 iter), loss = 1.28483
I0802 05:50:37.131376 18636 solver.cpp:375]     Train net output #0: loss = 1.08323 (* 1 = 1.08323 loss)
I0802 05:50:37.131388 18636 sgd_solver.cpp:136] Iteration 26800, lr = 0.008325, m = 0.9
I0802 05:50:51.073673 18636 solver.cpp:353] Iteration 26900 (7.17258 iter/s, 13.942s/100 iter), loss = 1.36901
I0802 05:50:51.073781 18636 solver.cpp:375]     Train net output #0: loss = 1.5163 (* 1 = 1.5163 loss)
I0802 05:50:51.073791 18636 sgd_solver.cpp:136] Iteration 26900, lr = 0.00831875, m = 0.9
I0802 05:51:04.790513 18636 solver.cpp:404] Sparsity after update:
I0802 05:51:04.803939 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:51:04.803953 18636 net.cpp:2270] conv1a_param_0(0.0267) 
I0802 05:51:04.803962 18636 net.cpp:2270] conv1b_param_0(0.0347) 
I0802 05:51:04.803966 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:51:04.803969 18636 net.cpp:2270] res2a_branch2a_param_0(0.0694) 
I0802 05:51:04.803973 18636 net.cpp:2270] res2a_branch2b_param_0(0.0694) 
I0802 05:51:04.803977 18636 net.cpp:2270] res3a_branch2a_param_0(0.0694) 
I0802 05:51:04.803979 18636 net.cpp:2270] res3a_branch2b_param_0(0.0694) 
I0802 05:51:04.803989 18636 net.cpp:2270] res4a_branch2a_param_0(0.0694) 
I0802 05:51:04.803994 18636 net.cpp:2270] res4a_branch2b_param_0(0.0694) 
I0802 05:51:04.803999 18636 net.cpp:2270] res5a_branch2a_param_0(0.0699) 
I0802 05:51:04.804003 18636 net.cpp:2270] res5a_branch2b_param_0(0.0694) 
I0802 05:51:04.804008 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (163814/2.86678e+06) 0.0571
I0802 05:51:04.932961 18661 solver.cpp:450] Finding and applying sparsity: 0.08
I0802 05:51:24.970907 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:51:24.972904 18636 solver.cpp:353] Iteration 27000 (2.95 iter/s, 33.8983s/100 iter), loss = 1.25808
I0802 05:51:24.972925 18636 solver.cpp:375]     Train net output #0: loss = 1.14989 (* 1 = 1.14989 loss)
I0802 05:51:24.972934 18636 sgd_solver.cpp:136] Iteration 27000, lr = 0.0083125, m = 0.9
I0802 05:51:39.426556 18636 solver.cpp:353] Iteration 27100 (6.91886 iter/s, 14.4533s/100 iter), loss = 1.52276
I0802 05:51:39.426584 18636 solver.cpp:375]     Train net output #0: loss = 1.66015 (* 1 = 1.66015 loss)
I0802 05:51:39.426591 18636 sgd_solver.cpp:136] Iteration 27100, lr = 0.00830625, m = 0.9
I0802 05:51:53.388947 18636 solver.cpp:353] Iteration 27200 (7.1623 iter/s, 13.962s/100 iter), loss = 1.53717
I0802 05:51:53.389037 18636 solver.cpp:375]     Train net output #0: loss = 1.47797 (* 1 = 1.47797 loss)
I0802 05:51:53.389063 18636 sgd_solver.cpp:136] Iteration 27200, lr = 0.0083, m = 0.9
I0802 05:52:07.359203 18636 solver.cpp:353] Iteration 27300 (7.15826 iter/s, 13.9699s/100 iter), loss = 1.61222
I0802 05:52:07.359269 18636 solver.cpp:375]     Train net output #0: loss = 1.58989 (* 1 = 1.58989 loss)
I0802 05:52:07.359274 18636 sgd_solver.cpp:136] Iteration 27300, lr = 0.00829375, m = 0.9
I0802 05:52:21.335191 18636 solver.cpp:353] Iteration 27400 (7.15532 iter/s, 13.9756s/100 iter), loss = 1.07942
I0802 05:52:21.335222 18636 solver.cpp:375]     Train net output #0: loss = 0.921983 (* 1 = 0.921983 loss)
I0802 05:52:21.335228 18636 sgd_solver.cpp:136] Iteration 27400, lr = 0.0082875, m = 0.9
I0802 05:52:35.370445 18636 solver.cpp:353] Iteration 27500 (7.12511 iter/s, 14.0349s/100 iter), loss = 1.27896
I0802 05:52:35.370473 18636 solver.cpp:375]     Train net output #0: loss = 1.30543 (* 1 = 1.30543 loss)
I0802 05:52:35.370479 18636 sgd_solver.cpp:136] Iteration 27500, lr = 0.00828125, m = 0.9
I0802 05:52:49.342378 18636 solver.cpp:353] Iteration 27600 (7.1574 iter/s, 13.9716s/100 iter), loss = 1.52811
I0802 05:52:49.342440 18636 solver.cpp:375]     Train net output #0: loss = 1.59892 (* 1 = 1.59892 loss)
I0802 05:52:49.342447 18636 sgd_solver.cpp:136] Iteration 27600, lr = 0.008275, m = 0.9
I0802 05:53:03.323745 18636 solver.cpp:353] Iteration 27700 (7.15257 iter/s, 13.981s/100 iter), loss = 1.44105
I0802 05:53:03.323770 18636 solver.cpp:375]     Train net output #0: loss = 1.39796 (* 1 = 1.39796 loss)
I0802 05:53:03.323774 18636 sgd_solver.cpp:136] Iteration 27700, lr = 0.00826875, m = 0.9
I0802 05:53:17.241407 18636 solver.cpp:353] Iteration 27800 (7.18531 iter/s, 13.9173s/100 iter), loss = 1.30981
I0802 05:53:17.241436 18636 solver.cpp:375]     Train net output #0: loss = 1.33884 (* 1 = 1.33884 loss)
I0802 05:53:17.241441 18636 sgd_solver.cpp:136] Iteration 27800, lr = 0.0082625, m = 0.9
I0802 05:53:31.153429 18636 solver.cpp:353] Iteration 27900 (7.18822 iter/s, 13.9116s/100 iter), loss = 1.06217
I0802 05:53:31.153514 18636 solver.cpp:375]     Train net output #0: loss = 1.06779 (* 1 = 1.06779 loss)
I0802 05:53:31.153522 18636 sgd_solver.cpp:136] Iteration 27900, lr = 0.00825625, m = 0.9
I0802 05:53:44.930532 18636 solver.cpp:404] Sparsity after update:
I0802 05:53:44.934460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:53:44.934471 18636 net.cpp:2270] conv1a_param_0(0.0262) 
I0802 05:53:44.934479 18636 net.cpp:2270] conv1b_param_0(0.0347) 
I0802 05:53:44.934484 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:53:44.934496 18636 net.cpp:2270] res2a_branch2a_param_0(0.0799) 
I0802 05:53:44.934505 18636 net.cpp:2270] res2a_branch2b_param_0(0.0764) 
I0802 05:53:44.934514 18636 net.cpp:2270] res3a_branch2a_param_0(0.0798) 
I0802 05:53:44.934522 18636 net.cpp:2270] res3a_branch2b_param_0(0.0799) 
I0802 05:53:44.934530 18636 net.cpp:2270] res4a_branch2a_param_0(0.0799) 
I0802 05:53:44.934538 18636 net.cpp:2270] res4a_branch2b_param_0(0.0799) 
I0802 05:53:44.934546 18636 net.cpp:2270] res5a_branch2a_param_0(0.0799) 
I0802 05:53:44.934556 18636 net.cpp:2270] res5a_branch2b_param_0(0.0798) 
I0802 05:53:44.934566 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (187754/2.86678e+06) 0.0655
I0802 05:53:44.934584 18636 solver.cpp:550] Iteration 28000, Testing net (#0)
I0802 05:53:48.686712 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 05:54:04.789305 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.554353
I0802 05:54:04.789420 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.790821
I0802 05:54:04.789429 18636 solver.cpp:635]     Test net output #2: loss = 1.98504 (* 1 = 1.98504 loss)
I0802 05:54:04.789448 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8543s
I0802 05:54:04.945808 18661 solver.cpp:450] Finding and applying sparsity: 0.09
I0802 05:54:24.515985 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:54:24.517915 18636 solver.cpp:353] Iteration 28000 (1.87396 iter/s, 53.3631s/100 iter), loss = 1.44075
I0802 05:54:24.517940 18636 solver.cpp:375]     Train net output #0: loss = 1.39853 (* 1 = 1.39853 loss)
I0802 05:54:24.517949 18636 sgd_solver.cpp:136] Iteration 28000, lr = 0.00825, m = 0.9
I0802 05:54:38.884678 18636 solver.cpp:353] Iteration 28100 (6.9607 iter/s, 14.3664s/100 iter), loss = 1.56361
I0802 05:54:38.884759 18636 solver.cpp:375]     Train net output #0: loss = 1.38216 (* 1 = 1.38216 loss)
I0802 05:54:38.884771 18636 sgd_solver.cpp:136] Iteration 28100, lr = 0.00824375, m = 0.9
I0802 05:54:52.827004 18636 solver.cpp:353] Iteration 28200 (7.1726 iter/s, 13.9419s/100 iter), loss = 1.50082
I0802 05:54:52.827054 18636 solver.cpp:375]     Train net output #0: loss = 1.92704 (* 1 = 1.92704 loss)
I0802 05:54:52.827066 18636 sgd_solver.cpp:136] Iteration 28200, lr = 0.0082375, m = 0.9
I0802 05:55:06.724313 18636 solver.cpp:353] Iteration 28300 (7.19583 iter/s, 13.8969s/100 iter), loss = 1.14405
I0802 05:55:06.724339 18636 solver.cpp:375]     Train net output #0: loss = 0.965398 (* 1 = 0.965398 loss)
I0802 05:55:06.724344 18636 sgd_solver.cpp:136] Iteration 28300, lr = 0.00823125, m = 0.9
I0802 05:55:20.617398 18636 solver.cpp:353] Iteration 28400 (7.19802 iter/s, 13.8927s/100 iter), loss = 1.33969
I0802 05:55:20.617461 18636 solver.cpp:375]     Train net output #0: loss = 1.24811 (* 1 = 1.24811 loss)
I0802 05:55:20.617511 18636 sgd_solver.cpp:136] Iteration 28400, lr = 0.008225, m = 0.9
I0802 05:55:34.476828 18636 solver.cpp:353] Iteration 28500 (7.2155 iter/s, 13.8591s/100 iter), loss = 1.48448
I0802 05:55:34.476853 18636 solver.cpp:375]     Train net output #0: loss = 1.35362 (* 1 = 1.35362 loss)
I0802 05:55:34.476857 18636 sgd_solver.cpp:136] Iteration 28500, lr = 0.00821875, m = 0.9
I0802 05:55:48.346257 18636 solver.cpp:353] Iteration 28600 (7.2103 iter/s, 13.8691s/100 iter), loss = 1.43251
I0802 05:55:48.346287 18636 solver.cpp:375]     Train net output #0: loss = 1.23167 (* 1 = 1.23167 loss)
I0802 05:55:48.346292 18636 sgd_solver.cpp:136] Iteration 28600, lr = 0.0082125, m = 0.9
I0802 05:56:02.275045 18636 solver.cpp:353] Iteration 28700 (7.17957 iter/s, 13.9284s/100 iter), loss = 1.44467
I0802 05:56:02.275142 18636 solver.cpp:375]     Train net output #0: loss = 1.49335 (* 1 = 1.49335 loss)
I0802 05:56:02.275151 18636 sgd_solver.cpp:136] Iteration 28700, lr = 0.00820625, m = 0.9
I0802 05:56:16.309741 18636 solver.cpp:353] Iteration 28800 (7.12539 iter/s, 14.0343s/100 iter), loss = 1.72062
I0802 05:56:16.309769 18636 solver.cpp:375]     Train net output #0: loss = 1.96237 (* 1 = 1.96237 loss)
I0802 05:56:16.309777 18636 sgd_solver.cpp:136] Iteration 28800, lr = 0.0082, m = 0.9
I0802 05:56:30.224898 18636 solver.cpp:353] Iteration 28900 (7.1866 iter/s, 13.9148s/100 iter), loss = 1.06731
I0802 05:56:30.224930 18636 solver.cpp:375]     Train net output #0: loss = 0.991142 (* 1 = 0.991142 loss)
I0802 05:56:30.224936 18636 sgd_solver.cpp:136] Iteration 28900, lr = 0.00819375, m = 0.9
I0802 05:56:43.965917 18636 solver.cpp:404] Sparsity after update:
I0802 05:56:43.977092 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:56:43.977107 18636 net.cpp:2270] conv1a_param_0(0.04) 
I0802 05:56:43.977114 18636 net.cpp:2270] conv1b_param_0(0.0417) 
I0802 05:56:43.977118 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:56:43.977129 18636 net.cpp:2270] res2a_branch2a_param_0(0.0868) 
I0802 05:56:43.977139 18636 net.cpp:2270] res2a_branch2b_param_0(0.0833) 
I0802 05:56:43.977149 18636 net.cpp:2270] res3a_branch2a_param_0(0.0885) 
I0802 05:56:43.977156 18636 net.cpp:2270] res3a_branch2b_param_0(0.0868) 
I0802 05:56:43.977165 18636 net.cpp:2270] res4a_branch2a_param_0(0.0894) 
I0802 05:56:43.977174 18636 net.cpp:2270] res4a_branch2b_param_0(0.0885) 
I0802 05:56:43.977182 18636 net.cpp:2270] res5a_branch2a_param_0(0.0898) 
I0802 05:56:43.977191 18636 net.cpp:2270] res5a_branch2b_param_0(0.0894) 
I0802 05:56:43.977201 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (210392/2.86678e+06) 0.0734
I0802 05:56:44.106552 18661 solver.cpp:450] Finding and applying sparsity: 0.1
I0802 05:57:04.043655 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 05:57:04.045635 18636 solver.cpp:353] Iteration 29000 (2.95685 iter/s, 33.8198s/100 iter), loss = 1.18944
I0802 05:57:04.045672 18636 solver.cpp:375]     Train net output #0: loss = 0.998471 (* 1 = 0.998471 loss)
I0802 05:57:04.045681 18636 sgd_solver.cpp:136] Iteration 29000, lr = 0.0081875, m = 0.9
I0802 05:57:18.509735 18636 solver.cpp:353] Iteration 29100 (6.91386 iter/s, 14.4637s/100 iter), loss = 1.42564
I0802 05:57:18.509838 18636 solver.cpp:375]     Train net output #0: loss = 1.19782 (* 1 = 1.19782 loss)
I0802 05:57:18.509860 18636 sgd_solver.cpp:136] Iteration 29100, lr = 0.00818125, m = 0.9
I0802 05:57:32.500514 18636 solver.cpp:353] Iteration 29200 (7.14776 iter/s, 13.9904s/100 iter), loss = 1.47032
I0802 05:57:32.500542 18636 solver.cpp:375]     Train net output #0: loss = 1.21898 (* 1 = 1.21898 loss)
I0802 05:57:32.500548 18636 sgd_solver.cpp:136] Iteration 29200, lr = 0.008175, m = 0.9
I0802 05:57:46.439697 18636 solver.cpp:353] Iteration 29300 (7.17422 iter/s, 13.9388s/100 iter), loss = 1.66436
I0802 05:57:46.439728 18636 solver.cpp:375]     Train net output #0: loss = 1.42395 (* 1 = 1.42395 loss)
I0802 05:57:46.439734 18636 sgd_solver.cpp:136] Iteration 29300, lr = 0.00816875, m = 0.9
I0802 05:58:00.393677 18636 solver.cpp:353] Iteration 29400 (7.16661 iter/s, 13.9536s/100 iter), loss = 1.53845
I0802 05:58:00.393759 18636 solver.cpp:375]     Train net output #0: loss = 1.38139 (* 1 = 1.38139 loss)
I0802 05:58:00.393766 18636 sgd_solver.cpp:136] Iteration 29400, lr = 0.0081625, m = 0.9
I0802 05:58:14.452641 18636 solver.cpp:353] Iteration 29500 (7.11309 iter/s, 14.0586s/100 iter), loss = 1.03383
I0802 05:58:14.452674 18636 solver.cpp:375]     Train net output #0: loss = 0.914532 (* 1 = 0.914532 loss)
I0802 05:58:14.452683 18636 sgd_solver.cpp:136] Iteration 29500, lr = 0.00815625, m = 0.9
I0802 05:58:28.427186 18636 solver.cpp:353] Iteration 29600 (7.15606 iter/s, 13.9742s/100 iter), loss = 1.31844
I0802 05:58:28.427227 18636 solver.cpp:375]     Train net output #0: loss = 1.50894 (* 1 = 1.50894 loss)
I0802 05:58:28.427235 18636 sgd_solver.cpp:136] Iteration 29600, lr = 0.00815, m = 0.9
I0802 05:58:42.444792 18636 solver.cpp:353] Iteration 29700 (7.13408 iter/s, 14.0172s/100 iter), loss = 1.38425
I0802 05:58:42.444916 18636 solver.cpp:375]     Train net output #0: loss = 0.928484 (* 1 = 0.928484 loss)
I0802 05:58:42.444922 18636 sgd_solver.cpp:136] Iteration 29700, lr = 0.00814375, m = 0.9
I0802 05:58:56.391649 18636 solver.cpp:353] Iteration 29800 (7.17027 iter/s, 13.9465s/100 iter), loss = 1.07253
I0802 05:58:56.391674 18636 solver.cpp:375]     Train net output #0: loss = 1.08238 (* 1 = 1.08238 loss)
I0802 05:58:56.391680 18636 sgd_solver.cpp:136] Iteration 29800, lr = 0.0081375, m = 0.9
I0802 05:59:10.329859 18636 solver.cpp:353] Iteration 29900 (7.17472 iter/s, 13.9378s/100 iter), loss = 1.21531
I0802 05:59:10.329883 18636 solver.cpp:375]     Train net output #0: loss = 1.20152 (* 1 = 1.20152 loss)
I0802 05:59:10.329888 18636 sgd_solver.cpp:136] Iteration 29900, lr = 0.00813125, m = 0.9
I0802 05:59:24.033574 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_30000.caffemodel
I0802 05:59:24.126144 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_30000.solverstate
I0802 05:59:24.130535 18636 solver.cpp:404] Sparsity after update:
I0802 05:59:24.132350 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 05:59:24.132361 18636 net.cpp:2270] conv1a_param_0(0.04) 
I0802 05:59:24.132370 18636 net.cpp:2270] conv1b_param_0(0.0486) 
I0802 05:59:24.132375 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 05:59:24.132385 18636 net.cpp:2270] res2a_branch2a_param_0(0.0972) 
I0802 05:59:24.132395 18636 net.cpp:2270] res2a_branch2b_param_0(0.0972) 
I0802 05:59:24.132405 18636 net.cpp:2270] res3a_branch2a_param_0(0.099) 
I0802 05:59:24.132412 18636 net.cpp:2270] res3a_branch2b_param_0(0.0972) 
I0802 05:59:24.132421 18636 net.cpp:2270] res4a_branch2a_param_0(0.0998) 
I0802 05:59:24.132429 18636 net.cpp:2270] res4a_branch2b_param_0(0.099) 
I0802 05:59:24.132438 18636 net.cpp:2270] res5a_branch2a_param_0(0.0998) 
I0802 05:59:24.132448 18636 net.cpp:2270] res5a_branch2b_param_0(0.0998) 
I0802 05:59:24.132458 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (234400/2.86678e+06) 0.0818
I0802 05:59:24.132483 18636 solver.cpp:550] Iteration 30000, Testing net (#0)
I0802 05:59:37.595752 18619 data_reader.cpp:264] Starting prefetch of epoch 3
I0802 05:59:44.095373 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.559235
I0802 05:59:44.095394 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.793174
I0802 05:59:44.095399 18636 solver.cpp:635]     Test net output #2: loss = 1.94894 (* 1 = 1.94894 loss)
I0802 05:59:44.095417 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9624s
I0802 05:59:44.233949 18661 solver.cpp:450] Finding and applying sparsity: 0.11
I0802 06:00:04.353149 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:00:04.355175 18636 solver.cpp:353] Iteration 30000 (1.85103 iter/s, 54.0239s/100 iter), loss = 1.55084
I0802 06:00:04.355196 18636 solver.cpp:375]     Train net output #0: loss = 1.76583 (* 1 = 1.76583 loss)
I0802 06:00:04.355204 18636 sgd_solver.cpp:136] Iteration 30000, lr = 0.008125, m = 0.9
I0802 06:00:18.704565 18636 solver.cpp:353] Iteration 30100 (6.96913 iter/s, 14.349s/100 iter), loss = 1.32596
I0802 06:00:18.704620 18636 solver.cpp:375]     Train net output #0: loss = 1.75135 (* 1 = 1.75135 loss)
I0802 06:00:18.704633 18636 sgd_solver.cpp:136] Iteration 30100, lr = 0.00811875, m = 0.9
I0802 06:00:32.593791 18636 solver.cpp:353] Iteration 30200 (7.20002 iter/s, 13.8888s/100 iter), loss = 1.54684
I0802 06:00:32.593843 18636 solver.cpp:375]     Train net output #0: loss = 1.27261 (* 1 = 1.27261 loss)
I0802 06:00:32.593855 18636 sgd_solver.cpp:136] Iteration 30200, lr = 0.0081125, m = 0.9
I0802 06:00:46.584283 18636 solver.cpp:353] Iteration 30300 (7.14791 iter/s, 13.9901s/100 iter), loss = 1.39891
I0802 06:00:46.584355 18636 solver.cpp:375]     Train net output #0: loss = 1.52353 (* 1 = 1.52353 loss)
I0802 06:00:46.584362 18636 sgd_solver.cpp:136] Iteration 30300, lr = 0.00810625, m = 0.9
I0802 06:01:00.582442 18636 solver.cpp:353] Iteration 30400 (7.14399 iter/s, 13.9978s/100 iter), loss = 1.61956
I0802 06:01:00.582473 18636 solver.cpp:375]     Train net output #0: loss = 1.50366 (* 1 = 1.50366 loss)
I0802 06:01:00.582479 18636 sgd_solver.cpp:136] Iteration 30400, lr = 0.0081, m = 0.9
I0802 06:01:14.577157 18636 solver.cpp:353] Iteration 30500 (7.14575 iter/s, 13.9943s/100 iter), loss = 1.28949
I0802 06:01:14.577262 18636 solver.cpp:375]     Train net output #0: loss = 1.10569 (* 1 = 1.10569 loss)
I0802 06:01:14.577283 18636 sgd_solver.cpp:136] Iteration 30500, lr = 0.00809375, m = 0.9
I0802 06:01:28.466857 18636 solver.cpp:353] Iteration 30600 (7.19978 iter/s, 13.8893s/100 iter), loss = 1.71852
I0802 06:01:28.467118 18636 solver.cpp:375]     Train net output #0: loss = 1.61279 (* 1 = 1.61279 loss)
I0802 06:01:28.467241 18636 sgd_solver.cpp:136] Iteration 30600, lr = 0.0080875, m = 0.9
I0802 06:01:42.438578 18636 solver.cpp:353] Iteration 30700 (7.15751 iter/s, 13.9713s/100 iter), loss = 1.45255
I0802 06:01:42.438616 18636 solver.cpp:375]     Train net output #0: loss = 1.45898 (* 1 = 1.45898 loss)
I0802 06:01:42.438623 18636 sgd_solver.cpp:136] Iteration 30700, lr = 0.00808125, m = 0.9
I0802 06:01:56.410507 18636 solver.cpp:353] Iteration 30800 (7.1574 iter/s, 13.9716s/100 iter), loss = 1.66551
I0802 06:01:56.410536 18636 solver.cpp:375]     Train net output #0: loss = 1.8377 (* 1 = 1.8377 loss)
I0802 06:01:56.410542 18636 sgd_solver.cpp:136] Iteration 30800, lr = 0.008075, m = 0.9
I0802 06:02:10.450546 18636 solver.cpp:353] Iteration 30900 (7.12268 iter/s, 14.0397s/100 iter), loss = 1.37373
I0802 06:02:10.450628 18636 solver.cpp:375]     Train net output #0: loss = 1.3678 (* 1 = 1.3678 loss)
I0802 06:02:10.450634 18636 sgd_solver.cpp:136] Iteration 30900, lr = 0.00806875, m = 0.9
I0802 06:02:24.294728 18636 solver.cpp:404] Sparsity after update:
I0802 06:02:24.305922 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:02:24.305934 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:02:24.305943 18636 net.cpp:2270] conv1b_param_0(0.0486) 
I0802 06:02:24.305948 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:02:24.305953 18636 net.cpp:2270] res2a_branch2a_param_0(0.108) 
I0802 06:02:24.305958 18636 net.cpp:2270] res2a_branch2b_param_0(0.104) 
I0802 06:02:24.305960 18636 net.cpp:2270] res3a_branch2a_param_0(0.109) 
I0802 06:02:24.305965 18636 net.cpp:2270] res3a_branch2b_param_0(0.108) 
I0802 06:02:24.305968 18636 net.cpp:2270] res4a_branch2a_param_0(0.109) 
I0802 06:02:24.305974 18636 net.cpp:2270] res4a_branch2b_param_0(0.109) 
I0802 06:02:24.305977 18636 net.cpp:2270] res5a_branch2a_param_0(0.11) 
I0802 06:02:24.305982 18636 net.cpp:2270] res5a_branch2b_param_0(0.109) 
I0802 06:02:24.305986 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (257606/2.86678e+06) 0.0899
I0802 06:02:24.450870 18661 solver.cpp:450] Finding and applying sparsity: 0.12
I0802 06:02:44.700291 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:02:44.702239 18636 solver.cpp:353] Iteration 31000 (2.91964 iter/s, 34.2508s/100 iter), loss = 1.54528
I0802 06:02:44.702256 18636 solver.cpp:375]     Train net output #0: loss = 1.26986 (* 1 = 1.26986 loss)
I0802 06:02:44.702262 18636 sgd_solver.cpp:136] Iteration 31000, lr = 0.0080625, m = 0.9
I0802 06:02:59.029135 18636 solver.cpp:353] Iteration 31100 (6.98007 iter/s, 14.3265s/100 iter), loss = 1.3692
I0802 06:02:59.029161 18636 solver.cpp:375]     Train net output #0: loss = 1.43204 (* 1 = 1.43204 loss)
I0802 06:02:59.029167 18636 sgd_solver.cpp:136] Iteration 31100, lr = 0.00805625, m = 0.9
I0802 06:03:12.971092 18636 solver.cpp:353] Iteration 31200 (7.17279 iter/s, 13.9416s/100 iter), loss = 1.51153
I0802 06:03:12.971119 18636 solver.cpp:375]     Train net output #0: loss = 1.30409 (* 1 = 1.30409 loss)
I0802 06:03:12.971125 18636 sgd_solver.cpp:136] Iteration 31200, lr = 0.00805, m = 0.9
I0802 06:03:26.903607 18636 solver.cpp:353] Iteration 31300 (7.17765 iter/s, 13.9321s/100 iter), loss = 1.53376
I0802 06:03:26.903708 18636 solver.cpp:375]     Train net output #0: loss = 1.68108 (* 1 = 1.68108 loss)
I0802 06:03:26.903717 18636 sgd_solver.cpp:136] Iteration 31300, lr = 0.00804375, m = 0.9
I0802 06:03:40.943881 18636 solver.cpp:353] Iteration 31400 (7.12256 iter/s, 14.0399s/100 iter), loss = 1.29764
I0802 06:03:40.943938 18636 solver.cpp:375]     Train net output #0: loss = 0.925732 (* 1 = 0.925732 loss)
I0802 06:03:40.943953 18636 sgd_solver.cpp:136] Iteration 31400, lr = 0.0080375, m = 0.9
I0802 06:03:54.825460 18636 solver.cpp:353] Iteration 31500 (7.20399 iter/s, 13.8812s/100 iter), loss = 1.62597
I0802 06:03:54.825489 18636 solver.cpp:375]     Train net output #0: loss = 1.41889 (* 1 = 1.41889 loss)
I0802 06:03:54.825492 18636 sgd_solver.cpp:136] Iteration 31500, lr = 0.00803125, m = 0.9
I0802 06:04:08.749730 18636 solver.cpp:353] Iteration 31600 (7.1819 iter/s, 13.9239s/100 iter), loss = 1.01587
I0802 06:04:08.749794 18636 solver.cpp:375]     Train net output #0: loss = 1.06167 (* 1 = 1.06167 loss)
I0802 06:04:08.749801 18636 sgd_solver.cpp:136] Iteration 31600, lr = 0.008025, m = 0.9
I0802 06:04:22.789878 18636 solver.cpp:353] Iteration 31700 (7.12262 iter/s, 14.0398s/100 iter), loss = 1.64736
I0802 06:04:22.789901 18636 solver.cpp:375]     Train net output #0: loss = 1.54187 (* 1 = 1.54187 loss)
I0802 06:04:22.789906 18636 sgd_solver.cpp:136] Iteration 31700, lr = 0.00801875, m = 0.9
I0802 06:04:36.716022 18636 solver.cpp:353] Iteration 31800 (7.18093 iter/s, 13.9258s/100 iter), loss = 1.391
I0802 06:04:36.716049 18636 solver.cpp:375]     Train net output #0: loss = 1.52721 (* 1 = 1.52721 loss)
I0802 06:04:36.716056 18636 sgd_solver.cpp:136] Iteration 31800, lr = 0.0080125, m = 0.9
I0802 06:04:50.609114 18636 solver.cpp:353] Iteration 31900 (7.19802 iter/s, 13.8927s/100 iter), loss = 1.54249
I0802 06:04:50.609360 18636 solver.cpp:375]     Train net output #0: loss = 1.55528 (* 1 = 1.55528 loss)
I0802 06:04:50.609378 18636 sgd_solver.cpp:136] Iteration 31900, lr = 0.00800625, m = 0.9
I0802 06:05:04.447976 18636 solver.cpp:404] Sparsity after update:
I0802 06:05:04.453987 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:05:04.454004 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:05:04.454010 18636 net.cpp:2270] conv1b_param_0(0.0556) 
I0802 06:05:04.454015 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:05:04.454017 18636 net.cpp:2270] res2a_branch2a_param_0(0.118) 
I0802 06:05:04.454021 18636 net.cpp:2270] res2a_branch2b_param_0(0.118) 
I0802 06:05:04.454026 18636 net.cpp:2270] res3a_branch2a_param_0(0.12) 
I0802 06:05:04.454030 18636 net.cpp:2270] res3a_branch2b_param_0(0.118) 
I0802 06:05:04.454033 18636 net.cpp:2270] res4a_branch2a_param_0(0.12) 
I0802 06:05:04.454036 18636 net.cpp:2270] res4a_branch2b_param_0(0.12) 
I0802 06:05:04.454040 18636 net.cpp:2270] res5a_branch2a_param_0(0.12) 
I0802 06:05:04.454042 18636 net.cpp:2270] res5a_branch2b_param_0(0.12) 
I0802 06:05:04.454046 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (281620/2.86678e+06) 0.0982
I0802 06:05:04.454067 18636 solver.cpp:550] Iteration 32000, Testing net (#0)
I0802 06:05:24.197046 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.553588
I0802 06:05:24.197094 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.792939
I0802 06:05:24.197103 18636 solver.cpp:635]     Test net output #2: loss = 1.98824 (* 1 = 1.98824 loss)
I0802 06:05:24.197170 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7426s
I0802 06:05:24.349567 18661 solver.cpp:450] Finding and applying sparsity: 0.13
I0802 06:05:44.432041 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:05:44.433919 18636 solver.cpp:353] Iteration 32000 (1.85793 iter/s, 53.8234s/100 iter), loss = 1.31415
I0802 06:05:44.433938 18636 solver.cpp:375]     Train net output #0: loss = 1.01202 (* 1 = 1.01202 loss)
I0802 06:05:44.433944 18636 sgd_solver.cpp:136] Iteration 32000, lr = 0.008, m = 0.9
I0802 06:05:58.895612 18636 solver.cpp:353] Iteration 32100 (6.91501 iter/s, 14.4613s/100 iter), loss = 1.21099
I0802 06:05:58.895697 18636 solver.cpp:375]     Train net output #0: loss = 1.15348 (* 1 = 1.15348 loss)
I0802 06:05:58.895704 18636 sgd_solver.cpp:136] Iteration 32100, lr = 0.00799375, m = 0.9
I0802 06:06:12.789685 18636 solver.cpp:353] Iteration 32200 (7.19751 iter/s, 13.8937s/100 iter), loss = 1.73192
I0802 06:06:12.789717 18636 solver.cpp:375]     Train net output #0: loss = 2.14005 (* 1 = 2.14005 loss)
I0802 06:06:12.789724 18636 sgd_solver.cpp:136] Iteration 32200, lr = 0.0079875, m = 0.9
I0802 06:06:26.737817 18636 solver.cpp:353] Iteration 32300 (7.16961 iter/s, 13.9478s/100 iter), loss = 1.58302
I0802 06:06:26.737839 18636 solver.cpp:375]     Train net output #0: loss = 1.36198 (* 1 = 1.36198 loss)
I0802 06:06:26.737843 18636 sgd_solver.cpp:136] Iteration 32300, lr = 0.00798125, m = 0.9
I0802 06:06:40.744541 18636 solver.cpp:353] Iteration 32400 (7.13962 iter/s, 14.0063s/100 iter), loss = 1.27726
I0802 06:06:40.744622 18636 solver.cpp:375]     Train net output #0: loss = 1.23522 (* 1 = 1.23522 loss)
I0802 06:06:40.744630 18636 sgd_solver.cpp:136] Iteration 32400, lr = 0.007975, m = 0.9
I0802 06:06:54.807512 18636 solver.cpp:353] Iteration 32500 (7.11106 iter/s, 14.0626s/100 iter), loss = 1.39991
I0802 06:06:54.807543 18636 solver.cpp:375]     Train net output #0: loss = 1.44973 (* 1 = 1.44973 loss)
I0802 06:06:54.807548 18636 sgd_solver.cpp:136] Iteration 32500, lr = 0.00796875, m = 0.9
I0802 06:07:08.808859 18636 solver.cpp:353] Iteration 32600 (7.14237 iter/s, 14.001s/100 iter), loss = 1.75013
I0802 06:07:08.808895 18636 solver.cpp:375]     Train net output #0: loss = 2.22344 (* 1 = 2.22344 loss)
I0802 06:07:08.808902 18636 sgd_solver.cpp:136] Iteration 32600, lr = 0.0079625, m = 0.9
I0802 06:07:22.758975 18636 solver.cpp:353] Iteration 32700 (7.16859 iter/s, 13.9497s/100 iter), loss = 1.17581
I0802 06:07:22.759032 18636 solver.cpp:375]     Train net output #0: loss = 1.31548 (* 1 = 1.31548 loss)
I0802 06:07:22.759038 18636 sgd_solver.cpp:136] Iteration 32700, lr = 0.00795625, m = 0.9
I0802 06:07:36.652197 18636 solver.cpp:353] Iteration 32800 (7.19795 iter/s, 13.8928s/100 iter), loss = 1.25648
I0802 06:07:36.652220 18636 solver.cpp:375]     Train net output #0: loss = 1.28467 (* 1 = 1.28467 loss)
I0802 06:07:36.652225 18636 sgd_solver.cpp:136] Iteration 32800, lr = 0.00795, m = 0.9
I0802 06:07:50.659379 18636 solver.cpp:353] Iteration 32900 (7.13939 iter/s, 14.0068s/100 iter), loss = 1.94627
I0802 06:07:50.659409 18636 solver.cpp:375]     Train net output #0: loss = 2.0849 (* 1 = 2.0849 loss)
I0802 06:07:50.659415 18636 sgd_solver.cpp:136] Iteration 32900, lr = 0.00794375, m = 0.9
I0802 06:08:04.500062 18636 solver.cpp:404] Sparsity after update:
I0802 06:08:04.511224 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:08:04.511237 18636 net.cpp:2270] conv1a_param_0(0.0533) 
I0802 06:08:04.511246 18636 net.cpp:2270] conv1b_param_0(0.0625) 
I0802 06:08:04.511250 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:08:04.511262 18636 net.cpp:2270] res2a_branch2a_param_0(0.128) 
I0802 06:08:04.511272 18636 net.cpp:2270] res2a_branch2b_param_0(0.125) 
I0802 06:08:04.511281 18636 net.cpp:2270] res3a_branch2a_param_0(0.128) 
I0802 06:08:04.511291 18636 net.cpp:2270] res3a_branch2b_param_0(0.128) 
I0802 06:08:04.511296 18636 net.cpp:2270] res4a_branch2a_param_0(0.129) 
I0802 06:08:04.511299 18636 net.cpp:2270] res4a_branch2b_param_0(0.128) 
I0802 06:08:04.511307 18636 net.cpp:2270] res5a_branch2a_param_0(0.13) 
I0802 06:08:04.511312 18636 net.cpp:2270] res5a_branch2b_param_0(0.129) 
I0802 06:08:04.511317 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (304422/2.86678e+06) 0.106
I0802 06:08:04.640012 18661 solver.cpp:450] Finding and applying sparsity: 0.14
I0802 06:08:24.951288 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:08:24.953225 18636 solver.cpp:353] Iteration 33000 (2.91606 iter/s, 34.2929s/100 iter), loss = 1.3684
I0802 06:08:24.953243 18636 solver.cpp:375]     Train net output #0: loss = 1.39817 (* 1 = 1.39817 loss)
I0802 06:08:24.953249 18636 sgd_solver.cpp:136] Iteration 33000, lr = 0.0079375, m = 0.9
I0802 06:08:39.351909 18636 solver.cpp:353] Iteration 33100 (6.94527 iter/s, 14.3983s/100 iter), loss = 1.43742
I0802 06:08:39.351992 18636 solver.cpp:375]     Train net output #0: loss = 1.53362 (* 1 = 1.53362 loss)
I0802 06:08:39.352001 18636 sgd_solver.cpp:136] Iteration 33100, lr = 0.00793125, m = 0.9
I0802 06:08:53.253420 18636 solver.cpp:353] Iteration 33200 (7.19366 iter/s, 13.9011s/100 iter), loss = 1.2981
I0802 06:08:53.253449 18636 solver.cpp:375]     Train net output #0: loss = 1.10609 (* 1 = 1.10609 loss)
I0802 06:08:53.253455 18636 sgd_solver.cpp:136] Iteration 33200, lr = 0.007925, m = 0.9
I0802 06:09:07.130131 18636 solver.cpp:353] Iteration 33300 (7.20651 iter/s, 13.8763s/100 iter), loss = 1.52726
I0802 06:09:07.130156 18636 solver.cpp:375]     Train net output #0: loss = 1.32184 (* 1 = 1.32184 loss)
I0802 06:09:07.130162 18636 sgd_solver.cpp:136] Iteration 33300, lr = 0.00791875, m = 0.9
I0802 06:09:20.979233 18636 solver.cpp:353] Iteration 33400 (7.22088 iter/s, 13.8487s/100 iter), loss = 1.5708
I0802 06:09:20.979318 18636 solver.cpp:375]     Train net output #0: loss = 1.31809 (* 1 = 1.31809 loss)
I0802 06:09:20.979326 18636 sgd_solver.cpp:136] Iteration 33400, lr = 0.0079125, m = 0.9
I0802 06:09:34.832259 18636 solver.cpp:353] Iteration 33500 (7.21884 iter/s, 13.8526s/100 iter), loss = 1.69316
I0802 06:09:34.832288 18636 solver.cpp:375]     Train net output #0: loss = 1.53227 (* 1 = 1.53227 loss)
I0802 06:09:34.832293 18636 sgd_solver.cpp:136] Iteration 33500, lr = 0.00790625, m = 0.9
I0802 06:09:48.706733 18636 solver.cpp:353] Iteration 33600 (7.20767 iter/s, 13.8741s/100 iter), loss = 1.39298
I0802 06:09:48.706763 18636 solver.cpp:375]     Train net output #0: loss = 1.55378 (* 1 = 1.55378 loss)
I0802 06:09:48.706769 18636 sgd_solver.cpp:136] Iteration 33600, lr = 0.0079, m = 0.9
I0802 06:10:02.608650 18636 solver.cpp:353] Iteration 33700 (7.19345 iter/s, 13.9015s/100 iter), loss = 1.55934
I0802 06:10:02.608757 18636 solver.cpp:375]     Train net output #0: loss = 1.90295 (* 1 = 1.90295 loss)
I0802 06:10:02.608765 18636 sgd_solver.cpp:136] Iteration 33700, lr = 0.00789375, m = 0.9
I0802 06:10:16.490907 18636 solver.cpp:353] Iteration 33800 (7.20363 iter/s, 13.8819s/100 iter), loss = 1.4353
I0802 06:10:16.490938 18636 solver.cpp:375]     Train net output #0: loss = 1.84529 (* 1 = 1.84529 loss)
I0802 06:10:16.490944 18636 sgd_solver.cpp:136] Iteration 33800, lr = 0.0078875, m = 0.9
I0802 06:10:30.520153 18636 solver.cpp:353] Iteration 33900 (7.12816 iter/s, 14.0289s/100 iter), loss = 1.21506
I0802 06:10:30.520223 18636 solver.cpp:375]     Train net output #0: loss = 1.20371 (* 1 = 1.20371 loss)
I0802 06:10:30.520243 18636 sgd_solver.cpp:136] Iteration 33900, lr = 0.00788125, m = 0.9
I0802 06:10:44.253865 18636 solver.cpp:404] Sparsity after update:
I0802 06:10:44.259771 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:10:44.259781 18636 net.cpp:2270] conv1a_param_0(0.0667) 
I0802 06:10:44.259789 18636 net.cpp:2270] conv1b_param_0(0.0694) 
I0802 06:10:44.259791 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:10:44.259793 18636 net.cpp:2270] res2a_branch2a_param_0(0.139) 
I0802 06:10:44.259795 18636 net.cpp:2270] res2a_branch2b_param_0(0.139) 
I0802 06:10:44.259798 18636 net.cpp:2270] res3a_branch2a_param_0(0.139) 
I0802 06:10:44.259799 18636 net.cpp:2270] res3a_branch2b_param_0(0.139) 
I0802 06:10:44.259801 18636 net.cpp:2270] res4a_branch2a_param_0(0.14) 
I0802 06:10:44.259802 18636 net.cpp:2270] res4a_branch2b_param_0(0.139) 
I0802 06:10:44.259804 18636 net.cpp:2270] res5a_branch2a_param_0(0.14) 
I0802 06:10:44.259806 18636 net.cpp:2270] res5a_branch2b_param_0(0.14) 
I0802 06:10:44.259809 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (328454/2.86678e+06) 0.115
I0802 06:10:44.259817 18636 solver.cpp:550] Iteration 34000, Testing net (#0)
I0802 06:10:53.497588 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:11:03.796056 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.549588
I0802 06:11:03.796079 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.787291
I0802 06:11:03.796085 18636 solver.cpp:635]     Test net output #2: loss = 2.00174 (* 1 = 2.00174 loss)
I0802 06:11:03.796108 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5358s
I0802 06:11:03.952508 18661 solver.cpp:450] Finding and applying sparsity: 0.15
I0802 06:11:24.097986 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:11:24.099927 18636 solver.cpp:353] Iteration 34000 (1.86643 iter/s, 53.5783s/100 iter), loss = 1.93675
I0802 06:11:24.099951 18636 solver.cpp:375]     Train net output #0: loss = 1.56001 (* 1 = 1.56001 loss)
I0802 06:11:24.099961 18636 sgd_solver.cpp:136] Iteration 34000, lr = 0.007875, m = 0.9
I0802 06:11:38.466827 18636 solver.cpp:353] Iteration 34100 (6.96064 iter/s, 14.3665s/100 iter), loss = 1.61132
I0802 06:11:38.466856 18636 solver.cpp:375]     Train net output #0: loss = 2.14462 (* 1 = 2.14462 loss)
I0802 06:11:38.466861 18636 sgd_solver.cpp:136] Iteration 34100, lr = 0.00786875, m = 0.9
I0802 06:11:52.376768 18636 solver.cpp:353] Iteration 34200 (7.1893 iter/s, 13.9096s/100 iter), loss = 1.47794
I0802 06:11:52.376798 18636 solver.cpp:375]     Train net output #0: loss = 0.957443 (* 1 = 0.957443 loss)
I0802 06:11:52.376806 18636 sgd_solver.cpp:136] Iteration 34200, lr = 0.0078625, m = 0.9
I0802 06:12:06.240746 18636 solver.cpp:353] Iteration 34300 (7.21313 iter/s, 13.8636s/100 iter), loss = 1.60245
I0802 06:12:06.240804 18636 solver.cpp:375]     Train net output #0: loss = 1.42783 (* 1 = 1.42783 loss)
I0802 06:12:06.240810 18636 sgd_solver.cpp:136] Iteration 34300, lr = 0.00785625, m = 0.9
I0802 06:12:20.134119 18636 solver.cpp:353] Iteration 34400 (7.19787 iter/s, 13.893s/100 iter), loss = 1.35297
I0802 06:12:20.134187 18636 solver.cpp:375]     Train net output #0: loss = 1.25616 (* 1 = 1.25616 loss)
I0802 06:12:20.134201 18636 sgd_solver.cpp:136] Iteration 34400, lr = 0.00785, m = 0.9
I0802 06:12:34.038715 18636 solver.cpp:353] Iteration 34500 (7.19206 iter/s, 13.9042s/100 iter), loss = 1.12554
I0802 06:12:34.038743 18636 solver.cpp:375]     Train net output #0: loss = 1.15932 (* 1 = 1.15932 loss)
I0802 06:12:34.038750 18636 sgd_solver.cpp:136] Iteration 34500, lr = 0.00784375, m = 0.9
I0802 06:12:47.964478 18636 solver.cpp:353] Iteration 34600 (7.18113 iter/s, 13.9254s/100 iter), loss = 1.33582
I0802 06:12:47.964535 18636 solver.cpp:375]     Train net output #0: loss = 1.322 (* 1 = 1.322 loss)
I0802 06:12:47.964540 18636 sgd_solver.cpp:136] Iteration 34600, lr = 0.0078375, m = 0.9
I0802 06:13:01.897832 18636 solver.cpp:353] Iteration 34700 (7.17722 iter/s, 13.933s/100 iter), loss = 1.23736
I0802 06:13:01.897884 18636 solver.cpp:375]     Train net output #0: loss = 1.24658 (* 1 = 1.24658 loss)
I0802 06:13:01.897897 18636 sgd_solver.cpp:136] Iteration 34700, lr = 0.00783125, m = 0.9
I0802 06:13:15.799737 18636 solver.cpp:353] Iteration 34800 (7.19345 iter/s, 13.9015s/100 iter), loss = 1.65103
I0802 06:13:15.799791 18636 solver.cpp:375]     Train net output #0: loss = 2.00466 (* 1 = 2.00466 loss)
I0802 06:13:15.799803 18636 sgd_solver.cpp:136] Iteration 34800, lr = 0.007825, m = 0.9
I0802 06:13:29.772428 18636 solver.cpp:353] Iteration 34900 (7.15701 iter/s, 13.9723s/100 iter), loss = 1.3906
I0802 06:13:29.772493 18636 solver.cpp:375]     Train net output #0: loss = 1.35142 (* 1 = 1.35142 loss)
I0802 06:13:29.772501 18636 sgd_solver.cpp:136] Iteration 34900, lr = 0.00781875, m = 0.9
I0802 06:13:43.697849 18636 solver.cpp:404] Sparsity after update:
I0802 06:13:43.709441 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:13:43.709455 18636 net.cpp:2270] conv1a_param_0(0.0667) 
I0802 06:13:43.709463 18636 net.cpp:2270] conv1b_param_0(0.0694) 
I0802 06:13:43.709467 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:13:43.709471 18636 net.cpp:2270] res2a_branch2a_param_0(0.149) 
I0802 06:13:43.709475 18636 net.cpp:2270] res2a_branch2b_param_0(0.146) 
I0802 06:13:43.709480 18636 net.cpp:2270] res3a_branch2a_param_0(0.149) 
I0802 06:13:43.709482 18636 net.cpp:2270] res3a_branch2b_param_0(0.149) 
I0802 06:13:43.709486 18636 net.cpp:2270] res4a_branch2a_param_0(0.149) 
I0802 06:13:43.709489 18636 net.cpp:2270] res4a_branch2b_param_0(0.149) 
I0802 06:13:43.709492 18636 net.cpp:2270] res5a_branch2a_param_0(0.15) 
I0802 06:13:43.709496 18636 net.cpp:2270] res5a_branch2b_param_0(0.149) 
I0802 06:13:43.709512 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (351632/2.86678e+06) 0.123
I0802 06:13:43.847515 18661 solver.cpp:450] Finding and applying sparsity: 0.16
I0802 06:14:04.641059 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:14:04.643103 18636 solver.cpp:353] Iteration 35000 (2.86782 iter/s, 34.8697s/100 iter), loss = 1.43152
I0802 06:14:04.643139 18636 solver.cpp:375]     Train net output #0: loss = 1.01164 (* 1 = 1.01164 loss)
I0802 06:14:04.643148 18636 sgd_solver.cpp:136] Iteration 35000, lr = 0.0078125, m = 0.9
I0802 06:14:18.947489 18636 solver.cpp:353] Iteration 35100 (6.99105 iter/s, 14.304s/100 iter), loss = 1.42457
I0802 06:14:18.947513 18636 solver.cpp:375]     Train net output #0: loss = 1.97777 (* 1 = 1.97777 loss)
I0802 06:14:18.947520 18636 sgd_solver.cpp:136] Iteration 35100, lr = 0.00780625, m = 0.9
I0802 06:14:32.969018 18636 solver.cpp:353] Iteration 35200 (7.13209 iter/s, 14.0211s/100 iter), loss = 1.42045
I0802 06:14:32.969049 18636 solver.cpp:375]     Train net output #0: loss = 1.4208 (* 1 = 1.4208 loss)
I0802 06:14:32.969055 18636 sgd_solver.cpp:136] Iteration 35200, lr = 0.0078, m = 0.9
I0802 06:14:46.913822 18636 solver.cpp:353] Iteration 35300 (7.17133 iter/s, 13.9444s/100 iter), loss = 1.41107
I0802 06:14:46.913913 18636 solver.cpp:375]     Train net output #0: loss = 0.936475 (* 1 = 0.936475 loss)
I0802 06:14:46.913920 18636 sgd_solver.cpp:136] Iteration 35300, lr = 0.00779375, m = 0.9
I0802 06:15:00.840399 18636 solver.cpp:353] Iteration 35400 (7.18071 iter/s, 13.9262s/100 iter), loss = 1.51751
I0802 06:15:00.840426 18636 solver.cpp:375]     Train net output #0: loss = 1.38669 (* 1 = 1.38669 loss)
I0802 06:15:00.840432 18636 sgd_solver.cpp:136] Iteration 35400, lr = 0.0077875, m = 0.9
I0802 06:15:14.787082 18636 solver.cpp:353] Iteration 35500 (7.17036 iter/s, 13.9463s/100 iter), loss = 1.56842
I0802 06:15:14.787112 18636 solver.cpp:375]     Train net output #0: loss = 1.52226 (* 1 = 1.52226 loss)
I0802 06:15:14.787118 18636 sgd_solver.cpp:136] Iteration 35500, lr = 0.00778125, m = 0.9
I0802 06:15:28.679105 18636 solver.cpp:353] Iteration 35600 (7.19857 iter/s, 13.8916s/100 iter), loss = 1.7313
I0802 06:15:28.679175 18636 solver.cpp:375]     Train net output #0: loss = 1.96809 (* 1 = 1.96809 loss)
I0802 06:15:28.679183 18636 sgd_solver.cpp:136] Iteration 35600, lr = 0.007775, m = 0.9
I0802 06:15:42.644631 18636 solver.cpp:353] Iteration 35700 (7.16068 iter/s, 13.9651s/100 iter), loss = 1.48752
I0802 06:15:42.644659 18636 solver.cpp:375]     Train net output #0: loss = 1.07982 (* 1 = 1.07982 loss)
I0802 06:15:42.644665 18636 sgd_solver.cpp:136] Iteration 35700, lr = 0.00776875, m = 0.9
I0802 06:15:56.663738 18636 solver.cpp:353] Iteration 35800 (7.13331 iter/s, 14.0187s/100 iter), loss = 1.3464
I0802 06:15:56.663767 18636 solver.cpp:375]     Train net output #0: loss = 1.33096 (* 1 = 1.33096 loss)
I0802 06:15:56.663774 18636 sgd_solver.cpp:136] Iteration 35800, lr = 0.0077625, m = 0.9
I0802 06:16:10.717176 18636 solver.cpp:353] Iteration 35900 (7.11589 iter/s, 14.0531s/100 iter), loss = 1.68913
I0802 06:16:10.717329 18636 solver.cpp:375]     Train net output #0: loss = 1.56663 (* 1 = 1.56663 loss)
I0802 06:16:10.717352 18636 sgd_solver.cpp:136] Iteration 35900, lr = 0.00775625, m = 0.9
I0802 06:16:24.580972 18636 solver.cpp:404] Sparsity after update:
I0802 06:16:24.586894 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:16:24.586905 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:16:24.586911 18636 net.cpp:2270] conv1b_param_0(0.0764) 
I0802 06:16:24.586913 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:16:24.586915 18636 net.cpp:2270] res2a_branch2a_param_0(0.16) 
I0802 06:16:24.586917 18636 net.cpp:2270] res2a_branch2b_param_0(0.16) 
I0802 06:16:24.586920 18636 net.cpp:2270] res3a_branch2a_param_0(0.16) 
I0802 06:16:24.586921 18636 net.cpp:2270] res3a_branch2b_param_0(0.16) 
I0802 06:16:24.586923 18636 net.cpp:2270] res4a_branch2a_param_0(0.16) 
I0802 06:16:24.586925 18636 net.cpp:2270] res4a_branch2b_param_0(0.16) 
I0802 06:16:24.586926 18636 net.cpp:2270] res5a_branch2a_param_0(0.16) 
I0802 06:16:24.586928 18636 net.cpp:2270] res5a_branch2b_param_0(0.16) 
I0802 06:16:24.586930 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (375680/2.86678e+06) 0.131
I0802 06:16:24.586938 18636 solver.cpp:550] Iteration 36000, Testing net (#0)
I0802 06:16:44.273229 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.555117
I0802 06:16:44.273355 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.794233
I0802 06:16:44.273365 18636 solver.cpp:635]     Test net output #2: loss = 1.92847 (* 1 = 1.92847 loss)
I0802 06:16:44.273385 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6859s
I0802 06:16:44.420588 18661 solver.cpp:450] Finding and applying sparsity: 0.17
I0802 06:17:04.913697 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:17:04.915570 18636 solver.cpp:353] Iteration 36000 (1.84512 iter/s, 54.1969s/100 iter), loss = 1.51753
I0802 06:17:04.915586 18636 solver.cpp:375]     Train net output #0: loss = 1.57273 (* 1 = 1.57273 loss)
I0802 06:17:04.915591 18636 sgd_solver.cpp:136] Iteration 36000, lr = 0.00775, m = 0.9
I0802 06:17:19.329577 18636 solver.cpp:353] Iteration 36100 (6.93789 iter/s, 14.4136s/100 iter), loss = 1.50182
I0802 06:17:19.329650 18636 solver.cpp:375]     Train net output #0: loss = 1.53348 (* 1 = 1.53348 loss)
I0802 06:17:19.329658 18636 sgd_solver.cpp:136] Iteration 36100, lr = 0.00774375, m = 0.9
I0802 06:17:33.286272 18636 solver.cpp:353] Iteration 36200 (7.16522 iter/s, 13.9563s/100 iter), loss = 1.76154
I0802 06:17:33.286296 18636 solver.cpp:375]     Train net output #0: loss = 1.67475 (* 1 = 1.67475 loss)
I0802 06:17:33.286301 18636 sgd_solver.cpp:136] Iteration 36200, lr = 0.0077375, m = 0.9
I0802 06:17:47.245664 18636 solver.cpp:353] Iteration 36300 (7.16383 iter/s, 13.959s/100 iter), loss = 1.09926
I0802 06:17:47.245688 18636 solver.cpp:375]     Train net output #0: loss = 1.27584 (* 1 = 1.27584 loss)
I0802 06:17:47.245693 18636 sgd_solver.cpp:136] Iteration 36300, lr = 0.00773125, m = 0.9
I0802 06:18:01.193382 18636 solver.cpp:353] Iteration 36400 (7.16983 iter/s, 13.9473s/100 iter), loss = 1.26449
I0802 06:18:01.193449 18636 solver.cpp:375]     Train net output #0: loss = 1.66912 (* 1 = 1.66912 loss)
I0802 06:18:01.193456 18636 sgd_solver.cpp:136] Iteration 36400, lr = 0.007725, m = 0.9
I0802 06:18:15.328508 18636 solver.cpp:353] Iteration 36500 (7.07477 iter/s, 14.1347s/100 iter), loss = 1.61662
I0802 06:18:15.328578 18636 solver.cpp:375]     Train net output #0: loss = 1.53164 (* 1 = 1.53164 loss)
I0802 06:18:15.328598 18636 sgd_solver.cpp:136] Iteration 36500, lr = 0.00771875, m = 0.9
I0802 06:18:29.340258 18636 solver.cpp:353] Iteration 36600 (7.13706 iter/s, 14.0114s/100 iter), loss = 1.60855
I0802 06:18:29.340286 18636 solver.cpp:375]     Train net output #0: loss = 1.48098 (* 1 = 1.48098 loss)
I0802 06:18:29.340291 18636 sgd_solver.cpp:136] Iteration 36600, lr = 0.0077125, m = 0.9
I0802 06:18:43.297201 18636 solver.cpp:353] Iteration 36700 (7.16508 iter/s, 13.9566s/100 iter), loss = 1.49479
I0802 06:18:43.297263 18636 solver.cpp:375]     Train net output #0: loss = 1.31479 (* 1 = 1.31479 loss)
I0802 06:18:43.297268 18636 sgd_solver.cpp:136] Iteration 36700, lr = 0.00770625, m = 0.9
I0802 06:18:57.193707 18636 solver.cpp:353] Iteration 36800 (7.19625 iter/s, 13.8961s/100 iter), loss = 1.4898
I0802 06:18:57.193732 18636 solver.cpp:375]     Train net output #0: loss = 1.62973 (* 1 = 1.62973 loss)
I0802 06:18:57.193737 18636 sgd_solver.cpp:136] Iteration 36800, lr = 0.0077, m = 0.9
I0802 06:19:11.067134 18636 solver.cpp:353] Iteration 36900 (7.20822 iter/s, 13.8731s/100 iter), loss = 1.21016
I0802 06:19:11.067162 18636 solver.cpp:375]     Train net output #0: loss = 1.23126 (* 1 = 1.23126 loss)
I0802 06:19:11.067167 18636 sgd_solver.cpp:136] Iteration 36900, lr = 0.00769375, m = 0.9
I0802 06:19:24.965551 18636 solver.cpp:404] Sparsity after update:
I0802 06:19:24.977135 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:19:24.977183 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:19:24.977205 18636 net.cpp:2270] conv1b_param_0(0.0833) 
I0802 06:19:24.977218 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:19:24.977231 18636 net.cpp:2270] res2a_branch2a_param_0(0.167) 
I0802 06:19:24.977246 18636 net.cpp:2270] res2a_branch2b_param_0(0.167) 
I0802 06:19:24.977258 18636 net.cpp:2270] res3a_branch2a_param_0(0.168) 
I0802 06:19:24.977270 18636 net.cpp:2270] res3a_branch2b_param_0(0.167) 
I0802 06:19:24.977283 18636 net.cpp:2270] res4a_branch2a_param_0(0.169) 
I0802 06:19:24.977298 18636 net.cpp:2270] res4a_branch2b_param_0(0.168) 
I0802 06:19:24.977311 18636 net.cpp:2270] res5a_branch2a_param_0(0.17) 
I0802 06:19:24.977324 18636 net.cpp:2270] res5a_branch2b_param_0(0.169) 
I0802 06:19:24.977336 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (398286/2.86678e+06) 0.139
I0802 06:19:25.106381 18661 solver.cpp:450] Finding and applying sparsity: 0.18
I0802 06:19:45.968976 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:19:45.971139 18636 solver.cpp:353] Iteration 37000 (2.86508 iter/s, 34.9031s/100 iter), loss = 1.26192
I0802 06:19:45.971158 18636 solver.cpp:375]     Train net output #0: loss = 1.16363 (* 1 = 1.16363 loss)
I0802 06:19:45.971163 18636 sgd_solver.cpp:136] Iteration 37000, lr = 0.0076875, m = 0.9
I0802 06:20:00.393435 18636 solver.cpp:353] Iteration 37100 (6.9339 iter/s, 14.4219s/100 iter), loss = 1.05397
I0802 06:20:00.393489 18636 solver.cpp:375]     Train net output #0: loss = 0.835889 (* 1 = 0.835889 loss)
I0802 06:20:00.393496 18636 sgd_solver.cpp:136] Iteration 37100, lr = 0.00768125, m = 0.9
I0802 06:20:14.286320 18636 solver.cpp:353] Iteration 37200 (7.19813 iter/s, 13.8925s/100 iter), loss = 1.8707
I0802 06:20:14.286346 18636 solver.cpp:375]     Train net output #0: loss = 1.66551 (* 1 = 1.66551 loss)
I0802 06:20:14.286350 18636 sgd_solver.cpp:136] Iteration 37200, lr = 0.007675, m = 0.9
I0802 06:20:28.226047 18636 solver.cpp:353] Iteration 37300 (7.17394 iter/s, 13.9393s/100 iter), loss = 1.72135
I0802 06:20:28.226070 18636 solver.cpp:375]     Train net output #0: loss = 1.74327 (* 1 = 1.74327 loss)
I0802 06:20:28.226074 18636 sgd_solver.cpp:136] Iteration 37300, lr = 0.00766875, m = 0.9
I0802 06:20:42.150656 18636 solver.cpp:353] Iteration 37400 (7.18173 iter/s, 13.9242s/100 iter), loss = 1.71549
I0802 06:20:42.150756 18636 solver.cpp:375]     Train net output #0: loss = 1.71501 (* 1 = 1.71501 loss)
I0802 06:20:42.150763 18636 sgd_solver.cpp:136] Iteration 37400, lr = 0.0076625, m = 0.9
I0802 06:20:56.064934 18636 solver.cpp:353] Iteration 37500 (7.18706 iter/s, 13.9139s/100 iter), loss = 1.6
I0802 06:20:56.064959 18636 solver.cpp:375]     Train net output #0: loss = 1.995 (* 1 = 1.995 loss)
I0802 06:20:56.064962 18636 sgd_solver.cpp:136] Iteration 37500, lr = 0.00765625, m = 0.9
I0802 06:21:10.059826 18636 solver.cpp:353] Iteration 37600 (7.14566 iter/s, 13.9945s/100 iter), loss = 1.39218
I0802 06:21:10.059876 18636 solver.cpp:375]     Train net output #0: loss = 1.61101 (* 1 = 1.61101 loss)
I0802 06:21:10.059888 18636 sgd_solver.cpp:136] Iteration 37600, lr = 0.00765, m = 0.9
I0802 06:21:23.919587 18636 solver.cpp:353] Iteration 37700 (7.21533 iter/s, 13.8594s/100 iter), loss = 1.57623
I0802 06:21:23.919646 18636 solver.cpp:375]     Train net output #0: loss = 1.2753 (* 1 = 1.2753 loss)
I0802 06:21:23.919651 18636 sgd_solver.cpp:136] Iteration 37700, lr = 0.00764375, m = 0.9
I0802 06:21:37.846767 18636 solver.cpp:353] Iteration 37800 (7.1804 iter/s, 13.9268s/100 iter), loss = 1.60018
I0802 06:21:37.846797 18636 solver.cpp:375]     Train net output #0: loss = 1.40636 (* 1 = 1.40636 loss)
I0802 06:21:37.846803 18636 sgd_solver.cpp:136] Iteration 37800, lr = 0.0076375, m = 0.9
I0802 06:21:51.780758 18636 solver.cpp:353] Iteration 37900 (7.17689 iter/s, 13.9336s/100 iter), loss = 1.53046
I0802 06:21:51.780783 18636 solver.cpp:375]     Train net output #0: loss = 2.12822 (* 1 = 2.12822 loss)
I0802 06:21:51.780787 18636 sgd_solver.cpp:136] Iteration 37900, lr = 0.00763125, m = 0.9
I0802 06:22:05.612592 18636 solver.cpp:404] Sparsity after update:
I0802 06:22:05.616559 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:22:05.616585 18636 net.cpp:2270] conv1a_param_0(0.08) 
I0802 06:22:05.616601 18636 net.cpp:2270] conv1b_param_0(0.0833) 
I0802 06:22:05.616611 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:22:05.616619 18636 net.cpp:2270] res2a_branch2a_param_0(0.177) 
I0802 06:22:05.616628 18636 net.cpp:2270] res2a_branch2b_param_0(0.174) 
I0802 06:22:05.616637 18636 net.cpp:2270] res3a_branch2a_param_0(0.179) 
I0802 06:22:05.616647 18636 net.cpp:2270] res3a_branch2b_param_0(0.177) 
I0802 06:22:05.616654 18636 net.cpp:2270] res4a_branch2a_param_0(0.18) 
I0802 06:22:05.616663 18636 net.cpp:2270] res4a_branch2b_param_0(0.179) 
I0802 06:22:05.616672 18636 net.cpp:2270] res5a_branch2a_param_0(0.18) 
I0802 06:22:05.616683 18636 net.cpp:2270] res5a_branch2b_param_0(0.18) 
I0802 06:22:05.616691 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (422239/2.86678e+06) 0.147
I0802 06:22:05.616708 18636 solver.cpp:550] Iteration 38000, Testing net (#0)
I0802 06:22:25.381539 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.552588
I0802 06:22:25.381563 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.791351
I0802 06:22:25.381570 18636 solver.cpp:635]     Test net output #2: loss = 1.98253 (* 1 = 1.98253 loss)
I0802 06:22:25.381592 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7644s
I0802 06:22:25.518003 18661 solver.cpp:450] Finding and applying sparsity: 0.19
I0802 06:22:46.400144 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:22:46.402097 18636 solver.cpp:353] Iteration 38000 (1.83084 iter/s, 54.6199s/100 iter), loss = 1.69205
I0802 06:22:46.402117 18636 solver.cpp:375]     Train net output #0: loss = 1.79909 (* 1 = 1.79909 loss)
I0802 06:22:46.402122 18636 sgd_solver.cpp:136] Iteration 38000, lr = 0.007625, m = 0.9
I0802 06:23:00.731480 18636 solver.cpp:353] Iteration 38100 (6.97886 iter/s, 14.329s/100 iter), loss = 1.80046
I0802 06:23:00.731506 18636 solver.cpp:375]     Train net output #0: loss = 2.05708 (* 1 = 2.05708 loss)
I0802 06:23:00.731510 18636 sgd_solver.cpp:136] Iteration 38100, lr = 0.00761875, m = 0.9
I0802 06:23:14.658001 18636 solver.cpp:353] Iteration 38200 (7.18074 iter/s, 13.9261s/100 iter), loss = 1.21661
I0802 06:23:14.658028 18636 solver.cpp:375]     Train net output #0: loss = 1.42619 (* 1 = 1.42619 loss)
I0802 06:23:14.658035 18636 sgd_solver.cpp:136] Iteration 38200, lr = 0.0076125, m = 0.9
I0802 06:23:28.583777 18636 solver.cpp:353] Iteration 38300 (7.18112 iter/s, 13.9254s/100 iter), loss = 1.25251
I0802 06:23:28.583835 18636 solver.cpp:375]     Train net output #0: loss = 1.37285 (* 1 = 1.37285 loss)
I0802 06:23:28.583842 18636 sgd_solver.cpp:136] Iteration 38300, lr = 0.00760625, m = 0.9
I0802 06:23:42.530740 18636 solver.cpp:353] Iteration 38400 (7.17022 iter/s, 13.9466s/100 iter), loss = 1.25288
I0802 06:23:42.530771 18636 solver.cpp:375]     Train net output #0: loss = 1.24914 (* 1 = 1.24914 loss)
I0802 06:23:42.530776 18636 sgd_solver.cpp:136] Iteration 38400, lr = 0.0076, m = 0.9
I0802 06:23:56.428102 18636 solver.cpp:353] Iteration 38500 (7.19581 iter/s, 13.897s/100 iter), loss = 1.42903
I0802 06:23:56.428128 18636 solver.cpp:375]     Train net output #0: loss = 1.47603 (* 1 = 1.47603 loss)
I0802 06:23:56.428131 18636 sgd_solver.cpp:136] Iteration 38500, lr = 0.00759375, m = 0.9
I0802 06:24:10.403116 18636 solver.cpp:353] Iteration 38600 (7.15582 iter/s, 13.9746s/100 iter), loss = 1.2294
I0802 06:24:10.403229 18636 solver.cpp:375]     Train net output #0: loss = 1.0918 (* 1 = 1.0918 loss)
I0802 06:24:10.403244 18636 sgd_solver.cpp:136] Iteration 38600, lr = 0.0075875, m = 0.9
I0802 06:24:24.326005 18636 solver.cpp:353] Iteration 38700 (7.18261 iter/s, 13.9225s/100 iter), loss = 1.25299
I0802 06:24:24.326031 18636 solver.cpp:375]     Train net output #0: loss = 1.15782 (* 1 = 1.15782 loss)
I0802 06:24:24.326037 18636 sgd_solver.cpp:136] Iteration 38700, lr = 0.00758125, m = 0.9
I0802 06:24:38.258417 18636 solver.cpp:353] Iteration 38800 (7.1777 iter/s, 13.932s/100 iter), loss = 1.20266
I0802 06:24:38.258519 18636 solver.cpp:375]     Train net output #0: loss = 1.23225 (* 1 = 1.23225 loss)
I0802 06:24:38.258541 18636 sgd_solver.cpp:136] Iteration 38800, lr = 0.007575, m = 0.9
I0802 06:24:52.170344 18636 solver.cpp:353] Iteration 38900 (7.18827 iter/s, 13.9115s/100 iter), loss = 1.60019
I0802 06:24:52.170416 18636 solver.cpp:375]     Train net output #0: loss = 1.53797 (* 1 = 1.53797 loss)
I0802 06:24:52.170423 18636 sgd_solver.cpp:136] Iteration 38900, lr = 0.00756875, m = 0.9
I0802 06:25:05.944622 18636 solver.cpp:404] Sparsity after update:
I0802 06:25:05.955860 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:25:05.955878 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:25:05.955888 18636 net.cpp:2270] conv1b_param_0(0.0903) 
I0802 06:25:05.955891 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:25:05.955894 18636 net.cpp:2270] res2a_branch2a_param_0(0.188) 
I0802 06:25:05.955899 18636 net.cpp:2270] res2a_branch2b_param_0(0.188) 
I0802 06:25:05.955904 18636 net.cpp:2270] res3a_branch2a_param_0(0.189) 
I0802 06:25:05.955907 18636 net.cpp:2270] res3a_branch2b_param_0(0.188) 
I0802 06:25:05.955912 18636 net.cpp:2270] res4a_branch2a_param_0(0.189) 
I0802 06:25:05.955915 18636 net.cpp:2270] res4a_branch2b_param_0(0.189) 
I0802 06:25:05.955920 18636 net.cpp:2270] res5a_branch2a_param_0(0.19) 
I0802 06:25:05.955924 18636 net.cpp:2270] res5a_branch2b_param_0(0.189) 
I0802 06:25:05.955927 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (445521/2.86678e+06) 0.155
I0802 06:25:06.100692 18661 solver.cpp:450] Finding and applying sparsity: 0.2
I0802 06:25:27.137229 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:25:27.139153 18636 solver.cpp:353] Iteration 39000 (2.85977 iter/s, 34.9679s/100 iter), loss = 1.27791
I0802 06:25:27.139178 18636 solver.cpp:375]     Train net output #0: loss = 1.22092 (* 1 = 1.22092 loss)
I0802 06:25:27.139188 18636 sgd_solver.cpp:136] Iteration 39000, lr = 0.0075625, m = 0.9
I0802 06:25:41.602329 18636 solver.cpp:353] Iteration 39100 (6.9143 iter/s, 14.4628s/100 iter), loss = 1.598
I0802 06:25:41.602355 18636 solver.cpp:375]     Train net output #0: loss = 1.65378 (* 1 = 1.65378 loss)
I0802 06:25:41.602360 18636 sgd_solver.cpp:136] Iteration 39100, lr = 0.00755625, m = 0.9
I0802 06:25:55.517410 18636 solver.cpp:353] Iteration 39200 (7.18665 iter/s, 13.9147s/100 iter), loss = 1.31253
I0802 06:25:55.517449 18636 solver.cpp:375]     Train net output #0: loss = 1.27237 (* 1 = 1.27237 loss)
I0802 06:25:55.517457 18636 sgd_solver.cpp:136] Iteration 39200, lr = 0.00755, m = 0.9
I0802 06:26:09.456235 18636 solver.cpp:353] Iteration 39300 (7.1744 iter/s, 13.9385s/100 iter), loss = 1.72936
I0802 06:26:09.456323 18636 solver.cpp:375]     Train net output #0: loss = 1.60916 (* 1 = 1.60916 loss)
I0802 06:26:09.456333 18636 sgd_solver.cpp:136] Iteration 39300, lr = 0.00754375, m = 0.9
I0802 06:26:23.416247 18636 solver.cpp:353] Iteration 39400 (7.16351 iter/s, 13.9596s/100 iter), loss = 1.26201
I0802 06:26:23.416275 18636 solver.cpp:375]     Train net output #0: loss = 1.18686 (* 1 = 1.18686 loss)
I0802 06:26:23.416280 18636 sgd_solver.cpp:136] Iteration 39400, lr = 0.0075375, m = 0.9
I0802 06:26:37.319764 18636 solver.cpp:353] Iteration 39500 (7.19262 iter/s, 13.9031s/100 iter), loss = 1.46721
I0802 06:26:37.319803 18636 solver.cpp:375]     Train net output #0: loss = 1.33026 (* 1 = 1.33026 loss)
I0802 06:26:37.319855 18636 sgd_solver.cpp:136] Iteration 39500, lr = 0.00753125, m = 0.9
I0802 06:26:51.252980 18636 solver.cpp:353] Iteration 39600 (7.17729 iter/s, 13.9328s/100 iter), loss = 1.27651
I0802 06:26:51.253078 18636 solver.cpp:375]     Train net output #0: loss = 1.35573 (* 1 = 1.35573 loss)
I0802 06:26:51.253087 18636 sgd_solver.cpp:136] Iteration 39600, lr = 0.007525, m = 0.9
I0802 06:27:05.245072 18636 solver.cpp:353] Iteration 39700 (7.14709 iter/s, 13.9917s/100 iter), loss = 1.70815
I0802 06:27:05.245102 18636 solver.cpp:375]     Train net output #0: loss = 1.46875 (* 1 = 1.46875 loss)
I0802 06:27:05.245108 18636 sgd_solver.cpp:136] Iteration 39700, lr = 0.00751875, m = 0.9
I0802 06:27:19.091055 18636 solver.cpp:353] Iteration 39800 (7.22251 iter/s, 13.8456s/100 iter), loss = 1.44988
I0802 06:27:19.091116 18636 solver.cpp:375]     Train net output #0: loss = 1.33867 (* 1 = 1.33867 loss)
I0802 06:27:19.091131 18636 sgd_solver.cpp:136] Iteration 39800, lr = 0.0075125, m = 0.9
I0802 06:27:33.081580 18636 solver.cpp:353] Iteration 39900 (7.14789 iter/s, 13.9901s/100 iter), loss = 1.47849
I0802 06:27:33.081645 18636 solver.cpp:375]     Train net output #0: loss = 1.57575 (* 1 = 1.57575 loss)
I0802 06:27:33.081652 18636 sgd_solver.cpp:136] Iteration 39900, lr = 0.00750625, m = 0.9
I0802 06:27:46.918226 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_40000.caffemodel
I0802 06:27:47.127272 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_40000.solverstate
I0802 06:27:47.133810 18636 solver.cpp:404] Sparsity after update:
I0802 06:27:47.135515 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:27:47.135679 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:27:47.135779 18636 net.cpp:2270] conv1b_param_0(0.0972) 
I0802 06:27:47.135867 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:27:47.135954 18636 net.cpp:2270] res2a_branch2a_param_0(0.198) 
I0802 06:27:47.136047 18636 net.cpp:2270] res2a_branch2b_param_0(0.194) 
I0802 06:27:47.136137 18636 net.cpp:2270] res3a_branch2a_param_0(0.2) 
I0802 06:27:47.136236 18636 net.cpp:2270] res3a_branch2b_param_0(0.198) 
I0802 06:27:47.136330 18636 net.cpp:2270] res4a_branch2a_param_0(0.2) 
I0802 06:27:47.136423 18636 net.cpp:2270] res4a_branch2b_param_0(0.2) 
I0802 06:27:47.138080 18636 net.cpp:2270] res5a_branch2a_param_0(0.2) 
I0802 06:27:47.138100 18636 net.cpp:2270] res5a_branch2b_param_0(0.2) 
I0802 06:27:47.138105 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (469468/2.86678e+06) 0.164
I0802 06:27:47.138140 18636 solver.cpp:550] Iteration 40000, Testing net (#0)
I0802 06:28:01.935674 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:28:06.800062 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.560177
I0802 06:28:06.800124 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.796115
I0802 06:28:06.800132 18636 solver.cpp:635]     Test net output #2: loss = 1.9378 (* 1 = 1.9378 loss)
I0802 06:28:06.800149 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6615s
I0802 06:28:06.946436 18661 solver.cpp:450] Finding and applying sparsity: 0.21
I0802 06:28:27.992902 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:28:27.994789 18636 solver.cpp:353] Iteration 40000 (1.8211 iter/s, 54.9117s/100 iter), loss = 1.63003
I0802 06:28:27.994812 18636 solver.cpp:375]     Train net output #0: loss = 1.55091 (* 1 = 1.55091 loss)
I0802 06:28:27.994820 18636 sgd_solver.cpp:136] Iteration 40000, lr = 0.0075, m = 0.9
I0802 06:28:42.409591 18636 solver.cpp:353] Iteration 40100 (6.9375 iter/s, 14.4144s/100 iter), loss = 1.71002
I0802 06:28:42.409649 18636 solver.cpp:375]     Train net output #0: loss = 1.50388 (* 1 = 1.50388 loss)
I0802 06:28:42.409656 18636 sgd_solver.cpp:136] Iteration 40100, lr = 0.00749375, m = 0.9
I0802 06:28:56.414604 18636 solver.cpp:353] Iteration 40200 (7.1405 iter/s, 14.0046s/100 iter), loss = 1.20617
I0802 06:28:56.414630 18636 solver.cpp:375]     Train net output #0: loss = 1.23194 (* 1 = 1.23194 loss)
I0802 06:28:56.414636 18636 sgd_solver.cpp:136] Iteration 40200, lr = 0.0074875, m = 0.9
I0802 06:29:10.462944 18636 solver.cpp:353] Iteration 40300 (7.11847 iter/s, 14.048s/100 iter), loss = 1.54082
I0802 06:29:10.462975 18636 solver.cpp:375]     Train net output #0: loss = 1.53425 (* 1 = 1.53425 loss)
I0802 06:29:10.462980 18636 sgd_solver.cpp:136] Iteration 40300, lr = 0.00748125, m = 0.9
I0802 06:29:24.406249 18636 solver.cpp:353] Iteration 40400 (7.1721 iter/s, 13.9429s/100 iter), loss = 1.21038
I0802 06:29:24.406561 18636 solver.cpp:375]     Train net output #0: loss = 1.28717 (* 1 = 1.28717 loss)
I0802 06:29:24.406568 18636 sgd_solver.cpp:136] Iteration 40400, lr = 0.007475, m = 0.9
I0802 06:29:38.334887 18636 solver.cpp:353] Iteration 40500 (7.17965 iter/s, 13.9283s/100 iter), loss = 1.48942
I0802 06:29:38.334914 18636 solver.cpp:375]     Train net output #0: loss = 1.36205 (* 1 = 1.36205 loss)
I0802 06:29:38.334921 18636 sgd_solver.cpp:136] Iteration 40500, lr = 0.00746875, m = 0.9
I0802 06:29:52.353590 18636 solver.cpp:353] Iteration 40600 (7.13352 iter/s, 14.0183s/100 iter), loss = 1.59644
I0802 06:29:52.353689 18636 solver.cpp:375]     Train net output #0: loss = 1.60522 (* 1 = 1.60522 loss)
I0802 06:29:52.353710 18636 sgd_solver.cpp:136] Iteration 40600, lr = 0.0074625, m = 0.9
I0802 06:30:06.332756 18636 solver.cpp:353] Iteration 40700 (7.1537 iter/s, 13.9788s/100 iter), loss = 0.950537
I0802 06:30:06.332834 18636 solver.cpp:375]     Train net output #0: loss = 0.931537 (* 1 = 0.931537 loss)
I0802 06:30:06.332852 18636 sgd_solver.cpp:136] Iteration 40700, lr = 0.00745625, m = 0.9
I0802 06:30:20.253262 18636 solver.cpp:353] Iteration 40800 (7.18384 iter/s, 13.9201s/100 iter), loss = 1.60472
I0802 06:30:20.253288 18636 solver.cpp:375]     Train net output #0: loss = 1.59545 (* 1 = 1.59545 loss)
I0802 06:30:20.253293 18636 sgd_solver.cpp:136] Iteration 40800, lr = 0.00745, m = 0.9
I0802 06:30:34.194393 18636 solver.cpp:353] Iteration 40900 (7.17321 iter/s, 13.9408s/100 iter), loss = 1.31298
I0802 06:30:34.194422 18636 solver.cpp:375]     Train net output #0: loss = 1.23913 (* 1 = 1.23913 loss)
I0802 06:30:34.194425 18636 sgd_solver.cpp:136] Iteration 40900, lr = 0.00744375, m = 0.9
I0802 06:30:47.880269 18636 solver.cpp:404] Sparsity after update:
I0802 06:30:47.890738 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:30:47.890750 18636 net.cpp:2270] conv1a_param_0(0.0933) 
I0802 06:30:47.890758 18636 net.cpp:2270] conv1b_param_0(0.104) 
I0802 06:30:47.890759 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:30:47.890761 18636 net.cpp:2270] res2a_branch2a_param_0(0.208) 
I0802 06:30:47.890763 18636 net.cpp:2270] res2a_branch2b_param_0(0.208) 
I0802 06:30:47.890765 18636 net.cpp:2270] res3a_branch2a_param_0(0.208) 
I0802 06:30:47.890768 18636 net.cpp:2270] res3a_branch2b_param_0(0.208) 
I0802 06:30:47.890769 18636 net.cpp:2270] res4a_branch2a_param_0(0.209) 
I0802 06:30:47.890771 18636 net.cpp:2270] res4a_branch2b_param_0(0.208) 
I0802 06:30:47.890774 18636 net.cpp:2270] res5a_branch2a_param_0(0.21) 
I0802 06:30:47.890777 18636 net.cpp:2270] res5a_branch2b_param_0(0.209) 
I0802 06:30:47.890781 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (492322/2.86678e+06) 0.172
I0802 06:30:48.029168 18661 solver.cpp:450] Finding and applying sparsity: 0.22
I0802 06:31:09.523921 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:31:09.525807 18636 solver.cpp:353] Iteration 41000 (2.83042 iter/s, 35.3305s/100 iter), loss = 0.992093
I0802 06:31:09.525825 18636 solver.cpp:375]     Train net output #0: loss = 1.14669 (* 1 = 1.14669 loss)
I0802 06:31:09.525830 18636 sgd_solver.cpp:136] Iteration 41000, lr = 0.0074375, m = 0.9
I0802 06:31:23.853233 18636 solver.cpp:353] Iteration 41100 (6.97981 iter/s, 14.327s/100 iter), loss = 1.90873
I0802 06:31:23.853332 18636 solver.cpp:375]     Train net output #0: loss = 1.75004 (* 1 = 1.75004 loss)
I0802 06:31:23.853348 18636 sgd_solver.cpp:136] Iteration 41100, lr = 0.00743125, m = 0.9
I0802 06:31:37.727987 18636 solver.cpp:353] Iteration 41200 (7.20753 iter/s, 13.8744s/100 iter), loss = 1.67371
I0802 06:31:37.728016 18636 solver.cpp:375]     Train net output #0: loss = 1.46641 (* 1 = 1.46641 loss)
I0802 06:31:37.728022 18636 sgd_solver.cpp:136] Iteration 41200, lr = 0.007425, m = 0.9
I0802 06:31:51.609165 18636 solver.cpp:353] Iteration 41300 (7.2042 iter/s, 13.8808s/100 iter), loss = 1.23522
I0802 06:31:51.609192 18636 solver.cpp:375]     Train net output #0: loss = 1.421 (* 1 = 1.421 loss)
I0802 06:31:51.609196 18636 sgd_solver.cpp:136] Iteration 41300, lr = 0.00741875, m = 0.9
I0802 06:32:05.446794 18636 solver.cpp:353] Iteration 41400 (7.22687 iter/s, 13.8373s/100 iter), loss = 1.44284
I0802 06:32:05.446856 18636 solver.cpp:375]     Train net output #0: loss = 1.37251 (* 1 = 1.37251 loss)
I0802 06:32:05.446863 18636 sgd_solver.cpp:136] Iteration 41400, lr = 0.0074125, m = 0.9
I0802 06:32:19.324635 18636 solver.cpp:353] Iteration 41500 (7.20593 iter/s, 13.8775s/100 iter), loss = 1.39509
I0802 06:32:19.324662 18636 solver.cpp:375]     Train net output #0: loss = 1.34528 (* 1 = 1.34528 loss)
I0802 06:32:19.324707 18636 sgd_solver.cpp:136] Iteration 41500, lr = 0.00740625, m = 0.9
I0802 06:32:33.161878 18636 solver.cpp:353] Iteration 41600 (7.22707 iter/s, 13.8369s/100 iter), loss = 1.61164
I0802 06:32:33.161908 18636 solver.cpp:375]     Train net output #0: loss = 1.16941 (* 1 = 1.16941 loss)
I0802 06:32:33.161914 18636 sgd_solver.cpp:136] Iteration 41600, lr = 0.0074, m = 0.9
I0802 06:32:47.023342 18636 solver.cpp:353] Iteration 41700 (7.21444 iter/s, 13.8611s/100 iter), loss = 1.30632
I0802 06:32:47.023402 18636 solver.cpp:375]     Train net output #0: loss = 1.3031 (* 1 = 1.3031 loss)
I0802 06:32:47.023408 18636 sgd_solver.cpp:136] Iteration 41700, lr = 0.00739375, m = 0.9
I0802 06:33:00.822670 18636 solver.cpp:353] Iteration 41800 (7.24693 iter/s, 13.799s/100 iter), loss = 1.58325
I0802 06:33:00.822700 18636 solver.cpp:375]     Train net output #0: loss = 1.396 (* 1 = 1.396 loss)
I0802 06:33:00.822705 18636 sgd_solver.cpp:136] Iteration 41800, lr = 0.0073875, m = 0.9
I0802 06:33:14.724967 18636 solver.cpp:353] Iteration 41900 (7.19325 iter/s, 13.9019s/100 iter), loss = 1.78261
I0802 06:33:14.724993 18636 solver.cpp:375]     Train net output #0: loss = 2.19002 (* 1 = 2.19002 loss)
I0802 06:33:14.724999 18636 sgd_solver.cpp:136] Iteration 41900, lr = 0.00738125, m = 0.9
I0802 06:33:28.467797 18636 solver.cpp:404] Sparsity after update:
I0802 06:33:28.473062 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:33:28.473076 18636 net.cpp:2270] conv1a_param_0(0.106) 
I0802 06:33:28.473085 18636 net.cpp:2270] conv1b_param_0(0.104) 
I0802 06:33:28.473088 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:33:28.473093 18636 net.cpp:2270] res2a_branch2a_param_0(0.219) 
I0802 06:33:28.473101 18636 net.cpp:2270] res2a_branch2b_param_0(0.215) 
I0802 06:33:28.473104 18636 net.cpp:2270] res3a_branch2a_param_0(0.219) 
I0802 06:33:28.473109 18636 net.cpp:2270] res3a_branch2b_param_0(0.219) 
I0802 06:33:28.473112 18636 net.cpp:2270] res4a_branch2a_param_0(0.22) 
I0802 06:33:28.473116 18636 net.cpp:2270] res4a_branch2b_param_0(0.219) 
I0802 06:33:28.473120 18636 net.cpp:2270] res5a_branch2a_param_0(0.22) 
I0802 06:33:28.473124 18636 net.cpp:2270] res5a_branch2b_param_0(0.22) 
I0802 06:33:28.473129 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (516297/2.86678e+06) 0.18
I0802 06:33:28.473140 18636 solver.cpp:550] Iteration 42000, Testing net (#0)
I0802 06:33:47.721364 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.565941
I0802 06:33:47.721385 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.796527
I0802 06:33:47.721390 18636 solver.cpp:635]     Test net output #2: loss = 1.9225 (* 1 = 1.9225 loss)
I0802 06:33:47.721451 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2478s
I0802 06:33:47.859217 18661 solver.cpp:450] Finding and applying sparsity: 0.23
I0802 06:34:09.007230 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:34:09.009160 18636 solver.cpp:353] Iteration 42000 (1.84221 iter/s, 54.2827s/100 iter), loss = 1.28439
I0802 06:34:09.009179 18636 solver.cpp:375]     Train net output #0: loss = 1.18323 (* 1 = 1.18323 loss)
I0802 06:34:09.009186 18636 sgd_solver.cpp:136] Iteration 42000, lr = 0.007375, m = 0.9
I0802 06:34:23.432950 18636 solver.cpp:353] Iteration 42100 (6.93318 iter/s, 14.4234s/100 iter), loss = 1.25685
I0802 06:34:23.432982 18636 solver.cpp:375]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0802 06:34:23.432988 18636 sgd_solver.cpp:136] Iteration 42100, lr = 0.00736875, m = 0.9
I0802 06:34:37.325703 18636 solver.cpp:353] Iteration 42200 (7.19819 iter/s, 13.8924s/100 iter), loss = 1.86303
I0802 06:34:37.325757 18636 solver.cpp:375]     Train net output #0: loss = 1.73459 (* 1 = 1.73459 loss)
I0802 06:34:37.325770 18636 sgd_solver.cpp:136] Iteration 42200, lr = 0.0073625, m = 0.9
I0802 06:34:51.245548 18636 solver.cpp:353] Iteration 42300 (7.18418 iter/s, 13.9195s/100 iter), loss = 1.18419
I0802 06:34:51.245607 18636 solver.cpp:375]     Train net output #0: loss = 1.33185 (* 1 = 1.33185 loss)
I0802 06:34:51.245611 18636 sgd_solver.cpp:136] Iteration 42300, lr = 0.00735625, m = 0.9
I0802 06:35:05.206889 18636 solver.cpp:353] Iteration 42400 (7.16283 iter/s, 13.961s/100 iter), loss = 1.68184
I0802 06:35:05.206918 18636 solver.cpp:375]     Train net output #0: loss = 1.59306 (* 1 = 1.59306 loss)
I0802 06:35:05.206923 18636 sgd_solver.cpp:136] Iteration 42400, lr = 0.00735, m = 0.9
I0802 06:35:19.135705 18636 solver.cpp:353] Iteration 42500 (7.17956 iter/s, 13.9284s/100 iter), loss = 1.17915
I0802 06:35:19.135735 18636 solver.cpp:375]     Train net output #0: loss = 0.95866 (* 1 = 0.95866 loss)
I0802 06:35:19.135740 18636 sgd_solver.cpp:136] Iteration 42500, lr = 0.00734375, m = 0.9
I0802 06:35:33.048720 18636 solver.cpp:353] Iteration 42600 (7.18771 iter/s, 13.9126s/100 iter), loss = 1.30587
I0802 06:35:33.048775 18636 solver.cpp:375]     Train net output #0: loss = 1.0482 (* 1 = 1.0482 loss)
I0802 06:35:33.048779 18636 sgd_solver.cpp:136] Iteration 42600, lr = 0.0073375, m = 0.9
I0802 06:35:47.022706 18636 solver.cpp:353] Iteration 42700 (7.15635 iter/s, 13.9736s/100 iter), loss = 1.58489
I0802 06:35:47.022732 18636 solver.cpp:375]     Train net output #0: loss = 1.62362 (* 1 = 1.62362 loss)
I0802 06:35:47.022737 18636 sgd_solver.cpp:136] Iteration 42700, lr = 0.00733125, m = 0.9
I0802 06:36:00.987190 18636 solver.cpp:353] Iteration 42800 (7.16122 iter/s, 13.9641s/100 iter), loss = 1.27826
I0802 06:36:00.987224 18636 solver.cpp:375]     Train net output #0: loss = 0.845746 (* 1 = 0.845746 loss)
I0802 06:36:00.987232 18636 sgd_solver.cpp:136] Iteration 42800, lr = 0.007325, m = 0.9
I0802 06:36:14.955454 18636 solver.cpp:353] Iteration 42900 (7.15928 iter/s, 13.9679s/100 iter), loss = 1.25878
I0802 06:36:14.955525 18636 solver.cpp:375]     Train net output #0: loss = 1.3283 (* 1 = 1.3283 loss)
I0802 06:36:14.955531 18636 sgd_solver.cpp:136] Iteration 42900, lr = 0.00731875, m = 0.9
I0802 06:36:28.790963 18636 solver.cpp:404] Sparsity after update:
I0802 06:36:28.802691 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:36:28.802703 18636 net.cpp:2270] conv1a_param_0(0.107) 
I0802 06:36:28.802711 18636 net.cpp:2270] conv1b_param_0(0.111) 
I0802 06:36:28.802713 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:36:28.802716 18636 net.cpp:2270] res2a_branch2a_param_0(0.229) 
I0802 06:36:28.802717 18636 net.cpp:2270] res2a_branch2b_param_0(0.229) 
I0802 06:36:28.802721 18636 net.cpp:2270] res3a_branch2a_param_0(0.229) 
I0802 06:36:28.802723 18636 net.cpp:2270] res3a_branch2b_param_0(0.229) 
I0802 06:36:28.802726 18636 net.cpp:2270] res4a_branch2a_param_0(0.229) 
I0802 06:36:28.802727 18636 net.cpp:2270] res4a_branch2b_param_0(0.229) 
I0802 06:36:28.802729 18636 net.cpp:2270] res5a_branch2a_param_0(0.23) 
I0802 06:36:28.802731 18636 net.cpp:2270] res5a_branch2b_param_0(0.229) 
I0802 06:36:28.802732 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (539552/2.86678e+06) 0.188
I0802 06:36:28.934412 18661 solver.cpp:450] Finding and applying sparsity: 0.24
I0802 06:36:50.518585 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:36:50.520534 18636 solver.cpp:353] Iteration 43000 (2.81182 iter/s, 35.5641s/100 iter), loss = 1.27689
I0802 06:36:50.520552 18636 solver.cpp:375]     Train net output #0: loss = 1.21047 (* 1 = 1.21047 loss)
I0802 06:36:50.520558 18636 sgd_solver.cpp:136] Iteration 43000, lr = 0.0073125, m = 0.9
I0802 06:37:04.926537 18636 solver.cpp:353] Iteration 43100 (6.94174 iter/s, 14.4056s/100 iter), loss = 1.03635
I0802 06:37:04.926636 18636 solver.cpp:375]     Train net output #0: loss = 1.204 (* 1 = 1.204 loss)
I0802 06:37:04.926661 18636 sgd_solver.cpp:136] Iteration 43100, lr = 0.00730625, m = 0.9
I0802 06:37:18.842052 18636 solver.cpp:353] Iteration 43200 (7.18642 iter/s, 13.9151s/100 iter), loss = 1.30922
I0802 06:37:18.842082 18636 solver.cpp:375]     Train net output #0: loss = 1.61254 (* 1 = 1.61254 loss)
I0802 06:37:18.842089 18636 sgd_solver.cpp:136] Iteration 43200, lr = 0.0073, m = 0.9
I0802 06:37:32.891185 18636 solver.cpp:353] Iteration 43300 (7.11807 iter/s, 14.0487s/100 iter), loss = 1.26509
I0802 06:37:32.891279 18636 solver.cpp:375]     Train net output #0: loss = 1.55621 (* 1 = 1.55621 loss)
I0802 06:37:32.891289 18636 sgd_solver.cpp:136] Iteration 43300, lr = 0.00729375, m = 0.9
I0802 06:37:46.772514 18636 solver.cpp:353] Iteration 43400 (7.20412 iter/s, 13.881s/100 iter), loss = 1.48852
I0802 06:37:46.772541 18636 solver.cpp:375]     Train net output #0: loss = 1.80188 (* 1 = 1.80188 loss)
I0802 06:37:46.772545 18636 sgd_solver.cpp:136] Iteration 43400, lr = 0.0072875, m = 0.9
I0802 06:38:00.719149 18636 solver.cpp:353] Iteration 43500 (7.17038 iter/s, 13.9463s/100 iter), loss = 1.30827
I0802 06:38:00.719179 18636 solver.cpp:375]     Train net output #0: loss = 1.36527 (* 1 = 1.36527 loss)
I0802 06:38:00.719185 18636 sgd_solver.cpp:136] Iteration 43500, lr = 0.00728125, m = 0.9
I0802 06:38:14.709920 18636 solver.cpp:353] Iteration 43600 (7.14776 iter/s, 13.9904s/100 iter), loss = 1.39245
I0802 06:38:14.712865 18636 solver.cpp:375]     Train net output #0: loss = 1.04971 (* 1 = 1.04971 loss)
I0802 06:38:14.712872 18636 sgd_solver.cpp:136] Iteration 43600, lr = 0.007275, m = 0.9
I0802 06:38:28.583206 18636 solver.cpp:353] Iteration 43700 (7.20829 iter/s, 13.8729s/100 iter), loss = 1.76581
I0802 06:38:28.583313 18636 solver.cpp:375]     Train net output #0: loss = 1.33426 (* 1 = 1.33426 loss)
I0802 06:38:28.583336 18636 sgd_solver.cpp:136] Iteration 43700, lr = 0.00726875, m = 0.9
I0802 06:38:42.498215 18636 solver.cpp:353] Iteration 43800 (7.18668 iter/s, 13.9146s/100 iter), loss = 1.59617
I0802 06:38:42.498288 18636 solver.cpp:375]     Train net output #0: loss = 1.95819 (* 1 = 1.95819 loss)
I0802 06:38:42.498308 18636 sgd_solver.cpp:136] Iteration 43800, lr = 0.0072625, m = 0.9
I0802 06:38:56.374387 18636 solver.cpp:353] Iteration 43900 (7.20679 iter/s, 13.8758s/100 iter), loss = 1.79397
I0802 06:38:56.374526 18636 solver.cpp:375]     Train net output #0: loss = 2.18008 (* 1 = 2.18008 loss)
I0802 06:38:56.374550 18636 sgd_solver.cpp:136] Iteration 43900, lr = 0.00725625, m = 0.9
I0802 06:39:10.116588 18636 solver.cpp:404] Sparsity after update:
I0802 06:39:10.121076 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:39:10.121088 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:39:10.121096 18636 net.cpp:2270] conv1b_param_0(0.118) 
I0802 06:39:10.121100 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:39:10.121105 18636 net.cpp:2270] res2a_branch2a_param_0(0.24) 
I0802 06:39:10.121109 18636 net.cpp:2270] res2a_branch2b_param_0(0.236) 
I0802 06:39:10.121112 18636 net.cpp:2270] res3a_branch2a_param_0(0.24) 
I0802 06:39:10.121115 18636 net.cpp:2270] res3a_branch2b_param_0(0.24) 
I0802 06:39:10.121117 18636 net.cpp:2270] res4a_branch2a_param_0(0.24) 
I0802 06:39:10.121120 18636 net.cpp:2270] res4a_branch2b_param_0(0.24) 
I0802 06:39:10.121124 18636 net.cpp:2270] res5a_branch2a_param_0(0.24) 
I0802 06:39:10.121126 18636 net.cpp:2270] res5a_branch2b_param_0(0.24) 
I0802 06:39:10.121130 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (563527/2.86678e+06) 0.197
I0802 06:39:10.121142 18636 solver.cpp:550] Iteration 44000, Testing net (#0)
I0802 06:39:29.524693 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.562294
I0802 06:39:29.524827 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.79788
I0802 06:39:29.524837 18636 solver.cpp:635]     Test net output #2: loss = 1.94508 (* 1 = 1.94508 loss)
I0802 06:39:29.524859 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4032s
I0802 06:39:29.682147 18661 solver.cpp:450] Finding and applying sparsity: 0.25
I0802 06:39:51.588835 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:39:51.590732 18636 solver.cpp:353] Iteration 44000 (1.81111 iter/s, 55.2149s/100 iter), loss = 1.46358
I0802 06:39:51.590750 18636 solver.cpp:375]     Train net output #0: loss = 1.61415 (* 1 = 1.61415 loss)
I0802 06:39:51.590755 18636 sgd_solver.cpp:136] Iteration 44000, lr = 0.00725, m = 0.9
I0802 06:40:05.990845 18636 solver.cpp:353] Iteration 44100 (6.94458 iter/s, 14.3997s/100 iter), loss = 1.216
I0802 06:40:05.990943 18636 solver.cpp:375]     Train net output #0: loss = 1.39276 (* 1 = 1.39276 loss)
I0802 06:40:05.990963 18636 sgd_solver.cpp:136] Iteration 44100, lr = 0.00724375, m = 0.9
I0802 06:40:19.838136 18636 solver.cpp:353] Iteration 44200 (7.22183 iter/s, 13.8469s/100 iter), loss = 1.01748
I0802 06:40:19.838167 18636 solver.cpp:375]     Train net output #0: loss = 1.11225 (* 1 = 1.11225 loss)
I0802 06:40:19.838173 18636 sgd_solver.cpp:136] Iteration 44200, lr = 0.0072375, m = 0.9
I0802 06:40:33.803078 18636 solver.cpp:353] Iteration 44300 (7.16098 iter/s, 13.9646s/100 iter), loss = 1.66549
I0802 06:40:33.803133 18636 solver.cpp:375]     Train net output #0: loss = 1.2116 (* 1 = 1.2116 loss)
I0802 06:40:33.803145 18636 sgd_solver.cpp:136] Iteration 44300, lr = 0.00723125, m = 0.9
I0802 06:40:47.661633 18636 solver.cpp:353] Iteration 44400 (7.21596 iter/s, 13.8582s/100 iter), loss = 1.56242
I0802 06:40:47.661742 18636 solver.cpp:375]     Train net output #0: loss = 1.87705 (* 1 = 1.87705 loss)
I0802 06:40:47.661749 18636 sgd_solver.cpp:136] Iteration 44400, lr = 0.007225, m = 0.9
I0802 06:41:01.575479 18636 solver.cpp:353] Iteration 44500 (7.18728 iter/s, 13.9135s/100 iter), loss = 1.39829
I0802 06:41:01.575574 18636 solver.cpp:375]     Train net output #0: loss = 1.17315 (* 1 = 1.17315 loss)
I0802 06:41:01.575587 18636 sgd_solver.cpp:136] Iteration 44500, lr = 0.00721875, m = 0.9
I0802 06:41:15.508016 18636 solver.cpp:353] Iteration 44600 (7.17764 iter/s, 13.9322s/100 iter), loss = 1.68973
I0802 06:41:15.508070 18636 solver.cpp:375]     Train net output #0: loss = 1.40314 (* 1 = 1.40314 loss)
I0802 06:41:15.508085 18636 sgd_solver.cpp:136] Iteration 44600, lr = 0.0072125, m = 0.9
I0802 06:41:27.982205 18597 data_reader.cpp:264] Starting prefetch of epoch 1
I0802 06:41:29.393496 18636 solver.cpp:353] Iteration 44700 (7.20196 iter/s, 13.8851s/100 iter), loss = 1.36495
I0802 06:41:29.393543 18636 solver.cpp:375]     Train net output #0: loss = 1.57697 (* 1 = 1.57697 loss)
I0802 06:41:29.393554 18636 sgd_solver.cpp:136] Iteration 44700, lr = 0.00720625, m = 0.9
I0802 06:41:43.324690 18636 solver.cpp:353] Iteration 44800 (7.17833 iter/s, 13.9308s/100 iter), loss = 1.53605
I0802 06:41:43.324717 18636 solver.cpp:375]     Train net output #0: loss = 1.87628 (* 1 = 1.87628 loss)
I0802 06:41:43.324723 18636 sgd_solver.cpp:136] Iteration 44800, lr = 0.0072, m = 0.9
I0802 06:41:57.215554 18636 solver.cpp:353] Iteration 44900 (7.19917 iter/s, 13.8905s/100 iter), loss = 1.27778
I0802 06:41:57.215580 18636 solver.cpp:375]     Train net output #0: loss = 1.67304 (* 1 = 1.67304 loss)
I0802 06:41:57.215584 18636 sgd_solver.cpp:136] Iteration 44900, lr = 0.00719375, m = 0.9
I0802 06:42:11.048933 18636 solver.cpp:404] Sparsity after update:
I0802 06:42:11.061384 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:42:11.061400 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:42:11.061410 18636 net.cpp:2270] conv1b_param_0(0.25) 
I0802 06:42:11.061414 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:42:11.061431 18636 net.cpp:2270] res2a_branch2a_param_0(0.25) 
I0802 06:42:11.061440 18636 net.cpp:2270] res2a_branch2b_param_0(0.25) 
I0802 06:42:11.061449 18636 net.cpp:2270] res3a_branch2a_param_0(0.25) 
I0802 06:42:11.061461 18636 net.cpp:2270] res3a_branch2b_param_0(0.25) 
I0802 06:42:11.061470 18636 net.cpp:2270] res4a_branch2a_param_0(0.25) 
I0802 06:42:11.061488 18636 net.cpp:2270] res4a_branch2b_param_0(0.25) 
I0802 06:42:11.061501 18636 net.cpp:2270] res5a_branch2a_param_0(0.25) 
I0802 06:42:11.061514 18636 net.cpp:2270] res5a_branch2b_param_0(0.25) 
I0802 06:42:11.061527 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (588349/2.86678e+06) 0.205
I0802 06:42:11.202025 18661 solver.cpp:450] Finding and applying sparsity: 0.26
I0802 06:42:32.753993 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:42:32.755877 18636 solver.cpp:353] Iteration 45000 (2.81378 iter/s, 35.5394s/100 iter), loss = 1.62799
I0802 06:42:32.755893 18636 solver.cpp:375]     Train net output #0: loss = 1.92437 (* 1 = 1.92437 loss)
I0802 06:42:32.755899 18636 sgd_solver.cpp:136] Iteration 45000, lr = 0.0071875, m = 0.9
I0802 06:42:47.250612 18636 solver.cpp:353] Iteration 45100 (6.89925 iter/s, 14.4943s/100 iter), loss = 1.63918
I0802 06:42:47.250674 18636 solver.cpp:375]     Train net output #0: loss = 1.90115 (* 1 = 1.90115 loss)
I0802 06:42:47.250680 18636 sgd_solver.cpp:136] Iteration 45100, lr = 0.00718125, m = 0.9
I0802 06:43:01.227965 18636 solver.cpp:353] Iteration 45200 (7.15463 iter/s, 13.977s/100 iter), loss = 1.42448
I0802 06:43:01.227993 18636 solver.cpp:375]     Train net output #0: loss = 1.12796 (* 1 = 1.12796 loss)
I0802 06:43:01.227999 18636 sgd_solver.cpp:136] Iteration 45200, lr = 0.007175, m = 0.9
I0802 06:43:15.182236 18636 solver.cpp:353] Iteration 45300 (7.16646 iter/s, 13.9539s/100 iter), loss = 1.50197
I0802 06:43:15.182265 18636 solver.cpp:375]     Train net output #0: loss = 1.30693 (* 1 = 1.30693 loss)
I0802 06:43:15.182270 18636 sgd_solver.cpp:136] Iteration 45300, lr = 0.00716875, m = 0.9
I0802 06:43:29.112654 18636 solver.cpp:353] Iteration 45400 (7.17873 iter/s, 13.93s/100 iter), loss = 1.307
I0802 06:43:29.112725 18636 solver.cpp:375]     Train net output #0: loss = 1.18026 (* 1 = 1.18026 loss)
I0802 06:43:29.112731 18636 sgd_solver.cpp:136] Iteration 45400, lr = 0.0071625, m = 0.9
I0802 06:43:42.985051 18636 solver.cpp:353] Iteration 45500 (7.20875 iter/s, 13.872s/100 iter), loss = 1.59157
I0802 06:43:42.985077 18636 solver.cpp:375]     Train net output #0: loss = 1.86329 (* 1 = 1.86329 loss)
I0802 06:43:42.985083 18636 sgd_solver.cpp:136] Iteration 45500, lr = 0.00715625, m = 0.9
I0802 06:43:57.002856 18636 solver.cpp:353] Iteration 45600 (7.13398 iter/s, 14.0174s/100 iter), loss = 1.24251
I0802 06:43:57.002882 18636 solver.cpp:375]     Train net output #0: loss = 1.19333 (* 1 = 1.19333 loss)
I0802 06:43:57.002885 18636 sgd_solver.cpp:136] Iteration 45600, lr = 0.00715, m = 0.9
I0802 06:44:10.969877 18636 solver.cpp:353] Iteration 45700 (7.15992 iter/s, 13.9666s/100 iter), loss = 1.3431
I0802 06:44:10.969983 18636 solver.cpp:375]     Train net output #0: loss = 1.52618 (* 1 = 1.52618 loss)
I0802 06:44:10.969990 18636 sgd_solver.cpp:136] Iteration 45700, lr = 0.00714375, m = 0.9
I0802 06:44:24.932498 18636 solver.cpp:353] Iteration 45800 (7.16217 iter/s, 13.9622s/100 iter), loss = 1.56623
I0802 06:44:24.932523 18636 solver.cpp:375]     Train net output #0: loss = 1.69944 (* 1 = 1.69944 loss)
I0802 06:44:24.932526 18636 sgd_solver.cpp:136] Iteration 45800, lr = 0.0071375, m = 0.9
I0802 06:44:38.879467 18636 solver.cpp:353] Iteration 45900 (7.17021 iter/s, 13.9466s/100 iter), loss = 1.10833
I0802 06:44:38.879492 18636 solver.cpp:375]     Train net output #0: loss = 1.12398 (* 1 = 1.12398 loss)
I0802 06:44:38.879497 18636 sgd_solver.cpp:136] Iteration 45900, lr = 0.00713125, m = 0.9
I0802 06:44:52.707373 18636 solver.cpp:404] Sparsity after update:
I0802 06:44:52.711374 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:44:52.711385 18636 net.cpp:2270] conv1a_param_0(0.12) 
I0802 06:44:52.711393 18636 net.cpp:2270] conv1b_param_0(0.25) 
I0802 06:44:52.711397 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:44:52.711402 18636 net.cpp:2270] res2a_branch2a_param_0(0.257) 
I0802 06:44:52.711405 18636 net.cpp:2270] res2a_branch2b_param_0(0.257) 
I0802 06:44:52.711408 18636 net.cpp:2270] res3a_branch2a_param_0(0.259) 
I0802 06:44:52.711411 18636 net.cpp:2270] res3a_branch2b_param_0(0.257) 
I0802 06:44:52.711414 18636 net.cpp:2270] res4a_branch2a_param_0(0.26) 
I0802 06:44:52.711418 18636 net.cpp:2270] res4a_branch2b_param_0(0.259) 
I0802 06:44:52.711422 18636 net.cpp:2270] res5a_branch2a_param_0(0.26) 
I0802 06:44:52.711426 18636 net.cpp:2270] res5a_branch2b_param_0(0.26) 
I0802 06:44:52.711431 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (610947/2.86678e+06) 0.213
I0802 06:44:52.711444 18636 solver.cpp:550] Iteration 46000, Testing net (#0)
I0802 06:45:12.764072 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.563647
I0802 06:45:12.764096 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.799057
I0802 06:45:12.764103 18636 solver.cpp:635]     Test net output #2: loss = 1.96481 (* 1 = 1.96481 loss)
I0802 06:45:12.764127 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0521s
I0802 06:45:12.912250 18661 solver.cpp:450] Finding and applying sparsity: 0.27
I0802 06:45:35.201942 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:45:35.203936 18636 solver.cpp:353] Iteration 46000 (1.77548 iter/s, 56.323s/100 iter), loss = 1.85064
I0802 06:45:35.203955 18636 solver.cpp:375]     Train net output #0: loss = 1.80574 (* 1 = 1.80574 loss)
I0802 06:45:35.203960 18636 sgd_solver.cpp:136] Iteration 46000, lr = 0.007125, m = 0.9
I0802 06:45:49.589026 18636 solver.cpp:353] Iteration 46100 (6.95184 iter/s, 14.3847s/100 iter), loss = 1.48732
I0802 06:45:49.589056 18636 solver.cpp:375]     Train net output #0: loss = 1.59209 (* 1 = 1.59209 loss)
I0802 06:45:49.589064 18636 sgd_solver.cpp:136] Iteration 46100, lr = 0.00711875, m = 0.9
I0802 06:46:03.439882 18636 solver.cpp:353] Iteration 46200 (7.21997 iter/s, 13.8505s/100 iter), loss = 1.02752
I0802 06:46:03.439913 18636 solver.cpp:375]     Train net output #0: loss = 0.630138 (* 1 = 0.630138 loss)
I0802 06:46:03.439918 18636 sgd_solver.cpp:136] Iteration 46200, lr = 0.0071125, m = 0.9
I0802 06:46:17.480677 18636 solver.cpp:353] Iteration 46300 (7.1223 iter/s, 14.0404s/100 iter), loss = 1.34733
I0802 06:46:17.480756 18636 solver.cpp:375]     Train net output #0: loss = 1.45305 (* 1 = 1.45305 loss)
I0802 06:46:17.480792 18636 sgd_solver.cpp:136] Iteration 46300, lr = 0.00710625, m = 0.9
I0802 06:46:31.429672 18636 solver.cpp:353] Iteration 46400 (7.16917 iter/s, 13.9486s/100 iter), loss = 1.44085
I0802 06:46:31.429733 18636 solver.cpp:375]     Train net output #0: loss = 1.21708 (* 1 = 1.21708 loss)
I0802 06:46:31.429749 18636 sgd_solver.cpp:136] Iteration 46400, lr = 0.0071, m = 0.9
I0802 06:46:45.427994 18636 solver.cpp:353] Iteration 46500 (7.14391 iter/s, 13.9979s/100 iter), loss = 1.55319
I0802 06:46:45.428270 18636 solver.cpp:375]     Train net output #0: loss = 1.64202 (* 1 = 1.64202 loss)
I0802 06:46:45.428378 18636 sgd_solver.cpp:136] Iteration 46500, lr = 0.00709375, m = 0.9
I0802 06:46:59.380161 18636 solver.cpp:353] Iteration 46600 (7.16754 iter/s, 13.9518s/100 iter), loss = 1.26816
I0802 06:46:59.380551 18636 solver.cpp:375]     Train net output #0: loss = 0.986781 (* 1 = 0.986781 loss)
I0802 06:46:59.380564 18636 sgd_solver.cpp:136] Iteration 46600, lr = 0.0070875, m = 0.9
I0802 06:47:13.300606 18636 solver.cpp:353] Iteration 46700 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.82209
I0802 06:47:13.300659 18636 solver.cpp:375]     Train net output #0: loss = 1.57574 (* 1 = 1.57574 loss)
I0802 06:47:13.300678 18636 sgd_solver.cpp:136] Iteration 46700, lr = 0.00708125, m = 0.9
I0802 06:47:27.272965 18636 solver.cpp:353] Iteration 46800 (7.15718 iter/s, 13.972s/100 iter), loss = 1.45986
I0802 06:47:27.272990 18636 solver.cpp:375]     Train net output #0: loss = 1.67214 (* 1 = 1.67214 loss)
I0802 06:47:27.272994 18636 sgd_solver.cpp:136] Iteration 46800, lr = 0.007075, m = 0.9
I0802 06:47:41.217309 18636 solver.cpp:353] Iteration 46900 (7.17156 iter/s, 13.944s/100 iter), loss = 1.67315
I0802 06:47:41.217409 18636 solver.cpp:375]     Train net output #0: loss = 1.9193 (* 1 = 1.9193 loss)
I0802 06:47:41.217417 18636 sgd_solver.cpp:136] Iteration 46900, lr = 0.00706875, m = 0.9
I0802 06:47:55.051767 18636 solver.cpp:404] Sparsity after update:
I0802 06:47:55.065769 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:47:55.065834 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:47:55.065860 18636 net.cpp:2270] conv1b_param_0(0.264) 
I0802 06:47:55.065872 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:47:55.065884 18636 net.cpp:2270] res2a_branch2a_param_0(0.267) 
I0802 06:47:55.065897 18636 net.cpp:2270] res2a_branch2b_param_0(0.264) 
I0802 06:47:55.065909 18636 net.cpp:2270] res3a_branch2a_param_0(0.269) 
I0802 06:47:55.065922 18636 net.cpp:2270] res3a_branch2b_param_0(0.267) 
I0802 06:47:55.065934 18636 net.cpp:2270] res4a_branch2a_param_0(0.27) 
I0802 06:47:55.065946 18636 net.cpp:2270] res4a_branch2b_param_0(0.269) 
I0802 06:47:55.065958 18636 net.cpp:2270] res5a_branch2a_param_0(0.27) 
I0802 06:47:55.065971 18636 net.cpp:2270] res5a_branch2b_param_0(0.27) 
I0802 06:47:55.065984 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (634946/2.86678e+06) 0.221
I0802 06:47:55.195879 18661 solver.cpp:450] Finding and applying sparsity: 0.28
I0802 06:48:17.474906 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:48:17.476811 18636 solver.cpp:353] Iteration 47000 (2.75797 iter/s, 36.2585s/100 iter), loss = 1.43364
I0802 06:48:17.476836 18636 solver.cpp:375]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0802 06:48:17.476841 18636 sgd_solver.cpp:136] Iteration 47000, lr = 0.0070625, m = 0.9
I0802 06:48:31.929507 18636 solver.cpp:353] Iteration 47100 (6.91931 iter/s, 14.4523s/100 iter), loss = 1.7444
I0802 06:48:31.929533 18636 solver.cpp:375]     Train net output #0: loss = 1.90673 (* 1 = 1.90673 loss)
I0802 06:48:31.929538 18636 sgd_solver.cpp:136] Iteration 47100, lr = 0.00705625, m = 0.9
I0802 06:48:45.907543 18636 solver.cpp:353] Iteration 47200 (7.15428 iter/s, 13.9777s/100 iter), loss = 1.40348
I0802 06:48:45.907568 18636 solver.cpp:375]     Train net output #0: loss = 1.12277 (* 1 = 1.12277 loss)
I0802 06:48:45.907574 18636 sgd_solver.cpp:136] Iteration 47200, lr = 0.00705, m = 0.9
I0802 06:48:59.868453 18636 solver.cpp:353] Iteration 47300 (7.16305 iter/s, 13.9605s/100 iter), loss = 1.0933
I0802 06:48:59.868542 18636 solver.cpp:375]     Train net output #0: loss = 1.21015 (* 1 = 1.21015 loss)
I0802 06:48:59.868549 18636 sgd_solver.cpp:136] Iteration 47300, lr = 0.00704375, m = 0.9
I0802 06:49:13.825317 18636 solver.cpp:353] Iteration 47400 (7.16513 iter/s, 13.9565s/100 iter), loss = 1.40051
I0802 06:49:13.825526 18636 solver.cpp:375]     Train net output #0: loss = 1.22915 (* 1 = 1.22915 loss)
I0802 06:49:13.825645 18636 sgd_solver.cpp:136] Iteration 47400, lr = 0.0070375, m = 0.9
I0802 06:49:27.719486 18636 solver.cpp:353] Iteration 47500 (7.19746 iter/s, 13.8938s/100 iter), loss = 1.26055
I0802 06:49:27.719513 18636 solver.cpp:375]     Train net output #0: loss = 1.3017 (* 1 = 1.3017 loss)
I0802 06:49:27.719517 18636 sgd_solver.cpp:136] Iteration 47500, lr = 0.00703125, m = 0.9
I0802 06:49:41.755682 18636 solver.cpp:353] Iteration 47600 (7.12463 iter/s, 14.0358s/100 iter), loss = 2.0023
I0802 06:49:41.760870 18636 solver.cpp:375]     Train net output #0: loss = 2.03366 (* 1 = 2.03366 loss)
I0802 06:49:41.760882 18636 sgd_solver.cpp:136] Iteration 47600, lr = 0.007025, m = 0.9
I0802 06:49:55.637300 18636 solver.cpp:353] Iteration 47700 (7.20397 iter/s, 13.8812s/100 iter), loss = 1.45381
I0802 06:49:55.637363 18636 solver.cpp:375]     Train net output #0: loss = 1.37967 (* 1 = 1.37967 loss)
I0802 06:49:55.637374 18636 sgd_solver.cpp:136] Iteration 47700, lr = 0.00701875, m = 0.9
I0802 06:50:09.616214 18636 solver.cpp:353] Iteration 47800 (7.15382 iter/s, 13.9785s/100 iter), loss = 1.29604
I0802 06:50:09.616245 18636 solver.cpp:375]     Train net output #0: loss = 1.12856 (* 1 = 1.12856 loss)
I0802 06:50:09.616250 18636 sgd_solver.cpp:136] Iteration 47800, lr = 0.0070125, m = 0.9
I0802 06:50:23.606892 18636 solver.cpp:353] Iteration 47900 (7.14781 iter/s, 13.9903s/100 iter), loss = 1.39784
I0802 06:50:23.606962 18636 solver.cpp:375]     Train net output #0: loss = 1.9935 (* 1 = 1.9935 loss)
I0802 06:50:23.606969 18636 sgd_solver.cpp:136] Iteration 47900, lr = 0.00700625, m = 0.9
I0802 06:50:37.389869 18636 solver.cpp:404] Sparsity after update:
I0802 06:50:37.412127 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:50:37.412143 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:50:37.412151 18636 net.cpp:2270] conv1b_param_0(0.278) 
I0802 06:50:37.412155 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:50:37.412158 18636 net.cpp:2270] res2a_branch2a_param_0(0.278) 
I0802 06:50:37.412161 18636 net.cpp:2270] res2a_branch2b_param_0(0.278) 
I0802 06:50:37.412168 18636 net.cpp:2270] res3a_branch2a_param_0(0.28) 
I0802 06:50:37.412173 18636 net.cpp:2270] res3a_branch2b_param_0(0.278) 
I0802 06:50:37.412175 18636 net.cpp:2270] res4a_branch2a_param_0(0.28) 
I0802 06:50:37.412178 18636 net.cpp:2270] res4a_branch2b_param_0(0.28) 
I0802 06:50:37.412181 18636 net.cpp:2270] res5a_branch2a_param_0(0.28) 
I0802 06:50:37.412184 18636 net.cpp:2270] res5a_branch2b_param_0(0.279) 
I0802 06:50:37.412189 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (658213/2.86678e+06) 0.23
I0802 06:50:37.412201 18636 solver.cpp:550] Iteration 48000, Testing net (#0)
I0802 06:50:38.225237 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 06:50:56.960484 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.566647
I0802 06:50:56.960579 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.799821
I0802 06:50:56.960587 18636 solver.cpp:635]     Test net output #2: loss = 1.91587 (* 1 = 1.91587 loss)
I0802 06:50:56.960606 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5479s
I0802 06:50:57.113481 18661 solver.cpp:450] Finding and applying sparsity: 0.29
I0802 06:51:19.837556 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:51:19.839766 18636 solver.cpp:353] Iteration 48000 (1.77837 iter/s, 56.2314s/100 iter), loss = 1.46168
I0802 06:51:19.839797 18636 solver.cpp:375]     Train net output #0: loss = 1.67141 (* 1 = 1.67141 loss)
I0802 06:51:19.839807 18636 sgd_solver.cpp:136] Iteration 48000, lr = 0.007, m = 0.9
I0802 06:51:34.164759 18636 solver.cpp:353] Iteration 48100 (6.981 iter/s, 14.3246s/100 iter), loss = 1.41451
I0802 06:51:34.164826 18636 solver.cpp:375]     Train net output #0: loss = 1.61945 (* 1 = 1.61945 loss)
I0802 06:51:34.164834 18636 sgd_solver.cpp:136] Iteration 48100, lr = 0.00699375, m = 0.9
I0802 06:51:48.059079 18636 solver.cpp:353] Iteration 48200 (7.19738 iter/s, 13.8939s/100 iter), loss = 1.70287
I0802 06:51:48.059129 18636 solver.cpp:375]     Train net output #0: loss = 1.90336 (* 1 = 1.90336 loss)
I0802 06:51:48.059141 18636 sgd_solver.cpp:136] Iteration 48200, lr = 0.0069875, m = 0.9
I0802 06:52:01.952579 18636 solver.cpp:353] Iteration 48300 (7.19781 iter/s, 13.8931s/100 iter), loss = 1.27285
I0802 06:52:01.952606 18636 solver.cpp:375]     Train net output #0: loss = 1.40388 (* 1 = 1.40388 loss)
I0802 06:52:01.952610 18636 sgd_solver.cpp:136] Iteration 48300, lr = 0.00698125, m = 0.9
I0802 06:52:15.848634 18636 solver.cpp:353] Iteration 48400 (7.19648 iter/s, 13.8957s/100 iter), loss = 1.47127
I0802 06:52:15.848747 18636 solver.cpp:375]     Train net output #0: loss = 1.09558 (* 1 = 1.09558 loss)
I0802 06:52:15.848757 18636 sgd_solver.cpp:136] Iteration 48400, lr = 0.006975, m = 0.9
I0802 06:52:29.761567 18636 solver.cpp:353] Iteration 48500 (7.18775 iter/s, 13.9126s/100 iter), loss = 1.35573
I0802 06:52:29.761595 18636 solver.cpp:375]     Train net output #0: loss = 1.24959 (* 1 = 1.24959 loss)
I0802 06:52:29.761601 18636 sgd_solver.cpp:136] Iteration 48500, lr = 0.00696875, m = 0.9
I0802 06:52:43.773345 18636 solver.cpp:353] Iteration 48600 (7.13705 iter/s, 14.0114s/100 iter), loss = 1.23291
I0802 06:52:43.773377 18636 solver.cpp:375]     Train net output #0: loss = 1.32274 (* 1 = 1.32274 loss)
I0802 06:52:43.773382 18636 sgd_solver.cpp:136] Iteration 48600, lr = 0.0069625, m = 0.9
I0802 06:52:57.674425 18636 solver.cpp:353] Iteration 48700 (7.19388 iter/s, 13.9007s/100 iter), loss = 1.4489
I0802 06:52:57.674484 18636 solver.cpp:375]     Train net output #0: loss = 1.47148 (* 1 = 1.47148 loss)
I0802 06:52:57.674491 18636 sgd_solver.cpp:136] Iteration 48700, lr = 0.00695625, m = 0.9
I0802 06:53:11.597658 18636 solver.cpp:353] Iteration 48800 (7.18243 iter/s, 13.9229s/100 iter), loss = 1.5043
I0802 06:53:11.597684 18636 solver.cpp:375]     Train net output #0: loss = 1.66918 (* 1 = 1.66918 loss)
I0802 06:53:11.597746 18636 sgd_solver.cpp:136] Iteration 48800, lr = 0.00695, m = 0.9
I0802 06:53:25.499907 18636 solver.cpp:353] Iteration 48900 (7.19327 iter/s, 13.9019s/100 iter), loss = 1.67643
I0802 06:53:25.499960 18636 solver.cpp:375]     Train net output #0: loss = 1.6099 (* 1 = 1.6099 loss)
I0802 06:53:25.499972 18636 sgd_solver.cpp:136] Iteration 48900, lr = 0.00694375, m = 0.9
I0802 06:53:39.304018 18636 solver.cpp:404] Sparsity after update:
I0802 06:53:39.314502 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:53:39.314517 18636 net.cpp:2270] conv1a_param_0(0.133) 
I0802 06:53:39.314525 18636 net.cpp:2270] conv1b_param_0(0.278) 
I0802 06:53:39.314528 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:53:39.314532 18636 net.cpp:2270] res2a_branch2a_param_0(0.288) 
I0802 06:53:39.314535 18636 net.cpp:2270] res2a_branch2b_param_0(0.285) 
I0802 06:53:39.314538 18636 net.cpp:2270] res3a_branch2a_param_0(0.29) 
I0802 06:53:39.314541 18636 net.cpp:2270] res3a_branch2b_param_0(0.288) 
I0802 06:53:39.314544 18636 net.cpp:2270] res4a_branch2a_param_0(0.29) 
I0802 06:53:39.314546 18636 net.cpp:2270] res4a_branch2b_param_0(0.29) 
I0802 06:53:39.314549 18636 net.cpp:2270] res5a_branch2a_param_0(0.29) 
I0802 06:53:39.314553 18636 net.cpp:2270] res5a_branch2b_param_0(0.29) 
I0802 06:53:39.314555 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (682156/2.86678e+06) 0.238
I0802 06:53:39.443033 18661 solver.cpp:450] Finding and applying sparsity: 0.3
I0802 06:54:02.264540 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:54:02.266433 18636 solver.cpp:353] Iteration 49000 (2.71994 iter/s, 36.7655s/100 iter), loss = 1.58539
I0802 06:54:02.266453 18636 solver.cpp:375]     Train net output #0: loss = 1.48071 (* 1 = 1.48071 loss)
I0802 06:54:02.266458 18636 sgd_solver.cpp:136] Iteration 49000, lr = 0.0069375, m = 0.9
I0802 06:54:16.650591 18636 solver.cpp:353] Iteration 49100 (6.95228 iter/s, 14.3838s/100 iter), loss = 1.62198
I0802 06:54:16.650651 18636 solver.cpp:375]     Train net output #0: loss = 1.80605 (* 1 = 1.80605 loss)
I0802 06:54:16.650658 18636 sgd_solver.cpp:136] Iteration 49100, lr = 0.00693125, m = 0.9
I0802 06:54:30.567860 18636 solver.cpp:353] Iteration 49200 (7.18551 iter/s, 13.9169s/100 iter), loss = 1.57636
I0802 06:54:30.567952 18636 solver.cpp:375]     Train net output #0: loss = 1.80384 (* 1 = 1.80384 loss)
I0802 06:54:30.567972 18636 sgd_solver.cpp:136] Iteration 49200, lr = 0.006925, m = 0.9
I0802 06:54:44.438364 18636 solver.cpp:353] Iteration 49300 (7.20974 iter/s, 13.8701s/100 iter), loss = 1.37102
I0802 06:54:44.438400 18636 solver.cpp:375]     Train net output #0: loss = 1.35321 (* 1 = 1.35321 loss)
I0802 06:54:44.438405 18636 sgd_solver.cpp:136] Iteration 49300, lr = 0.00691875, m = 0.9
I0802 06:54:58.346591 18636 solver.cpp:353] Iteration 49400 (7.19018 iter/s, 13.9079s/100 iter), loss = 1.30816
I0802 06:54:58.346665 18636 solver.cpp:375]     Train net output #0: loss = 1.01246 (* 1 = 1.01246 loss)
I0802 06:54:58.346673 18636 sgd_solver.cpp:136] Iteration 49400, lr = 0.0069125, m = 0.9
I0802 06:55:12.272529 18636 solver.cpp:353] Iteration 49500 (7.18104 iter/s, 13.9256s/100 iter), loss = 1.30787
I0802 06:55:12.272554 18636 solver.cpp:375]     Train net output #0: loss = 1.08105 (* 1 = 1.08105 loss)
I0802 06:55:12.272559 18636 sgd_solver.cpp:136] Iteration 49500, lr = 0.00690625, m = 0.9
I0802 06:55:26.163686 18636 solver.cpp:353] Iteration 49600 (7.19902 iter/s, 13.8908s/100 iter), loss = 1.48203
I0802 06:55:26.163799 18636 solver.cpp:375]     Train net output #0: loss = 1.61794 (* 1 = 1.61794 loss)
I0802 06:55:26.163820 18636 sgd_solver.cpp:136] Iteration 49600, lr = 0.0069, m = 0.9
I0802 06:55:40.105550 18636 solver.cpp:353] Iteration 49700 (7.17283 iter/s, 13.9415s/100 iter), loss = 1.69063
I0802 06:55:40.105645 18636 solver.cpp:375]     Train net output #0: loss = 1.51562 (* 1 = 1.51562 loss)
I0802 06:55:40.105662 18636 sgd_solver.cpp:136] Iteration 49700, lr = 0.00689375, m = 0.9
I0802 06:55:54.042373 18636 solver.cpp:353] Iteration 49800 (7.17543 iter/s, 13.9364s/100 iter), loss = 1.54997
I0802 06:55:54.042409 18636 solver.cpp:375]     Train net output #0: loss = 1.95499 (* 1 = 1.95499 loss)
I0802 06:55:54.042417 18636 sgd_solver.cpp:136] Iteration 49800, lr = 0.0068875, m = 0.9
I0802 06:56:08.002913 18636 solver.cpp:353] Iteration 49900 (7.16324 iter/s, 13.9602s/100 iter), loss = 1.24592
I0802 06:56:08.002944 18636 solver.cpp:375]     Train net output #0: loss = 1.1966 (* 1 = 1.1966 loss)
I0802 06:56:08.002951 18636 sgd_solver.cpp:136] Iteration 49900, lr = 0.00688125, m = 0.9
I0802 06:56:21.870254 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_50000.caffemodel
I0802 06:56:21.965221 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_50000.solverstate
I0802 06:56:21.971206 18636 solver.cpp:404] Sparsity after update:
I0802 06:56:21.973189 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:56:21.973201 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 06:56:21.973209 18636 net.cpp:2270] conv1b_param_0(0.292) 
I0802 06:56:21.973212 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:56:21.973217 18636 net.cpp:2270] res2a_branch2a_param_0(0.299) 
I0802 06:56:21.973219 18636 net.cpp:2270] res2a_branch2b_param_0(0.299) 
I0802 06:56:21.973223 18636 net.cpp:2270] res3a_branch2a_param_0(0.299) 
I0802 06:56:21.973227 18636 net.cpp:2270] res3a_branch2b_param_0(0.299) 
I0802 06:56:21.973229 18636 net.cpp:2270] res4a_branch2a_param_0(0.299) 
I0802 06:56:21.973232 18636 net.cpp:2270] res4a_branch2b_param_0(0.299) 
I0802 06:56:21.973237 18636 net.cpp:2270] res5a_branch2a_param_0(0.3) 
I0802 06:56:21.973239 18636 net.cpp:2270] res5a_branch2b_param_0(0.299) 
I0802 06:56:21.973243 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (705071/2.86678e+06) 0.246
I0802 06:56:21.973256 18636 solver.cpp:550] Iteration 50000, Testing net (#0)
I0802 06:56:41.616878 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.561411
I0802 06:56:41.616904 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.803821
I0802 06:56:41.616910 18636 solver.cpp:635]     Test net output #2: loss = 1.9167 (* 1 = 1.9167 loss)
I0802 06:56:41.616932 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6431s
I0802 06:56:41.756669 18661 solver.cpp:450] Finding and applying sparsity: 0.31
I0802 06:57:04.953845 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:57:04.955755 18636 solver.cpp:353] Iteration 50000 (1.75589 iter/s, 56.9513s/100 iter), loss = 1.42634
I0802 06:57:04.955772 18636 solver.cpp:375]     Train net output #0: loss = 1.31368 (* 1 = 1.31368 loss)
I0802 06:57:04.955778 18636 sgd_solver.cpp:136] Iteration 50000, lr = 0.006875, m = 0.9
I0802 06:57:19.352954 18636 solver.cpp:353] Iteration 50100 (6.94599 iter/s, 14.3968s/100 iter), loss = 1.49455
I0802 06:57:19.352982 18636 solver.cpp:375]     Train net output #0: loss = 1.33442 (* 1 = 1.33442 loss)
I0802 06:57:19.352988 18636 sgd_solver.cpp:136] Iteration 50100, lr = 0.00686875, m = 0.9
I0802 06:57:33.430371 18636 solver.cpp:353] Iteration 50200 (7.10377 iter/s, 14.077s/100 iter), loss = 1.31277
I0802 06:57:33.430402 18636 solver.cpp:375]     Train net output #0: loss = 1.11821 (* 1 = 1.11821 loss)
I0802 06:57:33.430454 18636 sgd_solver.cpp:136] Iteration 50200, lr = 0.0068625, m = 0.9
I0802 06:57:47.387488 18636 solver.cpp:353] Iteration 50300 (7.165 iter/s, 13.9567s/100 iter), loss = 1.42128
I0802 06:57:47.387569 18636 solver.cpp:375]     Train net output #0: loss = 1.32181 (* 1 = 1.32181 loss)
I0802 06:57:47.387575 18636 sgd_solver.cpp:136] Iteration 50300, lr = 0.00685625, m = 0.9
I0802 06:58:01.375219 18636 solver.cpp:353] Iteration 50400 (7.14932 iter/s, 13.9873s/100 iter), loss = 1.62011
I0802 06:58:01.375247 18636 solver.cpp:375]     Train net output #0: loss = 2.09463 (* 1 = 2.09463 loss)
I0802 06:58:01.375253 18636 sgd_solver.cpp:136] Iteration 50400, lr = 0.00685, m = 0.9
I0802 06:58:15.326139 18636 solver.cpp:353] Iteration 50500 (7.16818 iter/s, 13.9505s/100 iter), loss = 1.40214
I0802 06:58:15.326167 18636 solver.cpp:375]     Train net output #0: loss = 1.21161 (* 1 = 1.21161 loss)
I0802 06:58:15.326174 18636 sgd_solver.cpp:136] Iteration 50500, lr = 0.00684375, m = 0.9
I0802 06:58:29.311125 18636 solver.cpp:353] Iteration 50600 (7.15072 iter/s, 13.9846s/100 iter), loss = 1.29509
I0802 06:58:29.312919 18636 solver.cpp:375]     Train net output #0: loss = 1.39533 (* 1 = 1.39533 loss)
I0802 06:58:29.312942 18636 sgd_solver.cpp:136] Iteration 50600, lr = 0.0068375, m = 0.9
I0802 06:58:43.294925 18636 solver.cpp:353] Iteration 50700 (7.15133 iter/s, 13.9834s/100 iter), loss = 1.42442
I0802 06:58:43.294955 18636 solver.cpp:375]     Train net output #0: loss = 1.81988 (* 1 = 1.81988 loss)
I0802 06:58:43.294960 18636 sgd_solver.cpp:136] Iteration 50700, lr = 0.00683125, m = 0.9
I0802 06:58:57.313169 18636 solver.cpp:353] Iteration 50800 (7.13375 iter/s, 14.0179s/100 iter), loss = 1.65342
I0802 06:58:57.313194 18636 solver.cpp:375]     Train net output #0: loss = 1.66311 (* 1 = 1.66311 loss)
I0802 06:58:57.313199 18636 sgd_solver.cpp:136] Iteration 50800, lr = 0.006825, m = 0.9
I0802 06:59:11.291710 18636 solver.cpp:353] Iteration 50900 (7.15402 iter/s, 13.9782s/100 iter), loss = 1.24462
I0802 06:59:11.291844 18636 solver.cpp:375]     Train net output #0: loss = 1.28791 (* 1 = 1.28791 loss)
I0802 06:59:11.291867 18636 sgd_solver.cpp:136] Iteration 50900, lr = 0.00681875, m = 0.9
I0802 06:59:25.146364 18636 solver.cpp:404] Sparsity after update:
I0802 06:59:25.160383 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 06:59:25.160434 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 06:59:25.160459 18636 net.cpp:2270] conv1b_param_0(0.306) 
I0802 06:59:25.160472 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 06:59:25.160485 18636 net.cpp:2270] res2a_branch2a_param_0(0.309) 
I0802 06:59:25.160498 18636 net.cpp:2270] res2a_branch2b_param_0(0.306) 
I0802 06:59:25.160517 18636 net.cpp:2270] res3a_branch2a_param_0(0.309) 
I0802 06:59:25.160531 18636 net.cpp:2270] res3a_branch2b_param_0(0.309) 
I0802 06:59:25.160544 18636 net.cpp:2270] res4a_branch2a_param_0(0.31) 
I0802 06:59:25.160557 18636 net.cpp:2270] res4a_branch2b_param_0(0.309) 
I0802 06:59:25.160569 18636 net.cpp:2270] res5a_branch2a_param_0(0.31) 
I0802 06:59:25.160583 18636 net.cpp:2270] res5a_branch2b_param_0(0.31) 
I0802 06:59:25.160595 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (729022/2.86678e+06) 0.254
I0802 06:59:25.309448 18661 solver.cpp:450] Finding and applying sparsity: 0.32
I0802 06:59:48.668054 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 06:59:48.669999 18636 solver.cpp:353] Iteration 51000 (2.67542 iter/s, 37.3773s/100 iter), loss = 1.28452
I0802 06:59:48.670018 18636 solver.cpp:375]     Train net output #0: loss = 1.35639 (* 1 = 1.35639 loss)
I0802 06:59:48.670025 18636 sgd_solver.cpp:136] Iteration 51000, lr = 0.0068125, m = 0.9
I0802 07:00:02.994339 18636 solver.cpp:353] Iteration 51100 (6.98132 iter/s, 14.3239s/100 iter), loss = 1.63698
I0802 07:00:02.994391 18636 solver.cpp:375]     Train net output #0: loss = 1.47396 (* 1 = 1.47396 loss)
I0802 07:00:02.994405 18636 sgd_solver.cpp:136] Iteration 51100, lr = 0.00680625, m = 0.9
I0802 07:00:16.960281 18636 solver.cpp:353] Iteration 51200 (7.16047 iter/s, 13.9656s/100 iter), loss = 1.50861
I0802 07:00:16.960309 18636 solver.cpp:375]     Train net output #0: loss = 1.48856 (* 1 = 1.48856 loss)
I0802 07:00:16.960312 18636 sgd_solver.cpp:136] Iteration 51200, lr = 0.0068, m = 0.9
I0802 07:00:30.944360 18636 solver.cpp:353] Iteration 51300 (7.15118 iter/s, 13.9837s/100 iter), loss = 1.43701
I0802 07:00:30.944428 18636 solver.cpp:375]     Train net output #0: loss = 1.61454 (* 1 = 1.61454 loss)
I0802 07:00:30.944434 18636 sgd_solver.cpp:136] Iteration 51300, lr = 0.00679375, m = 0.9
I0802 07:00:44.883304 18636 solver.cpp:353] Iteration 51400 (7.17434 iter/s, 13.9386s/100 iter), loss = 1.76298
I0802 07:00:44.883330 18636 solver.cpp:375]     Train net output #0: loss = 1.62156 (* 1 = 1.62156 loss)
I0802 07:00:44.883337 18636 sgd_solver.cpp:136] Iteration 51400, lr = 0.0067875, m = 0.9
I0802 07:00:58.770870 18636 solver.cpp:353] Iteration 51500 (7.20088 iter/s, 13.8872s/100 iter), loss = 1.58322
I0802 07:00:58.770961 18636 solver.cpp:375]     Train net output #0: loss = 1.49675 (* 1 = 1.49675 loss)
I0802 07:00:58.770982 18636 sgd_solver.cpp:136] Iteration 51500, lr = 0.00678125, m = 0.9
I0802 07:01:12.664788 18636 solver.cpp:353] Iteration 51600 (7.19759 iter/s, 13.8935s/100 iter), loss = 1.38689
I0802 07:01:12.664846 18636 solver.cpp:375]     Train net output #0: loss = 1.24145 (* 1 = 1.24145 loss)
I0802 07:01:12.664851 18636 sgd_solver.cpp:136] Iteration 51600, lr = 0.006775, m = 0.9
I0802 07:01:26.669744 18636 solver.cpp:353] Iteration 51700 (7.14052 iter/s, 14.0046s/100 iter), loss = 1.40688
I0802 07:01:26.669767 18636 solver.cpp:375]     Train net output #0: loss = 1.59067 (* 1 = 1.59067 loss)
I0802 07:01:26.669771 18636 sgd_solver.cpp:136] Iteration 51700, lr = 0.00676875, m = 0.9
I0802 07:01:40.595296 18636 solver.cpp:353] Iteration 51800 (7.18124 iter/s, 13.9252s/100 iter), loss = 1.14221
I0802 07:01:40.595324 18636 solver.cpp:375]     Train net output #0: loss = 0.87731 (* 1 = 0.87731 loss)
I0802 07:01:40.595327 18636 sgd_solver.cpp:136] Iteration 51800, lr = 0.0067625, m = 0.9
I0802 07:01:54.571805 18636 solver.cpp:353] Iteration 51900 (7.15506 iter/s, 13.9761s/100 iter), loss = 1.59654
I0802 07:01:54.571871 18636 solver.cpp:375]     Train net output #0: loss = 1.30264 (* 1 = 1.30264 loss)
I0802 07:01:54.571877 18636 sgd_solver.cpp:136] Iteration 51900, lr = 0.00675625, m = 0.9
I0802 07:02:08.471431 18636 solver.cpp:404] Sparsity after update:
I0802 07:02:08.477458 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:02:08.477469 18636 net.cpp:2270] conv1a_param_0(0.146) 
I0802 07:02:08.477478 18636 net.cpp:2270] conv1b_param_0(0.319) 
I0802 07:02:08.477483 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:02:08.477485 18636 net.cpp:2270] res2a_branch2a_param_0(0.319) 
I0802 07:02:08.477494 18636 net.cpp:2270] res2a_branch2b_param_0(0.319) 
I0802 07:02:08.477499 18636 net.cpp:2270] res3a_branch2a_param_0(0.319) 
I0802 07:02:08.477504 18636 net.cpp:2270] res3a_branch2b_param_0(0.319) 
I0802 07:02:08.477509 18636 net.cpp:2270] res4a_branch2a_param_0(0.319) 
I0802 07:02:08.477514 18636 net.cpp:2270] res4a_branch2b_param_0(0.319) 
I0802 07:02:08.477516 18636 net.cpp:2270] res5a_branch2a_param_0(0.32) 
I0802 07:02:08.477521 18636 net.cpp:2270] res5a_branch2b_param_0(0.319) 
I0802 07:02:08.477526 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (752286/2.86678e+06) 0.262
I0802 07:02:08.477538 18636 solver.cpp:550] Iteration 52000, Testing net (#0)
I0802 07:02:27.808290 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.571647
I0802 07:02:27.808419 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805997
I0802 07:02:27.808429 18636 solver.cpp:635]     Test net output #2: loss = 1.88316 (* 1 = 1.88316 loss)
I0802 07:02:27.808447 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.3304s
I0802 07:02:27.947489 18661 solver.cpp:450] Finding and applying sparsity: 0.33
I0802 07:02:51.755393 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:02:51.757508 18636 solver.cpp:353] Iteration 52000 (1.74874 iter/s, 57.1842s/100 iter), loss = 1.33747
I0802 07:02:51.757534 18636 solver.cpp:375]     Train net output #0: loss = 0.915729 (* 1 = 0.915729 loss)
I0802 07:02:51.757544 18636 sgd_solver.cpp:136] Iteration 52000, lr = 0.00675, m = 0.9
I0802 07:03:06.099489 18636 solver.cpp:353] Iteration 52100 (6.97273 iter/s, 14.3416s/100 iter), loss = 1.14879
I0802 07:03:06.099555 18636 solver.cpp:375]     Train net output #0: loss = 1.09354 (* 1 = 1.09354 loss)
I0802 07:03:06.099561 18636 sgd_solver.cpp:136] Iteration 52100, lr = 0.00674375, m = 0.9
I0802 07:03:20.012018 18636 solver.cpp:353] Iteration 52200 (7.18796 iter/s, 13.9121s/100 iter), loss = 1.15975
I0802 07:03:20.012042 18636 solver.cpp:375]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0802 07:03:20.012046 18636 sgd_solver.cpp:136] Iteration 52200, lr = 0.0067375, m = 0.9
I0802 07:03:33.993377 18636 solver.cpp:353] Iteration 52300 (7.15258 iter/s, 13.981s/100 iter), loss = 1.56232
I0802 07:03:33.993407 18636 solver.cpp:375]     Train net output #0: loss = 1.73745 (* 1 = 1.73745 loss)
I0802 07:03:33.993412 18636 sgd_solver.cpp:136] Iteration 52300, lr = 0.00673125, m = 0.9
I0802 07:03:47.896731 18636 solver.cpp:353] Iteration 52400 (7.19271 iter/s, 13.903s/100 iter), loss = 1.19491
I0802 07:03:47.896808 18636 solver.cpp:375]     Train net output #0: loss = 1.24251 (* 1 = 1.24251 loss)
I0802 07:03:47.896821 18636 sgd_solver.cpp:136] Iteration 52400, lr = 0.006725, m = 0.9
I0802 07:04:01.850445 18636 solver.cpp:353] Iteration 52500 (7.16675 iter/s, 13.9533s/100 iter), loss = 1.34499
I0802 07:04:01.850540 18636 solver.cpp:375]     Train net output #0: loss = 1.02749 (* 1 = 1.02749 loss)
I0802 07:04:01.850560 18636 sgd_solver.cpp:136] Iteration 52500, lr = 0.00671875, m = 0.9
I0802 07:04:15.795472 18636 solver.cpp:353] Iteration 52600 (7.17121 iter/s, 13.9446s/100 iter), loss = 1.14722
I0802 07:04:15.795542 18636 solver.cpp:375]     Train net output #0: loss = 1.29363 (* 1 = 1.29363 loss)
I0802 07:04:15.795554 18636 sgd_solver.cpp:136] Iteration 52600, lr = 0.0067125, m = 0.9
I0802 07:04:29.791151 18636 solver.cpp:353] Iteration 52700 (7.14525 iter/s, 13.9953s/100 iter), loss = 1.05876
I0802 07:04:29.791239 18636 solver.cpp:375]     Train net output #0: loss = 0.923927 (* 1 = 0.923927 loss)
I0802 07:04:29.791245 18636 sgd_solver.cpp:136] Iteration 52700, lr = 0.00670625, m = 0.9
I0802 07:04:43.743845 18636 solver.cpp:353] Iteration 52800 (7.16727 iter/s, 13.9523s/100 iter), loss = 1.73719
I0802 07:04:43.743870 18636 solver.cpp:375]     Train net output #0: loss = 1.32157 (* 1 = 1.32157 loss)
I0802 07:04:43.743875 18636 sgd_solver.cpp:136] Iteration 52800, lr = 0.0067, m = 0.9
I0802 07:04:57.645217 18636 solver.cpp:353] Iteration 52900 (7.19373 iter/s, 13.901s/100 iter), loss = 1.38644
I0802 07:04:57.645248 18636 solver.cpp:375]     Train net output #0: loss = 1.38102 (* 1 = 1.38102 loss)
I0802 07:04:57.645254 18636 sgd_solver.cpp:136] Iteration 52900, lr = 0.00669375, m = 0.9
I0802 07:05:11.505561 18636 solver.cpp:404] Sparsity after update:
I0802 07:05:11.516348 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:05:11.516369 18636 net.cpp:2270] conv1a_param_0(0.159) 
I0802 07:05:11.516378 18636 net.cpp:2270] conv1b_param_0(0.319) 
I0802 07:05:11.516381 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:05:11.516384 18636 net.cpp:2270] res2a_branch2a_param_0(0.33) 
I0802 07:05:11.516394 18636 net.cpp:2270] res2a_branch2b_param_0(0.326) 
I0802 07:05:11.516400 18636 net.cpp:2270] res3a_branch2a_param_0(0.33) 
I0802 07:05:11.516405 18636 net.cpp:2270] res3a_branch2b_param_0(0.33) 
I0802 07:05:11.516408 18636 net.cpp:2270] res4a_branch2a_param_0(0.33) 
I0802 07:05:11.516412 18636 net.cpp:2270] res4a_branch2b_param_0(0.33) 
I0802 07:05:11.516415 18636 net.cpp:2270] res5a_branch2a_param_0(0.33) 
I0802 07:05:11.516419 18636 net.cpp:2270] res5a_branch2b_param_0(0.33) 
I0802 07:05:11.516424 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (776264/2.86678e+06) 0.271
I0802 07:05:11.647892 18661 solver.cpp:450] Finding and applying sparsity: 0.34
I0802 07:05:35.421032 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:05:35.422912 18636 solver.cpp:353] Iteration 53000 (2.64714 iter/s, 37.7767s/100 iter), loss = 1.3688
I0802 07:05:35.422931 18636 solver.cpp:375]     Train net output #0: loss = 1.2552 (* 1 = 1.2552 loss)
I0802 07:05:35.422937 18636 sgd_solver.cpp:136] Iteration 53000, lr = 0.0066875, m = 0.9
I0802 07:05:49.760010 18636 solver.cpp:353] Iteration 53100 (6.9751 iter/s, 14.3367s/100 iter), loss = 1.37704
I0802 07:05:49.760112 18636 solver.cpp:375]     Train net output #0: loss = 1.38668 (* 1 = 1.38668 loss)
I0802 07:05:49.760119 18636 sgd_solver.cpp:136] Iteration 53100, lr = 0.00668125, m = 0.9
I0802 07:06:03.750648 18636 solver.cpp:353] Iteration 53200 (7.14783 iter/s, 13.9903s/100 iter), loss = 1.31814
I0802 07:06:03.750895 18636 solver.cpp:375]     Train net output #0: loss = 1.35946 (* 1 = 1.35946 loss)
I0802 07:06:03.751005 18636 sgd_solver.cpp:136] Iteration 53200, lr = 0.006675, m = 0.9
I0802 07:06:17.688721 18636 solver.cpp:353] Iteration 53300 (7.17479 iter/s, 13.9377s/100 iter), loss = 1.26445
I0802 07:06:17.688747 18636 solver.cpp:375]     Train net output #0: loss = 1.13752 (* 1 = 1.13752 loss)
I0802 07:06:17.688752 18636 sgd_solver.cpp:136] Iteration 53300, lr = 0.00666875, m = 0.9
I0802 07:06:31.538981 18636 solver.cpp:353] Iteration 53400 (7.22028 iter/s, 13.8499s/100 iter), loss = 1.6693
I0802 07:06:31.539044 18636 solver.cpp:375]     Train net output #0: loss = 1.75626 (* 1 = 1.75626 loss)
I0802 07:06:31.539052 18636 sgd_solver.cpp:136] Iteration 53400, lr = 0.0066625, m = 0.9
I0802 07:06:45.611104 18636 solver.cpp:353] Iteration 53500 (7.10644 iter/s, 14.0717s/100 iter), loss = 1.26637
I0802 07:06:45.611130 18636 solver.cpp:375]     Train net output #0: loss = 1.47593 (* 1 = 1.47593 loss)
I0802 07:06:45.611135 18636 sgd_solver.cpp:136] Iteration 53500, lr = 0.00665625, m = 0.9
I0802 07:06:59.581105 18636 solver.cpp:353] Iteration 53600 (7.15839 iter/s, 13.9696s/100 iter), loss = 1.68158
I0802 07:06:59.581130 18636 solver.cpp:375]     Train net output #0: loss = 1.72183 (* 1 = 1.72183 loss)
I0802 07:06:59.581135 18636 sgd_solver.cpp:136] Iteration 53600, lr = 0.00665, m = 0.9
I0802 07:07:13.554539 18636 solver.cpp:353] Iteration 53700 (7.15663 iter/s, 13.9731s/100 iter), loss = 1.29332
I0802 07:07:13.554605 18636 solver.cpp:375]     Train net output #0: loss = 1.2885 (* 1 = 1.2885 loss)
I0802 07:07:13.554611 18636 sgd_solver.cpp:136] Iteration 53700, lr = 0.00664375, m = 0.9
I0802 07:07:27.582221 18636 solver.cpp:353] Iteration 53800 (7.12896 iter/s, 14.0273s/100 iter), loss = 1.42862
I0802 07:07:27.582247 18636 solver.cpp:375]     Train net output #0: loss = 1.82077 (* 1 = 1.82077 loss)
I0802 07:07:27.582252 18636 sgd_solver.cpp:136] Iteration 53800, lr = 0.0066375, m = 0.9
I0802 07:07:41.559911 18636 solver.cpp:353] Iteration 53900 (7.15445 iter/s, 13.9773s/100 iter), loss = 1.26151
I0802 07:07:41.560009 18636 solver.cpp:375]     Train net output #0: loss = 1.17131 (* 1 = 1.17131 loss)
I0802 07:07:41.560030 18636 sgd_solver.cpp:136] Iteration 53900, lr = 0.00663125, m = 0.9
I0802 07:07:55.302817 18636 solver.cpp:404] Sparsity after update:
I0802 07:07:55.308001 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:07:55.308013 18636 net.cpp:2270] conv1a_param_0(0.159) 
I0802 07:07:55.308022 18636 net.cpp:2270] conv1b_param_0(0.333) 
I0802 07:07:55.308024 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:07:55.308028 18636 net.cpp:2270] res2a_branch2a_param_0(0.337) 
I0802 07:07:55.308032 18636 net.cpp:2270] res2a_branch2b_param_0(0.333) 
I0802 07:07:55.308034 18636 net.cpp:2270] res3a_branch2a_param_0(0.339) 
I0802 07:07:55.308037 18636 net.cpp:2270] res3a_branch2b_param_0(0.337) 
I0802 07:07:55.308040 18636 net.cpp:2270] res4a_branch2a_param_0(0.339) 
I0802 07:07:55.308043 18636 net.cpp:2270] res4a_branch2b_param_0(0.339) 
I0802 07:07:55.308046 18636 net.cpp:2270] res5a_branch2a_param_0(0.34) 
I0802 07:07:55.308049 18636 net.cpp:2270] res5a_branch2b_param_0(0.339) 
I0802 07:07:55.308053 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (798889/2.86678e+06) 0.279
I0802 07:07:55.308063 18636 solver.cpp:550] Iteration 54000, Testing net (#0)
I0802 07:08:01.456009 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:08:14.873641 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.563353
I0802 07:08:14.873693 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.801762
I0802 07:08:14.873702 18636 solver.cpp:635]     Test net output #2: loss = 1.91771 (* 1 = 1.91771 loss)
I0802 07:08:14.873730 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5651s
I0802 07:08:15.025360 18661 solver.cpp:450] Finding and applying sparsity: 0.35
I0802 07:08:39.018271 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:08:39.020277 18636 solver.cpp:353] Iteration 54000 (1.74038 iter/s, 57.4588s/100 iter), loss = 1.41918
I0802 07:08:39.020298 18636 solver.cpp:375]     Train net output #0: loss = 1.563 (* 1 = 1.563 loss)
I0802 07:08:39.020303 18636 sgd_solver.cpp:136] Iteration 54000, lr = 0.006625, m = 0.9
I0802 07:08:53.371479 18636 solver.cpp:353] Iteration 54100 (6.96825 iter/s, 14.3508s/100 iter), loss = 1.46314
I0802 07:08:53.371506 18636 solver.cpp:375]     Train net output #0: loss = 1.79181 (* 1 = 1.79181 loss)
I0802 07:08:53.371512 18636 sgd_solver.cpp:136] Iteration 54100, lr = 0.00661875, m = 0.9
I0802 07:09:07.245044 18636 solver.cpp:353] Iteration 54200 (7.20815 iter/s, 13.8732s/100 iter), loss = 1.64423
I0802 07:09:07.245074 18636 solver.cpp:375]     Train net output #0: loss = 1.28533 (* 1 = 1.28533 loss)
I0802 07:09:07.245080 18636 sgd_solver.cpp:136] Iteration 54200, lr = 0.0066125, m = 0.9
I0802 07:09:21.184610 18636 solver.cpp:353] Iteration 54300 (7.17402 iter/s, 13.9392s/100 iter), loss = 1.3993
I0802 07:09:21.184743 18636 solver.cpp:375]     Train net output #0: loss = 1.31292 (* 1 = 1.31292 loss)
I0802 07:09:21.184765 18636 sgd_solver.cpp:136] Iteration 54300, lr = 0.00660625, m = 0.9
I0802 07:09:35.067245 18636 solver.cpp:353] Iteration 54400 (7.20344 iter/s, 13.8823s/100 iter), loss = 1.57866
I0802 07:09:35.067358 18636 solver.cpp:375]     Train net output #0: loss = 1.49391 (* 1 = 1.49391 loss)
I0802 07:09:35.067378 18636 sgd_solver.cpp:136] Iteration 54400, lr = 0.0066, m = 0.9
I0802 07:09:48.981613 18636 solver.cpp:353] Iteration 54500 (7.18701 iter/s, 13.914s/100 iter), loss = 1.55979
I0802 07:09:48.981643 18636 solver.cpp:375]     Train net output #0: loss = 1.88824 (* 1 = 1.88824 loss)
I0802 07:09:48.981647 18636 sgd_solver.cpp:136] Iteration 54500, lr = 0.00659375, m = 0.9
I0802 07:10:02.885670 18636 solver.cpp:353] Iteration 54600 (7.19234 iter/s, 13.9037s/100 iter), loss = 1.16714
I0802 07:10:02.885929 18636 solver.cpp:375]     Train net output #0: loss = 1.23169 (* 1 = 1.23169 loss)
I0802 07:10:02.886037 18636 sgd_solver.cpp:136] Iteration 54600, lr = 0.0065875, m = 0.9
I0802 07:10:16.838683 18636 solver.cpp:353] Iteration 54700 (7.16711 iter/s, 13.9526s/100 iter), loss = 1.50748
I0802 07:10:16.838714 18636 solver.cpp:375]     Train net output #0: loss = 1.6616 (* 1 = 1.6616 loss)
I0802 07:10:16.838721 18636 sgd_solver.cpp:136] Iteration 54700, lr = 0.00658125, m = 0.9
I0802 07:10:30.678393 18636 solver.cpp:353] Iteration 54800 (7.22578 iter/s, 13.8393s/100 iter), loss = 1.27701
I0802 07:10:30.678426 18636 solver.cpp:375]     Train net output #0: loss = 1.37952 (* 1 = 1.37952 loss)
I0802 07:10:30.678432 18636 sgd_solver.cpp:136] Iteration 54800, lr = 0.006575, m = 0.9
I0802 07:10:44.541751 18636 solver.cpp:353] Iteration 54900 (7.21345 iter/s, 13.863s/100 iter), loss = 1.81978
I0802 07:10:44.541862 18636 solver.cpp:375]     Train net output #0: loss = 1.86716 (* 1 = 1.86716 loss)
I0802 07:10:44.541882 18636 sgd_solver.cpp:136] Iteration 54900, lr = 0.00656875, m = 0.9
I0802 07:10:58.307562 18636 solver.cpp:404] Sparsity after update:
I0802 07:10:58.318047 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:10:58.318061 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:10:58.318069 18636 net.cpp:2270] conv1b_param_0(0.347) 
I0802 07:10:58.318073 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:10:58.318079 18636 net.cpp:2270] res2a_branch2a_param_0(0.347) 
I0802 07:10:58.318084 18636 net.cpp:2270] res2a_branch2b_param_0(0.347) 
I0802 07:10:58.318086 18636 net.cpp:2270] res3a_branch2a_param_0(0.349) 
I0802 07:10:58.318089 18636 net.cpp:2270] res3a_branch2b_param_0(0.347) 
I0802 07:10:58.318092 18636 net.cpp:2270] res4a_branch2a_param_0(0.35) 
I0802 07:10:58.318096 18636 net.cpp:2270] res4a_branch2b_param_0(0.349) 
I0802 07:10:58.318100 18636 net.cpp:2270] res5a_branch2a_param_0(0.35) 
I0802 07:10:58.318104 18636 net.cpp:2270] res5a_branch2b_param_0(0.35) 
I0802 07:10:58.318109 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (822947/2.86678e+06) 0.287
I0802 07:10:58.446967 18661 solver.cpp:450] Finding and applying sparsity: 0.36
I0802 07:11:22.830132 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:11:22.832044 18636 solver.cpp:353] Iteration 55000 (2.6117 iter/s, 38.2893s/100 iter), loss = 1.21977
I0802 07:11:22.832063 18636 solver.cpp:375]     Train net output #0: loss = 1.47755 (* 1 = 1.47755 loss)
I0802 07:11:22.832072 18636 sgd_solver.cpp:136] Iteration 55000, lr = 0.0065625, m = 0.9
I0802 07:11:37.284111 18636 solver.cpp:353] Iteration 55100 (6.91962 iter/s, 14.4517s/100 iter), loss = 1.47629
I0802 07:11:37.284142 18636 solver.cpp:375]     Train net output #0: loss = 1.16382 (* 1 = 1.16382 loss)
I0802 07:11:37.284147 18636 sgd_solver.cpp:136] Iteration 55100, lr = 0.00655625, m = 0.9
I0802 07:11:51.161692 18636 solver.cpp:353] Iteration 55200 (7.20607 iter/s, 13.8772s/100 iter), loss = 1.16159
I0802 07:11:51.161720 18636 solver.cpp:375]     Train net output #0: loss = 1.43692 (* 1 = 1.43692 loss)
I0802 07:11:51.161723 18636 sgd_solver.cpp:136] Iteration 55200, lr = 0.00655, m = 0.9
I0802 07:12:05.081414 18636 solver.cpp:353] Iteration 55300 (7.18425 iter/s, 13.9193s/100 iter), loss = 1.27465
I0802 07:12:05.081482 18636 solver.cpp:375]     Train net output #0: loss = 1.34837 (* 1 = 1.34837 loss)
I0802 07:12:05.081488 18636 sgd_solver.cpp:136] Iteration 55300, lr = 0.00654375, m = 0.9
I0802 07:12:18.982712 18636 solver.cpp:353] Iteration 55400 (7.19377 iter/s, 13.9009s/100 iter), loss = 1.64487
I0802 07:12:18.982738 18636 solver.cpp:375]     Train net output #0: loss = 1.67845 (* 1 = 1.67845 loss)
I0802 07:12:18.982743 18636 sgd_solver.cpp:136] Iteration 55400, lr = 0.0065375, m = 0.9
I0802 07:12:33.156852 18636 solver.cpp:353] Iteration 55500 (7.05529 iter/s, 14.1738s/100 iter), loss = 1.33269
I0802 07:12:33.156914 18636 solver.cpp:375]     Train net output #0: loss = 1.19603 (* 1 = 1.19603 loss)
I0802 07:12:33.156930 18636 sgd_solver.cpp:136] Iteration 55500, lr = 0.00653125, m = 0.9
I0802 07:12:47.185145 18636 solver.cpp:353] Iteration 55600 (7.12864 iter/s, 14.0279s/100 iter), loss = 1.65497
I0802 07:12:47.186980 18636 solver.cpp:375]     Train net output #0: loss = 1.69117 (* 1 = 1.69117 loss)
I0802 07:12:47.186990 18636 sgd_solver.cpp:136] Iteration 55600, lr = 0.006525, m = 0.9
I0802 07:13:01.106055 18636 solver.cpp:353] Iteration 55700 (7.18363 iter/s, 13.9205s/100 iter), loss = 1.56877
I0802 07:13:01.106081 18636 solver.cpp:375]     Train net output #0: loss = 1.77582 (* 1 = 1.77582 loss)
I0802 07:13:01.106086 18636 sgd_solver.cpp:136] Iteration 55700, lr = 0.00651875, m = 0.9
I0802 07:13:15.008054 18636 solver.cpp:353] Iteration 55800 (7.19341 iter/s, 13.9016s/100 iter), loss = 1.47388
I0802 07:13:15.008081 18636 solver.cpp:375]     Train net output #0: loss = 1.91846 (* 1 = 1.91846 loss)
I0802 07:13:15.008085 18636 sgd_solver.cpp:136] Iteration 55800, lr = 0.0065125, m = 0.9
I0802 07:13:28.984356 18636 solver.cpp:353] Iteration 55900 (7.15516 iter/s, 13.9759s/100 iter), loss = 1.3096
I0802 07:13:28.984428 18636 solver.cpp:375]     Train net output #0: loss = 1.29841 (* 1 = 1.29841 loss)
I0802 07:13:28.984433 18636 sgd_solver.cpp:136] Iteration 55900, lr = 0.00650625, m = 0.9
I0802 07:13:42.822312 18636 solver.cpp:404] Sparsity after update:
I0802 07:13:42.826253 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:13:42.826263 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:13:42.826272 18636 net.cpp:2270] conv1b_param_0(0.347) 
I0802 07:13:42.826275 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:13:42.826285 18636 net.cpp:2270] res2a_branch2a_param_0(0.358) 
I0802 07:13:42.826292 18636 net.cpp:2270] res2a_branch2b_param_0(0.354) 
I0802 07:13:42.826297 18636 net.cpp:2270] res3a_branch2a_param_0(0.359) 
I0802 07:13:42.826301 18636 net.cpp:2270] res3a_branch2b_param_0(0.358) 
I0802 07:13:42.826305 18636 net.cpp:2270] res4a_branch2a_param_0(0.359) 
I0802 07:13:42.826309 18636 net.cpp:2270] res4a_branch2b_param_0(0.359) 
I0802 07:13:42.826313 18636 net.cpp:2270] res5a_branch2a_param_0(0.36) 
I0802 07:13:42.826318 18636 net.cpp:2270] res5a_branch2b_param_0(0.359) 
I0802 07:13:42.826321 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (846122/2.86678e+06) 0.295
I0802 07:13:42.826333 18636 solver.cpp:550] Iteration 56000, Testing net (#0)
I0802 07:14:02.465950 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.570411
I0802 07:14:02.465999 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.804703
I0802 07:14:02.466008 18636 solver.cpp:635]     Test net output #2: loss = 1.88501 (* 1 = 1.88501 loss)
I0802 07:14:02.466029 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6392s
I0802 07:14:02.602612 18661 solver.cpp:450] Finding and applying sparsity: 0.37
I0802 07:14:27.401006 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:14:27.402935 18636 solver.cpp:353] Iteration 56000 (1.71183 iter/s, 58.417s/100 iter), loss = 1.27009
I0802 07:14:27.402964 18636 solver.cpp:375]     Train net output #0: loss = 1.18265 (* 1 = 1.18265 loss)
I0802 07:14:27.402971 18636 sgd_solver.cpp:136] Iteration 56000, lr = 0.0065, m = 0.9
I0802 07:14:41.788522 18636 solver.cpp:353] Iteration 56100 (6.95159 iter/s, 14.3852s/100 iter), loss = 1.44743
I0802 07:14:41.788604 18636 solver.cpp:375]     Train net output #0: loss = 1.75094 (* 1 = 1.75094 loss)
I0802 07:14:41.788612 18636 sgd_solver.cpp:136] Iteration 56100, lr = 0.00649375, m = 0.9
I0802 07:14:55.691238 18636 solver.cpp:353] Iteration 56200 (7.19304 iter/s, 13.9023s/100 iter), loss = 1.35106
I0802 07:14:55.691268 18636 solver.cpp:375]     Train net output #0: loss = 1.58864 (* 1 = 1.58864 loss)
I0802 07:14:55.691272 18636 sgd_solver.cpp:136] Iteration 56200, lr = 0.0064875, m = 0.9
I0802 07:15:09.641079 18636 solver.cpp:353] Iteration 56300 (7.16874 iter/s, 13.9495s/100 iter), loss = 1.53019
I0802 07:15:09.641105 18636 solver.cpp:375]     Train net output #0: loss = 1.4709 (* 1 = 1.4709 loss)
I0802 07:15:09.641110 18636 sgd_solver.cpp:136] Iteration 56300, lr = 0.00648125, m = 0.9
I0802 07:15:23.571559 18636 solver.cpp:353] Iteration 56400 (7.1787 iter/s, 13.9301s/100 iter), loss = 1.43427
I0802 07:15:23.571631 18636 solver.cpp:375]     Train net output #0: loss = 1.12767 (* 1 = 1.12767 loss)
I0802 07:15:23.571638 18636 sgd_solver.cpp:136] Iteration 56400, lr = 0.006475, m = 0.9
I0802 07:15:37.484747 18636 solver.cpp:353] Iteration 56500 (7.18762 iter/s, 13.9128s/100 iter), loss = 1.19695
I0802 07:15:37.484776 18636 solver.cpp:375]     Train net output #0: loss = 1.23702 (* 1 = 1.23702 loss)
I0802 07:15:37.484783 18636 sgd_solver.cpp:136] Iteration 56500, lr = 0.00646875, m = 0.9
I0802 07:15:51.387397 18636 solver.cpp:353] Iteration 56600 (7.19307 iter/s, 13.9023s/100 iter), loss = 1.17161
I0802 07:15:51.387428 18636 solver.cpp:375]     Train net output #0: loss = 1.15145 (* 1 = 1.15145 loss)
I0802 07:15:51.387435 18636 sgd_solver.cpp:136] Iteration 56600, lr = 0.0064625, m = 0.9
I0802 07:16:05.368883 18636 solver.cpp:353] Iteration 56700 (7.15251 iter/s, 13.9811s/100 iter), loss = 1.56862
I0802 07:16:05.369055 18636 solver.cpp:375]     Train net output #0: loss = 2.0181 (* 1 = 2.0181 loss)
I0802 07:16:05.369088 18636 sgd_solver.cpp:136] Iteration 56700, lr = 0.00645625, m = 0.9
I0802 07:16:19.451378 18636 solver.cpp:353] Iteration 56800 (7.10121 iter/s, 14.0821s/100 iter), loss = 1.52177
I0802 07:16:19.451406 18636 solver.cpp:375]     Train net output #0: loss = 1.73733 (* 1 = 1.73733 loss)
I0802 07:16:19.451411 18636 sgd_solver.cpp:136] Iteration 56800, lr = 0.00645, m = 0.9
I0802 07:16:33.338721 18636 solver.cpp:353] Iteration 56900 (7.201 iter/s, 13.887s/100 iter), loss = 1.29799
I0802 07:16:33.338747 18636 solver.cpp:375]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0802 07:16:33.338750 18636 sgd_solver.cpp:136] Iteration 56900, lr = 0.00644375, m = 0.9
I0802 07:16:47.146754 18636 solver.cpp:404] Sparsity after update:
I0802 07:16:47.157187 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:16:47.157202 18636 net.cpp:2270] conv1a_param_0(0.172) 
I0802 07:16:47.157212 18636 net.cpp:2270] conv1b_param_0(0.361) 
I0802 07:16:47.157214 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:16:47.157218 18636 net.cpp:2270] res2a_branch2a_param_0(0.368) 
I0802 07:16:47.157222 18636 net.cpp:2270] res2a_branch2b_param_0(0.368) 
I0802 07:16:47.157224 18636 net.cpp:2270] res3a_branch2a_param_0(0.37) 
I0802 07:16:47.157227 18636 net.cpp:2270] res3a_branch2b_param_0(0.368) 
I0802 07:16:47.157230 18636 net.cpp:2270] res4a_branch2a_param_0(0.37) 
I0802 07:16:47.157234 18636 net.cpp:2270] res4a_branch2b_param_0(0.37) 
I0802 07:16:47.157236 18636 net.cpp:2270] res5a_branch2a_param_0(0.37) 
I0802 07:16:47.157240 18636 net.cpp:2270] res5a_branch2b_param_0(0.37) 
I0802 07:16:47.157243 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (870155/2.86678e+06) 0.304
I0802 07:16:47.290729 18661 solver.cpp:450] Finding and applying sparsity: 0.38
I0802 07:17:12.588165 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:17:12.590158 18636 solver.cpp:353] Iteration 57000 (2.54775 iter/s, 39.2504s/100 iter), loss = 1.28647
I0802 07:17:12.590198 18636 solver.cpp:375]     Train net output #0: loss = 1.34178 (* 1 = 1.34178 loss)
I0802 07:17:12.590207 18636 sgd_solver.cpp:136] Iteration 57000, lr = 0.0064375, m = 0.9
I0802 07:17:27.065862 18636 solver.cpp:353] Iteration 57100 (6.90832 iter/s, 14.4753s/100 iter), loss = 1.49189
I0802 07:17:27.065965 18636 solver.cpp:375]     Train net output #0: loss = 1.29164 (* 1 = 1.29164 loss)
I0802 07:17:27.065984 18636 sgd_solver.cpp:136] Iteration 57100, lr = 0.00643125, m = 0.9
I0802 07:17:40.976732 18636 solver.cpp:353] Iteration 57200 (7.18882 iter/s, 13.9105s/100 iter), loss = 1.33051
I0802 07:17:40.976758 18636 solver.cpp:375]     Train net output #0: loss = 1.22851 (* 1 = 1.22851 loss)
I0802 07:17:40.976763 18636 sgd_solver.cpp:136] Iteration 57200, lr = 0.006425, m = 0.9
I0802 07:17:54.974357 18636 solver.cpp:353] Iteration 57300 (7.14427 iter/s, 13.9972s/100 iter), loss = 1.32794
I0802 07:17:54.974412 18636 solver.cpp:375]     Train net output #0: loss = 1.37752 (* 1 = 1.37752 loss)
I0802 07:17:54.974424 18636 sgd_solver.cpp:136] Iteration 57300, lr = 0.00641875, m = 0.9
I0802 07:18:08.856353 18636 solver.cpp:353] Iteration 57400 (7.20377 iter/s, 13.8816s/100 iter), loss = 1.43544
I0802 07:18:08.857069 18636 solver.cpp:375]     Train net output #0: loss = 1.32185 (* 1 = 1.32185 loss)
I0802 07:18:08.857082 18636 sgd_solver.cpp:136] Iteration 57400, lr = 0.0064125, m = 0.9
I0802 07:18:22.826472 18636 solver.cpp:353] Iteration 57500 (7.15833 iter/s, 13.9697s/100 iter), loss = 1.01827
I0802 07:18:22.826527 18636 solver.cpp:375]     Train net output #0: loss = 0.701854 (* 1 = 0.701854 loss)
I0802 07:18:22.826539 18636 sgd_solver.cpp:136] Iteration 57500, lr = 0.00640625, m = 0.9
I0802 07:18:36.797045 18636 solver.cpp:353] Iteration 57600 (7.1581 iter/s, 13.9702s/100 iter), loss = 1.30358
I0802 07:18:36.797072 18636 solver.cpp:375]     Train net output #0: loss = 1.48649 (* 1 = 1.48649 loss)
I0802 07:18:36.797078 18636 sgd_solver.cpp:136] Iteration 57600, lr = 0.0064, m = 0.9
I0802 07:18:50.727118 18636 solver.cpp:353] Iteration 57700 (7.17891 iter/s, 13.9297s/100 iter), loss = 1.34477
I0802 07:18:50.727237 18636 solver.cpp:375]     Train net output #0: loss = 1.43541 (* 1 = 1.43541 loss)
I0802 07:18:50.727244 18636 sgd_solver.cpp:136] Iteration 57700, lr = 0.00639375, m = 0.9
I0802 07:19:04.665344 18636 solver.cpp:353] Iteration 57800 (7.17471 iter/s, 13.9378s/100 iter), loss = 1.6367
I0802 07:19:04.665372 18636 solver.cpp:375]     Train net output #0: loss = 1.57905 (* 1 = 1.57905 loss)
I0802 07:19:04.665376 18636 sgd_solver.cpp:136] Iteration 57800, lr = 0.0063875, m = 0.9
I0802 07:19:18.631595 18636 solver.cpp:353] Iteration 57900 (7.16031 iter/s, 13.9659s/100 iter), loss = 1.56533
I0802 07:19:18.631664 18636 solver.cpp:375]     Train net output #0: loss = 1.47951 (* 1 = 1.47951 loss)
I0802 07:19:18.631676 18636 sgd_solver.cpp:136] Iteration 57900, lr = 0.00638125, m = 0.9
I0802 07:19:32.496054 18636 solver.cpp:404] Sparsity after update:
I0802 07:19:32.502087 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:19:32.502100 18636 net.cpp:2270] conv1a_param_0(0.185) 
I0802 07:19:32.502110 18636 net.cpp:2270] conv1b_param_0(0.375) 
I0802 07:19:32.502113 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:19:32.502116 18636 net.cpp:2270] res2a_branch2a_param_0(0.378) 
I0802 07:19:32.502120 18636 net.cpp:2270] res2a_branch2b_param_0(0.375) 
I0802 07:19:32.502123 18636 net.cpp:2270] res3a_branch2a_param_0(0.378) 
I0802 07:19:32.502127 18636 net.cpp:2270] res3a_branch2b_param_0(0.378) 
I0802 07:19:32.502130 18636 net.cpp:2270] res4a_branch2a_param_0(0.379) 
I0802 07:19:32.502133 18636 net.cpp:2270] res4a_branch2b_param_0(0.378) 
I0802 07:19:32.502136 18636 net.cpp:2270] res5a_branch2a_param_0(0.38) 
I0802 07:19:32.502140 18636 net.cpp:2270] res5a_branch2b_param_0(0.379) 
I0802 07:19:32.502144 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (892998/2.86678e+06) 0.311
I0802 07:19:32.502156 18636 solver.cpp:550] Iteration 58000, Testing net (#0)
I0802 07:19:52.364909 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.571883
I0802 07:19:52.364931 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.80288
I0802 07:19:52.364936 18636 solver.cpp:635]     Test net output #2: loss = 1.89267 (* 1 = 1.89267 loss)
I0802 07:19:52.364965 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8623s
I0802 07:19:52.510557 18661 solver.cpp:450] Finding and applying sparsity: 0.39
I0802 07:20:17.867076 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:20:17.869050 18636 solver.cpp:353] Iteration 58000 (1.68817 iter/s, 59.2359s/100 iter), loss = 1.9683
I0802 07:20:17.869071 18636 solver.cpp:375]     Train net output #0: loss = 1.64893 (* 1 = 1.64893 loss)
I0802 07:20:17.869076 18636 sgd_solver.cpp:136] Iteration 58000, lr = 0.006375, m = 0.9
I0802 07:20:32.372722 18636 solver.cpp:353] Iteration 58100 (6.895 iter/s, 14.5033s/100 iter), loss = 1.11556
I0802 07:20:32.372751 18636 solver.cpp:375]     Train net output #0: loss = 1.34231 (* 1 = 1.34231 loss)
I0802 07:20:32.372756 18636 sgd_solver.cpp:136] Iteration 58100, lr = 0.00636875, m = 0.9
I0802 07:20:46.368193 18636 solver.cpp:353] Iteration 58200 (7.14536 iter/s, 13.9951s/100 iter), loss = 1.48174
I0802 07:20:46.368221 18636 solver.cpp:375]     Train net output #0: loss = 1.41853 (* 1 = 1.41853 loss)
I0802 07:20:46.368227 18636 sgd_solver.cpp:136] Iteration 58200, lr = 0.0063625, m = 0.9
I0802 07:21:00.261178 18636 solver.cpp:353] Iteration 58300 (7.19807 iter/s, 13.8926s/100 iter), loss = 2.0441
I0802 07:21:00.261286 18636 solver.cpp:375]     Train net output #0: loss = 1.95299 (* 1 = 1.95299 loss)
I0802 07:21:00.261301 18636 sgd_solver.cpp:136] Iteration 58300, lr = 0.00635625, m = 0.9
I0802 07:21:14.171640 18636 solver.cpp:353] Iteration 58400 (7.18903 iter/s, 13.9101s/100 iter), loss = 1.54882
I0802 07:21:14.171674 18636 solver.cpp:375]     Train net output #0: loss = 1.74634 (* 1 = 1.74634 loss)
I0802 07:21:14.171679 18636 sgd_solver.cpp:136] Iteration 58400, lr = 0.00635, m = 0.9
I0802 07:21:28.137908 18636 solver.cpp:353] Iteration 58500 (7.16031 iter/s, 13.9659s/100 iter), loss = 1.73519
I0802 07:21:28.137935 18636 solver.cpp:375]     Train net output #0: loss = 1.39208 (* 1 = 1.39208 loss)
I0802 07:21:28.137940 18636 sgd_solver.cpp:136] Iteration 58500, lr = 0.00634375, m = 0.9
I0802 07:21:42.054123 18636 solver.cpp:353] Iteration 58600 (7.18606 iter/s, 13.9158s/100 iter), loss = 1.45902
I0802 07:21:42.054409 18636 solver.cpp:375]     Train net output #0: loss = 1.50557 (* 1 = 1.50557 loss)
I0802 07:21:42.054414 18636 sgd_solver.cpp:136] Iteration 58600, lr = 0.0063375, m = 0.9
I0802 07:21:56.000000 18636 solver.cpp:353] Iteration 58700 (7.17077 iter/s, 13.9455s/100 iter), loss = 1.35255
I0802 07:21:56.000032 18636 solver.cpp:375]     Train net output #0: loss = 1.13265 (* 1 = 1.13265 loss)
I0802 07:21:56.000038 18636 sgd_solver.cpp:136] Iteration 58700, lr = 0.00633125, m = 0.9
I0802 07:22:09.907995 18636 solver.cpp:353] Iteration 58800 (7.19031 iter/s, 13.9076s/100 iter), loss = 1.7962
I0802 07:22:09.908023 18636 solver.cpp:375]     Train net output #0: loss = 1.59622 (* 1 = 1.59622 loss)
I0802 07:22:09.908027 18636 sgd_solver.cpp:136] Iteration 58800, lr = 0.006325, m = 0.9
I0802 07:22:23.843312 18636 solver.cpp:353] Iteration 58900 (7.17621 iter/s, 13.9349s/100 iter), loss = 1.18926
I0802 07:22:23.843391 18636 solver.cpp:375]     Train net output #0: loss = 1.10351 (* 1 = 1.10351 loss)
I0802 07:22:23.843400 18636 sgd_solver.cpp:136] Iteration 58900, lr = 0.00631875, m = 0.9
I0802 07:22:37.648619 18636 solver.cpp:404] Sparsity after update:
I0802 07:22:37.659072 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:22:37.659088 18636 net.cpp:2270] conv1a_param_0(0.186) 
I0802 07:22:37.659097 18636 net.cpp:2270] conv1b_param_0(0.389) 
I0802 07:22:37.659101 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:22:37.659103 18636 net.cpp:2270] res2a_branch2a_param_0(0.389) 
I0802 07:22:37.659106 18636 net.cpp:2270] res2a_branch2b_param_0(0.389) 
I0802 07:22:37.659109 18636 net.cpp:2270] res3a_branch2a_param_0(0.389) 
I0802 07:22:37.659112 18636 net.cpp:2270] res3a_branch2b_param_0(0.389) 
I0802 07:22:37.659116 18636 net.cpp:2270] res4a_branch2a_param_0(0.39) 
I0802 07:22:37.659119 18636 net.cpp:2270] res4a_branch2b_param_0(0.389) 
I0802 07:22:37.659122 18636 net.cpp:2270] res5a_branch2a_param_0(0.39) 
I0802 07:22:37.659126 18636 net.cpp:2270] res5a_branch2b_param_0(0.39) 
I0802 07:22:37.659128 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (917033/2.86678e+06) 0.32
I0802 07:22:37.788271 18661 solver.cpp:450] Finding and applying sparsity: 0.4
I0802 07:23:03.504350 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:23:03.506274 18636 solver.cpp:353] Iteration 59000 (2.52131 iter/s, 39.6619s/100 iter), loss = 1.58673
I0802 07:23:03.506295 18636 solver.cpp:375]     Train net output #0: loss = 2.01155 (* 1 = 2.01155 loss)
I0802 07:23:03.506304 18636 sgd_solver.cpp:136] Iteration 59000, lr = 0.0063125, m = 0.9
I0802 07:23:17.818212 18636 solver.cpp:353] Iteration 59100 (6.98737 iter/s, 14.3115s/100 iter), loss = 1.82313
I0802 07:23:17.818236 18636 solver.cpp:375]     Train net output #0: loss = 1.41825 (* 1 = 1.41825 loss)
I0802 07:23:17.818240 18636 sgd_solver.cpp:136] Iteration 59100, lr = 0.00630625, m = 0.9
I0802 07:23:31.777236 18636 solver.cpp:353] Iteration 59200 (7.16402 iter/s, 13.9586s/100 iter), loss = 1.67298
I0802 07:23:31.777261 18636 solver.cpp:375]     Train net output #0: loss = 1.68318 (* 1 = 1.68318 loss)
I0802 07:23:31.777266 18636 sgd_solver.cpp:136] Iteration 59200, lr = 0.0063, m = 0.9
I0802 07:23:45.659060 18636 solver.cpp:353] Iteration 59300 (7.20386 iter/s, 13.8814s/100 iter), loss = 1.60126
I0802 07:23:45.659137 18636 solver.cpp:375]     Train net output #0: loss = 1.20719 (* 1 = 1.20719 loss)
I0802 07:23:45.659143 18636 sgd_solver.cpp:136] Iteration 59300, lr = 0.00629375, m = 0.9
I0802 07:23:59.618278 18636 solver.cpp:353] Iteration 59400 (7.16392 iter/s, 13.9588s/100 iter), loss = 1.79199
I0802 07:23:59.618304 18636 solver.cpp:375]     Train net output #0: loss = 1.7811 (* 1 = 1.7811 loss)
I0802 07:23:59.618309 18636 sgd_solver.cpp:136] Iteration 59400, lr = 0.0062875, m = 0.9
I0802 07:24:13.583524 18636 solver.cpp:353] Iteration 59500 (7.16083 iter/s, 13.9649s/100 iter), loss = 1.39625
I0802 07:24:13.583559 18636 solver.cpp:375]     Train net output #0: loss = 1.13655 (* 1 = 1.13655 loss)
I0802 07:24:13.583565 18636 sgd_solver.cpp:136] Iteration 59500, lr = 0.00628125, m = 0.9
I0802 07:24:25.753217 18597 data_reader.cpp:264] Starting prefetch of epoch 2
I0802 07:24:27.505362 18636 solver.cpp:353] Iteration 59600 (7.18316 iter/s, 13.9215s/100 iter), loss = 1.55658
I0802 07:24:27.505391 18636 solver.cpp:375]     Train net output #0: loss = 1.56884 (* 1 = 1.56884 loss)
I0802 07:24:27.505396 18636 sgd_solver.cpp:136] Iteration 59600, lr = 0.006275, m = 0.9
I0802 07:24:41.399225 18636 solver.cpp:353] Iteration 59700 (7.19762 iter/s, 13.8935s/100 iter), loss = 1.61404
I0802 07:24:41.399253 18636 solver.cpp:375]     Train net output #0: loss = 1.73803 (* 1 = 1.73803 loss)
I0802 07:24:41.399260 18636 sgd_solver.cpp:136] Iteration 59700, lr = 0.00626875, m = 0.9
I0802 07:24:55.377158 18636 solver.cpp:353] Iteration 59800 (7.15433 iter/s, 13.9776s/100 iter), loss = 1.42022
I0802 07:24:55.377187 18636 solver.cpp:375]     Train net output #0: loss = 1.41593 (* 1 = 1.41593 loss)
I0802 07:24:55.377192 18636 sgd_solver.cpp:136] Iteration 59800, lr = 0.0062625, m = 0.9
I0802 07:25:09.266149 18636 solver.cpp:353] Iteration 59900 (7.20014 iter/s, 13.8886s/100 iter), loss = 1.37849
I0802 07:25:09.266212 18636 solver.cpp:375]     Train net output #0: loss = 1.33551 (* 1 = 1.33551 loss)
I0802 07:25:09.266219 18636 sgd_solver.cpp:136] Iteration 59900, lr = 0.00625625, m = 0.9
I0802 07:25:23.095371 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_60000.caffemodel
I0802 07:25:23.188323 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_60000.solverstate
I0802 07:25:23.194314 18636 solver.cpp:404] Sparsity after update:
I0802 07:25:23.196532 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:25:23.196568 18636 net.cpp:2270] conv1a_param_0(0.186) 
I0802 07:25:23.196589 18636 net.cpp:2270] conv1b_param_0(0.389) 
I0802 07:25:23.196604 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:25:23.196616 18636 net.cpp:2270] res2a_branch2a_param_0(0.399) 
I0802 07:25:23.196630 18636 net.cpp:2270] res2a_branch2b_param_0(0.396) 
I0802 07:25:23.196642 18636 net.cpp:2270] res3a_branch2a_param_0(0.399) 
I0802 07:25:23.196655 18636 net.cpp:2270] res3a_branch2b_param_0(0.399) 
I0802 07:25:23.196667 18636 net.cpp:2270] res4a_branch2a_param_0(0.399) 
I0802 07:25:23.196686 18636 net.cpp:2270] res4a_branch2b_param_0(0.399) 
I0802 07:25:23.196699 18636 net.cpp:2270] res5a_branch2a_param_0(0.4) 
I0802 07:25:23.196713 18636 net.cpp:2270] res5a_branch2b_param_0(0.399) 
I0802 07:25:23.196725 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (940203/2.86678e+06) 0.328
I0802 07:25:23.196748 18636 solver.cpp:550] Iteration 60000, Testing net (#0)
I0802 07:25:34.694542 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:25:42.138268 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.573647
I0802 07:25:42.138358 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808585
I0802 07:25:42.138366 18636 solver.cpp:635]     Test net output #2: loss = 1.86643 (* 1 = 1.86643 loss)
I0802 07:25:42.138386 18636 solver.cpp:305] [MultiGPU] Tests completed in 18.9411s
I0802 07:25:42.275270 18661 solver.cpp:450] Finding and applying sparsity: 0.41
I0802 07:26:08.244931 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:26:08.246879 18636 solver.cpp:353] Iteration 60000 (1.69551 iter/s, 58.9791s/100 iter), loss = 1.6524
I0802 07:26:08.246898 18636 solver.cpp:375]     Train net output #0: loss = 2.182 (* 1 = 2.182 loss)
I0802 07:26:08.246904 18636 sgd_solver.cpp:136] Iteration 60000, lr = 0.00625, m = 0.9
I0802 07:26:22.635092 18636 solver.cpp:353] Iteration 60100 (6.95033 iter/s, 14.3878s/100 iter), loss = 1.60534
I0802 07:26:22.635159 18636 solver.cpp:375]     Train net output #0: loss = 1.46723 (* 1 = 1.46723 loss)
I0802 07:26:22.635166 18636 sgd_solver.cpp:136] Iteration 60100, lr = 0.00624375, m = 0.9
I0802 07:26:36.538588 18636 solver.cpp:353] Iteration 60200 (7.19263 iter/s, 13.9031s/100 iter), loss = 1.4236
I0802 07:26:36.538617 18636 solver.cpp:375]     Train net output #0: loss = 1.2661 (* 1 = 1.2661 loss)
I0802 07:26:36.538624 18636 sgd_solver.cpp:136] Iteration 60200, lr = 0.0062375, m = 0.9
I0802 07:26:50.515405 18636 solver.cpp:353] Iteration 60300 (7.1549 iter/s, 13.9764s/100 iter), loss = 1.30889
I0802 07:26:50.515434 18636 solver.cpp:375]     Train net output #0: loss = 1.24364 (* 1 = 1.24364 loss)
I0802 07:26:50.515439 18636 sgd_solver.cpp:136] Iteration 60300, lr = 0.00623125, m = 0.9
I0802 07:27:04.416568 18636 solver.cpp:353] Iteration 60400 (7.19384 iter/s, 13.9008s/100 iter), loss = 1.58455
I0802 07:27:04.416641 18636 solver.cpp:375]     Train net output #0: loss = 1.67805 (* 1 = 1.67805 loss)
I0802 07:27:04.416651 18636 sgd_solver.cpp:136] Iteration 60400, lr = 0.006225, m = 0.9
I0802 07:27:18.438828 18636 solver.cpp:353] Iteration 60500 (7.13171 iter/s, 14.0219s/100 iter), loss = 1.2347
I0802 07:27:18.438859 18636 solver.cpp:375]     Train net output #0: loss = 0.939074 (* 1 = 0.939074 loss)
I0802 07:27:18.438865 18636 sgd_solver.cpp:136] Iteration 60500, lr = 0.00621875, m = 0.9
I0802 07:27:32.487241 18636 solver.cpp:353] Iteration 60600 (7.11844 iter/s, 14.048s/100 iter), loss = 1.44834
I0802 07:27:32.487269 18636 solver.cpp:375]     Train net output #0: loss = 1.62215 (* 1 = 1.62215 loss)
I0802 07:27:32.487274 18636 sgd_solver.cpp:136] Iteration 60600, lr = 0.0062125, m = 0.9
I0802 07:27:46.488085 18636 solver.cpp:353] Iteration 60700 (7.14262 iter/s, 14.0005s/100 iter), loss = 1.45303
I0802 07:27:46.488144 18636 solver.cpp:375]     Train net output #0: loss = 1.37341 (* 1 = 1.37341 loss)
I0802 07:27:46.488204 18636 sgd_solver.cpp:136] Iteration 60700, lr = 0.00620625, m = 0.9
I0802 07:28:00.472434 18636 solver.cpp:353] Iteration 60800 (7.15104 iter/s, 13.984s/100 iter), loss = 1.43882
I0802 07:28:00.472465 18636 solver.cpp:375]     Train net output #0: loss = 1.62144 (* 1 = 1.62144 loss)
I0802 07:28:00.472471 18636 sgd_solver.cpp:136] Iteration 60800, lr = 0.0062, m = 0.9
I0802 07:28:14.364140 18636 solver.cpp:353] Iteration 60900 (7.19874 iter/s, 13.8913s/100 iter), loss = 1.70264
I0802 07:28:14.364166 18636 solver.cpp:375]     Train net output #0: loss = 1.58483 (* 1 = 1.58483 loss)
I0802 07:28:14.364171 18636 sgd_solver.cpp:136] Iteration 60900, lr = 0.00619375, m = 0.9
I0802 07:28:28.217761 18636 solver.cpp:404] Sparsity after update:
I0802 07:28:28.229600 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:28:28.229795 18636 net.cpp:2270] conv1a_param_0(0.199) 
I0802 07:28:28.229904 18636 net.cpp:2270] conv1b_param_0(0.403) 
I0802 07:28:28.230002 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:28:28.230093 18636 net.cpp:2270] res2a_branch2a_param_0(0.41) 
I0802 07:28:28.230185 18636 net.cpp:2270] res2a_branch2b_param_0(0.41) 
I0802 07:28:28.230279 18636 net.cpp:2270] res3a_branch2a_param_0(0.41) 
I0802 07:28:28.230376 18636 net.cpp:2270] res3a_branch2b_param_0(0.41) 
I0802 07:28:28.230469 18636 net.cpp:2270] res4a_branch2a_param_0(0.41) 
I0802 07:28:28.230554 18636 net.cpp:2270] res4a_branch2b_param_0(0.41) 
I0802 07:28:28.230638 18636 net.cpp:2270] res5a_branch2a_param_0(0.41) 
I0802 07:28:28.230721 18636 net.cpp:2270] res5a_branch2b_param_0(0.41) 
I0802 07:28:28.230811 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (964266/2.86678e+06) 0.336
I0802 07:28:28.369887 18661 solver.cpp:450] Finding and applying sparsity: 0.42
I0802 07:28:54.771836 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:28:54.773711 18636 solver.cpp:353] Iteration 61000 (2.47473 iter/s, 40.4085s/100 iter), loss = 1.51899
I0802 07:28:54.773730 18636 solver.cpp:375]     Train net output #0: loss = 1.56803 (* 1 = 1.56803 loss)
I0802 07:28:54.773736 18636 sgd_solver.cpp:136] Iteration 61000, lr = 0.0061875, m = 0.9
I0802 07:29:09.331300 18636 solver.cpp:353] Iteration 61100 (6.86946 iter/s, 14.5572s/100 iter), loss = 1.2902
I0802 07:29:09.331394 18636 solver.cpp:375]     Train net output #0: loss = 1.00981 (* 1 = 1.00981 loss)
I0802 07:29:09.331583 18636 sgd_solver.cpp:136] Iteration 61100, lr = 0.00618125, m = 0.9
I0802 07:29:23.309799 18636 solver.cpp:353] Iteration 61200 (7.15404 iter/s, 13.9781s/100 iter), loss = 1.32224
I0802 07:29:23.309828 18636 solver.cpp:375]     Train net output #0: loss = 1.70577 (* 1 = 1.70577 loss)
I0802 07:29:23.309834 18636 sgd_solver.cpp:136] Iteration 61200, lr = 0.006175, m = 0.9
I0802 07:29:37.291540 18636 solver.cpp:353] Iteration 61300 (7.15238 iter/s, 13.9814s/100 iter), loss = 1.81624
I0802 07:29:37.291570 18636 solver.cpp:375]     Train net output #0: loss = 1.75867 (* 1 = 1.75867 loss)
I0802 07:29:37.291574 18636 sgd_solver.cpp:136] Iteration 61300, lr = 0.00616875, m = 0.9
I0802 07:29:51.237061 18636 solver.cpp:353] Iteration 61400 (7.17096 iter/s, 13.9451s/100 iter), loss = 1.32494
I0802 07:29:51.237149 18636 solver.cpp:375]     Train net output #0: loss = 1.58517 (* 1 = 1.58517 loss)
I0802 07:29:51.237156 18636 sgd_solver.cpp:136] Iteration 61400, lr = 0.0061625, m = 0.9
I0802 07:30:05.254897 18636 solver.cpp:353] Iteration 61500 (7.13396 iter/s, 14.0175s/100 iter), loss = 1.35415
I0802 07:30:05.254922 18636 solver.cpp:375]     Train net output #0: loss = 1.24216 (* 1 = 1.24216 loss)
I0802 07:30:05.254926 18636 sgd_solver.cpp:136] Iteration 61500, lr = 0.00615625, m = 0.9
I0802 07:30:19.212620 18636 solver.cpp:353] Iteration 61600 (7.16469 iter/s, 13.9573s/100 iter), loss = 1.22835
I0802 07:30:19.212646 18636 solver.cpp:375]     Train net output #0: loss = 1.12502 (* 1 = 1.12502 loss)
I0802 07:30:19.212652 18636 sgd_solver.cpp:136] Iteration 61600, lr = 0.00615, m = 0.9
I0802 07:30:33.032500 18636 solver.cpp:353] Iteration 61700 (7.23615 iter/s, 13.8195s/100 iter), loss = 1.51404
I0802 07:30:33.032586 18636 solver.cpp:375]     Train net output #0: loss = 1.42565 (* 1 = 1.42565 loss)
I0802 07:30:33.032593 18636 sgd_solver.cpp:136] Iteration 61700, lr = 0.00614375, m = 0.9
I0802 07:30:47.092478 18636 solver.cpp:353] Iteration 61800 (7.11258 iter/s, 14.0596s/100 iter), loss = 1.20981
I0802 07:30:47.092502 18636 solver.cpp:375]     Train net output #0: loss = 1.22027 (* 1 = 1.22027 loss)
I0802 07:30:47.092509 18636 sgd_solver.cpp:136] Iteration 61800, lr = 0.0061375, m = 0.9
I0802 07:31:01.112046 18636 solver.cpp:353] Iteration 61900 (7.13308 iter/s, 14.0192s/100 iter), loss = 1.63269
I0802 07:31:01.112072 18636 solver.cpp:375]     Train net output #0: loss = 1.35717 (* 1 = 1.35717 loss)
I0802 07:31:01.112077 18636 sgd_solver.cpp:136] Iteration 61900, lr = 0.00613125, m = 0.9
I0802 07:31:14.922338 18636 solver.cpp:404] Sparsity after update:
I0802 07:31:14.928143 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:31:14.928153 18636 net.cpp:2270] conv1a_param_0(0.199) 
I0802 07:31:14.928161 18636 net.cpp:2270] conv1b_param_0(0.417) 
I0802 07:31:14.928165 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:31:14.928170 18636 net.cpp:2270] res2a_branch2a_param_0(0.417) 
I0802 07:31:14.928174 18636 net.cpp:2270] res2a_branch2b_param_0(0.417) 
I0802 07:31:14.928177 18636 net.cpp:2270] res3a_branch2a_param_0(0.418) 
I0802 07:31:14.928180 18636 net.cpp:2270] res3a_branch2b_param_0(0.417) 
I0802 07:31:14.928184 18636 net.cpp:2270] res4a_branch2a_param_0(0.419) 
I0802 07:31:14.928186 18636 net.cpp:2270] res4a_branch2b_param_0(0.418) 
I0802 07:31:14.928189 18636 net.cpp:2270] res5a_branch2a_param_0(0.42) 
I0802 07:31:14.928192 18636 net.cpp:2270] res5a_branch2b_param_0(0.419) 
I0802 07:31:14.928194 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (986896/2.86678e+06) 0.344
I0802 07:31:14.928206 18636 solver.cpp:550] Iteration 62000, Testing net (#0)
I0802 07:31:34.498687 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.573588
I0802 07:31:34.498759 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.806173
I0802 07:31:34.498778 18636 solver.cpp:635]     Test net output #2: loss = 1.86024 (* 1 = 1.86024 loss)
I0802 07:31:34.498811 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5701s
I0802 07:31:34.657292 18661 solver.cpp:450] Finding and applying sparsity: 0.43
I0802 07:32:01.193218 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:32:01.195147 18636 solver.cpp:353] Iteration 62000 (1.66441 iter/s, 60.0815s/100 iter), loss = 1.55012
I0802 07:32:01.195163 18636 solver.cpp:375]     Train net output #0: loss = 1.60266 (* 1 = 1.60266 loss)
I0802 07:32:01.195168 18636 sgd_solver.cpp:136] Iteration 62000, lr = 0.006125, m = 0.9
I0802 07:32:15.532398 18636 solver.cpp:353] Iteration 62100 (6.97503 iter/s, 14.3369s/100 iter), loss = 1.54202
I0802 07:32:15.532425 18636 solver.cpp:375]     Train net output #0: loss = 1.62652 (* 1 = 1.62652 loss)
I0802 07:32:15.532433 18636 sgd_solver.cpp:136] Iteration 62100, lr = 0.00611875, m = 0.9
I0802 07:32:29.390271 18636 solver.cpp:353] Iteration 62200 (7.21631 iter/s, 13.8575s/100 iter), loss = 1.36603
I0802 07:32:29.390298 18636 solver.cpp:375]     Train net output #0: loss = 1.47057 (* 1 = 1.47057 loss)
I0802 07:32:29.390303 18636 sgd_solver.cpp:136] Iteration 62200, lr = 0.0061125, m = 0.9
I0802 07:32:43.244763 18636 solver.cpp:353] Iteration 62300 (7.21807 iter/s, 13.8541s/100 iter), loss = 1.68403
I0802 07:32:43.244841 18636 solver.cpp:375]     Train net output #0: loss = 2.08293 (* 1 = 2.08293 loss)
I0802 07:32:43.244848 18636 sgd_solver.cpp:136] Iteration 62300, lr = 0.00610625, m = 0.9
I0802 07:32:57.196967 18636 solver.cpp:353] Iteration 62400 (7.16752 iter/s, 13.9518s/100 iter), loss = 1.46694
I0802 07:32:57.196992 18636 solver.cpp:375]     Train net output #0: loss = 1.3099 (* 1 = 1.3099 loss)
I0802 07:32:57.196996 18636 sgd_solver.cpp:136] Iteration 62400, lr = 0.0061, m = 0.9
I0802 07:33:11.056821 18636 solver.cpp:353] Iteration 62500 (7.21528 iter/s, 13.8595s/100 iter), loss = 1.49256
I0802 07:33:11.056913 18636 solver.cpp:375]     Train net output #0: loss = 1.3796 (* 1 = 1.3796 loss)
I0802 07:33:11.056932 18636 sgd_solver.cpp:136] Iteration 62500, lr = 0.00609375, m = 0.9
I0802 07:33:24.968339 18636 solver.cpp:353] Iteration 62600 (7.18848 iter/s, 13.9111s/100 iter), loss = 1.18628
I0802 07:33:24.968418 18636 solver.cpp:375]     Train net output #0: loss = 0.907872 (* 1 = 0.907872 loss)
I0802 07:33:24.968423 18636 sgd_solver.cpp:136] Iteration 62600, lr = 0.0060875, m = 0.9
I0802 07:33:38.861438 18636 solver.cpp:353] Iteration 62700 (7.19801 iter/s, 13.8927s/100 iter), loss = 1.31757
I0802 07:33:38.861464 18636 solver.cpp:375]     Train net output #0: loss = 1.6144 (* 1 = 1.6144 loss)
I0802 07:33:38.861469 18636 sgd_solver.cpp:136] Iteration 62700, lr = 0.00608125, m = 0.9
I0802 07:33:52.727260 18636 solver.cpp:353] Iteration 62800 (7.21217 iter/s, 13.8654s/100 iter), loss = 1.66265
I0802 07:33:52.727286 18636 solver.cpp:375]     Train net output #0: loss = 1.77026 (* 1 = 1.77026 loss)
I0802 07:33:52.727293 18636 sgd_solver.cpp:136] Iteration 62800, lr = 0.006075, m = 0.9
I0802 07:34:06.641360 18636 solver.cpp:353] Iteration 62900 (7.18715 iter/s, 13.9137s/100 iter), loss = 1.51339
I0802 07:34:06.641417 18636 solver.cpp:375]     Train net output #0: loss = 1.48016 (* 1 = 1.48016 loss)
I0802 07:34:06.641423 18636 sgd_solver.cpp:136] Iteration 62900, lr = 0.00606875, m = 0.9
I0802 07:34:20.367535 18636 solver.cpp:404] Sparsity after update:
I0802 07:34:20.380069 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:34:20.380102 18636 net.cpp:2270] conv1a_param_0(0.212) 
I0802 07:34:20.380117 18636 net.cpp:2270] conv1b_param_0(0.417) 
I0802 07:34:20.380125 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:34:20.380136 18636 net.cpp:2270] res2a_branch2a_param_0(0.427) 
I0802 07:34:20.380151 18636 net.cpp:2270] res2a_branch2b_param_0(0.424) 
I0802 07:34:20.380162 18636 net.cpp:2270] res3a_branch2a_param_0(0.429) 
I0802 07:34:20.380165 18636 net.cpp:2270] res3a_branch2b_param_0(0.427) 
I0802 07:34:20.380169 18636 net.cpp:2270] res4a_branch2a_param_0(0.43) 
I0802 07:34:20.380173 18636 net.cpp:2270] res4a_branch2b_param_0(0.429) 
I0802 07:34:20.380177 18636 net.cpp:2270] res5a_branch2a_param_0(0.43) 
I0802 07:34:20.380180 18636 net.cpp:2270] res5a_branch2b_param_0(0.43) 
I0802 07:34:20.380183 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.01086e+06/2.86678e+06) 0.353
I0802 07:34:20.510294 18661 solver.cpp:450] Finding and applying sparsity: 0.44
I0802 07:34:47.579383 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:34:47.581336 18636 solver.cpp:353] Iteration 63000 (2.44267 iter/s, 40.9389s/100 iter), loss = 1.48433
I0802 07:34:47.581360 18636 solver.cpp:375]     Train net output #0: loss = 1.06015 (* 1 = 1.06015 loss)
I0802 07:34:47.581370 18636 sgd_solver.cpp:136] Iteration 63000, lr = 0.0060625, m = 0.9
I0802 07:35:02.037474 18636 solver.cpp:353] Iteration 63100 (6.91767 iter/s, 14.4557s/100 iter), loss = 1.71332
I0802 07:35:02.037499 18636 solver.cpp:375]     Train net output #0: loss = 1.39971 (* 1 = 1.39971 loss)
I0802 07:35:02.037504 18636 sgd_solver.cpp:136] Iteration 63100, lr = 0.00605625, m = 0.9
I0802 07:35:15.907038 18636 solver.cpp:353] Iteration 63200 (7.21023 iter/s, 13.8692s/100 iter), loss = 1.48834
I0802 07:35:15.907068 18636 solver.cpp:375]     Train net output #0: loss = 1.43662 (* 1 = 1.43662 loss)
I0802 07:35:15.907073 18636 sgd_solver.cpp:136] Iteration 63200, lr = 0.00605, m = 0.9
I0802 07:35:29.842914 18636 solver.cpp:353] Iteration 63300 (7.17592 iter/s, 13.9355s/100 iter), loss = 1.32188
I0802 07:35:29.843008 18636 solver.cpp:375]     Train net output #0: loss = 1.2824 (* 1 = 1.2824 loss)
I0802 07:35:29.843016 18636 sgd_solver.cpp:136] Iteration 63300, lr = 0.00604375, m = 0.9
I0802 07:35:43.713835 18636 solver.cpp:353] Iteration 63400 (7.20953 iter/s, 13.8705s/100 iter), loss = 1.21602
I0802 07:35:43.714102 18636 solver.cpp:375]     Train net output #0: loss = 1.38435 (* 1 = 1.38435 loss)
I0802 07:35:43.714213 18636 sgd_solver.cpp:136] Iteration 63400, lr = 0.0060375, m = 0.9
I0802 07:35:57.593972 18636 solver.cpp:353] Iteration 63500 (7.20474 iter/s, 13.8798s/100 iter), loss = 1.33337
I0802 07:35:57.594000 18636 solver.cpp:375]     Train net output #0: loss = 1.40573 (* 1 = 1.40573 loss)
I0802 07:35:57.594007 18636 sgd_solver.cpp:136] Iteration 63500, lr = 0.00603125, m = 0.9
I0802 07:36:11.519785 18636 solver.cpp:353] Iteration 63600 (7.18111 iter/s, 13.9254s/100 iter), loss = 1.79018
I0802 07:36:11.520062 18636 solver.cpp:375]     Train net output #0: loss = 1.78139 (* 1 = 1.78139 loss)
I0802 07:36:11.520174 18636 sgd_solver.cpp:136] Iteration 63600, lr = 0.006025, m = 0.9
I0802 07:36:25.375258 18636 solver.cpp:353] Iteration 63700 (7.21756 iter/s, 13.8551s/100 iter), loss = 1.50495
I0802 07:36:25.375291 18636 solver.cpp:375]     Train net output #0: loss = 1.46092 (* 1 = 1.46092 loss)
I0802 07:36:25.375344 18636 sgd_solver.cpp:136] Iteration 63700, lr = 0.00601875, m = 0.9
I0802 07:36:39.428907 18636 solver.cpp:353] Iteration 63800 (7.11578 iter/s, 14.0533s/100 iter), loss = 1.16023
I0802 07:36:39.428935 18636 solver.cpp:375]     Train net output #0: loss = 1.18778 (* 1 = 1.18778 loss)
I0802 07:36:39.428941 18636 sgd_solver.cpp:136] Iteration 63800, lr = 0.0060125, m = 0.9
I0802 07:36:53.380240 18636 solver.cpp:353] Iteration 63900 (7.16797 iter/s, 13.951s/100 iter), loss = 1.42845
I0802 07:36:53.380313 18636 solver.cpp:375]     Train net output #0: loss = 1.46941 (* 1 = 1.46941 loss)
I0802 07:36:53.380319 18636 sgd_solver.cpp:136] Iteration 63900, lr = 0.00600625, m = 0.9
I0802 07:37:07.144001 18636 solver.cpp:404] Sparsity after update:
I0802 07:37:07.148421 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:37:07.148430 18636 net.cpp:2270] conv1a_param_0(0.213) 
I0802 07:37:07.148437 18636 net.cpp:2270] conv1b_param_0(0.431) 
I0802 07:37:07.148439 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:37:07.148442 18636 net.cpp:2270] res2a_branch2a_param_0(0.438) 
I0802 07:37:07.148443 18636 net.cpp:2270] res2a_branch2b_param_0(0.438) 
I0802 07:37:07.148447 18636 net.cpp:2270] res3a_branch2a_param_0(0.439) 
I0802 07:37:07.148449 18636 net.cpp:2270] res3a_branch2b_param_0(0.438) 
I0802 07:37:07.148452 18636 net.cpp:2270] res4a_branch2a_param_0(0.439) 
I0802 07:37:07.148453 18636 net.cpp:2270] res4a_branch2b_param_0(0.439) 
I0802 07:37:07.148455 18636 net.cpp:2270] res5a_branch2a_param_0(0.44) 
I0802 07:37:07.148458 18636 net.cpp:2270] res5a_branch2b_param_0(0.439) 
I0802 07:37:07.148459 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.03413e+06/2.86678e+06) 0.361
I0802 07:37:07.148468 18636 solver.cpp:550] Iteration 64000, Testing net (#0)
I0802 07:37:26.668401 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.572882
I0802 07:37:26.668512 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808115
I0802 07:37:26.668522 18636 solver.cpp:635]     Test net output #2: loss = 1.86762 (* 1 = 1.86762 loss)
I0802 07:37:26.668541 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5195s
I0802 07:37:26.806454 18661 solver.cpp:450] Finding and applying sparsity: 0.45
I0802 07:37:54.447587 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:37:54.449483 18636 solver.cpp:353] Iteration 64000 (1.63753 iter/s, 61.0676s/100 iter), loss = 1.36541
I0802 07:37:54.449501 18636 solver.cpp:375]     Train net output #0: loss = 1.75363 (* 1 = 1.75363 loss)
I0802 07:37:54.449508 18636 sgd_solver.cpp:136] Iteration 64000, lr = 0.006, m = 0.9
I0802 07:38:08.843225 18636 solver.cpp:353] Iteration 64100 (6.94766 iter/s, 14.3933s/100 iter), loss = 1.53945
I0802 07:38:08.852936 18636 solver.cpp:375]     Train net output #0: loss = 1.14346 (* 1 = 1.14346 loss)
I0802 07:38:08.852963 18636 sgd_solver.cpp:136] Iteration 64100, lr = 0.00599375, m = 0.9
I0802 07:38:22.830160 18636 solver.cpp:353] Iteration 64200 (7.14973 iter/s, 13.9865s/100 iter), loss = 1.25985
I0802 07:38:22.830185 18636 solver.cpp:375]     Train net output #0: loss = 1.31094 (* 1 = 1.31094 loss)
I0802 07:38:22.830190 18636 sgd_solver.cpp:136] Iteration 64200, lr = 0.0059875, m = 0.9
I0802 07:38:36.765686 18636 solver.cpp:353] Iteration 64300 (7.1761 iter/s, 13.9351s/100 iter), loss = 1.51629
I0802 07:38:36.765719 18636 solver.cpp:375]     Train net output #0: loss = 1.67176 (* 1 = 1.67176 loss)
I0802 07:38:36.765727 18636 sgd_solver.cpp:136] Iteration 64300, lr = 0.00598125, m = 0.9
I0802 07:38:50.706857 18636 solver.cpp:353] Iteration 64400 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.4062
I0802 07:38:50.706940 18636 solver.cpp:375]     Train net output #0: loss = 1.33929 (* 1 = 1.33929 loss)
I0802 07:38:50.706954 18636 sgd_solver.cpp:136] Iteration 64400, lr = 0.005975, m = 0.9
I0802 07:39:04.572878 18636 solver.cpp:353] Iteration 64500 (7.21208 iter/s, 13.8656s/100 iter), loss = 1.01918
I0802 07:39:04.572911 18636 solver.cpp:375]     Train net output #0: loss = 1.27415 (* 1 = 1.27415 loss)
I0802 07:39:04.572917 18636 sgd_solver.cpp:136] Iteration 64500, lr = 0.00596875, m = 0.9
I0802 07:39:18.445140 18636 solver.cpp:353] Iteration 64600 (7.20883 iter/s, 13.8719s/100 iter), loss = 1.85363
I0802 07:39:18.445169 18636 solver.cpp:375]     Train net output #0: loss = 1.96038 (* 1 = 1.96038 loss)
I0802 07:39:18.445175 18636 sgd_solver.cpp:136] Iteration 64600, lr = 0.0059625, m = 0.9
I0802 07:39:32.342420 18636 solver.cpp:353] Iteration 64700 (7.19585 iter/s, 13.8969s/100 iter), loss = 1.74791
I0802 07:39:32.342519 18636 solver.cpp:375]     Train net output #0: loss = 1.77092 (* 1 = 1.77092 loss)
I0802 07:39:32.342523 18636 sgd_solver.cpp:136] Iteration 64700, lr = 0.00595625, m = 0.9
I0802 07:39:46.279719 18636 solver.cpp:353] Iteration 64800 (7.17519 iter/s, 13.9369s/100 iter), loss = 1.80771
I0802 07:39:46.279749 18636 solver.cpp:375]     Train net output #0: loss = 1.77105 (* 1 = 1.77105 loss)
I0802 07:39:46.279755 18636 sgd_solver.cpp:136] Iteration 64800, lr = 0.00595, m = 0.9
I0802 07:40:00.151794 18636 solver.cpp:353] Iteration 64900 (7.20892 iter/s, 13.8717s/100 iter), loss = 1.43673
I0802 07:40:00.151823 18636 solver.cpp:375]     Train net output #0: loss = 1.46238 (* 1 = 1.46238 loss)
I0802 07:40:00.151829 18636 sgd_solver.cpp:136] Iteration 64900, lr = 0.00594375, m = 0.9
I0802 07:40:13.992605 18636 solver.cpp:404] Sparsity after update:
I0802 07:40:14.003777 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:40:14.003792 18636 net.cpp:2270] conv1a_param_0(0.213) 
I0802 07:40:14.003800 18636 net.cpp:2270] conv1b_param_0(0.444) 
I0802 07:40:14.003803 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:40:14.003808 18636 net.cpp:2270] res2a_branch2a_param_0(0.448) 
I0802 07:40:14.003810 18636 net.cpp:2270] res2a_branch2b_param_0(0.444) 
I0802 07:40:14.003813 18636 net.cpp:2270] res3a_branch2a_param_0(0.45) 
I0802 07:40:14.003816 18636 net.cpp:2270] res3a_branch2b_param_0(0.448) 
I0802 07:40:14.003819 18636 net.cpp:2270] res4a_branch2a_param_0(0.45) 
I0802 07:40:14.003823 18636 net.cpp:2270] res4a_branch2b_param_0(0.45) 
I0802 07:40:14.003852 18636 net.cpp:2270] res5a_branch2a_param_0(0.45) 
I0802 07:40:14.003865 18636 net.cpp:2270] res5a_branch2b_param_0(0.45) 
I0802 07:40:14.003875 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.0581e+06/2.86678e+06) 0.369
I0802 07:40:14.135583 18661 solver.cpp:450] Finding and applying sparsity: 0.46
I0802 07:40:42.461403 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:40:42.463345 18636 solver.cpp:353] Iteration 65000 (2.36349 iter/s, 42.3104s/100 iter), loss = 1.16467
I0802 07:40:42.463362 18636 solver.cpp:375]     Train net output #0: loss = 1.23418 (* 1 = 1.23418 loss)
I0802 07:40:42.463368 18636 sgd_solver.cpp:136] Iteration 65000, lr = 0.0059375, m = 0.9
I0802 07:40:56.910101 18636 solver.cpp:353] Iteration 65100 (6.92216 iter/s, 14.4464s/100 iter), loss = 1.26144
I0802 07:40:56.910163 18636 solver.cpp:375]     Train net output #0: loss = 1.27404 (* 1 = 1.27404 loss)
I0802 07:40:56.910169 18636 sgd_solver.cpp:136] Iteration 65100, lr = 0.00593125, m = 0.9
I0802 07:41:10.783941 18636 solver.cpp:353] Iteration 65200 (7.20801 iter/s, 13.8735s/100 iter), loss = 1.57076
I0802 07:41:10.783970 18636 solver.cpp:375]     Train net output #0: loss = 1.53381 (* 1 = 1.53381 loss)
I0802 07:41:10.783977 18636 sgd_solver.cpp:136] Iteration 65200, lr = 0.005925, m = 0.9
I0802 07:41:24.717042 18636 solver.cpp:353] Iteration 65300 (7.17735 iter/s, 13.9327s/100 iter), loss = 1.33193
I0802 07:41:24.717075 18636 solver.cpp:375]     Train net output #0: loss = 1.58152 (* 1 = 1.58152 loss)
I0802 07:41:24.717082 18636 sgd_solver.cpp:136] Iteration 65300, lr = 0.00591875, m = 0.9
I0802 07:41:38.697914 18636 solver.cpp:353] Iteration 65400 (7.15283 iter/s, 13.9805s/100 iter), loss = 1.39541
I0802 07:41:38.697963 18636 solver.cpp:375]     Train net output #0: loss = 1.71016 (* 1 = 1.71016 loss)
I0802 07:41:38.697968 18636 sgd_solver.cpp:136] Iteration 65400, lr = 0.0059125, m = 0.9
I0802 07:41:52.639107 18636 solver.cpp:353] Iteration 65500 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.15582
I0802 07:41:52.639135 18636 solver.cpp:375]     Train net output #0: loss = 1.03702 (* 1 = 1.03702 loss)
I0802 07:41:52.639415 18636 sgd_solver.cpp:136] Iteration 65500, lr = 0.00590625, m = 0.9
I0802 07:42:06.594452 18636 solver.cpp:353] Iteration 65600 (7.16591 iter/s, 13.955s/100 iter), loss = 1.53059
I0802 07:42:06.594477 18636 solver.cpp:375]     Train net output #0: loss = 1.31113 (* 1 = 1.31113 loss)
I0802 07:42:06.594483 18636 sgd_solver.cpp:136] Iteration 65600, lr = 0.0059, m = 0.9
I0802 07:42:20.539932 18636 solver.cpp:353] Iteration 65700 (7.17098 iter/s, 13.9451s/100 iter), loss = 1.4122
I0802 07:42:20.540002 18636 solver.cpp:375]     Train net output #0: loss = 1.21928 (* 1 = 1.21928 loss)
I0802 07:42:20.540007 18636 sgd_solver.cpp:136] Iteration 65700, lr = 0.00589375, m = 0.9
I0802 07:42:34.437901 18636 solver.cpp:353] Iteration 65800 (7.19549 iter/s, 13.8976s/100 iter), loss = 1.35234
I0802 07:42:34.437930 18636 solver.cpp:375]     Train net output #0: loss = 1.214 (* 1 = 1.214 loss)
I0802 07:42:34.437935 18636 sgd_solver.cpp:136] Iteration 65800, lr = 0.0058875, m = 0.9
I0802 07:42:48.459800 18636 solver.cpp:353] Iteration 65900 (7.1319 iter/s, 14.0215s/100 iter), loss = 1.74007
I0802 07:42:48.459825 18636 solver.cpp:375]     Train net output #0: loss = 2.22475 (* 1 = 2.22475 loss)
I0802 07:42:48.459830 18636 sgd_solver.cpp:136] Iteration 65900, lr = 0.00588125, m = 0.9
I0802 07:43:02.388413 18636 solver.cpp:404] Sparsity after update:
I0802 07:43:02.392331 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:43:02.392341 18636 net.cpp:2270] conv1a_param_0(0.225) 
I0802 07:43:02.392349 18636 net.cpp:2270] conv1b_param_0(0.458) 
I0802 07:43:02.392350 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:43:02.392352 18636 net.cpp:2270] res2a_branch2a_param_0(0.458) 
I0802 07:43:02.392354 18636 net.cpp:2270] res2a_branch2b_param_0(0.458) 
I0802 07:43:02.392356 18636 net.cpp:2270] res3a_branch2a_param_0(0.458) 
I0802 07:43:02.392359 18636 net.cpp:2270] res3a_branch2b_param_0(0.458) 
I0802 07:43:02.392360 18636 net.cpp:2270] res4a_branch2a_param_0(0.459) 
I0802 07:43:02.392362 18636 net.cpp:2270] res4a_branch2b_param_0(0.458) 
I0802 07:43:02.392364 18636 net.cpp:2270] res5a_branch2a_param_0(0.46) 
I0802 07:43:02.392365 18636 net.cpp:2270] res5a_branch2b_param_0(0.459) 
I0802 07:43:02.392367 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.081e+06/2.86678e+06) 0.377
I0802 07:43:02.392376 18636 solver.cpp:550] Iteration 66000, Testing net (#0)
I0802 07:43:19.925297 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 07:43:22.088539 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.567412
I0802 07:43:22.088567 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.798998
I0802 07:43:22.088574 18636 solver.cpp:635]     Test net output #2: loss = 1.89731 (* 1 = 1.89731 loss)
I0802 07:43:22.088639 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6957s
I0802 07:43:22.228395 18661 solver.cpp:450] Finding and applying sparsity: 0.47
I0802 07:43:51.233933 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:43:51.236095 18636 solver.cpp:353] Iteration 66000 (1.593 iter/s, 62.7746s/100 iter), loss = 1.58217
I0802 07:43:51.236132 18636 solver.cpp:375]     Train net output #0: loss = 1.61546 (* 1 = 1.61546 loss)
I0802 07:43:51.236141 18636 sgd_solver.cpp:136] Iteration 66000, lr = 0.005875, m = 0.9
I0802 07:44:05.639430 18636 solver.cpp:353] Iteration 66100 (6.94303 iter/s, 14.4029s/100 iter), loss = 1.32567
I0802 07:44:05.639457 18636 solver.cpp:375]     Train net output #0: loss = 1.08699 (* 1 = 1.08699 loss)
I0802 07:44:05.639461 18636 sgd_solver.cpp:136] Iteration 66100, lr = 0.00586875, m = 0.9
I0802 07:44:19.564285 18636 solver.cpp:353] Iteration 66200 (7.1816 iter/s, 13.9245s/100 iter), loss = 1.39844
I0802 07:44:19.564312 18636 solver.cpp:375]     Train net output #0: loss = 1.82646 (* 1 = 1.82646 loss)
I0802 07:44:19.564318 18636 sgd_solver.cpp:136] Iteration 66200, lr = 0.0058625, m = 0.9
I0802 07:44:33.565402 18636 solver.cpp:353] Iteration 66300 (7.14249 iter/s, 14.0007s/100 iter), loss = 1.68865
I0802 07:44:33.565546 18636 solver.cpp:375]     Train net output #0: loss = 1.5466 (* 1 = 1.5466 loss)
I0802 07:44:33.565567 18636 sgd_solver.cpp:136] Iteration 66300, lr = 0.00585625, m = 0.9
I0802 07:44:47.489442 18636 solver.cpp:353] Iteration 66400 (7.18202 iter/s, 13.9237s/100 iter), loss = 1.25565
I0802 07:44:47.489467 18636 solver.cpp:375]     Train net output #0: loss = 1.27664 (* 1 = 1.27664 loss)
I0802 07:44:47.489472 18636 sgd_solver.cpp:136] Iteration 66400, lr = 0.00585, m = 0.9
I0802 07:45:01.363088 18636 solver.cpp:353] Iteration 66500 (7.20811 iter/s, 13.8733s/100 iter), loss = 1.49215
I0802 07:45:01.363143 18636 solver.cpp:375]     Train net output #0: loss = 1.48417 (* 1 = 1.48417 loss)
I0802 07:45:01.363158 18636 sgd_solver.cpp:136] Iteration 66500, lr = 0.00584375, m = 0.9
I0802 07:45:15.423049 18636 solver.cpp:353] Iteration 66600 (7.11259 iter/s, 14.0596s/100 iter), loss = 1.08526
I0802 07:45:15.423125 18636 solver.cpp:375]     Train net output #0: loss = 1.19209 (* 1 = 1.19209 loss)
I0802 07:45:15.423130 18636 sgd_solver.cpp:136] Iteration 66600, lr = 0.0058375, m = 0.9
I0802 07:45:29.377828 18636 solver.cpp:353] Iteration 66700 (7.1662 iter/s, 13.9544s/100 iter), loss = 1.60817
I0802 07:45:29.377939 18636 solver.cpp:375]     Train net output #0: loss = 1.39533 (* 1 = 1.39533 loss)
I0802 07:45:29.377964 18636 sgd_solver.cpp:136] Iteration 66700, lr = 0.00583125, m = 0.9
I0802 07:45:43.244518 18636 solver.cpp:353] Iteration 66800 (7.21172 iter/s, 13.8663s/100 iter), loss = 1.16151
I0802 07:45:43.244612 18636 solver.cpp:375]     Train net output #0: loss = 0.982587 (* 1 = 0.982587 loss)
I0802 07:45:43.244632 18636 sgd_solver.cpp:136] Iteration 66800, lr = 0.005825, m = 0.9
I0802 07:45:57.263063 18636 solver.cpp:353] Iteration 66900 (7.1336 iter/s, 14.0182s/100 iter), loss = 1.52456
I0802 07:45:57.263126 18636 solver.cpp:375]     Train net output #0: loss = 1.42058 (* 1 = 1.42058 loss)
I0802 07:45:57.263131 18636 sgd_solver.cpp:136] Iteration 66900, lr = 0.00581875, m = 0.9
I0802 07:46:11.140434 18636 solver.cpp:404] Sparsity after update:
I0802 07:46:11.153281 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:46:11.153314 18636 net.cpp:2270] conv1a_param_0(0.225) 
I0802 07:46:11.153329 18636 net.cpp:2270] conv1b_param_0(0.458) 
I0802 07:46:11.153337 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:46:11.153345 18636 net.cpp:2270] res2a_branch2a_param_0(0.469) 
I0802 07:46:11.153359 18636 net.cpp:2270] res2a_branch2b_param_0(0.465) 
I0802 07:46:11.153368 18636 net.cpp:2270] res3a_branch2a_param_0(0.469) 
I0802 07:46:11.153376 18636 net.cpp:2270] res3a_branch2b_param_0(0.469) 
I0802 07:46:11.153386 18636 net.cpp:2270] res4a_branch2a_param_0(0.47) 
I0802 07:46:11.153393 18636 net.cpp:2270] res4a_branch2b_param_0(0.469) 
I0802 07:46:11.153401 18636 net.cpp:2270] res5a_branch2a_param_0(0.47) 
I0802 07:46:11.153409 18636 net.cpp:2270] res5a_branch2b_param_0(0.47) 
I0802 07:46:11.153416 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.10494e+06/2.86678e+06) 0.385
I0802 07:46:11.298895 18661 solver.cpp:450] Finding and applying sparsity: 0.48
I0802 07:46:40.714207 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:46:40.716116 18636 solver.cpp:353] Iteration 67000 (2.3014 iter/s, 43.4519s/100 iter), loss = 1.42981
I0802 07:46:40.716140 18636 solver.cpp:375]     Train net output #0: loss = 1.39155 (* 1 = 1.39155 loss)
I0802 07:46:40.716147 18636 sgd_solver.cpp:136] Iteration 67000, lr = 0.0058125, m = 0.9
I0802 07:46:55.049696 18636 solver.cpp:353] Iteration 67100 (6.97682 iter/s, 14.3332s/100 iter), loss = 1.31716
I0802 07:46:55.049724 18636 solver.cpp:375]     Train net output #0: loss = 1.24875 (* 1 = 1.24875 loss)
I0802 07:46:55.049731 18636 sgd_solver.cpp:136] Iteration 67100, lr = 0.00580625, m = 0.9
I0802 07:47:09.061275 18636 solver.cpp:353] Iteration 67200 (7.13715 iter/s, 14.0112s/100 iter), loss = 1.27174
I0802 07:47:09.061327 18636 solver.cpp:375]     Train net output #0: loss = 1.37132 (* 1 = 1.37132 loss)
I0802 07:47:09.061341 18636 sgd_solver.cpp:136] Iteration 67200, lr = 0.0058, m = 0.9
I0802 07:47:23.052278 18636 solver.cpp:353] Iteration 67300 (7.14765 iter/s, 13.9906s/100 iter), loss = 1.11125
I0802 07:47:23.052693 18636 solver.cpp:375]     Train net output #0: loss = 1.09042 (* 1 = 1.09042 loss)
I0802 07:47:23.052701 18636 sgd_solver.cpp:136] Iteration 67300, lr = 0.00579375, m = 0.9
I0802 07:47:37.029759 18636 solver.cpp:353] Iteration 67400 (7.15456 iter/s, 13.9771s/100 iter), loss = 1.34184
I0802 07:47:37.029786 18636 solver.cpp:375]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0802 07:47:37.029793 18636 sgd_solver.cpp:136] Iteration 67400, lr = 0.0057875, m = 0.9
I0802 07:47:51.001070 18636 solver.cpp:353] Iteration 67500 (7.15772 iter/s, 13.9709s/100 iter), loss = 1.36116
I0802 07:47:51.001098 18636 solver.cpp:375]     Train net output #0: loss = 1.16349 (* 1 = 1.16349 loss)
I0802 07:47:51.001104 18636 sgd_solver.cpp:136] Iteration 67500, lr = 0.00578125, m = 0.9
I0802 07:48:04.927791 18636 solver.cpp:353] Iteration 67600 (7.18064 iter/s, 13.9263s/100 iter), loss = 1.20023
I0802 07:48:04.927860 18636 solver.cpp:375]     Train net output #0: loss = 1.23168 (* 1 = 1.23168 loss)
I0802 07:48:04.927867 18636 sgd_solver.cpp:136] Iteration 67600, lr = 0.005775, m = 0.9
I0802 07:48:18.795410 18636 solver.cpp:353] Iteration 67700 (7.21124 iter/s, 13.8672s/100 iter), loss = 1.15618
I0802 07:48:18.795439 18636 solver.cpp:375]     Train net output #0: loss = 1.1508 (* 1 = 1.1508 loss)
I0802 07:48:18.795444 18636 sgd_solver.cpp:136] Iteration 67700, lr = 0.00576875, m = 0.9
I0802 07:48:32.789120 18636 solver.cpp:353] Iteration 67800 (7.14626 iter/s, 13.9933s/100 iter), loss = 1.21673
I0802 07:48:32.789147 18636 solver.cpp:375]     Train net output #0: loss = 1.28263 (* 1 = 1.28263 loss)
I0802 07:48:32.789152 18636 sgd_solver.cpp:136] Iteration 67800, lr = 0.0057625, m = 0.9
I0802 07:48:46.703519 18636 solver.cpp:353] Iteration 67900 (7.187 iter/s, 13.914s/100 iter), loss = 1.29765
I0802 07:48:46.703575 18636 solver.cpp:375]     Train net output #0: loss = 1.25619 (* 1 = 1.25619 loss)
I0802 07:48:46.703583 18636 sgd_solver.cpp:136] Iteration 67900, lr = 0.00575625, m = 0.9
I0802 07:49:00.529093 18636 solver.cpp:404] Sparsity after update:
I0802 07:49:00.533008 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:49:00.533017 18636 net.cpp:2270] conv1a_param_0(0.226) 
I0802 07:49:00.533025 18636 net.cpp:2270] conv1b_param_0(0.472) 
I0802 07:49:00.533026 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:49:00.533028 18636 net.cpp:2270] res2a_branch2a_param_0(0.479) 
I0802 07:49:00.533030 18636 net.cpp:2270] res2a_branch2b_param_0(0.479) 
I0802 07:49:00.533032 18636 net.cpp:2270] res3a_branch2a_param_0(0.479) 
I0802 07:49:00.533035 18636 net.cpp:2270] res3a_branch2b_param_0(0.479) 
I0802 07:49:00.533040 18636 net.cpp:2270] res4a_branch2a_param_0(0.479) 
I0802 07:49:00.533041 18636 net.cpp:2270] res4a_branch2b_param_0(0.479) 
I0802 07:49:00.533043 18636 net.cpp:2270] res5a_branch2a_param_0(0.48) 
I0802 07:49:00.533046 18636 net.cpp:2270] res5a_branch2b_param_0(0.479) 
I0802 07:49:00.533047 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.12821e+06/2.86678e+06) 0.394
I0802 07:49:00.533054 18636 solver.cpp:550] Iteration 68000, Testing net (#0)
I0802 07:49:19.829439 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574882
I0802 07:49:19.829552 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809116
I0802 07:49:19.829561 18636 solver.cpp:635]     Test net output #2: loss = 1.8555 (* 1 = 1.8555 loss)
I0802 07:49:19.829586 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.296s
I0802 07:49:19.981024 18661 solver.cpp:450] Finding and applying sparsity: 0.49
I0802 07:49:49.775996 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:49:49.777971 18636 solver.cpp:353] Iteration 68000 (1.58547 iter/s, 63.0727s/100 iter), loss = 1.67936
I0802 07:49:49.777995 18636 solver.cpp:375]     Train net output #0: loss = 1.40997 (* 1 = 1.40997 loss)
I0802 07:49:49.778004 18636 sgd_solver.cpp:136] Iteration 68000, lr = 0.00575, m = 0.9
I0802 07:50:04.061417 18636 solver.cpp:353] Iteration 68100 (7.00131 iter/s, 14.283s/100 iter), loss = 1.41305
I0802 07:50:04.061484 18636 solver.cpp:375]     Train net output #0: loss = 0.976402 (* 1 = 0.976402 loss)
I0802 07:50:04.061491 18636 sgd_solver.cpp:136] Iteration 68100, lr = 0.00574375, m = 0.9
I0802 07:50:17.960958 18636 solver.cpp:353] Iteration 68200 (7.19468 iter/s, 13.8992s/100 iter), loss = 1.35467
I0802 07:50:17.960988 18636 solver.cpp:375]     Train net output #0: loss = 1.33436 (* 1 = 1.33436 loss)
I0802 07:50:17.960994 18636 sgd_solver.cpp:136] Iteration 68200, lr = 0.0057375, m = 0.9
I0802 07:50:31.848479 18636 solver.cpp:353] Iteration 68300 (7.20091 iter/s, 13.8871s/100 iter), loss = 1.80343
I0802 07:50:31.848570 18636 solver.cpp:375]     Train net output #0: loss = 1.55111 (* 1 = 1.55111 loss)
I0802 07:50:31.848590 18636 sgd_solver.cpp:136] Iteration 68300, lr = 0.00573125, m = 0.9
I0802 07:50:45.822165 18636 solver.cpp:353] Iteration 68400 (7.15651 iter/s, 13.9733s/100 iter), loss = 1.64918
I0802 07:50:45.822239 18636 solver.cpp:375]     Train net output #0: loss = 1.93625 (* 1 = 1.93625 loss)
I0802 07:50:45.822253 18636 sgd_solver.cpp:136] Iteration 68400, lr = 0.005725, m = 0.9
I0802 07:50:59.748235 18636 solver.cpp:353] Iteration 68500 (7.18097 iter/s, 13.9257s/100 iter), loss = 1.20004
I0802 07:50:59.748265 18636 solver.cpp:375]     Train net output #0: loss = 1.46419 (* 1 = 1.46419 loss)
I0802 07:50:59.748271 18636 sgd_solver.cpp:136] Iteration 68500, lr = 0.00571875, m = 0.9
I0802 07:51:13.681089 18636 solver.cpp:353] Iteration 68600 (7.17748 iter/s, 13.9325s/100 iter), loss = 1.33721
I0802 07:51:13.681161 18636 solver.cpp:375]     Train net output #0: loss = 1.47377 (* 1 = 1.47377 loss)
I0802 07:51:13.681180 18636 sgd_solver.cpp:136] Iteration 68600, lr = 0.0057125, m = 0.9
I0802 07:51:27.611589 18636 solver.cpp:353] Iteration 68700 (7.17869 iter/s, 13.9301s/100 iter), loss = 1.39573
I0802 07:51:27.611660 18636 solver.cpp:375]     Train net output #0: loss = 1.259 (* 1 = 1.259 loss)
I0802 07:51:27.611667 18636 sgd_solver.cpp:136] Iteration 68700, lr = 0.00570625, m = 0.9
I0802 07:51:41.532148 18636 solver.cpp:353] Iteration 68800 (7.18382 iter/s, 13.9202s/100 iter), loss = 1.2406
I0802 07:51:41.532172 18636 solver.cpp:375]     Train net output #0: loss = 1.44715 (* 1 = 1.44715 loss)
I0802 07:51:41.532178 18636 sgd_solver.cpp:136] Iteration 68800, lr = 0.0057, m = 0.9
I0802 07:51:55.489465 18636 solver.cpp:353] Iteration 68900 (7.1649 iter/s, 13.9569s/100 iter), loss = 1.03995
I0802 07:51:55.489490 18636 solver.cpp:375]     Train net output #0: loss = 1.29312 (* 1 = 1.29312 loss)
I0802 07:51:55.489496 18636 sgd_solver.cpp:136] Iteration 68900, lr = 0.00569375, m = 0.9
I0802 07:52:09.308851 18636 solver.cpp:404] Sparsity after update:
I0802 07:52:09.319339 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:52:09.319352 18636 net.cpp:2270] conv1a_param_0(0.239) 
I0802 07:52:09.319361 18636 net.cpp:2270] conv1b_param_0(0.486) 
I0802 07:52:09.319365 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:52:09.319368 18636 net.cpp:2270] res2a_branch2a_param_0(0.49) 
I0802 07:52:09.319378 18636 net.cpp:2270] res2a_branch2b_param_0(0.486) 
I0802 07:52:09.319382 18636 net.cpp:2270] res3a_branch2a_param_0(0.49) 
I0802 07:52:09.319386 18636 net.cpp:2270] res3a_branch2b_param_0(0.49) 
I0802 07:52:09.319388 18636 net.cpp:2270] res4a_branch2a_param_0(0.49) 
I0802 07:52:09.319391 18636 net.cpp:2270] res4a_branch2b_param_0(0.49) 
I0802 07:52:09.319394 18636 net.cpp:2270] res5a_branch2a_param_0(0.49) 
I0802 07:52:09.319398 18636 net.cpp:2270] res5a_branch2b_param_0(0.49) 
I0802 07:52:09.319401 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.15221e+06/2.86678e+06) 0.402
I0802 07:52:09.452428 18661 solver.cpp:450] Finding and applying sparsity: 0.5
I0802 07:52:39.236739 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:52:39.238648 18636 solver.cpp:353] Iteration 69000 (2.28582 iter/s, 43.748s/100 iter), loss = 1.75969
I0802 07:52:39.238667 18636 solver.cpp:375]     Train net output #0: loss = 1.69373 (* 1 = 1.69373 loss)
I0802 07:52:39.238672 18636 sgd_solver.cpp:136] Iteration 69000, lr = 0.0056875, m = 0.9
I0802 07:52:53.641041 18636 solver.cpp:353] Iteration 69100 (6.94349 iter/s, 14.402s/100 iter), loss = 1.45194
I0802 07:52:53.641113 18636 solver.cpp:375]     Train net output #0: loss = 1.52745 (* 1 = 1.52745 loss)
I0802 07:52:53.641120 18636 sgd_solver.cpp:136] Iteration 69100, lr = 0.00568125, m = 0.9
I0802 07:53:07.564748 18636 solver.cpp:353] Iteration 69200 (7.18219 iter/s, 13.9233s/100 iter), loss = 1.21042
I0802 07:53:07.564779 18636 solver.cpp:375]     Train net output #0: loss = 1.07642 (* 1 = 1.07642 loss)
I0802 07:53:07.564785 18636 sgd_solver.cpp:136] Iteration 69200, lr = 0.005675, m = 0.9
I0802 07:53:21.485532 18636 solver.cpp:353] Iteration 69300 (7.1837 iter/s, 13.9204s/100 iter), loss = 1.56885
I0802 07:53:21.485560 18636 solver.cpp:375]     Train net output #0: loss = 1.22849 (* 1 = 1.22849 loss)
I0802 07:53:21.485566 18636 sgd_solver.cpp:136] Iteration 69300, lr = 0.00566875, m = 0.9
I0802 07:53:35.423655 18636 solver.cpp:353] Iteration 69400 (7.17476 iter/s, 13.9377s/100 iter), loss = 1.57649
I0802 07:53:35.423725 18636 solver.cpp:375]     Train net output #0: loss = 1.20864 (* 1 = 1.20864 loss)
I0802 07:53:35.423732 18636 sgd_solver.cpp:136] Iteration 69400, lr = 0.0056625, m = 0.9
I0802 07:53:49.334275 18636 solver.cpp:353] Iteration 69500 (7.18895 iter/s, 13.9102s/100 iter), loss = 1.45886
I0802 07:53:49.334302 18636 solver.cpp:375]     Train net output #0: loss = 1.63244 (* 1 = 1.63244 loss)
I0802 07:53:49.334309 18636 sgd_solver.cpp:136] Iteration 69500, lr = 0.00565625, m = 0.9
I0802 07:54:03.293103 18636 solver.cpp:353] Iteration 69600 (7.16412 iter/s, 13.9584s/100 iter), loss = 1.0838
I0802 07:54:03.293131 18636 solver.cpp:375]     Train net output #0: loss = 1.30775 (* 1 = 1.30775 loss)
I0802 07:54:03.293136 18636 sgd_solver.cpp:136] Iteration 69600, lr = 0.00565, m = 0.9
I0802 07:54:17.200891 18636 solver.cpp:353] Iteration 69700 (7.19042 iter/s, 13.9074s/100 iter), loss = 1.37905
I0802 07:54:17.204915 18636 solver.cpp:375]     Train net output #0: loss = 1.31419 (* 1 = 1.31419 loss)
I0802 07:54:17.204944 18636 sgd_solver.cpp:136] Iteration 69700, lr = 0.00564375, m = 0.9
I0802 07:54:31.128787 18636 solver.cpp:353] Iteration 69800 (7.18003 iter/s, 13.9275s/100 iter), loss = 1.68834
I0802 07:54:31.128823 18636 solver.cpp:375]     Train net output #0: loss = 1.84706 (* 1 = 1.84706 loss)
I0802 07:54:31.128829 18636 sgd_solver.cpp:136] Iteration 69800, lr = 0.0056375, m = 0.9
I0802 07:54:45.017858 18636 solver.cpp:353] Iteration 69900 (7.2001 iter/s, 13.8887s/100 iter), loss = 1.1604
I0802 07:54:45.017887 18636 solver.cpp:375]     Train net output #0: loss = 1.54404 (* 1 = 1.54404 loss)
I0802 07:54:45.017894 18636 sgd_solver.cpp:136] Iteration 69900, lr = 0.00563125, m = 0.9
I0802 07:54:58.777457 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_70000.caffemodel
I0802 07:54:58.911262 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_70000.solverstate
I0802 07:54:58.916059 18636 solver.cpp:404] Sparsity after update:
I0802 07:54:58.917249 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:54:58.917259 18636 net.cpp:2270] conv1a_param_0(0.239) 
I0802 07:54:58.917266 18636 net.cpp:2270] conv1b_param_0(0.486) 
I0802 07:54:58.917269 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:54:58.917274 18636 net.cpp:2270] res2a_branch2a_param_0(0.497) 
I0802 07:54:58.917276 18636 net.cpp:2270] res2a_branch2b_param_0(0.493) 
I0802 07:54:58.917279 18636 net.cpp:2270] res3a_branch2a_param_0(0.498) 
I0802 07:54:58.917280 18636 net.cpp:2270] res3a_branch2b_param_0(0.497) 
I0802 07:54:58.917282 18636 net.cpp:2270] res4a_branch2a_param_0(0.499) 
I0802 07:54:58.917284 18636 net.cpp:2270] res4a_branch2b_param_0(0.498) 
I0802 07:54:58.917287 18636 net.cpp:2270] res5a_branch2a_param_0(0.5) 
I0802 07:54:58.917289 18636 net.cpp:2270] res5a_branch2b_param_0(0.499) 
I0802 07:54:58.917291 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.1748e+06/2.86678e+06) 0.41
I0802 07:54:58.917300 18636 solver.cpp:550] Iteration 70000, Testing net (#0)
I0802 07:55:18.085870 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.575176
I0802 07:55:18.085891 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809703
I0802 07:55:18.085896 18636 solver.cpp:635]     Test net output #2: loss = 1.87494 (* 1 = 1.87494 loss)
I0802 07:55:18.085911 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1681s
I0802 07:55:18.223258 18661 solver.cpp:450] Finding and applying sparsity: 0.51
I0802 07:55:48.831424 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:55:48.833417 18636 solver.cpp:353] Iteration 70000 (1.56706 iter/s, 63.8138s/100 iter), loss = 1.4431
I0802 07:55:48.833436 18636 solver.cpp:375]     Train net output #0: loss = 1.45462 (* 1 = 1.45462 loss)
I0802 07:55:48.833441 18636 sgd_solver.cpp:136] Iteration 70000, lr = 0.005625, m = 0.9
I0802 07:56:03.231654 18636 solver.cpp:353] Iteration 70100 (6.94549 iter/s, 14.3978s/100 iter), loss = 1.3406
I0802 07:56:03.231685 18636 solver.cpp:375]     Train net output #0: loss = 1.33157 (* 1 = 1.33157 loss)
I0802 07:56:03.231691 18636 sgd_solver.cpp:136] Iteration 70100, lr = 0.00561875, m = 0.9
I0802 07:56:17.081763 18636 solver.cpp:353] Iteration 70200 (7.22037 iter/s, 13.8497s/100 iter), loss = 1.30579
I0802 07:56:17.082036 18636 solver.cpp:375]     Train net output #0: loss = 1.46223 (* 1 = 1.46223 loss)
I0802 07:56:17.082059 18636 sgd_solver.cpp:136] Iteration 70200, lr = 0.0056125, m = 0.9
I0802 07:56:31.088872 18636 solver.cpp:353] Iteration 70300 (7.13943 iter/s, 14.0067s/100 iter), loss = 1.57607
I0802 07:56:31.088984 18636 solver.cpp:375]     Train net output #0: loss = 1.10424 (* 1 = 1.10424 loss)
I0802 07:56:31.089005 18636 sgd_solver.cpp:136] Iteration 70300, lr = 0.00560625, m = 0.9
I0802 07:56:45.055557 18636 solver.cpp:353] Iteration 70400 (7.16009 iter/s, 13.9663s/100 iter), loss = 1.3838
I0802 07:56:45.055583 18636 solver.cpp:375]     Train net output #0: loss = 1.17459 (* 1 = 1.17459 loss)
I0802 07:56:45.055588 18636 sgd_solver.cpp:136] Iteration 70400, lr = 0.0056, m = 0.9
I0802 07:56:59.017473 18636 solver.cpp:353] Iteration 70500 (7.16254 iter/s, 13.9615s/100 iter), loss = 1.10995
I0802 07:56:59.017565 18636 solver.cpp:375]     Train net output #0: loss = 1.07344 (* 1 = 1.07344 loss)
I0802 07:56:59.017586 18636 sgd_solver.cpp:136] Iteration 70500, lr = 0.00559375, m = 0.9
I0802 07:57:13.087718 18636 solver.cpp:353] Iteration 70600 (7.10739 iter/s, 14.0699s/100 iter), loss = 1.75401
I0802 07:57:13.088457 18636 solver.cpp:375]     Train net output #0: loss = 1.53673 (* 1 = 1.53673 loss)
I0802 07:57:13.088465 18636 sgd_solver.cpp:136] Iteration 70600, lr = 0.0055875, m = 0.9
I0802 07:57:27.077567 18636 solver.cpp:353] Iteration 70700 (7.14823 iter/s, 13.9895s/100 iter), loss = 1.78046
I0802 07:57:27.077591 18636 solver.cpp:375]     Train net output #0: loss = 1.68208 (* 1 = 1.68208 loss)
I0802 07:57:27.077595 18636 sgd_solver.cpp:136] Iteration 70700, lr = 0.00558125, m = 0.9
I0802 07:57:40.979928 18636 solver.cpp:353] Iteration 70800 (7.19322 iter/s, 13.902s/100 iter), loss = 1.39341
I0802 07:57:40.980041 18636 solver.cpp:375]     Train net output #0: loss = 1.1439 (* 1 = 1.1439 loss)
I0802 07:57:40.980068 18636 sgd_solver.cpp:136] Iteration 70800, lr = 0.005575, m = 0.9
I0802 07:57:54.889436 18636 solver.cpp:353] Iteration 70900 (7.18952 iter/s, 13.9091s/100 iter), loss = 1.09789
I0802 07:57:54.889500 18636 solver.cpp:375]     Train net output #0: loss = 0.911678 (* 1 = 0.911678 loss)
I0802 07:57:54.889506 18636 sgd_solver.cpp:136] Iteration 70900, lr = 0.00556875, m = 0.9
I0802 07:58:08.759035 18636 solver.cpp:404] Sparsity after update:
I0802 07:58:08.770213 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 07:58:08.770226 18636 net.cpp:2270] conv1a_param_0(0.251) 
I0802 07:58:08.770236 18636 net.cpp:2270] conv1b_param_0(0.5) 
I0802 07:58:08.770237 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 07:58:08.770241 18636 net.cpp:2270] res2a_branch2a_param_0(0.507) 
I0802 07:58:08.770242 18636 net.cpp:2270] res2a_branch2b_param_0(0.506) 
I0802 07:58:08.770243 18636 net.cpp:2270] res3a_branch2a_param_0(0.509) 
I0802 07:58:08.770246 18636 net.cpp:2270] res3a_branch2b_param_0(0.507) 
I0802 07:58:08.770247 18636 net.cpp:2270] res4a_branch2a_param_0(0.51) 
I0802 07:58:08.770249 18636 net.cpp:2270] res4a_branch2b_param_0(0.509) 
I0802 07:58:08.770251 18636 net.cpp:2270] res5a_branch2a_param_0(0.51) 
I0802 07:58:08.770253 18636 net.cpp:2270] res5a_branch2b_param_0(0.51) 
I0802 07:58:08.770256 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.19938e+06/2.86678e+06) 0.418
I0802 07:58:08.899322 18661 solver.cpp:450] Finding and applying sparsity: 0.52
I0802 07:58:40.153949 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 07:58:40.155865 18636 solver.cpp:353] Iteration 71000 (2.2092 iter/s, 45.2652s/100 iter), loss = 1.04932
I0802 07:58:40.155885 18636 solver.cpp:375]     Train net output #0: loss = 1.12705 (* 1 = 1.12705 loss)
I0802 07:58:40.155892 18636 sgd_solver.cpp:136] Iteration 71000, lr = 0.0055625, m = 0.9
I0802 07:58:54.626370 18636 solver.cpp:353] Iteration 71100 (6.9108 iter/s, 14.4701s/100 iter), loss = 1.01022
I0802 07:58:54.626399 18636 solver.cpp:375]     Train net output #0: loss = 1.17045 (* 1 = 1.17045 loss)
I0802 07:58:54.626404 18636 sgd_solver.cpp:136] Iteration 71100, lr = 0.00555625, m = 0.9
I0802 07:59:08.594136 18636 solver.cpp:353] Iteration 71200 (7.15954 iter/s, 13.9674s/100 iter), loss = 1.28741
I0802 07:59:08.594214 18636 solver.cpp:375]     Train net output #0: loss = 1.10459 (* 1 = 1.10459 loss)
I0802 07:59:08.594234 18636 sgd_solver.cpp:136] Iteration 71200, lr = 0.00555, m = 0.9
I0802 07:59:22.590752 18636 solver.cpp:353] Iteration 71300 (7.14478 iter/s, 13.9962s/100 iter), loss = 1.25376
I0802 07:59:22.590854 18636 solver.cpp:375]     Train net output #0: loss = 1.20394 (* 1 = 1.20394 loss)
I0802 07:59:22.590873 18636 sgd_solver.cpp:136] Iteration 71300, lr = 0.00554375, m = 0.9
I0802 07:59:36.505765 18636 solver.cpp:353] Iteration 71400 (7.18668 iter/s, 13.9146s/100 iter), loss = 1.56604
I0802 07:59:36.505794 18636 solver.cpp:375]     Train net output #0: loss = 1.9287 (* 1 = 1.9287 loss)
I0802 07:59:36.505800 18636 sgd_solver.cpp:136] Iteration 71400, lr = 0.0055375, m = 0.9
I0802 07:59:50.401963 18636 solver.cpp:353] Iteration 71500 (7.19641 iter/s, 13.8958s/100 iter), loss = 1.11948
I0802 07:59:50.401988 18636 solver.cpp:375]     Train net output #0: loss = 1.15599 (* 1 = 1.15599 loss)
I0802 07:59:50.401994 18636 sgd_solver.cpp:136] Iteration 71500, lr = 0.00553125, m = 0.9
I0802 08:00:04.373935 18636 solver.cpp:353] Iteration 71600 (7.15739 iter/s, 13.9716s/100 iter), loss = 1.15567
I0802 08:00:04.374092 18636 solver.cpp:375]     Train net output #0: loss = 1.02003 (* 1 = 1.02003 loss)
I0802 08:00:04.374114 18636 sgd_solver.cpp:136] Iteration 71600, lr = 0.005525, m = 0.9
I0802 08:00:18.433351 18636 solver.cpp:353] Iteration 71700 (7.11286 iter/s, 14.059s/100 iter), loss = 1.55132
I0802 08:00:18.433447 18636 solver.cpp:375]     Train net output #0: loss = 1.36541 (* 1 = 1.36541 loss)
I0802 08:00:18.433470 18636 sgd_solver.cpp:136] Iteration 71700, lr = 0.00551875, m = 0.9
I0802 08:00:32.458916 18636 solver.cpp:353] Iteration 71800 (7.13003 iter/s, 14.0252s/100 iter), loss = 1.53104
I0802 08:00:32.458942 18636 solver.cpp:375]     Train net output #0: loss = 1.48322 (* 1 = 1.48322 loss)
I0802 08:00:32.458947 18636 sgd_solver.cpp:136] Iteration 71800, lr = 0.0055125, m = 0.9
I0802 08:00:46.374083 18636 solver.cpp:353] Iteration 71900 (7.1866 iter/s, 13.9148s/100 iter), loss = 1.49535
I0802 08:00:46.374204 18636 solver.cpp:375]     Train net output #0: loss = 1.61956 (* 1 = 1.61956 loss)
I0802 08:00:46.374213 18636 sgd_solver.cpp:136] Iteration 71900, lr = 0.00550625, m = 0.9
I0802 08:01:00.193200 18636 solver.cpp:404] Sparsity after update:
I0802 08:01:00.197470 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:01:00.197480 18636 net.cpp:2270] conv1a_param_0(0.252) 
I0802 08:01:00.197487 18636 net.cpp:2270] conv1b_param_0(0.513) 
I0802 08:01:00.197489 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:01:00.197491 18636 net.cpp:2270] res2a_branch2a_param_0(0.517) 
I0802 08:01:00.197494 18636 net.cpp:2270] res2a_branch2b_param_0(0.513) 
I0802 08:01:00.197495 18636 net.cpp:2270] res3a_branch2a_param_0(0.519) 
I0802 08:01:00.197497 18636 net.cpp:2270] res3a_branch2b_param_0(0.517) 
I0802 08:01:00.197499 18636 net.cpp:2270] res4a_branch2a_param_0(0.52) 
I0802 08:01:00.197501 18636 net.cpp:2270] res4a_branch2b_param_0(0.519) 
I0802 08:01:00.197504 18636 net.cpp:2270] res5a_branch2a_param_0(0.52) 
I0802 08:01:00.197505 18636 net.cpp:2270] res5a_branch2b_param_0(0.52) 
I0802 08:01:00.197510 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.22334e+06/2.86678e+06) 0.427
I0802 08:01:00.197520 18636 solver.cpp:550] Iteration 72000, Testing net (#0)
I0802 08:01:19.958081 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.572471
I0802 08:01:19.958209 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.804174
I0802 08:01:19.958220 18636 solver.cpp:635]     Test net output #2: loss = 1.88335 (* 1 = 1.88335 loss)
I0802 08:01:19.958242 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7602s
I0802 08:01:20.096855 18661 solver.cpp:450] Finding and applying sparsity: 0.53
I0802 08:01:52.283674 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:01:52.285619 18636 solver.cpp:353] Iteration 72000 (1.51723 iter/s, 65.9097s/100 iter), loss = 1.58838
I0802 08:01:52.285640 18636 solver.cpp:375]     Train net output #0: loss = 1.29715 (* 1 = 1.29715 loss)
I0802 08:01:52.285645 18636 sgd_solver.cpp:136] Iteration 72000, lr = 0.0055, m = 0.9
I0802 08:02:06.657491 18636 solver.cpp:353] Iteration 72100 (6.95823 iter/s, 14.3715s/100 iter), loss = 1.66071
I0802 08:02:06.657519 18636 solver.cpp:375]     Train net output #0: loss = 1.82002 (* 1 = 1.82002 loss)
I0802 08:02:06.657526 18636 sgd_solver.cpp:136] Iteration 72100, lr = 0.00549375, m = 0.9
I0802 08:02:20.582490 18636 solver.cpp:353] Iteration 72200 (7.18153 iter/s, 13.9246s/100 iter), loss = 1.33367
I0802 08:02:20.582523 18636 solver.cpp:375]     Train net output #0: loss = 1.33511 (* 1 = 1.33511 loss)
I0802 08:02:20.582530 18636 sgd_solver.cpp:136] Iteration 72200, lr = 0.0054875, m = 0.9
I0802 08:02:34.548604 18636 solver.cpp:353] Iteration 72300 (7.16039 iter/s, 13.9657s/100 iter), loss = 1.48072
I0802 08:02:34.552850 18636 solver.cpp:375]     Train net output #0: loss = 1.31978 (* 1 = 1.31978 loss)
I0802 08:02:34.552862 18636 sgd_solver.cpp:136] Iteration 72300, lr = 0.00548125, m = 0.9
I0802 08:02:48.545006 18636 solver.cpp:353] Iteration 72400 (7.14489 iter/s, 13.996s/100 iter), loss = 1.4859
I0802 08:02:48.545033 18636 solver.cpp:375]     Train net output #0: loss = 1.71166 (* 1 = 1.71166 loss)
I0802 08:02:48.545039 18636 sgd_solver.cpp:136] Iteration 72400, lr = 0.005475, m = 0.9
I0802 08:03:02.486632 18636 solver.cpp:353] Iteration 72500 (7.17296 iter/s, 13.9412s/100 iter), loss = 1.20358
I0802 08:03:02.486657 18636 solver.cpp:375]     Train net output #0: loss = 1.22072 (* 1 = 1.22072 loss)
I0802 08:03:02.486662 18636 sgd_solver.cpp:136] Iteration 72500, lr = 0.00546875, m = 0.9
I0802 08:03:16.403381 18636 solver.cpp:353] Iteration 72600 (7.18578 iter/s, 13.9164s/100 iter), loss = 1.08699
I0802 08:03:16.403439 18636 solver.cpp:375]     Train net output #0: loss = 1.26995 (* 1 = 1.26995 loss)
I0802 08:03:16.403443 18636 sgd_solver.cpp:136] Iteration 72600, lr = 0.0054625, m = 0.9
I0802 08:03:30.409562 18636 solver.cpp:353] Iteration 72700 (7.1399 iter/s, 14.0058s/100 iter), loss = 1.4426
I0802 08:03:30.409590 18636 solver.cpp:375]     Train net output #0: loss = 1.30968 (* 1 = 1.30968 loss)
I0802 08:03:30.409595 18636 sgd_solver.cpp:136] Iteration 72700, lr = 0.00545625, m = 0.9
I0802 08:03:44.280190 18636 solver.cpp:353] Iteration 72800 (7.20968 iter/s, 13.8702s/100 iter), loss = 1.32172
I0802 08:03:44.280216 18636 solver.cpp:375]     Train net output #0: loss = 1.47756 (* 1 = 1.47756 loss)
I0802 08:03:44.280222 18636 sgd_solver.cpp:136] Iteration 72800, lr = 0.00545, m = 0.9
I0802 08:03:58.198317 18636 solver.cpp:353] Iteration 72900 (7.18507 iter/s, 13.9177s/100 iter), loss = 1.33922
I0802 08:03:58.198395 18636 solver.cpp:375]     Train net output #0: loss = 1.29821 (* 1 = 1.29821 loss)
I0802 08:03:58.198402 18636 sgd_solver.cpp:136] Iteration 72900, lr = 0.00544375, m = 0.9
I0802 08:04:12.097672 18636 solver.cpp:404] Sparsity after update:
I0802 08:04:12.109246 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:04:12.109258 18636 net.cpp:2270] conv1a_param_0(0.252) 
I0802 08:04:12.109267 18636 net.cpp:2270] conv1b_param_0(0.527) 
I0802 08:04:12.109271 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:04:12.109282 18636 net.cpp:2270] res2a_branch2a_param_0(0.528) 
I0802 08:04:12.109292 18636 net.cpp:2270] res2a_branch2b_param_0(0.526) 
I0802 08:04:12.109299 18636 net.cpp:2270] res3a_branch2a_param_0(0.53) 
I0802 08:04:12.109308 18636 net.cpp:2270] res3a_branch2b_param_0(0.528) 
I0802 08:04:12.109316 18636 net.cpp:2270] res4a_branch2a_param_0(0.53) 
I0802 08:04:12.109324 18636 net.cpp:2270] res4a_branch2b_param_0(0.53) 
I0802 08:04:12.109333 18636 net.cpp:2270] res5a_branch2a_param_0(0.53) 
I0802 08:04:12.109344 18636 net.cpp:2270] res5a_branch2b_param_0(0.53) 
I0802 08:04:12.109354 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.24659e+06/2.86678e+06) 0.435
I0802 08:04:12.237202 18661 solver.cpp:450] Finding and applying sparsity: 0.54
I0802 08:04:44.603379 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:04:44.605329 18636 solver.cpp:353] Iteration 73000 (2.15491 iter/s, 46.4057s/100 iter), loss = 1.25414
I0802 08:04:44.605351 18636 solver.cpp:375]     Train net output #0: loss = 1.36101 (* 1 = 1.36101 loss)
I0802 08:04:44.605360 18636 sgd_solver.cpp:136] Iteration 73000, lr = 0.0054375, m = 0.9
I0802 08:04:59.307580 18636 solver.cpp:353] Iteration 73100 (6.80187 iter/s, 14.7018s/100 iter), loss = 1.44571
I0802 08:04:59.307610 18636 solver.cpp:375]     Train net output #0: loss = 1.345 (* 1 = 1.345 loss)
I0802 08:04:59.307615 18636 sgd_solver.cpp:136] Iteration 73100, lr = 0.00543125, m = 0.9
I0802 08:05:13.177667 18636 solver.cpp:353] Iteration 73200 (7.20996 iter/s, 13.8697s/100 iter), loss = 1.17028
I0802 08:05:13.177691 18636 solver.cpp:375]     Train net output #0: loss = 1.30014 (* 1 = 1.30014 loss)
I0802 08:05:13.177697 18636 sgd_solver.cpp:136] Iteration 73200, lr = 0.005425, m = 0.9
I0802 08:05:27.020087 18636 solver.cpp:353] Iteration 73300 (7.22437 iter/s, 13.842s/100 iter), loss = 1.13036
I0802 08:05:27.020140 18636 solver.cpp:375]     Train net output #0: loss = 1.15774 (* 1 = 1.15774 loss)
I0802 08:05:27.020146 18636 sgd_solver.cpp:136] Iteration 73300, lr = 0.00541875, m = 0.9
I0802 08:05:30.888306 18598 blocking_queue.cpp:40] Waiting for datum
I0802 08:05:41.034279 18636 solver.cpp:353] Iteration 73400 (7.13582 iter/s, 14.0138s/100 iter), loss = 1.2131
I0802 08:05:41.034303 18636 solver.cpp:375]     Train net output #0: loss = 1.15396 (* 1 = 1.15396 loss)
I0802 08:05:41.034307 18636 sgd_solver.cpp:136] Iteration 73400, lr = 0.0054125, m = 0.9
I0802 08:05:54.995373 18636 solver.cpp:353] Iteration 73500 (7.16296 iter/s, 13.9607s/100 iter), loss = 1.36263
I0802 08:05:54.995424 18636 solver.cpp:375]     Train net output #0: loss = 1.09646 (* 1 = 1.09646 loss)
I0802 08:05:54.995437 18636 sgd_solver.cpp:136] Iteration 73500, lr = 0.00540625, m = 0.9
I0802 08:06:08.931278 18636 solver.cpp:353] Iteration 73600 (7.17591 iter/s, 13.9355s/100 iter), loss = 1.2117
I0802 08:06:08.931365 18636 solver.cpp:375]     Train net output #0: loss = 1.1703 (* 1 = 1.1703 loss)
I0802 08:06:08.931371 18636 sgd_solver.cpp:136] Iteration 73600, lr = 0.0054, m = 0.9
I0802 08:06:22.911173 18636 solver.cpp:353] Iteration 73700 (7.15333 iter/s, 13.9795s/100 iter), loss = 1.33447
I0802 08:06:22.911197 18636 solver.cpp:375]     Train net output #0: loss = 1.40971 (* 1 = 1.40971 loss)
I0802 08:06:22.911201 18636 sgd_solver.cpp:136] Iteration 73700, lr = 0.00539375, m = 0.9
I0802 08:06:36.818135 18636 solver.cpp:353] Iteration 73800 (7.19084 iter/s, 13.9066s/100 iter), loss = 1.44144
I0802 08:06:36.818163 18636 solver.cpp:375]     Train net output #0: loss = 1.55613 (* 1 = 1.55613 loss)
I0802 08:06:36.818171 18636 sgd_solver.cpp:136] Iteration 73800, lr = 0.0053875, m = 0.9
I0802 08:06:50.626868 18636 solver.cpp:353] Iteration 73900 (7.24199 iter/s, 13.8084s/100 iter), loss = 1.54135
I0802 08:06:50.626955 18636 solver.cpp:375]     Train net output #0: loss = 1.50792 (* 1 = 1.50792 loss)
I0802 08:06:50.626962 18636 sgd_solver.cpp:136] Iteration 73900, lr = 0.00538125, m = 0.9
I0802 08:07:04.387171 18636 solver.cpp:404] Sparsity after update:
I0802 08:07:04.391553 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:07:04.391568 18636 net.cpp:2270] conv1a_param_0(0.264) 
I0802 08:07:04.391578 18636 net.cpp:2270] conv1b_param_0(0.527) 
I0802 08:07:04.391582 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:07:04.391587 18636 net.cpp:2270] res2a_branch2a_param_0(0.538) 
I0802 08:07:04.391590 18636 net.cpp:2270] res2a_branch2b_param_0(0.533) 
I0802 08:07:04.391594 18636 net.cpp:2270] res3a_branch2a_param_0(0.54) 
I0802 08:07:04.391597 18636 net.cpp:2270] res3a_branch2b_param_0(0.538) 
I0802 08:07:04.391600 18636 net.cpp:2270] res4a_branch2a_param_0(0.54) 
I0802 08:07:04.391603 18636 net.cpp:2270] res4a_branch2b_param_0(0.54) 
I0802 08:07:04.391607 18636 net.cpp:2270] res5a_branch2a_param_0(0.54) 
I0802 08:07:04.391609 18636 net.cpp:2270] res5a_branch2b_param_0(0.54) 
I0802 08:07:04.391613 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.27056e+06/2.86678e+06) 0.443
I0802 08:07:04.391623 18636 solver.cpp:550] Iteration 74000, Testing net (#0)
I0802 08:07:07.516822 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:07:09.473918 18619 data_reader.cpp:264] Starting prefetch of epoch 4
I0802 08:07:23.680622 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.580294
I0802 08:07:23.680735 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.812351
I0802 08:07:23.680744 18636 solver.cpp:635]     Test net output #2: loss = 1.83164 (* 1 = 1.83164 loss)
I0802 08:07:23.680764 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2886s
I0802 08:07:23.835762 18661 solver.cpp:450] Finding and applying sparsity: 0.55
I0802 08:07:56.570442 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:07:56.572371 18636 solver.cpp:353] Iteration 74000 (1.51644 iter/s, 65.9437s/100 iter), loss = 1.33973
I0802 08:07:56.572391 18636 solver.cpp:375]     Train net output #0: loss = 1.00397 (* 1 = 1.00397 loss)
I0802 08:07:56.572397 18636 sgd_solver.cpp:136] Iteration 74000, lr = 0.005375, m = 0.9
I0802 08:08:10.897367 18636 solver.cpp:353] Iteration 74100 (6.981 iter/s, 14.3246s/100 iter), loss = 1.569
I0802 08:08:10.897399 18636 solver.cpp:375]     Train net output #0: loss = 1.61277 (* 1 = 1.61277 loss)
I0802 08:08:10.897405 18636 sgd_solver.cpp:136] Iteration 74100, lr = 0.00536875, m = 0.9
I0802 08:08:24.883930 18636 solver.cpp:353] Iteration 74200 (7.14992 iter/s, 13.9862s/100 iter), loss = 1.69327
I0802 08:08:24.883963 18636 solver.cpp:375]     Train net output #0: loss = 1.93148 (* 1 = 1.93148 loss)
I0802 08:08:24.883970 18636 sgd_solver.cpp:136] Iteration 74200, lr = 0.0053625, m = 0.9
I0802 08:08:38.771098 18636 solver.cpp:353] Iteration 74300 (7.20109 iter/s, 13.8868s/100 iter), loss = 1.12379
I0802 08:08:38.771154 18636 solver.cpp:375]     Train net output #0: loss = 1.22194 (* 1 = 1.22194 loss)
I0802 08:08:38.771162 18636 sgd_solver.cpp:136] Iteration 74300, lr = 0.00535625, m = 0.9
I0802 08:08:52.687589 18636 solver.cpp:353] Iteration 74400 (7.18592 iter/s, 13.9161s/100 iter), loss = 1.13894
I0802 08:08:52.687680 18636 solver.cpp:375]     Train net output #0: loss = 1.06957 (* 1 = 1.06957 loss)
I0802 08:08:52.687698 18636 sgd_solver.cpp:136] Iteration 74400, lr = 0.00535, m = 0.9
I0802 08:09:06.646972 18636 solver.cpp:353] Iteration 74500 (7.16384 iter/s, 13.959s/100 iter), loss = 1.66617
I0802 08:09:06.646998 18636 solver.cpp:375]     Train net output #0: loss = 1.83807 (* 1 = 1.83807 loss)
I0802 08:09:06.647003 18636 sgd_solver.cpp:136] Iteration 74500, lr = 0.00534375, m = 0.9
I0802 08:09:20.549233 18636 solver.cpp:353] Iteration 74600 (7.19327 iter/s, 13.9019s/100 iter), loss = 1.25345
I0802 08:09:20.549315 18636 solver.cpp:375]     Train net output #0: loss = 0.997739 (* 1 = 0.997739 loss)
I0802 08:09:20.549324 18636 sgd_solver.cpp:136] Iteration 74600, lr = 0.0053375, m = 0.9
I0802 08:09:34.464601 18636 solver.cpp:353] Iteration 74700 (7.1865 iter/s, 13.915s/100 iter), loss = 1.11344
I0802 08:09:34.464624 18636 solver.cpp:375]     Train net output #0: loss = 1.25958 (* 1 = 1.25958 loss)
I0802 08:09:34.464628 18636 sgd_solver.cpp:136] Iteration 74700, lr = 0.00533125, m = 0.9
I0802 08:09:48.356710 18636 solver.cpp:353] Iteration 74800 (7.19853 iter/s, 13.8917s/100 iter), loss = 1.51957
I0802 08:09:48.356739 18636 solver.cpp:375]     Train net output #0: loss = 1.50459 (* 1 = 1.50459 loss)
I0802 08:09:48.356745 18636 sgd_solver.cpp:136] Iteration 74800, lr = 0.005325, m = 0.9
I0802 08:10:02.249914 18636 solver.cpp:353] Iteration 74900 (7.19796 iter/s, 13.8928s/100 iter), loss = 1.68665
I0802 08:10:02.249974 18636 solver.cpp:375]     Train net output #0: loss = 2.00398 (* 1 = 2.00398 loss)
I0802 08:10:02.249979 18636 sgd_solver.cpp:136] Iteration 74900, lr = 0.00531875, m = 0.9
I0802 08:10:15.996865 18636 solver.cpp:404] Sparsity after update:
I0802 08:10:16.007060 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:10:16.007072 18636 net.cpp:2270] conv1a_param_0(0.265) 
I0802 08:10:16.007082 18636 net.cpp:2270] conv1b_param_0(0.54) 
I0802 08:10:16.007086 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:10:16.007089 18636 net.cpp:2270] res2a_branch2a_param_0(0.549) 
I0802 08:10:16.007092 18636 net.cpp:2270] res2a_branch2b_param_0(0.546) 
I0802 08:10:16.007095 18636 net.cpp:2270] res3a_branch2a_param_0(0.549) 
I0802 08:10:16.007098 18636 net.cpp:2270] res3a_branch2b_param_0(0.548) 
I0802 08:10:16.007102 18636 net.cpp:2270] res4a_branch2a_param_0(0.549) 
I0802 08:10:16.007104 18636 net.cpp:2270] res4a_branch2b_param_0(0.549) 
I0802 08:10:16.007108 18636 net.cpp:2270] res5a_branch2a_param_0(0.55) 
I0802 08:10:16.007112 18636 net.cpp:2270] res5a_branch2b_param_0(0.549) 
I0802 08:10:16.007114 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.29343e+06/2.86678e+06) 0.451
I0802 08:10:16.135731 18661 solver.cpp:450] Finding and applying sparsity: 0.56
I0802 08:10:49.662852 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:10:49.664790 18636 solver.cpp:353] Iteration 75000 (2.1091 iter/s, 47.4136s/100 iter), loss = 1.08956
I0802 08:10:49.664809 18636 solver.cpp:375]     Train net output #0: loss = 1.13773 (* 1 = 1.13773 loss)
I0802 08:10:49.664819 18636 sgd_solver.cpp:136] Iteration 75000, lr = 0.0053125, m = 0.9
I0802 08:11:04.155052 18636 solver.cpp:353] Iteration 75100 (6.90138 iter/s, 14.4899s/100 iter), loss = 1.00517
I0802 08:11:04.155082 18636 solver.cpp:375]     Train net output #0: loss = 1.01676 (* 1 = 1.01676 loss)
I0802 08:11:04.155088 18636 sgd_solver.cpp:136] Iteration 75100, lr = 0.00530625, m = 0.9
I0802 08:11:18.108217 18636 solver.cpp:353] Iteration 75200 (7.16703 iter/s, 13.9528s/100 iter), loss = 1.24104
I0802 08:11:18.108253 18636 solver.cpp:375]     Train net output #0: loss = 1.40189 (* 1 = 1.40189 loss)
I0802 08:11:18.108260 18636 sgd_solver.cpp:136] Iteration 75200, lr = 0.0053, m = 0.9
I0802 08:11:32.021363 18636 solver.cpp:353] Iteration 75300 (7.18764 iter/s, 13.9128s/100 iter), loss = 1.62443
I0802 08:11:32.021915 18636 solver.cpp:375]     Train net output #0: loss = 2.08066 (* 1 = 2.08066 loss)
I0802 08:11:32.021920 18636 sgd_solver.cpp:136] Iteration 75300, lr = 0.00529375, m = 0.9
I0802 08:11:46.041849 18636 solver.cpp:353] Iteration 75400 (7.13262 iter/s, 14.0201s/100 iter), loss = 1.61623
I0802 08:11:46.041875 18636 solver.cpp:375]     Train net output #0: loss = 1.64552 (* 1 = 1.64552 loss)
I0802 08:11:46.041880 18636 sgd_solver.cpp:136] Iteration 75400, lr = 0.0052875, m = 0.9
I0802 08:11:59.962222 18636 solver.cpp:353] Iteration 75500 (7.18391 iter/s, 13.92s/100 iter), loss = 1.27937
I0802 08:11:59.962249 18636 solver.cpp:375]     Train net output #0: loss = 1.31399 (* 1 = 1.31399 loss)
I0802 08:11:59.962254 18636 sgd_solver.cpp:136] Iteration 75500, lr = 0.00528125, m = 0.9
I0802 08:12:13.908139 18636 solver.cpp:353] Iteration 75600 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.16087
I0802 08:12:13.908210 18636 solver.cpp:375]     Train net output #0: loss = 1.26023 (* 1 = 1.26023 loss)
I0802 08:12:13.908217 18636 sgd_solver.cpp:136] Iteration 75600, lr = 0.005275, m = 0.9
I0802 08:12:27.820760 18636 solver.cpp:353] Iteration 75700 (7.18792 iter/s, 13.9122s/100 iter), loss = 1.16611
I0802 08:12:27.820792 18636 solver.cpp:375]     Train net output #0: loss = 1.26403 (* 1 = 1.26403 loss)
I0802 08:12:27.820799 18636 sgd_solver.cpp:136] Iteration 75700, lr = 0.00526875, m = 0.9
I0802 08:12:41.764339 18636 solver.cpp:353] Iteration 75800 (7.17196 iter/s, 13.9432s/100 iter), loss = 1.09373
I0802 08:12:41.764420 18636 solver.cpp:375]     Train net output #0: loss = 1.01472 (* 1 = 1.01472 loss)
I0802 08:12:41.764443 18636 sgd_solver.cpp:136] Iteration 75800, lr = 0.0052625, m = 0.9
I0802 08:12:55.837488 18636 solver.cpp:353] Iteration 75900 (7.10593 iter/s, 14.0728s/100 iter), loss = 1.01327
I0802 08:12:55.837555 18636 solver.cpp:375]     Train net output #0: loss = 0.895902 (* 1 = 0.895902 loss)
I0802 08:12:55.837563 18636 sgd_solver.cpp:136] Iteration 75900, lr = 0.00525625, m = 0.9
I0802 08:13:09.685866 18636 solver.cpp:404] Sparsity after update:
I0802 08:13:09.690080 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:13:09.690091 18636 net.cpp:2270] conv1a_param_0(0.265) 
I0802 08:13:09.690099 18636 net.cpp:2270] conv1b_param_0(0.553) 
I0802 08:13:09.690101 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:13:09.690104 18636 net.cpp:2270] res2a_branch2a_param_0(0.559) 
I0802 08:13:09.690105 18636 net.cpp:2270] res2a_branch2b_param_0(0.553) 
I0802 08:13:09.690107 18636 net.cpp:2270] res3a_branch2a_param_0(0.559) 
I0802 08:13:09.690111 18636 net.cpp:2270] res3a_branch2b_param_0(0.559) 
I0802 08:13:09.690115 18636 net.cpp:2270] res4a_branch2a_param_0(0.56) 
I0802 08:13:09.690119 18636 net.cpp:2270] res4a_branch2b_param_0(0.559) 
I0802 08:13:09.690121 18636 net.cpp:2270] res5a_branch2a_param_0(0.56) 
I0802 08:13:09.690130 18636 net.cpp:2270] res5a_branch2b_param_0(0.56) 
I0802 08:13:09.690135 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.31739e+06/2.86678e+06) 0.46
I0802 08:13:09.690147 18636 solver.cpp:550] Iteration 76000, Testing net (#0)
I0802 08:13:29.311144 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574941
I0802 08:13:29.311261 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805761
I0802 08:13:29.311270 18636 solver.cpp:635]     Test net output #2: loss = 1.88112 (* 1 = 1.88112 loss)
I0802 08:13:29.311291 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6206s
I0802 08:13:29.458905 18661 solver.cpp:450] Finding and applying sparsity: 0.57
I0802 08:14:04.003764 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:14:04.005677 18636 solver.cpp:353] Iteration 76000 (1.467 iter/s, 68.1663s/100 iter), loss = 1.45668
I0802 08:14:04.005699 18636 solver.cpp:375]     Train net output #0: loss = 1.28637 (* 1 = 1.28637 loss)
I0802 08:14:04.005707 18636 sgd_solver.cpp:136] Iteration 76000, lr = 0.00525, m = 0.9
I0802 08:14:18.343466 18636 solver.cpp:353] Iteration 76100 (6.97478 iter/s, 14.3374s/100 iter), loss = 1.07852
I0802 08:14:18.343513 18636 solver.cpp:375]     Train net output #0: loss = 0.916718 (* 1 = 0.916718 loss)
I0802 08:14:18.343520 18636 sgd_solver.cpp:136] Iteration 76100, lr = 0.00524375, m = 0.9
I0802 08:14:32.326293 18636 solver.cpp:353] Iteration 76200 (7.15183 iter/s, 13.9824s/100 iter), loss = 1.10464
I0802 08:14:32.326344 18636 solver.cpp:375]     Train net output #0: loss = 1.46668 (* 1 = 1.46668 loss)
I0802 08:14:32.326356 18636 sgd_solver.cpp:136] Iteration 76200, lr = 0.0052375, m = 0.9
I0802 08:14:46.292982 18636 solver.cpp:353] Iteration 76300 (7.16009 iter/s, 13.9663s/100 iter), loss = 1.17117
I0802 08:14:46.293922 18636 solver.cpp:375]     Train net output #0: loss = 1.1837 (* 1 = 1.1837 loss)
I0802 08:14:46.293929 18636 sgd_solver.cpp:136] Iteration 76300, lr = 0.00523125, m = 0.9
I0802 08:15:00.200189 18636 solver.cpp:353] Iteration 76400 (7.19072 iter/s, 13.9068s/100 iter), loss = 1.24655
I0802 08:15:00.200218 18636 solver.cpp:375]     Train net output #0: loss = 1.08557 (* 1 = 1.08557 loss)
I0802 08:15:00.200225 18636 sgd_solver.cpp:136] Iteration 76400, lr = 0.005225, m = 0.9
I0802 08:15:14.188031 18636 solver.cpp:353] Iteration 76500 (7.14926 iter/s, 13.9875s/100 iter), loss = 1.25519
I0802 08:15:14.188138 18636 solver.cpp:375]     Train net output #0: loss = 1.24763 (* 1 = 1.24763 loss)
I0802 08:15:14.188156 18636 sgd_solver.cpp:136] Iteration 76500, lr = 0.00521875, m = 0.9
I0802 08:15:28.218001 18636 solver.cpp:353] Iteration 76600 (7.1278 iter/s, 14.0296s/100 iter), loss = 1.20024
I0802 08:15:28.218086 18636 solver.cpp:375]     Train net output #0: loss = 1.10367 (* 1 = 1.10367 loss)
I0802 08:15:28.218097 18636 sgd_solver.cpp:136] Iteration 76600, lr = 0.0052125, m = 0.9
I0802 08:15:42.292749 18636 solver.cpp:353] Iteration 76700 (7.10512 iter/s, 14.0744s/100 iter), loss = 1.31893
I0802 08:15:42.292779 18636 solver.cpp:375]     Train net output #0: loss = 1.53437 (* 1 = 1.53437 loss)
I0802 08:15:42.292785 18636 sgd_solver.cpp:136] Iteration 76700, lr = 0.00520625, m = 0.9
I0802 08:15:56.241667 18636 solver.cpp:353] Iteration 76800 (7.16921 iter/s, 13.9485s/100 iter), loss = 1.24894
I0802 08:15:56.241721 18636 solver.cpp:375]     Train net output #0: loss = 1.18864 (* 1 = 1.18864 loss)
I0802 08:15:56.241734 18636 sgd_solver.cpp:136] Iteration 76800, lr = 0.0052, m = 0.9
I0802 08:16:10.150779 18636 solver.cpp:353] Iteration 76900 (7.18973 iter/s, 13.9087s/100 iter), loss = 1.38769
I0802 08:16:10.150837 18636 solver.cpp:375]     Train net output #0: loss = 1.44202 (* 1 = 1.44202 loss)
I0802 08:16:10.150842 18636 sgd_solver.cpp:136] Iteration 76900, lr = 0.00519375, m = 0.9
I0802 08:16:24.028152 18636 solver.cpp:404] Sparsity after update:
I0802 08:16:24.038656 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:16:24.038671 18636 net.cpp:2270] conv1a_param_0(0.278) 
I0802 08:16:24.038679 18636 net.cpp:2270] conv1b_param_0(0.567) 
I0802 08:16:24.038682 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:16:24.038686 18636 net.cpp:2270] res2a_branch2a_param_0(0.569) 
I0802 08:16:24.038689 18636 net.cpp:2270] res2a_branch2b_param_0(0.566) 
I0802 08:16:24.038699 18636 net.cpp:2270] res3a_branch2a_param_0(0.569) 
I0802 08:16:24.038705 18636 net.cpp:2270] res3a_branch2b_param_0(0.569) 
I0802 08:16:24.038710 18636 net.cpp:2270] res4a_branch2a_param_0(0.569) 
I0802 08:16:24.038715 18636 net.cpp:2270] res4a_branch2b_param_0(0.569) 
I0802 08:16:24.038719 18636 net.cpp:2270] res5a_branch2a_param_0(0.57) 
I0802 08:16:24.038724 18636 net.cpp:2270] res5a_branch2b_param_0(0.569) 
I0802 08:16:24.038728 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.34068e+06/2.86678e+06) 0.468
I0802 08:16:24.167753 18661 solver.cpp:450] Finding and applying sparsity: 0.58
I0802 08:16:59.883116 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:16:59.885057 18636 solver.cpp:353] Iteration 77000 (2.01074 iter/s, 49.7329s/100 iter), loss = 1.29005
I0802 08:16:59.885074 18636 solver.cpp:375]     Train net output #0: loss = 1.4213 (* 1 = 1.4213 loss)
I0802 08:16:59.885079 18636 sgd_solver.cpp:136] Iteration 77000, lr = 0.0051875, m = 0.9
I0802 08:17:14.268240 18636 solver.cpp:353] Iteration 77100 (6.95276 iter/s, 14.3828s/100 iter), loss = 1.25629
I0802 08:17:14.268268 18636 solver.cpp:375]     Train net output #0: loss = 1.08426 (* 1 = 1.08426 loss)
I0802 08:17:14.268275 18636 sgd_solver.cpp:136] Iteration 77100, lr = 0.00518125, m = 0.9
I0802 08:17:28.153934 18636 solver.cpp:353] Iteration 77200 (7.20186 iter/s, 13.8853s/100 iter), loss = 1.19158
I0802 08:17:28.153959 18636 solver.cpp:375]     Train net output #0: loss = 0.868437 (* 1 = 0.868437 loss)
I0802 08:17:28.153964 18636 sgd_solver.cpp:136] Iteration 77200, lr = 0.005175, m = 0.9
I0802 08:17:42.071753 18636 solver.cpp:353] Iteration 77300 (7.18523 iter/s, 13.9174s/100 iter), loss = 1.28968
I0802 08:17:42.071847 18636 solver.cpp:375]     Train net output #0: loss = 1.15461 (* 1 = 1.15461 loss)
I0802 08:17:42.071854 18636 sgd_solver.cpp:136] Iteration 77300, lr = 0.00516875, m = 0.9
I0802 08:17:55.962553 18636 solver.cpp:353] Iteration 77400 (7.19921 iter/s, 13.8904s/100 iter), loss = 1.60079
I0802 08:17:55.962579 18636 solver.cpp:375]     Train net output #0: loss = 1.18907 (* 1 = 1.18907 loss)
I0802 08:17:55.962584 18636 sgd_solver.cpp:136] Iteration 77400, lr = 0.0051625, m = 0.9
I0802 08:18:09.949780 18636 solver.cpp:353] Iteration 77500 (7.14958 iter/s, 13.9868s/100 iter), loss = 1.64344
I0802 08:18:09.949856 18636 solver.cpp:375]     Train net output #0: loss = 1.39875 (* 1 = 1.39875 loss)
I0802 08:18:09.949874 18636 sgd_solver.cpp:136] Iteration 77500, lr = 0.00515625, m = 0.9
I0802 08:18:24.371942 18636 solver.cpp:353] Iteration 77600 (6.93396 iter/s, 14.4218s/100 iter), loss = 1.16385
I0802 08:18:24.372042 18636 solver.cpp:375]     Train net output #0: loss = 1.03967 (* 1 = 1.03967 loss)
I0802 08:18:24.372051 18636 sgd_solver.cpp:136] Iteration 77600, lr = 0.00515, m = 0.9
I0802 08:18:38.402966 18636 solver.cpp:353] Iteration 77700 (7.12726 iter/s, 14.0306s/100 iter), loss = 1.51309
I0802 08:18:38.402993 18636 solver.cpp:375]     Train net output #0: loss = 1.47739 (* 1 = 1.47739 loss)
I0802 08:18:38.402999 18636 sgd_solver.cpp:136] Iteration 77700, lr = 0.00514375, m = 0.9
I0802 08:18:52.366325 18636 solver.cpp:353] Iteration 77800 (7.1618 iter/s, 13.963s/100 iter), loss = 1.22672
I0802 08:18:52.366358 18636 solver.cpp:375]     Train net output #0: loss = 1.45643 (* 1 = 1.45643 loss)
I0802 08:18:52.366364 18636 sgd_solver.cpp:136] Iteration 77800, lr = 0.0051375, m = 0.9
I0802 08:19:06.256942 18636 solver.cpp:353] Iteration 77900 (7.1993 iter/s, 13.8902s/100 iter), loss = 0.986368
I0802 08:19:06.256999 18636 solver.cpp:375]     Train net output #0: loss = 0.845375 (* 1 = 0.845375 loss)
I0802 08:19:06.257004 18636 sgd_solver.cpp:136] Iteration 77900, lr = 0.00513125, m = 0.9
I0802 08:19:20.090966 18636 solver.cpp:404] Sparsity after update:
I0802 08:19:20.095268 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:19:20.095280 18636 net.cpp:2270] conv1a_param_0(0.278) 
I0802 08:19:20.095289 18636 net.cpp:2270] conv1b_param_0(0.567) 
I0802 08:19:20.095293 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:19:20.095299 18636 net.cpp:2270] res2a_branch2a_param_0(0.58) 
I0802 08:19:20.095301 18636 net.cpp:2270] res2a_branch2b_param_0(0.572) 
I0802 08:19:20.095304 18636 net.cpp:2270] res3a_branch2a_param_0(0.58) 
I0802 08:19:20.095309 18636 net.cpp:2270] res3a_branch2b_param_0(0.58) 
I0802 08:19:20.095311 18636 net.cpp:2270] res4a_branch2a_param_0(0.58) 
I0802 08:19:20.095315 18636 net.cpp:2270] res4a_branch2b_param_0(0.58) 
I0802 08:19:20.095319 18636 net.cpp:2270] res5a_branch2a_param_0(0.58) 
I0802 08:19:20.095324 18636 net.cpp:2270] res5a_branch2b_param_0(0.58) 
I0802 08:19:20.095327 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.3646e+06/2.86678e+06) 0.476
I0802 08:19:20.095340 18636 solver.cpp:550] Iteration 78000, Testing net (#0)
I0802 08:19:39.661051 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578765
I0802 08:19:39.661154 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810644
I0802 08:19:39.661164 18636 solver.cpp:635]     Test net output #2: loss = 1.83807 (* 1 = 1.83807 loss)
I0802 08:19:39.661190 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5653s
I0802 08:19:39.823632 18661 solver.cpp:450] Finding and applying sparsity: 0.59
I0802 08:20:15.916676 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:20:15.918823 18636 solver.cpp:353] Iteration 78000 (1.43554 iter/s, 69.66s/100 iter), loss = 1.28687
I0802 08:20:15.918860 18636 solver.cpp:375]     Train net output #0: loss = 1.25517 (* 1 = 1.25517 loss)
I0802 08:20:15.918870 18636 sgd_solver.cpp:136] Iteration 78000, lr = 0.005125, m = 0.9
I0802 08:20:30.354903 18636 solver.cpp:353] Iteration 78100 (6.92728 iter/s, 14.4357s/100 iter), loss = 1.34036
I0802 08:20:30.354928 18636 solver.cpp:375]     Train net output #0: loss = 1.27248 (* 1 = 1.27248 loss)
I0802 08:20:30.354933 18636 sgd_solver.cpp:136] Iteration 78100, lr = 0.00511875, m = 0.9
I0802 08:20:44.187207 18636 solver.cpp:353] Iteration 78200 (7.22965 iter/s, 13.8319s/100 iter), loss = 1.24309
I0802 08:20:44.187237 18636 solver.cpp:375]     Train net output #0: loss = 1.31145 (* 1 = 1.31145 loss)
I0802 08:20:44.187243 18636 sgd_solver.cpp:136] Iteration 78200, lr = 0.0051125, m = 0.9
I0802 08:20:58.086968 18636 solver.cpp:353] Iteration 78300 (7.19457 iter/s, 13.8994s/100 iter), loss = 1.34501
I0802 08:20:58.087075 18636 solver.cpp:375]     Train net output #0: loss = 1.25495 (* 1 = 1.25495 loss)
I0802 08:20:58.087082 18636 sgd_solver.cpp:136] Iteration 78300, lr = 0.00510625, m = 0.9
I0802 08:21:12.019338 18636 solver.cpp:353] Iteration 78400 (7.17773 iter/s, 13.932s/100 iter), loss = 1.6249
I0802 08:21:12.019368 18636 solver.cpp:375]     Train net output #0: loss = 1.61225 (* 1 = 1.61225 loss)
I0802 08:21:12.019374 18636 sgd_solver.cpp:136] Iteration 78400, lr = 0.0051, m = 0.9
I0802 08:21:26.033515 18636 solver.cpp:353] Iteration 78500 (7.13583 iter/s, 14.0138s/100 iter), loss = 1.07121
I0802 08:21:26.033545 18636 solver.cpp:375]     Train net output #0: loss = 1.14162 (* 1 = 1.14162 loss)
I0802 08:21:26.033551 18636 sgd_solver.cpp:136] Iteration 78500, lr = 0.00509375, m = 0.9
I0802 08:21:40.026865 18636 solver.cpp:353] Iteration 78600 (7.14645 iter/s, 13.993s/100 iter), loss = 1.37187
I0802 08:21:40.026952 18636 solver.cpp:375]     Train net output #0: loss = 1.58404 (* 1 = 1.58404 loss)
I0802 08:21:40.026958 18636 sgd_solver.cpp:136] Iteration 78600, lr = 0.0050875, m = 0.9
I0802 08:21:53.925032 18636 solver.cpp:353] Iteration 78700 (7.19539 iter/s, 13.8978s/100 iter), loss = 1.50024
I0802 08:21:53.925142 18636 solver.cpp:375]     Train net output #0: loss = 1.44175 (* 1 = 1.44175 loss)
I0802 08:21:53.925166 18636 sgd_solver.cpp:136] Iteration 78700, lr = 0.00508125, m = 0.9
I0802 08:22:07.840158 18636 solver.cpp:353] Iteration 78800 (7.18662 iter/s, 13.9147s/100 iter), loss = 1.52296
I0802 08:22:07.840194 18636 solver.cpp:375]     Train net output #0: loss = 1.31754 (* 1 = 1.31754 loss)
I0802 08:22:07.840200 18636 sgd_solver.cpp:136] Iteration 78800, lr = 0.005075, m = 0.9
I0802 08:22:21.799145 18636 solver.cpp:353] Iteration 78900 (7.16404 iter/s, 13.9586s/100 iter), loss = 1.12924
I0802 08:22:21.799223 18636 solver.cpp:375]     Train net output #0: loss = 1.18742 (* 1 = 1.18742 loss)
I0802 08:22:21.799232 18636 sgd_solver.cpp:136] Iteration 78900, lr = 0.00506875, m = 0.9
I0802 08:22:35.525624 18636 solver.cpp:404] Sparsity after update:
I0802 08:22:35.538538 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:22:35.538599 18636 net.cpp:2270] conv1a_param_0(0.29) 
I0802 08:22:35.538620 18636 net.cpp:2270] conv1b_param_0(0.58) 
I0802 08:22:35.538633 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:22:35.538652 18636 net.cpp:2270] res2a_branch2a_param_0(0.587) 
I0802 08:22:35.538666 18636 net.cpp:2270] res2a_branch2b_param_0(0.579) 
I0802 08:22:35.538678 18636 net.cpp:2270] res3a_branch2a_param_0(0.589) 
I0802 08:22:35.538691 18636 net.cpp:2270] res3a_branch2b_param_0(0.586) 
I0802 08:22:35.538702 18636 net.cpp:2270] res4a_branch2a_param_0(0.589) 
I0802 08:22:35.538714 18636 net.cpp:2270] res4a_branch2b_param_0(0.589) 
I0802 08:22:35.538727 18636 net.cpp:2270] res5a_branch2a_param_0(0.59) 
I0802 08:22:35.538738 18636 net.cpp:2270] res5a_branch2b_param_0(0.589) 
I0802 08:22:35.538750 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.38725e+06/2.86678e+06) 0.484
I0802 08:22:35.668232 18661 solver.cpp:450] Finding and applying sparsity: 0.6
I0802 08:23:12.899114 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:23:12.901078 18636 solver.cpp:353] Iteration 79000 (1.95693 iter/s, 51.1005s/100 iter), loss = 1.22542
I0802 08:23:12.901108 18636 solver.cpp:375]     Train net output #0: loss = 1.16044 (* 1 = 1.16044 loss)
I0802 08:23:12.901120 18636 sgd_solver.cpp:136] Iteration 79000, lr = 0.0050625, m = 0.9
I0802 08:23:27.249292 18636 solver.cpp:353] Iteration 79100 (6.9697 iter/s, 14.3478s/100 iter), loss = 1.38256
I0802 08:23:27.249322 18636 solver.cpp:375]     Train net output #0: loss = 1.07833 (* 1 = 1.07833 loss)
I0802 08:23:27.249328 18636 sgd_solver.cpp:136] Iteration 79100, lr = 0.00505625, m = 0.9
I0802 08:23:41.148561 18636 solver.cpp:353] Iteration 79200 (7.19483 iter/s, 13.8989s/100 iter), loss = 1.50554
I0802 08:23:41.148598 18636 solver.cpp:375]     Train net output #0: loss = 1.57927 (* 1 = 1.57927 loss)
I0802 08:23:41.148607 18636 sgd_solver.cpp:136] Iteration 79200, lr = 0.00505, m = 0.9
I0802 08:23:55.041637 18636 solver.cpp:353] Iteration 79300 (7.19803 iter/s, 13.8927s/100 iter), loss = 0.911328
I0802 08:23:55.041738 18636 solver.cpp:375]     Train net output #0: loss = 0.976643 (* 1 = 0.976643 loss)
I0802 08:23:55.041749 18636 sgd_solver.cpp:136] Iteration 79300, lr = 0.00504375, m = 0.9
I0802 08:24:08.928073 18636 solver.cpp:353] Iteration 79400 (7.20147 iter/s, 13.8861s/100 iter), loss = 1.57239
I0802 08:24:08.928143 18636 solver.cpp:375]     Train net output #0: loss = 1.75079 (* 1 = 1.75079 loss)
I0802 08:24:08.928156 18636 sgd_solver.cpp:136] Iteration 79400, lr = 0.0050375, m = 0.9
I0802 08:24:22.854384 18636 solver.cpp:353] Iteration 79500 (7.18085 iter/s, 13.9259s/100 iter), loss = 1.3449
I0802 08:24:22.854414 18636 solver.cpp:375]     Train net output #0: loss = 1.44048 (* 1 = 1.44048 loss)
I0802 08:24:22.854420 18636 sgd_solver.cpp:136] Iteration 79500, lr = 0.00503125, m = 0.9
I0802 08:24:36.779860 18636 solver.cpp:353] Iteration 79600 (7.18128 iter/s, 13.9251s/100 iter), loss = 1.04484
I0802 08:24:36.779914 18636 solver.cpp:375]     Train net output #0: loss = 1.1605 (* 1 = 1.1605 loss)
I0802 08:24:36.779920 18636 sgd_solver.cpp:136] Iteration 79600, lr = 0.005025, m = 0.9
I0802 08:24:50.643939 18636 solver.cpp:353] Iteration 79700 (7.21309 iter/s, 13.8637s/100 iter), loss = 1.41923
I0802 08:24:50.643967 18636 solver.cpp:375]     Train net output #0: loss = 1.61653 (* 1 = 1.61653 loss)
I0802 08:24:50.643973 18636 sgd_solver.cpp:136] Iteration 79700, lr = 0.00501875, m = 0.9
I0802 08:25:04.564327 18636 solver.cpp:353] Iteration 79800 (7.18391 iter/s, 13.92s/100 iter), loss = 1.2544
I0802 08:25:04.564353 18636 solver.cpp:375]     Train net output #0: loss = 0.954917 (* 1 = 0.954917 loss)
I0802 08:25:04.564359 18636 sgd_solver.cpp:136] Iteration 79800, lr = 0.0050125, m = 0.9
I0802 08:25:18.406965 18636 solver.cpp:353] Iteration 79900 (7.22426 iter/s, 13.8423s/100 iter), loss = 1.60874
I0802 08:25:18.407025 18636 solver.cpp:375]     Train net output #0: loss = 1.49709 (* 1 = 1.49709 loss)
I0802 08:25:18.407032 18636 sgd_solver.cpp:136] Iteration 79900, lr = 0.00500625, m = 0.9
I0802 08:25:32.104825 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_80000.caffemodel
I0802 08:25:32.213457 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_80000.solverstate
I0802 08:25:32.218302 18636 solver.cpp:404] Sparsity after update:
I0802 08:25:32.219527 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:25:32.219537 18636 net.cpp:2270] conv1a_param_0(0.29) 
I0802 08:25:32.219543 18636 net.cpp:2270] conv1b_param_0(0.594) 
I0802 08:25:32.219547 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:25:32.219548 18636 net.cpp:2270] res2a_branch2a_param_0(0.597) 
I0802 08:25:32.219554 18636 net.cpp:2270] res2a_branch2b_param_0(0.591) 
I0802 08:25:32.219557 18636 net.cpp:2270] res3a_branch2a_param_0(0.599) 
I0802 08:25:32.219561 18636 net.cpp:2270] res3a_branch2b_param_0(0.596) 
I0802 08:25:32.219563 18636 net.cpp:2270] res4a_branch2a_param_0(0.6) 
I0802 08:25:32.219565 18636 net.cpp:2270] res4a_branch2b_param_0(0.599) 
I0802 08:25:32.219568 18636 net.cpp:2270] res5a_branch2a_param_0(0.6) 
I0802 08:25:32.219568 18636 net.cpp:2270] res5a_branch2b_param_0(0.6) 
I0802 08:25:32.219571 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.41125e+06/2.86678e+06) 0.492
I0802 08:25:32.219583 18636 solver.cpp:550] Iteration 80000, Testing net (#0)
I0802 08:25:40.773552 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:25:51.836937 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.586235
I0802 08:25:51.837065 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817761
I0802 08:25:51.837074 18636 solver.cpp:635]     Test net output #2: loss = 1.80879 (* 1 = 1.80879 loss)
I0802 08:25:51.837096 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.617s
I0802 08:25:51.984975 18661 solver.cpp:450] Finding and applying sparsity: 0.61
I0802 08:26:29.894803 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:26:29.896733 18636 solver.cpp:353] Iteration 80000 (1.39884 iter/s, 71.4878s/100 iter), loss = 1.18251
I0802 08:26:29.896750 18636 solver.cpp:375]     Train net output #0: loss = 1.24914 (* 1 = 1.24914 loss)
I0802 08:26:29.896756 18636 sgd_solver.cpp:136] Iteration 80000, lr = 0.005, m = 0.9
I0802 08:26:44.253335 18636 solver.cpp:353] Iteration 80100 (6.96563 iter/s, 14.3562s/100 iter), loss = 1.42974
I0802 08:26:44.253360 18636 solver.cpp:375]     Train net output #0: loss = 1.50574 (* 1 = 1.50574 loss)
I0802 08:26:44.253365 18636 sgd_solver.cpp:136] Iteration 80100, lr = 0.00499375, m = 0.9
I0802 08:26:58.166296 18636 solver.cpp:353] Iteration 80200 (7.18775 iter/s, 13.9126s/100 iter), loss = 1.11287
I0802 08:26:58.166339 18636 solver.cpp:375]     Train net output #0: loss = 1.4231 (* 1 = 1.4231 loss)
I0802 08:26:58.166349 18636 sgd_solver.cpp:136] Iteration 80200, lr = 0.0049875, m = 0.9
I0802 08:27:12.129176 18636 solver.cpp:353] Iteration 80300 (7.16205 iter/s, 13.9625s/100 iter), loss = 1.00964
I0802 08:27:12.129305 18636 solver.cpp:375]     Train net output #0: loss = 1.07273 (* 1 = 1.07273 loss)
I0802 08:27:12.129318 18636 sgd_solver.cpp:136] Iteration 80300, lr = 0.00498125, m = 0.9
I0802 08:27:26.099581 18636 solver.cpp:353] Iteration 80400 (7.15819 iter/s, 13.97s/100 iter), loss = 1.28263
I0802 08:27:26.099671 18636 solver.cpp:375]     Train net output #0: loss = 1.32564 (* 1 = 1.32564 loss)
I0802 08:27:26.099691 18636 sgd_solver.cpp:136] Iteration 80400, lr = 0.004975, m = 0.9
I0802 08:27:40.020251 18636 solver.cpp:353] Iteration 80500 (7.18376 iter/s, 13.9203s/100 iter), loss = 1.39533
I0802 08:27:40.020277 18636 solver.cpp:375]     Train net output #0: loss = 1.24234 (* 1 = 1.24234 loss)
I0802 08:27:40.020283 18636 sgd_solver.cpp:136] Iteration 80500, lr = 0.00496875, m = 0.9
I0802 08:27:53.993978 18636 solver.cpp:353] Iteration 80600 (7.15649 iter/s, 13.9733s/100 iter), loss = 1.88848
I0802 08:27:53.994040 18636 solver.cpp:375]     Train net output #0: loss = 2.15348 (* 1 = 2.15348 loss)
I0802 08:27:53.994046 18636 sgd_solver.cpp:136] Iteration 80600, lr = 0.0049625, m = 0.9
I0802 08:28:07.955111 18636 solver.cpp:353] Iteration 80700 (7.16294 iter/s, 13.9607s/100 iter), loss = 1.36112
I0802 08:28:07.955144 18636 solver.cpp:375]     Train net output #0: loss = 1.59342 (* 1 = 1.59342 loss)
I0802 08:28:07.955149 18636 sgd_solver.cpp:136] Iteration 80700, lr = 0.00495625, m = 0.9
I0802 08:28:21.922616 18636 solver.cpp:353] Iteration 80800 (7.15968 iter/s, 13.9671s/100 iter), loss = 1.15291
I0802 08:28:21.922650 18636 solver.cpp:375]     Train net output #0: loss = 1.41829 (* 1 = 1.41829 loss)
I0802 08:28:21.922657 18636 sgd_solver.cpp:136] Iteration 80800, lr = 0.00495, m = 0.9
I0802 08:28:35.958209 18636 solver.cpp:353] Iteration 80900 (7.12494 iter/s, 14.0352s/100 iter), loss = 1.20137
I0802 08:28:35.958314 18636 solver.cpp:375]     Train net output #0: loss = 1.27187 (* 1 = 1.27187 loss)
I0802 08:28:35.958323 18636 sgd_solver.cpp:136] Iteration 80900, lr = 0.00494375, m = 0.9
I0802 08:28:49.810437 18636 solver.cpp:404] Sparsity after update:
I0802 08:28:49.820920 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:28:49.820935 18636 net.cpp:2270] conv1a_param_0(0.291) 
I0802 08:28:49.820945 18636 net.cpp:2270] conv1b_param_0(0.595) 
I0802 08:28:49.820950 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:28:49.820952 18636 net.cpp:2270] res2a_branch2a_param_0(0.608) 
I0802 08:28:49.820955 18636 net.cpp:2270] res2a_branch2b_param_0(0.597) 
I0802 08:28:49.820960 18636 net.cpp:2270] res3a_branch2a_param_0(0.609) 
I0802 08:28:49.820962 18636 net.cpp:2270] res3a_branch2b_param_0(0.607) 
I0802 08:28:49.820966 18636 net.cpp:2270] res4a_branch2a_param_0(0.609) 
I0802 08:28:49.820968 18636 net.cpp:2270] res4a_branch2b_param_0(0.609) 
I0802 08:28:49.820971 18636 net.cpp:2270] res5a_branch2a_param_0(0.61) 
I0802 08:28:49.820974 18636 net.cpp:2270] res5a_branch2b_param_0(0.609) 
I0802 08:28:49.820978 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.4344e+06/2.86678e+06) 0.5
I0802 08:28:49.953758 18661 solver.cpp:450] Finding and applying sparsity: 0.62
I0802 08:29:28.985553 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:29:28.990823 18636 solver.cpp:353] Iteration 81000 (1.88568 iter/s, 53.0312s/100 iter), loss = 1.35476
I0802 08:29:28.990846 18636 solver.cpp:375]     Train net output #0: loss = 1.29426 (* 1 = 1.29426 loss)
I0802 08:29:28.990852 18636 sgd_solver.cpp:136] Iteration 81000, lr = 0.0049375, m = 0.9
I0802 08:29:43.303635 18636 solver.cpp:353] Iteration 81100 (6.98694 iter/s, 14.3124s/100 iter), loss = 1.3264
I0802 08:29:43.303699 18636 solver.cpp:375]     Train net output #0: loss = 1.00546 (* 1 = 1.00546 loss)
I0802 08:29:43.303715 18636 sgd_solver.cpp:136] Iteration 81100, lr = 0.00493125, m = 0.9
I0802 08:29:57.279871 18636 solver.cpp:353] Iteration 81200 (7.1552 iter/s, 13.9758s/100 iter), loss = 1.39455
I0802 08:29:57.279896 18636 solver.cpp:375]     Train net output #0: loss = 1.48593 (* 1 = 1.48593 loss)
I0802 08:29:57.279901 18636 sgd_solver.cpp:136] Iteration 81200, lr = 0.004925, m = 0.9
I0802 08:30:11.161691 18636 solver.cpp:353] Iteration 81300 (7.20387 iter/s, 13.8814s/100 iter), loss = 1.2342
I0802 08:30:11.161773 18636 solver.cpp:375]     Train net output #0: loss = 0.823726 (* 1 = 0.823726 loss)
I0802 08:30:11.161780 18636 sgd_solver.cpp:136] Iteration 81300, lr = 0.00491875, m = 0.9
I0802 08:30:25.125581 18636 solver.cpp:353] Iteration 81400 (7.16153 iter/s, 13.9635s/100 iter), loss = 1.22532
I0802 08:30:25.125607 18636 solver.cpp:375]     Train net output #0: loss = 1.27855 (* 1 = 1.27855 loss)
I0802 08:30:25.125612 18636 sgd_solver.cpp:136] Iteration 81400, lr = 0.0049125, m = 0.9
I0802 08:30:39.130906 18636 solver.cpp:353] Iteration 81500 (7.14034 iter/s, 14.0049s/100 iter), loss = 1.39802
I0802 08:30:39.130933 18636 solver.cpp:375]     Train net output #0: loss = 1.33604 (* 1 = 1.33604 loss)
I0802 08:30:39.130937 18636 sgd_solver.cpp:136] Iteration 81500, lr = 0.00490625, m = 0.9
I0802 08:30:53.087574 18636 solver.cpp:353] Iteration 81600 (7.16523 iter/s, 13.9563s/100 iter), loss = 1.28745
I0802 08:30:53.087642 18636 solver.cpp:375]     Train net output #0: loss = 1.37188 (* 1 = 1.37188 loss)
I0802 08:30:53.087648 18636 sgd_solver.cpp:136] Iteration 81600, lr = 0.0049, m = 0.9
I0802 08:31:07.033478 18636 solver.cpp:353] Iteration 81700 (7.17076 iter/s, 13.9455s/100 iter), loss = 1.12058
I0802 08:31:07.033501 18636 solver.cpp:375]     Train net output #0: loss = 1.01834 (* 1 = 1.01834 loss)
I0802 08:31:07.033506 18636 sgd_solver.cpp:136] Iteration 81700, lr = 0.00489375, m = 0.9
I0802 08:31:20.947892 18636 solver.cpp:353] Iteration 81800 (7.18699 iter/s, 13.914s/100 iter), loss = 1.72613
I0802 08:31:20.947916 18636 solver.cpp:375]     Train net output #0: loss = 1.4465 (* 1 = 1.4465 loss)
I0802 08:31:20.947919 18636 sgd_solver.cpp:136] Iteration 81800, lr = 0.0048875, m = 0.9
I0802 08:31:34.986563 18636 solver.cpp:353] Iteration 81900 (7.12338 iter/s, 14.0383s/100 iter), loss = 1.2489
I0802 08:31:34.986642 18636 solver.cpp:375]     Train net output #0: loss = 1.07763 (* 1 = 1.07763 loss)
I0802 08:31:34.986649 18636 sgd_solver.cpp:136] Iteration 81900, lr = 0.00488125, m = 0.9
I0802 08:31:48.838657 18636 solver.cpp:404] Sparsity after update:
I0802 08:31:48.843839 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:31:48.843875 18636 net.cpp:2270] conv1a_param_0(0.303) 
I0802 08:31:48.843904 18636 net.cpp:2270] conv1b_param_0(0.607) 
I0802 08:31:48.843917 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:31:48.843930 18636 net.cpp:2270] res2a_branch2a_param_0(0.618) 
I0802 08:31:48.843945 18636 net.cpp:2270] res2a_branch2b_param_0(0.608) 
I0802 08:31:48.843957 18636 net.cpp:2270] res3a_branch2a_param_0(0.62) 
I0802 08:31:48.843971 18636 net.cpp:2270] res3a_branch2b_param_0(0.617) 
I0802 08:31:48.843982 18636 net.cpp:2270] res4a_branch2a_param_0(0.62) 
I0802 08:31:48.843996 18636 net.cpp:2270] res4a_branch2b_param_0(0.62) 
I0802 08:31:48.844009 18636 net.cpp:2270] res5a_branch2a_param_0(0.62) 
I0802 08:31:48.844022 18636 net.cpp:2270] res5a_branch2b_param_0(0.62) 
I0802 08:31:48.844034 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.45842e+06/2.86678e+06) 0.509
I0802 08:31:48.844060 18636 solver.cpp:550] Iteration 82000, Testing net (#0)
I0802 08:32:08.723357 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.57647
I0802 08:32:08.723456 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810115
I0802 08:32:08.723466 18636 solver.cpp:635]     Test net output #2: loss = 1.83166 (* 1 = 1.83166 loss)
I0802 08:32:08.723487 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8789s
I0802 08:32:08.862314 18661 solver.cpp:450] Finding and applying sparsity: 0.63
I0802 08:32:48.822274 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:32:48.824334 18636 solver.cpp:353] Iteration 82000 (1.35436 iter/s, 73.8357s/100 iter), loss = 1.30475
I0802 08:32:48.824357 18636 solver.cpp:375]     Train net output #0: loss = 1.23373 (* 1 = 1.23373 loss)
I0802 08:32:48.824369 18636 sgd_solver.cpp:136] Iteration 82000, lr = 0.004875, m = 0.9
I0802 08:33:03.167552 18636 solver.cpp:353] Iteration 82100 (6.97213 iter/s, 14.3428s/100 iter), loss = 1.11683
I0802 08:33:03.167580 18636 solver.cpp:375]     Train net output #0: loss = 1.10106 (* 1 = 1.10106 loss)
I0802 08:33:03.167587 18636 sgd_solver.cpp:136] Iteration 82100, lr = 0.00486875, m = 0.9
I0802 08:33:17.173638 18636 solver.cpp:353] Iteration 82200 (7.13995 iter/s, 14.0057s/100 iter), loss = 1.3144
I0802 08:33:17.173663 18636 solver.cpp:375]     Train net output #0: loss = 1.15361 (* 1 = 1.15361 loss)
I0802 08:33:17.173669 18636 sgd_solver.cpp:136] Iteration 82200, lr = 0.0048625, m = 0.9
I0802 08:33:31.180074 18636 solver.cpp:353] Iteration 82300 (7.13978 iter/s, 14.006s/100 iter), loss = 1.39811
I0802 08:33:31.180136 18636 solver.cpp:375]     Train net output #0: loss = 1.18271 (* 1 = 1.18271 loss)
I0802 08:33:31.180143 18636 sgd_solver.cpp:136] Iteration 82300, lr = 0.00485625, m = 0.9
I0802 08:33:45.142235 18636 solver.cpp:353] Iteration 82400 (7.16242 iter/s, 13.9618s/100 iter), loss = 1.30661
I0802 08:33:45.142335 18636 solver.cpp:375]     Train net output #0: loss = 1.51205 (* 1 = 1.51205 loss)
I0802 08:33:45.142356 18636 sgd_solver.cpp:136] Iteration 82400, lr = 0.00485, m = 0.9
I0802 08:33:59.083524 18636 solver.cpp:353] Iteration 82500 (7.17314 iter/s, 13.9409s/100 iter), loss = 1.16339
I0802 08:33:59.083554 18636 solver.cpp:375]     Train net output #0: loss = 0.870602 (* 1 = 0.870602 loss)
I0802 08:33:59.083559 18636 sgd_solver.cpp:136] Iteration 82500, lr = 0.00484375, m = 0.9
I0802 08:34:13.149065 18636 solver.cpp:353] Iteration 82600 (7.10977 iter/s, 14.0652s/100 iter), loss = 1.52479
I0802 08:34:13.149147 18636 solver.cpp:375]     Train net output #0: loss = 1.7122 (* 1 = 1.7122 loss)
I0802 08:34:13.149154 18636 sgd_solver.cpp:136] Iteration 82600, lr = 0.0048375, m = 0.9
I0802 08:34:27.137925 18636 solver.cpp:353] Iteration 82700 (7.14874 iter/s, 13.9885s/100 iter), loss = 1.52391
I0802 08:34:27.137953 18636 solver.cpp:375]     Train net output #0: loss = 1.47082 (* 1 = 1.47082 loss)
I0802 08:34:27.137959 18636 sgd_solver.cpp:136] Iteration 82700, lr = 0.00483125, m = 0.9
I0802 08:34:41.082917 18636 solver.cpp:353] Iteration 82800 (7.17123 iter/s, 13.9446s/100 iter), loss = 1.63197
I0802 08:34:41.082947 18636 solver.cpp:375]     Train net output #0: loss = 1.80693 (* 1 = 1.80693 loss)
I0802 08:34:41.082952 18636 sgd_solver.cpp:136] Iteration 82800, lr = 0.004825, m = 0.9
I0802 08:34:55.061313 18636 solver.cpp:353] Iteration 82900 (7.15409 iter/s, 13.978s/100 iter), loss = 1.30194
I0802 08:34:55.061388 18636 solver.cpp:375]     Train net output #0: loss = 1.50527 (* 1 = 1.50527 loss)
I0802 08:34:55.061393 18636 sgd_solver.cpp:136] Iteration 82900, lr = 0.00481875, m = 0.9
I0802 08:35:08.970690 18636 solver.cpp:404] Sparsity after update:
I0802 08:35:08.982228 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:35:08.982240 18636 net.cpp:2270] conv1a_param_0(0.304) 
I0802 08:35:08.982246 18636 net.cpp:2270] conv1b_param_0(0.619) 
I0802 08:35:08.982249 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:35:08.982251 18636 net.cpp:2270] res2a_branch2a_param_0(0.628) 
I0802 08:35:08.982254 18636 net.cpp:2270] res2a_branch2b_param_0(0.614) 
I0802 08:35:08.982255 18636 net.cpp:2270] res3a_branch2a_param_0(0.628) 
I0802 08:35:08.982256 18636 net.cpp:2270] res3a_branch2b_param_0(0.627) 
I0802 08:35:08.982259 18636 net.cpp:2270] res4a_branch2a_param_0(0.629) 
I0802 08:35:08.982260 18636 net.cpp:2270] res4a_branch2b_param_0(0.628) 
I0802 08:35:08.982262 18636 net.cpp:2270] res5a_branch2a_param_0(0.63) 
I0802 08:35:08.982267 18636 net.cpp:2270] res5a_branch2b_param_0(0.629) 
I0802 08:35:08.982270 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.4812e+06/2.86678e+06) 0.517
I0802 08:35:09.111374 18661 solver.cpp:450] Finding and applying sparsity: 0.64
I0802 08:35:50.176528 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:35:50.178519 18636 solver.cpp:353] Iteration 83000 (1.81437 iter/s, 55.1157s/100 iter), loss = 1.37236
I0802 08:35:50.178546 18636 solver.cpp:375]     Train net output #0: loss = 1.45526 (* 1 = 1.45526 loss)
I0802 08:35:50.178555 18636 sgd_solver.cpp:136] Iteration 83000, lr = 0.0048125, m = 0.9
I0802 08:36:04.537715 18636 solver.cpp:353] Iteration 83100 (6.96438 iter/s, 14.3588s/100 iter), loss = 1.6284
I0802 08:36:04.537771 18636 solver.cpp:375]     Train net output #0: loss = 1.82038 (* 1 = 1.82038 loss)
I0802 08:36:04.537786 18636 sgd_solver.cpp:136] Iteration 83100, lr = 0.00480625, m = 0.9
I0802 08:36:18.457523 18636 solver.cpp:353] Iteration 83200 (7.18421 iter/s, 13.9194s/100 iter), loss = 1.29568
I0802 08:36:18.457550 18636 solver.cpp:375]     Train net output #0: loss = 1.79353 (* 1 = 1.79353 loss)
I0802 08:36:18.457556 18636 sgd_solver.cpp:136] Iteration 83200, lr = 0.0048, m = 0.9
I0802 08:36:32.445777 18636 solver.cpp:353] Iteration 83300 (7.14906 iter/s, 13.9879s/100 iter), loss = 1.322
I0802 08:36:32.445840 18636 solver.cpp:375]     Train net output #0: loss = 1.32145 (* 1 = 1.32145 loss)
I0802 08:36:32.445844 18636 sgd_solver.cpp:136] Iteration 83300, lr = 0.00479375, m = 0.9
I0802 08:36:46.400741 18636 solver.cpp:353] Iteration 83400 (7.16611 iter/s, 13.9546s/100 iter), loss = 2.04376
I0802 08:36:46.400775 18636 solver.cpp:375]     Train net output #0: loss = 2.11902 (* 1 = 2.11902 loss)
I0802 08:36:46.400781 18636 sgd_solver.cpp:136] Iteration 83400, lr = 0.0047875, m = 0.9
I0802 08:37:00.289937 18636 solver.cpp:353] Iteration 83500 (7.20004 iter/s, 13.8888s/100 iter), loss = 1.31913
I0802 08:37:00.289968 18636 solver.cpp:375]     Train net output #0: loss = 1.51814 (* 1 = 1.51814 loss)
I0802 08:37:00.289973 18636 sgd_solver.cpp:136] Iteration 83500, lr = 0.00478125, m = 0.9
I0802 08:37:14.097812 18636 solver.cpp:353] Iteration 83600 (7.24245 iter/s, 13.8075s/100 iter), loss = 1.72159
I0802 08:37:14.097915 18636 solver.cpp:375]     Train net output #0: loss = 1.77538 (* 1 = 1.77538 loss)
I0802 08:37:14.097923 18636 sgd_solver.cpp:136] Iteration 83600, lr = 0.004775, m = 0.9
I0802 08:37:28.048424 18636 solver.cpp:353] Iteration 83700 (7.16834 iter/s, 13.9502s/100 iter), loss = 1.3064
I0802 08:37:28.048449 18636 solver.cpp:375]     Train net output #0: loss = 1.48389 (* 1 = 1.48389 loss)
I0802 08:37:28.048454 18636 sgd_solver.cpp:136] Iteration 83700, lr = 0.00476875, m = 0.9
I0802 08:37:42.085304 18636 solver.cpp:353] Iteration 83800 (7.12429 iter/s, 14.0365s/100 iter), loss = 1.46614
I0802 08:37:42.085331 18636 solver.cpp:375]     Train net output #0: loss = 1.62069 (* 1 = 1.62069 loss)
I0802 08:37:42.085337 18636 sgd_solver.cpp:136] Iteration 83800, lr = 0.0047625, m = 0.9
I0802 08:37:56.027633 18636 solver.cpp:353] Iteration 83900 (7.1726 iter/s, 13.9419s/100 iter), loss = 1.4161
I0802 08:37:56.027768 18636 solver.cpp:375]     Train net output #0: loss = 1.49624 (* 1 = 1.49624 loss)
I0802 08:37:56.027788 18636 sgd_solver.cpp:136] Iteration 83900, lr = 0.00475625, m = 0.9
I0802 08:38:09.809615 18636 solver.cpp:404] Sparsity after update:
I0802 08:38:09.814463 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:38:09.814473 18636 net.cpp:2270] conv1a_param_0(0.304) 
I0802 08:38:09.814481 18636 net.cpp:2270] conv1b_param_0(0.631) 
I0802 08:38:09.814482 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:38:09.814484 18636 net.cpp:2270] res2a_branch2a_param_0(0.638) 
I0802 08:38:09.814486 18636 net.cpp:2270] res2a_branch2b_param_0(0.624) 
I0802 08:38:09.814488 18636 net.cpp:2270] res3a_branch2a_param_0(0.639) 
I0802 08:38:09.814491 18636 net.cpp:2270] res3a_branch2b_param_0(0.636) 
I0802 08:38:09.814492 18636 net.cpp:2270] res4a_branch2a_param_0(0.64) 
I0802 08:38:09.814496 18636 net.cpp:2270] res4a_branch2b_param_0(0.639) 
I0802 08:38:09.814498 18636 net.cpp:2270] res5a_branch2a_param_0(0.64) 
I0802 08:38:09.814499 18636 net.cpp:2270] res5a_branch2b_param_0(0.64) 
I0802 08:38:09.814502 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.50516e+06/2.86678e+06) 0.525
I0802 08:38:09.814512 18636 solver.cpp:550] Iteration 84000, Testing net (#0)
I0802 08:38:29.068907 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581294
I0802 08:38:29.069006 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.812232
I0802 08:38:29.069020 18636 solver.cpp:635]     Test net output #2: loss = 1.82919 (* 1 = 1.82919 loss)
I0802 08:38:29.069041 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.254s
I0802 08:38:29.206245 18661 solver.cpp:450] Finding and applying sparsity: 0.65
I0802 08:39:11.353955 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:39:11.355943 18636 solver.cpp:353] Iteration 84000 (1.32756 iter/s, 75.3262s/100 iter), loss = 1.50909
I0802 08:39:11.355962 18636 solver.cpp:375]     Train net output #0: loss = 1.81334 (* 1 = 1.81334 loss)
I0802 08:39:11.355967 18636 sgd_solver.cpp:136] Iteration 84000, lr = 0.00475, m = 0.9
I0802 08:39:25.627679 18636 solver.cpp:353] Iteration 84100 (7.00705 iter/s, 14.2713s/100 iter), loss = 1.38418
I0802 08:39:25.627709 18636 solver.cpp:375]     Train net output #0: loss = 1.42063 (* 1 = 1.42063 loss)
I0802 08:39:25.627715 18636 sgd_solver.cpp:136] Iteration 84100, lr = 0.00474375, m = 0.9
I0802 08:39:39.510905 18636 solver.cpp:353] Iteration 84200 (7.20314 iter/s, 13.8828s/100 iter), loss = 1.28011
I0802 08:39:39.510938 18636 solver.cpp:375]     Train net output #0: loss = 1.51217 (* 1 = 1.51217 loss)
I0802 08:39:39.510944 18636 sgd_solver.cpp:136] Iteration 84200, lr = 0.0047375, m = 0.9
I0802 08:39:53.377825 18636 solver.cpp:353] Iteration 84300 (7.21161 iter/s, 13.8665s/100 iter), loss = 1.66469
I0802 08:39:53.377887 18636 solver.cpp:375]     Train net output #0: loss = 1.52806 (* 1 = 1.52806 loss)
I0802 08:39:53.377894 18636 sgd_solver.cpp:136] Iteration 84300, lr = 0.00473125, m = 0.9
I0802 08:40:07.245970 18636 solver.cpp:353] Iteration 84400 (7.21097 iter/s, 13.8678s/100 iter), loss = 1.35266
I0802 08:40:07.245996 18636 solver.cpp:375]     Train net output #0: loss = 1.48416 (* 1 = 1.48416 loss)
I0802 08:40:07.246002 18636 sgd_solver.cpp:136] Iteration 84400, lr = 0.004725, m = 0.9
I0802 08:40:21.130336 18636 solver.cpp:353] Iteration 84500 (7.20255 iter/s, 13.884s/100 iter), loss = 1.53167
I0802 08:40:21.130363 18636 solver.cpp:375]     Train net output #0: loss = 1.29905 (* 1 = 1.29905 loss)
I0802 08:40:21.130369 18636 sgd_solver.cpp:136] Iteration 84500, lr = 0.00471875, m = 0.9
I0802 08:40:35.031826 18636 solver.cpp:353] Iteration 84600 (7.19367 iter/s, 13.9011s/100 iter), loss = 1.38658
I0802 08:40:35.031893 18636 solver.cpp:375]     Train net output #0: loss = 1.0045 (* 1 = 1.0045 loss)
I0802 08:40:35.031899 18636 sgd_solver.cpp:136] Iteration 84600, lr = 0.0047125, m = 0.9
I0802 08:40:48.909915 18636 solver.cpp:353] Iteration 84700 (7.2058 iter/s, 13.8777s/100 iter), loss = 1.40321
I0802 08:40:48.909940 18636 solver.cpp:375]     Train net output #0: loss = 1.1543 (* 1 = 1.1543 loss)
I0802 08:40:48.909945 18636 sgd_solver.cpp:136] Iteration 84700, lr = 0.00470625, m = 0.9
I0802 08:41:02.831507 18636 solver.cpp:353] Iteration 84800 (7.18329 iter/s, 13.9212s/100 iter), loss = 1.36079
I0802 08:41:02.831533 18636 solver.cpp:375]     Train net output #0: loss = 0.899291 (* 1 = 0.899291 loss)
I0802 08:41:02.831539 18636 sgd_solver.cpp:136] Iteration 84800, lr = 0.0047, m = 0.9
I0802 08:41:16.707743 18636 solver.cpp:353] Iteration 84900 (7.20676 iter/s, 13.8759s/100 iter), loss = 1.35346
I0802 08:41:16.707866 18636 solver.cpp:375]     Train net output #0: loss = 1.4303 (* 1 = 1.4303 loss)
I0802 08:41:16.707886 18636 sgd_solver.cpp:136] Iteration 84900, lr = 0.00469375, m = 0.9
I0802 08:41:30.561363 18636 solver.cpp:404] Sparsity after update:
I0802 08:41:30.572913 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:41:30.572928 18636 net.cpp:2270] conv1a_param_0(0.317) 
I0802 08:41:30.572937 18636 net.cpp:2270] conv1b_param_0(0.632) 
I0802 08:41:30.572940 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:41:30.572943 18636 net.cpp:2270] res2a_branch2a_param_0(0.648) 
I0802 08:41:30.572947 18636 net.cpp:2270] res2a_branch2b_param_0(0.63) 
I0802 08:41:30.572950 18636 net.cpp:2270] res3a_branch2a_param_0(0.649) 
I0802 08:41:30.572953 18636 net.cpp:2270] res3a_branch2b_param_0(0.646) 
I0802 08:41:30.572957 18636 net.cpp:2270] res4a_branch2a_param_0(0.649) 
I0802 08:41:30.572959 18636 net.cpp:2270] res4a_branch2b_param_0(0.649) 
I0802 08:41:30.572962 18636 net.cpp:2270] res5a_branch2a_param_0(0.65) 
I0802 08:41:30.572965 18636 net.cpp:2270] res5a_branch2b_param_0(0.649) 
I0802 08:41:30.572985 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.52831e+06/2.86678e+06) 0.533
I0802 08:41:30.702749 18661 solver.cpp:450] Finding and applying sparsity: 0.66
I0802 08:42:14.258988 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:42:14.261000 18636 solver.cpp:353] Iteration 85000 (1.73757 iter/s, 57.5517s/100 iter), loss = 1.25734
I0802 08:42:14.261046 18636 solver.cpp:375]     Train net output #0: loss = 1.01407 (* 1 = 1.01407 loss)
I0802 08:42:14.261055 18636 sgd_solver.cpp:136] Iteration 85000, lr = 0.0046875, m = 0.9
I0802 08:42:28.646077 18636 solver.cpp:353] Iteration 85100 (6.95184 iter/s, 14.3847s/100 iter), loss = 1.47939
I0802 08:42:28.646105 18636 solver.cpp:375]     Train net output #0: loss = 1.54512 (* 1 = 1.54512 loss)
I0802 08:42:28.646109 18636 sgd_solver.cpp:136] Iteration 85100, lr = 0.00468125, m = 0.9
I0802 08:42:42.676409 18636 solver.cpp:353] Iteration 85200 (7.12761 iter/s, 14.0299s/100 iter), loss = 1.09353
I0802 08:42:42.676434 18636 solver.cpp:375]     Train net output #0: loss = 1.01421 (* 1 = 1.01421 loss)
I0802 08:42:42.676439 18636 sgd_solver.cpp:136] Iteration 85200, lr = 0.004675, m = 0.9
I0802 08:42:56.656628 18636 solver.cpp:353] Iteration 85300 (7.15316 iter/s, 13.9798s/100 iter), loss = 1.60625
I0802 08:42:56.656682 18636 solver.cpp:375]     Train net output #0: loss = 1.42149 (* 1 = 1.42149 loss)
I0802 08:42:56.656688 18636 sgd_solver.cpp:136] Iteration 85300, lr = 0.00466875, m = 0.9
I0802 08:43:10.561394 18636 solver.cpp:353] Iteration 85400 (7.19198 iter/s, 13.9044s/100 iter), loss = 1.09982
I0802 08:43:10.561422 18636 solver.cpp:375]     Train net output #0: loss = 1.19813 (* 1 = 1.19813 loss)
I0802 08:43:10.561429 18636 sgd_solver.cpp:136] Iteration 85400, lr = 0.0046625, m = 0.9
I0802 08:43:24.499294 18636 solver.cpp:353] Iteration 85500 (7.17488 iter/s, 13.9375s/100 iter), loss = 1.41403
I0802 08:43:24.499321 18636 solver.cpp:375]     Train net output #0: loss = 1.52008 (* 1 = 1.52008 loss)
I0802 08:43:24.499327 18636 sgd_solver.cpp:136] Iteration 85500, lr = 0.00465625, m = 0.9
I0802 08:43:38.411670 18636 solver.cpp:353] Iteration 85600 (7.18805 iter/s, 13.912s/100 iter), loss = 1.59299
I0802 08:43:38.411749 18636 solver.cpp:375]     Train net output #0: loss = 1.72131 (* 1 = 1.72131 loss)
I0802 08:43:38.411756 18636 sgd_solver.cpp:136] Iteration 85600, lr = 0.00465, m = 0.9
I0802 08:43:52.422169 18636 solver.cpp:353] Iteration 85700 (7.1377 iter/s, 14.0101s/100 iter), loss = 1.14781
I0802 08:43:52.422248 18636 solver.cpp:375]     Train net output #0: loss = 1.32066 (* 1 = 1.32066 loss)
I0802 08:43:52.422272 18636 sgd_solver.cpp:136] Iteration 85700, lr = 0.00464375, m = 0.9
I0802 08:44:06.333395 18636 solver.cpp:353] Iteration 85800 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.11974
I0802 08:44:06.333511 18636 solver.cpp:375]     Train net output #0: loss = 1.27032 (* 1 = 1.27032 loss)
I0802 08:44:06.333535 18636 sgd_solver.cpp:136] Iteration 85800, lr = 0.0046375, m = 0.9
I0802 08:44:20.271857 18636 solver.cpp:353] Iteration 85900 (7.17459 iter/s, 13.9381s/100 iter), loss = 1.4261
I0802 08:44:20.276914 18636 solver.cpp:375]     Train net output #0: loss = 1.69123 (* 1 = 1.69123 loss)
I0802 08:44:20.276938 18636 sgd_solver.cpp:136] Iteration 85900, lr = 0.00463125, m = 0.9
I0802 08:44:34.047463 18636 solver.cpp:404] Sparsity after update:
I0802 08:44:34.054312 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:44:34.054330 18636 net.cpp:2270] conv1a_param_0(0.317) 
I0802 08:44:34.054338 18636 net.cpp:2270] conv1b_param_0(0.642) 
I0802 08:44:34.054342 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:44:34.054345 18636 net.cpp:2270] res2a_branch2a_param_0(0.658) 
I0802 08:44:34.054349 18636 net.cpp:2270] res2a_branch2b_param_0(0.64) 
I0802 08:44:34.054353 18636 net.cpp:2270] res3a_branch2a_param_0(0.66) 
I0802 08:44:34.054356 18636 net.cpp:2270] res3a_branch2b_param_0(0.655) 
I0802 08:44:34.054359 18636 net.cpp:2270] res4a_branch2a_param_0(0.66) 
I0802 08:44:34.054363 18636 net.cpp:2270] res4a_branch2b_param_0(0.659) 
I0802 08:44:34.054366 18636 net.cpp:2270] res5a_branch2a_param_0(0.66) 
I0802 08:44:34.054369 18636 net.cpp:2270] res5a_branch2b_param_0(0.66) 
I0802 08:44:34.054373 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.55223e+06/2.86678e+06) 0.541
I0802 08:44:34.054384 18636 solver.cpp:550] Iteration 86000, Testing net (#0)
I0802 08:44:48.171142 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 08:44:53.460463 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574705
I0802 08:44:53.460544 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811939
I0802 08:44:53.460551 18636 solver.cpp:635]     Test net output #2: loss = 1.85063 (* 1 = 1.85063 loss)
I0802 08:44:53.460571 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4057s
I0802 08:44:53.608839 18661 solver.cpp:450] Finding and applying sparsity: 0.67
I0802 08:45:38.115324 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:45:38.117326 18636 solver.cpp:353] Iteration 86000 (1.28463 iter/s, 77.8433s/100 iter), loss = 1.32319
I0802 08:45:38.117343 18636 solver.cpp:375]     Train net output #0: loss = 1.59326 (* 1 = 1.59326 loss)
I0802 08:45:38.117349 18636 sgd_solver.cpp:136] Iteration 86000, lr = 0.004625, m = 0.9
I0802 08:45:52.358584 18636 solver.cpp:353] Iteration 86100 (7.02205 iter/s, 14.2409s/100 iter), loss = 1.3768
I0802 08:45:52.358614 18636 solver.cpp:375]     Train net output #0: loss = 1.27371 (* 1 = 1.27371 loss)
I0802 08:45:52.358654 18636 sgd_solver.cpp:136] Iteration 86100, lr = 0.00461875, m = 0.9
I0802 08:46:06.321938 18636 solver.cpp:353] Iteration 86200 (7.1618 iter/s, 13.963s/100 iter), loss = 1.52258
I0802 08:46:06.321967 18636 solver.cpp:375]     Train net output #0: loss = 1.12805 (* 1 = 1.12805 loss)
I0802 08:46:06.321972 18636 sgd_solver.cpp:136] Iteration 86200, lr = 0.0046125, m = 0.9
I0802 08:46:20.257473 18636 solver.cpp:353] Iteration 86300 (7.1761 iter/s, 13.9351s/100 iter), loss = 1.40451
I0802 08:46:20.257572 18636 solver.cpp:375]     Train net output #0: loss = 1.42826 (* 1 = 1.42826 loss)
I0802 08:46:20.257586 18636 sgd_solver.cpp:136] Iteration 86300, lr = 0.00460625, m = 0.9
I0802 08:46:34.171502 18636 solver.cpp:353] Iteration 86400 (7.18719 iter/s, 13.9136s/100 iter), loss = 1.44121
I0802 08:46:34.171531 18636 solver.cpp:375]     Train net output #0: loss = 1.18439 (* 1 = 1.18439 loss)
I0802 08:46:34.171537 18636 sgd_solver.cpp:136] Iteration 86400, lr = 0.0046, m = 0.9
I0802 08:46:48.061694 18636 solver.cpp:353] Iteration 86500 (7.19953 iter/s, 13.8898s/100 iter), loss = 1.2828
I0802 08:46:48.061736 18636 solver.cpp:375]     Train net output #0: loss = 1.26162 (* 1 = 1.26162 loss)
I0802 08:46:48.061743 18636 sgd_solver.cpp:136] Iteration 86500, lr = 0.00459375, m = 0.9
I0802 08:47:02.025527 18636 solver.cpp:353] Iteration 86600 (7.16156 iter/s, 13.9634s/100 iter), loss = 1.57253
I0802 08:47:02.025600 18636 solver.cpp:375]     Train net output #0: loss = 1.23145 (* 1 = 1.23145 loss)
I0802 08:47:02.025607 18636 sgd_solver.cpp:136] Iteration 86600, lr = 0.0045875, m = 0.9
I0802 08:47:15.893581 18636 solver.cpp:353] Iteration 86700 (7.21102 iter/s, 13.8677s/100 iter), loss = 1.32981
I0802 08:47:15.893607 18636 solver.cpp:375]     Train net output #0: loss = 1.14904 (* 1 = 1.14904 loss)
I0802 08:47:15.893612 18636 sgd_solver.cpp:136] Iteration 86700, lr = 0.00458125, m = 0.9
I0802 08:47:29.818837 18636 solver.cpp:353] Iteration 86800 (7.1814 iter/s, 13.9249s/100 iter), loss = 1.51511
I0802 08:47:29.818861 18636 solver.cpp:375]     Train net output #0: loss = 1.66036 (* 1 = 1.66036 loss)
I0802 08:47:29.818867 18636 sgd_solver.cpp:136] Iteration 86800, lr = 0.004575, m = 0.9
I0802 08:47:43.690582 18636 solver.cpp:353] Iteration 86900 (7.2091 iter/s, 13.8714s/100 iter), loss = 1.27293
I0802 08:47:43.690651 18636 solver.cpp:375]     Train net output #0: loss = 1.17823 (* 1 = 1.17823 loss)
I0802 08:47:43.690659 18636 sgd_solver.cpp:136] Iteration 86900, lr = 0.00456875, m = 0.9
I0802 08:47:57.506793 18636 solver.cpp:404] Sparsity after update:
I0802 08:47:57.519568 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:47:57.519623 18636 net.cpp:2270] conv1a_param_0(0.328) 
I0802 08:47:57.519642 18636 net.cpp:2270] conv1b_param_0(0.652) 
I0802 08:47:57.519651 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:47:57.519659 18636 net.cpp:2270] res2a_branch2a_param_0(0.665) 
I0802 08:47:57.519667 18636 net.cpp:2270] res2a_branch2b_param_0(0.645) 
I0802 08:47:57.519676 18636 net.cpp:2270] res3a_branch2a_param_0(0.668) 
I0802 08:47:57.519685 18636 net.cpp:2270] res3a_branch2b_param_0(0.662) 
I0802 08:47:57.519692 18636 net.cpp:2270] res4a_branch2a_param_0(0.669) 
I0802 08:47:57.519701 18636 net.cpp:2270] res4a_branch2b_param_0(0.668) 
I0802 08:47:57.519709 18636 net.cpp:2270] res5a_branch2a_param_0(0.67) 
I0802 08:47:57.519717 18636 net.cpp:2270] res5a_branch2b_param_0(0.669) 
I0802 08:47:57.519726 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.57483e+06/2.86678e+06) 0.549
I0802 08:47:57.651391 18661 solver.cpp:450] Finding and applying sparsity: 0.68
I0802 08:48:43.213217 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:48:43.215142 18636 solver.cpp:353] Iteration 87000 (1.68002 iter/s, 59.5229s/100 iter), loss = 0.962858
I0802 08:48:43.215160 18636 solver.cpp:375]     Train net output #0: loss = 1.22429 (* 1 = 1.22429 loss)
I0802 08:48:43.215167 18636 sgd_solver.cpp:136] Iteration 87000, lr = 0.0045625, m = 0.9
I0802 08:48:57.519390 18636 solver.cpp:353] Iteration 87100 (6.99113 iter/s, 14.3038s/100 iter), loss = 1.11381
I0802 08:48:57.519541 18636 solver.cpp:375]     Train net output #0: loss = 1.29369 (* 1 = 1.29369 loss)
I0802 08:48:57.519554 18636 sgd_solver.cpp:136] Iteration 87100, lr = 0.00455625, m = 0.9
I0802 08:49:11.434891 18636 solver.cpp:353] Iteration 87200 (7.18643 iter/s, 13.9151s/100 iter), loss = 1.51388
I0802 08:49:11.434916 18636 solver.cpp:375]     Train net output #0: loss = 1.17931 (* 1 = 1.17931 loss)
I0802 08:49:11.434921 18636 sgd_solver.cpp:136] Iteration 87200, lr = 0.00455, m = 0.9
I0802 08:49:25.351001 18636 solver.cpp:353] Iteration 87300 (7.18612 iter/s, 13.9157s/100 iter), loss = 1.84624
I0802 08:49:25.351120 18636 solver.cpp:375]     Train net output #0: loss = 2.21072 (* 1 = 2.21072 loss)
I0802 08:49:25.351140 18636 sgd_solver.cpp:136] Iteration 87300, lr = 0.00454375, m = 0.9
I0802 08:49:39.298013 18636 solver.cpp:353] Iteration 87400 (7.17019 iter/s, 13.9466s/100 iter), loss = 1.49797
I0802 08:49:39.298038 18636 solver.cpp:375]     Train net output #0: loss = 1.72144 (* 1 = 1.72144 loss)
I0802 08:49:39.298041 18636 sgd_solver.cpp:136] Iteration 87400, lr = 0.0045375, m = 0.9
I0802 08:49:53.263254 18636 solver.cpp:353] Iteration 87500 (7.16083 iter/s, 13.9649s/100 iter), loss = 1.26
I0802 08:49:53.263353 18636 solver.cpp:375]     Train net output #0: loss = 1.63028 (* 1 = 1.63028 loss)
I0802 08:49:53.263375 18636 sgd_solver.cpp:136] Iteration 87500, lr = 0.00453125, m = 0.9
I0802 08:50:07.202610 18636 solver.cpp:353] Iteration 87600 (7.17413 iter/s, 13.939s/100 iter), loss = 1.3509
I0802 08:50:07.202711 18636 solver.cpp:375]     Train net output #0: loss = 1.64186 (* 1 = 1.64186 loss)
I0802 08:50:07.202729 18636 sgd_solver.cpp:136] Iteration 87600, lr = 0.004525, m = 0.9
I0802 08:50:21.165262 18636 solver.cpp:353] Iteration 87700 (7.16216 iter/s, 13.9623s/100 iter), loss = 1.38938
I0802 08:50:21.165288 18636 solver.cpp:375]     Train net output #0: loss = 1.42266 (* 1 = 1.42266 loss)
I0802 08:50:21.165293 18636 sgd_solver.cpp:136] Iteration 87700, lr = 0.00451875, m = 0.9
I0802 08:50:35.148449 18636 solver.cpp:353] Iteration 87800 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.52252
I0802 08:50:35.148476 18636 solver.cpp:375]     Train net output #0: loss = 1.565 (* 1 = 1.565 loss)
I0802 08:50:35.148481 18636 sgd_solver.cpp:136] Iteration 87800, lr = 0.0045125, m = 0.9
I0802 08:50:49.105473 18636 solver.cpp:353] Iteration 87900 (7.16505 iter/s, 13.9566s/100 iter), loss = 1.39721
I0802 08:50:49.105571 18636 solver.cpp:375]     Train net output #0: loss = 1.45263 (* 1 = 1.45263 loss)
I0802 08:50:49.105581 18636 sgd_solver.cpp:136] Iteration 87900, lr = 0.00450625, m = 0.9
I0802 08:51:02.883594 18636 solver.cpp:404] Sparsity after update:
I0802 08:51:02.888474 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:51:02.888487 18636 net.cpp:2270] conv1a_param_0(0.329) 
I0802 08:51:02.888497 18636 net.cpp:2270] conv1b_param_0(0.655) 
I0802 08:51:02.888501 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:51:02.888505 18636 net.cpp:2270] res2a_branch2a_param_0(0.675) 
I0802 08:51:02.888509 18636 net.cpp:2270] res2a_branch2b_param_0(0.651) 
I0802 08:51:02.888514 18636 net.cpp:2270] res3a_branch2a_param_0(0.679) 
I0802 08:51:02.888516 18636 net.cpp:2270] res3a_branch2b_param_0(0.671) 
I0802 08:51:02.888520 18636 net.cpp:2270] res4a_branch2a_param_0(0.68) 
I0802 08:51:02.888523 18636 net.cpp:2270] res4a_branch2b_param_0(0.678) 
I0802 08:51:02.888527 18636 net.cpp:2270] res5a_branch2a_param_0(0.68) 
I0802 08:51:02.888537 18636 net.cpp:2270] res5a_branch2b_param_0(0.68) 
I0802 08:51:02.888541 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.59867e+06/2.86678e+06) 0.558
I0802 08:51:02.888552 18636 solver.cpp:550] Iteration 88000, Testing net (#0)
I0802 08:51:05.512367 18619 data_reader.cpp:264] Starting prefetch of epoch 5
I0802 08:51:22.364962 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.583235
I0802 08:51:22.365092 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809115
I0802 08:51:22.365103 18636 solver.cpp:635]     Test net output #2: loss = 1.82375 (* 1 = 1.82375 loss)
I0802 08:51:22.365120 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.476s
I0802 08:51:22.530488 18661 solver.cpp:450] Finding and applying sparsity: 0.69
I0802 08:52:08.930378 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:52:08.932440 18636 solver.cpp:353] Iteration 88000 (1.25274 iter/s, 79.8248s/100 iter), loss = 1.23901
I0802 08:52:08.932468 18636 solver.cpp:375]     Train net output #0: loss = 1.22075 (* 1 = 1.22075 loss)
I0802 08:52:08.932477 18636 sgd_solver.cpp:136] Iteration 88000, lr = 0.0045, m = 0.9
I0802 08:52:23.202023 18636 solver.cpp:353] Iteration 88100 (7.00811 iter/s, 14.2692s/100 iter), loss = 1.20662
I0802 08:52:23.202049 18636 solver.cpp:375]     Train net output #0: loss = 1.10975 (* 1 = 1.10975 loss)
I0802 08:52:23.202054 18636 sgd_solver.cpp:136] Iteration 88100, lr = 0.00449375, m = 0.9
I0802 08:52:37.092562 18636 solver.cpp:353] Iteration 88200 (7.19935 iter/s, 13.8902s/100 iter), loss = 1.18488
I0802 08:52:37.092591 18636 solver.cpp:375]     Train net output #0: loss = 1.02874 (* 1 = 1.02874 loss)
I0802 08:52:37.092597 18636 sgd_solver.cpp:136] Iteration 88200, lr = 0.0044875, m = 0.9
I0802 08:52:51.088282 18636 solver.cpp:353] Iteration 88300 (7.14524 iter/s, 13.9953s/100 iter), loss = 1.50409
I0802 08:52:51.088409 18636 solver.cpp:375]     Train net output #0: loss = 1.46664 (* 1 = 1.46664 loss)
I0802 08:52:51.088428 18636 sgd_solver.cpp:136] Iteration 88300, lr = 0.00448125, m = 0.9
I0802 08:53:05.018251 18636 solver.cpp:353] Iteration 88400 (7.17897 iter/s, 13.9296s/100 iter), loss = 1.53924
I0802 08:53:05.018276 18636 solver.cpp:375]     Train net output #0: loss = 1.67828 (* 1 = 1.67828 loss)
I0802 08:53:05.018282 18636 sgd_solver.cpp:136] Iteration 88400, lr = 0.004475, m = 0.9
I0802 08:53:18.949398 18636 solver.cpp:353] Iteration 88500 (7.17836 iter/s, 13.9308s/100 iter), loss = 1.35887
I0802 08:53:18.949425 18636 solver.cpp:375]     Train net output #0: loss = 1.1978 (* 1 = 1.1978 loss)
I0802 08:53:18.949430 18636 sgd_solver.cpp:136] Iteration 88500, lr = 0.00446875, m = 0.9
I0802 08:53:32.838855 18636 solver.cpp:353] Iteration 88600 (7.19991 iter/s, 13.8891s/100 iter), loss = 1.35303
I0802 08:53:32.838958 18636 solver.cpp:375]     Train net output #0: loss = 1.53147 (* 1 = 1.53147 loss)
I0802 08:53:32.838976 18636 sgd_solver.cpp:136] Iteration 88600, lr = 0.0044625, m = 0.9
I0802 08:53:46.729542 18636 solver.cpp:353] Iteration 88700 (7.19927 iter/s, 13.8903s/100 iter), loss = 1.55227
I0802 08:53:46.729569 18636 solver.cpp:375]     Train net output #0: loss = 1.97111 (* 1 = 1.97111 loss)
I0802 08:53:46.729574 18636 sgd_solver.cpp:136] Iteration 88700, lr = 0.00445625, m = 0.9
I0802 08:54:00.608783 18636 solver.cpp:353] Iteration 88800 (7.2052 iter/s, 13.8789s/100 iter), loss = 1.34878
I0802 08:54:00.608808 18636 solver.cpp:375]     Train net output #0: loss = 1.2469 (* 1 = 1.2469 loss)
I0802 08:54:00.608814 18636 sgd_solver.cpp:136] Iteration 88800, lr = 0.00445, m = 0.9
I0802 08:54:14.559067 18636 solver.cpp:353] Iteration 88900 (7.16851 iter/s, 13.9499s/100 iter), loss = 1.52187
I0802 08:54:14.559345 18636 solver.cpp:375]     Train net output #0: loss = 0.811696 (* 1 = 0.811696 loss)
I0802 08:54:14.559458 18636 sgd_solver.cpp:136] Iteration 88900, lr = 0.00444375, m = 0.9
I0802 08:54:28.309801 18636 solver.cpp:404] Sparsity after update:
I0802 08:54:28.321324 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:54:28.321338 18636 net.cpp:2270] conv1a_param_0(0.329) 
I0802 08:54:28.321347 18636 net.cpp:2270] conv1b_param_0(0.665) 
I0802 08:54:28.321350 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:54:28.321362 18636 net.cpp:2270] res2a_branch2a_param_0(0.684) 
I0802 08:54:28.321372 18636 net.cpp:2270] res2a_branch2b_param_0(0.66) 
I0802 08:54:28.321382 18636 net.cpp:2270] res3a_branch2a_param_0(0.689) 
I0802 08:54:28.321390 18636 net.cpp:2270] res3a_branch2b_param_0(0.68) 
I0802 08:54:28.321398 18636 net.cpp:2270] res4a_branch2a_param_0(0.689) 
I0802 08:54:28.321413 18636 net.cpp:2270] res4a_branch2b_param_0(0.688) 
I0802 08:54:28.321421 18636 net.cpp:2270] res5a_branch2a_param_0(0.69) 
I0802 08:54:28.321431 18636 net.cpp:2270] res5a_branch2b_param_0(0.689) 
I0802 08:54:28.321440 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.62174e+06/2.86678e+06) 0.566
I0802 08:54:28.450793 18661 solver.cpp:450] Finding and applying sparsity: 0.7
I0802 08:55:15.661182 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:55:15.663120 18636 solver.cpp:353] Iteration 89000 (1.6366 iter/s, 61.1024s/100 iter), loss = 1.45586
I0802 08:55:15.663141 18636 solver.cpp:375]     Train net output #0: loss = 1.55272 (* 1 = 1.55272 loss)
I0802 08:55:15.663148 18636 sgd_solver.cpp:136] Iteration 89000, lr = 0.0044375, m = 0.9
I0802 08:55:30.009748 18636 solver.cpp:353] Iteration 89100 (6.97048 iter/s, 14.3462s/100 iter), loss = 1.2203
I0802 08:55:30.009774 18636 solver.cpp:375]     Train net output #0: loss = 1.52629 (* 1 = 1.52629 loss)
I0802 08:55:30.009779 18636 sgd_solver.cpp:136] Iteration 89100, lr = 0.00443125, m = 0.9
I0802 08:55:43.866152 18636 solver.cpp:353] Iteration 89200 (7.21708 iter/s, 13.856s/100 iter), loss = 1.82391
I0802 08:55:43.866181 18636 solver.cpp:375]     Train net output #0: loss = 1.48263 (* 1 = 1.48263 loss)
I0802 08:55:43.866186 18636 sgd_solver.cpp:136] Iteration 89200, lr = 0.004425, m = 0.9
I0802 08:55:57.764144 18636 solver.cpp:353] Iteration 89300 (7.19549 iter/s, 13.8976s/100 iter), loss = 1.4085
I0802 08:55:57.764226 18636 solver.cpp:375]     Train net output #0: loss = 1.05281 (* 1 = 1.05281 loss)
I0802 08:55:57.764235 18636 sgd_solver.cpp:136] Iteration 89300, lr = 0.00441875, m = 0.9
I0802 08:56:11.664780 18636 solver.cpp:353] Iteration 89400 (7.19411 iter/s, 13.9003s/100 iter), loss = 1.15619
I0802 08:56:11.664809 18636 solver.cpp:375]     Train net output #0: loss = 1.15286 (* 1 = 1.15286 loss)
I0802 08:56:11.664822 18636 sgd_solver.cpp:136] Iteration 89400, lr = 0.0044125, m = 0.9
I0802 08:56:25.489771 18636 solver.cpp:353] Iteration 89500 (7.23348 iter/s, 13.8246s/100 iter), loss = 1.25944
I0802 08:56:25.489794 18636 solver.cpp:375]     Train net output #0: loss = 1.04668 (* 1 = 1.04668 loss)
I0802 08:56:25.489799 18636 sgd_solver.cpp:136] Iteration 89500, lr = 0.00440625, m = 0.9
I0802 08:56:39.341161 18636 solver.cpp:353] Iteration 89600 (7.21969 iter/s, 13.851s/100 iter), loss = 1.36002
I0802 08:56:39.341223 18636 solver.cpp:375]     Train net output #0: loss = 1.48537 (* 1 = 1.48537 loss)
I0802 08:56:39.341228 18636 sgd_solver.cpp:136] Iteration 89600, lr = 0.0044, m = 0.9
I0802 08:56:53.181243 18636 solver.cpp:353] Iteration 89700 (7.22559 iter/s, 13.8397s/100 iter), loss = 1.32503
I0802 08:56:53.181274 18636 solver.cpp:375]     Train net output #0: loss = 1.35539 (* 1 = 1.35539 loss)
I0802 08:56:53.181282 18636 sgd_solver.cpp:136] Iteration 89700, lr = 0.00439375, m = 0.9
I0802 08:57:07.037693 18636 solver.cpp:353] Iteration 89800 (7.21706 iter/s, 13.8561s/100 iter), loss = 1.48107
I0802 08:57:07.037719 18636 solver.cpp:375]     Train net output #0: loss = 1.68988 (* 1 = 1.68988 loss)
I0802 08:57:07.037724 18636 sgd_solver.cpp:136] Iteration 89800, lr = 0.0043875, m = 0.9
I0802 08:57:20.912775 18636 solver.cpp:353] Iteration 89900 (7.20736 iter/s, 13.8747s/100 iter), loss = 1.40908
I0802 08:57:20.913442 18636 solver.cpp:375]     Train net output #0: loss = 1.77448 (* 1 = 1.77448 loss)
I0802 08:57:20.913449 18636 sgd_solver.cpp:136] Iteration 89900, lr = 0.00438125, m = 0.9
I0802 08:57:34.626440 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_90000.caffemodel
I0802 08:57:34.697134 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_90000.solverstate
I0802 08:57:34.701521 18636 solver.cpp:404] Sparsity after update:
I0802 08:57:34.704785 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 08:57:34.704794 18636 net.cpp:2270] conv1a_param_0(0.342) 
I0802 08:57:34.704803 18636 net.cpp:2270] conv1b_param_0(0.675) 
I0802 08:57:34.704807 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 08:57:34.704825 18636 net.cpp:2270] res2a_branch2a_param_0(0.694) 
I0802 08:57:34.704835 18636 net.cpp:2270] res2a_branch2b_param_0(0.665) 
I0802 08:57:34.704843 18636 net.cpp:2270] res3a_branch2a_param_0(0.699) 
I0802 08:57:34.704852 18636 net.cpp:2270] res3a_branch2b_param_0(0.689) 
I0802 08:57:34.704860 18636 net.cpp:2270] res4a_branch2a_param_0(0.7) 
I0802 08:57:34.704870 18636 net.cpp:2270] res4a_branch2b_param_0(0.698) 
I0802 08:57:34.704883 18636 net.cpp:2270] res5a_branch2a_param_0(0.7) 
I0802 08:57:34.704890 18636 net.cpp:2270] res5a_branch2b_param_0(0.7) 
I0802 08:57:34.704896 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.64553e+06/2.86678e+06) 0.574
I0802 08:57:34.704913 18636 solver.cpp:550] Iteration 90000, Testing net (#0)
I0802 08:57:53.763344 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584823
I0802 08:57:53.763478 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816526
I0802 08:57:53.763487 18636 solver.cpp:635]     Test net output #2: loss = 1.80895 (* 1 = 1.80895 loss)
I0802 08:57:53.763506 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.0581s
I0802 08:57:53.901083 18661 solver.cpp:450] Finding and applying sparsity: 0.71
I0802 08:58:41.912343 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 08:58:41.914276 18636 solver.cpp:353] Iteration 90000 (1.23458 iter/s, 80.9993s/100 iter), loss = 1.5666
I0802 08:58:41.914295 18636 solver.cpp:375]     Train net output #0: loss = 1.70678 (* 1 = 1.70678 loss)
I0802 08:58:41.914304 18636 sgd_solver.cpp:136] Iteration 90000, lr = 0.004375, m = 0.9
I0802 08:58:56.175129 18636 solver.cpp:353] Iteration 90100 (7.0124 iter/s, 14.2604s/100 iter), loss = 1.53521
I0802 08:58:56.175158 18636 solver.cpp:375]     Train net output #0: loss = 1.46559 (* 1 = 1.46559 loss)
I0802 08:58:56.175161 18636 sgd_solver.cpp:136] Iteration 90100, lr = 0.00436875, m = 0.9
I0802 08:59:09.999436 18636 solver.cpp:353] Iteration 90200 (7.23384 iter/s, 13.8239s/100 iter), loss = 1.55019
I0802 08:59:09.999465 18636 solver.cpp:375]     Train net output #0: loss = 1.6271 (* 1 = 1.6271 loss)
I0802 08:59:09.999470 18636 sgd_solver.cpp:136] Iteration 90200, lr = 0.0043625, m = 0.9
I0802 08:59:23.915781 18636 solver.cpp:353] Iteration 90300 (7.186 iter/s, 13.916s/100 iter), loss = 1.23606
I0802 08:59:23.915848 18636 solver.cpp:375]     Train net output #0: loss = 1.06332 (* 1 = 1.06332 loss)
I0802 08:59:23.915855 18636 sgd_solver.cpp:136] Iteration 90300, lr = 0.00435625, m = 0.9
I0802 08:59:37.837008 18636 solver.cpp:353] Iteration 90400 (7.18348 iter/s, 13.9208s/100 iter), loss = 1.37117
I0802 08:59:37.837038 18636 solver.cpp:375]     Train net output #0: loss = 1.257 (* 1 = 1.257 loss)
I0802 08:59:37.837041 18636 sgd_solver.cpp:136] Iteration 90400, lr = 0.00435, m = 0.9
I0802 08:59:51.712304 18636 solver.cpp:353] Iteration 90500 (7.20725 iter/s, 13.8749s/100 iter), loss = 1.1092
I0802 08:59:51.712330 18636 solver.cpp:375]     Train net output #0: loss = 1.25577 (* 1 = 1.25577 loss)
I0802 08:59:51.712334 18636 sgd_solver.cpp:136] Iteration 90500, lr = 0.00434375, m = 0.9
I0802 09:00:05.619259 18636 solver.cpp:353] Iteration 90600 (7.19085 iter/s, 13.9066s/100 iter), loss = 1.34664
I0802 09:00:05.619338 18636 solver.cpp:375]     Train net output #0: loss = 1.15817 (* 1 = 1.15817 loss)
I0802 09:00:05.619344 18636 sgd_solver.cpp:136] Iteration 90600, lr = 0.0043375, m = 0.9
I0802 09:00:19.609673 18636 solver.cpp:353] Iteration 90700 (7.14795 iter/s, 13.99s/100 iter), loss = 1.00384
I0802 09:00:19.609704 18636 solver.cpp:375]     Train net output #0: loss = 0.995206 (* 1 = 0.995206 loss)
I0802 09:00:19.609710 18636 sgd_solver.cpp:136] Iteration 90700, lr = 0.00433125, m = 0.9
I0802 09:00:33.477140 18636 solver.cpp:353] Iteration 90800 (7.21132 iter/s, 13.8671s/100 iter), loss = 1.71948
I0802 09:00:33.477169 18636 solver.cpp:375]     Train net output #0: loss = 1.30504 (* 1 = 1.30504 loss)
I0802 09:00:33.477175 18636 sgd_solver.cpp:136] Iteration 90800, lr = 0.004325, m = 0.9
I0802 09:00:47.344890 18636 solver.cpp:353] Iteration 90900 (7.21118 iter/s, 13.8674s/100 iter), loss = 1.99398
I0802 09:00:47.344960 18636 solver.cpp:375]     Train net output #0: loss = 2.1506 (* 1 = 2.1506 loss)
I0802 09:00:47.344967 18636 sgd_solver.cpp:136] Iteration 90900, lr = 0.00431875, m = 0.9
I0802 09:01:01.126853 18636 solver.cpp:404] Sparsity after update:
I0802 09:01:01.138432 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:01:01.138447 18636 net.cpp:2270] conv1a_param_0(0.331) 
I0802 09:01:01.138456 18636 net.cpp:2270] conv1b_param_0(0.685) 
I0802 09:01:01.138459 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:01:01.138470 18636 net.cpp:2270] res2a_branch2a_param_0(0.703) 
I0802 09:01:01.138476 18636 net.cpp:2270] res2a_branch2b_param_0(0.672) 
I0802 09:01:01.138481 18636 net.cpp:2270] res3a_branch2a_param_0(0.708) 
I0802 09:01:01.138485 18636 net.cpp:2270] res3a_branch2b_param_0(0.697) 
I0802 09:01:01.138490 18636 net.cpp:2270] res4a_branch2a_param_0(0.709) 
I0802 09:01:01.138494 18636 net.cpp:2270] res4a_branch2b_param_0(0.706) 
I0802 09:01:01.138499 18636 net.cpp:2270] res5a_branch2a_param_0(0.71) 
I0802 09:01:01.138504 18636 net.cpp:2270] res5a_branch2b_param_0(0.709) 
I0802 09:01:01.138507 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.66811e+06/2.86678e+06) 0.582
I0802 09:01:01.280616 18661 solver.cpp:450] Finding and applying sparsity: 0.72
I0802 09:01:51.034814 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:01:51.036746 18636 solver.cpp:353] Iteration 91000 (1.5701 iter/s, 63.6901s/100 iter), loss = 1.73759
I0802 09:01:51.036767 18636 solver.cpp:375]     Train net output #0: loss = 1.89228 (* 1 = 1.89228 loss)
I0802 09:01:51.036775 18636 sgd_solver.cpp:136] Iteration 91000, lr = 0.0043125, m = 0.9
I0802 09:02:05.313053 18636 solver.cpp:353] Iteration 91100 (7.00481 iter/s, 14.2759s/100 iter), loss = 1.32941
I0802 09:02:05.313153 18636 solver.cpp:375]     Train net output #0: loss = 1.52134 (* 1 = 1.52134 loss)
I0802 09:02:05.313175 18636 sgd_solver.cpp:136] Iteration 91100, lr = 0.00430625, m = 0.9
I0802 09:02:19.171399 18636 solver.cpp:353] Iteration 91200 (7.21607 iter/s, 13.858s/100 iter), loss = 1.35759
I0802 09:02:19.171425 18636 solver.cpp:375]     Train net output #0: loss = 1.16341 (* 1 = 1.16341 loss)
I0802 09:02:19.171430 18636 sgd_solver.cpp:136] Iteration 91200, lr = 0.0043, m = 0.9
I0802 09:02:33.091248 18636 solver.cpp:353] Iteration 91300 (7.18419 iter/s, 13.9195s/100 iter), loss = 1.03429
I0802 09:02:33.091369 18636 solver.cpp:375]     Train net output #0: loss = 1.11414 (* 1 = 1.11414 loss)
I0802 09:02:33.091388 18636 sgd_solver.cpp:136] Iteration 91300, lr = 0.00429375, m = 0.9
I0802 09:02:46.932096 18636 solver.cpp:353] Iteration 91400 (7.22519 iter/s, 13.8405s/100 iter), loss = 1.11031
I0802 09:02:46.932127 18636 solver.cpp:375]     Train net output #0: loss = 1.33782 (* 1 = 1.33782 loss)
I0802 09:02:46.932134 18636 sgd_solver.cpp:136] Iteration 91400, lr = 0.0042875, m = 0.9
I0802 09:03:00.800863 18636 solver.cpp:353] Iteration 91500 (7.21065 iter/s, 13.8684s/100 iter), loss = 1.31878
I0802 09:03:00.800894 18636 solver.cpp:375]     Train net output #0: loss = 1.25964 (* 1 = 1.25964 loss)
I0802 09:03:00.800899 18636 sgd_solver.cpp:136] Iteration 91500, lr = 0.00428125, m = 0.9
I0802 09:03:14.771708 18636 solver.cpp:353] Iteration 91600 (7.15796 iter/s, 13.9705s/100 iter), loss = 1.18656
I0802 09:03:14.771770 18636 solver.cpp:375]     Train net output #0: loss = 1.09562 (* 1 = 1.09562 loss)
I0802 09:03:14.771775 18636 sgd_solver.cpp:136] Iteration 91600, lr = 0.004275, m = 0.9
I0802 09:03:28.659773 18636 solver.cpp:353] Iteration 91700 (7.20063 iter/s, 13.8877s/100 iter), loss = 1.19929
I0802 09:03:28.659802 18636 solver.cpp:375]     Train net output #0: loss = 1.03104 (* 1 = 1.03104 loss)
I0802 09:03:28.659809 18636 sgd_solver.cpp:136] Iteration 91700, lr = 0.00426875, m = 0.9
I0802 09:03:42.535064 18636 solver.cpp:353] Iteration 91800 (7.20726 iter/s, 13.8749s/100 iter), loss = 1.20735
I0802 09:03:42.535095 18636 solver.cpp:375]     Train net output #0: loss = 1.19184 (* 1 = 1.19184 loss)
I0802 09:03:42.535100 18636 sgd_solver.cpp:136] Iteration 91800, lr = 0.0042625, m = 0.9
I0802 09:03:56.404919 18636 solver.cpp:353] Iteration 91900 (7.21008 iter/s, 13.8695s/100 iter), loss = 1.44965
I0802 09:03:56.405020 18636 solver.cpp:375]     Train net output #0: loss = 1.52524 (* 1 = 1.52524 loss)
I0802 09:03:56.405027 18636 sgd_solver.cpp:136] Iteration 91900, lr = 0.00425625, m = 0.9
I0802 09:04:10.136062 18636 solver.cpp:404] Sparsity after update:
I0802 09:04:10.141319 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:04:10.141330 18636 net.cpp:2270] conv1a_param_0(0.335) 
I0802 09:04:10.141340 18636 net.cpp:2270] conv1b_param_0(0.686) 
I0802 09:04:10.141343 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:04:10.141360 18636 net.cpp:2270] res2a_branch2a_param_0(0.712) 
I0802 09:04:10.141368 18636 net.cpp:2270] res2a_branch2b_param_0(0.677) 
I0802 09:04:10.141376 18636 net.cpp:2270] res3a_branch2a_param_0(0.718) 
I0802 09:04:10.141386 18636 net.cpp:2270] res3a_branch2b_param_0(0.705) 
I0802 09:04:10.141392 18636 net.cpp:2270] res4a_branch2a_param_0(0.72) 
I0802 09:04:10.141400 18636 net.cpp:2270] res4a_branch2b_param_0(0.716) 
I0802 09:04:10.141410 18636 net.cpp:2270] res5a_branch2a_param_0(0.72) 
I0802 09:04:10.141419 18636 net.cpp:2270] res5a_branch2b_param_0(0.72) 
I0802 09:04:10.141427 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.69178e+06/2.86678e+06) 0.59
I0802 09:04:10.141443 18636 solver.cpp:550] Iteration 92000, Testing net (#0)
I0802 09:04:29.432979 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.575059
I0802 09:04:29.433079 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805233
I0802 09:04:29.433089 18636 solver.cpp:635]     Test net output #2: loss = 1.85073 (* 1 = 1.85073 loss)
I0802 09:04:29.433107 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2911s
I0802 09:04:29.571313 18661 solver.cpp:450] Finding and applying sparsity: 0.73
I0802 09:05:19.084910 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:05:19.086846 18636 solver.cpp:353] Iteration 92000 (1.20949 iter/s, 82.6796s/100 iter), loss = 1.43995
I0802 09:05:19.086864 18636 solver.cpp:375]     Train net output #0: loss = 1.33322 (* 1 = 1.33322 loss)
I0802 09:05:19.086870 18636 sgd_solver.cpp:136] Iteration 92000, lr = 0.00425, m = 0.9
I0802 09:05:33.279531 18636 solver.cpp:353] Iteration 92100 (7.04608 iter/s, 14.1923s/100 iter), loss = 1.43048
I0802 09:05:33.279558 18636 solver.cpp:375]     Train net output #0: loss = 1.07722 (* 1 = 1.07722 loss)
I0802 09:05:33.279563 18636 sgd_solver.cpp:136] Iteration 92100, lr = 0.00424375, m = 0.9
I0802 09:05:47.153479 18636 solver.cpp:353] Iteration 92200 (7.20796 iter/s, 13.8736s/100 iter), loss = 1.42904
I0802 09:05:47.153508 18636 solver.cpp:375]     Train net output #0: loss = 1.26045 (* 1 = 1.26045 loss)
I0802 09:05:47.153514 18636 sgd_solver.cpp:136] Iteration 92200, lr = 0.0042375, m = 0.9
I0802 09:06:01.023161 18636 solver.cpp:353] Iteration 92300 (7.21017 iter/s, 13.8693s/100 iter), loss = 1.76016
I0802 09:06:01.023221 18636 solver.cpp:375]     Train net output #0: loss = 1.74641 (* 1 = 1.74641 loss)
I0802 09:06:01.023226 18636 sgd_solver.cpp:136] Iteration 92300, lr = 0.00423125, m = 0.9
I0802 09:06:14.839328 18636 solver.cpp:353] Iteration 92400 (7.2381 iter/s, 13.8158s/100 iter), loss = 1.12946
I0802 09:06:14.839368 18636 solver.cpp:375]     Train net output #0: loss = 0.972882 (* 1 = 0.972882 loss)
I0802 09:06:14.839375 18636 sgd_solver.cpp:136] Iteration 92400, lr = 0.004225, m = 0.9
I0802 09:06:28.676776 18636 solver.cpp:353] Iteration 92500 (7.22696 iter/s, 13.8371s/100 iter), loss = 1.02756
I0802 09:06:28.676805 18636 solver.cpp:375]     Train net output #0: loss = 0.999278 (* 1 = 0.999278 loss)
I0802 09:06:28.676811 18636 sgd_solver.cpp:136] Iteration 92500, lr = 0.00421875, m = 0.9
I0802 09:06:42.524588 18636 solver.cpp:353] Iteration 92600 (7.22156 iter/s, 13.8474s/100 iter), loss = 1.55658
I0802 09:06:42.524708 18636 solver.cpp:375]     Train net output #0: loss = 1.61406 (* 1 = 1.61406 loss)
I0802 09:06:42.524715 18636 sgd_solver.cpp:136] Iteration 92600, lr = 0.0042125, m = 0.9
I0802 09:06:56.411448 18636 solver.cpp:353] Iteration 92700 (7.20125 iter/s, 13.8865s/100 iter), loss = 1.43113
I0802 09:06:56.411473 18636 solver.cpp:375]     Train net output #0: loss = 1.09897 (* 1 = 1.09897 loss)
I0802 09:06:56.411478 18636 sgd_solver.cpp:136] Iteration 92700, lr = 0.00420625, m = 0.9
I0802 09:07:10.275451 18636 solver.cpp:353] Iteration 92800 (7.21312 iter/s, 13.8636s/100 iter), loss = 1.56438
I0802 09:07:10.275478 18636 solver.cpp:375]     Train net output #0: loss = 1.83227 (* 1 = 1.83227 loss)
I0802 09:07:10.275485 18636 sgd_solver.cpp:136] Iteration 92800, lr = 0.0042, m = 0.9
I0802 09:07:24.178577 18636 solver.cpp:353] Iteration 92900 (7.19283 iter/s, 13.9027s/100 iter), loss = 1.43547
I0802 09:07:24.178643 18636 solver.cpp:375]     Train net output #0: loss = 1.48784 (* 1 = 1.48784 loss)
I0802 09:07:24.178650 18636 sgd_solver.cpp:136] Iteration 92900, lr = 0.00419375, m = 0.9
I0802 09:07:37.872086 18636 solver.cpp:404] Sparsity after update:
I0802 09:07:37.886112 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:07:37.886128 18636 net.cpp:2270] conv1a_param_0(0.349) 
I0802 09:07:37.886138 18636 net.cpp:2270] conv1b_param_0(0.694) 
I0802 09:07:37.886142 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:07:37.886144 18636 net.cpp:2270] res2a_branch2a_param_0(0.721) 
I0802 09:07:37.886148 18636 net.cpp:2270] res2a_branch2b_param_0(0.682) 
I0802 09:07:37.886152 18636 net.cpp:2270] res3a_branch2a_param_0(0.728) 
I0802 09:07:37.886154 18636 net.cpp:2270] res3a_branch2b_param_0(0.712) 
I0802 09:07:37.886157 18636 net.cpp:2270] res4a_branch2a_param_0(0.729) 
I0802 09:07:37.886160 18636 net.cpp:2270] res4a_branch2b_param_0(0.725) 
I0802 09:07:37.886163 18636 net.cpp:2270] res5a_branch2a_param_0(0.73) 
I0802 09:07:37.886168 18636 net.cpp:2270] res5a_branch2b_param_0(0.729) 
I0802 09:07:37.886170 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.71469e+06/2.86678e+06) 0.598
I0802 09:07:38.016484 18661 solver.cpp:450] Finding and applying sparsity: 0.74
I0802 09:08:29.251960 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:08:29.253918 18636 solver.cpp:353] Iteration 93000 (1.53672 iter/s, 65.0735s/100 iter), loss = 1.31286
I0802 09:08:29.253937 18636 solver.cpp:375]     Train net output #0: loss = 1.43413 (* 1 = 1.43413 loss)
I0802 09:08:29.253944 18636 sgd_solver.cpp:136] Iteration 93000, lr = 0.0041875, m = 0.9
I0802 09:08:43.463793 18636 solver.cpp:353] Iteration 93100 (7.03756 iter/s, 14.2095s/100 iter), loss = 1.48675
I0802 09:08:43.463845 18636 solver.cpp:375]     Train net output #0: loss = 1.72398 (* 1 = 1.72398 loss)
I0802 09:08:43.463857 18636 sgd_solver.cpp:136] Iteration 93100, lr = 0.00418125, m = 0.9
I0802 09:08:57.303495 18636 solver.cpp:353] Iteration 93200 (7.22579 iter/s, 13.8393s/100 iter), loss = 1.25355
I0802 09:08:57.303524 18636 solver.cpp:375]     Train net output #0: loss = 1.25102 (* 1 = 1.25102 loss)
I0802 09:08:57.303529 18636 sgd_solver.cpp:136] Iteration 93200, lr = 0.004175, m = 0.9
I0802 09:09:11.238610 18636 solver.cpp:353] Iteration 93300 (7.17632 iter/s, 13.9347s/100 iter), loss = 1.38078
I0802 09:09:11.238700 18636 solver.cpp:375]     Train net output #0: loss = 1.09018 (* 1 = 1.09018 loss)
I0802 09:09:11.238708 18636 sgd_solver.cpp:136] Iteration 93300, lr = 0.00416875, m = 0.9
I0802 09:09:25.213346 18636 solver.cpp:353] Iteration 93400 (7.15597 iter/s, 13.9743s/100 iter), loss = 1.78342
I0802 09:09:25.213372 18636 solver.cpp:375]     Train net output #0: loss = 1.82909 (* 1 = 1.82909 loss)
I0802 09:09:25.213379 18636 sgd_solver.cpp:136] Iteration 93400, lr = 0.0041625, m = 0.9
I0802 09:09:39.135700 18636 solver.cpp:353] Iteration 93500 (7.18289 iter/s, 13.922s/100 iter), loss = 1.34983
I0802 09:09:39.135730 18636 solver.cpp:375]     Train net output #0: loss = 1.47399 (* 1 = 1.47399 loss)
I0802 09:09:39.135771 18636 sgd_solver.cpp:136] Iteration 93500, lr = 0.00415625, m = 0.9
I0802 09:09:53.012441 18636 solver.cpp:353] Iteration 93600 (7.2065 iter/s, 13.8764s/100 iter), loss = 1.70012
I0802 09:09:53.013111 18636 solver.cpp:375]     Train net output #0: loss = 1.37061 (* 1 = 1.37061 loss)
I0802 09:09:53.013134 18636 sgd_solver.cpp:136] Iteration 93600, lr = 0.00415, m = 0.9
I0802 09:10:06.929141 18636 solver.cpp:353] Iteration 93700 (7.18581 iter/s, 13.9163s/100 iter), loss = 1.01916
I0802 09:10:06.929173 18636 solver.cpp:375]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0802 09:10:06.929180 18636 sgd_solver.cpp:136] Iteration 93700, lr = 0.00414375, m = 0.9
I0802 09:10:20.874249 18636 solver.cpp:353] Iteration 93800 (7.17117 iter/s, 13.9447s/100 iter), loss = 0.964316
I0802 09:10:20.874280 18636 solver.cpp:375]     Train net output #0: loss = 0.968726 (* 1 = 0.968726 loss)
I0802 09:10:20.874286 18636 sgd_solver.cpp:136] Iteration 93800, lr = 0.0041375, m = 0.9
I0802 09:10:34.808835 18636 solver.cpp:353] Iteration 93900 (7.17659 iter/s, 13.9342s/100 iter), loss = 1.43874
I0802 09:10:34.808900 18636 solver.cpp:375]     Train net output #0: loss = 1.42453 (* 1 = 1.42453 loss)
I0802 09:10:34.808908 18636 sgd_solver.cpp:136] Iteration 93900, lr = 0.00413125, m = 0.9
I0802 09:10:48.630020 18636 solver.cpp:404] Sparsity after update:
I0802 09:10:48.636037 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:10:48.636050 18636 net.cpp:2270] conv1a_param_0(0.352) 
I0802 09:10:48.636059 18636 net.cpp:2270] conv1b_param_0(0.701) 
I0802 09:10:48.636062 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:10:48.636067 18636 net.cpp:2270] res2a_branch2a_param_0(0.73) 
I0802 09:10:48.636070 18636 net.cpp:2270] res2a_branch2b_param_0(0.685) 
I0802 09:10:48.636073 18636 net.cpp:2270] res3a_branch2a_param_0(0.738) 
I0802 09:10:48.636076 18636 net.cpp:2270] res3a_branch2b_param_0(0.719) 
I0802 09:10:48.636080 18636 net.cpp:2270] res4a_branch2a_param_0(0.74) 
I0802 09:10:48.636085 18636 net.cpp:2270] res4a_branch2b_param_0(0.734) 
I0802 09:10:48.636088 18636 net.cpp:2270] res5a_branch2a_param_0(0.74) 
I0802 09:10:48.636091 18636 net.cpp:2270] res5a_branch2b_param_0(0.74) 
I0802 09:10:48.636096 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.73823e+06/2.86678e+06) 0.606
I0802 09:10:48.636109 18636 solver.cpp:550] Iteration 94000, Testing net (#0)
I0802 09:10:49.173979 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:11:08.486057 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.579294
I0802 09:11:08.486109 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811703
I0802 09:11:08.486114 18636 solver.cpp:635]     Test net output #2: loss = 1.84217 (* 1 = 1.84217 loss)
I0802 09:11:08.486133 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.8495s
I0802 09:11:08.638149 18661 solver.cpp:450] Finding and applying sparsity: 0.75
I0802 09:12:01.096415 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:12:01.098361 18636 solver.cpp:353] Iteration 94000 (1.15892 iter/s, 86.2871s/100 iter), loss = 1.61096
I0802 09:12:01.098379 18636 solver.cpp:375]     Train net output #0: loss = 1.9893 (* 1 = 1.9893 loss)
I0802 09:12:01.098388 18636 sgd_solver.cpp:136] Iteration 94000, lr = 0.004125, m = 0.9
I0802 09:12:15.365159 18636 solver.cpp:353] Iteration 94100 (7.00948 iter/s, 14.2664s/100 iter), loss = 1.52549
I0802 09:12:15.365193 18636 solver.cpp:375]     Train net output #0: loss = 1.30401 (* 1 = 1.30401 loss)
I0802 09:12:15.365200 18636 sgd_solver.cpp:136] Iteration 94100, lr = 0.00411875, m = 0.9
I0802 09:12:29.304847 18636 solver.cpp:353] Iteration 94200 (7.17396 iter/s, 13.9393s/100 iter), loss = 1.52705
I0802 09:12:29.304939 18636 solver.cpp:375]     Train net output #0: loss = 1.55584 (* 1 = 1.55584 loss)
I0802 09:12:29.304960 18636 sgd_solver.cpp:136] Iteration 94200, lr = 0.0041125, m = 0.9
I0802 09:12:43.317581 18636 solver.cpp:353] Iteration 94300 (7.13657 iter/s, 14.0123s/100 iter), loss = 1.33492
I0802 09:12:43.317685 18636 solver.cpp:375]     Train net output #0: loss = 1.67652 (* 1 = 1.67652 loss)
I0802 09:12:43.317693 18636 sgd_solver.cpp:136] Iteration 94300, lr = 0.00410625, m = 0.9
I0802 09:12:57.275323 18636 solver.cpp:353] Iteration 94400 (7.16469 iter/s, 13.9573s/100 iter), loss = 1.84577
I0802 09:12:57.275365 18636 solver.cpp:375]     Train net output #0: loss = 2.23878 (* 1 = 2.23878 loss)
I0802 09:12:57.275372 18636 sgd_solver.cpp:136] Iteration 94400, lr = 0.0041, m = 0.9
I0802 09:13:11.262715 18636 solver.cpp:353] Iteration 94500 (7.1495 iter/s, 13.987s/100 iter), loss = 1.7174
I0802 09:13:11.262816 18636 solver.cpp:375]     Train net output #0: loss = 1.41863 (* 1 = 1.41863 loss)
I0802 09:13:11.262838 18636 sgd_solver.cpp:136] Iteration 94500, lr = 0.00409375, m = 0.9
I0802 09:13:25.210671 18636 solver.cpp:353] Iteration 94600 (7.1697 iter/s, 13.9476s/100 iter), loss = 0.876213
I0802 09:13:25.210728 18636 solver.cpp:375]     Train net output #0: loss = 1.17565 (* 1 = 1.17565 loss)
I0802 09:13:25.210734 18636 sgd_solver.cpp:136] Iteration 94600, lr = 0.0040875, m = 0.9
I0802 09:13:39.220795 18636 solver.cpp:353] Iteration 94700 (7.13789 iter/s, 14.0097s/100 iter), loss = 1.61629
I0802 09:13:39.220824 18636 solver.cpp:375]     Train net output #0: loss = 1.87358 (* 1 = 1.87358 loss)
I0802 09:13:39.220830 18636 sgd_solver.cpp:136] Iteration 94700, lr = 0.00408125, m = 0.9
I0802 09:13:53.163422 18636 solver.cpp:353] Iteration 94800 (7.17245 iter/s, 13.9422s/100 iter), loss = 1.04097
I0802 09:13:53.163447 18636 solver.cpp:375]     Train net output #0: loss = 0.97897 (* 1 = 0.97897 loss)
I0802 09:13:53.163453 18636 sgd_solver.cpp:136] Iteration 94800, lr = 0.004075, m = 0.9
I0802 09:14:07.197845 18636 solver.cpp:353] Iteration 94900 (7.12554 iter/s, 14.034s/100 iter), loss = 1.29103
I0802 09:14:07.197901 18636 solver.cpp:375]     Train net output #0: loss = 1.36321 (* 1 = 1.36321 loss)
I0802 09:14:07.197907 18636 sgd_solver.cpp:136] Iteration 94900, lr = 0.00406875, m = 0.9
I0802 09:14:21.047907 18636 solver.cpp:404] Sparsity after update:
I0802 09:14:21.061589 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:14:21.061601 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:14:21.061609 18636 net.cpp:2270] conv1b_param_0(0.703) 
I0802 09:14:21.061610 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:14:21.061612 18636 net.cpp:2270] res2a_branch2a_param_0(0.736) 
I0802 09:14:21.061614 18636 net.cpp:2270] res2a_branch2b_param_0(0.688) 
I0802 09:14:21.061616 18636 net.cpp:2270] res3a_branch2a_param_0(0.747) 
I0802 09:14:21.061619 18636 net.cpp:2270] res3a_branch2b_param_0(0.724) 
I0802 09:14:21.061622 18636 net.cpp:2270] res4a_branch2a_param_0(0.749) 
I0802 09:14:21.061625 18636 net.cpp:2270] res4a_branch2b_param_0(0.742) 
I0802 09:14:21.061626 18636 net.cpp:2270] res5a_branch2a_param_0(0.75) 
I0802 09:14:21.061628 18636 net.cpp:2270] res5a_branch2b_param_0(0.749) 
I0802 09:14:21.061630 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.76048e+06/2.86678e+06) 0.614
I0802 09:14:21.191269 18661 solver.cpp:450] Finding and applying sparsity: 0.76
I0802 09:15:14.861099 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:15:14.863003 18636 solver.cpp:353] Iteration 95000 (1.47791 iter/s, 67.6633s/100 iter), loss = 1.64177
I0802 09:15:14.863021 18636 solver.cpp:375]     Train net output #0: loss = 1.72137 (* 1 = 1.72137 loss)
I0802 09:15:14.863028 18636 sgd_solver.cpp:136] Iteration 95000, lr = 0.0040625, m = 0.9
I0802 09:15:29.136780 18636 solver.cpp:353] Iteration 95100 (7.00605 iter/s, 14.2734s/100 iter), loss = 1.32893
I0802 09:15:29.136808 18636 solver.cpp:375]     Train net output #0: loss = 1.43546 (* 1 = 1.43546 loss)
I0802 09:15:29.136823 18636 sgd_solver.cpp:136] Iteration 95100, lr = 0.00405625, m = 0.9
I0802 09:15:43.090350 18636 solver.cpp:353] Iteration 95200 (7.16683 iter/s, 13.9532s/100 iter), loss = 1.36915
I0802 09:15:43.090379 18636 solver.cpp:375]     Train net output #0: loss = 1.48339 (* 1 = 1.48339 loss)
I0802 09:15:43.090384 18636 sgd_solver.cpp:136] Iteration 95200, lr = 0.00405, m = 0.9
I0802 09:15:56.992043 18636 solver.cpp:353] Iteration 95300 (7.19357 iter/s, 13.9013s/100 iter), loss = 1.06387
I0802 09:15:56.992121 18636 solver.cpp:375]     Train net output #0: loss = 1.38316 (* 1 = 1.38316 loss)
I0802 09:15:56.992128 18636 sgd_solver.cpp:136] Iteration 95300, lr = 0.00404375, m = 0.9
I0802 09:16:10.931789 18636 solver.cpp:353] Iteration 95400 (7.17393 iter/s, 13.9394s/100 iter), loss = 1.78959
I0802 09:16:10.931818 18636 solver.cpp:375]     Train net output #0: loss = 1.78789 (* 1 = 1.78789 loss)
I0802 09:16:10.931824 18636 sgd_solver.cpp:136] Iteration 95400, lr = 0.0040375, m = 0.9
I0802 09:16:24.846587 18636 solver.cpp:353] Iteration 95500 (7.1868 iter/s, 13.9144s/100 iter), loss = 1.75896
I0802 09:16:24.846614 18636 solver.cpp:375]     Train net output #0: loss = 1.44924 (* 1 = 1.44924 loss)
I0802 09:16:24.846618 18636 sgd_solver.cpp:136] Iteration 95500, lr = 0.00403125, m = 0.9
I0802 09:16:38.869429 18636 solver.cpp:353] Iteration 95600 (7.13142 iter/s, 14.0224s/100 iter), loss = 1.18899
I0802 09:16:38.869488 18636 solver.cpp:375]     Train net output #0: loss = 1.21697 (* 1 = 1.21697 loss)
I0802 09:16:38.869529 18636 sgd_solver.cpp:136] Iteration 95600, lr = 0.004025, m = 0.9
I0802 09:16:52.790230 18636 solver.cpp:353] Iteration 95700 (7.1837 iter/s, 13.9204s/100 iter), loss = 1.87014
I0802 09:16:52.790256 18636 solver.cpp:375]     Train net output #0: loss = 1.6599 (* 1 = 1.6599 loss)
I0802 09:16:52.790261 18636 sgd_solver.cpp:136] Iteration 95700, lr = 0.00401875, m = 0.9
I0802 09:17:06.760025 18636 solver.cpp:353] Iteration 95800 (7.1585 iter/s, 13.9694s/100 iter), loss = 1.4117
I0802 09:17:06.760082 18636 solver.cpp:375]     Train net output #0: loss = 1.38653 (* 1 = 1.38653 loss)
I0802 09:17:06.760094 18636 sgd_solver.cpp:136] Iteration 95800, lr = 0.0040125, m = 0.9
I0802 09:17:20.712826 18636 solver.cpp:353] Iteration 95900 (7.16722 iter/s, 13.9524s/100 iter), loss = 1.46208
I0802 09:17:20.712888 18636 solver.cpp:375]     Train net output #0: loss = 1.57686 (* 1 = 1.57686 loss)
I0802 09:17:20.712895 18636 sgd_solver.cpp:136] Iteration 95900, lr = 0.00400625, m = 0.9
I0802 09:17:34.525063 18636 solver.cpp:404] Sparsity after update:
I0802 09:17:34.528950 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:17:34.528959 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:17:34.528969 18636 net.cpp:2270] conv1b_param_0(0.71) 
I0802 09:17:34.528972 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:17:34.528977 18636 net.cpp:2270] res2a_branch2a_param_0(0.745) 
I0802 09:17:34.528981 18636 net.cpp:2270] res2a_branch2b_param_0(0.692) 
I0802 09:17:34.528985 18636 net.cpp:2270] res3a_branch2a_param_0(0.757) 
I0802 09:17:34.528987 18636 net.cpp:2270] res3a_branch2b_param_0(0.731) 
I0802 09:17:34.528990 18636 net.cpp:2270] res4a_branch2a_param_0(0.759) 
I0802 09:17:34.528993 18636 net.cpp:2270] res4a_branch2b_param_0(0.75) 
I0802 09:17:34.528996 18636 net.cpp:2270] res5a_branch2a_param_0(0.76) 
I0802 09:17:34.529000 18636 net.cpp:2270] res5a_branch2b_param_0(0.76) 
I0802 09:17:34.529003 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.78432e+06/2.86678e+06) 0.622
I0802 09:17:34.529014 18636 solver.cpp:550] Iteration 96000, Testing net (#0)
I0802 09:17:54.608105 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.577706
I0802 09:17:54.608209 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809645
I0802 09:17:54.608220 18636 solver.cpp:635]     Test net output #2: loss = 1.85062 (* 1 = 1.85062 loss)
I0802 09:17:54.608244 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0787s
I0802 09:17:54.765228 18661 solver.cpp:450] Finding and applying sparsity: 0.77
I0802 09:18:49.853689 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:18:49.855682 18636 solver.cpp:353] Iteration 96000 (1.12183 iter/s, 89.1404s/100 iter), loss = 1.76848
I0802 09:18:49.855702 18636 solver.cpp:375]     Train net output #0: loss = 1.84809 (* 1 = 1.84809 loss)
I0802 09:18:49.855708 18636 sgd_solver.cpp:136] Iteration 96000, lr = 0.004, m = 0.9
I0802 09:19:04.137110 18636 solver.cpp:353] Iteration 96100 (7.0023 iter/s, 14.281s/100 iter), loss = 1.52795
I0802 09:19:04.137140 18636 solver.cpp:375]     Train net output #0: loss = 1.6318 (* 1 = 1.6318 loss)
I0802 09:19:04.137147 18636 sgd_solver.cpp:136] Iteration 96100, lr = 0.00399375, m = 0.9
I0802 09:19:18.048338 18636 solver.cpp:353] Iteration 96200 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.60839
I0802 09:19:18.048363 18636 solver.cpp:375]     Train net output #0: loss = 1.33641 (* 1 = 1.33641 loss)
I0802 09:19:18.048368 18636 sgd_solver.cpp:136] Iteration 96200, lr = 0.0039875, m = 0.9
I0802 09:19:31.997923 18636 solver.cpp:353] Iteration 96300 (7.16888 iter/s, 13.9492s/100 iter), loss = 1.42451
I0802 09:19:31.998003 18636 solver.cpp:375]     Train net output #0: loss = 1.40979 (* 1 = 1.40979 loss)
I0802 09:19:31.998009 18636 sgd_solver.cpp:136] Iteration 96300, lr = 0.00398125, m = 0.9
I0802 09:19:45.935307 18636 solver.cpp:353] Iteration 96400 (7.17515 iter/s, 13.937s/100 iter), loss = 1.31048
I0802 09:19:45.935331 18636 solver.cpp:375]     Train net output #0: loss = 1.22957 (* 1 = 1.22957 loss)
I0802 09:19:45.935335 18636 sgd_solver.cpp:136] Iteration 96400, lr = 0.003975, m = 0.9
I0802 09:19:59.882690 18636 solver.cpp:353] Iteration 96500 (7.17 iter/s, 13.947s/100 iter), loss = 1.40212
I0802 09:19:59.882715 18636 solver.cpp:375]     Train net output #0: loss = 1.5218 (* 1 = 1.5218 loss)
I0802 09:19:59.882720 18636 sgd_solver.cpp:136] Iteration 96500, lr = 0.00396875, m = 0.9
I0802 09:20:13.837250 18636 solver.cpp:353] Iteration 96600 (7.16632 iter/s, 13.9542s/100 iter), loss = 1.13521
I0802 09:20:13.837311 18636 solver.cpp:375]     Train net output #0: loss = 1.15758 (* 1 = 1.15758 loss)
I0802 09:20:13.837316 18636 sgd_solver.cpp:136] Iteration 96600, lr = 0.0039625, m = 0.9
I0802 09:20:27.787292 18636 solver.cpp:353] Iteration 96700 (7.16864 iter/s, 13.9496s/100 iter), loss = 1.39145
I0802 09:20:27.787328 18636 solver.cpp:375]     Train net output #0: loss = 1.34268 (* 1 = 1.34268 loss)
I0802 09:20:27.787333 18636 sgd_solver.cpp:136] Iteration 96700, lr = 0.00395625, m = 0.9
I0802 09:20:41.676031 18636 solver.cpp:353] Iteration 96800 (7.20028 iter/s, 13.8884s/100 iter), loss = 1.38418
I0802 09:20:41.676059 18636 solver.cpp:375]     Train net output #0: loss = 0.992555 (* 1 = 0.992555 loss)
I0802 09:20:41.676064 18636 sgd_solver.cpp:136] Iteration 96800, lr = 0.00395, m = 0.9
I0802 09:20:55.673876 18636 solver.cpp:353] Iteration 96900 (7.14416 iter/s, 13.9975s/100 iter), loss = 1.10794
I0802 09:20:55.673960 18636 solver.cpp:375]     Train net output #0: loss = 1.00191 (* 1 = 1.00191 loss)
I0802 09:20:55.673966 18636 sgd_solver.cpp:136] Iteration 96900, lr = 0.00394375, m = 0.9
I0802 09:21:09.507333 18636 solver.cpp:404] Sparsity after update:
I0802 09:21:09.521702 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:21:09.521716 18636 net.cpp:2270] conv1a_param_0(0.366) 
I0802 09:21:09.521725 18636 net.cpp:2270] conv1b_param_0(0.716) 
I0802 09:21:09.521728 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:21:09.521733 18636 net.cpp:2270] res2a_branch2a_param_0(0.753) 
I0802 09:21:09.521735 18636 net.cpp:2270] res2a_branch2b_param_0(0.695) 
I0802 09:21:09.521739 18636 net.cpp:2270] res3a_branch2a_param_0(0.766) 
I0802 09:21:09.521741 18636 net.cpp:2270] res3a_branch2b_param_0(0.736) 
I0802 09:21:09.521745 18636 net.cpp:2270] res4a_branch2a_param_0(0.769) 
I0802 09:21:09.521749 18636 net.cpp:2270] res4a_branch2b_param_0(0.758) 
I0802 09:21:09.521751 18636 net.cpp:2270] res5a_branch2a_param_0(0.77) 
I0802 09:21:09.521754 18636 net.cpp:2270] res5a_branch2b_param_0(0.77) 
I0802 09:21:09.521764 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.80755e+06/2.86678e+06) 0.631
I0802 09:21:09.650537 18661 solver.cpp:450] Finding and applying sparsity: 0.78
I0802 09:22:05.689914 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:22:05.691857 18636 solver.cpp:353] Iteration 97000 (1.42824 iter/s, 70.016s/100 iter), loss = 1.69221
I0802 09:22:05.691879 18636 solver.cpp:375]     Train net output #0: loss = 1.64771 (* 1 = 1.64771 loss)
I0802 09:22:05.691889 18636 sgd_solver.cpp:136] Iteration 97000, lr = 0.0039375, m = 0.9
I0802 09:22:19.876739 18636 solver.cpp:353] Iteration 97100 (7.04996 iter/s, 14.1845s/100 iter), loss = 1.68533
I0802 09:22:19.876762 18636 solver.cpp:375]     Train net output #0: loss = 1.47322 (* 1 = 1.47322 loss)
I0802 09:22:19.876767 18636 sgd_solver.cpp:136] Iteration 97100, lr = 0.00393125, m = 0.9
I0802 09:22:33.759124 18636 solver.cpp:353] Iteration 97200 (7.20358 iter/s, 13.882s/100 iter), loss = 1.3261
I0802 09:22:33.759153 18636 solver.cpp:375]     Train net output #0: loss = 1.27275 (* 1 = 1.27275 loss)
I0802 09:22:33.759160 18636 sgd_solver.cpp:136] Iteration 97200, lr = 0.003925, m = 0.9
I0802 09:22:47.589381 18636 solver.cpp:353] Iteration 97300 (7.23073 iter/s, 13.8299s/100 iter), loss = 1.43066
I0802 09:22:47.589447 18636 solver.cpp:375]     Train net output #0: loss = 1.26803 (* 1 = 1.26803 loss)
I0802 09:22:47.589454 18636 sgd_solver.cpp:136] Iteration 97300, lr = 0.00391875, m = 0.9
I0802 09:23:01.417098 18636 solver.cpp:353] Iteration 97400 (7.23206 iter/s, 13.8273s/100 iter), loss = 1.54721
I0802 09:23:01.417124 18636 solver.cpp:375]     Train net output #0: loss = 1.04439 (* 1 = 1.04439 loss)
I0802 09:23:01.417130 18636 sgd_solver.cpp:136] Iteration 97400, lr = 0.0039125, m = 0.9
I0802 09:23:15.328413 18636 solver.cpp:353] Iteration 97500 (7.1886 iter/s, 13.9109s/100 iter), loss = 1.21448
I0802 09:23:15.328446 18636 solver.cpp:375]     Train net output #0: loss = 1.1555 (* 1 = 1.1555 loss)
I0802 09:23:15.328454 18636 sgd_solver.cpp:136] Iteration 97500, lr = 0.00390625, m = 0.9
I0802 09:23:29.193457 18636 solver.cpp:353] Iteration 97600 (7.21258 iter/s, 13.8647s/100 iter), loss = 1.06108
I0802 09:23:29.193518 18636 solver.cpp:375]     Train net output #0: loss = 1.16389 (* 1 = 1.16389 loss)
I0802 09:23:29.193526 18636 sgd_solver.cpp:136] Iteration 97600, lr = 0.0039, m = 0.9
I0802 09:23:43.021287 18636 solver.cpp:353] Iteration 97700 (7.232 iter/s, 13.8274s/100 iter), loss = 1.73912
I0802 09:23:43.021327 18636 solver.cpp:375]     Train net output #0: loss = 1.58647 (* 1 = 1.58647 loss)
I0802 09:23:43.021332 18636 sgd_solver.cpp:136] Iteration 97700, lr = 0.00389375, m = 0.9
I0802 09:23:56.844413 18636 solver.cpp:353] Iteration 97800 (7.23445 iter/s, 13.8227s/100 iter), loss = 1.43812
I0802 09:23:56.844441 18636 solver.cpp:375]     Train net output #0: loss = 0.827959 (* 1 = 0.827959 loss)
I0802 09:23:56.844447 18636 sgd_solver.cpp:136] Iteration 97800, lr = 0.0038875, m = 0.9
I0802 09:24:10.655431 18636 solver.cpp:353] Iteration 97900 (7.2408 iter/s, 13.8106s/100 iter), loss = 1.45125
I0802 09:24:10.655494 18636 solver.cpp:375]     Train net output #0: loss = 1.57395 (* 1 = 1.57395 loss)
I0802 09:24:10.655501 18636 sgd_solver.cpp:136] Iteration 97900, lr = 0.00388125, m = 0.9
I0802 09:24:24.431077 18636 solver.cpp:404] Sparsity after update:
I0802 09:24:24.435014 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:24:24.435025 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:24:24.435034 18636 net.cpp:2270] conv1b_param_0(0.72) 
I0802 09:24:24.435037 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:24:24.435046 18636 net.cpp:2270] res2a_branch2a_param_0(0.762) 
I0802 09:24:24.435051 18636 net.cpp:2270] res2a_branch2b_param_0(0.7) 
I0802 09:24:24.435057 18636 net.cpp:2270] res3a_branch2a_param_0(0.775) 
I0802 09:24:24.435060 18636 net.cpp:2270] res3a_branch2b_param_0(0.742) 
I0802 09:24:24.435063 18636 net.cpp:2270] res4a_branch2a_param_0(0.779) 
I0802 09:24:24.435067 18636 net.cpp:2270] res4a_branch2b_param_0(0.765) 
I0802 09:24:24.435070 18636 net.cpp:2270] res5a_branch2a_param_0(0.78) 
I0802 09:24:24.435075 18636 net.cpp:2270] res5a_branch2b_param_0(0.779) 
I0802 09:24:24.435078 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.82989e+06/2.86678e+06) 0.638
I0802 09:24:24.435089 18636 solver.cpp:550] Iteration 98000, Testing net (#0)
I0802 09:24:43.385797 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578294
I0802 09:24:43.385861 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810174
I0802 09:24:43.385869 18636 solver.cpp:635]     Test net output #2: loss = 1.8377 (* 1 = 1.8377 loss)
I0802 09:24:43.385888 18636 solver.cpp:305] [MultiGPU] Tests completed in 18.9503s
I0802 09:24:43.527159 18661 solver.cpp:450] Finding and applying sparsity: 0.79
I0802 09:25:40.339295 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:25:40.341307 18636 solver.cpp:353] Iteration 98000 (1.11503 iter/s, 89.6834s/100 iter), loss = 1.50464
I0802 09:25:40.341327 18636 solver.cpp:375]     Train net output #0: loss = 1.48014 (* 1 = 1.48014 loss)
I0802 09:25:40.341336 18636 sgd_solver.cpp:136] Iteration 98000, lr = 0.003875, m = 0.9
I0802 09:25:54.496304 18636 solver.cpp:353] Iteration 98100 (7.06484 iter/s, 14.1546s/100 iter), loss = 1.32414
I0802 09:25:54.496328 18636 solver.cpp:375]     Train net output #0: loss = 1.29798 (* 1 = 1.29798 loss)
I0802 09:25:54.496333 18636 sgd_solver.cpp:136] Iteration 98100, lr = 0.00386875, m = 0.9
I0802 09:26:08.438084 18636 solver.cpp:353] Iteration 98200 (7.17289 iter/s, 13.9414s/100 iter), loss = 1.52907
I0802 09:26:08.438112 18636 solver.cpp:375]     Train net output #0: loss = 1.53238 (* 1 = 1.53238 loss)
I0802 09:26:08.438117 18636 sgd_solver.cpp:136] Iteration 98200, lr = 0.0038625, m = 0.9
I0802 09:26:22.286980 18636 solver.cpp:353] Iteration 98300 (7.22099 iter/s, 13.8485s/100 iter), loss = 1.72646
I0802 09:26:22.287063 18636 solver.cpp:375]     Train net output #0: loss = 1.41555 (* 1 = 1.41555 loss)
I0802 09:26:22.287070 18636 sgd_solver.cpp:136] Iteration 98300, lr = 0.00385625, m = 0.9
I0802 09:26:36.221694 18636 solver.cpp:353] Iteration 98400 (7.17653 iter/s, 13.9343s/100 iter), loss = 1.59057
I0802 09:26:36.221760 18636 solver.cpp:375]     Train net output #0: loss = 1.34421 (* 1 = 1.34421 loss)
I0802 09:26:36.221773 18636 sgd_solver.cpp:136] Iteration 98400, lr = 0.00385, m = 0.9
I0802 09:26:50.211385 18636 solver.cpp:353] Iteration 98500 (7.14832 iter/s, 13.9893s/100 iter), loss = 1.74565
I0802 09:26:50.211422 18636 solver.cpp:375]     Train net output #0: loss = 1.20495 (* 1 = 1.20495 loss)
I0802 09:26:50.211427 18636 sgd_solver.cpp:136] Iteration 98500, lr = 0.00384375, m = 0.9
I0802 09:27:04.151973 18636 solver.cpp:353] Iteration 98600 (7.1735 iter/s, 13.9402s/100 iter), loss = 1.72803
I0802 09:27:04.152039 18636 solver.cpp:375]     Train net output #0: loss = 1.50731 (* 1 = 1.50731 loss)
I0802 09:27:04.152045 18636 sgd_solver.cpp:136] Iteration 98600, lr = 0.0038375, m = 0.9
I0802 09:27:18.097182 18636 solver.cpp:353] Iteration 98700 (7.17112 iter/s, 13.9448s/100 iter), loss = 1.30107
I0802 09:27:18.097208 18636 solver.cpp:375]     Train net output #0: loss = 1.00097 (* 1 = 1.00097 loss)
I0802 09:27:18.097213 18636 sgd_solver.cpp:136] Iteration 98700, lr = 0.00383125, m = 0.9
I0802 09:27:32.035022 18636 solver.cpp:353] Iteration 98800 (7.17491 iter/s, 13.9375s/100 iter), loss = 1.48978
I0802 09:27:32.035049 18636 solver.cpp:375]     Train net output #0: loss = 1.77942 (* 1 = 1.77942 loss)
I0802 09:27:32.035055 18636 sgd_solver.cpp:136] Iteration 98800, lr = 0.003825, m = 0.9
I0802 09:27:46.041523 18636 solver.cpp:353] Iteration 98900 (7.13974 iter/s, 14.0061s/100 iter), loss = 1.532
I0802 09:27:46.041584 18636 solver.cpp:375]     Train net output #0: loss = 1.48488 (* 1 = 1.48488 loss)
I0802 09:27:46.041589 18636 sgd_solver.cpp:136] Iteration 98900, lr = 0.00381875, m = 0.9
I0802 09:27:59.862835 18636 solver.cpp:404] Sparsity after update:
I0802 09:27:59.873970 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:27:59.873981 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:27:59.873988 18636 net.cpp:2270] conv1b_param_0(0.723) 
I0802 09:27:59.873991 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:27:59.873992 18636 net.cpp:2270] res2a_branch2a_param_0(0.771) 
I0802 09:27:59.873994 18636 net.cpp:2270] res2a_branch2b_param_0(0.702) 
I0802 09:27:59.873996 18636 net.cpp:2270] res3a_branch2a_param_0(0.784) 
I0802 09:27:59.873997 18636 net.cpp:2270] res3a_branch2b_param_0(0.747) 
I0802 09:27:59.873999 18636 net.cpp:2270] res4a_branch2a_param_0(0.789) 
I0802 09:27:59.874001 18636 net.cpp:2270] res4a_branch2b_param_0(0.772) 
I0802 09:27:59.874003 18636 net.cpp:2270] res5a_branch2a_param_0(0.79) 
I0802 09:27:59.874006 18636 net.cpp:2270] res5a_branch2b_param_0(0.79) 
I0802 09:27:59.874007 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.85274e+06/2.86678e+06) 0.646
I0802 09:28:00.003440 18661 solver.cpp:450] Finding and applying sparsity: 0.8
I0802 09:28:59.111878 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:28:59.113847 18636 solver.cpp:353] Iteration 99000 (1.36855 iter/s, 73.0703s/100 iter), loss = 1.72222
I0802 09:28:59.113867 18636 solver.cpp:375]     Train net output #0: loss = 2.05928 (* 1 = 2.05928 loss)
I0802 09:28:59.113875 18636 sgd_solver.cpp:136] Iteration 99000, lr = 0.0038125, m = 0.9
I0802 09:29:13.270308 18636 solver.cpp:353] Iteration 99100 (7.06411 iter/s, 14.1561s/100 iter), loss = 1.59446
I0802 09:29:13.270337 18636 solver.cpp:375]     Train net output #0: loss = 1.55107 (* 1 = 1.55107 loss)
I0802 09:29:13.270344 18636 sgd_solver.cpp:136] Iteration 99100, lr = 0.00380625, m = 0.9
I0802 09:29:27.231827 18636 solver.cpp:353] Iteration 99200 (7.16275 iter/s, 13.9611s/100 iter), loss = 1.69119
I0802 09:29:27.231854 18636 solver.cpp:375]     Train net output #0: loss = 1.76497 (* 1 = 1.76497 loss)
I0802 09:29:27.231858 18636 sgd_solver.cpp:136] Iteration 99200, lr = 0.0038, m = 0.9
I0802 09:29:41.164608 18636 solver.cpp:353] Iteration 99300 (7.17752 iter/s, 13.9324s/100 iter), loss = 1.57669
I0802 09:29:41.164666 18636 solver.cpp:375]     Train net output #0: loss = 1.45035 (* 1 = 1.45035 loss)
I0802 09:29:41.164671 18636 sgd_solver.cpp:136] Iteration 99300, lr = 0.00379375, m = 0.9
I0802 09:29:55.059517 18636 solver.cpp:353] Iteration 99400 (7.19708 iter/s, 13.8945s/100 iter), loss = 1.55947
I0802 09:29:55.059545 18636 solver.cpp:375]     Train net output #0: loss = 1.51574 (* 1 = 1.51574 loss)
I0802 09:29:55.059551 18636 sgd_solver.cpp:136] Iteration 99400, lr = 0.0037875, m = 0.9
I0802 09:30:09.069967 18636 solver.cpp:353] Iteration 99500 (7.13773 iter/s, 14.0101s/100 iter), loss = 1.78114
I0802 09:30:09.069994 18636 solver.cpp:375]     Train net output #0: loss = 1.67765 (* 1 = 1.67765 loss)
I0802 09:30:09.070000 18636 sgd_solver.cpp:136] Iteration 99500, lr = 0.00378125, m = 0.9
I0802 09:30:23.156080 18636 solver.cpp:353] Iteration 99600 (7.09939 iter/s, 14.0857s/100 iter), loss = 1.24045
I0802 09:30:23.156227 18636 solver.cpp:375]     Train net output #0: loss = 1.08646 (* 1 = 1.08646 loss)
I0802 09:30:23.156252 18636 sgd_solver.cpp:136] Iteration 99600, lr = 0.003775, m = 0.9
I0802 09:30:37.098304 18636 solver.cpp:353] Iteration 99700 (7.17266 iter/s, 13.9418s/100 iter), loss = 1.54153
I0802 09:30:37.098332 18636 solver.cpp:375]     Train net output #0: loss = 1.73266 (* 1 = 1.73266 loss)
I0802 09:30:37.098337 18636 sgd_solver.cpp:136] Iteration 99700, lr = 0.00376875, m = 0.9
I0802 09:30:50.983302 18636 solver.cpp:353] Iteration 99800 (7.20222 iter/s, 13.8846s/100 iter), loss = 1.53903
I0802 09:30:50.983326 18636 solver.cpp:375]     Train net output #0: loss = 1.16461 (* 1 = 1.16461 loss)
I0802 09:30:50.983330 18636 sgd_solver.cpp:136] Iteration 99800, lr = 0.0037625, m = 0.9
I0802 09:31:04.876701 18636 solver.cpp:353] Iteration 99900 (7.19786 iter/s, 13.893s/100 iter), loss = 1.44928
I0802 09:31:04.876762 18636 solver.cpp:375]     Train net output #0: loss = 1.25062 (* 1 = 1.25062 loss)
I0802 09:31:04.876768 18636 sgd_solver.cpp:136] Iteration 99900, lr = 0.00375625, m = 0.9
I0802 09:31:18.618074 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_100000.caffemodel
I0802 09:31:18.678428 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_100000.solverstate
I0802 09:31:18.683329 18636 solver.cpp:404] Sparsity after update:
I0802 09:31:18.688526 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:31:18.688563 18636 net.cpp:2270] conv1a_param_0(0.378) 
I0802 09:31:18.688585 18636 net.cpp:2270] conv1b_param_0(0.727) 
I0802 09:31:18.688599 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:31:18.688613 18636 net.cpp:2270] res2a_branch2a_param_0(0.779) 
I0802 09:31:18.688627 18636 net.cpp:2270] res2a_branch2b_param_0(0.706) 
I0802 09:31:18.688639 18636 net.cpp:2270] res3a_branch2a_param_0(0.791) 
I0802 09:31:18.688652 18636 net.cpp:2270] res3a_branch2b_param_0(0.752) 
I0802 09:31:18.688664 18636 net.cpp:2270] res4a_branch2a_param_0(0.798) 
I0802 09:31:18.688676 18636 net.cpp:2270] res4a_branch2b_param_0(0.777) 
I0802 09:31:18.688689 18636 net.cpp:2270] res5a_branch2a_param_0(0.8) 
I0802 09:31:18.688704 18636 net.cpp:2270] res5a_branch2b_param_0(0.799) 
I0802 09:31:18.688715 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.87442e+06/2.86678e+06) 0.654
I0802 09:31:18.688737 18636 solver.cpp:550] Iteration 100000, Testing net (#0)
I0802 09:31:24.579694 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:31:37.392954 18619 data_reader.cpp:264] Starting prefetch of epoch 6
I0802 09:31:38.346082 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.579588
I0802 09:31:38.346107 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811703
I0802 09:31:38.346112 18636 solver.cpp:635]     Test net output #2: loss = 1.84294 (* 1 = 1.84294 loss)
I0802 09:31:38.346132 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6568s
I0802 09:31:38.484393 18661 solver.cpp:450] Finding and applying sparsity: 0.81
I0802 09:32:38.909106 18661 net.cpp:2244] All zero weights of convolution layers are frozen
I0802 09:32:38.911051 18636 solver.cpp:353] Iteration 100000 (1.06347 iter/s, 94.0317s/100 iter), loss = 1.05636
I0802 09:32:38.911069 18636 solver.cpp:375]     Train net output #0: loss = 1.12629 (* 1 = 1.12629 loss)
I0802 09:32:38.911077 18636 sgd_solver.cpp:136] Iteration 100000, lr = 0.00375, m = 0.9
I0802 09:32:53.009567 18636 solver.cpp:353] Iteration 100100 (7.09315 iter/s, 14.0981s/100 iter), loss = 1.75593
I0802 09:32:53.009589 18636 solver.cpp:375]     Train net output #0: loss = 1.83332 (* 1 = 1.83332 loss)
I0802 09:32:53.009595 18636 sgd_solver.cpp:136] Iteration 100100, lr = 0.00374375, m = 0.9
I0802 09:33:06.950006 18636 solver.cpp:353] Iteration 100200 (7.17358 iter/s, 13.94s/100 iter), loss = 1.65658
I0802 09:33:06.950031 18636 solver.cpp:375]     Train net output #0: loss = 1.89256 (* 1 = 1.89256 loss)
I0802 09:33:06.950034 18636 sgd_solver.cpp:136] Iteration 100200, lr = 0.0037375, m = 0.9
I0802 09:33:20.789495 18636 solver.cpp:353] Iteration 100300 (7.2259 iter/s, 13.8391s/100 iter), loss = 1.13369
I0802 09:33:20.789793 18636 solver.cpp:375]     Train net output #0: loss = 1.01064 (* 1 = 1.01064 loss)
I0802 09:33:20.789916 18636 sgd_solver.cpp:136] Iteration 100300, lr = 0.00373125, m = 0.9
I0802 09:33:34.686321 18636 solver.cpp:353] Iteration 100400 (7.19609 iter/s, 13.8964s/100 iter), loss = 1.83013
I0802 09:33:34.686379 18636 solver.cpp:375]     Train net output #0: loss = 1.87397 (* 1 = 1.87397 loss)
I0802 09:33:34.686403 18636 sgd_solver.cpp:136] Iteration 100400, lr = 0.003725, m = 0.9
I0802 09:33:48.620753 18636 solver.cpp:353] Iteration 100500 (7.17667 iter/s, 13.934s/100 iter), loss = 1.45339
I0802 09:33:48.620836 18636 solver.cpp:375]     Train net output #0: loss = 1.6827 (* 1 = 1.6827 loss)
I0802 09:33:48.620860 18636 sgd_solver.cpp:136] Iteration 100500, lr = 0.00371875, m = 0.9
I0802 09:34:02.628841 18636 solver.cpp:353] Iteration 100600 (7.13893 iter/s, 14.0077s/100 iter), loss = 1.73787
I0802 09:34:02.628929 18636 solver.cpp:375]     Train net output #0: loss = 1.90965 (* 1 = 1.90965 loss)
I0802 09:34:02.628937 18636 sgd_solver.cpp:136] Iteration 100600, lr = 0.0037125, m = 0.9
I0802 09:34:16.565910 18636 solver.cpp:353] Iteration 100700 (7.17531 iter/s, 13.9367s/100 iter), loss = 1.50043
I0802 09:34:16.565939 18636 solver.cpp:375]     Train net output #0: loss = 2.01057 (* 1 = 2.01057 loss)
I0802 09:34:16.565945 18636 sgd_solver.cpp:136] Iteration 100700, lr = 0.00370625, m = 0.9
I0802 09:34:30.497944 18636 solver.cpp:353] Iteration 100800 (7.1779 iter/s, 13.9316s/100 iter), loss = 1.13327
I0802 09:34:30.497969 18636 solver.cpp:375]     Train net output #0: loss = 1.17901 (* 1 = 1.17901 loss)
I0802 09:34:30.497974 18636 sgd_solver.cpp:136] Iteration 100800, lr = 0.0037, m = 0.9
I0802 09:34:44.420953 18636 solver.cpp:353] Iteration 100900 (7.18256 iter/s, 13.9226s/100 iter), loss = 1.28511
I0802 09:34:44.421010 18636 solver.cpp:375]     Train net output #0: loss = 1.42288 (* 1 = 1.42288 loss)
I0802 09:34:44.421015 18636 sgd_solver.cpp:136] Iteration 100900, lr = 0.00369375, m = 0.9
I0802 09:34:58.268474 18636 solver.cpp:404] Sparsity after update:
I0802 09:34:58.280022 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:34:58.280038 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:34:58.280048 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:34:58.280051 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:34:58.280055 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:34:58.280058 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:34:58.280061 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:34:58.280066 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:34:58.280068 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:34:58.280071 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:34:58.280076 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:34:58.280078 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:34:58.280087 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:34:58.409523 18636 solver.cpp:353] Iteration 101000 (7.14889 iter/s, 13.9882s/100 iter), loss = 2.10897
I0802 09:34:58.409546 18636 solver.cpp:375]     Train net output #0: loss = 2.07723 (* 1 = 2.07723 loss)
I0802 09:34:58.409551 18636 sgd_solver.cpp:136] Iteration 101000, lr = 0.0036875, m = 0.9
I0802 09:35:12.315387 18636 solver.cpp:353] Iteration 101100 (7.19141 iter/s, 13.9055s/100 iter), loss = 1.62913
I0802 09:35:12.315412 18636 solver.cpp:375]     Train net output #0: loss = 1.44452 (* 1 = 1.44452 loss)
I0802 09:35:12.315418 18636 sgd_solver.cpp:136] Iteration 101100, lr = 0.00368125, m = 0.9
I0802 09:35:26.254663 18636 solver.cpp:353] Iteration 101200 (7.17417 iter/s, 13.9389s/100 iter), loss = 1.15224
I0802 09:35:26.254720 18636 solver.cpp:375]     Train net output #0: loss = 1.23748 (* 1 = 1.23748 loss)
I0802 09:35:26.254725 18636 sgd_solver.cpp:136] Iteration 101200, lr = 0.003675, m = 0.9
I0802 09:35:40.176602 18636 solver.cpp:353] Iteration 101300 (7.18311 iter/s, 13.9216s/100 iter), loss = 1.39322
I0802 09:35:40.176626 18636 solver.cpp:375]     Train net output #0: loss = 1.49874 (* 1 = 1.49874 loss)
I0802 09:35:40.176630 18636 sgd_solver.cpp:136] Iteration 101300, lr = 0.00366875, m = 0.9
I0802 09:35:54.035303 18636 solver.cpp:353] Iteration 101400 (7.21588 iter/s, 13.8583s/100 iter), loss = 1.09496
I0802 09:35:54.035331 18636 solver.cpp:375]     Train net output #0: loss = 1.10446 (* 1 = 1.10446 loss)
I0802 09:35:54.035337 18636 sgd_solver.cpp:136] Iteration 101400, lr = 0.0036625, m = 0.9
I0802 09:36:07.987918 18636 solver.cpp:353] Iteration 101500 (7.16731 iter/s, 13.9522s/100 iter), loss = 1.53272
I0802 09:36:07.987990 18636 solver.cpp:375]     Train net output #0: loss = 1.6388 (* 1 = 1.6388 loss)
I0802 09:36:07.987998 18636 sgd_solver.cpp:136] Iteration 101500, lr = 0.00365625, m = 0.9
I0802 09:36:21.901752 18636 solver.cpp:353] Iteration 101600 (7.18729 iter/s, 13.9134s/100 iter), loss = 1.34612
I0802 09:36:21.901777 18636 solver.cpp:375]     Train net output #0: loss = 1.52886 (* 1 = 1.52886 loss)
I0802 09:36:21.901783 18636 sgd_solver.cpp:136] Iteration 101600, lr = 0.00365, m = 0.9
I0802 09:36:35.772459 18636 solver.cpp:353] Iteration 101700 (7.20964 iter/s, 13.8703s/100 iter), loss = 1.34812
I0802 09:36:35.772486 18636 solver.cpp:375]     Train net output #0: loss = 0.76577 (* 1 = 0.76577 loss)
I0802 09:36:35.772491 18636 sgd_solver.cpp:136] Iteration 101700, lr = 0.00364375, m = 0.9
I0802 09:36:49.666208 18636 solver.cpp:353] Iteration 101800 (7.19768 iter/s, 13.8934s/100 iter), loss = 1.49958
I0802 09:36:49.666314 18636 solver.cpp:375]     Train net output #0: loss = 1.85362 (* 1 = 1.85362 loss)
I0802 09:36:49.666321 18636 sgd_solver.cpp:136] Iteration 101800, lr = 0.0036375, m = 0.9
I0802 09:37:03.500195 18636 solver.cpp:353] Iteration 101900 (7.22877 iter/s, 13.8336s/100 iter), loss = 1.52082
I0802 09:37:03.500223 18636 solver.cpp:375]     Train net output #0: loss = 1.75047 (* 1 = 1.75047 loss)
I0802 09:37:03.500229 18636 sgd_solver.cpp:136] Iteration 101900, lr = 0.00363125, m = 0.9
I0802 09:37:17.341089 18636 solver.cpp:404] Sparsity after update:
I0802 09:37:17.345057 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:37:17.345083 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:37:17.345100 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:37:17.345109 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:37:17.345119 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:37:17.345129 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:37:17.345137 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:37:17.345145 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:37:17.345155 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:37:17.345163 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:37:17.345172 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:37:17.345180 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:37:17.345190 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:37:17.345206 18636 solver.cpp:550] Iteration 102000, Testing net (#0)
I0802 09:37:37.025959 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.574176
I0802 09:37:37.026068 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.805703
I0802 09:37:37.026077 18636 solver.cpp:635]     Test net output #2: loss = 1.86111 (* 1 = 1.86111 loss)
I0802 09:37:37.026096 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6803s
I0802 09:37:37.194598 18636 solver.cpp:353] Iteration 102000 (2.96793 iter/s, 33.6935s/100 iter), loss = 1.99437
I0802 09:37:37.194624 18636 solver.cpp:375]     Train net output #0: loss = 2.46158 (* 1 = 2.46158 loss)
I0802 09:37:37.194629 18636 sgd_solver.cpp:136] Iteration 102000, lr = 0.003625, m = 0.9
I0802 09:37:51.090293 18636 solver.cpp:353] Iteration 102100 (7.19667 iter/s, 13.8953s/100 iter), loss = 1.21927
I0802 09:37:51.090317 18636 solver.cpp:375]     Train net output #0: loss = 1.22717 (* 1 = 1.22717 loss)
I0802 09:37:51.090322 18636 sgd_solver.cpp:136] Iteration 102100, lr = 0.00361875, m = 0.9
I0802 09:38:04.930346 18636 solver.cpp:353] Iteration 102200 (7.22561 iter/s, 13.8397s/100 iter), loss = 1.32408
I0802 09:38:04.930379 18636 solver.cpp:375]     Train net output #0: loss = 1.2771 (* 1 = 1.2771 loss)
I0802 09:38:04.930387 18636 sgd_solver.cpp:136] Iteration 102200, lr = 0.0036125, m = 0.9
I0802 09:38:18.839226 18636 solver.cpp:353] Iteration 102300 (7.18985 iter/s, 13.9085s/100 iter), loss = 1.83622
I0802 09:38:18.839292 18636 solver.cpp:375]     Train net output #0: loss = 2.18686 (* 1 = 2.18686 loss)
I0802 09:38:18.839298 18636 sgd_solver.cpp:136] Iteration 102300, lr = 0.00360625, m = 0.9
I0802 09:38:32.692760 18636 solver.cpp:353] Iteration 102400 (7.21858 iter/s, 13.8531s/100 iter), loss = 1.25369
I0802 09:38:32.692785 18636 solver.cpp:375]     Train net output #0: loss = 1.54582 (* 1 = 1.54582 loss)
I0802 09:38:32.692792 18636 sgd_solver.cpp:136] Iteration 102400, lr = 0.0036, m = 0.9
I0802 09:38:46.598501 18636 solver.cpp:353] Iteration 102500 (7.19147 iter/s, 13.9054s/100 iter), loss = 1.24543
I0802 09:38:46.598556 18636 solver.cpp:375]     Train net output #0: loss = 1.05792 (* 1 = 1.05792 loss)
I0802 09:38:46.598568 18636 sgd_solver.cpp:136] Iteration 102500, lr = 0.00359375, m = 0.9
I0802 09:39:00.550827 18636 solver.cpp:353] Iteration 102600 (7.16746 iter/s, 13.9519s/100 iter), loss = 1.03739
I0802 09:39:00.550935 18636 solver.cpp:375]     Train net output #0: loss = 0.730379 (* 1 = 0.730379 loss)
I0802 09:39:00.550947 18636 sgd_solver.cpp:136] Iteration 102600, lr = 0.0035875, m = 0.9
I0802 09:39:14.460743 18636 solver.cpp:353] Iteration 102700 (7.18931 iter/s, 13.9095s/100 iter), loss = 1.35219
I0802 09:39:14.460769 18636 solver.cpp:375]     Train net output #0: loss = 1.42928 (* 1 = 1.42928 loss)
I0802 09:39:14.460773 18636 sgd_solver.cpp:136] Iteration 102700, lr = 0.00358125, m = 0.9
I0802 09:39:28.414854 18636 solver.cpp:353] Iteration 102800 (7.16655 iter/s, 13.9537s/100 iter), loss = 1.6574
I0802 09:39:28.414881 18636 solver.cpp:375]     Train net output #0: loss = 1.36031 (* 1 = 1.36031 loss)
I0802 09:39:28.414887 18636 sgd_solver.cpp:136] Iteration 102800, lr = 0.003575, m = 0.9
I0802 09:39:42.368685 18636 solver.cpp:353] Iteration 102900 (7.16669 iter/s, 13.9534s/100 iter), loss = 1.63915
I0802 09:39:42.368770 18636 solver.cpp:375]     Train net output #0: loss = 1.35476 (* 1 = 1.35476 loss)
I0802 09:39:42.368777 18636 sgd_solver.cpp:136] Iteration 102900, lr = 0.00356875, m = 0.9
I0802 09:39:56.219862 18636 solver.cpp:404] Sparsity after update:
I0802 09:39:56.232403 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:39:56.232491 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:39:56.232518 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:39:56.232532 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:39:56.232544 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:39:56.232558 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:39:56.232569 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:39:56.232580 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:39:56.232592 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:39:56.232604 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:39:56.232616 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:39:56.232630 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:39:56.232641 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:39:56.361999 18636 solver.cpp:353] Iteration 103000 (7.14647 iter/s, 13.9929s/100 iter), loss = 1.56361
I0802 09:39:56.362078 18636 solver.cpp:375]     Train net output #0: loss = 1.01154 (* 1 = 1.01154 loss)
I0802 09:39:56.362095 18636 sgd_solver.cpp:136] Iteration 103000, lr = 0.0035625, m = 0.9
I0802 09:40:10.358038 18636 solver.cpp:353] Iteration 103100 (7.14508 iter/s, 13.9957s/100 iter), loss = 1.18107
I0802 09:40:10.358069 18636 solver.cpp:375]     Train net output #0: loss = 1.10753 (* 1 = 1.10753 loss)
I0802 09:40:10.358075 18636 sgd_solver.cpp:136] Iteration 103100, lr = 0.00355625, m = 0.9
I0802 09:40:24.247227 18636 solver.cpp:353] Iteration 103200 (7.20004 iter/s, 13.8888s/100 iter), loss = 1.55026
I0802 09:40:24.247328 18636 solver.cpp:375]     Train net output #0: loss = 1.3097 (* 1 = 1.3097 loss)
I0802 09:40:24.247337 18636 sgd_solver.cpp:136] Iteration 103200, lr = 0.00355, m = 0.9
I0802 09:40:38.174479 18636 solver.cpp:353] Iteration 103300 (7.18036 iter/s, 13.9269s/100 iter), loss = 1.53082
I0802 09:40:38.174510 18636 solver.cpp:375]     Train net output #0: loss = 1.83109 (* 1 = 1.83109 loss)
I0802 09:40:38.174516 18636 sgd_solver.cpp:136] Iteration 103300, lr = 0.00354375, m = 0.9
I0802 09:40:52.105681 18636 solver.cpp:353] Iteration 103400 (7.17833 iter/s, 13.9308s/100 iter), loss = 1.57074
I0802 09:40:52.105710 18636 solver.cpp:375]     Train net output #0: loss = 1.96531 (* 1 = 1.96531 loss)
I0802 09:40:52.105716 18636 sgd_solver.cpp:136] Iteration 103400, lr = 0.0035375, m = 0.9
I0802 09:41:06.034324 18636 solver.cpp:353] Iteration 103500 (7.17965 iter/s, 13.9283s/100 iter), loss = 1.22471
I0802 09:41:06.034440 18636 solver.cpp:375]     Train net output #0: loss = 1.03625 (* 1 = 1.03625 loss)
I0802 09:41:06.034461 18636 sgd_solver.cpp:136] Iteration 103500, lr = 0.00353125, m = 0.9
I0802 09:41:20.050493 18636 solver.cpp:353] Iteration 103600 (7.13481 iter/s, 14.0158s/100 iter), loss = 1.26582
I0802 09:41:20.050523 18636 solver.cpp:375]     Train net output #0: loss = 1.20506 (* 1 = 1.20506 loss)
I0802 09:41:20.050529 18636 sgd_solver.cpp:136] Iteration 103600, lr = 0.003525, m = 0.9
I0802 09:41:33.916713 18636 solver.cpp:353] Iteration 103700 (7.21197 iter/s, 13.8658s/100 iter), loss = 1.01781
I0802 09:41:33.916739 18636 solver.cpp:375]     Train net output #0: loss = 1.20099 (* 1 = 1.20099 loss)
I0802 09:41:33.916745 18636 sgd_solver.cpp:136] Iteration 103700, lr = 0.00351875, m = 0.9
I0802 09:41:47.866715 18636 solver.cpp:353] Iteration 103800 (7.16865 iter/s, 13.9496s/100 iter), loss = 1.51808
I0802 09:41:47.866771 18636 solver.cpp:375]     Train net output #0: loss = 1.57503 (* 1 = 1.57503 loss)
I0802 09:41:47.866776 18636 sgd_solver.cpp:136] Iteration 103800, lr = 0.0035125, m = 0.9
I0802 09:42:01.809232 18636 solver.cpp:353] Iteration 103900 (7.1725 iter/s, 13.9421s/100 iter), loss = 1.54744
I0802 09:42:01.809260 18636 solver.cpp:375]     Train net output #0: loss = 1.41026 (* 1 = 1.41026 loss)
I0802 09:42:01.809264 18636 sgd_solver.cpp:136] Iteration 103900, lr = 0.00350625, m = 0.9
I0802 09:42:15.655648 18636 solver.cpp:404] Sparsity after update:
I0802 09:42:15.659632 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:42:15.659644 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:42:15.659653 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:42:15.659657 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:42:15.659664 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:42:15.659670 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:42:15.659675 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:42:15.659680 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:42:15.659684 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:42:15.659688 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:42:15.659693 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:42:15.659696 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:42:15.659700 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:42:15.659710 18636 solver.cpp:550] Iteration 104000, Testing net (#0)
I0802 09:42:35.089581 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578294
I0802 09:42:35.089691 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.808115
I0802 09:42:35.089700 18636 solver.cpp:635]     Test net output #2: loss = 1.84777 (* 1 = 1.84777 loss)
I0802 09:42:35.089720 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4295s
I0802 09:42:35.227929 18636 solver.cpp:353] Iteration 104000 (2.99242 iter/s, 33.4178s/100 iter), loss = 1.2111
I0802 09:42:35.227957 18636 solver.cpp:375]     Train net output #0: loss = 1.03677 (* 1 = 1.03677 loss)
I0802 09:42:35.227962 18636 sgd_solver.cpp:136] Iteration 104000, lr = 0.0035, m = 0.9
I0802 09:42:49.149415 18636 solver.cpp:353] Iteration 104100 (7.18334 iter/s, 13.9211s/100 iter), loss = 1.332
I0802 09:42:49.149443 18636 solver.cpp:375]     Train net output #0: loss = 1.23387 (* 1 = 1.23387 loss)
I0802 09:42:49.149451 18636 sgd_solver.cpp:136] Iteration 104100, lr = 0.00349375, m = 0.9
I0802 09:43:03.106521 18636 solver.cpp:353] Iteration 104200 (7.16501 iter/s, 13.9567s/100 iter), loss = 1.36598
I0802 09:43:03.106550 18636 solver.cpp:375]     Train net output #0: loss = 1.60109 (* 1 = 1.60109 loss)
I0802 09:43:03.106556 18636 sgd_solver.cpp:136] Iteration 104200, lr = 0.0034875, m = 0.9
I0802 09:43:17.000056 18636 solver.cpp:353] Iteration 104300 (7.19779 iter/s, 13.8931s/100 iter), loss = 1.39647
I0802 09:43:17.000149 18636 solver.cpp:375]     Train net output #0: loss = 1.71228 (* 1 = 1.71228 loss)
I0802 09:43:17.000157 18636 sgd_solver.cpp:136] Iteration 104300, lr = 0.00348125, m = 0.9
I0802 09:43:30.890250 18636 solver.cpp:353] Iteration 104400 (7.19952 iter/s, 13.8898s/100 iter), loss = 1.79687
I0802 09:43:30.890275 18636 solver.cpp:375]     Train net output #0: loss = 1.6572 (* 1 = 1.6572 loss)
I0802 09:43:30.890280 18636 sgd_solver.cpp:136] Iteration 104400, lr = 0.003475, m = 0.9
I0802 09:43:44.850674 18636 solver.cpp:353] Iteration 104500 (7.16331 iter/s, 13.96s/100 iter), loss = 1.4613
I0802 09:43:44.850728 18636 solver.cpp:375]     Train net output #0: loss = 1.23126 (* 1 = 1.23126 loss)
I0802 09:43:44.850740 18636 sgd_solver.cpp:136] Iteration 104500, lr = 0.00346875, m = 0.9
I0802 09:43:58.745499 18636 solver.cpp:353] Iteration 104600 (7.19712 iter/s, 13.8944s/100 iter), loss = 1.49202
I0802 09:43:58.745609 18636 solver.cpp:375]     Train net output #0: loss = 1.42756 (* 1 = 1.42756 loss)
I0802 09:43:58.745630 18636 sgd_solver.cpp:136] Iteration 104600, lr = 0.0034625, m = 0.9
I0802 09:44:12.627842 18636 solver.cpp:353] Iteration 104700 (7.20359 iter/s, 13.882s/100 iter), loss = 1.11219
I0802 09:44:12.627876 18636 solver.cpp:375]     Train net output #0: loss = 1.19194 (* 1 = 1.19194 loss)
I0802 09:44:12.627882 18636 sgd_solver.cpp:136] Iteration 104700, lr = 0.00345625, m = 0.9
I0802 09:44:26.601918 18636 solver.cpp:353] Iteration 104800 (7.15631 iter/s, 13.9737s/100 iter), loss = 1.36374
I0802 09:44:26.601946 18636 solver.cpp:375]     Train net output #0: loss = 0.988896 (* 1 = 0.988896 loss)
I0802 09:44:26.601953 18636 sgd_solver.cpp:136] Iteration 104800, lr = 0.00345, m = 0.9
I0802 09:44:40.536388 18636 solver.cpp:353] Iteration 104900 (7.17665 iter/s, 13.9341s/100 iter), loss = 1.63781
I0802 09:44:40.536444 18636 solver.cpp:375]     Train net output #0: loss = 1.51105 (* 1 = 1.51105 loss)
I0802 09:44:40.536450 18636 sgd_solver.cpp:136] Iteration 104900, lr = 0.00344375, m = 0.9
I0802 09:44:54.318403 18636 solver.cpp:404] Sparsity after update:
I0802 09:44:54.328938 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:44:54.328953 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:44:54.328963 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:44:54.328966 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:44:54.328982 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:44:54.328992 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:44:54.329000 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:44:54.329010 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:44:54.329017 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:44:54.329026 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:44:54.329035 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:44:54.329042 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:44:54.329051 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:44:54.458329 18636 solver.cpp:353] Iteration 105000 (7.1831 iter/s, 13.9216s/100 iter), loss = 1.0689
I0802 09:44:54.458354 18636 solver.cpp:375]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0802 09:44:54.458359 18636 sgd_solver.cpp:136] Iteration 105000, lr = 0.0034375, m = 0.9
I0802 09:45:08.341802 18636 solver.cpp:353] Iteration 105100 (7.20301 iter/s, 13.8831s/100 iter), loss = 1.33651
I0802 09:45:08.341984 18636 solver.cpp:375]     Train net output #0: loss = 1.30175 (* 1 = 1.30175 loss)
I0802 09:45:08.342068 18636 sgd_solver.cpp:136] Iteration 105100, lr = 0.00343125, m = 0.9
I0802 09:45:22.325664 18636 solver.cpp:353] Iteration 105200 (7.1513 iter/s, 13.9835s/100 iter), loss = 1.69766
I0802 09:45:22.325749 18636 solver.cpp:375]     Train net output #0: loss = 1.497 (* 1 = 1.497 loss)
I0802 09:45:22.325762 18636 sgd_solver.cpp:136] Iteration 105200, lr = 0.003425, m = 0.9
I0802 09:45:36.322141 18636 solver.cpp:353] Iteration 105300 (7.14485 iter/s, 13.9961s/100 iter), loss = 1.63983
I0802 09:45:36.322163 18636 solver.cpp:375]     Train net output #0: loss = 1.62252 (* 1 = 1.62252 loss)
I0802 09:45:36.322170 18636 sgd_solver.cpp:136] Iteration 105300, lr = 0.00341875, m = 0.9
I0802 09:45:50.254701 18636 solver.cpp:353] Iteration 105400 (7.17763 iter/s, 13.9322s/100 iter), loss = 1.22358
I0802 09:45:50.254729 18636 solver.cpp:375]     Train net output #0: loss = 1.07443 (* 1 = 1.07443 loss)
I0802 09:45:50.254736 18636 sgd_solver.cpp:136] Iteration 105400, lr = 0.0034125, m = 0.9
I0802 09:46:04.260617 18636 solver.cpp:353] Iteration 105500 (7.14004 iter/s, 14.0055s/100 iter), loss = 1.20908
I0802 09:46:04.260704 18636 solver.cpp:375]     Train net output #0: loss = 1.13749 (* 1 = 1.13749 loss)
I0802 09:46:04.260711 18636 sgd_solver.cpp:136] Iteration 105500, lr = 0.00340625, m = 0.9
I0802 09:46:18.179473 18636 solver.cpp:353] Iteration 105600 (7.1847 iter/s, 13.9185s/100 iter), loss = 1.37035
I0802 09:46:18.179502 18636 solver.cpp:375]     Train net output #0: loss = 1.10046 (* 1 = 1.10046 loss)
I0802 09:46:18.179508 18636 sgd_solver.cpp:136] Iteration 105600, lr = 0.0034, m = 0.9
I0802 09:46:32.125982 18636 solver.cpp:353] Iteration 105700 (7.17045 iter/s, 13.9461s/100 iter), loss = 1.55902
I0802 09:46:32.126010 18636 solver.cpp:375]     Train net output #0: loss = 1.72694 (* 1 = 1.72694 loss)
I0802 09:46:32.126016 18636 sgd_solver.cpp:136] Iteration 105700, lr = 0.00339375, m = 0.9
I0802 09:46:46.102259 18636 solver.cpp:353] Iteration 105800 (7.15518 iter/s, 13.9759s/100 iter), loss = 1.52161
I0802 09:46:46.102362 18636 solver.cpp:375]     Train net output #0: loss = 1.60564 (* 1 = 1.60564 loss)
I0802 09:46:46.102381 18636 sgd_solver.cpp:136] Iteration 105800, lr = 0.0033875, m = 0.9
I0802 09:47:00.129954 18636 solver.cpp:353] Iteration 105900 (7.12895 iter/s, 14.0273s/100 iter), loss = 1.22783
I0802 09:47:00.129981 18636 solver.cpp:375]     Train net output #0: loss = 1.56583 (* 1 = 1.56583 loss)
I0802 09:47:00.129987 18636 sgd_solver.cpp:136] Iteration 105900, lr = 0.00338125, m = 0.9
I0802 09:47:13.921906 18636 solver.cpp:404] Sparsity after update:
I0802 09:47:13.926381 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:47:13.926417 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:47:13.926430 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:47:13.926439 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:47:13.926450 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:47:13.926460 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:47:13.926470 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:47:13.926481 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:47:13.926488 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:47:13.926496 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:47:13.926512 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:47:13.926520 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:47:13.926528 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:47:13.926549 18636 solver.cpp:550] Iteration 106000, Testing net (#0)
I0802 09:47:25.376945 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 09:47:33.440882 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578
I0802 09:47:33.440906 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809292
I0802 09:47:33.440912 18636 solver.cpp:635]     Test net output #2: loss = 1.82838 (* 1 = 1.82838 loss)
I0802 09:47:33.441009 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5139s
I0802 09:47:33.578055 18636 solver.cpp:353] Iteration 106000 (2.98979 iter/s, 33.4472s/100 iter), loss = 1.43387
I0802 09:47:33.578305 18636 solver.cpp:375]     Train net output #0: loss = 1.28378 (* 1 = 1.28378 loss)
I0802 09:47:33.578418 18636 sgd_solver.cpp:136] Iteration 106000, lr = 0.003375, m = 0.9
I0802 09:47:47.503957 18636 solver.cpp:353] Iteration 106100 (7.18106 iter/s, 13.9255s/100 iter), loss = 1.44487
I0802 09:47:47.503984 18636 solver.cpp:375]     Train net output #0: loss = 1.67332 (* 1 = 1.67332 loss)
I0802 09:47:47.503988 18636 sgd_solver.cpp:136] Iteration 106100, lr = 0.00336875, m = 0.9
I0802 09:48:01.487061 18636 solver.cpp:353] Iteration 106200 (7.15169 iter/s, 13.9827s/100 iter), loss = 1.39506
I0802 09:48:01.487180 18636 solver.cpp:375]     Train net output #0: loss = 1.25272 (* 1 = 1.25272 loss)
I0802 09:48:01.487190 18636 sgd_solver.cpp:136] Iteration 106200, lr = 0.0033625, m = 0.9
I0802 09:48:15.390166 18636 solver.cpp:353] Iteration 106300 (7.19284 iter/s, 13.9027s/100 iter), loss = 1.12708
I0802 09:48:15.390195 18636 solver.cpp:375]     Train net output #0: loss = 1.21603 (* 1 = 1.21603 loss)
I0802 09:48:15.390202 18636 sgd_solver.cpp:136] Iteration 106300, lr = 0.00335625, m = 0.9
I0802 09:48:29.330901 18636 solver.cpp:353] Iteration 106400 (7.17342 iter/s, 13.9404s/100 iter), loss = 1.33752
I0802 09:48:29.330930 18636 solver.cpp:375]     Train net output #0: loss = 1.55121 (* 1 = 1.55121 loss)
I0802 09:48:29.330937 18636 sgd_solver.cpp:136] Iteration 106400, lr = 0.00335, m = 0.9
I0802 09:48:43.346096 18636 solver.cpp:353] Iteration 106500 (7.13531 iter/s, 14.0148s/100 iter), loss = 1.43256
I0802 09:48:43.346165 18636 solver.cpp:375]     Train net output #0: loss = 1.34552 (* 1 = 1.34552 loss)
I0802 09:48:43.346173 18636 sgd_solver.cpp:136] Iteration 106500, lr = 0.00334375, m = 0.9
I0802 09:48:57.271948 18636 solver.cpp:353] Iteration 106600 (7.18109 iter/s, 13.9255s/100 iter), loss = 1.6253
I0802 09:48:57.271978 18636 solver.cpp:375]     Train net output #0: loss = 1.70686 (* 1 = 1.70686 loss)
I0802 09:48:57.271984 18636 sgd_solver.cpp:136] Iteration 106600, lr = 0.0033375, m = 0.9
I0802 09:49:11.233012 18636 solver.cpp:353] Iteration 106700 (7.16298 iter/s, 13.9607s/100 iter), loss = 1.55936
I0802 09:49:11.233041 18636 solver.cpp:375]     Train net output #0: loss = 1.36271 (* 1 = 1.36271 loss)
I0802 09:49:11.233047 18636 sgd_solver.cpp:136] Iteration 106700, lr = 0.00333125, m = 0.9
I0802 09:49:25.130383 18636 solver.cpp:353] Iteration 106800 (7.19581 iter/s, 13.897s/100 iter), loss = 1.68735
I0802 09:49:25.130481 18636 solver.cpp:375]     Train net output #0: loss = 1.44218 (* 1 = 1.44218 loss)
I0802 09:49:25.130499 18636 sgd_solver.cpp:136] Iteration 106800, lr = 0.003325, m = 0.9
I0802 09:49:39.088791 18636 solver.cpp:353] Iteration 106900 (7.16434 iter/s, 13.958s/100 iter), loss = 1.91405
I0802 09:49:39.088829 18636 solver.cpp:375]     Train net output #0: loss = 1.78122 (* 1 = 1.78122 loss)
I0802 09:49:39.088878 18636 sgd_solver.cpp:136] Iteration 106900, lr = 0.00331875, m = 0.9
I0802 09:49:53.062469 18636 solver.cpp:404] Sparsity after update:
I0802 09:49:53.073631 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:49:53.073648 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:49:53.073657 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:49:53.073660 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:49:53.073663 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:49:53.073667 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:49:53.073670 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:49:53.073673 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:49:53.073676 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:49:53.073679 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:49:53.073683 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:49:53.073685 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:49:53.073688 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:49:53.203754 18636 solver.cpp:353] Iteration 107000 (7.08488 iter/s, 14.1146s/100 iter), loss = 1.6388
I0802 09:49:53.203781 18636 solver.cpp:375]     Train net output #0: loss = 1.59377 (* 1 = 1.59377 loss)
I0802 09:49:53.203788 18636 sgd_solver.cpp:136] Iteration 107000, lr = 0.0033125, m = 0.9
I0802 09:50:07.220563 18636 solver.cpp:353] Iteration 107100 (7.13449 iter/s, 14.0164s/100 iter), loss = 1.42288
I0802 09:50:07.220651 18636 solver.cpp:375]     Train net output #0: loss = 1.58914 (* 1 = 1.58914 loss)
I0802 09:50:07.220659 18636 sgd_solver.cpp:136] Iteration 107100, lr = 0.00330625, m = 0.9
I0802 09:50:21.151489 18636 solver.cpp:353] Iteration 107200 (7.17847 iter/s, 13.9305s/100 iter), loss = 1.53385
I0802 09:50:21.151515 18636 solver.cpp:375]     Train net output #0: loss = 1.15959 (* 1 = 1.15959 loss)
I0802 09:50:21.151522 18636 sgd_solver.cpp:136] Iteration 107200, lr = 0.0033, m = 0.9
I0802 09:50:35.035845 18636 solver.cpp:353] Iteration 107300 (7.20255 iter/s, 13.884s/100 iter), loss = 1.23671
I0802 09:50:35.035873 18636 solver.cpp:375]     Train net output #0: loss = 1.19911 (* 1 = 1.19911 loss)
I0802 09:50:35.035879 18636 sgd_solver.cpp:136] Iteration 107300, lr = 0.00329375, m = 0.9
I0802 09:50:48.963404 18636 solver.cpp:353] Iteration 107400 (7.18021 iter/s, 13.9272s/100 iter), loss = 1.33468
I0802 09:50:48.963508 18636 solver.cpp:375]     Train net output #0: loss = 1.44681 (* 1 = 1.44681 loss)
I0802 09:50:48.963515 18636 sgd_solver.cpp:136] Iteration 107400, lr = 0.0032875, m = 0.9
I0802 09:51:02.870666 18636 solver.cpp:353] Iteration 107500 (7.19069 iter/s, 13.9069s/100 iter), loss = 1.67017
I0802 09:51:02.870695 18636 solver.cpp:375]     Train net output #0: loss = 2.04814 (* 1 = 2.04814 loss)
I0802 09:51:02.870702 18636 sgd_solver.cpp:136] Iteration 107500, lr = 0.00328125, m = 0.9
I0802 09:51:16.766012 18636 solver.cpp:353] Iteration 107600 (7.19686 iter/s, 13.895s/100 iter), loss = 1.31426
I0802 09:51:16.766046 18636 solver.cpp:375]     Train net output #0: loss = 1.40396 (* 1 = 1.40396 loss)
I0802 09:51:16.766052 18636 sgd_solver.cpp:136] Iteration 107600, lr = 0.003275, m = 0.9
I0802 09:51:30.710449 18636 solver.cpp:353] Iteration 107700 (7.17152 iter/s, 13.9441s/100 iter), loss = 1.44487
I0802 09:51:30.710579 18636 solver.cpp:375]     Train net output #0: loss = 1.50806 (* 1 = 1.50806 loss)
I0802 09:51:30.710588 18636 sgd_solver.cpp:136] Iteration 107700, lr = 0.00326875, m = 0.9
I0802 09:51:44.601438 18636 solver.cpp:353] Iteration 107800 (7.19911 iter/s, 13.8906s/100 iter), loss = 1.30251
I0802 09:51:44.601470 18636 solver.cpp:375]     Train net output #0: loss = 1.37887 (* 1 = 1.37887 loss)
I0802 09:51:44.601476 18636 sgd_solver.cpp:136] Iteration 107800, lr = 0.0032625, m = 0.9
I0802 09:51:58.508955 18636 solver.cpp:353] Iteration 107900 (7.19056 iter/s, 13.9071s/100 iter), loss = 1.51297
I0802 09:51:58.508985 18636 solver.cpp:375]     Train net output #0: loss = 1.60829 (* 1 = 1.60829 loss)
I0802 09:51:58.508988 18636 sgd_solver.cpp:136] Iteration 107900, lr = 0.00325625, m = 0.9
I0802 09:52:12.235821 18636 solver.cpp:404] Sparsity after update:
I0802 09:52:12.239812 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:52:12.239825 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:52:12.239833 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:52:12.239836 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:52:12.239840 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:52:12.239843 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:52:12.239846 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:52:12.239850 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:52:12.239852 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:52:12.239856 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:52:12.239857 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:52:12.239861 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:52:12.239864 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:52:12.239876 18636 solver.cpp:550] Iteration 108000, Testing net (#0)
I0802 09:52:31.359550 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.578765
I0802 09:52:31.359586 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.81188
I0802 09:52:31.359591 18636 solver.cpp:635]     Test net output #2: loss = 1.84376 (* 1 = 1.84376 loss)
I0802 09:52:31.360846 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1193s
I0802 09:52:31.500010 18636 solver.cpp:353] Iteration 108000 (3.03121 iter/s, 32.9901s/100 iter), loss = 1.21066
I0802 09:52:31.500036 18636 solver.cpp:375]     Train net output #0: loss = 1.08903 (* 1 = 1.08903 loss)
I0802 09:52:31.500041 18636 sgd_solver.cpp:136] Iteration 108000, lr = 0.00325, m = 0.9
I0802 09:52:45.461787 18636 solver.cpp:353] Iteration 108100 (7.16261 iter/s, 13.9614s/100 iter), loss = 1.54481
I0802 09:52:45.461869 18636 solver.cpp:375]     Train net output #0: loss = 1.65168 (* 1 = 1.65168 loss)
I0802 09:52:45.461875 18636 sgd_solver.cpp:136] Iteration 108100, lr = 0.00324375, m = 0.9
I0802 09:52:59.398116 18636 solver.cpp:353] Iteration 108200 (7.17569 iter/s, 13.9359s/100 iter), loss = 1.445
I0802 09:52:59.398145 18636 solver.cpp:375]     Train net output #0: loss = 1.31885 (* 1 = 1.31885 loss)
I0802 09:52:59.398152 18636 sgd_solver.cpp:136] Iteration 108200, lr = 0.0032375, m = 0.9
I0802 09:53:13.314244 18636 solver.cpp:353] Iteration 108300 (7.18611 iter/s, 13.9157s/100 iter), loss = 1.53293
I0802 09:53:13.314270 18636 solver.cpp:375]     Train net output #0: loss = 1.64212 (* 1 = 1.64212 loss)
I0802 09:53:13.314276 18636 sgd_solver.cpp:136] Iteration 108300, lr = 0.00323125, m = 0.9
I0802 09:53:27.187794 18636 solver.cpp:353] Iteration 108400 (7.20816 iter/s, 13.8732s/100 iter), loss = 1.92139
I0802 09:53:27.187855 18636 solver.cpp:375]     Train net output #0: loss = 1.87155 (* 1 = 1.87155 loss)
I0802 09:53:27.187860 18636 sgd_solver.cpp:136] Iteration 108400, lr = 0.003225, m = 0.9
I0802 09:53:41.089586 18636 solver.cpp:353] Iteration 108500 (7.19352 iter/s, 13.9014s/100 iter), loss = 1.4418
I0802 09:53:41.089614 18636 solver.cpp:375]     Train net output #0: loss = 1.74164 (* 1 = 1.74164 loss)
I0802 09:53:41.089622 18636 sgd_solver.cpp:136] Iteration 108500, lr = 0.00321875, m = 0.9
I0802 09:53:54.912930 18636 solver.cpp:353] Iteration 108600 (7.23434 iter/s, 13.823s/100 iter), loss = 1.43752
I0802 09:53:54.912958 18636 solver.cpp:375]     Train net output #0: loss = 1.59108 (* 1 = 1.59108 loss)
I0802 09:53:54.912964 18636 sgd_solver.cpp:136] Iteration 108600, lr = 0.0032125, m = 0.9
I0802 09:54:08.803300 18636 solver.cpp:353] Iteration 108700 (7.19943 iter/s, 13.89s/100 iter), loss = 1.43184
I0802 09:54:08.803360 18636 solver.cpp:375]     Train net output #0: loss = 1.27682 (* 1 = 1.27682 loss)
I0802 09:54:08.803367 18636 sgd_solver.cpp:136] Iteration 108700, lr = 0.00320625, m = 0.9
I0802 09:54:22.686467 18636 solver.cpp:353] Iteration 108800 (7.20317 iter/s, 13.8828s/100 iter), loss = 1.50791
I0802 09:54:22.686568 18636 solver.cpp:375]     Train net output #0: loss = 1.32833 (* 1 = 1.32833 loss)
I0802 09:54:22.686589 18636 sgd_solver.cpp:136] Iteration 108800, lr = 0.0032, m = 0.9
I0802 09:54:36.691031 18636 solver.cpp:353] Iteration 108900 (7.14073 iter/s, 14.0042s/100 iter), loss = 1.62764
I0802 09:54:36.691099 18636 solver.cpp:375]     Train net output #0: loss = 1.76581 (* 1 = 1.76581 loss)
I0802 09:54:36.691118 18636 sgd_solver.cpp:136] Iteration 108900, lr = 0.00319375, m = 0.9
I0802 09:54:50.523632 18636 solver.cpp:404] Sparsity after update:
I0802 09:54:50.534070 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:54:50.534080 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:54:50.534087 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:54:50.534090 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:54:50.534091 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:54:50.534093 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:54:50.534096 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:54:50.534106 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:54:50.534109 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:54:50.534112 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:54:50.534116 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:54:50.534118 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:54:50.534127 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:54:50.664719 18636 solver.cpp:353] Iteration 109000 (7.15651 iter/s, 13.9733s/100 iter), loss = 1.38409
I0802 09:54:50.664750 18636 solver.cpp:375]     Train net output #0: loss = 1.27052 (* 1 = 1.27052 loss)
I0802 09:54:50.664757 18636 sgd_solver.cpp:136] Iteration 109000, lr = 0.0031875, m = 0.9
I0802 09:55:04.629637 18636 solver.cpp:353] Iteration 109100 (7.161 iter/s, 13.9645s/100 iter), loss = 1.64361
I0802 09:55:04.629688 18636 solver.cpp:375]     Train net output #0: loss = 1.77281 (* 1 = 1.77281 loss)
I0802 09:55:04.629701 18636 sgd_solver.cpp:136] Iteration 109100, lr = 0.00318125, m = 0.9
I0802 09:55:18.633031 18636 solver.cpp:353] Iteration 109200 (7.14133 iter/s, 14.003s/100 iter), loss = 1.53448
I0802 09:55:18.633085 18636 solver.cpp:375]     Train net output #0: loss = 1.54255 (* 1 = 1.54255 loss)
I0802 09:55:18.633098 18636 sgd_solver.cpp:136] Iteration 109200, lr = 0.003175, m = 0.9
I0802 09:55:32.551074 18636 solver.cpp:353] Iteration 109300 (7.18512 iter/s, 13.9177s/100 iter), loss = 1.43142
I0802 09:55:32.551142 18636 solver.cpp:375]     Train net output #0: loss = 1.64677 (* 1 = 1.64677 loss)
I0802 09:55:32.551147 18636 sgd_solver.cpp:136] Iteration 109300, lr = 0.00316875, m = 0.9
I0802 09:55:46.535156 18636 solver.cpp:353] Iteration 109400 (7.15119 iter/s, 13.9837s/100 iter), loss = 1.26337
I0802 09:55:46.535184 18636 solver.cpp:375]     Train net output #0: loss = 1.25766 (* 1 = 1.25766 loss)
I0802 09:55:46.535190 18636 sgd_solver.cpp:136] Iteration 109400, lr = 0.0031625, m = 0.9
I0802 09:56:00.438591 18636 solver.cpp:353] Iteration 109500 (7.19267 iter/s, 13.9031s/100 iter), loss = 1.18013
I0802 09:56:00.438614 18636 solver.cpp:375]     Train net output #0: loss = 0.886575 (* 1 = 0.886575 loss)
I0802 09:56:00.438618 18636 sgd_solver.cpp:136] Iteration 109500, lr = 0.00315625, m = 0.9
I0802 09:56:14.330024 18636 solver.cpp:353] Iteration 109600 (7.19888 iter/s, 13.891s/100 iter), loss = 1.06956
I0802 09:56:14.330083 18636 solver.cpp:375]     Train net output #0: loss = 0.973335 (* 1 = 0.973335 loss)
I0802 09:56:14.330088 18636 sgd_solver.cpp:136] Iteration 109600, lr = 0.00315, m = 0.9
I0802 09:56:28.331392 18636 solver.cpp:353] Iteration 109700 (7.14236 iter/s, 14.001s/100 iter), loss = 1.50621
I0802 09:56:28.331419 18636 solver.cpp:375]     Train net output #0: loss = 1.65386 (* 1 = 1.65386 loss)
I0802 09:56:28.331426 18636 sgd_solver.cpp:136] Iteration 109700, lr = 0.00314375, m = 0.9
I0802 09:56:42.287451 18636 solver.cpp:353] Iteration 109800 (7.16555 iter/s, 13.9557s/100 iter), loss = 1.37565
I0802 09:56:42.287549 18636 solver.cpp:375]     Train net output #0: loss = 1.28733 (* 1 = 1.28733 loss)
I0802 09:56:42.287571 18636 sgd_solver.cpp:136] Iteration 109800, lr = 0.0031375, m = 0.9
I0802 09:56:56.294145 18636 solver.cpp:353] Iteration 109900 (7.13964 iter/s, 14.0063s/100 iter), loss = 1.55475
I0802 09:56:56.294253 18636 solver.cpp:375]     Train net output #0: loss = 1.72318 (* 1 = 1.72318 loss)
I0802 09:56:56.294261 18636 sgd_solver.cpp:136] Iteration 109900, lr = 0.00313125, m = 0.9
I0802 09:57:10.049906 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_110000.caffemodel
I0802 09:57:10.133685 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_110000.solverstate
I0802 09:57:10.138453 18636 solver.cpp:404] Sparsity after update:
I0802 09:57:10.139535 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:57:10.139544 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:57:10.139551 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:57:10.139554 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:57:10.139555 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:57:10.139557 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:57:10.139559 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:57:10.139561 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:57:10.139564 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:57:10.139564 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:57:10.139566 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:57:10.139569 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:57:10.139570 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:57:10.139578 18636 solver.cpp:550] Iteration 110000, Testing net (#0)
I0802 09:57:29.896694 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587176
I0802 09:57:29.896785 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.814761
I0802 09:57:29.896792 18636 solver.cpp:635]     Test net output #2: loss = 1.82084 (* 1 = 1.82084 loss)
I0802 09:57:29.896823 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7567s
I0802 09:57:30.061194 18636 solver.cpp:353] Iteration 110000 (2.96155 iter/s, 33.7661s/100 iter), loss = 1.54245
I0802 09:57:30.061223 18636 solver.cpp:375]     Train net output #0: loss = 1.98987 (* 1 = 1.98987 loss)
I0802 09:57:30.061229 18636 sgd_solver.cpp:136] Iteration 110000, lr = 0.003125, m = 0.9
I0802 09:57:43.999763 18636 solver.cpp:353] Iteration 110100 (7.17454 iter/s, 13.9382s/100 iter), loss = 1.42871
I0802 09:57:43.999792 18636 solver.cpp:375]     Train net output #0: loss = 0.943846 (* 1 = 0.943846 loss)
I0802 09:57:43.999799 18636 sgd_solver.cpp:136] Iteration 110100, lr = 0.00311875, m = 0.9
I0802 09:57:57.951606 18636 solver.cpp:353] Iteration 110200 (7.16771 iter/s, 13.9515s/100 iter), loss = 1.56683
I0802 09:57:57.951630 18636 solver.cpp:375]     Train net output #0: loss = 1.39526 (* 1 = 1.39526 loss)
I0802 09:57:57.951634 18636 sgd_solver.cpp:136] Iteration 110200, lr = 0.0031125, m = 0.9
I0802 09:58:11.862828 18636 solver.cpp:353] Iteration 110300 (7.18864 iter/s, 13.9108s/100 iter), loss = 1.37877
I0802 09:58:11.862887 18636 solver.cpp:375]     Train net output #0: loss = 1.34745 (* 1 = 1.34745 loss)
I0802 09:58:11.862895 18636 sgd_solver.cpp:136] Iteration 110300, lr = 0.00310625, m = 0.9
I0802 09:58:25.759505 18636 solver.cpp:353] Iteration 110400 (7.19617 iter/s, 13.8963s/100 iter), loss = 1.60023
I0802 09:58:25.759534 18636 solver.cpp:375]     Train net output #0: loss = 1.60565 (* 1 = 1.60565 loss)
I0802 09:58:25.759541 18636 sgd_solver.cpp:136] Iteration 110400, lr = 0.0031, m = 0.9
I0802 09:58:39.693251 18636 solver.cpp:353] Iteration 110500 (7.17702 iter/s, 13.9334s/100 iter), loss = 0.899308
I0802 09:58:39.693280 18636 solver.cpp:375]     Train net output #0: loss = 0.705947 (* 1 = 0.705947 loss)
I0802 09:58:39.693284 18636 sgd_solver.cpp:136] Iteration 110500, lr = 0.00309375, m = 0.9
I0802 09:58:53.647609 18636 solver.cpp:353] Iteration 110600 (7.16642 iter/s, 13.954s/100 iter), loss = 1.66885
I0802 09:58:53.647687 18636 solver.cpp:375]     Train net output #0: loss = 1.31351 (* 1 = 1.31351 loss)
I0802 09:58:53.647694 18636 sgd_solver.cpp:136] Iteration 110600, lr = 0.0030875, m = 0.9
I0802 09:59:07.584286 18636 solver.cpp:353] Iteration 110700 (7.17551 iter/s, 13.9363s/100 iter), loss = 1.432
I0802 09:59:07.584338 18636 solver.cpp:375]     Train net output #0: loss = 1.36339 (* 1 = 1.36339 loss)
I0802 09:59:07.584352 18636 sgd_solver.cpp:136] Iteration 110700, lr = 0.00308125, m = 0.9
I0802 09:59:21.551941 18636 solver.cpp:353] Iteration 110800 (7.1596 iter/s, 13.9673s/100 iter), loss = 1.69279
I0802 09:59:21.551971 18636 solver.cpp:375]     Train net output #0: loss = 1.97351 (* 1 = 1.97351 loss)
I0802 09:59:21.551976 18636 sgd_solver.cpp:136] Iteration 110800, lr = 0.003075, m = 0.9
I0802 09:59:35.541040 18636 solver.cpp:353] Iteration 110900 (7.14862 iter/s, 13.9887s/100 iter), loss = 1.5668
I0802 09:59:35.541118 18636 solver.cpp:375]     Train net output #0: loss = 1.42046 (* 1 = 1.42046 loss)
I0802 09:59:35.541124 18636 sgd_solver.cpp:136] Iteration 110900, lr = 0.00306875, m = 0.9
I0802 09:59:49.294559 18636 solver.cpp:404] Sparsity after update:
I0802 09:59:49.308532 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 09:59:49.308547 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 09:59:49.308555 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 09:59:49.308559 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 09:59:49.308562 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 09:59:49.308567 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 09:59:49.308571 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 09:59:49.308575 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 09:59:49.308579 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 09:59:49.308583 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 09:59:49.308586 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 09:59:49.308590 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 09:59:49.308594 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 09:59:49.438077 18636 solver.cpp:353] Iteration 111000 (7.19598 iter/s, 13.8966s/100 iter), loss = 1.22502
I0802 09:59:49.438123 18636 solver.cpp:375]     Train net output #0: loss = 1.4101 (* 1 = 1.4101 loss)
I0802 09:59:49.438132 18636 sgd_solver.cpp:136] Iteration 111000, lr = 0.0030625, m = 0.9
I0802 10:00:03.381567 18636 solver.cpp:353] Iteration 111100 (7.17201 iter/s, 13.9431s/100 iter), loss = 1.45615
I0802 10:00:03.381666 18636 solver.cpp:375]     Train net output #0: loss = 1.70429 (* 1 = 1.70429 loss)
I0802 10:00:03.381687 18636 sgd_solver.cpp:136] Iteration 111100, lr = 0.00305625, m = 0.9
I0802 10:00:17.235638 18636 solver.cpp:353] Iteration 111200 (7.2183 iter/s, 13.8537s/100 iter), loss = 1.59103
I0802 10:00:17.235751 18636 solver.cpp:375]     Train net output #0: loss = 1.52261 (* 1 = 1.52261 loss)
I0802 10:00:17.235774 18636 sgd_solver.cpp:136] Iteration 111200, lr = 0.00305, m = 0.9
I0802 10:00:31.216117 18636 solver.cpp:353] Iteration 111300 (7.15303 iter/s, 13.9801s/100 iter), loss = 1.72469
I0802 10:00:31.216210 18636 solver.cpp:375]     Train net output #0: loss = 1.9546 (* 1 = 1.9546 loss)
I0802 10:00:31.216230 18636 sgd_solver.cpp:136] Iteration 111300, lr = 0.00304375, m = 0.9
I0802 10:00:45.175932 18636 solver.cpp:353] Iteration 111400 (7.16362 iter/s, 13.9594s/100 iter), loss = 1.60009
I0802 10:00:45.175963 18636 solver.cpp:375]     Train net output #0: loss = 1.76351 (* 1 = 1.76351 loss)
I0802 10:00:45.175969 18636 sgd_solver.cpp:136] Iteration 111400, lr = 0.0030375, m = 0.9
I0802 10:00:59.124423 18636 solver.cpp:353] Iteration 111500 (7.16943 iter/s, 13.9481s/100 iter), loss = 1.45916
I0802 10:00:59.124488 18636 solver.cpp:375]     Train net output #0: loss = 1.30357 (* 1 = 1.30357 loss)
I0802 10:00:59.124495 18636 sgd_solver.cpp:136] Iteration 111500, lr = 0.00303125, m = 0.9
I0802 10:01:13.140432 18636 solver.cpp:353] Iteration 111600 (7.1349 iter/s, 14.0156s/100 iter), loss = 1.1732
I0802 10:01:13.140458 18636 solver.cpp:375]     Train net output #0: loss = 1.2387 (* 1 = 1.2387 loss)
I0802 10:01:13.140465 18636 sgd_solver.cpp:136] Iteration 111600, lr = 0.003025, m = 0.9
I0802 10:01:27.083883 18636 solver.cpp:353] Iteration 111700 (7.17203 iter/s, 13.9431s/100 iter), loss = 1.26682
I0802 10:01:27.083935 18636 solver.cpp:375]     Train net output #0: loss = 1.34781 (* 1 = 1.34781 loss)
I0802 10:01:27.083947 18636 sgd_solver.cpp:136] Iteration 111700, lr = 0.00301875, m = 0.9
I0802 10:01:40.986263 18636 solver.cpp:353] Iteration 111800 (7.19321 iter/s, 13.902s/100 iter), loss = 1.1719
I0802 10:01:40.986347 18636 solver.cpp:375]     Train net output #0: loss = 0.891695 (* 1 = 0.891695 loss)
I0802 10:01:40.986356 18636 sgd_solver.cpp:136] Iteration 111800, lr = 0.0030125, m = 0.9
I0802 10:01:54.894105 18636 solver.cpp:353] Iteration 111900 (7.19039 iter/s, 13.9075s/100 iter), loss = 1.47227
I0802 10:01:54.894134 18636 solver.cpp:375]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0802 10:01:54.894140 18636 sgd_solver.cpp:136] Iteration 111900, lr = 0.00300625, m = 0.9
I0802 10:02:08.691491 18636 solver.cpp:404] Sparsity after update:
I0802 10:02:08.695911 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:02:08.695924 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:02:08.695932 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:02:08.695935 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:02:08.695943 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:02:08.695948 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:02:08.695953 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:02:08.695958 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:02:08.695962 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:02:08.695967 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:02:08.695971 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:02:08.695976 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:02:08.695979 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:02:08.695991 18636 solver.cpp:550] Iteration 112000, Testing net (#0)
I0802 10:02:25.807714 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:02:28.220942 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581235
I0802 10:02:28.220966 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.809409
I0802 10:02:28.220971 18636 solver.cpp:635]     Test net output #2: loss = 1.83961 (* 1 = 1.83961 loss)
I0802 10:02:28.221216 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5247s
I0802 10:02:28.365306 18636 solver.cpp:353] Iteration 112000 (2.98773 iter/s, 33.4703s/100 iter), loss = 1.51207
I0802 10:02:28.365339 18636 solver.cpp:375]     Train net output #0: loss = 1.71552 (* 1 = 1.71552 loss)
I0802 10:02:28.365345 18636 sgd_solver.cpp:136] Iteration 112000, lr = 0.003, m = 0.9
I0802 10:02:42.256425 18636 solver.cpp:353] Iteration 112100 (7.19904 iter/s, 13.8907s/100 iter), loss = 1.39908
I0802 10:02:42.256479 18636 solver.cpp:375]     Train net output #0: loss = 1.46986 (* 1 = 1.46986 loss)
I0802 10:02:42.256491 18636 sgd_solver.cpp:136] Iteration 112100, lr = 0.00299375, m = 0.9
I0802 10:02:56.214717 18636 solver.cpp:353] Iteration 112200 (7.1644 iter/s, 13.9579s/100 iter), loss = 1.15719
I0802 10:02:56.214818 18636 solver.cpp:375]     Train net output #0: loss = 1.06433 (* 1 = 1.06433 loss)
I0802 10:02:56.214836 18636 sgd_solver.cpp:136] Iteration 112200, lr = 0.0029875, m = 0.9
I0802 10:03:10.220976 18636 solver.cpp:353] Iteration 112300 (7.13986 iter/s, 14.0059s/100 iter), loss = 1.48543
I0802 10:03:10.221004 18636 solver.cpp:375]     Train net output #0: loss = 1.42599 (* 1 = 1.42599 loss)
I0802 10:03:10.221007 18636 sgd_solver.cpp:136] Iteration 112300, lr = 0.00298125, m = 0.9
I0802 10:03:24.168282 18636 solver.cpp:353] Iteration 112400 (7.17004 iter/s, 13.9469s/100 iter), loss = 1.2516
I0802 10:03:24.168505 18636 solver.cpp:375]     Train net output #0: loss = 1.13621 (* 1 = 1.13621 loss)
I0802 10:03:24.168615 18636 sgd_solver.cpp:136] Iteration 112400, lr = 0.002975, m = 0.9
I0802 10:03:38.097812 18636 solver.cpp:353] Iteration 112500 (7.17919 iter/s, 13.9291s/100 iter), loss = 1.63233
I0802 10:03:38.097895 18636 solver.cpp:375]     Train net output #0: loss = 1.43651 (* 1 = 1.43651 loss)
I0802 10:03:38.097903 18636 sgd_solver.cpp:136] Iteration 112500, lr = 0.00296875, m = 0.9
I0802 10:03:52.156004 18636 solver.cpp:353] Iteration 112600 (7.11349 iter/s, 14.0578s/100 iter), loss = 1.50537
I0802 10:03:52.156030 18636 solver.cpp:375]     Train net output #0: loss = 1.54782 (* 1 = 1.54782 loss)
I0802 10:03:52.156035 18636 sgd_solver.cpp:136] Iteration 112600, lr = 0.0029625, m = 0.9
I0802 10:04:06.066702 18636 solver.cpp:353] Iteration 112700 (7.18891 iter/s, 13.9103s/100 iter), loss = 1.38207
I0802 10:04:06.066731 18636 solver.cpp:375]     Train net output #0: loss = 1.62054 (* 1 = 1.62054 loss)
I0802 10:04:06.066737 18636 sgd_solver.cpp:136] Iteration 112700, lr = 0.00295625, m = 0.9
I0802 10:04:19.999792 18636 solver.cpp:353] Iteration 112800 (7.17736 iter/s, 13.9327s/100 iter), loss = 1.4825
I0802 10:04:19.999855 18636 solver.cpp:375]     Train net output #0: loss = 1.74482 (* 1 = 1.74482 loss)
I0802 10:04:19.999861 18636 sgd_solver.cpp:136] Iteration 112800, lr = 0.00295, m = 0.9
I0802 10:04:34.025063 18636 solver.cpp:353] Iteration 112900 (7.13018 iter/s, 14.0249s/100 iter), loss = 1.74798
I0802 10:04:34.025092 18636 solver.cpp:375]     Train net output #0: loss = 1.6714 (* 1 = 1.6714 loss)
I0802 10:04:34.025099 18636 sgd_solver.cpp:136] Iteration 112900, lr = 0.00294375, m = 0.9
I0802 10:04:47.829897 18636 solver.cpp:404] Sparsity after update:
I0802 10:04:47.842758 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:04:47.842772 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:04:47.842780 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:04:47.842782 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:04:47.842784 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:04:47.842787 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:04:47.842788 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:04:47.842790 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:04:47.842792 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:04:47.842793 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:04:47.842795 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:04:47.842797 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:04:47.842799 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:04:47.971690 18636 solver.cpp:353] Iteration 113000 (7.17039 iter/s, 13.9462s/100 iter), loss = 1.55995
I0802 10:04:47.971741 18636 solver.cpp:375]     Train net output #0: loss = 1.1716 (* 1 = 1.1716 loss)
I0802 10:04:47.971755 18636 sgd_solver.cpp:136] Iteration 113000, lr = 0.0029375, m = 0.9
I0802 10:05:01.949004 18636 solver.cpp:353] Iteration 113100 (7.15465 iter/s, 13.9769s/100 iter), loss = 1.59824
I0802 10:05:01.949098 18636 solver.cpp:375]     Train net output #0: loss = 1.68197 (* 1 = 1.68197 loss)
I0802 10:05:01.949111 18636 sgd_solver.cpp:136] Iteration 113100, lr = 0.00293125, m = 0.9
I0802 10:05:15.855602 18636 solver.cpp:353] Iteration 113200 (7.19103 iter/s, 13.9062s/100 iter), loss = 1.27216
I0802 10:05:15.855630 18636 solver.cpp:375]     Train net output #0: loss = 1.14336 (* 1 = 1.14336 loss)
I0802 10:05:15.855635 18636 sgd_solver.cpp:136] Iteration 113200, lr = 0.002925, m = 0.9
I0802 10:05:29.762634 18636 solver.cpp:353] Iteration 113300 (7.19081 iter/s, 13.9066s/100 iter), loss = 1.53708
I0802 10:05:29.762661 18636 solver.cpp:375]     Train net output #0: loss = 0.987813 (* 1 = 0.987813 loss)
I0802 10:05:29.762667 18636 sgd_solver.cpp:136] Iteration 113300, lr = 0.00291875, m = 0.9
I0802 10:05:43.789441 18636 solver.cpp:353] Iteration 113400 (7.12941 iter/s, 14.0264s/100 iter), loss = 1.38819
I0802 10:05:43.789589 18636 solver.cpp:375]     Train net output #0: loss = 1.46613 (* 1 = 1.46613 loss)
I0802 10:05:43.789609 18636 sgd_solver.cpp:136] Iteration 113400, lr = 0.0029125, m = 0.9
I0802 10:05:57.762074 18636 solver.cpp:353] Iteration 113500 (7.15704 iter/s, 13.9722s/100 iter), loss = 1.34474
I0802 10:05:57.762101 18636 solver.cpp:375]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I0802 10:05:57.762106 18636 sgd_solver.cpp:136] Iteration 113500, lr = 0.00290625, m = 0.9
I0802 10:06:11.718737 18636 solver.cpp:353] Iteration 113600 (7.16524 iter/s, 13.9563s/100 iter), loss = 1.24925
I0802 10:06:11.718761 18636 solver.cpp:375]     Train net output #0: loss = 1.27021 (* 1 = 1.27021 loss)
I0802 10:06:11.718767 18636 sgd_solver.cpp:136] Iteration 113600, lr = 0.0029, m = 0.9
I0802 10:06:25.852998 18636 solver.cpp:353] Iteration 113700 (7.0752 iter/s, 14.1339s/100 iter), loss = 1.70991
I0802 10:06:25.853081 18636 solver.cpp:375]     Train net output #0: loss = 1.89208 (* 1 = 1.89208 loss)
I0802 10:06:25.853088 18636 sgd_solver.cpp:136] Iteration 113700, lr = 0.00289375, m = 0.9
I0802 10:06:39.865314 18636 solver.cpp:353] Iteration 113800 (7.13678 iter/s, 14.0119s/100 iter), loss = 1.31448
I0802 10:06:39.865340 18636 solver.cpp:375]     Train net output #0: loss = 1.70257 (* 1 = 1.70257 loss)
I0802 10:06:39.865345 18636 sgd_solver.cpp:136] Iteration 113800, lr = 0.0028875, m = 0.9
I0802 10:06:53.767094 18636 solver.cpp:353] Iteration 113900 (7.19352 iter/s, 13.9014s/100 iter), loss = 1.59577
I0802 10:06:53.767124 18636 solver.cpp:375]     Train net output #0: loss = 1.5135 (* 1 = 1.5135 loss)
I0802 10:06:53.767130 18636 sgd_solver.cpp:136] Iteration 113900, lr = 0.00288125, m = 0.9
I0802 10:07:07.618507 18636 solver.cpp:404] Sparsity after update:
I0802 10:07:07.623481 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:07:07.623492 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:07:07.623500 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:07:07.623504 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:07:07.623512 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:07:07.623517 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:07:07.623522 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:07:07.623527 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:07:07.623531 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:07:07.623535 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:07:07.623540 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:07:07.623543 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:07:07.623548 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:07:07.623560 18636 solver.cpp:550] Iteration 114000, Testing net (#0)
I0802 10:07:27.359398 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.577353
I0802 10:07:27.359424 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810173
I0802 10:07:27.359429 18636 solver.cpp:635]     Test net output #2: loss = 1.85034 (* 1 = 1.85034 loss)
I0802 10:07:27.359480 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7354s
I0802 10:07:27.508147 18636 solver.cpp:353] Iteration 114000 (2.96383 iter/s, 33.7401s/100 iter), loss = 0.91309
I0802 10:07:27.508347 18636 solver.cpp:375]     Train net output #0: loss = 0.764577 (* 1 = 0.764577 loss)
I0802 10:07:27.508437 18636 sgd_solver.cpp:136] Iteration 114000, lr = 0.002875, m = 0.9
I0802 10:07:41.491348 18636 solver.cpp:353] Iteration 114100 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.34853
I0802 10:07:41.491435 18636 solver.cpp:375]     Train net output #0: loss = 1.35189 (* 1 = 1.35189 loss)
I0802 10:07:41.491441 18636 sgd_solver.cpp:136] Iteration 114100, lr = 0.00286875, m = 0.9
I0802 10:07:55.438851 18636 solver.cpp:353] Iteration 114200 (7.16994 iter/s, 13.9471s/100 iter), loss = 1.26506
I0802 10:07:55.438947 18636 solver.cpp:375]     Train net output #0: loss = 1.3461 (* 1 = 1.3461 loss)
I0802 10:07:55.438966 18636 sgd_solver.cpp:136] Iteration 114200, lr = 0.0028625, m = 0.9
I0802 10:07:56.891306 18597 data_reader.cpp:264] Starting prefetch of epoch 3
I0802 10:08:09.345686 18636 solver.cpp:353] Iteration 114300 (7.19091 iter/s, 13.9064s/100 iter), loss = 1.5841
I0802 10:08:09.345715 18636 solver.cpp:375]     Train net output #0: loss = 2.10423 (* 1 = 2.10423 loss)
I0802 10:08:09.345721 18636 sgd_solver.cpp:136] Iteration 114300, lr = 0.00285625, m = 0.9
I0802 10:08:23.400413 18636 solver.cpp:353] Iteration 114400 (7.11524 iter/s, 14.0543s/100 iter), loss = 1.5817
I0802 10:08:23.400475 18636 solver.cpp:375]     Train net output #0: loss = 1.74919 (* 1 = 1.74919 loss)
I0802 10:08:23.400481 18636 sgd_solver.cpp:136] Iteration 114400, lr = 0.00285, m = 0.9
I0802 10:08:37.269358 18636 solver.cpp:353] Iteration 114500 (7.21056 iter/s, 13.8686s/100 iter), loss = 2.00215
I0802 10:08:37.269409 18636 solver.cpp:375]     Train net output #0: loss = 2.21537 (* 1 = 2.21537 loss)
I0802 10:08:37.269423 18636 sgd_solver.cpp:136] Iteration 114500, lr = 0.00284375, m = 0.9
I0802 10:08:51.389118 18636 solver.cpp:353] Iteration 114600 (7.08247 iter/s, 14.1194s/100 iter), loss = 1.50907
I0802 10:08:51.389147 18636 solver.cpp:375]     Train net output #0: loss = 1.39477 (* 1 = 1.39477 loss)
I0802 10:08:51.389153 18636 sgd_solver.cpp:136] Iteration 114600, lr = 0.0028375, m = 0.9
I0802 10:09:05.277951 18636 solver.cpp:353] Iteration 114700 (7.20023 iter/s, 13.8884s/100 iter), loss = 1.1697
I0802 10:09:05.278053 18636 solver.cpp:375]     Train net output #0: loss = 1.18772 (* 1 = 1.18772 loss)
I0802 10:09:05.278064 18636 sgd_solver.cpp:136] Iteration 114700, lr = 0.00283125, m = 0.9
I0802 10:09:19.196823 18636 solver.cpp:353] Iteration 114800 (7.18469 iter/s, 13.9185s/100 iter), loss = 1.55788
I0802 10:09:19.196852 18636 solver.cpp:375]     Train net output #0: loss = 1.59841 (* 1 = 1.59841 loss)
I0802 10:09:19.196858 18636 sgd_solver.cpp:136] Iteration 114800, lr = 0.002825, m = 0.9
I0802 10:09:33.123132 18636 solver.cpp:353] Iteration 114900 (7.18085 iter/s, 13.9259s/100 iter), loss = 1.15911
I0802 10:09:33.123164 18636 solver.cpp:375]     Train net output #0: loss = 1.25971 (* 1 = 1.25971 loss)
I0802 10:09:33.123172 18636 sgd_solver.cpp:136] Iteration 114900, lr = 0.00281875, m = 0.9
I0802 10:09:46.929257 18636 solver.cpp:404] Sparsity after update:
I0802 10:09:46.940212 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:09:46.940244 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:09:46.940260 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:09:46.940270 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:09:46.940280 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:09:46.940289 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:09:46.940299 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:09:46.940309 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:09:46.940317 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:09:46.940326 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:09:46.940335 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:09:46.940345 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:09:46.940353 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:09:47.071051 18636 solver.cpp:353] Iteration 115000 (7.16973 iter/s, 13.9475s/100 iter), loss = 1.47883
I0802 10:09:47.071080 18636 solver.cpp:375]     Train net output #0: loss = 1.34086 (* 1 = 1.34086 loss)
I0802 10:09:47.071085 18636 sgd_solver.cpp:136] Iteration 115000, lr = 0.0028125, m = 0.9
I0802 10:10:01.087105 18636 solver.cpp:353] Iteration 115100 (7.13488 iter/s, 14.0157s/100 iter), loss = 1.60786
I0802 10:10:01.087157 18636 solver.cpp:375]     Train net output #0: loss = 1.28492 (* 1 = 1.28492 loss)
I0802 10:10:01.087167 18636 sgd_solver.cpp:136] Iteration 115100, lr = 0.00280625, m = 0.9
I0802 10:10:15.190274 18636 solver.cpp:353] Iteration 115200 (7.0908 iter/s, 14.1028s/100 iter), loss = 1.33766
I0802 10:10:15.190299 18636 solver.cpp:375]     Train net output #0: loss = 1.29343 (* 1 = 1.29343 loss)
I0802 10:10:15.190304 18636 sgd_solver.cpp:136] Iteration 115200, lr = 0.0028, m = 0.9
I0802 10:10:29.220010 18636 solver.cpp:353] Iteration 115300 (7.12792 iter/s, 14.0293s/100 iter), loss = 1.71744
I0802 10:10:29.220069 18636 solver.cpp:375]     Train net output #0: loss = 2.18873 (* 1 = 2.18873 loss)
I0802 10:10:29.220078 18636 sgd_solver.cpp:136] Iteration 115300, lr = 0.00279375, m = 0.9
I0802 10:10:43.194103 18636 solver.cpp:353] Iteration 115400 (7.1563 iter/s, 13.9737s/100 iter), loss = 0.949011
I0802 10:10:43.194139 18636 solver.cpp:375]     Train net output #0: loss = 1.0021 (* 1 = 1.0021 loss)
I0802 10:10:43.194146 18636 sgd_solver.cpp:136] Iteration 115400, lr = 0.0027875, m = 0.9
I0802 10:10:57.485473 18636 solver.cpp:353] Iteration 115500 (6.99742 iter/s, 14.291s/100 iter), loss = 1.64631
I0802 10:10:57.485503 18636 solver.cpp:375]     Train net output #0: loss = 1.68729 (* 1 = 1.68729 loss)
I0802 10:10:57.485509 18636 sgd_solver.cpp:136] Iteration 115500, lr = 0.00278125, m = 0.9
I0802 10:11:11.456862 18636 solver.cpp:353] Iteration 115600 (7.15768 iter/s, 13.971s/100 iter), loss = 1.74328
I0802 10:11:11.456967 18636 solver.cpp:375]     Train net output #0: loss = 1.91956 (* 1 = 1.91956 loss)
I0802 10:11:11.456974 18636 sgd_solver.cpp:136] Iteration 115600, lr = 0.002775, m = 0.9
I0802 10:11:25.411651 18636 solver.cpp:353] Iteration 115700 (7.1662 iter/s, 13.9544s/100 iter), loss = 1.01207
I0802 10:11:25.411680 18636 solver.cpp:375]     Train net output #0: loss = 0.98901 (* 1 = 0.98901 loss)
I0802 10:11:25.411686 18636 sgd_solver.cpp:136] Iteration 115700, lr = 0.00276875, m = 0.9
I0802 10:11:39.485565 18636 solver.cpp:353] Iteration 115800 (7.10554 iter/s, 14.0735s/100 iter), loss = 1.77353
I0802 10:11:39.485594 18636 solver.cpp:375]     Train net output #0: loss = 2.0803 (* 1 = 2.0803 loss)
I0802 10:11:39.485599 18636 sgd_solver.cpp:136] Iteration 115800, lr = 0.0027625, m = 0.9
I0802 10:11:53.385000 18636 solver.cpp:353] Iteration 115900 (7.19474 iter/s, 13.8991s/100 iter), loss = 1.52729
I0802 10:11:53.385087 18636 solver.cpp:375]     Train net output #0: loss = 1.65443 (* 1 = 1.65443 loss)
I0802 10:11:53.385098 18636 sgd_solver.cpp:136] Iteration 115900, lr = 0.00275625, m = 0.9
I0802 10:12:07.182519 18636 solver.cpp:404] Sparsity after update:
I0802 10:12:07.186753 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:12:07.186765 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:12:07.186774 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:12:07.186777 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:12:07.186790 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:12:07.186800 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:12:07.186810 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:12:07.186818 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:12:07.186826 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:12:07.186836 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:12:07.186844 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:12:07.186854 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:12:07.186864 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:12:07.186883 18636 solver.cpp:550] Iteration 116000, Testing net (#0)
I0802 10:12:26.842962 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584471
I0802 10:12:26.843070 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.813644
I0802 10:12:26.843080 18636 solver.cpp:635]     Test net output #2: loss = 1.80801 (* 1 = 1.80801 loss)
I0802 10:12:26.843098 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6557s
I0802 10:12:26.982319 18636 solver.cpp:353] Iteration 116000 (2.97651 iter/s, 33.5964s/100 iter), loss = 1.2782
I0802 10:12:26.982373 18636 solver.cpp:375]     Train net output #0: loss = 1.27656 (* 1 = 1.27656 loss)
I0802 10:12:26.982386 18636 sgd_solver.cpp:136] Iteration 116000, lr = 0.00275, m = 0.9
I0802 10:12:40.941445 18636 solver.cpp:353] Iteration 116100 (7.16397 iter/s, 13.9587s/100 iter), loss = 1.39822
I0802 10:12:40.941473 18636 solver.cpp:375]     Train net output #0: loss = 1.22729 (* 1 = 1.22729 loss)
I0802 10:12:40.941478 18636 sgd_solver.cpp:136] Iteration 116100, lr = 0.00274375, m = 0.9
I0802 10:12:54.906072 18636 solver.cpp:353] Iteration 116200 (7.16115 iter/s, 13.9642s/100 iter), loss = 1.44122
I0802 10:12:54.906096 18636 solver.cpp:375]     Train net output #0: loss = 1.43812 (* 1 = 1.43812 loss)
I0802 10:12:54.906102 18636 sgd_solver.cpp:136] Iteration 116200, lr = 0.0027375, m = 0.9
I0802 10:13:08.883584 18636 solver.cpp:353] Iteration 116300 (7.15455 iter/s, 13.9771s/100 iter), loss = 1.64097
I0802 10:13:08.883641 18636 solver.cpp:375]     Train net output #0: loss = 1.85543 (* 1 = 1.85543 loss)
I0802 10:13:08.883646 18636 sgd_solver.cpp:136] Iteration 116300, lr = 0.00273125, m = 0.9
I0802 10:13:22.914695 18636 solver.cpp:353] Iteration 116400 (7.12722 iter/s, 14.0307s/100 iter), loss = 1.32614
I0802 10:13:22.914721 18636 solver.cpp:375]     Train net output #0: loss = 0.980576 (* 1 = 0.980576 loss)
I0802 10:13:22.914724 18636 sgd_solver.cpp:136] Iteration 116400, lr = 0.002725, m = 0.9
I0802 10:13:36.847661 18636 solver.cpp:353] Iteration 116500 (7.17742 iter/s, 13.9326s/100 iter), loss = 1.27136
I0802 10:13:36.847697 18636 solver.cpp:375]     Train net output #0: loss = 1.22615 (* 1 = 1.22615 loss)
I0802 10:13:36.847703 18636 sgd_solver.cpp:136] Iteration 116500, lr = 0.00271875, m = 0.9
I0802 10:13:50.887928 18636 solver.cpp:353] Iteration 116600 (7.12257 iter/s, 14.0399s/100 iter), loss = 1.30314
I0802 10:13:50.888010 18636 solver.cpp:375]     Train net output #0: loss = 1.31045 (* 1 = 1.31045 loss)
I0802 10:13:50.888016 18636 sgd_solver.cpp:136] Iteration 116600, lr = 0.0027125, m = 0.9
I0802 10:14:04.846424 18636 solver.cpp:353] Iteration 116700 (7.1643 iter/s, 13.9581s/100 iter), loss = 1.10706
I0802 10:14:04.846451 18636 solver.cpp:375]     Train net output #0: loss = 1.19037 (* 1 = 1.19037 loss)
I0802 10:14:04.846457 18636 sgd_solver.cpp:136] Iteration 116700, lr = 0.00270625, m = 0.9
I0802 10:14:18.736294 18636 solver.cpp:353] Iteration 116800 (7.19969 iter/s, 13.8895s/100 iter), loss = 1.68322
I0802 10:14:18.736323 18636 solver.cpp:375]     Train net output #0: loss = 1.68153 (* 1 = 1.68153 loss)
I0802 10:14:18.736330 18636 sgd_solver.cpp:136] Iteration 116800, lr = 0.0027, m = 0.9
I0802 10:14:32.684116 18636 solver.cpp:353] Iteration 116900 (7.16978 iter/s, 13.9474s/100 iter), loss = 1.4956
I0802 10:14:32.684226 18636 solver.cpp:375]     Train net output #0: loss = 1.49683 (* 1 = 1.49683 loss)
I0802 10:14:32.684231 18636 sgd_solver.cpp:136] Iteration 116900, lr = 0.00269375, m = 0.9
I0802 10:14:46.714704 18636 solver.cpp:404] Sparsity after update:
I0802 10:14:46.727128 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:14:46.727140 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:14:46.727147 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:14:46.727149 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:14:46.727151 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:14:46.727154 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:14:46.727155 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:14:46.727157 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:14:46.727162 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:14:46.727165 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:14:46.727169 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:14:46.727171 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:14:46.727175 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:14:46.856703 18636 solver.cpp:353] Iteration 117000 (7.05607 iter/s, 14.1722s/100 iter), loss = 1.36616
I0802 10:14:46.856727 18636 solver.cpp:375]     Train net output #0: loss = 1.15066 (* 1 = 1.15066 loss)
I0802 10:14:46.856734 18636 sgd_solver.cpp:136] Iteration 117000, lr = 0.0026875, m = 0.9
I0802 10:15:00.813944 18636 solver.cpp:353] Iteration 117100 (7.16494 iter/s, 13.9569s/100 iter), loss = 1.02112
I0802 10:15:00.813971 18636 solver.cpp:375]     Train net output #0: loss = 1.02217 (* 1 = 1.02217 loss)
I0802 10:15:00.813976 18636 sgd_solver.cpp:136] Iteration 117100, lr = 0.00268125, m = 0.9
I0802 10:15:14.774521 18636 solver.cpp:353] Iteration 117200 (7.16323 iter/s, 13.9602s/100 iter), loss = 1.7225
I0802 10:15:14.774606 18636 solver.cpp:375]     Train net output #0: loss = 1.46356 (* 1 = 1.46356 loss)
I0802 10:15:14.774613 18636 sgd_solver.cpp:136] Iteration 117200, lr = 0.002675, m = 0.9
I0802 10:15:28.646308 18636 solver.cpp:353] Iteration 117300 (7.20908 iter/s, 13.8714s/100 iter), loss = 1.48062
I0802 10:15:28.646337 18636 solver.cpp:375]     Train net output #0: loss = 1.74852 (* 1 = 1.74852 loss)
I0802 10:15:28.646342 18636 sgd_solver.cpp:136] Iteration 117300, lr = 0.00266875, m = 0.9
I0802 10:15:42.877852 18636 solver.cpp:353] Iteration 117400 (7.02684 iter/s, 14.2312s/100 iter), loss = 1.53866
I0802 10:15:42.877878 18636 solver.cpp:375]     Train net output #0: loss = 1.51422 (* 1 = 1.51422 loss)
I0802 10:15:42.877884 18636 sgd_solver.cpp:136] Iteration 117400, lr = 0.0026625, m = 0.9
I0802 10:15:56.808331 18636 solver.cpp:353] Iteration 117500 (7.1787 iter/s, 13.9301s/100 iter), loss = 1.60402
I0802 10:15:56.808410 18636 solver.cpp:375]     Train net output #0: loss = 1.20729 (* 1 = 1.20729 loss)
I0802 10:15:56.808418 18636 sgd_solver.cpp:136] Iteration 117500, lr = 0.00265625, m = 0.9
I0802 10:16:10.805320 18636 solver.cpp:353] Iteration 117600 (7.14459 iter/s, 13.9966s/100 iter), loss = 1.21281
I0802 10:16:10.805343 18636 solver.cpp:375]     Train net output #0: loss = 1.09235 (* 1 = 1.09235 loss)
I0802 10:16:10.805347 18636 sgd_solver.cpp:136] Iteration 117600, lr = 0.00265, m = 0.9
I0802 10:16:24.966953 18636 solver.cpp:353] Iteration 117700 (7.06153 iter/s, 14.1612s/100 iter), loss = 1.09583
I0802 10:16:24.967047 18636 solver.cpp:375]     Train net output #0: loss = 1.04774 (* 1 = 1.04774 loss)
I0802 10:16:24.967067 18636 sgd_solver.cpp:136] Iteration 117700, lr = 0.00264375, m = 0.9
I0802 10:16:38.959575 18636 solver.cpp:353] Iteration 117800 (7.14682 iter/s, 13.9922s/100 iter), loss = 1.49
I0802 10:16:38.959663 18636 solver.cpp:375]     Train net output #0: loss = 1.46232 (* 1 = 1.46232 loss)
I0802 10:16:38.959676 18636 sgd_solver.cpp:136] Iteration 117800, lr = 0.0026375, m = 0.9
I0802 10:16:52.881922 18636 solver.cpp:353] Iteration 117900 (7.1829 iter/s, 13.922s/100 iter), loss = 1.17485
I0802 10:16:52.881954 18636 solver.cpp:375]     Train net output #0: loss = 1.14365 (* 1 = 1.14365 loss)
I0802 10:16:52.881960 18636 sgd_solver.cpp:136] Iteration 117900, lr = 0.00263125, m = 0.9
I0802 10:17:06.730336 18636 solver.cpp:404] Sparsity after update:
I0802 10:17:06.736109 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:17:06.736155 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:17:06.736173 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:17:06.736181 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:17:06.736189 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:17:06.736197 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:17:06.736204 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:17:06.736212 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:17:06.736222 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:17:06.736232 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:17:06.736241 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:17:06.736250 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:17:06.736258 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:17:06.736276 18636 solver.cpp:550] Iteration 118000, Testing net (#0)
I0802 10:17:26.275025 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.581
I0802 10:17:26.275140 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.811233
I0802 10:17:26.275149 18636 solver.cpp:635]     Test net output #2: loss = 1.82966 (* 1 = 1.82966 loss)
I0802 10:17:26.275173 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5384s
I0802 10:17:26.421171 18636 solver.cpp:353] Iteration 118000 (2.98166 iter/s, 33.5383s/100 iter), loss = 1.45173
I0802 10:17:26.421196 18636 solver.cpp:375]     Train net output #0: loss = 1.53097 (* 1 = 1.53097 loss)
I0802 10:17:26.421201 18636 sgd_solver.cpp:136] Iteration 118000, lr = 0.002625, m = 0.9
I0802 10:17:40.343070 18636 solver.cpp:353] Iteration 118100 (7.18313 iter/s, 13.9215s/100 iter), loss = 1.44201
I0802 10:17:40.343097 18636 solver.cpp:375]     Train net output #0: loss = 1.52047 (* 1 = 1.52047 loss)
I0802 10:17:40.343103 18636 sgd_solver.cpp:136] Iteration 118100, lr = 0.00261875, m = 0.9
I0802 10:17:54.231024 18636 solver.cpp:353] Iteration 118200 (7.20069 iter/s, 13.8876s/100 iter), loss = 1.64977
I0802 10:17:54.231122 18636 solver.cpp:375]     Train net output #0: loss = 1.16506 (* 1 = 1.16506 loss)
I0802 10:17:54.231144 18636 sgd_solver.cpp:136] Iteration 118200, lr = 0.0026125, m = 0.9
I0802 10:18:08.225963 18636 solver.cpp:353] Iteration 118300 (7.14564 iter/s, 13.9945s/100 iter), loss = 1.23777
I0802 10:18:08.226042 18636 solver.cpp:375]     Train net output #0: loss = 1.33069 (* 1 = 1.33069 loss)
I0802 10:18:08.226047 18636 sgd_solver.cpp:136] Iteration 118300, lr = 0.00260625, m = 0.9
I0802 10:18:22.159646 18636 solver.cpp:353] Iteration 118400 (7.17705 iter/s, 13.9333s/100 iter), loss = 1.59327
I0802 10:18:22.159677 18636 solver.cpp:375]     Train net output #0: loss = 1.46228 (* 1 = 1.46228 loss)
I0802 10:18:22.159683 18636 sgd_solver.cpp:136] Iteration 118400, lr = 0.0026, m = 0.9
I0802 10:18:36.106509 18636 solver.cpp:353] Iteration 118500 (7.17027 iter/s, 13.9465s/100 iter), loss = 1.65896
I0802 10:18:36.106537 18636 solver.cpp:375]     Train net output #0: loss = 1.88491 (* 1 = 1.88491 loss)
I0802 10:18:36.106542 18636 sgd_solver.cpp:136] Iteration 118500, lr = 0.00259375, m = 0.9
I0802 10:18:50.062742 18636 solver.cpp:353] Iteration 118600 (7.16546 iter/s, 13.9558s/100 iter), loss = 1.12877
I0802 10:18:50.062826 18636 solver.cpp:375]     Train net output #0: loss = 1.14675 (* 1 = 1.14675 loss)
I0802 10:18:50.062840 18636 sgd_solver.cpp:136] Iteration 118600, lr = 0.0025875, m = 0.9
I0802 10:19:03.978341 18636 solver.cpp:353] Iteration 118700 (7.18638 iter/s, 13.9152s/100 iter), loss = 1.68054
I0802 10:19:03.978369 18636 solver.cpp:375]     Train net output #0: loss = 1.66131 (* 1 = 1.66131 loss)
I0802 10:19:03.978375 18636 sgd_solver.cpp:136] Iteration 118700, lr = 0.00258125, m = 0.9
I0802 10:19:17.980592 18636 solver.cpp:353] Iteration 118800 (7.14191 iter/s, 14.0019s/100 iter), loss = 1.31926
I0802 10:19:17.980620 18636 solver.cpp:375]     Train net output #0: loss = 1.39081 (* 1 = 1.39081 loss)
I0802 10:19:17.980625 18636 sgd_solver.cpp:136] Iteration 118800, lr = 0.002575, m = 0.9
I0802 10:19:31.868602 18636 solver.cpp:353] Iteration 118900 (7.20065 iter/s, 13.8876s/100 iter), loss = 1.2019
I0802 10:19:31.868656 18636 solver.cpp:375]     Train net output #0: loss = 1.15696 (* 1 = 1.15696 loss)
I0802 10:19:31.868664 18636 sgd_solver.cpp:136] Iteration 118900, lr = 0.00256875, m = 0.9
I0802 10:19:45.675964 18636 solver.cpp:404] Sparsity after update:
I0802 10:19:45.686460 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:19:45.686477 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:19:45.686487 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:19:45.686491 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:19:45.686494 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:19:45.686497 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:19:45.686501 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:19:45.686511 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:19:45.686513 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:19:45.686518 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:19:45.686523 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:19:45.686527 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:19:45.686532 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:19:45.817364 18636 solver.cpp:353] Iteration 119000 (7.16929 iter/s, 13.9484s/100 iter), loss = 1.21921
I0802 10:19:45.817392 18636 solver.cpp:375]     Train net output #0: loss = 1.27606 (* 1 = 1.27606 loss)
I0802 10:19:45.817399 18636 sgd_solver.cpp:136] Iteration 119000, lr = 0.0025625, m = 0.9
I0802 10:19:59.843375 18636 solver.cpp:353] Iteration 119100 (7.12981 iter/s, 14.0256s/100 iter), loss = 1.33124
I0802 10:19:59.843405 18636 solver.cpp:375]     Train net output #0: loss = 1.66949 (* 1 = 1.66949 loss)
I0802 10:19:59.843411 18636 sgd_solver.cpp:136] Iteration 119100, lr = 0.00255625, m = 0.9
I0802 10:20:13.938814 18636 solver.cpp:353] Iteration 119200 (7.09469 iter/s, 14.095s/100 iter), loss = 1.07882
I0802 10:20:13.938899 18636 solver.cpp:375]     Train net output #0: loss = 0.845329 (* 1 = 0.845329 loss)
I0802 10:20:13.938906 18636 sgd_solver.cpp:136] Iteration 119200, lr = 0.00255, m = 0.9
I0802 10:20:27.906287 18636 solver.cpp:353] Iteration 119300 (7.15969 iter/s, 13.9671s/100 iter), loss = 1.06553
I0802 10:20:27.906555 18636 solver.cpp:375]     Train net output #0: loss = 1.14193 (* 1 = 1.14193 loss)
I0802 10:20:27.906677 18636 sgd_solver.cpp:136] Iteration 119300, lr = 0.00254375, m = 0.9
I0802 10:20:41.896365 18636 solver.cpp:353] Iteration 119400 (7.14812 iter/s, 13.9897s/100 iter), loss = 1.38762
I0802 10:20:41.896394 18636 solver.cpp:375]     Train net output #0: loss = 1.08779 (* 1 = 1.08779 loss)
I0802 10:20:41.896399 18636 sgd_solver.cpp:136] Iteration 119400, lr = 0.0025375, m = 0.9
I0802 10:20:55.820029 18636 solver.cpp:353] Iteration 119500 (7.18222 iter/s, 13.9233s/100 iter), loss = 1.42313
I0802 10:20:55.820127 18636 solver.cpp:375]     Train net output #0: loss = 0.943013 (* 1 = 0.943013 loss)
I0802 10:20:55.820137 18636 sgd_solver.cpp:136] Iteration 119500, lr = 0.00253125, m = 0.9
I0802 10:21:09.774708 18636 solver.cpp:353] Iteration 119600 (7.16626 iter/s, 13.9543s/100 iter), loss = 1.45692
I0802 10:21:09.774731 18636 solver.cpp:375]     Train net output #0: loss = 1.65854 (* 1 = 1.65854 loss)
I0802 10:21:09.774735 18636 sgd_solver.cpp:136] Iteration 119600, lr = 0.002525, m = 0.9
I0802 10:21:23.687458 18636 solver.cpp:353] Iteration 119700 (7.18785 iter/s, 13.9124s/100 iter), loss = 1.09034
I0802 10:21:23.687487 18636 solver.cpp:375]     Train net output #0: loss = 0.988528 (* 1 = 0.988528 loss)
I0802 10:21:23.687494 18636 sgd_solver.cpp:136] Iteration 119700, lr = 0.00251875, m = 0.9
I0802 10:21:37.681584 18636 solver.cpp:353] Iteration 119800 (7.14605 iter/s, 13.9937s/100 iter), loss = 1.52346
I0802 10:21:37.681666 18636 solver.cpp:375]     Train net output #0: loss = 1.32251 (* 1 = 1.32251 loss)
I0802 10:21:37.681674 18636 sgd_solver.cpp:136] Iteration 119800, lr = 0.0025125, m = 0.9
I0802 10:21:51.838387 18636 solver.cpp:353] Iteration 119900 (7.06394 iter/s, 14.1564s/100 iter), loss = 1.26304
I0802 10:21:51.838414 18636 solver.cpp:375]     Train net output #0: loss = 1.19972 (* 1 = 1.19972 loss)
I0802 10:21:51.838420 18636 sgd_solver.cpp:136] Iteration 119900, lr = 0.00250625, m = 0.9
I0802 10:22:05.583375 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_120000.caffemodel
I0802 10:22:05.637727 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_120000.solverstate
I0802 10:22:05.644142 18636 solver.cpp:404] Sparsity after update:
I0802 10:22:05.648171 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:22:05.648187 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:22:05.648196 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:22:05.648200 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:22:05.648203 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:22:05.648206 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:22:05.648210 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:22:05.648212 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:22:05.648216 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:22:05.648218 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:22:05.648221 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:22:05.648224 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:22:05.648227 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:22:05.648238 18636 solver.cpp:550] Iteration 120000, Testing net (#0)
I0802 10:22:06.212010 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:22:26.146622 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.588353
I0802 10:22:26.146718 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816174
I0802 10:22:26.146728 18636 solver.cpp:635]     Test net output #2: loss = 1.79882 (* 1 = 1.79882 loss)
I0802 10:22:26.146746 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.4979s
I0802 10:22:26.285859 18636 solver.cpp:353] Iteration 120000 (2.90305 iter/s, 34.4465s/100 iter), loss = 1.53001
I0802 10:22:26.285887 18636 solver.cpp:375]     Train net output #0: loss = 1.52381 (* 1 = 1.52381 loss)
I0802 10:22:26.285892 18636 sgd_solver.cpp:136] Iteration 120000, lr = 0.0025, m = 0.9
I0802 10:22:40.444013 18636 solver.cpp:353] Iteration 120100 (7.06326 iter/s, 14.1578s/100 iter), loss = 1.50322
I0802 10:22:40.444042 18636 solver.cpp:375]     Train net output #0: loss = 1.85385 (* 1 = 1.85385 loss)
I0802 10:22:40.444048 18636 sgd_solver.cpp:136] Iteration 120100, lr = 0.00249375, m = 0.9
I0802 10:22:54.430203 18636 solver.cpp:353] Iteration 120200 (7.15011 iter/s, 13.9858s/100 iter), loss = 1.73912
I0802 10:22:54.430232 18636 solver.cpp:375]     Train net output #0: loss = 1.46637 (* 1 = 1.46637 loss)
I0802 10:22:54.430238 18636 sgd_solver.cpp:136] Iteration 120200, lr = 0.0024875, m = 0.9
I0802 10:23:08.341454 18636 solver.cpp:353] Iteration 120300 (7.18863 iter/s, 13.9109s/100 iter), loss = 1.57143
I0802 10:23:08.341542 18636 solver.cpp:375]     Train net output #0: loss = 0.853292 (* 1 = 0.853292 loss)
I0802 10:23:08.341547 18636 sgd_solver.cpp:136] Iteration 120300, lr = 0.00248125, m = 0.9
I0802 10:23:22.193362 18636 solver.cpp:353] Iteration 120400 (7.21942 iter/s, 13.8515s/100 iter), loss = 1.2672
I0802 10:23:22.193387 18636 solver.cpp:375]     Train net output #0: loss = 1.10881 (* 1 = 1.10881 loss)
I0802 10:23:22.193392 18636 sgd_solver.cpp:136] Iteration 120400, lr = 0.002475, m = 0.9
I0802 10:23:36.225322 18636 solver.cpp:353] Iteration 120500 (7.12679 iter/s, 14.0316s/100 iter), loss = 1.64652
I0802 10:23:36.225352 18636 solver.cpp:375]     Train net output #0: loss = 1.34888 (* 1 = 1.34888 loss)
I0802 10:23:36.225358 18636 sgd_solver.cpp:136] Iteration 120500, lr = 0.00246875, m = 0.9
I0802 10:23:50.336848 18636 solver.cpp:353] Iteration 120600 (7.0866 iter/s, 14.1111s/100 iter), loss = 1.14811
I0802 10:23:50.336910 18636 solver.cpp:375]     Train net output #0: loss = 1.13971 (* 1 = 1.13971 loss)
I0802 10:23:50.336916 18636 sgd_solver.cpp:136] Iteration 120600, lr = 0.0024625, m = 0.9
I0802 10:24:04.302829 18636 solver.cpp:353] Iteration 120700 (7.16046 iter/s, 13.9656s/100 iter), loss = 1.04241
I0802 10:24:04.302858 18636 solver.cpp:375]     Train net output #0: loss = 0.688617 (* 1 = 0.688617 loss)
I0802 10:24:04.302865 18636 sgd_solver.cpp:136] Iteration 120700, lr = 0.00245625, m = 0.9
I0802 10:24:18.390738 18636 solver.cpp:353] Iteration 120800 (7.09848 iter/s, 14.0875s/100 iter), loss = 1.70143
I0802 10:24:18.390769 18636 solver.cpp:375]     Train net output #0: loss = 1.68669 (* 1 = 1.68669 loss)
I0802 10:24:18.390774 18636 sgd_solver.cpp:136] Iteration 120800, lr = 0.00245, m = 0.9
I0802 10:24:32.308394 18636 solver.cpp:353] Iteration 120900 (7.18532 iter/s, 13.9173s/100 iter), loss = 1.18431
I0802 10:24:32.308470 18636 solver.cpp:375]     Train net output #0: loss = 1.15101 (* 1 = 1.15101 loss)
I0802 10:24:32.308476 18636 sgd_solver.cpp:136] Iteration 120900, lr = 0.00244375, m = 0.9
I0802 10:24:46.126444 18636 solver.cpp:404] Sparsity after update:
I0802 10:24:46.137917 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:24:46.137930 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:24:46.137939 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:24:46.137943 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:24:46.137956 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:24:46.137965 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:24:46.137974 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:24:46.137982 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:24:46.137991 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:24:46.138000 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:24:46.138008 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:24:46.138021 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:24:46.138027 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:24:46.267364 18636 solver.cpp:353] Iteration 121000 (7.16405 iter/s, 13.9586s/100 iter), loss = 1.30205
I0802 10:24:46.267390 18636 solver.cpp:375]     Train net output #0: loss = 1.03801 (* 1 = 1.03801 loss)
I0802 10:24:46.267395 18636 sgd_solver.cpp:136] Iteration 121000, lr = 0.0024375, m = 0.9
I0802 10:25:00.232249 18636 solver.cpp:353] Iteration 121100 (7.16102 iter/s, 13.9645s/100 iter), loss = 1.41153
I0802 10:25:00.232272 18636 solver.cpp:375]     Train net output #0: loss = 1.40017 (* 1 = 1.40017 loss)
I0802 10:25:00.232276 18636 sgd_solver.cpp:136] Iteration 121100, lr = 0.00243125, m = 0.9
I0802 10:25:14.275840 18636 solver.cpp:353] Iteration 121200 (7.12088 iter/s, 14.0432s/100 iter), loss = 1.72838
I0802 10:25:14.275909 18636 solver.cpp:375]     Train net output #0: loss = 1.53963 (* 1 = 1.53963 loss)
I0802 10:25:14.275914 18636 sgd_solver.cpp:136] Iteration 121200, lr = 0.002425, m = 0.9
I0802 10:25:28.200256 18636 solver.cpp:353] Iteration 121300 (7.18183 iter/s, 13.924s/100 iter), loss = 1.56015
I0802 10:25:28.200286 18636 solver.cpp:375]     Train net output #0: loss = 1.16389 (* 1 = 1.16389 loss)
I0802 10:25:28.200291 18636 sgd_solver.cpp:136] Iteration 121300, lr = 0.00241875, m = 0.9
I0802 10:25:42.171277 18636 solver.cpp:353] Iteration 121400 (7.15787 iter/s, 13.9706s/100 iter), loss = 1.38161
I0802 10:25:42.171304 18636 solver.cpp:375]     Train net output #0: loss = 0.921456 (* 1 = 0.921456 loss)
I0802 10:25:42.171309 18636 sgd_solver.cpp:136] Iteration 121400, lr = 0.0024125, m = 0.9
I0802 10:25:56.272372 18636 solver.cpp:353] Iteration 121500 (7.09185 iter/s, 14.1007s/100 iter), loss = 1.4821
I0802 10:25:56.276852 18636 solver.cpp:375]     Train net output #0: loss = 1.45402 (* 1 = 1.45402 loss)
I0802 10:25:56.276875 18636 sgd_solver.cpp:136] Iteration 121500, lr = 0.00240625, m = 0.9
I0802 10:26:10.303227 18636 solver.cpp:353] Iteration 121600 (7.12735 iter/s, 14.0305s/100 iter), loss = 1.55965
I0802 10:26:10.303267 18636 solver.cpp:375]     Train net output #0: loss = 1.42389 (* 1 = 1.42389 loss)
I0802 10:26:10.303275 18636 sgd_solver.cpp:136] Iteration 121600, lr = 0.0024, m = 0.9
I0802 10:26:24.324072 18636 solver.cpp:353] Iteration 121700 (7.13243 iter/s, 14.0205s/100 iter), loss = 1.40915
I0802 10:26:24.324102 18636 solver.cpp:375]     Train net output #0: loss = 1.43191 (* 1 = 1.43191 loss)
I0802 10:26:24.324108 18636 sgd_solver.cpp:136] Iteration 121700, lr = 0.00239375, m = 0.9
I0802 10:26:38.448526 18636 solver.cpp:353] Iteration 121800 (7.08012 iter/s, 14.1241s/100 iter), loss = 1.36707
I0802 10:26:38.448606 18636 solver.cpp:375]     Train net output #0: loss = 1.43998 (* 1 = 1.43998 loss)
I0802 10:26:38.448612 18636 sgd_solver.cpp:136] Iteration 121800, lr = 0.0023875, m = 0.9
I0802 10:26:52.481994 18636 solver.cpp:353] Iteration 121900 (7.12602 iter/s, 14.0331s/100 iter), loss = 1.64323
I0802 10:26:52.482023 18636 solver.cpp:375]     Train net output #0: loss = 1.60681 (* 1 = 1.60681 loss)
I0802 10:26:52.482029 18636 sgd_solver.cpp:136] Iteration 121900, lr = 0.00238125, m = 0.9
I0802 10:27:06.394404 18636 solver.cpp:404] Sparsity after update:
I0802 10:27:06.398707 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:27:06.398720 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:27:06.398855 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:27:06.398900 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:27:06.398939 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:27:06.398982 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:27:06.399022 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:27:06.399062 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:27:06.399103 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:27:06.399143 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:27:06.399184 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:27:06.399224 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:27:06.399265 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:27:06.399281 18636 solver.cpp:550] Iteration 122000, Testing net (#0)
I0802 10:27:25.634285 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.585529
I0802 10:27:25.634410 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.810644
I0802 10:27:25.634419 18636 solver.cpp:635]     Test net output #2: loss = 1.82079 (* 1 = 1.82079 loss)
I0802 10:27:25.634438 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.2346s
I0802 10:27:25.772424 18636 solver.cpp:353] Iteration 122000 (3.00395 iter/s, 33.2895s/100 iter), loss = 1.28656
I0802 10:27:25.772476 18636 solver.cpp:375]     Train net output #0: loss = 1.17683 (* 1 = 1.17683 loss)
I0802 10:27:25.772488 18636 sgd_solver.cpp:136] Iteration 122000, lr = 0.002375, m = 0.9
I0802 10:27:39.830593 18636 solver.cpp:353] Iteration 122100 (7.1135 iter/s, 14.0578s/100 iter), loss = 1.39148
I0802 10:27:39.830622 18636 solver.cpp:375]     Train net output #0: loss = 1.37227 (* 1 = 1.37227 loss)
I0802 10:27:39.830628 18636 sgd_solver.cpp:136] Iteration 122100, lr = 0.00236875, m = 0.9
I0802 10:27:53.869428 18636 solver.cpp:353] Iteration 122200 (7.1233 iter/s, 14.0384s/100 iter), loss = 1.21639
I0802 10:27:53.869457 18636 solver.cpp:375]     Train net output #0: loss = 1.20847 (* 1 = 1.20847 loss)
I0802 10:27:53.869463 18636 sgd_solver.cpp:136] Iteration 122200, lr = 0.0023625, m = 0.9
I0802 10:28:07.882468 18636 solver.cpp:353] Iteration 122300 (7.13641 iter/s, 14.0126s/100 iter), loss = 1.42819
I0802 10:28:07.882542 18636 solver.cpp:375]     Train net output #0: loss = 1.38671 (* 1 = 1.38671 loss)
I0802 10:28:07.882550 18636 sgd_solver.cpp:136] Iteration 122300, lr = 0.00235625, m = 0.9
I0802 10:28:22.048732 18636 solver.cpp:353] Iteration 122400 (7.05922 iter/s, 14.1659s/100 iter), loss = 1.21884
I0802 10:28:22.048836 18636 solver.cpp:375]     Train net output #0: loss = 1.33957 (* 1 = 1.33957 loss)
I0802 10:28:22.048847 18636 sgd_solver.cpp:136] Iteration 122400, lr = 0.00235, m = 0.9
I0802 10:28:36.098235 18636 solver.cpp:353] Iteration 122500 (7.11789 iter/s, 14.0491s/100 iter), loss = 1.30233
I0802 10:28:36.098258 18636 solver.cpp:375]     Train net output #0: loss = 1.22268 (* 1 = 1.22268 loss)
I0802 10:28:36.098263 18636 sgd_solver.cpp:136] Iteration 122500, lr = 0.00234375, m = 0.9
I0802 10:28:50.216099 18636 solver.cpp:353] Iteration 122600 (7.08342 iter/s, 14.1175s/100 iter), loss = 1.46555
I0802 10:28:50.216159 18636 solver.cpp:375]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I0802 10:28:50.216166 18636 sgd_solver.cpp:136] Iteration 122600, lr = 0.0023375, m = 0.9
I0802 10:29:04.175253 18636 solver.cpp:353] Iteration 122700 (7.16396 iter/s, 13.9588s/100 iter), loss = 1.48203
I0802 10:29:04.175282 18636 solver.cpp:375]     Train net output #0: loss = 1.64611 (* 1 = 1.64611 loss)
I0802 10:29:04.175285 18636 sgd_solver.cpp:136] Iteration 122700, lr = 0.00233125, m = 0.9
I0802 10:29:18.254364 18636 solver.cpp:353] Iteration 122800 (7.10292 iter/s, 14.0787s/100 iter), loss = 1.62132
I0802 10:29:18.254391 18636 solver.cpp:375]     Train net output #0: loss = 1.39254 (* 1 = 1.39254 loss)
I0802 10:29:18.254397 18636 sgd_solver.cpp:136] Iteration 122800, lr = 0.002325, m = 0.9
I0802 10:29:32.232586 18636 solver.cpp:353] Iteration 122900 (7.15418 iter/s, 13.9778s/100 iter), loss = 1.43189
I0802 10:29:32.232653 18636 solver.cpp:375]     Train net output #0: loss = 1.72661 (* 1 = 1.72661 loss)
I0802 10:29:32.232661 18636 sgd_solver.cpp:136] Iteration 122900, lr = 0.00231875, m = 0.9
I0802 10:29:46.085816 18636 solver.cpp:404] Sparsity after update:
I0802 10:29:46.097561 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:29:46.097579 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:29:46.097586 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:29:46.097590 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:29:46.097594 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:29:46.097597 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:29:46.097600 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:29:46.097604 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:29:46.097606 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:29:46.097609 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:29:46.097612 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:29:46.097616 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:29:46.097620 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:29:46.226452 18636 solver.cpp:353] Iteration 123000 (7.14619 iter/s, 13.9935s/100 iter), loss = 1.49119
I0802 10:29:46.226481 18636 solver.cpp:375]     Train net output #0: loss = 1.45813 (* 1 = 1.45813 loss)
I0802 10:29:46.226487 18636 sgd_solver.cpp:136] Iteration 123000, lr = 0.0023125, m = 0.9
I0802 10:30:00.266937 18636 solver.cpp:353] Iteration 123100 (7.12246 iter/s, 14.0401s/100 iter), loss = 1.32709
I0802 10:30:00.266961 18636 solver.cpp:375]     Train net output #0: loss = 1.72187 (* 1 = 1.72187 loss)
I0802 10:30:00.266968 18636 sgd_solver.cpp:136] Iteration 123100, lr = 0.00230625, m = 0.9
I0802 10:30:14.621865 18636 solver.cpp:353] Iteration 123200 (6.96644 iter/s, 14.3545s/100 iter), loss = 1.59676
I0802 10:30:14.621942 18636 solver.cpp:375]     Train net output #0: loss = 1.39444 (* 1 = 1.39444 loss)
I0802 10:30:14.621948 18636 sgd_solver.cpp:136] Iteration 123200, lr = 0.0023, m = 0.9
I0802 10:30:28.610344 18636 solver.cpp:353] Iteration 123300 (7.14894 iter/s, 13.9881s/100 iter), loss = 1.55918
I0802 10:30:28.610374 18636 solver.cpp:375]     Train net output #0: loss = 1.23413 (* 1 = 1.23413 loss)
I0802 10:30:28.610380 18636 sgd_solver.cpp:136] Iteration 123300, lr = 0.00229375, m = 0.9
I0802 10:30:42.548075 18636 solver.cpp:353] Iteration 123400 (7.17497 iter/s, 13.9373s/100 iter), loss = 1.41108
I0802 10:30:42.548104 18636 solver.cpp:375]     Train net output #0: loss = 1.50678 (* 1 = 1.50678 loss)
I0802 10:30:42.548108 18636 sgd_solver.cpp:136] Iteration 123400, lr = 0.0022875, m = 0.9
I0802 10:30:56.449455 18636 solver.cpp:353] Iteration 123500 (7.19373 iter/s, 13.901s/100 iter), loss = 1.21396
I0802 10:30:56.449530 18636 solver.cpp:375]     Train net output #0: loss = 1.02108 (* 1 = 1.02108 loss)
I0802 10:30:56.449537 18636 sgd_solver.cpp:136] Iteration 123500, lr = 0.00228125, m = 0.9
I0802 10:31:10.353868 18636 solver.cpp:353] Iteration 123600 (7.19216 iter/s, 13.904s/100 iter), loss = 1.37475
I0802 10:31:10.353899 18636 solver.cpp:375]     Train net output #0: loss = 1.4133 (* 1 = 1.4133 loss)
I0802 10:31:10.353904 18636 sgd_solver.cpp:136] Iteration 123600, lr = 0.002275, m = 0.9
I0802 10:31:24.194486 18636 solver.cpp:353] Iteration 123700 (7.22531 iter/s, 13.8402s/100 iter), loss = 1.54896
I0802 10:31:24.194512 18636 solver.cpp:375]     Train net output #0: loss = 1.69741 (* 1 = 1.69741 loss)
I0802 10:31:24.194517 18636 sgd_solver.cpp:136] Iteration 123700, lr = 0.00226875, m = 0.9
I0802 10:31:38.192493 18636 solver.cpp:353] Iteration 123800 (7.14407 iter/s, 13.9976s/100 iter), loss = 1.10141
I0802 10:31:38.192576 18636 solver.cpp:375]     Train net output #0: loss = 1.31106 (* 1 = 1.31106 loss)
I0802 10:31:38.192584 18636 sgd_solver.cpp:136] Iteration 123800, lr = 0.0022625, m = 0.9
I0802 10:31:52.087831 18636 solver.cpp:353] Iteration 123900 (7.19686 iter/s, 13.8949s/100 iter), loss = 1.56661
I0802 10:31:52.087863 18636 solver.cpp:375]     Train net output #0: loss = 1.74073 (* 1 = 1.74073 loss)
I0802 10:31:52.087869 18636 sgd_solver.cpp:136] Iteration 123900, lr = 0.00225625, m = 0.9
I0802 10:32:06.010910 18636 solver.cpp:404] Sparsity after update:
I0802 10:32:06.016975 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:32:06.016989 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:32:06.016999 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:32:06.017004 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:32:06.017071 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:32:06.017077 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:32:06.017081 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:32:06.017084 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:32:06.017087 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:32:06.017091 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:32:06.017093 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:32:06.017097 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:32:06.017101 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:32:06.017112 18636 solver.cpp:550] Iteration 124000, Testing net (#0)
I0802 10:32:25.209769 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.58747
I0802 10:32:25.209904 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.816879
I0802 10:32:25.209913 18636 solver.cpp:635]     Test net output #2: loss = 1.80071 (* 1 = 1.80071 loss)
I0802 10:32:25.209935 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.1923s
I0802 10:32:25.349867 18636 solver.cpp:353] Iteration 124000 (3.00651 iter/s, 33.2611s/100 iter), loss = 1.53339
I0802 10:32:25.349896 18636 solver.cpp:375]     Train net output #0: loss = 1.42815 (* 1 = 1.42815 loss)
I0802 10:32:25.349902 18636 sgd_solver.cpp:136] Iteration 124000, lr = 0.00225, m = 0.9
I0802 10:32:39.252344 18636 solver.cpp:353] Iteration 124100 (7.19316 iter/s, 13.9021s/100 iter), loss = 1.39585
I0802 10:32:39.252372 18636 solver.cpp:375]     Train net output #0: loss = 1.27577 (* 1 = 1.27577 loss)
I0802 10:32:39.252378 18636 sgd_solver.cpp:136] Iteration 124100, lr = 0.00224375, m = 0.9
I0802 10:32:53.284677 18636 solver.cpp:353] Iteration 124200 (7.1266 iter/s, 14.0319s/100 iter), loss = 1.52668
I0802 10:32:53.284771 18636 solver.cpp:375]     Train net output #0: loss = 1.14951 (* 1 = 1.14951 loss)
I0802 10:32:53.284791 18636 sgd_solver.cpp:136] Iteration 124200, lr = 0.0022375, m = 0.9
I0802 10:33:07.197041 18636 solver.cpp:353] Iteration 124300 (7.18805 iter/s, 13.912s/100 iter), loss = 1.25
I0802 10:33:07.197103 18636 solver.cpp:375]     Train net output #0: loss = 1.36511 (* 1 = 1.36511 loss)
I0802 10:33:07.197110 18636 sgd_solver.cpp:136] Iteration 124300, lr = 0.00223125, m = 0.9
I0802 10:33:21.067073 18636 solver.cpp:353] Iteration 124400 (7.20999 iter/s, 13.8696s/100 iter), loss = 1.3178
I0802 10:33:21.067108 18636 solver.cpp:375]     Train net output #0: loss = 1.58009 (* 1 = 1.58009 loss)
I0802 10:33:21.067114 18636 sgd_solver.cpp:136] Iteration 124400, lr = 0.002225, m = 0.9
I0802 10:33:34.973579 18636 solver.cpp:353] Iteration 124500 (7.19108 iter/s, 13.9061s/100 iter), loss = 1.49912
I0802 10:33:34.973634 18636 solver.cpp:375]     Train net output #0: loss = 1.37536 (* 1 = 1.37536 loss)
I0802 10:33:34.973646 18636 sgd_solver.cpp:136] Iteration 124500, lr = 0.00221875, m = 0.9
I0802 10:33:48.926632 18636 solver.cpp:353] Iteration 124600 (7.16709 iter/s, 13.9527s/100 iter), loss = 1.36149
I0802 10:33:48.926705 18636 solver.cpp:375]     Train net output #0: loss = 1.34846 (* 1 = 1.34846 loss)
I0802 10:33:48.926712 18636 sgd_solver.cpp:136] Iteration 124600, lr = 0.0022125, m = 0.9
I0802 10:34:02.846715 18636 solver.cpp:353] Iteration 124700 (7.18406 iter/s, 13.9197s/100 iter), loss = 1.38187
I0802 10:34:02.846745 18636 solver.cpp:375]     Train net output #0: loss = 1.22883 (* 1 = 1.22883 loss)
I0802 10:34:02.846750 18636 sgd_solver.cpp:136] Iteration 124700, lr = 0.00220625, m = 0.9
I0802 10:34:16.934561 18636 solver.cpp:353] Iteration 124800 (7.09852 iter/s, 14.0875s/100 iter), loss = 1.28286
I0802 10:34:16.934658 18636 solver.cpp:375]     Train net output #0: loss = 1.0544 (* 1 = 1.0544 loss)
I0802 10:34:16.934679 18636 sgd_solver.cpp:136] Iteration 124800, lr = 0.0022, m = 0.9
I0802 10:34:31.009464 18636 solver.cpp:353] Iteration 124900 (7.10504 iter/s, 14.0745s/100 iter), loss = 1.40133
I0802 10:34:31.009569 18636 solver.cpp:375]     Train net output #0: loss = 1.39136 (* 1 = 1.39136 loss)
I0802 10:34:31.009578 18636 sgd_solver.cpp:136] Iteration 124900, lr = 0.00219375, m = 0.9
I0802 10:34:44.811422 18636 solver.cpp:404] Sparsity after update:
I0802 10:34:44.822659 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:34:44.822718 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:34:44.822739 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:34:44.822751 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:34:44.822759 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:34:44.822768 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:34:44.822777 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:34:44.822785 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:34:44.822793 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:34:44.822803 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:34:44.822811 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:34:44.822819 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:34:44.822827 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:34:44.952342 18636 solver.cpp:353] Iteration 125000 (7.17232 iter/s, 13.9425s/100 iter), loss = 1.6776
I0802 10:34:44.952373 18636 solver.cpp:375]     Train net output #0: loss = 1.30366 (* 1 = 1.30366 loss)
I0802 10:34:44.952380 18636 sgd_solver.cpp:136] Iteration 125000, lr = 0.0021875, m = 0.9
I0802 10:34:58.987972 18636 solver.cpp:353] Iteration 125100 (7.12492 iter/s, 14.0352s/100 iter), loss = 1.37337
I0802 10:34:58.987999 18636 solver.cpp:375]     Train net output #0: loss = 1.268 (* 1 = 1.268 loss)
I0802 10:34:58.988006 18636 sgd_solver.cpp:136] Iteration 125100, lr = 0.00218125, m = 0.9
I0802 10:35:12.812402 18636 solver.cpp:353] Iteration 125200 (7.23377 iter/s, 13.824s/100 iter), loss = 0.922937
I0802 10:35:12.812516 18636 solver.cpp:375]     Train net output #0: loss = 0.970998 (* 1 = 0.970998 loss)
I0802 10:35:12.812527 18636 sgd_solver.cpp:136] Iteration 125200, lr = 0.002175, m = 0.9
I0802 10:35:26.966352 18636 solver.cpp:353] Iteration 125300 (7.06536 iter/s, 14.1536s/100 iter), loss = 1.65907
I0802 10:35:26.966406 18636 solver.cpp:375]     Train net output #0: loss = 1.47654 (* 1 = 1.47654 loss)
I0802 10:35:26.966418 18636 sgd_solver.cpp:136] Iteration 125300, lr = 0.00216875, m = 0.9
I0802 10:35:40.866487 18636 solver.cpp:353] Iteration 125400 (7.19437 iter/s, 13.8997s/100 iter), loss = 1.53847
I0802 10:35:40.866511 18636 solver.cpp:375]     Train net output #0: loss = 1.44464 (* 1 = 1.44464 loss)
I0802 10:35:40.866518 18636 sgd_solver.cpp:136] Iteration 125400, lr = 0.0021625, m = 0.9
I0802 10:35:54.755765 18636 solver.cpp:353] Iteration 125500 (7.2 iter/s, 13.8889s/100 iter), loss = 1.55569
I0802 10:35:54.755822 18636 solver.cpp:375]     Train net output #0: loss = 1.36267 (* 1 = 1.36267 loss)
I0802 10:35:54.755828 18636 sgd_solver.cpp:136] Iteration 125500, lr = 0.00215625, m = 0.9
I0802 10:36:08.673485 18636 solver.cpp:353] Iteration 125600 (7.18528 iter/s, 13.9173s/100 iter), loss = 1.79303
I0802 10:36:08.673509 18636 solver.cpp:375]     Train net output #0: loss = 2.07458 (* 1 = 2.07458 loss)
I0802 10:36:08.673513 18636 sgd_solver.cpp:136] Iteration 125600, lr = 0.00215, m = 0.9
I0802 10:36:22.565158 18636 solver.cpp:353] Iteration 125700 (7.19876 iter/s, 13.8913s/100 iter), loss = 1.44903
I0802 10:36:22.565186 18636 solver.cpp:375]     Train net output #0: loss = 1.50722 (* 1 = 1.50722 loss)
I0802 10:36:22.565192 18636 sgd_solver.cpp:136] Iteration 125700, lr = 0.00214375, m = 0.9
I0802 10:36:36.542999 18636 solver.cpp:353] Iteration 125800 (7.15438 iter/s, 13.9775s/100 iter), loss = 1.30065
I0802 10:36:36.543066 18636 solver.cpp:375]     Train net output #0: loss = 1.45253 (* 1 = 1.45253 loss)
I0802 10:36:36.543073 18636 sgd_solver.cpp:136] Iteration 125800, lr = 0.0021375, m = 0.9
I0802 10:36:50.610205 18636 solver.cpp:353] Iteration 125900 (7.10893 iter/s, 14.0668s/100 iter), loss = 1.37642
I0802 10:36:50.610231 18636 solver.cpp:375]     Train net output #0: loss = 1.4357 (* 1 = 1.4357 loss)
I0802 10:36:50.610235 18636 sgd_solver.cpp:136] Iteration 125900, lr = 0.00213125, m = 0.9
I0802 10:37:04.402117 18636 solver.cpp:404] Sparsity after update:
I0802 10:37:04.406569 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:37:04.406584 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:37:04.406590 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:37:04.406594 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:37:04.406597 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:37:04.406600 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:37:04.406605 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:37:04.406607 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:37:04.406610 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:37:04.406613 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:37:04.406616 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:37:04.406620 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:37:04.406623 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:37:04.406633 18636 solver.cpp:550] Iteration 126000, Testing net (#0)
I0802 10:37:08.091444 18638 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:37:24.099871 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.585823
I0802 10:37:24.099891 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.815056
I0802 10:37:24.099898 18636 solver.cpp:635]     Test net output #2: loss = 1.81104 (* 1 = 1.81104 loss)
I0802 10:37:24.099936 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.6928s
I0802 10:37:24.261355 18636 solver.cpp:353] Iteration 126000 (2.97175 iter/s, 33.6502s/100 iter), loss = 1.7184
I0802 10:37:24.261381 18636 solver.cpp:375]     Train net output #0: loss = 1.6471 (* 1 = 1.6471 loss)
I0802 10:37:24.261386 18636 sgd_solver.cpp:136] Iteration 126000, lr = 0.002125, m = 0.9
I0802 10:37:38.251597 18636 solver.cpp:353] Iteration 126100 (7.14804 iter/s, 13.9898s/100 iter), loss = 1.26601
I0802 10:37:38.251664 18636 solver.cpp:375]     Train net output #0: loss = 1.16532 (* 1 = 1.16532 loss)
I0802 10:37:38.251672 18636 sgd_solver.cpp:136] Iteration 126100, lr = 0.00211875, m = 0.9
I0802 10:37:52.253252 18636 solver.cpp:353] Iteration 126200 (7.14221 iter/s, 14.0013s/100 iter), loss = 1.54688
I0802 10:37:52.253278 18636 solver.cpp:375]     Train net output #0: loss = 1.61398 (* 1 = 1.61398 loss)
I0802 10:37:52.253284 18636 sgd_solver.cpp:136] Iteration 126200, lr = 0.0021125, m = 0.9
I0802 10:38:06.199187 18636 solver.cpp:353] Iteration 126300 (7.17075 iter/s, 13.9455s/100 iter), loss = 1.50402
I0802 10:38:06.199215 18636 solver.cpp:375]     Train net output #0: loss = 1.89781 (* 1 = 1.89781 loss)
I0802 10:38:06.199221 18636 sgd_solver.cpp:136] Iteration 126300, lr = 0.00210625, m = 0.9
I0802 10:38:20.063993 18636 solver.cpp:353] Iteration 126400 (7.21271 iter/s, 13.8644s/100 iter), loss = 1.19733
I0802 10:38:20.064137 18636 solver.cpp:375]     Train net output #0: loss = 0.955924 (* 1 = 0.955924 loss)
I0802 10:38:20.064160 18636 sgd_solver.cpp:136] Iteration 126400, lr = 0.0021, m = 0.9
I0802 10:38:34.001648 18636 solver.cpp:353] Iteration 126500 (7.17501 iter/s, 13.9373s/100 iter), loss = 1.76423
I0802 10:38:34.001888 18636 solver.cpp:375]     Train net output #0: loss = 1.6883 (* 1 = 1.6883 loss)
I0802 10:38:34.002009 18636 sgd_solver.cpp:136] Iteration 126500, lr = 0.00209375, m = 0.9
I0802 10:38:47.902889 18636 solver.cpp:353] Iteration 126600 (7.1938 iter/s, 13.9009s/100 iter), loss = 1.4839
I0802 10:38:47.902915 18636 solver.cpp:375]     Train net output #0: loss = 1.32126 (* 1 = 1.32126 loss)
I0802 10:38:47.902920 18636 sgd_solver.cpp:136] Iteration 126600, lr = 0.0020875, m = 0.9
I0802 10:39:01.871222 18636 solver.cpp:353] Iteration 126700 (7.15925 iter/s, 13.9679s/100 iter), loss = 1.29294
I0802 10:39:01.871328 18636 solver.cpp:375]     Train net output #0: loss = 1.37428 (* 1 = 1.37428 loss)
I0802 10:39:01.871335 18636 sgd_solver.cpp:136] Iteration 126700, lr = 0.00208125, m = 0.9
I0802 10:39:15.833292 18636 solver.cpp:353] Iteration 126800 (7.16246 iter/s, 13.9617s/100 iter), loss = 1.13902
I0802 10:39:15.833410 18636 solver.cpp:375]     Train net output #0: loss = 1.36856 (* 1 = 1.36856 loss)
I0802 10:39:15.833432 18636 sgd_solver.cpp:136] Iteration 126800, lr = 0.002075, m = 0.9
I0802 10:39:29.897500 18636 solver.cpp:353] Iteration 126900 (7.11045 iter/s, 14.0638s/100 iter), loss = 1.1546
I0802 10:39:29.897555 18636 solver.cpp:375]     Train net output #0: loss = 1.13853 (* 1 = 1.13853 loss)
I0802 10:39:29.897568 18636 sgd_solver.cpp:136] Iteration 126900, lr = 0.00206875, m = 0.9
I0802 10:39:43.725003 18636 solver.cpp:404] Sparsity after update:
I0802 10:39:43.736534 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:39:43.736549 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:39:43.736558 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:39:43.736562 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:39:43.736573 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:39:43.736582 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:39:43.736591 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:39:43.736600 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:39:43.736609 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:39:43.736618 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:39:43.736626 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:39:43.736639 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:39:43.736647 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:39:43.865221 18636 solver.cpp:353] Iteration 127000 (7.15956 iter/s, 13.9673s/100 iter), loss = 1.32047
I0802 10:39:43.865309 18636 solver.cpp:375]     Train net output #0: loss = 1.56258 (* 1 = 1.56258 loss)
I0802 10:39:43.865329 18636 sgd_solver.cpp:136] Iteration 127000, lr = 0.0020625, m = 0.9
I0802 10:39:57.804968 18636 solver.cpp:353] Iteration 127100 (7.17393 iter/s, 13.9394s/100 iter), loss = 1.37623
I0802 10:39:57.804994 18636 solver.cpp:375]     Train net output #0: loss = 1.5418 (* 1 = 1.5418 loss)
I0802 10:39:57.804999 18636 sgd_solver.cpp:136] Iteration 127100, lr = 0.00205625, m = 0.9
I0802 10:40:11.876392 18636 solver.cpp:353] Iteration 127200 (7.1068 iter/s, 14.071s/100 iter), loss = 1.14033
I0802 10:40:11.876420 18636 solver.cpp:375]     Train net output #0: loss = 1.14445 (* 1 = 1.14445 loss)
I0802 10:40:11.876425 18636 sgd_solver.cpp:136] Iteration 127200, lr = 0.00205, m = 0.9
I0802 10:40:25.795935 18636 solver.cpp:353] Iteration 127300 (7.18434 iter/s, 13.9192s/100 iter), loss = 1.36284
I0802 10:40:25.796000 18636 solver.cpp:375]     Train net output #0: loss = 1.38816 (* 1 = 1.38816 loss)
I0802 10:40:25.796007 18636 sgd_solver.cpp:136] Iteration 127300, lr = 0.00204375, m = 0.9
I0802 10:40:39.758096 18636 solver.cpp:353] Iteration 127400 (7.16241 iter/s, 13.9618s/100 iter), loss = 1.29579
I0802 10:40:39.758123 18636 solver.cpp:375]     Train net output #0: loss = 1.4781 (* 1 = 1.4781 loss)
I0802 10:40:39.758129 18636 sgd_solver.cpp:136] Iteration 127400, lr = 0.0020375, m = 0.9
I0802 10:40:53.801403 18636 solver.cpp:353] Iteration 127500 (7.12103 iter/s, 14.0429s/100 iter), loss = 1.47354
I0802 10:40:53.801434 18636 solver.cpp:375]     Train net output #0: loss = 1.52387 (* 1 = 1.52387 loss)
I0802 10:40:53.801440 18636 sgd_solver.cpp:136] Iteration 127500, lr = 0.00203125, m = 0.9
I0802 10:41:08.015792 18636 solver.cpp:353] Iteration 127600 (7.03532 iter/s, 14.214s/100 iter), loss = 1.32305
I0802 10:41:08.015862 18636 solver.cpp:375]     Train net output #0: loss = 1.61213 (* 1 = 1.61213 loss)
I0802 10:41:08.015918 18636 sgd_solver.cpp:136] Iteration 127600, lr = 0.002025, m = 0.9
I0802 10:41:21.961410 18636 solver.cpp:353] Iteration 127700 (7.17091 iter/s, 13.9452s/100 iter), loss = 1.39618
I0802 10:41:21.961442 18636 solver.cpp:375]     Train net output #0: loss = 1.77732 (* 1 = 1.77732 loss)
I0802 10:41:21.961449 18636 sgd_solver.cpp:136] Iteration 127700, lr = 0.00201875, m = 0.9
I0802 10:41:36.063915 18636 solver.cpp:353] Iteration 127800 (7.09113 iter/s, 14.1021s/100 iter), loss = 1.48899
I0802 10:41:36.063948 18636 solver.cpp:375]     Train net output #0: loss = 1.41362 (* 1 = 1.41362 loss)
I0802 10:41:36.063954 18636 sgd_solver.cpp:136] Iteration 127800, lr = 0.0020125, m = 0.9
I0802 10:41:50.111706 18636 solver.cpp:353] Iteration 127900 (7.11875 iter/s, 14.0474s/100 iter), loss = 1.26211
I0802 10:41:50.111822 18636 solver.cpp:375]     Train net output #0: loss = 1.17691 (* 1 = 1.17691 loss)
I0802 10:41:50.111840 18636 sgd_solver.cpp:136] Iteration 127900, lr = 0.00200625, m = 0.9
I0802 10:42:03.974838 18636 solver.cpp:404] Sparsity after update:
I0802 10:42:03.979104 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:42:03.979147 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:42:03.979166 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:42:03.979179 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:42:03.979192 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:42:03.979212 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:42:03.979235 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:42:03.979249 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:42:03.979261 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:42:03.979276 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:42:03.979290 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:42:03.979307 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:42:03.979321 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:42:03.979342 18636 solver.cpp:550] Iteration 128000, Testing net (#0)
I0802 10:42:23.996559 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.584823
I0802 10:42:23.996618 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.815997
I0802 10:42:23.996625 18636 solver.cpp:635]     Test net output #2: loss = 1.79809 (* 1 = 1.79809 loss)
I0802 10:42:23.996644 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0168s
I0802 10:42:24.140820 18636 solver.cpp:353] Iteration 128000 (2.93874 iter/s, 34.0282s/100 iter), loss = 1.22393
I0802 10:42:24.140846 18636 solver.cpp:375]     Train net output #0: loss = 1.30582 (* 1 = 1.30582 loss)
I0802 10:42:24.140851 18636 sgd_solver.cpp:136] Iteration 128000, lr = 0.002, m = 0.9
I0802 10:42:38.227772 18636 solver.cpp:353] Iteration 128100 (7.09896 iter/s, 14.0866s/100 iter), loss = 1.13438
I0802 10:42:38.227799 18636 solver.cpp:375]     Train net output #0: loss = 0.906485 (* 1 = 0.906485 loss)
I0802 10:42:38.227804 18636 sgd_solver.cpp:136] Iteration 128100, lr = 0.00199375, m = 0.9
I0802 10:42:52.226603 18636 solver.cpp:353] Iteration 128200 (7.14365 iter/s, 13.9984s/100 iter), loss = 1.13099
I0802 10:42:52.226629 18636 solver.cpp:375]     Train net output #0: loss = 0.845308 (* 1 = 0.845308 loss)
I0802 10:42:52.226634 18636 sgd_solver.cpp:136] Iteration 128200, lr = 0.0019875, m = 0.9
I0802 10:43:06.366298 18636 solver.cpp:353] Iteration 128300 (7.07249 iter/s, 14.1393s/100 iter), loss = 1.23407
I0802 10:43:06.366443 18636 solver.cpp:375]     Train net output #0: loss = 1.23084 (* 1 = 1.23084 loss)
I0802 10:43:06.366467 18636 sgd_solver.cpp:136] Iteration 128300, lr = 0.00198125, m = 0.9
I0802 10:43:20.296720 18636 solver.cpp:353] Iteration 128400 (7.17873 iter/s, 13.93s/100 iter), loss = 1.37139
I0802 10:43:20.296748 18636 solver.cpp:375]     Train net output #0: loss = 1.58417 (* 1 = 1.58417 loss)
I0802 10:43:20.296754 18636 sgd_solver.cpp:136] Iteration 128400, lr = 0.001975, m = 0.9
I0802 10:43:34.233956 18636 solver.cpp:353] Iteration 128500 (7.17522 iter/s, 13.9368s/100 iter), loss = 1.47294
I0802 10:43:34.234056 18636 solver.cpp:375]     Train net output #0: loss = 1.38609 (* 1 = 1.38609 loss)
I0802 10:43:34.234064 18636 sgd_solver.cpp:136] Iteration 128500, lr = 0.00196875, m = 0.9
I0802 10:43:48.217932 18636 solver.cpp:353] Iteration 128600 (7.15124 iter/s, 13.9836s/100 iter), loss = 1.22176
I0802 10:43:48.218017 18636 solver.cpp:375]     Train net output #0: loss = 1.00287 (* 1 = 1.00287 loss)
I0802 10:43:48.218024 18636 sgd_solver.cpp:136] Iteration 128600, lr = 0.0019625, m = 0.9
I0802 10:44:02.443891 18636 solver.cpp:353] Iteration 128700 (7.0296 iter/s, 14.2256s/100 iter), loss = 1.17207
I0802 10:44:02.443923 18636 solver.cpp:375]     Train net output #0: loss = 0.973115 (* 1 = 0.973115 loss)
I0802 10:44:02.443929 18636 sgd_solver.cpp:136] Iteration 128700, lr = 0.00195625, m = 0.9
I0802 10:44:16.415683 18636 solver.cpp:353] Iteration 128800 (7.15747 iter/s, 13.9714s/100 iter), loss = 1.33028
I0802 10:44:16.415710 18636 solver.cpp:375]     Train net output #0: loss = 1.37935 (* 1 = 1.37935 loss)
I0802 10:44:16.415716 18636 sgd_solver.cpp:136] Iteration 128800, lr = 0.00195, m = 0.9
I0802 10:44:30.392012 18636 solver.cpp:353] Iteration 128900 (7.15515 iter/s, 13.9759s/100 iter), loss = 1.62931
I0802 10:44:30.392855 18636 solver.cpp:375]     Train net output #0: loss = 1.68193 (* 1 = 1.68193 loss)
I0802 10:44:30.392864 18636 sgd_solver.cpp:136] Iteration 128900, lr = 0.00194375, m = 0.9
I0802 10:44:44.248262 18636 solver.cpp:404] Sparsity after update:
I0802 10:44:44.258203 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:44:44.258222 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:44:44.258232 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:44:44.258237 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:44:44.258242 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:44:44.258246 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:44:44.258252 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:44:44.258257 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:44:44.258261 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:44:44.258267 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:44:44.258271 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:44:44.258276 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:44:44.258280 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:44:44.425493 18636 solver.cpp:353] Iteration 129000 (7.12601 iter/s, 14.0331s/100 iter), loss = 1.48048
I0802 10:44:44.425529 18636 solver.cpp:375]     Train net output #0: loss = 1.4718 (* 1 = 1.4718 loss)
I0802 10:44:44.425534 18636 sgd_solver.cpp:136] Iteration 129000, lr = 0.0019375, m = 0.9
I0802 10:44:58.465214 18636 solver.cpp:353] Iteration 129100 (7.12284 iter/s, 14.0393s/100 iter), loss = 1.69769
I0802 10:44:58.465322 18636 solver.cpp:375]     Train net output #0: loss = 1.73979 (* 1 = 1.73979 loss)
I0802 10:44:58.465343 18636 sgd_solver.cpp:136] Iteration 129100, lr = 0.00193125, m = 0.9
I0802 10:44:59.547487 18597 data_reader.cpp:264] Starting prefetch of epoch 4
I0802 10:45:12.472998 18636 solver.cpp:353] Iteration 129200 (7.13909 iter/s, 14.0074s/100 iter), loss = 1.53326
I0802 10:45:12.473099 18636 solver.cpp:375]     Train net output #0: loss = 1.18325 (* 1 = 1.18325 loss)
I0802 10:45:12.473121 18636 sgd_solver.cpp:136] Iteration 129200, lr = 0.001925, m = 0.9
I0802 10:45:26.491858 18636 solver.cpp:353] Iteration 129300 (7.13344 iter/s, 14.0185s/100 iter), loss = 1.07509
I0802 10:45:26.491897 18636 solver.cpp:375]     Train net output #0: loss = 1.10359 (* 1 = 1.10359 loss)
I0802 10:45:26.491904 18636 sgd_solver.cpp:136] Iteration 129300, lr = 0.00191875, m = 0.9
I0802 10:45:40.451555 18636 solver.cpp:353] Iteration 129400 (7.16368 iter/s, 13.9593s/100 iter), loss = 1.48224
I0802 10:45:40.451581 18636 solver.cpp:375]     Train net output #0: loss = 1.35509 (* 1 = 1.35509 loss)
I0802 10:45:40.451586 18636 sgd_solver.cpp:136] Iteration 129400, lr = 0.0019125, m = 0.9
I0802 10:45:54.390617 18636 solver.cpp:353] Iteration 129500 (7.17428 iter/s, 13.9387s/100 iter), loss = 1.10945
I0802 10:45:54.391253 18636 solver.cpp:375]     Train net output #0: loss = 1.41789 (* 1 = 1.41789 loss)
I0802 10:45:54.391258 18636 sgd_solver.cpp:136] Iteration 129500, lr = 0.00190625, m = 0.9
I0802 10:46:08.488770 18636 solver.cpp:353] Iteration 129600 (7.09332 iter/s, 14.0978s/100 iter), loss = 1.80776
I0802 10:46:08.488798 18636 solver.cpp:375]     Train net output #0: loss = 2.38071 (* 1 = 2.38071 loss)
I0802 10:46:08.488804 18636 sgd_solver.cpp:136] Iteration 129600, lr = 0.0019, m = 0.9
I0802 10:46:22.457442 18636 solver.cpp:353] Iteration 129700 (7.15907 iter/s, 13.9683s/100 iter), loss = 1.15136
I0802 10:46:22.457473 18636 solver.cpp:375]     Train net output #0: loss = 1.46839 (* 1 = 1.46839 loss)
I0802 10:46:22.457479 18636 sgd_solver.cpp:136] Iteration 129700, lr = 0.00189375, m = 0.9
I0802 10:46:36.376380 18636 solver.cpp:353] Iteration 129800 (7.18466 iter/s, 13.9186s/100 iter), loss = 1.75692
I0802 10:46:36.376508 18636 solver.cpp:375]     Train net output #0: loss = 1.80477 (* 1 = 1.80477 loss)
I0802 10:46:36.376523 18636 sgd_solver.cpp:136] Iteration 129800, lr = 0.0018875, m = 0.9
I0802 10:46:50.328701 18636 solver.cpp:353] Iteration 129900 (7.16746 iter/s, 13.9519s/100 iter), loss = 1.71175
I0802 10:46:50.328732 18636 solver.cpp:375]     Train net output #0: loss = 1.74195 (* 1 = 1.74195 loss)
I0802 10:46:50.328737 18636 sgd_solver.cpp:136] Iteration 129900, lr = 0.00188125, m = 0.9
I0802 10:47:04.340049 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_130000.caffemodel
I0802 10:47:04.466578 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_130000.solverstate
I0802 10:47:04.471041 18636 solver.cpp:404] Sparsity after update:
I0802 10:47:04.476486 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:47:04.476500 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:47:04.476508 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:47:04.476511 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:47:04.476516 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:47:04.476531 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:47:04.476539 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:47:04.476548 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:47:04.476557 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:47:04.476564 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:47:04.476572 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:47:04.476580 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:47:04.476588 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:47:04.476605 18636 solver.cpp:550] Iteration 130000, Testing net (#0)
I0802 10:47:24.052140 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591
I0802 10:47:24.052251 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817939
I0802 10:47:24.052260 18636 solver.cpp:635]     Test net output #2: loss = 1.78912 (* 1 = 1.78912 loss)
I0802 10:47:24.052280 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5751s
I0802 10:47:24.200960 18636 solver.cpp:353] Iteration 130000 (2.95235 iter/s, 33.8713s/100 iter), loss = 1.23416
I0802 10:47:24.200994 18636 solver.cpp:375]     Train net output #0: loss = 1.4953 (* 1 = 1.4953 loss)
I0802 10:47:24.200999 18636 sgd_solver.cpp:136] Iteration 130000, lr = 0.001875, m = 0.9
I0802 10:47:38.127789 18636 solver.cpp:353] Iteration 130100 (7.18059 iter/s, 13.9264s/100 iter), loss = 1.63635
I0802 10:47:38.127816 18636 solver.cpp:375]     Train net output #0: loss = 1.46394 (* 1 = 1.46394 loss)
I0802 10:47:38.127822 18636 sgd_solver.cpp:136] Iteration 130100, lr = 0.00186875, m = 0.9
I0802 10:47:52.111613 18636 solver.cpp:353] Iteration 130200 (7.15132 iter/s, 13.9834s/100 iter), loss = 1.56229
I0802 10:47:52.111639 18636 solver.cpp:375]     Train net output #0: loss = 1.49774 (* 1 = 1.49774 loss)
I0802 10:47:52.111644 18636 sgd_solver.cpp:136] Iteration 130200, lr = 0.0018625, m = 0.9
I0802 10:48:06.033505 18636 solver.cpp:353] Iteration 130300 (7.18313 iter/s, 13.9215s/100 iter), loss = 1.34422
I0802 10:48:06.033572 18636 solver.cpp:375]     Train net output #0: loss = 1.25499 (* 1 = 1.25499 loss)
I0802 10:48:06.033578 18636 sgd_solver.cpp:136] Iteration 130300, lr = 0.00185625, m = 0.9
I0802 10:48:19.934944 18636 solver.cpp:353] Iteration 130400 (7.1937 iter/s, 13.9011s/100 iter), loss = 1.06763
I0802 10:48:19.935019 18636 solver.cpp:375]     Train net output #0: loss = 1.18339 (* 1 = 1.18339 loss)
I0802 10:48:19.935040 18636 sgd_solver.cpp:136] Iteration 130400, lr = 0.00185, m = 0.9
I0802 10:48:33.892046 18636 solver.cpp:353] Iteration 130500 (7.16501 iter/s, 13.9567s/100 iter), loss = 1.36848
I0802 10:48:33.892072 18636 solver.cpp:375]     Train net output #0: loss = 1.58564 (* 1 = 1.58564 loss)
I0802 10:48:33.892112 18636 sgd_solver.cpp:136] Iteration 130500, lr = 0.00184375, m = 0.9
I0802 10:48:47.788547 18636 solver.cpp:353] Iteration 130600 (7.19626 iter/s, 13.8961s/100 iter), loss = 1.74909
I0802 10:48:47.788676 18636 solver.cpp:375]     Train net output #0: loss = 2.22989 (* 1 = 2.22989 loss)
I0802 10:48:47.788697 18636 sgd_solver.cpp:136] Iteration 130600, lr = 0.0018375, m = 0.9
I0802 10:49:01.820412 18636 solver.cpp:353] Iteration 130700 (7.12683 iter/s, 14.0315s/100 iter), loss = 1.37421
I0802 10:49:01.820521 18636 solver.cpp:375]     Train net output #0: loss = 1.47853 (* 1 = 1.47853 loss)
I0802 10:49:01.820544 18636 sgd_solver.cpp:136] Iteration 130700, lr = 0.00183125, m = 0.9
I0802 10:49:15.827250 18636 solver.cpp:353] Iteration 130800 (7.13957 iter/s, 14.0064s/100 iter), loss = 1.49381
I0802 10:49:15.827323 18636 solver.cpp:375]     Train net output #0: loss = 1.55529 (* 1 = 1.55529 loss)
I0802 10:49:15.827337 18636 sgd_solver.cpp:136] Iteration 130800, lr = 0.001825, m = 0.9
I0802 10:49:29.837476 18636 solver.cpp:353] Iteration 130900 (7.13784 iter/s, 14.0098s/100 iter), loss = 1.20213
I0802 10:49:29.837564 18636 solver.cpp:375]     Train net output #0: loss = 1.23876 (* 1 = 1.23876 loss)
I0802 10:49:29.837574 18636 sgd_solver.cpp:136] Iteration 130900, lr = 0.00181875, m = 0.9
I0802 10:49:43.664014 18636 solver.cpp:404] Sparsity after update:
I0802 10:49:43.675660 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:49:43.675715 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:49:43.675736 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:49:43.675750 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:49:43.675762 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:49:43.675776 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:49:43.675788 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:49:43.675801 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:49:43.675813 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:49:43.675827 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:49:43.675838 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:49:43.675851 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:49:43.675863 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:49:43.822743 18636 solver.cpp:353] Iteration 131000 (7.15058 iter/s, 13.9849s/100 iter), loss = 1.80075
I0802 10:49:43.822808 18636 solver.cpp:375]     Train net output #0: loss = 1.89711 (* 1 = 1.89711 loss)
I0802 10:49:43.822821 18636 sgd_solver.cpp:136] Iteration 131000, lr = 0.0018125, m = 0.9
I0802 10:49:57.780027 18636 solver.cpp:353] Iteration 131100 (7.16492 iter/s, 13.9569s/100 iter), loss = 1.39288
I0802 10:49:57.780109 18636 solver.cpp:375]     Train net output #0: loss = 1.56057 (* 1 = 1.56057 loss)
I0802 10:49:57.780129 18636 sgd_solver.cpp:136] Iteration 131100, lr = 0.00180625, m = 0.9
I0802 10:50:11.700489 18636 solver.cpp:353] Iteration 131200 (7.18387 iter/s, 13.9201s/100 iter), loss = 1.34142
I0802 10:50:11.700542 18636 solver.cpp:375]     Train net output #0: loss = 1.59412 (* 1 = 1.59412 loss)
I0802 10:50:11.700548 18636 sgd_solver.cpp:136] Iteration 131200, lr = 0.0018, m = 0.9
I0802 10:50:25.808435 18636 solver.cpp:353] Iteration 131300 (7.0884 iter/s, 14.1076s/100 iter), loss = 1.45082
I0802 10:50:25.808460 18636 solver.cpp:375]     Train net output #0: loss = 1.51055 (* 1 = 1.51055 loss)
I0802 10:50:25.808465 18636 sgd_solver.cpp:136] Iteration 131300, lr = 0.00179375, m = 0.9
I0802 10:50:39.667026 18636 solver.cpp:353] Iteration 131400 (7.21594 iter/s, 13.8582s/100 iter), loss = 1.20729
I0802 10:50:39.667050 18636 solver.cpp:375]     Train net output #0: loss = 1.2329 (* 1 = 1.2329 loss)
I0802 10:50:39.667057 18636 sgd_solver.cpp:136] Iteration 131400, lr = 0.0017875, m = 0.9
I0802 10:50:53.595650 18636 solver.cpp:353] Iteration 131500 (7.17966 iter/s, 13.9282s/100 iter), loss = 1.7916
I0802 10:50:53.595717 18636 solver.cpp:375]     Train net output #0: loss = 1.81535 (* 1 = 1.81535 loss)
I0802 10:50:53.595723 18636 sgd_solver.cpp:136] Iteration 131500, lr = 0.00178125, m = 0.9
I0802 10:51:07.613113 18636 solver.cpp:353] Iteration 131600 (7.13416 iter/s, 14.0171s/100 iter), loss = 0.818414
I0802 10:51:07.613209 18636 solver.cpp:375]     Train net output #0: loss = 0.6297 (* 1 = 0.6297 loss)
I0802 10:51:07.613230 18636 sgd_solver.cpp:136] Iteration 131600, lr = 0.001775, m = 0.9
I0802 10:51:21.543830 18636 solver.cpp:353] Iteration 131700 (7.17858 iter/s, 13.9303s/100 iter), loss = 1.38166
I0802 10:51:21.543857 18636 solver.cpp:375]     Train net output #0: loss = 1.5634 (* 1 = 1.5634 loss)
I0802 10:51:21.543861 18636 sgd_solver.cpp:136] Iteration 131700, lr = 0.00176875, m = 0.9
I0802 10:51:35.535920 18636 solver.cpp:353] Iteration 131800 (7.14709 iter/s, 13.9917s/100 iter), loss = 1.3804
I0802 10:51:35.536074 18636 solver.cpp:375]     Train net output #0: loss = 1.48057 (* 1 = 1.48057 loss)
I0802 10:51:35.536103 18636 sgd_solver.cpp:136] Iteration 131800, lr = 0.0017625, m = 0.9
I0802 10:51:49.466671 18636 solver.cpp:353] Iteration 131900 (7.17856 iter/s, 13.9304s/100 iter), loss = 1.60318
I0802 10:51:49.466696 18636 solver.cpp:375]     Train net output #0: loss = 1.58725 (* 1 = 1.58725 loss)
I0802 10:51:49.466699 18636 sgd_solver.cpp:136] Iteration 131900, lr = 0.00175625, m = 0.9
I0802 10:52:03.442961 18636 solver.cpp:404] Sparsity after update:
I0802 10:52:03.447903 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:52:03.447921 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:52:03.447928 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:52:03.447932 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:52:03.447935 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:52:03.447940 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:52:03.447945 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:52:03.447948 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:52:03.447952 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:52:03.447955 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:52:03.447958 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:52:03.447962 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:52:03.447968 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:52:03.447979 18636 solver.cpp:550] Iteration 132000, Testing net (#0)
I0802 10:52:10.546973 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 10:52:23.238548 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591235
I0802 10:52:23.238572 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.817055
I0802 10:52:23.238577 18636 solver.cpp:635]     Test net output #2: loss = 1.7854 (* 1 = 1.7854 loss)
I0802 10:52:23.238689 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7902s
I0802 10:52:23.380903 18636 solver.cpp:353] Iteration 132000 (2.9487 iter/s, 33.9133s/100 iter), loss = 1.4178
I0802 10:52:23.380955 18636 solver.cpp:375]     Train net output #0: loss = 1.21796 (* 1 = 1.21796 loss)
I0802 10:52:23.380967 18636 sgd_solver.cpp:136] Iteration 132000, lr = 0.00175, m = 0.9
I0802 10:52:37.280565 18636 solver.cpp:353] Iteration 132100 (7.19462 iter/s, 13.8993s/100 iter), loss = 1.8376
I0802 10:52:37.280591 18636 solver.cpp:375]     Train net output #0: loss = 1.62969 (* 1 = 1.62969 loss)
I0802 10:52:37.280596 18636 sgd_solver.cpp:136] Iteration 132100, lr = 0.00174375, m = 0.9
I0802 10:52:51.247493 18636 solver.cpp:353] Iteration 132200 (7.15997 iter/s, 13.9665s/100 iter), loss = 1.21308
I0802 10:52:51.247591 18636 solver.cpp:375]     Train net output #0: loss = 0.947242 (* 1 = 0.947242 loss)
I0802 10:52:51.247598 18636 sgd_solver.cpp:136] Iteration 132200, lr = 0.0017375, m = 0.9
I0802 10:53:05.135985 18636 solver.cpp:353] Iteration 132300 (7.20041 iter/s, 13.8881s/100 iter), loss = 1.48625
I0802 10:53:05.136066 18636 solver.cpp:375]     Train net output #0: loss = 1.91055 (* 1 = 1.91055 loss)
I0802 10:53:05.136087 18636 sgd_solver.cpp:136] Iteration 132300, lr = 0.00173125, m = 0.9
I0802 10:53:19.086601 18636 solver.cpp:353] Iteration 132400 (7.16834 iter/s, 13.9502s/100 iter), loss = 1.47904
I0802 10:53:19.086638 18636 solver.cpp:375]     Train net output #0: loss = 1.32819 (* 1 = 1.32819 loss)
I0802 10:53:19.086645 18636 sgd_solver.cpp:136] Iteration 132400, lr = 0.001725, m = 0.9
I0802 10:53:32.964922 18636 solver.cpp:353] Iteration 132500 (7.20568 iter/s, 13.8779s/100 iter), loss = 1.19309
I0802 10:53:32.964987 18636 solver.cpp:375]     Train net output #0: loss = 1.24754 (* 1 = 1.24754 loss)
I0802 10:53:32.964994 18636 sgd_solver.cpp:136] Iteration 132500, lr = 0.00171875, m = 0.9
I0802 10:53:47.050106 18636 solver.cpp:353] Iteration 132600 (7.09986 iter/s, 14.0848s/100 iter), loss = 1.36187
I0802 10:53:47.050393 18636 solver.cpp:375]     Train net output #0: loss = 1.28927 (* 1 = 1.28927 loss)
I0802 10:53:47.050510 18636 sgd_solver.cpp:136] Iteration 132600, lr = 0.0017125, m = 0.9
I0802 10:54:00.987725 18636 solver.cpp:353] Iteration 132700 (7.17502 iter/s, 13.9372s/100 iter), loss = 1.45726
I0802 10:54:00.987753 18636 solver.cpp:375]     Train net output #0: loss = 1.40137 (* 1 = 1.40137 loss)
I0802 10:54:00.987758 18636 sgd_solver.cpp:136] Iteration 132700, lr = 0.00170625, m = 0.9
I0802 10:54:14.906196 18636 solver.cpp:353] Iteration 132800 (7.1849 iter/s, 13.9181s/100 iter), loss = 1.34404
I0802 10:54:14.906332 18636 solver.cpp:375]     Train net output #0: loss = 0.924179 (* 1 = 0.924179 loss)
I0802 10:54:14.906352 18636 sgd_solver.cpp:136] Iteration 132800, lr = 0.0017, m = 0.9
I0802 10:54:28.953744 18636 solver.cpp:353] Iteration 132900 (7.11887 iter/s, 14.0472s/100 iter), loss = 1.44871
I0802 10:54:28.953774 18636 solver.cpp:375]     Train net output #0: loss = 1.17802 (* 1 = 1.17802 loss)
I0802 10:54:28.953780 18636 sgd_solver.cpp:136] Iteration 132900, lr = 0.00169375, m = 0.9
I0802 10:54:42.868659 18636 solver.cpp:404] Sparsity after update:
I0802 10:54:42.880317 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:54:42.880329 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:54:42.880336 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:54:42.880338 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:54:42.880340 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:54:42.880342 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:54:42.880344 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:54:42.880347 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:54:42.880348 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:54:42.880350 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:54:42.880352 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:54:42.880357 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:54:42.880359 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:54:43.008481 18636 solver.cpp:353] Iteration 133000 (7.11523 iter/s, 14.0544s/100 iter), loss = 0.94251
I0802 10:54:43.008507 18636 solver.cpp:375]     Train net output #0: loss = 1.01859 (* 1 = 1.01859 loss)
I0802 10:54:43.008512 18636 sgd_solver.cpp:136] Iteration 133000, lr = 0.0016875, m = 0.9
I0802 10:54:57.091567 18636 solver.cpp:353] Iteration 133100 (7.10091 iter/s, 14.0827s/100 iter), loss = 1.41639
I0802 10:54:57.091671 18636 solver.cpp:375]     Train net output #0: loss = 1.55453 (* 1 = 1.55453 loss)
I0802 10:54:57.091691 18636 sgd_solver.cpp:136] Iteration 133100, lr = 0.00168125, m = 0.9
I0802 10:55:11.188513 18636 solver.cpp:353] Iteration 133200 (7.09393 iter/s, 14.0966s/100 iter), loss = 1.26932
I0802 10:55:11.188542 18636 solver.cpp:375]     Train net output #0: loss = 1.34499 (* 1 = 1.34499 loss)
I0802 10:55:11.188547 18636 sgd_solver.cpp:136] Iteration 133200, lr = 0.001675, m = 0.9
I0802 10:55:25.254235 18636 solver.cpp:353] Iteration 133300 (7.10968 iter/s, 14.0653s/100 iter), loss = 1.54261
I0802 10:55:25.254261 18636 solver.cpp:375]     Train net output #0: loss = 1.72605 (* 1 = 1.72605 loss)
I0802 10:55:25.254264 18636 sgd_solver.cpp:136] Iteration 133300, lr = 0.00166875, m = 0.9
I0802 10:55:39.382041 18636 solver.cpp:353] Iteration 133400 (7.07844 iter/s, 14.1274s/100 iter), loss = 1.41054
I0802 10:55:39.382143 18636 solver.cpp:375]     Train net output #0: loss = 1.28096 (* 1 = 1.28096 loss)
I0802 10:55:39.382150 18636 sgd_solver.cpp:136] Iteration 133400, lr = 0.0016625, m = 0.9
I0802 10:55:53.323215 18636 solver.cpp:353] Iteration 133500 (7.17319 iter/s, 13.9408s/100 iter), loss = 1.15845
I0802 10:55:53.323426 18636 solver.cpp:375]     Train net output #0: loss = 1.13737 (* 1 = 1.13737 loss)
I0802 10:55:53.323534 18636 sgd_solver.cpp:136] Iteration 133500, lr = 0.00165625, m = 0.9
I0802 10:56:07.361366 18636 solver.cpp:353] Iteration 133600 (7.12364 iter/s, 14.0378s/100 iter), loss = 1.65164
I0802 10:56:07.361402 18636 solver.cpp:375]     Train net output #0: loss = 1.66275 (* 1 = 1.66275 loss)
I0802 10:56:07.361408 18636 sgd_solver.cpp:136] Iteration 133600, lr = 0.00165, m = 0.9
I0802 10:56:21.460191 18636 solver.cpp:353] Iteration 133700 (7.09299 iter/s, 14.0984s/100 iter), loss = 1.53652
I0802 10:56:21.460314 18636 solver.cpp:375]     Train net output #0: loss = 1.19141 (* 1 = 1.19141 loss)
I0802 10:56:21.460321 18636 sgd_solver.cpp:136] Iteration 133700, lr = 0.00164375, m = 0.9
I0802 10:56:35.675984 18636 solver.cpp:353] Iteration 133800 (7.03462 iter/s, 14.2154s/100 iter), loss = 0.897293
I0802 10:56:35.676010 18636 solver.cpp:375]     Train net output #0: loss = 0.946251 (* 1 = 0.946251 loss)
I0802 10:56:35.676017 18636 sgd_solver.cpp:136] Iteration 133800, lr = 0.0016375, m = 0.9
I0802 10:56:49.785593 18636 solver.cpp:353] Iteration 133900 (7.08756 iter/s, 14.1092s/100 iter), loss = 1.28601
I0802 10:56:49.785620 18636 solver.cpp:375]     Train net output #0: loss = 1.57509 (* 1 = 1.57509 loss)
I0802 10:56:49.785626 18636 sgd_solver.cpp:136] Iteration 133900, lr = 0.00163125, m = 0.9
I0802 10:57:03.689306 18636 solver.cpp:404] Sparsity after update:
I0802 10:57:03.694501 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:57:03.694512 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:57:03.694520 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:57:03.694525 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:57:03.694535 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:57:03.694538 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:57:03.694541 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:57:03.694547 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:57:03.694551 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:57:03.694555 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:57:03.694561 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:57:03.694564 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:57:03.694568 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:57:03.694581 18636 solver.cpp:550] Iteration 134000, Testing net (#0)
I0802 10:57:23.292168 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.587177
I0802 10:57:23.292193 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.819527
I0802 10:57:23.292201 18636 solver.cpp:635]     Test net output #2: loss = 1.78841 (* 1 = 1.78841 loss)
I0802 10:57:23.292255 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5971s
I0802 10:57:23.458808 18636 solver.cpp:353] Iteration 134000 (2.9698 iter/s, 33.6723s/100 iter), loss = 1.2957
I0802 10:57:23.458835 18636 solver.cpp:375]     Train net output #0: loss = 1.23551 (* 1 = 1.23551 loss)
I0802 10:57:23.458885 18636 sgd_solver.cpp:136] Iteration 134000, lr = 0.001625, m = 0.9
I0802 10:57:37.694674 18636 solver.cpp:353] Iteration 134100 (7.02471 iter/s, 14.2355s/100 iter), loss = 1.54346
I0802 10:57:37.694749 18636 solver.cpp:375]     Train net output #0: loss = 1.73716 (* 1 = 1.73716 loss)
I0802 10:57:37.694756 18636 sgd_solver.cpp:136] Iteration 134100, lr = 0.00161875, m = 0.9
I0802 10:57:51.661579 18636 solver.cpp:353] Iteration 134200 (7.15998 iter/s, 13.9665s/100 iter), loss = 1.38435
I0802 10:57:51.661607 18636 solver.cpp:375]     Train net output #0: loss = 1.62731 (* 1 = 1.62731 loss)
I0802 10:57:51.661610 18636 sgd_solver.cpp:136] Iteration 134200, lr = 0.0016125, m = 0.9
I0802 10:58:05.657759 18636 solver.cpp:353] Iteration 134300 (7.14501 iter/s, 13.9958s/100 iter), loss = 1.31104
I0802 10:58:05.657791 18636 solver.cpp:375]     Train net output #0: loss = 1.15077 (* 1 = 1.15077 loss)
I0802 10:58:05.657799 18636 sgd_solver.cpp:136] Iteration 134300, lr = 0.00160625, m = 0.9
I0802 10:58:19.878829 18636 solver.cpp:353] Iteration 134400 (7.03202 iter/s, 14.2207s/100 iter), loss = 1.64566
I0802 10:58:19.878907 18636 solver.cpp:375]     Train net output #0: loss = 1.83631 (* 1 = 1.83631 loss)
I0802 10:58:19.878917 18636 sgd_solver.cpp:136] Iteration 134400, lr = 0.0016, m = 0.9
I0802 10:58:33.850033 18636 solver.cpp:353] Iteration 134500 (7.15777 iter/s, 13.9708s/100 iter), loss = 1.27295
I0802 10:58:33.850059 18636 solver.cpp:375]     Train net output #0: loss = 1.41003 (* 1 = 1.41003 loss)
I0802 10:58:33.850064 18636 sgd_solver.cpp:136] Iteration 134500, lr = 0.00159375, m = 0.9
I0802 10:58:47.841738 18636 solver.cpp:353] Iteration 134600 (7.14729 iter/s, 13.9913s/100 iter), loss = 1.50706
I0802 10:58:47.841766 18636 solver.cpp:375]     Train net output #0: loss = 1.10679 (* 1 = 1.10679 loss)
I0802 10:58:47.841773 18636 sgd_solver.cpp:136] Iteration 134600, lr = 0.0015875, m = 0.9
I0802 10:59:01.801584 18636 solver.cpp:353] Iteration 134700 (7.1636 iter/s, 13.9595s/100 iter), loss = 1.54624
I0802 10:59:01.801656 18636 solver.cpp:375]     Train net output #0: loss = 1.53643 (* 1 = 1.53643 loss)
I0802 10:59:01.801663 18636 sgd_solver.cpp:136] Iteration 134700, lr = 0.00158125, m = 0.9
I0802 10:59:15.811053 18636 solver.cpp:353] Iteration 134800 (7.13823 iter/s, 14.0091s/100 iter), loss = 1.05589
I0802 10:59:15.811080 18636 solver.cpp:375]     Train net output #0: loss = 1.26774 (* 1 = 1.26774 loss)
I0802 10:59:15.811086 18636 sgd_solver.cpp:136] Iteration 134800, lr = 0.001575, m = 0.9
I0802 10:59:29.847959 18636 solver.cpp:353] Iteration 134900 (7.12427 iter/s, 14.0365s/100 iter), loss = 1.22279
I0802 10:59:29.847995 18636 solver.cpp:375]     Train net output #0: loss = 1.24797 (* 1 = 1.24797 loss)
I0802 10:59:29.848001 18636 sgd_solver.cpp:136] Iteration 134900, lr = 0.00156875, m = 0.9
I0802 10:59:43.646406 18636 solver.cpp:404] Sparsity after update:
I0802 10:59:43.658041 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 10:59:43.658061 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 10:59:43.658071 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 10:59:43.658074 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 10:59:43.658078 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 10:59:43.658082 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 10:59:43.658085 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 10:59:43.658089 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 10:59:43.658093 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 10:59:43.658097 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 10:59:43.658099 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 10:59:43.658103 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 10:59:43.658120 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 10:59:43.793201 18636 solver.cpp:353] Iteration 135000 (7.1711 iter/s, 13.9449s/100 iter), loss = 1.75288
I0802 10:59:43.793231 18636 solver.cpp:375]     Train net output #0: loss = 2.34828 (* 1 = 2.34828 loss)
I0802 10:59:43.793238 18636 sgd_solver.cpp:136] Iteration 135000, lr = 0.0015625, m = 0.9
I0802 10:59:57.791503 18636 solver.cpp:353] Iteration 135100 (7.14392 iter/s, 13.9979s/100 iter), loss = 1.98778
I0802 10:59:57.791528 18636 solver.cpp:375]     Train net output #0: loss = 2.11033 (* 1 = 2.11033 loss)
I0802 10:59:57.791533 18636 sgd_solver.cpp:136] Iteration 135100, lr = 0.00155625, m = 0.9
I0802 11:00:11.997627 18636 solver.cpp:353] Iteration 135200 (7.03941 iter/s, 14.2057s/100 iter), loss = 1.80491
I0802 11:00:11.997653 18636 solver.cpp:375]     Train net output #0: loss = 1.89167 (* 1 = 1.89167 loss)
I0802 11:00:11.997658 18636 sgd_solver.cpp:136] Iteration 135200, lr = 0.00155, m = 0.9
I0802 11:00:26.188418 18636 solver.cpp:353] Iteration 135300 (7.04702 iter/s, 14.1904s/100 iter), loss = 1.29216
I0802 11:00:26.188519 18636 solver.cpp:375]     Train net output #0: loss = 1.22987 (* 1 = 1.22987 loss)
I0802 11:00:26.188530 18636 sgd_solver.cpp:136] Iteration 135300, lr = 0.00154375, m = 0.9
I0802 11:00:40.275568 18636 solver.cpp:353] Iteration 135400 (7.09886 iter/s, 14.0868s/100 iter), loss = 1.31622
I0802 11:00:40.275594 18636 solver.cpp:375]     Train net output #0: loss = 1.4844 (* 1 = 1.4844 loss)
I0802 11:00:40.275599 18636 sgd_solver.cpp:136] Iteration 135400, lr = 0.0015375, m = 0.9
I0802 11:00:54.240270 18636 solver.cpp:353] Iteration 135500 (7.16111 iter/s, 13.9643s/100 iter), loss = 1.34158
I0802 11:00:54.240295 18636 solver.cpp:375]     Train net output #0: loss = 0.910261 (* 1 = 0.910261 loss)
I0802 11:00:54.240299 18636 sgd_solver.cpp:136] Iteration 135500, lr = 0.00153125, m = 0.9
I0802 11:01:08.280275 18636 solver.cpp:353] Iteration 135600 (7.1227 iter/s, 14.0396s/100 iter), loss = 1.54704
I0802 11:01:08.280385 18636 solver.cpp:375]     Train net output #0: loss = 1.57443 (* 1 = 1.57443 loss)
I0802 11:01:08.280392 18636 sgd_solver.cpp:136] Iteration 135600, lr = 0.001525, m = 0.9
I0802 11:01:22.212112 18636 solver.cpp:353] Iteration 135700 (7.178 iter/s, 13.9315s/100 iter), loss = 1.40761
I0802 11:01:22.212141 18636 solver.cpp:375]     Train net output #0: loss = 1.72757 (* 1 = 1.72757 loss)
I0802 11:01:22.212146 18636 sgd_solver.cpp:136] Iteration 135700, lr = 0.00151875, m = 0.9
I0802 11:01:36.133363 18636 solver.cpp:353] Iteration 135800 (7.18346 iter/s, 13.9209s/100 iter), loss = 1.40727
I0802 11:01:36.133390 18636 solver.cpp:375]     Train net output #0: loss = 1.70456 (* 1 = 1.70456 loss)
I0802 11:01:36.133396 18636 sgd_solver.cpp:136] Iteration 135800, lr = 0.0015125, m = 0.9
I0802 11:01:50.222350 18636 solver.cpp:353] Iteration 135900 (7.09794 iter/s, 14.0886s/100 iter), loss = 0.992058
I0802 11:01:50.222434 18636 solver.cpp:375]     Train net output #0: loss = 1.13859 (* 1 = 1.13859 loss)
I0802 11:01:50.222440 18636 sgd_solver.cpp:136] Iteration 135900, lr = 0.00150625, m = 0.9
I0802 11:02:04.082376 18636 solver.cpp:404] Sparsity after update:
I0802 11:02:04.086755 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:02:04.086765 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:02:04.086771 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:02:04.086772 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:02:04.086774 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:02:04.086776 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:02:04.086778 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:02:04.086781 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:02:04.086782 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:02:04.086784 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:02:04.086786 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:02:04.086787 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:02:04.086789 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:02:04.086797 18636 solver.cpp:550] Iteration 136000, Testing net (#0)
I0802 11:02:23.788300 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.592235
I0802 11:02:23.788427 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821056
I0802 11:02:23.788436 18636 solver.cpp:635]     Test net output #2: loss = 1.76265 (* 1 = 1.76265 loss)
I0802 11:02:23.788458 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7011s
I0802 11:02:23.929625 18636 solver.cpp:353] Iteration 136000 (2.9668 iter/s, 33.7064s/100 iter), loss = 1.18168
I0802 11:02:23.929648 18636 solver.cpp:375]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0802 11:02:23.929652 18636 sgd_solver.cpp:136] Iteration 136000, lr = 0.0015, m = 0.9
I0802 11:02:37.946132 18636 solver.cpp:353] Iteration 136100 (7.13464 iter/s, 14.0161s/100 iter), loss = 1.52869
I0802 11:02:37.946161 18636 solver.cpp:375]     Train net output #0: loss = 1.37779 (* 1 = 1.37779 loss)
I0802 11:02:37.946167 18636 sgd_solver.cpp:136] Iteration 136100, lr = 0.00149375, m = 0.9
I0802 11:02:51.929813 18636 solver.cpp:353] Iteration 136200 (7.15139 iter/s, 13.9833s/100 iter), loss = 1.04117
I0802 11:02:51.929841 18636 solver.cpp:375]     Train net output #0: loss = 1.05713 (* 1 = 1.05713 loss)
I0802 11:02:51.929847 18636 sgd_solver.cpp:136] Iteration 136200, lr = 0.0014875, m = 0.9
I0802 11:03:05.763082 18636 solver.cpp:353] Iteration 136300 (7.22915 iter/s, 13.8329s/100 iter), loss = 1.21047
I0802 11:03:05.763170 18636 solver.cpp:375]     Train net output #0: loss = 1.06629 (* 1 = 1.06629 loss)
I0802 11:03:05.763180 18636 sgd_solver.cpp:136] Iteration 136300, lr = 0.00148125, m = 0.9
I0802 11:03:19.695267 18636 solver.cpp:353] Iteration 136400 (7.17782 iter/s, 13.9318s/100 iter), loss = 1.39079
I0802 11:03:19.695528 18636 solver.cpp:375]     Train net output #0: loss = 1.2027 (* 1 = 1.2027 loss)
I0802 11:03:19.695619 18636 sgd_solver.cpp:136] Iteration 136400, lr = 0.001475, m = 0.9
I0802 11:03:33.765907 18636 solver.cpp:353] Iteration 136500 (7.10719 iter/s, 14.0703s/100 iter), loss = 1.33419
I0802 11:03:33.765933 18636 solver.cpp:375]     Train net output #0: loss = 1.24645 (* 1 = 1.24645 loss)
I0802 11:03:33.765936 18636 sgd_solver.cpp:136] Iteration 136500, lr = 0.00146875, m = 0.9
I0802 11:03:47.783540 18636 solver.cpp:353] Iteration 136600 (7.13407 iter/s, 14.0172s/100 iter), loss = 1.08018
I0802 11:03:47.783807 18636 solver.cpp:375]     Train net output #0: loss = 0.954852 (* 1 = 0.954852 loss)
I0802 11:03:47.783927 18636 sgd_solver.cpp:136] Iteration 136600, lr = 0.0014625, m = 0.9
I0802 11:04:01.782974 18636 solver.cpp:353] Iteration 136700 (7.14334 iter/s, 13.9991s/100 iter), loss = 1.35047
I0802 11:04:01.783006 18636 solver.cpp:375]     Train net output #0: loss = 1.48949 (* 1 = 1.48949 loss)
I0802 11:04:01.783013 18636 sgd_solver.cpp:136] Iteration 136700, lr = 0.00145625, m = 0.9
I0802 11:04:15.743969 18636 solver.cpp:353] Iteration 136800 (7.16302 iter/s, 13.9606s/100 iter), loss = 1.52766
I0802 11:04:15.744009 18636 solver.cpp:375]     Train net output #0: loss = 1.62443 (* 1 = 1.62443 loss)
I0802 11:04:15.744014 18636 sgd_solver.cpp:136] Iteration 136800, lr = 0.00145, m = 0.9
I0802 11:04:29.913023 18636 solver.cpp:353] Iteration 136900 (7.05783 iter/s, 14.1687s/100 iter), loss = 1.23868
I0802 11:04:29.913105 18636 solver.cpp:375]     Train net output #0: loss = 1.0682 (* 1 = 1.0682 loss)
I0802 11:04:29.913116 18636 sgd_solver.cpp:136] Iteration 136900, lr = 0.00144375, m = 0.9
I0802 11:04:43.732321 18636 solver.cpp:404] Sparsity after update:
I0802 11:04:43.742844 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:04:43.742861 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:04:43.742869 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:04:43.742873 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:04:43.742877 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:04:43.742879 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:04:43.742890 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:04:43.742894 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:04:43.742898 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:04:43.742902 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:04:43.742905 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:04:43.742909 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:04:43.742913 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:04:43.871795 18636 solver.cpp:353] Iteration 137000 (7.16415 iter/s, 13.9584s/100 iter), loss = 1.22763
I0802 11:04:43.871846 18636 solver.cpp:375]     Train net output #0: loss = 1.20101 (* 1 = 1.20101 loss)
I0802 11:04:43.871858 18636 sgd_solver.cpp:136] Iteration 137000, lr = 0.0014375, m = 0.9
I0802 11:04:57.817221 18636 solver.cpp:353] Iteration 137100 (7.17101 iter/s, 13.945s/100 iter), loss = 1.33389
I0802 11:04:57.817250 18636 solver.cpp:375]     Train net output #0: loss = 1.61257 (* 1 = 1.61257 loss)
I0802 11:04:57.817258 18636 sgd_solver.cpp:136] Iteration 137100, lr = 0.00143125, m = 0.9
I0802 11:05:11.745789 18636 solver.cpp:353] Iteration 137200 (7.17969 iter/s, 13.9282s/100 iter), loss = 1.26186
I0802 11:05:11.747647 18636 solver.cpp:375]     Train net output #0: loss = 1.27802 (* 1 = 1.27802 loss)
I0802 11:05:11.747670 18636 sgd_solver.cpp:136] Iteration 137200, lr = 0.001425, m = 0.9
I0802 11:05:25.726739 18636 solver.cpp:353] Iteration 137300 (7.15279 iter/s, 13.9806s/100 iter), loss = 1.25161
I0802 11:05:25.726766 18636 solver.cpp:375]     Train net output #0: loss = 1.30269 (* 1 = 1.30269 loss)
I0802 11:05:25.726771 18636 sgd_solver.cpp:136] Iteration 137300, lr = 0.00141875, m = 0.9
I0802 11:05:39.711583 18636 solver.cpp:353] Iteration 137400 (7.1508 iter/s, 13.9845s/100 iter), loss = 1.68546
I0802 11:05:39.711609 18636 solver.cpp:375]     Train net output #0: loss = 1.77683 (* 1 = 1.77683 loss)
I0802 11:05:39.711616 18636 sgd_solver.cpp:136] Iteration 137400, lr = 0.0014125, m = 0.9
I0802 11:05:53.633442 18636 solver.cpp:353] Iteration 137500 (7.18315 iter/s, 13.9215s/100 iter), loss = 1.18459
I0802 11:05:53.633502 18636 solver.cpp:375]     Train net output #0: loss = 1.44322 (* 1 = 1.44322 loss)
I0802 11:05:53.633508 18636 sgd_solver.cpp:136] Iteration 137500, lr = 0.00140625, m = 0.9
I0802 11:06:07.989102 18636 solver.cpp:353] Iteration 137600 (6.96609 iter/s, 14.3553s/100 iter), loss = 1.24664
I0802 11:06:07.989130 18636 solver.cpp:375]     Train net output #0: loss = 1.24466 (* 1 = 1.24466 loss)
I0802 11:06:07.989133 18636 sgd_solver.cpp:136] Iteration 137600, lr = 0.0014, m = 0.9
I0802 11:06:22.086616 18636 solver.cpp:353] Iteration 137700 (7.09364 iter/s, 14.0971s/100 iter), loss = 1.20273
I0802 11:06:22.086642 18636 solver.cpp:375]     Train net output #0: loss = 1.12886 (* 1 = 1.12886 loss)
I0802 11:06:22.086647 18636 sgd_solver.cpp:136] Iteration 137700, lr = 0.00139375, m = 0.9
I0802 11:06:36.087189 18636 solver.cpp:353] Iteration 137800 (7.14276 iter/s, 14.0002s/100 iter), loss = 1.46494
I0802 11:06:36.087249 18636 solver.cpp:375]     Train net output #0: loss = 1.6372 (* 1 = 1.6372 loss)
I0802 11:06:36.087256 18636 sgd_solver.cpp:136] Iteration 137800, lr = 0.0013875, m = 0.9
I0802 11:06:50.156350 18636 solver.cpp:353] Iteration 137900 (7.10794 iter/s, 14.0688s/100 iter), loss = 1.04278
I0802 11:06:50.156384 18636 solver.cpp:375]     Train net output #0: loss = 1.02119 (* 1 = 1.02119 loss)
I0802 11:06:50.156390 18636 sgd_solver.cpp:136] Iteration 137900, lr = 0.00138125, m = 0.9
I0802 11:07:04.067942 18636 solver.cpp:404] Sparsity after update:
I0802 11:07:04.072870 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:07:04.072882 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:07:04.072890 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:07:04.072895 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:07:04.072897 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:07:04.072901 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:07:04.072904 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:07:04.072907 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:07:04.072911 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:07:04.072938 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:07:04.072944 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:07:04.072948 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:07:04.072952 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:07:04.072962 18636 solver.cpp:550] Iteration 138000, Testing net (#0)
I0802 11:07:13.728456 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:07:23.988601 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589235
I0802 11:07:23.988626 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.814468
I0802 11:07:23.988631 18636 solver.cpp:635]     Test net output #2: loss = 1.79738 (* 1 = 1.79738 loss)
I0802 11:07:23.988726 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9152s
I0802 11:07:24.125946 18636 solver.cpp:353] Iteration 138000 (2.94389 iter/s, 33.9687s/100 iter), loss = 1.29298
I0802 11:07:24.125972 18636 solver.cpp:375]     Train net output #0: loss = 1.20092 (* 1 = 1.20092 loss)
I0802 11:07:24.125977 18636 sgd_solver.cpp:136] Iteration 138000, lr = 0.001375, m = 0.9
I0802 11:07:38.048163 18636 solver.cpp:353] Iteration 138100 (7.18297 iter/s, 13.9218s/100 iter), loss = 1.07743
I0802 11:07:38.048197 18636 solver.cpp:375]     Train net output #0: loss = 0.943131 (* 1 = 0.943131 loss)
I0802 11:07:38.048204 18636 sgd_solver.cpp:136] Iteration 138100, lr = 0.00136875, m = 0.9
I0802 11:07:51.970371 18636 solver.cpp:353] Iteration 138200 (7.18297 iter/s, 13.9218s/100 iter), loss = 1.38149
I0802 11:07:51.970424 18636 solver.cpp:375]     Train net output #0: loss = 1.20915 (* 1 = 1.20915 loss)
I0802 11:07:51.970432 18636 sgd_solver.cpp:136] Iteration 138200, lr = 0.0013625, m = 0.9
I0802 11:08:06.178175 18636 solver.cpp:353] Iteration 138300 (7.03858 iter/s, 14.2074s/100 iter), loss = 1.29331
I0802 11:08:06.178203 18636 solver.cpp:375]     Train net output #0: loss = 1.2515 (* 1 = 1.2515 loss)
I0802 11:08:06.178210 18636 sgd_solver.cpp:136] Iteration 138300, lr = 0.00135625, m = 0.9
I0802 11:08:20.305958 18636 solver.cpp:353] Iteration 138400 (7.07845 iter/s, 14.1274s/100 iter), loss = 1.15253
I0802 11:08:20.305985 18636 solver.cpp:375]     Train net output #0: loss = 1.20367 (* 1 = 1.20367 loss)
I0802 11:08:20.305990 18636 sgd_solver.cpp:136] Iteration 138400, lr = 0.00135, m = 0.9
I0802 11:08:34.205858 18636 solver.cpp:353] Iteration 138500 (7.19449 iter/s, 13.8995s/100 iter), loss = 1.53748
I0802 11:08:34.205920 18636 solver.cpp:375]     Train net output #0: loss = 1.4217 (* 1 = 1.4217 loss)
I0802 11:08:34.205927 18636 sgd_solver.cpp:136] Iteration 138500, lr = 0.00134375, m = 0.9
I0802 11:08:48.317706 18636 solver.cpp:353] Iteration 138600 (7.08644 iter/s, 14.1115s/100 iter), loss = 1.56189
I0802 11:08:48.317733 18636 solver.cpp:375]     Train net output #0: loss = 1.40548 (* 1 = 1.40548 loss)
I0802 11:08:48.317737 18636 sgd_solver.cpp:136] Iteration 138600, lr = 0.0013375, m = 0.9
I0802 11:09:02.210073 18636 solver.cpp:353] Iteration 138700 (7.1984 iter/s, 13.892s/100 iter), loss = 1.65857
I0802 11:09:02.210153 18636 solver.cpp:375]     Train net output #0: loss = 1.09167 (* 1 = 1.09167 loss)
I0802 11:09:02.210176 18636 sgd_solver.cpp:136] Iteration 138700, lr = 0.00133125, m = 0.9
I0802 11:09:16.162526 18636 solver.cpp:353] Iteration 138800 (7.1674 iter/s, 13.9521s/100 iter), loss = 1.39808
I0802 11:09:16.162614 18636 solver.cpp:375]     Train net output #0: loss = 1.5144 (* 1 = 1.5144 loss)
I0802 11:09:16.162621 18636 sgd_solver.cpp:136] Iteration 138800, lr = 0.001325, m = 0.9
I0802 11:09:30.244060 18636 solver.cpp:353] Iteration 138900 (7.10169 iter/s, 14.0811s/100 iter), loss = 1.10086
I0802 11:09:30.244092 18636 solver.cpp:375]     Train net output #0: loss = 0.949328 (* 1 = 0.949328 loss)
I0802 11:09:30.244096 18636 sgd_solver.cpp:136] Iteration 138900, lr = 0.00131875, m = 0.9
I0802 11:09:44.240813 18636 solver.cpp:404] Sparsity after update:
I0802 11:09:44.252354 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:09:44.252367 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:09:44.252374 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:09:44.252377 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:09:44.252378 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:09:44.252380 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:09:44.252382 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:09:44.252384 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:09:44.252387 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:09:44.252388 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:09:44.252390 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:09:44.252393 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:09:44.252401 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:09:44.381583 18636 solver.cpp:353] Iteration 139000 (7.07357 iter/s, 14.1371s/100 iter), loss = 1.48479
I0802 11:09:44.381610 18636 solver.cpp:375]     Train net output #0: loss = 1.27964 (* 1 = 1.27964 loss)
I0802 11:09:44.381615 18636 sgd_solver.cpp:136] Iteration 139000, lr = 0.0013125, m = 0.9
I0802 11:09:58.408828 18636 solver.cpp:353] Iteration 139100 (7.12918 iter/s, 14.0269s/100 iter), loss = 1.56852
I0802 11:09:58.408901 18636 solver.cpp:375]     Train net output #0: loss = 1.69397 (* 1 = 1.69397 loss)
I0802 11:09:58.408908 18636 sgd_solver.cpp:136] Iteration 139100, lr = 0.00130625, m = 0.9
I0802 11:10:12.554687 18636 solver.cpp:353] Iteration 139200 (7.0694 iter/s, 14.1455s/100 iter), loss = 1.03359
I0802 11:10:12.554714 18636 solver.cpp:375]     Train net output #0: loss = 1.15937 (* 1 = 1.15937 loss)
I0802 11:10:12.554720 18636 sgd_solver.cpp:136] Iteration 139200, lr = 0.0013, m = 0.9
I0802 11:10:26.640630 18636 solver.cpp:353] Iteration 139300 (7.09947 iter/s, 14.0856s/100 iter), loss = 1.32019
I0802 11:10:26.640661 18636 solver.cpp:375]     Train net output #0: loss = 1.27156 (* 1 = 1.27156 loss)
I0802 11:10:26.640667 18636 sgd_solver.cpp:136] Iteration 139300, lr = 0.00129375, m = 0.9
I0802 11:10:41.225664 18636 solver.cpp:353] Iteration 139400 (6.85653 iter/s, 14.5846s/100 iter), loss = 1.47844
I0802 11:10:41.225724 18636 solver.cpp:375]     Train net output #0: loss = 1.47475 (* 1 = 1.47475 loss)
I0802 11:10:41.225731 18636 sgd_solver.cpp:136] Iteration 139400, lr = 0.0012875, m = 0.9
I0802 11:10:55.229275 18636 solver.cpp:353] Iteration 139500 (7.14121 iter/s, 14.0032s/100 iter), loss = 1.14839
I0802 11:10:55.229305 18636 solver.cpp:375]     Train net output #0: loss = 1.1948 (* 1 = 1.1948 loss)
I0802 11:10:55.229311 18636 sgd_solver.cpp:136] Iteration 139500, lr = 0.00128125, m = 0.9
I0802 11:11:09.335073 18636 solver.cpp:353] Iteration 139600 (7.08948 iter/s, 14.1054s/100 iter), loss = 1.51389
I0802 11:11:09.335103 18636 solver.cpp:375]     Train net output #0: loss = 1.55261 (* 1 = 1.55261 loss)
I0802 11:11:09.335109 18636 sgd_solver.cpp:136] Iteration 139600, lr = 0.001275, m = 0.9
I0802 11:11:23.560186 18636 solver.cpp:353] Iteration 139700 (7.03002 iter/s, 14.2247s/100 iter), loss = 1.30979
I0802 11:11:23.560268 18636 solver.cpp:375]     Train net output #0: loss = 1.07211 (* 1 = 1.07211 loss)
I0802 11:11:23.560277 18636 sgd_solver.cpp:136] Iteration 139700, lr = 0.00126875, m = 0.9
I0802 11:11:37.820204 18636 solver.cpp:353] Iteration 139800 (7.01281 iter/s, 14.2596s/100 iter), loss = 1.37354
I0802 11:11:37.820228 18636 solver.cpp:375]     Train net output #0: loss = 1.41992 (* 1 = 1.41992 loss)
I0802 11:11:37.820233 18636 sgd_solver.cpp:136] Iteration 139800, lr = 0.0012625, m = 0.9
I0802 11:11:51.894024 18636 solver.cpp:353] Iteration 139900 (7.10559 iter/s, 14.0734s/100 iter), loss = 1.18228
I0802 11:11:51.894117 18636 solver.cpp:375]     Train net output #0: loss = 1.0052 (* 1 = 1.0052 loss)
I0802 11:11:51.894136 18636 sgd_solver.cpp:136] Iteration 139900, lr = 0.00125625, m = 0.9
I0802 11:12:05.752779 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_140000.caffemodel
I0802 11:12:05.856480 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_140000.solverstate
I0802 11:12:05.862812 18636 solver.cpp:404] Sparsity after update:
I0802 11:12:05.864459 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:12:05.864470 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:12:05.864478 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:12:05.864482 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:12:05.864486 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:12:05.864491 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:12:05.864495 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:12:05.864500 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:12:05.864503 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:12:05.864507 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:12:05.864511 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:12:05.864516 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:12:05.864521 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:12:05.864531 18636 solver.cpp:550] Iteration 140000, Testing net (#0)
I0802 11:12:25.770706 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589176
I0802 11:12:25.770730 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818468
I0802 11:12:25.770736 18636 solver.cpp:635]     Test net output #2: loss = 1.7797 (* 1 = 1.7797 loss)
I0802 11:12:25.784838 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9198s
I0802 11:12:25.919323 18636 solver.cpp:353] Iteration 140000 (2.93907 iter/s, 34.0244s/100 iter), loss = 1.31527
I0802 11:12:25.919348 18636 solver.cpp:375]     Train net output #0: loss = 1.4923 (* 1 = 1.4923 loss)
I0802 11:12:25.919350 18636 sgd_solver.cpp:136] Iteration 140000, lr = 0.00125, m = 0.9
I0802 11:12:39.861150 18636 solver.cpp:353] Iteration 140100 (7.17286 iter/s, 13.9414s/100 iter), loss = 1.38543
I0802 11:12:39.861238 18636 solver.cpp:375]     Train net output #0: loss = 1.7424 (* 1 = 1.7424 loss)
I0802 11:12:39.861245 18636 sgd_solver.cpp:136] Iteration 140100, lr = 0.00124375, m = 0.9
I0802 11:12:53.858573 18636 solver.cpp:353] Iteration 140200 (7.14437 iter/s, 13.997s/100 iter), loss = 1.60482
I0802 11:12:53.858603 18636 solver.cpp:375]     Train net output #0: loss = 1.98419 (* 1 = 1.98419 loss)
I0802 11:12:53.858610 18636 sgd_solver.cpp:136] Iteration 140200, lr = 0.0012375, m = 0.9
I0802 11:13:07.967780 18636 solver.cpp:353] Iteration 140300 (7.08777 iter/s, 14.1088s/100 iter), loss = 1.33943
I0802 11:13:07.967806 18636 solver.cpp:375]     Train net output #0: loss = 1.58867 (* 1 = 1.58867 loss)
I0802 11:13:07.967811 18636 sgd_solver.cpp:136] Iteration 140300, lr = 0.00123125, m = 0.9
I0802 11:13:22.003746 18636 solver.cpp:353] Iteration 140400 (7.12475 iter/s, 14.0356s/100 iter), loss = 1.63441
I0802 11:13:22.003810 18636 solver.cpp:375]     Train net output #0: loss = 1.63779 (* 1 = 1.63779 loss)
I0802 11:13:22.003818 18636 sgd_solver.cpp:136] Iteration 140400, lr = 0.001225, m = 0.9
I0802 11:13:36.071707 18636 solver.cpp:353] Iteration 140500 (7.10855 iter/s, 14.0676s/100 iter), loss = 1.48672
I0802 11:13:36.071737 18636 solver.cpp:375]     Train net output #0: loss = 1.64292 (* 1 = 1.64292 loss)
I0802 11:13:36.071789 18636 sgd_solver.cpp:136] Iteration 140500, lr = 0.00121875, m = 0.9
I0802 11:13:50.267091 18636 solver.cpp:353] Iteration 140600 (7.04474 iter/s, 14.195s/100 iter), loss = 1.53328
I0802 11:13:50.267115 18636 solver.cpp:375]     Train net output #0: loss = 1.48452 (* 1 = 1.48452 loss)
I0802 11:13:50.267119 18636 sgd_solver.cpp:136] Iteration 140600, lr = 0.0012125, m = 0.9
I0802 11:14:04.349267 18636 solver.cpp:353] Iteration 140700 (7.10137 iter/s, 14.0818s/100 iter), loss = 1.40747
I0802 11:14:04.349341 18636 solver.cpp:375]     Train net output #0: loss = 1.08233 (* 1 = 1.08233 loss)
I0802 11:14:04.349349 18636 sgd_solver.cpp:136] Iteration 140700, lr = 0.00120625, m = 0.9
I0802 11:14:18.515189 18636 solver.cpp:353] Iteration 140800 (7.05939 iter/s, 14.1655s/100 iter), loss = 1.40008
I0802 11:14:18.515223 18636 solver.cpp:375]     Train net output #0: loss = 1.48653 (* 1 = 1.48653 loss)
I0802 11:14:18.515295 18636 sgd_solver.cpp:136] Iteration 140800, lr = 0.0012, m = 0.9
I0802 11:14:32.622336 18636 solver.cpp:353] Iteration 140900 (7.0888 iter/s, 14.1068s/100 iter), loss = 1.64201
I0802 11:14:32.622426 18636 solver.cpp:375]     Train net output #0: loss = 1.68974 (* 1 = 1.68974 loss)
I0802 11:14:32.622452 18636 sgd_solver.cpp:136] Iteration 140900, lr = 0.00119375, m = 0.9
I0802 11:14:46.501168 18636 solver.cpp:404] Sparsity after update:
I0802 11:14:46.515219 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:14:46.515236 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:14:46.515242 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:14:46.515244 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:14:46.515246 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:14:46.515249 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:14:46.515250 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:14:46.515252 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:14:46.515254 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:14:46.515256 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:14:46.515259 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:14:46.515260 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:14:46.515262 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:14:46.647114 18636 solver.cpp:353] Iteration 141000 (7.13043 iter/s, 14.0244s/100 iter), loss = 1.43087
I0802 11:14:46.647142 18636 solver.cpp:375]     Train net output #0: loss = 1.12432 (* 1 = 1.12432 loss)
I0802 11:14:46.647148 18636 sgd_solver.cpp:136] Iteration 141000, lr = 0.0011875, m = 0.9
I0802 11:15:00.610615 18636 solver.cpp:353] Iteration 141100 (7.16173 iter/s, 13.9631s/100 iter), loss = 1.58005
I0802 11:15:00.610709 18636 solver.cpp:375]     Train net output #0: loss = 2.3339 (* 1 = 2.3339 loss)
I0802 11:15:00.610728 18636 sgd_solver.cpp:136] Iteration 141100, lr = 0.00118125, m = 0.9
I0802 11:15:14.561875 18636 solver.cpp:353] Iteration 141200 (7.16801 iter/s, 13.9509s/100 iter), loss = 1.67332
I0802 11:15:14.561904 18636 solver.cpp:375]     Train net output #0: loss = 1.48681 (* 1 = 1.48681 loss)
I0802 11:15:14.561909 18636 sgd_solver.cpp:136] Iteration 141200, lr = 0.001175, m = 0.9
I0802 11:15:28.606899 18636 solver.cpp:353] Iteration 141300 (7.12016 iter/s, 14.0446s/100 iter), loss = 1.41926
I0802 11:15:28.607012 18636 solver.cpp:375]     Train net output #0: loss = 1.17212 (* 1 = 1.17212 loss)
I0802 11:15:28.607024 18636 sgd_solver.cpp:136] Iteration 141300, lr = 0.00116875, m = 0.9
I0802 11:15:42.522994 18636 solver.cpp:353] Iteration 141400 (7.18612 iter/s, 13.9157s/100 iter), loss = 1.39366
I0802 11:15:42.523028 18636 solver.cpp:375]     Train net output #0: loss = 1.49053 (* 1 = 1.49053 loss)
I0802 11:15:42.523036 18636 sgd_solver.cpp:136] Iteration 141400, lr = 0.0011625, m = 0.9
I0802 11:15:56.565964 18636 solver.cpp:353] Iteration 141500 (7.1212 iter/s, 14.0426s/100 iter), loss = 1.51274
I0802 11:15:56.566062 18636 solver.cpp:375]     Train net output #0: loss = 1.41114 (* 1 = 1.41114 loss)
I0802 11:15:56.566088 18636 sgd_solver.cpp:136] Iteration 141500, lr = 0.00115625, m = 0.9
I0802 11:16:10.634734 18636 solver.cpp:353] Iteration 141600 (7.10814 iter/s, 14.0684s/100 iter), loss = 1.60164
I0802 11:16:10.634852 18636 solver.cpp:375]     Train net output #0: loss = 1.64332 (* 1 = 1.64332 loss)
I0802 11:16:10.634876 18636 sgd_solver.cpp:136] Iteration 141600, lr = 0.00115, m = 0.9
I0802 11:16:24.594013 18636 solver.cpp:353] Iteration 141700 (7.16389 iter/s, 13.9589s/100 iter), loss = 1.39293
I0802 11:16:24.594040 18636 solver.cpp:375]     Train net output #0: loss = 1.40206 (* 1 = 1.40206 loss)
I0802 11:16:24.594045 18636 sgd_solver.cpp:136] Iteration 141700, lr = 0.00114375, m = 0.9
I0802 11:16:38.694725 18636 solver.cpp:353] Iteration 141800 (7.09204 iter/s, 14.1003s/100 iter), loss = 1.07753
I0802 11:16:38.694805 18636 solver.cpp:375]     Train net output #0: loss = 1.1988 (* 1 = 1.1988 loss)
I0802 11:16:38.694828 18636 sgd_solver.cpp:136] Iteration 141800, lr = 0.0011375, m = 0.9
I0802 11:16:52.749698 18636 solver.cpp:353] Iteration 141900 (7.11511 iter/s, 14.0546s/100 iter), loss = 1.57563
I0802 11:16:52.750000 18636 solver.cpp:375]     Train net output #0: loss = 1.17026 (* 1 = 1.17026 loss)
I0802 11:16:52.750110 18636 sgd_solver.cpp:136] Iteration 141900, lr = 0.00113125, m = 0.9
I0802 11:17:06.627187 18636 solver.cpp:404] Sparsity after update:
I0802 11:17:06.631189 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:17:06.631219 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:17:06.631235 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:17:06.631245 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:17:06.631254 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:17:06.631263 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:17:06.631273 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:17:06.631281 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:17:06.631290 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:17:06.631299 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:17:06.631309 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:17:06.631317 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:17:06.631326 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:17:06.631343 18636 solver.cpp:550] Iteration 142000, Testing net (#0)
I0802 11:17:26.642571 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.589823
I0802 11:17:26.642675 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818996
I0802 11:17:26.642684 18636 solver.cpp:635]     Test net output #2: loss = 1.76149 (* 1 = 1.76149 loss)
I0802 11:17:26.642704 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0108s
I0802 11:17:26.794104 18636 solver.cpp:353] Iteration 142000 (2.93742 iter/s, 34.0435s/100 iter), loss = 1.42292
I0802 11:17:26.794129 18636 solver.cpp:375]     Train net output #0: loss = 1.63501 (* 1 = 1.63501 loss)
I0802 11:17:26.794136 18636 sgd_solver.cpp:136] Iteration 142000, lr = 0.001125, m = 0.9
I0802 11:17:40.761147 18636 solver.cpp:353] Iteration 142100 (7.15991 iter/s, 13.9667s/100 iter), loss = 1.28774
I0802 11:17:40.761174 18636 solver.cpp:375]     Train net output #0: loss = 1.18999 (* 1 = 1.18999 loss)
I0802 11:17:40.761180 18636 sgd_solver.cpp:136] Iteration 142100, lr = 0.00111875, m = 0.9
I0802 11:17:54.731523 18636 solver.cpp:353] Iteration 142200 (7.1582 iter/s, 13.97s/100 iter), loss = 1.47519
I0802 11:17:54.731554 18636 solver.cpp:375]     Train net output #0: loss = 1.56781 (* 1 = 1.56781 loss)
I0802 11:17:54.731560 18636 sgd_solver.cpp:136] Iteration 142200, lr = 0.0011125, m = 0.9
I0802 11:18:08.659237 18636 solver.cpp:353] Iteration 142300 (7.18013 iter/s, 13.9273s/100 iter), loss = 1.2544
I0802 11:18:08.659298 18636 solver.cpp:375]     Train net output #0: loss = 1.27399 (* 1 = 1.27399 loss)
I0802 11:18:08.659307 18636 sgd_solver.cpp:136] Iteration 142300, lr = 0.00110625, m = 0.9
I0802 11:18:22.675796 18636 solver.cpp:353] Iteration 142400 (7.13462 iter/s, 14.0162s/100 iter), loss = 1.24946
I0802 11:18:22.675886 18636 solver.cpp:375]     Train net output #0: loss = 1.47291 (* 1 = 1.47291 loss)
I0802 11:18:22.675912 18636 sgd_solver.cpp:136] Iteration 142400, lr = 0.0011, m = 0.9
I0802 11:18:36.760824 18636 solver.cpp:353] Iteration 142500 (7.09993 iter/s, 14.0846s/100 iter), loss = 1.69797
I0802 11:18:36.760848 18636 solver.cpp:375]     Train net output #0: loss = 1.6587 (* 1 = 1.6587 loss)
I0802 11:18:36.760854 18636 sgd_solver.cpp:136] Iteration 142500, lr = 0.00109375, m = 0.9
I0802 11:18:50.660125 18636 solver.cpp:353] Iteration 142600 (7.1948 iter/s, 13.8989s/100 iter), loss = 1.46242
I0802 11:18:50.660223 18636 solver.cpp:375]     Train net output #0: loss = 1.29453 (* 1 = 1.29453 loss)
I0802 11:18:50.660231 18636 sgd_solver.cpp:136] Iteration 142600, lr = 0.0010875, m = 0.9
I0802 11:19:04.674456 18636 solver.cpp:353] Iteration 142700 (7.13575 iter/s, 14.0139s/100 iter), loss = 1.19167
I0802 11:19:04.674487 18636 solver.cpp:375]     Train net output #0: loss = 0.94524 (* 1 = 0.94524 loss)
I0802 11:19:04.674491 18636 sgd_solver.cpp:136] Iteration 142700, lr = 0.00108125, m = 0.9
I0802 11:19:18.689563 18636 solver.cpp:353] Iteration 142800 (7.13536 iter/s, 14.0147s/100 iter), loss = 1.35245
I0802 11:19:18.689599 18636 solver.cpp:375]     Train net output #0: loss = 1.27591 (* 1 = 1.27591 loss)
I0802 11:19:18.689604 18636 sgd_solver.cpp:136] Iteration 142800, lr = 0.001075, m = 0.9
I0802 11:19:32.651149 18636 solver.cpp:353] Iteration 142900 (7.16271 iter/s, 13.9612s/100 iter), loss = 1.56554
I0802 11:19:32.651231 18636 solver.cpp:375]     Train net output #0: loss = 1.80321 (* 1 = 1.80321 loss)
I0802 11:19:32.651237 18636 sgd_solver.cpp:136] Iteration 142900, lr = 0.00106875, m = 0.9
I0802 11:19:46.591547 18636 solver.cpp:404] Sparsity after update:
I0802 11:19:46.605845 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:19:46.605864 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:19:46.605872 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:19:46.605875 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:19:46.605878 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:19:46.605882 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:19:46.605893 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:19:46.605901 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:19:46.605911 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:19:46.605918 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:19:46.605926 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:19:46.605942 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:19:46.605947 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:19:46.735455 18636 solver.cpp:353] Iteration 143000 (7.1003 iter/s, 14.0839s/100 iter), loss = 1.27104
I0802 11:19:46.735522 18636 solver.cpp:375]     Train net output #0: loss = 1.25462 (* 1 = 1.25462 loss)
I0802 11:19:46.735540 18636 sgd_solver.cpp:136] Iteration 143000, lr = 0.0010625, m = 0.9
I0802 11:20:00.723748 18636 solver.cpp:353] Iteration 143100 (7.14903 iter/s, 13.9879s/100 iter), loss = 1.34048
I0802 11:20:00.723778 18636 solver.cpp:375]     Train net output #0: loss = 0.970854 (* 1 = 0.970854 loss)
I0802 11:20:00.723784 18636 sgd_solver.cpp:136] Iteration 143100, lr = 0.00105625, m = 0.9
I0802 11:20:14.639871 18636 solver.cpp:353] Iteration 143200 (7.18611 iter/s, 13.9157s/100 iter), loss = 1.32331
I0802 11:20:14.639925 18636 solver.cpp:375]     Train net output #0: loss = 1.43876 (* 1 = 1.43876 loss)
I0802 11:20:14.639930 18636 sgd_solver.cpp:136] Iteration 143200, lr = 0.00105, m = 0.9
I0802 11:20:28.731055 18636 solver.cpp:353] Iteration 143300 (7.09683 iter/s, 14.0908s/100 iter), loss = 1.39758
I0802 11:20:28.731083 18636 solver.cpp:375]     Train net output #0: loss = 0.999909 (* 1 = 0.999909 loss)
I0802 11:20:28.731089 18636 sgd_solver.cpp:136] Iteration 143300, lr = 0.00104375, m = 0.9
I0802 11:20:42.604496 18636 solver.cpp:353] Iteration 143400 (7.20822 iter/s, 13.8731s/100 iter), loss = 1.38181
I0802 11:20:42.604521 18636 solver.cpp:375]     Train net output #0: loss = 1.55951 (* 1 = 1.55951 loss)
I0802 11:20:42.604526 18636 sgd_solver.cpp:136] Iteration 143400, lr = 0.0010375, m = 0.9
I0802 11:20:56.627651 18636 solver.cpp:353] Iteration 143500 (7.13126 iter/s, 14.0228s/100 iter), loss = 1.14685
I0802 11:20:56.627748 18636 solver.cpp:375]     Train net output #0: loss = 1.32042 (* 1 = 1.32042 loss)
I0802 11:20:56.627763 18636 sgd_solver.cpp:136] Iteration 143500, lr = 0.00103125, m = 0.9
I0802 11:21:10.641834 18636 solver.cpp:353] Iteration 143600 (7.13583 iter/s, 14.0138s/100 iter), loss = 1.71948
I0802 11:21:10.641861 18636 solver.cpp:375]     Train net output #0: loss = 1.37679 (* 1 = 1.37679 loss)
I0802 11:21:10.641866 18636 sgd_solver.cpp:136] Iteration 143600, lr = 0.001025, m = 0.9
I0802 11:21:24.634057 18636 solver.cpp:353] Iteration 143700 (7.14702 iter/s, 13.9918s/100 iter), loss = 1.32405
I0802 11:21:24.634081 18636 solver.cpp:375]     Train net output #0: loss = 1.62347 (* 1 = 1.62347 loss)
I0802 11:21:24.634088 18636 sgd_solver.cpp:136] Iteration 143700, lr = 0.00101875, m = 0.9
I0802 11:21:38.583900 18636 solver.cpp:353] Iteration 143800 (7.16874 iter/s, 13.9495s/100 iter), loss = 1.1563
I0802 11:21:38.584347 18636 solver.cpp:375]     Train net output #0: loss = 0.979246 (* 1 = 0.979246 loss)
I0802 11:21:38.584355 18636 sgd_solver.cpp:136] Iteration 143800, lr = 0.0010125, m = 0.9
I0802 11:21:52.650717 18636 solver.cpp:353] Iteration 143900 (7.10912 iter/s, 14.0664s/100 iter), loss = 1.6055
I0802 11:21:52.650745 18636 solver.cpp:375]     Train net output #0: loss = 1.12546 (* 1 = 1.12546 loss)
I0802 11:21:52.650753 18636 sgd_solver.cpp:136] Iteration 143900, lr = 0.00100625, m = 0.9
I0802 11:22:06.692282 18636 solver.cpp:404] Sparsity after update:
I0802 11:22:06.696590 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:22:06.696602 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:22:06.696611 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:22:06.696614 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:22:06.696617 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:22:06.696633 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:22:06.696650 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:22:06.696658 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:22:06.696667 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:22:06.696676 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:22:06.696684 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:22:06.696693 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:22:06.696702 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:22:06.696718 18636 solver.cpp:550] Iteration 144000, Testing net (#0)
I0802 11:22:17.183061 18619 data_reader.cpp:264] Starting prefetch of epoch 7
I0802 11:22:18.208210 18636 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:22:26.156183 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.591941
I0802 11:22:26.156208 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.819644
I0802 11:22:26.156215 18636 solver.cpp:635]     Test net output #2: loss = 1.78087 (* 1 = 1.78087 loss)
I0802 11:22:26.156296 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.459s
I0802 11:22:26.302522 18636 solver.cpp:353] Iteration 144000 (2.97169 iter/s, 33.6509s/100 iter), loss = 1.33317
I0802 11:22:26.302567 18636 solver.cpp:375]     Train net output #0: loss = 1.43983 (* 1 = 1.43983 loss)
I0802 11:22:26.302579 18636 sgd_solver.cpp:136] Iteration 144000, lr = 0.001, m = 0.9
I0802 11:22:40.279929 18636 solver.cpp:353] Iteration 144100 (7.1546 iter/s, 13.977s/100 iter), loss = 1.16617
I0802 11:22:40.279955 18636 solver.cpp:375]     Train net output #0: loss = 1.01862 (* 1 = 1.01862 loss)
I0802 11:22:40.279960 18636 sgd_solver.cpp:136] Iteration 144100, lr = 0.00099375, m = 0.9
I0802 11:22:54.261903 18636 solver.cpp:353] Iteration 144200 (7.15227 iter/s, 13.9816s/100 iter), loss = 1.58703
I0802 11:22:54.262033 18636 solver.cpp:375]     Train net output #0: loss = 1.37896 (* 1 = 1.37896 loss)
I0802 11:22:54.262040 18636 sgd_solver.cpp:136] Iteration 144200, lr = 0.0009875, m = 0.9
I0802 11:23:08.336942 18636 solver.cpp:353] Iteration 144300 (7.10497 iter/s, 14.0747s/100 iter), loss = 1.48206
I0802 11:23:08.336971 18636 solver.cpp:375]     Train net output #0: loss = 2.26298 (* 1 = 2.26298 loss)
I0802 11:23:08.336977 18636 sgd_solver.cpp:136] Iteration 144300, lr = 0.00098125, m = 0.9
I0802 11:23:22.520958 18636 solver.cpp:353] Iteration 144400 (7.05038 iter/s, 14.1836s/100 iter), loss = 1.3419
I0802 11:23:22.520987 18636 solver.cpp:375]     Train net output #0: loss = 1.48125 (* 1 = 1.48125 loss)
I0802 11:23:22.520992 18636 sgd_solver.cpp:136] Iteration 144400, lr = 0.000975, m = 0.9
I0802 11:23:36.527294 18636 solver.cpp:353] Iteration 144500 (7.13982 iter/s, 14.0059s/100 iter), loss = 1.0434
I0802 11:23:36.527369 18636 solver.cpp:375]     Train net output #0: loss = 0.98397 (* 1 = 0.98397 loss)
I0802 11:23:36.527375 18636 sgd_solver.cpp:136] Iteration 144500, lr = 0.00096875, m = 0.9
I0802 11:23:50.506899 18636 solver.cpp:353] Iteration 144600 (7.15348 iter/s, 13.9792s/100 iter), loss = 1.23236
I0802 11:23:50.506923 18636 solver.cpp:375]     Train net output #0: loss = 1.44325 (* 1 = 1.44325 loss)
I0802 11:23:50.506927 18636 sgd_solver.cpp:136] Iteration 144600, lr = 0.0009625, m = 0.9
I0802 11:24:04.517333 18636 solver.cpp:353] Iteration 144700 (7.13774 iter/s, 14.01s/100 iter), loss = 1.10314
I0802 11:24:04.517359 18636 solver.cpp:375]     Train net output #0: loss = 1.35401 (* 1 = 1.35401 loss)
I0802 11:24:04.517365 18636 sgd_solver.cpp:136] Iteration 144700, lr = 0.00095625, m = 0.9
I0802 11:24:18.490977 18636 solver.cpp:353] Iteration 144800 (7.15653 iter/s, 13.9733s/100 iter), loss = 1.31775
I0802 11:24:18.491063 18636 solver.cpp:375]     Train net output #0: loss = 1.46925 (* 1 = 1.46925 loss)
I0802 11:24:18.491070 18636 sgd_solver.cpp:136] Iteration 144800, lr = 0.00095, m = 0.9
I0802 11:24:32.738629 18636 solver.cpp:353] Iteration 144900 (7.01889 iter/s, 14.2473s/100 iter), loss = 1.6966
I0802 11:24:32.738656 18636 solver.cpp:375]     Train net output #0: loss = 1.74494 (* 1 = 1.74494 loss)
I0802 11:24:32.738661 18636 sgd_solver.cpp:136] Iteration 144900, lr = 0.00094375, m = 0.9
I0802 11:24:46.815779 18636 solver.cpp:404] Sparsity after update:
I0802 11:24:46.831048 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:24:46.831060 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:24:46.831068 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:24:46.831069 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:24:46.831071 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:24:46.831073 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:24:46.831075 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:24:46.831077 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:24:46.831079 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:24:46.831081 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:24:46.831084 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:24:46.831089 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:24:46.831091 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:24:46.960371 18636 solver.cpp:353] Iteration 145000 (7.03168 iter/s, 14.2214s/100 iter), loss = 1.12562
I0802 11:24:46.960398 18636 solver.cpp:375]     Train net output #0: loss = 1.27206 (* 1 = 1.27206 loss)
I0802 11:24:46.960404 18636 sgd_solver.cpp:136] Iteration 145000, lr = 0.0009375, m = 0.9
I0802 11:25:00.998283 18636 solver.cpp:353] Iteration 145100 (7.12376 iter/s, 14.0375s/100 iter), loss = 1.5004
I0802 11:25:00.998345 18636 solver.cpp:375]     Train net output #0: loss = 1.65358 (* 1 = 1.65358 loss)
I0802 11:25:00.998353 18636 sgd_solver.cpp:136] Iteration 145100, lr = 0.00093125, m = 0.9
I0802 11:25:15.250144 18636 solver.cpp:353] Iteration 145200 (7.01682 iter/s, 14.2515s/100 iter), loss = 1.31789
I0802 11:25:15.250174 18636 solver.cpp:375]     Train net output #0: loss = 1.8524 (* 1 = 1.8524 loss)
I0802 11:25:15.250178 18636 sgd_solver.cpp:136] Iteration 145200, lr = 0.000925, m = 0.9
I0802 11:25:29.329699 18636 solver.cpp:353] Iteration 145300 (7.10269 iter/s, 14.0792s/100 iter), loss = 1.72259
I0802 11:25:29.329728 18636 solver.cpp:375]     Train net output #0: loss = 2.01006 (* 1 = 2.01006 loss)
I0802 11:25:29.329735 18636 sgd_solver.cpp:136] Iteration 145300, lr = 0.00091875, m = 0.9
I0802 11:25:43.569835 18636 solver.cpp:353] Iteration 145400 (7.0226 iter/s, 14.2397s/100 iter), loss = 1.40516
I0802 11:25:43.569923 18636 solver.cpp:375]     Train net output #0: loss = 1.33604 (* 1 = 1.33604 loss)
I0802 11:25:43.569929 18636 sgd_solver.cpp:136] Iteration 145400, lr = 0.0009125, m = 0.9
I0802 11:25:57.459067 18636 solver.cpp:353] Iteration 145500 (7.20002 iter/s, 13.8888s/100 iter), loss = 1.25875
I0802 11:25:57.459092 18636 solver.cpp:375]     Train net output #0: loss = 1.158 (* 1 = 1.158 loss)
I0802 11:25:57.459096 18636 sgd_solver.cpp:136] Iteration 145500, lr = 0.00090625, m = 0.9
I0802 11:26:11.490809 18636 solver.cpp:353] Iteration 145600 (7.1269 iter/s, 14.0314s/100 iter), loss = 1.33435
I0802 11:26:11.490833 18636 solver.cpp:375]     Train net output #0: loss = 1.70921 (* 1 = 1.70921 loss)
I0802 11:26:11.490839 18636 sgd_solver.cpp:136] Iteration 145600, lr = 0.0009, m = 0.9
I0802 11:26:25.429002 18636 solver.cpp:353] Iteration 145700 (7.17473 iter/s, 13.9378s/100 iter), loss = 1.48368
I0802 11:26:25.429083 18636 solver.cpp:375]     Train net output #0: loss = 1.42845 (* 1 = 1.42845 loss)
I0802 11:26:25.429090 18636 sgd_solver.cpp:136] Iteration 145700, lr = 0.00089375, m = 0.9
I0802 11:26:39.423571 18636 solver.cpp:353] Iteration 145800 (7.14583 iter/s, 13.9942s/100 iter), loss = 1.40255
I0802 11:26:39.423604 18636 solver.cpp:375]     Train net output #0: loss = 1.49684 (* 1 = 1.49684 loss)
I0802 11:26:39.423610 18636 sgd_solver.cpp:136] Iteration 145800, lr = 0.0008875, m = 0.9
I0802 11:26:53.457383 18636 solver.cpp:353] Iteration 145900 (7.12585 iter/s, 14.0334s/100 iter), loss = 1.92962
I0802 11:26:53.457417 18636 solver.cpp:375]     Train net output #0: loss = 2.03531 (* 1 = 2.03531 loss)
I0802 11:26:53.457422 18636 sgd_solver.cpp:136] Iteration 145900, lr = 0.00088125, m = 0.9
I0802 11:27:07.243315 18636 solver.cpp:404] Sparsity after update:
I0802 11:27:07.248476 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:27:07.248654 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:27:07.248755 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:27:07.248852 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:27:07.248944 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:27:07.249039 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:27:07.249155 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:27:07.249228 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:27:07.249245 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:27:07.249260 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:27:07.249275 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:27:07.249290 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:27:07.249305 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:27:07.249337 18636 solver.cpp:550] Iteration 146000, Testing net (#0)
I0802 11:27:26.737860 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.595117
I0802 11:27:26.737885 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.82235
I0802 11:27:26.737890 18636 solver.cpp:635]     Test net output #2: loss = 1.75301 (* 1 = 1.75301 loss)
I0802 11:27:26.738116 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4882s
I0802 11:27:26.874523 18636 solver.cpp:353] Iteration 146000 (2.99256 iter/s, 33.4162s/100 iter), loss = 1.23914
I0802 11:27:26.874552 18636 solver.cpp:375]     Train net output #0: loss = 1.22793 (* 1 = 1.22793 loss)
I0802 11:27:26.874615 18636 sgd_solver.cpp:136] Iteration 146000, lr = 0.000875, m = 0.9
I0802 11:27:40.817167 18636 solver.cpp:353] Iteration 146100 (7.17244 iter/s, 13.9423s/100 iter), loss = 1.08719
I0802 11:27:40.817291 18636 solver.cpp:375]     Train net output #0: loss = 0.798414 (* 1 = 0.798414 loss)
I0802 11:27:40.817311 18636 sgd_solver.cpp:136] Iteration 146100, lr = 0.00086875, m = 0.9
I0802 11:27:54.739648 18636 solver.cpp:353] Iteration 146200 (7.18283 iter/s, 13.9221s/100 iter), loss = 1.11924
I0802 11:27:54.739681 18636 solver.cpp:375]     Train net output #0: loss = 1.3272 (* 1 = 1.3272 loss)
I0802 11:27:54.739687 18636 sgd_solver.cpp:136] Iteration 146200, lr = 0.0008625, m = 0.9
I0802 11:28:08.592671 18636 solver.cpp:353] Iteration 146300 (7.21884 iter/s, 13.8526s/100 iter), loss = 1.19014
I0802 11:28:08.592700 18636 solver.cpp:375]     Train net output #0: loss = 1.23571 (* 1 = 1.23571 loss)
I0802 11:28:08.592706 18636 sgd_solver.cpp:136] Iteration 146300, lr = 0.00085625, m = 0.9
I0802 11:28:22.627697 18636 solver.cpp:353] Iteration 146400 (7.12523 iter/s, 14.0346s/100 iter), loss = 1.62929
I0802 11:28:22.627758 18636 solver.cpp:375]     Train net output #0: loss = 1.70528 (* 1 = 1.70528 loss)
I0802 11:28:22.627763 18636 sgd_solver.cpp:136] Iteration 146400, lr = 0.00085, m = 0.9
I0802 11:28:36.517572 18636 solver.cpp:353] Iteration 146500 (7.19969 iter/s, 13.8895s/100 iter), loss = 1.18751
I0802 11:28:36.517666 18636 solver.cpp:375]     Train net output #0: loss = 1.11464 (* 1 = 1.11464 loss)
I0802 11:28:36.517688 18636 sgd_solver.cpp:136] Iteration 146500, lr = 0.00084375, m = 0.9
I0802 11:28:50.423141 18636 solver.cpp:353] Iteration 146600 (7.19156 iter/s, 13.9052s/100 iter), loss = 1.61013
I0802 11:28:50.423171 18636 solver.cpp:375]     Train net output #0: loss = 1.57835 (* 1 = 1.57835 loss)
I0802 11:28:50.423177 18636 sgd_solver.cpp:136] Iteration 146600, lr = 0.0008375, m = 0.9
I0802 11:29:04.421890 18636 solver.cpp:353] Iteration 146700 (7.14369 iter/s, 13.9984s/100 iter), loss = 1.38296
I0802 11:29:04.422013 18636 solver.cpp:375]     Train net output #0: loss = 1.6254 (* 1 = 1.6254 loss)
I0802 11:29:04.422032 18636 sgd_solver.cpp:136] Iteration 146700, lr = 0.00083125, m = 0.9
I0802 11:29:18.452179 18636 solver.cpp:353] Iteration 146800 (7.12763 iter/s, 14.0299s/100 iter), loss = 1.55365
I0802 11:29:18.452206 18636 solver.cpp:375]     Train net output #0: loss = 1.79012 (* 1 = 1.79012 loss)
I0802 11:29:18.452211 18636 sgd_solver.cpp:136] Iteration 146800, lr = 0.000825, m = 0.9
I0802 11:29:32.472455 18636 solver.cpp:353] Iteration 146900 (7.13273 iter/s, 14.0199s/100 iter), loss = 1.29596
I0802 11:29:32.472489 18636 solver.cpp:375]     Train net output #0: loss = 1.18621 (* 1 = 1.18621 loss)
I0802 11:29:32.472493 18636 sgd_solver.cpp:136] Iteration 146900, lr = 0.00081875, m = 0.9
I0802 11:29:46.382127 18636 solver.cpp:404] Sparsity after update:
I0802 11:29:46.396091 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:29:46.396191 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:29:46.396221 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:29:46.396239 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:29:46.396255 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:29:46.396267 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:29:46.396280 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:29:46.396291 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:29:46.396304 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:29:46.396327 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:29:46.396340 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:29:46.396353 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:29:46.396365 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:29:46.527338 18636 solver.cpp:353] Iteration 147000 (7.11516 iter/s, 14.0545s/100 iter), loss = 1.87244
I0802 11:29:46.527369 18636 solver.cpp:375]     Train net output #0: loss = 2.19166 (* 1 = 2.19166 loss)
I0802 11:29:46.527376 18636 sgd_solver.cpp:136] Iteration 147000, lr = 0.0008125, m = 0.9
I0802 11:30:00.581209 18636 solver.cpp:353] Iteration 147100 (7.11567 iter/s, 14.0535s/100 iter), loss = 1.19585
I0802 11:30:00.581265 18636 solver.cpp:375]     Train net output #0: loss = 0.910317 (* 1 = 0.910317 loss)
I0802 11:30:00.581287 18636 sgd_solver.cpp:136] Iteration 147100, lr = 0.00080625, m = 0.9
I0802 11:30:14.569136 18636 solver.cpp:353] Iteration 147200 (7.14922 iter/s, 13.9875s/100 iter), loss = 1.4624
I0802 11:30:14.569190 18636 solver.cpp:375]     Train net output #0: loss = 1.69846 (* 1 = 1.69846 loss)
I0802 11:30:14.569203 18636 sgd_solver.cpp:136] Iteration 147200, lr = 0.0008, m = 0.9
I0802 11:30:28.809895 18636 solver.cpp:353] Iteration 147300 (7.02229 iter/s, 14.2404s/100 iter), loss = 0.966283
I0802 11:30:28.809998 18636 solver.cpp:375]     Train net output #0: loss = 0.946633 (* 1 = 0.946633 loss)
I0802 11:30:28.810004 18636 sgd_solver.cpp:136] Iteration 147300, lr = 0.00079375, m = 0.9
I0802 11:30:42.891916 18636 solver.cpp:353] Iteration 147400 (7.10145 iter/s, 14.0816s/100 iter), loss = 1.37443
I0802 11:30:42.891942 18636 solver.cpp:375]     Train net output #0: loss = 1.41783 (* 1 = 1.41783 loss)
I0802 11:30:42.891947 18636 sgd_solver.cpp:136] Iteration 147400, lr = 0.0007875, m = 0.9
I0802 11:30:56.912236 18636 solver.cpp:353] Iteration 147500 (7.1327 iter/s, 14.0199s/100 iter), loss = 1.25536
I0802 11:30:56.912261 18636 solver.cpp:375]     Train net output #0: loss = 1.02847 (* 1 = 1.02847 loss)
I0802 11:30:56.912266 18636 sgd_solver.cpp:136] Iteration 147500, lr = 0.00078125, m = 0.9
I0802 11:31:10.857516 18636 solver.cpp:353] Iteration 147600 (7.17108 iter/s, 13.9449s/100 iter), loss = 1.08857
I0802 11:31:10.857591 18636 solver.cpp:375]     Train net output #0: loss = 1.26227 (* 1 = 1.26227 loss)
I0802 11:31:10.857597 18636 sgd_solver.cpp:136] Iteration 147600, lr = 0.000775, m = 0.9
I0802 11:31:24.962972 18636 solver.cpp:353] Iteration 147700 (7.08965 iter/s, 14.1051s/100 iter), loss = 1.41942
I0802 11:31:24.963001 18636 solver.cpp:375]     Train net output #0: loss = 1.4384 (* 1 = 1.4384 loss)
I0802 11:31:24.963006 18636 sgd_solver.cpp:136] Iteration 147700, lr = 0.00076875, m = 0.9
I0802 11:31:38.992924 18636 solver.cpp:353] Iteration 147800 (7.1278 iter/s, 14.0296s/100 iter), loss = 1.71926
I0802 11:31:38.992949 18636 solver.cpp:375]     Train net output #0: loss = 1.75389 (* 1 = 1.75389 loss)
I0802 11:31:38.992955 18636 sgd_solver.cpp:136] Iteration 147800, lr = 0.0007625, m = 0.9
I0802 11:31:53.295266 18636 solver.cpp:353] Iteration 147900 (6.99205 iter/s, 14.3019s/100 iter), loss = 1.47309
I0802 11:31:53.295341 18636 solver.cpp:375]     Train net output #0: loss = 1.71563 (* 1 = 1.71563 loss)
I0802 11:31:53.295347 18636 sgd_solver.cpp:136] Iteration 147900, lr = 0.00075625, m = 0.9
I0802 11:32:07.141373 18636 solver.cpp:404] Sparsity after update:
I0802 11:32:07.146383 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:32:07.146394 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:32:07.146400 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:32:07.146404 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:32:07.146406 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:32:07.146410 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:32:07.146414 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:32:07.146417 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:32:07.146421 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:32:07.146425 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:32:07.146428 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:32:07.146433 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:32:07.146436 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:32:07.146448 18636 solver.cpp:550] Iteration 148000, Testing net (#0)
I0802 11:32:26.618331 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.593235
I0802 11:32:26.618401 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.820644
I0802 11:32:26.618412 18636 solver.cpp:635]     Test net output #2: loss = 1.75509 (* 1 = 1.75509 loss)
I0802 11:32:26.618435 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.4715s
I0802 11:32:26.763950 18636 solver.cpp:353] Iteration 148000 (2.98795 iter/s, 33.4678s/100 iter), loss = 1.11303
I0802 11:32:26.763983 18636 solver.cpp:375]     Train net output #0: loss = 1.28604 (* 1 = 1.28604 loss)
I0802 11:32:26.763986 18636 sgd_solver.cpp:136] Iteration 148000, lr = 0.00075, m = 0.9
I0802 11:32:40.697044 18636 solver.cpp:353] Iteration 148100 (7.17736 iter/s, 13.9327s/100 iter), loss = 1.39559
I0802 11:32:40.697070 18636 solver.cpp:375]     Train net output #0: loss = 1.40616 (* 1 = 1.40616 loss)
I0802 11:32:40.697077 18636 sgd_solver.cpp:136] Iteration 148100, lr = 0.00074375, m = 0.9
I0802 11:32:54.835325 18636 solver.cpp:353] Iteration 148200 (7.07319 iter/s, 14.1379s/100 iter), loss = 1.01646
I0802 11:32:54.835353 18636 solver.cpp:375]     Train net output #0: loss = 1.17068 (* 1 = 1.17068 loss)
I0802 11:32:54.835361 18636 sgd_solver.cpp:136] Iteration 148200, lr = 0.0007375, m = 0.9
I0802 11:33:08.928104 18636 solver.cpp:353] Iteration 148300 (7.09603 iter/s, 14.0924s/100 iter), loss = 1.19
I0802 11:33:08.928181 18636 solver.cpp:375]     Train net output #0: loss = 1.00703 (* 1 = 1.00703 loss)
I0802 11:33:08.928189 18636 sgd_solver.cpp:136] Iteration 148300, lr = 0.00073125, m = 0.9
I0802 11:33:23.158668 18636 solver.cpp:353] Iteration 148400 (7.02732 iter/s, 14.2302s/100 iter), loss = 1.38536
I0802 11:33:23.158695 18636 solver.cpp:375]     Train net output #0: loss = 1.424 (* 1 = 1.424 loss)
I0802 11:33:23.158701 18636 sgd_solver.cpp:136] Iteration 148400, lr = 0.000725, m = 0.9
I0802 11:33:37.064863 18636 solver.cpp:353] Iteration 148500 (7.19124 iter/s, 13.9058s/100 iter), loss = 1.09853
I0802 11:33:37.064895 18636 solver.cpp:375]     Train net output #0: loss = 1.05972 (* 1 = 1.05972 loss)
I0802 11:33:37.064903 18636 sgd_solver.cpp:136] Iteration 148500, lr = 0.00071875, m = 0.9
I0802 11:33:51.066584 18636 solver.cpp:353] Iteration 148600 (7.14218 iter/s, 14.0013s/100 iter), loss = 1.40854
I0802 11:33:51.066710 18636 solver.cpp:375]     Train net output #0: loss = 1.17097 (* 1 = 1.17097 loss)
I0802 11:33:51.066730 18636 sgd_solver.cpp:136] Iteration 148600, lr = 0.0007125, m = 0.9
I0802 11:34:05.269552 18636 solver.cpp:353] Iteration 148700 (7.04098 iter/s, 14.2026s/100 iter), loss = 1.28712
I0802 11:34:05.269580 18636 solver.cpp:375]     Train net output #0: loss = 1.39642 (* 1 = 1.39642 loss)
I0802 11:34:05.269587 18636 sgd_solver.cpp:136] Iteration 148700, lr = 0.00070625, m = 0.9
I0802 11:34:19.212249 18636 solver.cpp:353] Iteration 148800 (7.17241 iter/s, 13.9423s/100 iter), loss = 1.17114
I0802 11:34:19.212280 18636 solver.cpp:375]     Train net output #0: loss = 1.16087 (* 1 = 1.16087 loss)
I0802 11:34:19.212286 18636 sgd_solver.cpp:136] Iteration 148800, lr = 0.0007, m = 0.9
I0802 11:34:33.281287 18636 solver.cpp:353] Iteration 148900 (7.108 iter/s, 14.0686s/100 iter), loss = 1.17149
I0802 11:34:33.281350 18636 solver.cpp:375]     Train net output #0: loss = 1.08011 (* 1 = 1.08011 loss)
I0802 11:34:33.281358 18636 sgd_solver.cpp:136] Iteration 148900, lr = 0.00069375, m = 0.9
I0802 11:34:47.214671 18636 solver.cpp:404] Sparsity after update:
I0802 11:34:47.225177 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:34:47.225190 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:34:47.225199 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:34:47.225203 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:34:47.225205 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:34:47.225209 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:34:47.225214 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:34:47.225217 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:34:47.225221 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:34:47.225225 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:34:47.225229 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:34:47.225232 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:34:47.225235 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:34:47.364859 18636 solver.cpp:353] Iteration 149000 (7.10067 iter/s, 14.0832s/100 iter), loss = 1.41666
I0802 11:34:47.364886 18636 solver.cpp:375]     Train net output #0: loss = 1.25952 (* 1 = 1.25952 loss)
I0802 11:34:47.364890 18636 sgd_solver.cpp:136] Iteration 149000, lr = 0.0006875, m = 0.9
I0802 11:35:01.383285 18636 solver.cpp:353] Iteration 149100 (7.13367 iter/s, 14.018s/100 iter), loss = 1.4093
I0802 11:35:01.383311 18636 solver.cpp:375]     Train net output #0: loss = 1.63157 (* 1 = 1.63157 loss)
I0802 11:35:01.383317 18636 sgd_solver.cpp:136] Iteration 149100, lr = 0.00068125, m = 0.9
I0802 11:35:15.324658 18636 solver.cpp:353] Iteration 149200 (7.17309 iter/s, 13.941s/100 iter), loss = 1.44665
I0802 11:35:15.324746 18636 solver.cpp:375]     Train net output #0: loss = 1.48443 (* 1 = 1.48443 loss)
I0802 11:35:15.324753 18636 sgd_solver.cpp:136] Iteration 149200, lr = 0.000675, m = 0.9
I0802 11:35:29.406072 18636 solver.cpp:353] Iteration 149300 (7.10175 iter/s, 14.081s/100 iter), loss = 1.31102
I0802 11:35:29.406108 18636 solver.cpp:375]     Train net output #0: loss = 1.19287 (* 1 = 1.19287 loss)
I0802 11:35:29.406114 18636 sgd_solver.cpp:136] Iteration 149300, lr = 0.00066875, m = 0.9
I0802 11:35:43.369595 18636 solver.cpp:353] Iteration 149400 (7.16171 iter/s, 13.9631s/100 iter), loss = 1.42343
I0802 11:35:43.369622 18636 solver.cpp:375]     Train net output #0: loss = 1.49325 (* 1 = 1.49325 loss)
I0802 11:35:43.369627 18636 sgd_solver.cpp:136] Iteration 149400, lr = 0.0006625, m = 0.9
I0802 11:35:57.381333 18636 solver.cpp:353] Iteration 149500 (7.13707 iter/s, 14.0114s/100 iter), loss = 1.24056
I0802 11:35:57.381407 18636 solver.cpp:375]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0802 11:35:57.381414 18636 sgd_solver.cpp:136] Iteration 149500, lr = 0.00065625, m = 0.9
I0802 11:36:11.394445 18636 solver.cpp:353] Iteration 149600 (7.13637 iter/s, 14.0127s/100 iter), loss = 1.27946
I0802 11:36:11.394472 18636 solver.cpp:375]     Train net output #0: loss = 1.45157 (* 1 = 1.45157 loss)
I0802 11:36:11.394479 18636 sgd_solver.cpp:136] Iteration 149600, lr = 0.00065, m = 0.9
I0802 11:36:25.301125 18636 solver.cpp:353] Iteration 149700 (7.19099 iter/s, 13.9063s/100 iter), loss = 1.37463
I0802 11:36:25.301200 18636 solver.cpp:375]     Train net output #0: loss = 1.15878 (* 1 = 1.15878 loss)
I0802 11:36:25.301223 18636 sgd_solver.cpp:136] Iteration 149700, lr = 0.00064375, m = 0.9
I0802 11:36:39.298321 18636 solver.cpp:353] Iteration 149800 (7.14448 iter/s, 13.9968s/100 iter), loss = 1.14414
I0802 11:36:39.298400 18636 solver.cpp:375]     Train net output #0: loss = 1.24349 (* 1 = 1.24349 loss)
I0802 11:36:39.298408 18636 sgd_solver.cpp:136] Iteration 149800, lr = 0.0006375, m = 0.9
I0802 11:36:53.264767 18636 solver.cpp:353] Iteration 149900 (7.16021 iter/s, 13.9661s/100 iter), loss = 1.31889
I0802 11:36:53.264796 18636 solver.cpp:375]     Train net output #0: loss = 1.38855 (* 1 = 1.38855 loss)
I0802 11:36:53.264802 18636 sgd_solver.cpp:136] Iteration 149900, lr = 0.00063125, m = 0.9
I0802 11:37:07.049062 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_150000.caffemodel
I0802 11:37:07.139809 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_150000.solverstate
I0802 11:37:07.146023 18636 solver.cpp:404] Sparsity after update:
I0802 11:37:07.149183 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:37:07.149211 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:37:07.149230 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:37:07.149240 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:37:07.149248 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:37:07.149258 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:37:07.149269 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:37:07.149278 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:37:07.149287 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:37:07.149300 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:37:07.149308 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:37:07.149317 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:37:07.149325 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:37:07.149344 18636 solver.cpp:550] Iteration 150000, Testing net (#0)
I0802 11:37:20.965715 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:37:26.857408 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.594235
I0802 11:37:26.857434 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.820997
I0802 11:37:26.857439 18636 solver.cpp:635]     Test net output #2: loss = 1.76753 (* 1 = 1.76753 loss)
I0802 11:37:26.857460 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7076s
I0802 11:37:27.022351 18636 solver.cpp:353] Iteration 150000 (2.96238 iter/s, 33.7567s/100 iter), loss = 1.26078
I0802 11:37:27.022378 18636 solver.cpp:375]     Train net output #0: loss = 1.3744 (* 1 = 1.3744 loss)
I0802 11:37:27.022384 18636 sgd_solver.cpp:136] Iteration 150000, lr = 0.000625, m = 0.9
I0802 11:37:41.046640 18636 solver.cpp:353] Iteration 150100 (7.13069 iter/s, 14.0239s/100 iter), loss = 1.0329
I0802 11:37:41.046674 18636 solver.cpp:375]     Train net output #0: loss = 1.14736 (* 1 = 1.14736 loss)
I0802 11:37:41.046680 18636 sgd_solver.cpp:136] Iteration 150100, lr = 0.00061875, m = 0.9
I0802 11:37:55.126945 18636 solver.cpp:353] Iteration 150200 (7.10231 iter/s, 14.0799s/100 iter), loss = 1.23432
I0802 11:37:55.126999 18636 solver.cpp:375]     Train net output #0: loss = 1.31091 (* 1 = 1.31091 loss)
I0802 11:37:55.127005 18636 sgd_solver.cpp:136] Iteration 150200, lr = 0.0006125, m = 0.9
I0802 11:38:09.102627 18636 solver.cpp:353] Iteration 150300 (7.15548 iter/s, 13.9753s/100 iter), loss = 1.19774
I0802 11:38:09.102653 18636 solver.cpp:375]     Train net output #0: loss = 1.03457 (* 1 = 1.03457 loss)
I0802 11:38:09.102658 18636 sgd_solver.cpp:136] Iteration 150300, lr = 0.00060625, m = 0.9
I0802 11:38:22.994369 18636 solver.cpp:353] Iteration 150400 (7.19872 iter/s, 13.8914s/100 iter), loss = 1.35344
I0802 11:38:22.994405 18636 solver.cpp:375]     Train net output #0: loss = 1.35564 (* 1 = 1.35564 loss)
I0802 11:38:22.994410 18636 sgd_solver.cpp:136] Iteration 150400, lr = 0.0006, m = 0.9
I0802 11:38:36.867291 18636 solver.cpp:353] Iteration 150500 (7.20849 iter/s, 13.8725s/100 iter), loss = 1.26955
I0802 11:38:36.867394 18636 solver.cpp:375]     Train net output #0: loss = 1.23964 (* 1 = 1.23964 loss)
I0802 11:38:36.867413 18636 sgd_solver.cpp:136] Iteration 150500, lr = 0.00059375, m = 0.9
I0802 11:38:50.771713 18636 solver.cpp:353] Iteration 150600 (7.19215 iter/s, 13.904s/100 iter), loss = 1.16902
I0802 11:38:50.771739 18636 solver.cpp:375]     Train net output #0: loss = 1.25418 (* 1 = 1.25418 loss)
I0802 11:38:50.771742 18636 sgd_solver.cpp:136] Iteration 150600, lr = 0.0005875, m = 0.9
I0802 11:39:04.686683 18636 solver.cpp:353] Iteration 150700 (7.1867 iter/s, 13.9146s/100 iter), loss = 1.32402
I0802 11:39:04.686708 18636 solver.cpp:375]     Train net output #0: loss = 1.5675 (* 1 = 1.5675 loss)
I0802 11:39:04.686714 18636 sgd_solver.cpp:136] Iteration 150700, lr = 0.00058125, m = 0.9
I0802 11:39:18.669878 18636 solver.cpp:353] Iteration 150800 (7.15164 iter/s, 13.9828s/100 iter), loss = 1.7505
I0802 11:39:18.669934 18636 solver.cpp:375]     Train net output #0: loss = 1.91647 (* 1 = 1.91647 loss)
I0802 11:39:18.669940 18636 sgd_solver.cpp:136] Iteration 150800, lr = 0.000575, m = 0.9
I0802 11:39:32.662202 18636 solver.cpp:353] Iteration 150900 (7.14697 iter/s, 13.9919s/100 iter), loss = 1.25603
I0802 11:39:32.662230 18636 solver.cpp:375]     Train net output #0: loss = 1.14988 (* 1 = 1.14988 loss)
I0802 11:39:32.662233 18636 sgd_solver.cpp:136] Iteration 150900, lr = 0.00056875, m = 0.9
I0802 11:39:46.469586 18636 solver.cpp:404] Sparsity after update:
I0802 11:39:46.484884 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:39:46.484897 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:39:46.484905 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:39:46.484906 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:39:46.484908 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:39:46.484910 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:39:46.484912 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:39:46.484915 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:39:46.484916 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:39:46.484918 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:39:46.484920 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:39:46.484921 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:39:46.484923 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:39:46.618747 18636 solver.cpp:353] Iteration 151000 (7.16529 iter/s, 13.9562s/100 iter), loss = 1.19327
I0802 11:39:46.618770 18636 solver.cpp:375]     Train net output #0: loss = 1.07802 (* 1 = 1.07802 loss)
I0802 11:39:46.618777 18636 sgd_solver.cpp:136] Iteration 151000, lr = 0.0005625, m = 0.9
I0802 11:40:00.544242 18636 solver.cpp:353] Iteration 151100 (7.18127 iter/s, 13.9251s/100 iter), loss = 1.24504
I0802 11:40:00.544318 18636 solver.cpp:375]     Train net output #0: loss = 1.28096 (* 1 = 1.28096 loss)
I0802 11:40:00.544325 18636 sgd_solver.cpp:136] Iteration 151100, lr = 0.00055625, m = 0.9
I0802 11:40:14.494585 18636 solver.cpp:353] Iteration 151200 (7.16848 iter/s, 13.95s/100 iter), loss = 1.36345
I0802 11:40:14.494616 18636 solver.cpp:375]     Train net output #0: loss = 1.22347 (* 1 = 1.22347 loss)
I0802 11:40:14.494621 18636 sgd_solver.cpp:136] Iteration 151200, lr = 0.00055, m = 0.9
I0802 11:40:28.753473 18636 solver.cpp:353] Iteration 151300 (7.01336 iter/s, 14.2585s/100 iter), loss = 1.25633
I0802 11:40:28.753502 18636 solver.cpp:375]     Train net output #0: loss = 1.48047 (* 1 = 1.48047 loss)
I0802 11:40:28.753509 18636 sgd_solver.cpp:136] Iteration 151300, lr = 0.00054375, m = 0.9
I0802 11:40:42.709946 18636 solver.cpp:353] Iteration 151400 (7.16533 iter/s, 13.9561s/100 iter), loss = 1.16135
I0802 11:40:42.710005 18636 solver.cpp:375]     Train net output #0: loss = 1.30551 (* 1 = 1.30551 loss)
I0802 11:40:42.710011 18636 sgd_solver.cpp:136] Iteration 151400, lr = 0.0005375, m = 0.9
I0802 11:40:56.981022 18636 solver.cpp:353] Iteration 151500 (7.00737 iter/s, 14.2707s/100 iter), loss = 1.83674
I0802 11:40:56.981047 18636 solver.cpp:375]     Train net output #0: loss = 2.25326 (* 1 = 2.25326 loss)
I0802 11:40:56.981052 18636 sgd_solver.cpp:136] Iteration 151500, lr = 0.00053125, m = 0.9
I0802 11:41:11.217921 18636 solver.cpp:353] Iteration 151600 (7.0242 iter/s, 14.2365s/100 iter), loss = 1.4707
I0802 11:41:11.218004 18636 solver.cpp:375]     Train net output #0: loss = 1.26735 (* 1 = 1.26735 loss)
I0802 11:41:11.218025 18636 sgd_solver.cpp:136] Iteration 151600, lr = 0.000525, m = 0.9
I0802 11:41:25.232522 18636 solver.cpp:353] Iteration 151700 (7.13561 iter/s, 14.0142s/100 iter), loss = 1.71721
I0802 11:41:25.232595 18636 solver.cpp:375]     Train net output #0: loss = 1.68313 (* 1 = 1.68313 loss)
I0802 11:41:25.232604 18636 sgd_solver.cpp:136] Iteration 151700, lr = 0.00051875, m = 0.9
I0802 11:41:39.224946 18636 solver.cpp:353] Iteration 151800 (7.14692 iter/s, 13.992s/100 iter), loss = 1.10707
I0802 11:41:39.225011 18636 solver.cpp:375]     Train net output #0: loss = 1.3282 (* 1 = 1.3282 loss)
I0802 11:41:39.225024 18636 sgd_solver.cpp:136] Iteration 151800, lr = 0.0005125, m = 0.9
I0802 11:41:53.321758 18636 solver.cpp:353] Iteration 151900 (7.094 iter/s, 14.0964s/100 iter), loss = 1.85981
I0802 11:41:53.321784 18636 solver.cpp:375]     Train net output #0: loss = 2.27163 (* 1 = 2.27163 loss)
I0802 11:41:53.321789 18636 sgd_solver.cpp:136] Iteration 151900, lr = 0.00050625, m = 0.9
I0802 11:42:07.253010 18636 solver.cpp:404] Sparsity after update:
I0802 11:42:07.257289 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:42:07.257324 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:42:07.257347 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:42:07.257356 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:42:07.257364 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:42:07.257372 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:42:07.257380 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:42:07.257386 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:42:07.257393 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:42:07.257401 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:42:07.257410 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:42:07.257416 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:42:07.257423 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:42:07.257447 18636 solver.cpp:550] Iteration 152000, Testing net (#0)
I0802 11:42:27.042915 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.597353
I0802 11:42:27.042939 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821409
I0802 11:42:27.042944 18636 solver.cpp:635]     Test net output #2: loss = 1.74317 (* 1 = 1.74317 loss)
I0802 11:42:27.044925 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.7869s
I0802 11:42:27.180780 18636 solver.cpp:353] Iteration 152000 (2.9535 iter/s, 33.8581s/100 iter), loss = 1.35058
I0802 11:42:27.180809 18636 solver.cpp:375]     Train net output #0: loss = 1.24402 (* 1 = 1.24402 loss)
I0802 11:42:27.180825 18636 sgd_solver.cpp:136] Iteration 152000, lr = 0.0005, m = 0.9
I0802 11:42:41.190059 18636 solver.cpp:353] Iteration 152100 (7.13833 iter/s, 14.0089s/100 iter), loss = 1.67263
I0802 11:42:41.190124 18636 solver.cpp:375]     Train net output #0: loss = 1.91185 (* 1 = 1.91185 loss)
I0802 11:42:41.190130 18636 sgd_solver.cpp:136] Iteration 152100, lr = 0.00049375, m = 0.9
I0802 11:42:55.205901 18636 solver.cpp:353] Iteration 152200 (7.13498 iter/s, 14.0155s/100 iter), loss = 1.28579
I0802 11:42:55.205931 18636 solver.cpp:375]     Train net output #0: loss = 1.33586 (* 1 = 1.33586 loss)
I0802 11:42:55.205936 18636 sgd_solver.cpp:136] Iteration 152200, lr = 0.0004875, m = 0.9
I0802 11:43:09.198330 18636 solver.cpp:353] Iteration 152300 (7.14692 iter/s, 13.992s/100 iter), loss = 1.38182
I0802 11:43:09.198359 18636 solver.cpp:375]     Train net output #0: loss = 1.01972 (* 1 = 1.01972 loss)
I0802 11:43:09.198365 18636 sgd_solver.cpp:136] Iteration 152300, lr = 0.00048125, m = 0.9
I0802 11:43:23.076411 18636 solver.cpp:353] Iteration 152400 (7.20581 iter/s, 13.8777s/100 iter), loss = 1.67236
I0802 11:43:23.076514 18636 solver.cpp:375]     Train net output #0: loss = 1.6482 (* 1 = 1.6482 loss)
I0802 11:43:23.076522 18636 sgd_solver.cpp:136] Iteration 152400, lr = 0.000475, m = 0.9
I0802 11:43:37.198633 18636 solver.cpp:353] Iteration 152500 (7.08123 iter/s, 14.1218s/100 iter), loss = 1.42989
I0802 11:43:37.198685 18636 solver.cpp:375]     Train net output #0: loss = 1.5735 (* 1 = 1.5735 loss)
I0802 11:43:37.198698 18636 sgd_solver.cpp:136] Iteration 152500, lr = 0.00046875, m = 0.9
I0802 11:43:51.265012 18636 solver.cpp:353] Iteration 152600 (7.10935 iter/s, 14.066s/100 iter), loss = 1.33252
I0802 11:43:51.265038 18636 solver.cpp:375]     Train net output #0: loss = 1.52829 (* 1 = 1.52829 loss)
I0802 11:43:51.265043 18636 sgd_solver.cpp:136] Iteration 152600, lr = 0.0004625, m = 0.9
I0802 11:44:05.186854 18636 solver.cpp:353] Iteration 152700 (7.18316 iter/s, 13.9215s/100 iter), loss = 1.0193
I0802 11:44:05.186933 18636 solver.cpp:375]     Train net output #0: loss = 1.12443 (* 1 = 1.12443 loss)
I0802 11:44:05.186946 18636 sgd_solver.cpp:136] Iteration 152700, lr = 0.00045625, m = 0.9
I0802 11:44:19.285681 18636 solver.cpp:353] Iteration 152800 (7.09299 iter/s, 14.0984s/100 iter), loss = 1.1976
I0802 11:44:19.285711 18636 solver.cpp:375]     Train net output #0: loss = 1.18495 (* 1 = 1.18495 loss)
I0802 11:44:19.285714 18636 sgd_solver.cpp:136] Iteration 152800, lr = 0.00045, m = 0.9
I0802 11:44:33.188010 18636 solver.cpp:353] Iteration 152900 (7.19324 iter/s, 13.9019s/100 iter), loss = 1.27445
I0802 11:44:33.188035 18636 solver.cpp:375]     Train net output #0: loss = 1.40357 (* 1 = 1.40357 loss)
I0802 11:44:33.188041 18636 sgd_solver.cpp:136] Iteration 152900, lr = 0.00044375, m = 0.9
I0802 11:44:47.115128 18636 solver.cpp:404] Sparsity after update:
I0802 11:44:47.130409 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:44:47.130422 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:44:47.130431 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:44:47.130435 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:44:47.130439 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:44:47.130444 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:44:47.130446 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:44:47.130450 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:44:47.130452 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:44:47.130455 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:44:47.130458 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:44:47.130461 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:44:47.130465 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:44:47.260123 18636 solver.cpp:353] Iteration 153000 (7.10645 iter/s, 14.0717s/100 iter), loss = 1.91205
I0802 11:44:47.260149 18636 solver.cpp:375]     Train net output #0: loss = 1.75958 (* 1 = 1.75958 loss)
I0802 11:44:47.260154 18636 sgd_solver.cpp:136] Iteration 153000, lr = 0.0004375, m = 0.9
I0802 11:45:01.221174 18636 solver.cpp:353] Iteration 153100 (7.16298 iter/s, 13.9607s/100 iter), loss = 1.28431
I0802 11:45:01.221199 18636 solver.cpp:375]     Train net output #0: loss = 1.56884 (* 1 = 1.56884 loss)
I0802 11:45:01.221202 18636 sgd_solver.cpp:136] Iteration 153100, lr = 0.00043125, m = 0.9
I0802 11:45:15.268788 18636 solver.cpp:353] Iteration 153200 (7.11884 iter/s, 14.0472s/100 iter), loss = 1.34195
I0802 11:45:15.268826 18636 solver.cpp:375]     Train net output #0: loss = 1.3871 (* 1 = 1.3871 loss)
I0802 11:45:15.268833 18636 sgd_solver.cpp:136] Iteration 153200, lr = 0.000425, m = 0.9
I0802 11:45:29.236768 18636 solver.cpp:353] Iteration 153300 (7.15943 iter/s, 13.9676s/100 iter), loss = 1.4367
I0802 11:45:29.236866 18636 solver.cpp:375]     Train net output #0: loss = 1.38358 (* 1 = 1.38358 loss)
I0802 11:45:29.236879 18636 sgd_solver.cpp:136] Iteration 153300, lr = 0.00041875, m = 0.9
I0802 11:45:43.257155 18636 solver.cpp:353] Iteration 153400 (7.13267 iter/s, 14.02s/100 iter), loss = 1.73954
I0802 11:45:43.257251 18636 solver.cpp:375]     Train net output #0: loss = 1.71129 (* 1 = 1.71129 loss)
I0802 11:45:43.257270 18636 sgd_solver.cpp:136] Iteration 153400, lr = 0.0004125, m = 0.9
I0802 11:45:57.193217 18636 solver.cpp:353] Iteration 153500 (7.17583 iter/s, 13.9357s/100 iter), loss = 1.01902
I0802 11:45:57.193244 18636 solver.cpp:375]     Train net output #0: loss = 0.935565 (* 1 = 0.935565 loss)
I0802 11:45:57.193250 18636 sgd_solver.cpp:136] Iteration 153500, lr = 0.00040625, m = 0.9
I0802 11:46:11.113880 18636 solver.cpp:353] Iteration 153600 (7.18376 iter/s, 13.9203s/100 iter), loss = 1.18872
I0802 11:46:11.113961 18636 solver.cpp:375]     Train net output #0: loss = 1.11964 (* 1 = 1.11964 loss)
I0802 11:46:11.113975 18636 sgd_solver.cpp:136] Iteration 153600, lr = 0.0004, m = 0.9
I0802 11:46:25.109661 18636 solver.cpp:353] Iteration 153700 (7.14521 iter/s, 13.9954s/100 iter), loss = 1.56588
I0802 11:46:25.109685 18636 solver.cpp:375]     Train net output #0: loss = 1.38959 (* 1 = 1.38959 loss)
I0802 11:46:25.109689 18636 sgd_solver.cpp:136] Iteration 153700, lr = 0.00039375, m = 0.9
I0802 11:46:39.362329 18636 solver.cpp:353] Iteration 153800 (7.01643 iter/s, 14.2523s/100 iter), loss = 1.47752
I0802 11:46:39.362361 18636 solver.cpp:375]     Train net output #0: loss = 1.64974 (* 1 = 1.64974 loss)
I0802 11:46:39.362368 18636 sgd_solver.cpp:136] Iteration 153800, lr = 0.0003875, m = 0.9
I0802 11:46:53.441833 18636 solver.cpp:353] Iteration 153900 (7.10272 iter/s, 14.0791s/100 iter), loss = 1.33661
I0802 11:46:53.441910 18636 solver.cpp:375]     Train net output #0: loss = 1.43707 (* 1 = 1.43707 loss)
I0802 11:46:53.441916 18636 sgd_solver.cpp:136] Iteration 153900, lr = 0.00038125, m = 0.9
I0802 11:47:07.433465 18636 solver.cpp:404] Sparsity after update:
I0802 11:47:07.437940 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:47:07.437950 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:47:07.437958 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:47:07.437959 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:47:07.437961 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:47:07.437963 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:47:07.437965 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:47:07.437968 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:47:07.437973 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:47:07.437974 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:47:07.437976 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:47:07.437979 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:47:07.437983 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:47:07.437994 18636 solver.cpp:550] Iteration 154000, Testing net (#0)
I0802 11:47:27.376582 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.592588
I0802 11:47:27.376644 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.818468
I0802 11:47:27.376651 18636 solver.cpp:635]     Test net output #2: loss = 1.77486 (* 1 = 1.77486 loss)
I0802 11:47:27.376670 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.9381s
I0802 11:47:27.533879 18636 solver.cpp:353] Iteration 154000 (2.93332 iter/s, 34.0911s/100 iter), loss = 1.0654
I0802 11:47:27.533906 18636 solver.cpp:375]     Train net output #0: loss = 1.00879 (* 1 = 1.00879 loss)
I0802 11:47:27.533912 18636 sgd_solver.cpp:136] Iteration 154000, lr = 0.000375, m = 0.9
I0802 11:47:41.549482 18636 solver.cpp:353] Iteration 154100 (7.1351 iter/s, 14.0152s/100 iter), loss = 1.26634
I0802 11:47:41.549515 18636 solver.cpp:375]     Train net output #0: loss = 1.23883 (* 1 = 1.23883 loss)
I0802 11:47:41.549523 18636 sgd_solver.cpp:136] Iteration 154100, lr = 0.00036875, m = 0.9
I0802 11:47:55.457367 18636 solver.cpp:353] Iteration 154200 (7.19036 iter/s, 13.9075s/100 iter), loss = 1.25579
I0802 11:47:55.457393 18636 solver.cpp:375]     Train net output #0: loss = 1.3951 (* 1 = 1.3951 loss)
I0802 11:47:55.457398 18636 sgd_solver.cpp:136] Iteration 154200, lr = 0.0003625, m = 0.9
I0802 11:48:09.580948 18636 solver.cpp:353] Iteration 154300 (7.08056 iter/s, 14.1232s/100 iter), loss = 1.4149
I0802 11:48:09.581070 18636 solver.cpp:375]     Train net output #0: loss = 1.69923 (* 1 = 1.69923 loss)
I0802 11:48:09.581094 18636 sgd_solver.cpp:136] Iteration 154300, lr = 0.00035625, m = 0.9
I0802 11:48:23.704908 18636 solver.cpp:353] Iteration 154400 (7.08036 iter/s, 14.1236s/100 iter), loss = 1.16303
I0802 11:48:23.704944 18636 solver.cpp:375]     Train net output #0: loss = 1.24752 (* 1 = 1.24752 loss)
I0802 11:48:23.704951 18636 sgd_solver.cpp:136] Iteration 154400, lr = 0.00035, m = 0.9
I0802 11:48:37.664886 18636 solver.cpp:353] Iteration 154500 (7.16353 iter/s, 13.9596s/100 iter), loss = 1.20458
I0802 11:48:37.664952 18636 solver.cpp:375]     Train net output #0: loss = 1.29481 (* 1 = 1.29481 loss)
I0802 11:48:37.664965 18636 sgd_solver.cpp:136] Iteration 154500, lr = 0.00034375, m = 0.9
I0802 11:48:51.679968 18636 solver.cpp:353] Iteration 154600 (7.13537 iter/s, 14.0147s/100 iter), loss = 0.823556
I0802 11:48:51.680258 18636 solver.cpp:375]     Train net output #0: loss = 0.925412 (* 1 = 0.925412 loss)
I0802 11:48:51.680352 18636 sgd_solver.cpp:136] Iteration 154600, lr = 0.0003375, m = 0.9
I0802 11:49:05.727923 18636 solver.cpp:353] Iteration 154700 (7.11867 iter/s, 14.0476s/100 iter), loss = 1.58487
I0802 11:49:05.728034 18636 solver.cpp:375]     Train net output #0: loss = 1.19683 (* 1 = 1.19683 loss)
I0802 11:49:05.728057 18636 sgd_solver.cpp:136] Iteration 154700, lr = 0.00033125, m = 0.9
I0802 11:49:19.670145 18636 solver.cpp:353] Iteration 154800 (7.17266 iter/s, 13.9418s/100 iter), loss = 1.33698
I0802 11:49:19.670186 18636 solver.cpp:375]     Train net output #0: loss = 1.19788 (* 1 = 1.19788 loss)
I0802 11:49:19.670192 18636 sgd_solver.cpp:136] Iteration 154800, lr = 0.000325, m = 0.9
I0802 11:49:33.614943 18636 solver.cpp:353] Iteration 154900 (7.17133 iter/s, 13.9444s/100 iter), loss = 1.14985
I0802 11:49:33.615094 18636 solver.cpp:375]     Train net output #0: loss = 1.00716 (* 1 = 1.00716 loss)
I0802 11:49:33.615113 18636 sgd_solver.cpp:136] Iteration 154900, lr = 0.00031875, m = 0.9
I0802 11:49:47.714117 18636 solver.cpp:404] Sparsity after update:
I0802 11:49:47.725476 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:49:47.725699 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:49:47.725801 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:49:47.725896 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:49:47.725992 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:49:47.726090 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:49:47.726182 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:49:47.726276 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:49:47.726366 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:49:47.726454 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:49:47.726546 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:49:47.726639 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:49:47.726730 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:49:47.860724 18636 solver.cpp:353] Iteration 155000 (7.01982 iter/s, 14.2454s/100 iter), loss = 1.25328
I0802 11:49:47.860750 18636 solver.cpp:375]     Train net output #0: loss = 1.16173 (* 1 = 1.16173 loss)
I0802 11:49:47.860755 18636 sgd_solver.cpp:136] Iteration 155000, lr = 0.0003125, m = 0.9
I0802 11:50:01.813266 18636 solver.cpp:353] Iteration 155100 (7.16735 iter/s, 13.9522s/100 iter), loss = 1.10239
I0802 11:50:01.813297 18636 solver.cpp:375]     Train net output #0: loss = 1.23634 (* 1 = 1.23634 loss)
I0802 11:50:01.813302 18636 sgd_solver.cpp:136] Iteration 155100, lr = 0.00030625, m = 0.9
I0802 11:50:15.771095 18636 solver.cpp:353] Iteration 155200 (7.16463 iter/s, 13.9574s/100 iter), loss = 1.25036
I0802 11:50:15.771148 18636 solver.cpp:375]     Train net output #0: loss = 1.08132 (* 1 = 1.08132 loss)
I0802 11:50:15.771154 18636 sgd_solver.cpp:136] Iteration 155200, lr = 0.0003, m = 0.9
I0802 11:50:29.662369 18636 solver.cpp:353] Iteration 155300 (7.19896 iter/s, 13.8909s/100 iter), loss = 1.34848
I0802 11:50:29.662400 18636 solver.cpp:375]     Train net output #0: loss = 0.963143 (* 1 = 0.963143 loss)
I0802 11:50:29.662405 18636 sgd_solver.cpp:136] Iteration 155300, lr = 0.00029375, m = 0.9
I0802 11:50:43.673676 18636 solver.cpp:353] Iteration 155400 (7.13729 iter/s, 14.0109s/100 iter), loss = 1.19106
I0802 11:50:43.673729 18636 solver.cpp:375]     Train net output #0: loss = 0.902023 (* 1 = 0.902023 loss)
I0802 11:50:43.673743 18636 sgd_solver.cpp:136] Iteration 155400, lr = 0.0002875, m = 0.9
I0802 11:50:57.690989 18636 solver.cpp:353] Iteration 155500 (7.13423 iter/s, 14.0169s/100 iter), loss = 1.28041
I0802 11:50:57.691045 18636 solver.cpp:375]     Train net output #0: loss = 1.3928 (* 1 = 1.3928 loss)
I0802 11:50:57.691051 18636 sgd_solver.cpp:136] Iteration 155500, lr = 0.00028125, m = 0.9
I0802 11:51:11.626233 18636 solver.cpp:353] Iteration 155600 (7.17625 iter/s, 13.9349s/100 iter), loss = 1.41746
I0802 11:51:11.626360 18636 solver.cpp:375]     Train net output #0: loss = 1.30866 (* 1 = 1.30866 loss)
I0802 11:51:11.626389 18636 sgd_solver.cpp:136] Iteration 155600, lr = 0.000275, m = 0.9
I0802 11:51:25.703326 18636 solver.cpp:353] Iteration 155700 (7.10393 iter/s, 14.0767s/100 iter), loss = 1.52764
I0802 11:51:25.703410 18636 solver.cpp:375]     Train net output #0: loss = 1.31406 (* 1 = 1.31406 loss)
I0802 11:51:25.703431 18636 sgd_solver.cpp:136] Iteration 155700, lr = 0.00026875, m = 0.9
I0802 11:51:39.601037 18636 solver.cpp:353] Iteration 155800 (7.19563 iter/s, 13.8973s/100 iter), loss = 1.14127
I0802 11:51:39.601140 18636 solver.cpp:375]     Train net output #0: loss = 1.50405 (* 1 = 1.50405 loss)
I0802 11:51:39.601147 18636 sgd_solver.cpp:136] Iteration 155800, lr = 0.0002625, m = 0.9
I0802 11:51:53.537324 18636 solver.cpp:353] Iteration 155900 (7.17571 iter/s, 13.9359s/100 iter), loss = 1.23459
I0802 11:51:53.537349 18636 solver.cpp:375]     Train net output #0: loss = 1.19289 (* 1 = 1.19289 loss)
I0802 11:51:53.537355 18636 sgd_solver.cpp:136] Iteration 155900, lr = 0.00025625, m = 0.9
I0802 11:52:07.411674 18636 solver.cpp:404] Sparsity after update:
I0802 11:52:07.416996 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:52:07.417011 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:52:07.417017 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:52:07.417019 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:52:07.417021 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:52:07.417023 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:52:07.417026 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:52:07.417031 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:52:07.417032 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:52:07.417033 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:52:07.417035 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:52:07.417037 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:52:07.417039 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:52:07.417047 18636 solver.cpp:550] Iteration 156000, Testing net (#0)
I0802 11:52:24.151203 18637 blocking_queue.cpp:40] Data layer prefetch queue empty
I0802 11:52:26.973140 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.595529
I0802 11:52:26.973165 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.82235
I0802 11:52:26.973170 18636 solver.cpp:635]     Test net output #2: loss = 1.75038 (* 1 = 1.75038 loss)
I0802 11:52:26.973191 18636 solver.cpp:305] [MultiGPU] Tests completed in 19.5556s
I0802 11:52:27.113400 18636 solver.cpp:353] Iteration 156000 (2.97839 iter/s, 33.5752s/100 iter), loss = 1.27678
I0802 11:52:27.113427 18636 solver.cpp:375]     Train net output #0: loss = 0.94104 (* 1 = 0.94104 loss)
I0802 11:52:27.113433 18636 sgd_solver.cpp:136] Iteration 156000, lr = 0.00025, m = 0.9
I0802 11:52:41.315587 18636 solver.cpp:353] Iteration 156100 (7.04137 iter/s, 14.2018s/100 iter), loss = 1.62884
I0802 11:52:41.315671 18636 solver.cpp:375]     Train net output #0: loss = 1.39114 (* 1 = 1.39114 loss)
I0802 11:52:41.315692 18636 sgd_solver.cpp:136] Iteration 156100, lr = 0.00024375, m = 0.9
I0802 11:52:55.253736 18636 solver.cpp:353] Iteration 156200 (7.17475 iter/s, 13.9378s/100 iter), loss = 1.38796
I0802 11:52:55.253818 18636 solver.cpp:375]     Train net output #0: loss = 1.42701 (* 1 = 1.42701 loss)
I0802 11:52:55.253825 18636 sgd_solver.cpp:136] Iteration 156200, lr = 0.0002375, m = 0.9
I0802 11:53:09.114647 18636 solver.cpp:353] Iteration 156300 (7.21473 iter/s, 13.8605s/100 iter), loss = 1.5004
I0802 11:53:09.114678 18636 solver.cpp:375]     Train net output #0: loss = 1.73752 (* 1 = 1.73752 loss)
I0802 11:53:09.114683 18636 sgd_solver.cpp:136] Iteration 156300, lr = 0.00023125, m = 0.9
I0802 11:53:23.116225 18636 solver.cpp:353] Iteration 156400 (7.14225 iter/s, 14.0012s/100 iter), loss = 1.18736
I0802 11:53:23.116250 18636 solver.cpp:375]     Train net output #0: loss = 1.01776 (* 1 = 1.01776 loss)
I0802 11:53:23.116255 18636 sgd_solver.cpp:136] Iteration 156400, lr = 0.000225, m = 0.9
I0802 11:53:37.208250 18636 solver.cpp:353] Iteration 156500 (7.09641 iter/s, 14.0916s/100 iter), loss = 0.975879
I0802 11:53:37.208335 18636 solver.cpp:375]     Train net output #0: loss = 1.0344 (* 1 = 1.0344 loss)
I0802 11:53:37.208343 18636 sgd_solver.cpp:136] Iteration 156500, lr = 0.00021875, m = 0.9
I0802 11:53:51.238888 18636 solver.cpp:353] Iteration 156600 (7.12746 iter/s, 14.0303s/100 iter), loss = 1.26513
I0802 11:53:51.238914 18636 solver.cpp:375]     Train net output #0: loss = 1.32872 (* 1 = 1.32872 loss)
I0802 11:53:51.238919 18636 sgd_solver.cpp:136] Iteration 156600, lr = 0.0002125, m = 0.9
I0802 11:54:05.412086 18636 solver.cpp:353] Iteration 156700 (7.05576 iter/s, 14.1728s/100 iter), loss = 1.12415
I0802 11:54:05.412272 18636 solver.cpp:375]     Train net output #0: loss = 0.967269 (* 1 = 0.967269 loss)
I0802 11:54:05.412356 18636 sgd_solver.cpp:136] Iteration 156700, lr = 0.00020625, m = 0.9
I0802 11:54:19.294850 18636 solver.cpp:353] Iteration 156800 (7.20338 iter/s, 13.8824s/100 iter), loss = 1.39266
I0802 11:54:19.294924 18636 solver.cpp:375]     Train net output #0: loss = 1.35531 (* 1 = 1.35531 loss)
I0802 11:54:19.294930 18636 sgd_solver.cpp:136] Iteration 156800, lr = 0.0002, m = 0.9
I0802 11:54:33.488267 18636 solver.cpp:353] Iteration 156900 (7.04571 iter/s, 14.193s/100 iter), loss = 1.12764
I0802 11:54:33.488296 18636 solver.cpp:375]     Train net output #0: loss = 1.06411 (* 1 = 1.06411 loss)
I0802 11:54:33.488302 18636 sgd_solver.cpp:136] Iteration 156900, lr = 0.00019375, m = 0.9
I0802 11:54:47.390472 18636 solver.cpp:404] Sparsity after update:
I0802 11:54:47.401659 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:54:47.401674 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:54:47.401682 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:54:47.401685 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:54:47.401690 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:54:47.401692 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:54:47.401695 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:54:47.401698 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:54:47.401701 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:54:47.401705 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:54:47.401707 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:54:47.401710 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:54:47.401713 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:54:47.531847 18636 solver.cpp:353] Iteration 157000 (7.12089 iter/s, 14.0432s/100 iter), loss = 1.12193
I0802 11:54:47.531877 18636 solver.cpp:375]     Train net output #0: loss = 0.972871 (* 1 = 0.972871 loss)
I0802 11:54:47.531883 18636 sgd_solver.cpp:136] Iteration 157000, lr = 0.0001875, m = 0.9
I0802 11:55:01.447368 18636 solver.cpp:353] Iteration 157100 (7.18642 iter/s, 13.9151s/100 iter), loss = 1.16635
I0802 11:55:01.447434 18636 solver.cpp:375]     Train net output #0: loss = 1.46873 (* 1 = 1.46873 loss)
I0802 11:55:01.447441 18636 sgd_solver.cpp:136] Iteration 157100, lr = 0.00018125, m = 0.9
I0802 11:55:15.485008 18636 solver.cpp:353] Iteration 157200 (7.1239 iter/s, 14.0373s/100 iter), loss = 1.63805
I0802 11:55:15.485033 18636 solver.cpp:375]     Train net output #0: loss = 1.83998 (* 1 = 1.83998 loss)
I0802 11:55:15.485036 18636 sgd_solver.cpp:136] Iteration 157200, lr = 0.000175, m = 0.9
I0802 11:55:29.492837 18636 solver.cpp:353] Iteration 157300 (7.13906 iter/s, 14.0074s/100 iter), loss = 1.67872
I0802 11:55:29.492866 18636 solver.cpp:375]     Train net output #0: loss = 1.64696 (* 1 = 1.64696 loss)
I0802 11:55:29.492871 18636 sgd_solver.cpp:136] Iteration 157300, lr = 0.00016875, m = 0.9
I0802 11:55:43.541795 18636 solver.cpp:353] Iteration 157400 (7.11816 iter/s, 14.0486s/100 iter), loss = 1.32172
I0802 11:55:43.541877 18636 solver.cpp:375]     Train net output #0: loss = 1.32011 (* 1 = 1.32011 loss)
I0802 11:55:43.541885 18636 sgd_solver.cpp:136] Iteration 157400, lr = 0.0001625, m = 0.9
I0802 11:55:57.552955 18636 solver.cpp:353] Iteration 157500 (7.13736 iter/s, 14.0108s/100 iter), loss = 1.257
I0802 11:55:57.552979 18636 solver.cpp:375]     Train net output #0: loss = 1.39085 (* 1 = 1.39085 loss)
I0802 11:55:57.552983 18636 sgd_solver.cpp:136] Iteration 157500, lr = 0.00015625, m = 0.9
I0802 11:56:11.829499 18636 solver.cpp:353] Iteration 157600 (7.00469 iter/s, 14.2762s/100 iter), loss = 1.35501
I0802 11:56:11.829527 18636 solver.cpp:375]     Train net output #0: loss = 1.12058 (* 1 = 1.12058 loss)
I0802 11:56:11.829535 18636 sgd_solver.cpp:136] Iteration 157600, lr = 0.00015, m = 0.9
I0802 11:56:25.794214 18636 solver.cpp:353] Iteration 157700 (7.16111 iter/s, 13.9643s/100 iter), loss = 1.38557
I0802 11:56:25.794368 18636 solver.cpp:375]     Train net output #0: loss = 1.68378 (* 1 = 1.68378 loss)
I0802 11:56:25.794389 18636 sgd_solver.cpp:136] Iteration 157700, lr = 0.00014375, m = 0.9
I0802 11:56:39.764595 18636 solver.cpp:353] Iteration 157800 (7.1582 iter/s, 13.97s/100 iter), loss = 1.37735
I0802 11:56:39.764623 18636 solver.cpp:375]     Train net output #0: loss = 1.51351 (* 1 = 1.51351 loss)
I0802 11:56:39.764629 18636 sgd_solver.cpp:136] Iteration 157800, lr = 0.0001375, m = 0.9
I0802 11:56:53.866894 18636 solver.cpp:353] Iteration 157900 (7.09124 iter/s, 14.1019s/100 iter), loss = 1.37591
I0802 11:56:53.866986 18636 solver.cpp:375]     Train net output #0: loss = 1.4839 (* 1 = 1.4839 loss)
I0802 11:56:53.867007 18636 sgd_solver.cpp:136] Iteration 157900, lr = 0.00013125, m = 0.9
I0802 11:57:07.756615 18636 solver.cpp:404] Sparsity after update:
I0802 11:57:07.761014 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:57:07.761025 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:57:07.761032 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:57:07.761034 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:57:07.761036 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:57:07.761039 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:57:07.761040 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:57:07.761042 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:57:07.761046 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:57:07.761049 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:57:07.761050 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:57:07.761052 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:57:07.761054 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:57:07.761062 18636 solver.cpp:550] Iteration 158000, Testing net (#0)
I0802 11:57:16.447721 18619 data_reader.cpp:264] Starting prefetch of epoch 8
I0802 11:57:27.807376 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.594941
I0802 11:57:27.807405 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821938
I0802 11:57:27.807413 18636 solver.cpp:635]     Test net output #2: loss = 1.75563 (* 1 = 1.75563 loss)
I0802 11:57:27.807433 18636 solver.cpp:305] [MultiGPU] Tests completed in 20.0458s
I0802 11:57:27.944092 18636 solver.cpp:353] Iteration 158000 (2.93459 iter/s, 34.0763s/100 iter), loss = 1.33139
I0802 11:57:27.944120 18636 solver.cpp:375]     Train net output #0: loss = 1.07038 (* 1 = 1.07038 loss)
I0802 11:57:27.944125 18636 sgd_solver.cpp:136] Iteration 158000, lr = 0.000125, m = 0.9
I0802 11:57:42.228689 18636 solver.cpp:353] Iteration 158100 (7.00075 iter/s, 14.2842s/100 iter), loss = 1.36206
I0802 11:57:42.228803 18636 solver.cpp:375]     Train net output #0: loss = 1.36122 (* 1 = 1.36122 loss)
I0802 11:57:42.228827 18636 sgd_solver.cpp:136] Iteration 158100, lr = 0.00011875, m = 0.9
I0802 11:57:56.353569 18636 solver.cpp:353] Iteration 158200 (7.0799 iter/s, 14.1245s/100 iter), loss = 1.36536
I0802 11:57:56.353600 18636 solver.cpp:375]     Train net output #0: loss = 1.18187 (* 1 = 1.18187 loss)
I0802 11:57:56.353607 18636 sgd_solver.cpp:136] Iteration 158200, lr = 0.0001125, m = 0.9
I0802 11:58:10.592788 18636 solver.cpp:353] Iteration 158300 (7.02305 iter/s, 14.2388s/100 iter), loss = 1.3406
I0802 11:58:10.592824 18636 solver.cpp:375]     Train net output #0: loss = 1.35916 (* 1 = 1.35916 loss)
I0802 11:58:10.592830 18636 sgd_solver.cpp:136] Iteration 158300, lr = 0.00010625, m = 0.9
I0802 11:58:24.893550 18636 solver.cpp:353] Iteration 158400 (6.99283 iter/s, 14.3004s/100 iter), loss = 1.50423
I0802 11:58:24.893628 18636 solver.cpp:375]     Train net output #0: loss = 1.46722 (* 1 = 1.46722 loss)
I0802 11:58:24.893635 18636 sgd_solver.cpp:136] Iteration 158400, lr = 9.99999e-05, m = 0.9
I0802 11:58:38.956511 18636 solver.cpp:353] Iteration 158500 (7.11108 iter/s, 14.0626s/100 iter), loss = 1.27294
I0802 11:58:38.956567 18636 solver.cpp:375]     Train net output #0: loss = 1.5219 (* 1 = 1.5219 loss)
I0802 11:58:38.956579 18636 sgd_solver.cpp:136] Iteration 158500, lr = 9.37498e-05, m = 0.9
I0802 11:58:53.005486 18636 solver.cpp:353] Iteration 158600 (7.11815 iter/s, 14.0486s/100 iter), loss = 1.11176
I0802 11:58:53.005511 18636 solver.cpp:375]     Train net output #0: loss = 1.04643 (* 1 = 1.04643 loss)
I0802 11:58:53.005517 18636 sgd_solver.cpp:136] Iteration 158600, lr = 8.75002e-05, m = 0.9
I0802 11:59:07.106804 18636 solver.cpp:353] Iteration 158700 (7.09173 iter/s, 14.1009s/100 iter), loss = 1.38624
I0802 11:59:07.106866 18636 solver.cpp:375]     Train net output #0: loss = 1.3043 (* 1 = 1.3043 loss)
I0802 11:59:07.106874 18636 sgd_solver.cpp:136] Iteration 158700, lr = 8.12501e-05, m = 0.9
I0802 11:59:21.038017 18636 solver.cpp:353] Iteration 158800 (7.17832 iter/s, 13.9308s/100 iter), loss = 1.36418
I0802 11:59:21.038043 18636 solver.cpp:375]     Train net output #0: loss = 1.16214 (* 1 = 1.16214 loss)
I0802 11:59:21.038048 18636 sgd_solver.cpp:136] Iteration 158800, lr = 7.49999e-05, m = 0.9
I0802 11:59:34.905232 18636 solver.cpp:353] Iteration 158900 (7.21145 iter/s, 13.8668s/100 iter), loss = 1.00751
I0802 11:59:34.905264 18636 solver.cpp:375]     Train net output #0: loss = 0.904927 (* 1 = 0.904927 loss)
I0802 11:59:34.905270 18636 sgd_solver.cpp:136] Iteration 158900, lr = 6.87498e-05, m = 0.9
I0802 11:59:49.045388 18636 solver.cpp:404] Sparsity after update:
I0802 11:59:49.055928 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 11:59:49.055959 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 11:59:49.055974 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 11:59:49.055984 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 11:59:49.055991 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 11:59:49.055999 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 11:59:49.056007 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 11:59:49.056015 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 11:59:49.056023 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 11:59:49.056031 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 11:59:49.056040 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 11:59:49.056047 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 11:59:49.056056 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 11:59:49.185381 18636 solver.cpp:353] Iteration 159000 (7.00292 iter/s, 14.2798s/100 iter), loss = 1.74865
I0802 11:59:49.185432 18636 solver.cpp:375]     Train net output #0: loss = 1.76277 (* 1 = 1.76277 loss)
I0802 11:59:49.185443 18636 sgd_solver.cpp:136] Iteration 159000, lr = 6.25002e-05, m = 0.9
I0802 12:00:03.209468 18636 solver.cpp:353] Iteration 159100 (7.13078 iter/s, 14.0237s/100 iter), loss = 1.39727
I0802 12:00:03.209493 18636 solver.cpp:375]     Train net output #0: loss = 1.46254 (* 1 = 1.46254 loss)
I0802 12:00:03.209497 18636 sgd_solver.cpp:136] Iteration 159100, lr = 5.62501e-05, m = 0.9
I0802 12:00:17.257881 18636 solver.cpp:353] Iteration 159200 (7.11844 iter/s, 14.048s/100 iter), loss = 1.61655
I0802 12:00:17.257906 18636 solver.cpp:375]     Train net output #0: loss = 1.93229 (* 1 = 1.93229 loss)
I0802 12:00:17.257910 18636 sgd_solver.cpp:136] Iteration 159200, lr = 5e-05, m = 0.9
I0802 12:00:31.229521 18636 solver.cpp:353] Iteration 159300 (7.15755 iter/s, 13.9713s/100 iter), loss = 1.33516
I0802 12:00:31.229586 18636 solver.cpp:375]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0802 12:00:31.229593 18636 sgd_solver.cpp:136] Iteration 159300, lr = 4.37498e-05, m = 0.9
I0802 12:00:45.408804 18636 solver.cpp:353] Iteration 159400 (7.05274 iter/s, 14.1789s/100 iter), loss = 1.49017
I0802 12:00:45.408841 18636 solver.cpp:375]     Train net output #0: loss = 1.52334 (* 1 = 1.52334 loss)
I0802 12:00:45.408848 18636 sgd_solver.cpp:136] Iteration 159400, lr = 3.75003e-05, m = 0.9
I0802 12:00:59.325413 18636 solver.cpp:353] Iteration 159500 (7.18586 iter/s, 13.9162s/100 iter), loss = 1.20673
I0802 12:00:59.325443 18636 solver.cpp:375]     Train net output #0: loss = 1.09974 (* 1 = 1.09974 loss)
I0802 12:00:59.325448 18636 sgd_solver.cpp:136] Iteration 159500, lr = 3.12501e-05, m = 0.9
I0802 12:01:13.241336 18636 solver.cpp:353] Iteration 159600 (7.18621 iter/s, 13.9155s/100 iter), loss = 1.39125
I0802 12:01:13.241448 18636 solver.cpp:375]     Train net output #0: loss = 1.4983 (* 1 = 1.4983 loss)
I0802 12:01:13.241456 18636 sgd_solver.cpp:136] Iteration 159600, lr = 2.5e-05, m = 0.9
I0802 12:01:27.237045 18636 solver.cpp:353] Iteration 159700 (7.14524 iter/s, 13.9953s/100 iter), loss = 1.25924
I0802 12:01:27.237071 18636 solver.cpp:375]     Train net output #0: loss = 1.36253 (* 1 = 1.36253 loss)
I0802 12:01:27.237076 18636 sgd_solver.cpp:136] Iteration 159700, lr = 1.87498e-05, m = 0.9
I0802 12:01:41.190138 18636 solver.cpp:353] Iteration 159800 (7.16707 iter/s, 13.9527s/100 iter), loss = 1.43359
I0802 12:01:41.190189 18636 solver.cpp:375]     Train net output #0: loss = 1.44849 (* 1 = 1.44849 loss)
I0802 12:01:41.190201 18636 sgd_solver.cpp:136] Iteration 159800, lr = 1.25003e-05, m = 0.9
I0802 12:01:55.238560 18636 solver.cpp:353] Iteration 159900 (7.11843 iter/s, 14.048s/100 iter), loss = 1.03472
I0802 12:01:55.238642 18636 solver.cpp:375]     Train net output #0: loss = 0.969054 (* 1 = 0.969054 loss)
I0802 12:01:55.238654 18636 sgd_solver.cpp:136] Iteration 159900, lr = 6.25014e-06, m = 0.9
I0802 12:02:09.065933 18636 solver.cpp:353] Iteration 159999 (7.15991 iter/s, 13.827s/99 iter), loss = 1.57142
I0802 12:02:09.065960 18636 solver.cpp:375]     Train net output #0: loss = 1.77526 (* 1 = 1.77526 loss)
I0802 12:02:09.065968 18636 solver.cpp:680] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_160000.caffemodel
I0802 12:02:09.096949 18636 sgd_solver.cpp:310] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-08-01_15-21-31/sparse/imagenet_jacintonet11v2_iter_160000.solverstate
I0802 12:02:09.101287 18636 solver.cpp:404] Sparsity after update:
I0802 12:02:09.102345 18636 net.cpp:2261] Num Params(11), Sparsity (zero_weights/count): 
I0802 12:02:09.102355 18636 net.cpp:2270] conv1a_param_0(0.39) 
I0802 12:02:09.102361 18636 net.cpp:2270] conv1b_param_0(0.73) 
I0802 12:02:09.102365 18636 net.cpp:2270] fc1000_param_0(0) 
I0802 12:02:09.102366 18636 net.cpp:2270] res2a_branch2a_param_0(0.787) 
I0802 12:02:09.102368 18636 net.cpp:2270] res2a_branch2b_param_0(0.708) 
I0802 12:02:09.102371 18636 net.cpp:2270] res3a_branch2a_param_0(0.799) 
I0802 12:02:09.102373 18636 net.cpp:2270] res3a_branch2b_param_0(0.756) 
I0802 12:02:09.102375 18636 net.cpp:2270] res4a_branch2a_param_0(0.807) 
I0802 12:02:09.102377 18636 net.cpp:2270] res4a_branch2b_param_0(0.783) 
I0802 12:02:09.102380 18636 net.cpp:2270] res5a_branch2a_param_0(0.81) 
I0802 12:02:09.102382 18636 net.cpp:2270] res5a_branch2b_param_0(0.81) 
I0802 12:02:09.102385 18636 net.cpp:2272] Total Sparsity (zero_weights/count) =  (1.89672e+06/2.86678e+06) 0.662
I0802 12:02:09.164032 18636 solver.cpp:527] Iteration 160000, loss = 1.32036
I0802 12:02:09.164060 18636 solver.cpp:550] Iteration 160000, Testing net (#0)
I0802 12:02:29.389502 18636 solver.cpp:635]     Test net output #0: accuracy/top1 = 0.596764
I0802 12:02:29.389619 18636 solver.cpp:635]     Test net output #1: accuracy/top5 = 0.821821
I0802 12:02:29.389629 18636 solver.cpp:635]     Test net output #2: loss = 1.75474 (* 1 = 1.75474 loss)
I0802 12:02:29.397680 18523 parallel.cpp:73] Root Solver performance on device 0: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397693 18523 parallel.cpp:78]      Solver performance on device 1: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397697 18523 parallel.cpp:78]      Solver performance on device 2: 6.058 * 43 = 260.5 img/sec (160000 itr in 2.641e+04 sec)
I0802 12:02:29.397701 18523 parallel.cpp:81] Overall multi-GPU performance: 781.514 img/sec
I0802 12:02:29.948015 18523 caffe.cpp:247] Optimization Done in 7h 20m 36s
