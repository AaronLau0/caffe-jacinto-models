I0628 19:46:16.128695  5852 caffe.cpp:608] This is NVCaffe 0.16.2 started at Wed Jun 28 19:46:15 2017
I0628 19:46:16.128806  5852 caffe.cpp:611] CuDNN version: 6.0.21
I0628 19:46:16.128810  5852 caffe.cpp:612] CuBLAS version: 8000
I0628 19:46:16.128813  5852 caffe.cpp:613] CUDA version: 8000
I0628 19:46:16.128813  5852 caffe.cpp:614] CUDA driver version: 8000
I0628 19:46:16.252646  5852 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0628 19:46:16.253146  5852 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8277393408, dev_info[0]: total=8506769408 free=8277393408
I0628 19:46:16.253598  5852 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8277393408, dev_info[1]: total=8508145664 free=8379236352
I0628 19:46:16.253608  5852 caffe.cpp:208] Using GPUs 0, 1
I0628 19:46:16.253868  5852 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0628 19:46:16.254128  5852 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0628 19:46:16.254166  5852 solver.cpp:42] Solver data type: FLOAT
I0628 19:46:16.254201  5852 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/train.prototxt"
test_net: "training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/test.prototxt"
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 160000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 2
type: "SGD"
display_sparsity: 1000
sparse_mode: SPARSE_UPDATE
sparsity_target: 0.8
sparsity_step_factor: 0.01
sparsity_step_iter: 1000
sparsity_start_iter: 0
sparsity_start_factor: 0
I0628 19:46:16.259508  5852 solver.cpp:77] Creating training net from train_net file: training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/train.prototxt
I0628 19:46:16.259923  5852 net.cpp:442] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0628 19:46:16.259929  5852 net.cpp:442] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0628 19:46:16.260071  5852 net.cpp:77] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_train_lmdb"
    batch_size: 64
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0628 19:46:16.260179  5852 net.cpp:108] Using FLOAT as default forward math type
I0628 19:46:16.260185  5852 net.cpp:114] Using FLOAT as default backward math type
I0628 19:46:16.260190  5852 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0628 19:46:16.260193  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.260239  5852 net.cpp:183] Created Layer data (0)
I0628 19:46:16.260246  5852 net.cpp:529] data -> data
I0628 19:46:16.260257  5852 net.cpp:529] data -> label
I0628 19:46:16.260280  5852 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 64
I0628 19:46:16.260303  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 19:46:16.261749  5875 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0628 19:46:16.263173  5852 data_layer.cpp:188] ReshapePrefetch 64, 3, 224, 224
I0628 19:46:16.263221  5852 data_layer.cpp:206] Output data size: 64, 3, 224, 224
I0628 19:46:16.263229  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 19:46:16.263248  5852 net.cpp:244] Setting up data
I0628 19:46:16.263258  5852 net.cpp:251] TRAIN Top shape for layer 0 'data' 64 3 224 224 (9633792)
I0628 19:46:16.263263  5852 net.cpp:251] TRAIN Top shape for layer 0 'data' 64 (64)
I0628 19:46:16.263268  5852 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0628 19:46:16.263272  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.263285  5852 net.cpp:183] Created Layer data/bias (1)
I0628 19:46:16.263289  5852 net.cpp:560] data/bias <- data
I0628 19:46:16.263298  5852 net.cpp:529] data/bias -> data/bias
I0628 19:46:16.265542  5852 net.cpp:244] Setting up data/bias
I0628 19:46:16.265586  5852 net.cpp:251] TRAIN Top shape for layer 1 'data/bias' 64 3 224 224 (9633792)
I0628 19:46:16.265606  5852 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0628 19:46:16.265612  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.265637  5852 net.cpp:183] Created Layer conv1a (2)
I0628 19:46:16.265652  5852 net.cpp:560] conv1a <- data/bias
I0628 19:46:16.265663  5852 net.cpp:529] conv1a -> conv1a
I0628 19:46:16.582965  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 1  (limit 7.87G, req 0G)
I0628 19:46:16.582996  5852 net.cpp:244] Setting up conv1a
I0628 19:46:16.583004  5852 net.cpp:251] TRAIN Top shape for layer 2 'conv1a' 64 32 112 112 (25690112)
I0628 19:46:16.583014  5852 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0628 19:46:16.583017  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.583027  5852 net.cpp:183] Created Layer conv1a/bn (3)
I0628 19:46:16.583030  5852 net.cpp:560] conv1a/bn <- conv1a
I0628 19:46:16.583035  5852 net.cpp:512] conv1a/bn -> conv1a (in-place)
I0628 19:46:16.583585  5852 net.cpp:244] Setting up conv1a/bn
I0628 19:46:16.583592  5852 net.cpp:251] TRAIN Top shape for layer 3 'conv1a/bn' 64 32 112 112 (25690112)
I0628 19:46:16.583600  5852 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0628 19:46:16.583601  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.583606  5852 net.cpp:183] Created Layer conv1a/relu (4)
I0628 19:46:16.583608  5852 net.cpp:560] conv1a/relu <- conv1a
I0628 19:46:16.583611  5852 net.cpp:512] conv1a/relu -> conv1a (in-place)
I0628 19:46:16.583623  5852 net.cpp:244] Setting up conv1a/relu
I0628 19:46:16.583627  5852 net.cpp:251] TRAIN Top shape for layer 4 'conv1a/relu' 64 32 112 112 (25690112)
I0628 19:46:16.583629  5852 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0628 19:46:16.583632  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.583645  5852 net.cpp:183] Created Layer conv1b (5)
I0628 19:46:16.583648  5852 net.cpp:560] conv1b <- conv1a
I0628 19:46:16.583650  5852 net.cpp:529] conv1b -> conv1b
I0628 19:46:16.612560  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.66G, req 0G)
I0628 19:46:16.612591  5852 net.cpp:244] Setting up conv1b
I0628 19:46:16.612599  5852 net.cpp:251] TRAIN Top shape for layer 5 'conv1b' 64 32 112 112 (25690112)
I0628 19:46:16.612609  5852 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0628 19:46:16.612613  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.612622  5852 net.cpp:183] Created Layer conv1b/bn (6)
I0628 19:46:16.612627  5852 net.cpp:560] conv1b/bn <- conv1b
I0628 19:46:16.612632  5852 net.cpp:512] conv1b/bn -> conv1b (in-place)
I0628 19:46:16.613358  5852 net.cpp:244] Setting up conv1b/bn
I0628 19:46:16.613384  5852 net.cpp:251] TRAIN Top shape for layer 6 'conv1b/bn' 64 32 112 112 (25690112)
I0628 19:46:16.613397  5852 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0628 19:46:16.613402  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.613409  5852 net.cpp:183] Created Layer conv1b/relu (7)
I0628 19:46:16.613412  5852 net.cpp:560] conv1b/relu <- conv1b
I0628 19:46:16.613417  5852 net.cpp:512] conv1b/relu -> conv1b (in-place)
I0628 19:46:16.613426  5852 net.cpp:244] Setting up conv1b/relu
I0628 19:46:16.613431  5852 net.cpp:251] TRAIN Top shape for layer 7 'conv1b/relu' 64 32 112 112 (25690112)
I0628 19:46:16.613435  5852 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0628 19:46:16.613438  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.613447  5852 net.cpp:183] Created Layer pool1 (8)
I0628 19:46:16.613452  5852 net.cpp:560] pool1 <- conv1b
I0628 19:46:16.613456  5852 net.cpp:529] pool1 -> pool1
I0628 19:46:16.613534  5852 net.cpp:244] Setting up pool1
I0628 19:46:16.613543  5852 net.cpp:251] TRAIN Top shape for layer 8 'pool1' 64 32 56 56 (6422528)
I0628 19:46:16.613561  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0628 19:46:16.613569  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.613584  5852 net.cpp:183] Created Layer res2a_branch2a (9)
I0628 19:46:16.613589  5852 net.cpp:560] res2a_branch2a <- pool1
I0628 19:46:16.613593  5852 net.cpp:529] res2a_branch2a -> res2a_branch2a
I0628 19:46:16.646313  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.5G, req 0G)
I0628 19:46:16.646342  5852 net.cpp:244] Setting up res2a_branch2a
I0628 19:46:16.646356  5852 net.cpp:251] TRAIN Top shape for layer 9 'res2a_branch2a' 64 64 56 56 (12845056)
I0628 19:46:16.646371  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.646378  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.646389  5852 net.cpp:183] Created Layer res2a_branch2a/bn (10)
I0628 19:46:16.646395  5852 net.cpp:560] res2a_branch2a/bn <- res2a_branch2a
I0628 19:46:16.646401  5852 net.cpp:512] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0628 19:46:16.647200  5852 net.cpp:244] Setting up res2a_branch2a/bn
I0628 19:46:16.647214  5852 net.cpp:251] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 64 64 56 56 (12845056)
I0628 19:46:16.647230  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.647238  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.647245  5852 net.cpp:183] Created Layer res2a_branch2a/relu (11)
I0628 19:46:16.647251  5852 net.cpp:560] res2a_branch2a/relu <- res2a_branch2a
I0628 19:46:16.647259  5852 net.cpp:512] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0628 19:46:16.647269  5852 net.cpp:244] Setting up res2a_branch2a/relu
I0628 19:46:16.647279  5852 net.cpp:251] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 64 64 56 56 (12845056)
I0628 19:46:16.647285  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0628 19:46:16.647294  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.647308  5852 net.cpp:183] Created Layer res2a_branch2b (12)
I0628 19:46:16.647313  5852 net.cpp:560] res2a_branch2b <- res2a_branch2a
I0628 19:46:16.647320  5852 net.cpp:529] res2a_branch2b -> res2a_branch2b
I0628 19:46:16.662880  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.4G, req 0G)
I0628 19:46:16.662925  5852 net.cpp:244] Setting up res2a_branch2b
I0628 19:46:16.662940  5852 net.cpp:251] TRAIN Top shape for layer 12 'res2a_branch2b' 64 64 56 56 (12845056)
I0628 19:46:16.662976  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.662987  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.663007  5852 net.cpp:183] Created Layer res2a_branch2b/bn (13)
I0628 19:46:16.663014  5852 net.cpp:560] res2a_branch2b/bn <- res2a_branch2b
I0628 19:46:16.663025  5852 net.cpp:512] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0628 19:46:16.663982  5852 net.cpp:244] Setting up res2a_branch2b/bn
I0628 19:46:16.663998  5852 net.cpp:251] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 64 64 56 56 (12845056)
I0628 19:46:16.664016  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.664024  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.664033  5852 net.cpp:183] Created Layer res2a_branch2b/relu (14)
I0628 19:46:16.664041  5852 net.cpp:560] res2a_branch2b/relu <- res2a_branch2b
I0628 19:46:16.664048  5852 net.cpp:512] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0628 19:46:16.664060  5852 net.cpp:244] Setting up res2a_branch2b/relu
I0628 19:46:16.664069  5852 net.cpp:251] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 64 64 56 56 (12845056)
I0628 19:46:16.664078  5852 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0628 19:46:16.664086  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.664098  5852 net.cpp:183] Created Layer pool2 (15)
I0628 19:46:16.664106  5852 net.cpp:560] pool2 <- res2a_branch2b
I0628 19:46:16.664115  5852 net.cpp:529] pool2 -> pool2
I0628 19:46:16.664206  5852 net.cpp:244] Setting up pool2
I0628 19:46:16.664216  5852 net.cpp:251] TRAIN Top shape for layer 15 'pool2' 64 64 28 28 (3211264)
I0628 19:46:16.664224  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0628 19:46:16.664233  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.664257  5852 net.cpp:183] Created Layer res3a_branch2a (16)
I0628 19:46:16.664263  5852 net.cpp:560] res3a_branch2a <- pool2
I0628 19:46:16.664271  5852 net.cpp:529] res3a_branch2a -> res3a_branch2a
I0628 19:46:16.693342  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 7.31G, req 0G)
I0628 19:46:16.693389  5852 net.cpp:244] Setting up res3a_branch2a
I0628 19:46:16.693406  5852 net.cpp:251] TRAIN Top shape for layer 16 'res3a_branch2a' 64 128 28 28 (6422528)
I0628 19:46:16.693425  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.693434  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.693454  5852 net.cpp:183] Created Layer res3a_branch2a/bn (17)
I0628 19:46:16.693464  5852 net.cpp:560] res3a_branch2a/bn <- res3a_branch2a
I0628 19:46:16.693472  5852 net.cpp:512] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0628 19:46:16.694442  5852 net.cpp:244] Setting up res3a_branch2a/bn
I0628 19:46:16.694458  5852 net.cpp:251] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 64 128 28 28 (6422528)
I0628 19:46:16.694479  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.694488  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.694496  5852 net.cpp:183] Created Layer res3a_branch2a/relu (18)
I0628 19:46:16.694505  5852 net.cpp:560] res3a_branch2a/relu <- res3a_branch2a
I0628 19:46:16.694512  5852 net.cpp:512] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0628 19:46:16.694525  5852 net.cpp:244] Setting up res3a_branch2a/relu
I0628 19:46:16.694535  5852 net.cpp:251] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 64 128 28 28 (6422528)
I0628 19:46:16.694542  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0628 19:46:16.694551  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.694583  5852 net.cpp:183] Created Layer res3a_branch2b (19)
I0628 19:46:16.694591  5852 net.cpp:560] res3a_branch2b <- res3a_branch2a
I0628 19:46:16.694598  5852 net.cpp:529] res3a_branch2b -> res3a_branch2b
I0628 19:46:16.707240  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.26G, req 0G)
I0628 19:46:16.707274  5852 net.cpp:244] Setting up res3a_branch2b
I0628 19:46:16.707289  5852 net.cpp:251] TRAIN Top shape for layer 19 'res3a_branch2b' 64 128 28 28 (6422528)
I0628 19:46:16.707304  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.707312  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.707325  5852 net.cpp:183] Created Layer res3a_branch2b/bn (20)
I0628 19:46:16.707334  5852 net.cpp:560] res3a_branch2b/bn <- res3a_branch2b
I0628 19:46:16.707341  5852 net.cpp:512] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0628 19:46:16.708233  5852 net.cpp:244] Setting up res3a_branch2b/bn
I0628 19:46:16.708250  5852 net.cpp:251] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 64 128 28 28 (6422528)
I0628 19:46:16.708267  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.708276  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.708284  5852 net.cpp:183] Created Layer res3a_branch2b/relu (21)
I0628 19:46:16.708292  5852 net.cpp:560] res3a_branch2b/relu <- res3a_branch2b
I0628 19:46:16.708299  5852 net.cpp:512] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0628 19:46:16.708310  5852 net.cpp:244] Setting up res3a_branch2b/relu
I0628 19:46:16.708320  5852 net.cpp:251] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 64 128 28 28 (6422528)
I0628 19:46:16.708328  5852 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0628 19:46:16.708335  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.708348  5852 net.cpp:183] Created Layer pool3 (22)
I0628 19:46:16.708354  5852 net.cpp:560] pool3 <- res3a_branch2b
I0628 19:46:16.708361  5852 net.cpp:529] pool3 -> pool3
I0628 19:46:16.708451  5852 net.cpp:244] Setting up pool3
I0628 19:46:16.708461  5852 net.cpp:251] TRAIN Top shape for layer 22 'pool3' 64 128 14 14 (1605632)
I0628 19:46:16.708470  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0628 19:46:16.708478  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.708495  5852 net.cpp:183] Created Layer res4a_branch2a (23)
I0628 19:46:16.708503  5852 net.cpp:560] res4a_branch2a <- pool3
I0628 19:46:16.708510  5852 net.cpp:529] res4a_branch2a -> res4a_branch2a
I0628 19:46:16.740785  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 3  (limit 7.21G, req 0G)
I0628 19:46:16.740814  5852 net.cpp:244] Setting up res4a_branch2a
I0628 19:46:16.740825  5852 net.cpp:251] TRAIN Top shape for layer 23 'res4a_branch2a' 64 256 14 14 (3211264)
I0628 19:46:16.740838  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.740842  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.740854  5852 net.cpp:183] Created Layer res4a_branch2a/bn (24)
I0628 19:46:16.740859  5852 net.cpp:560] res4a_branch2a/bn <- res4a_branch2a
I0628 19:46:16.740864  5852 net.cpp:512] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0628 19:46:16.741425  5852 net.cpp:244] Setting up res4a_branch2a/bn
I0628 19:46:16.741435  5852 net.cpp:251] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 64 256 14 14 (3211264)
I0628 19:46:16.741443  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.741447  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.741452  5852 net.cpp:183] Created Layer res4a_branch2a/relu (25)
I0628 19:46:16.741464  5852 net.cpp:560] res4a_branch2a/relu <- res4a_branch2a
I0628 19:46:16.741468  5852 net.cpp:512] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0628 19:46:16.741475  5852 net.cpp:244] Setting up res4a_branch2a/relu
I0628 19:46:16.741479  5852 net.cpp:251] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 64 256 14 14 (3211264)
I0628 19:46:16.741482  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0628 19:46:16.741487  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.741495  5852 net.cpp:183] Created Layer res4a_branch2b (26)
I0628 19:46:16.741499  5852 net.cpp:560] res4a_branch2b <- res4a_branch2a
I0628 19:46:16.741503  5852 net.cpp:529] res4a_branch2b -> res4a_branch2b
I0628 19:46:16.752436  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.18G, req 0G)
I0628 19:46:16.752455  5852 net.cpp:244] Setting up res4a_branch2b
I0628 19:46:16.752461  5852 net.cpp:251] TRAIN Top shape for layer 26 'res4a_branch2b' 64 256 14 14 (3211264)
I0628 19:46:16.752467  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.752470  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.752475  5852 net.cpp:183] Created Layer res4a_branch2b/bn (27)
I0628 19:46:16.752478  5852 net.cpp:560] res4a_branch2b/bn <- res4a_branch2b
I0628 19:46:16.752481  5852 net.cpp:512] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0628 19:46:16.752995  5852 net.cpp:244] Setting up res4a_branch2b/bn
I0628 19:46:16.753002  5852 net.cpp:251] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 64 256 14 14 (3211264)
I0628 19:46:16.753008  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.753011  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.753015  5852 net.cpp:183] Created Layer res4a_branch2b/relu (28)
I0628 19:46:16.753016  5852 net.cpp:560] res4a_branch2b/relu <- res4a_branch2b
I0628 19:46:16.753018  5852 net.cpp:512] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0628 19:46:16.753022  5852 net.cpp:244] Setting up res4a_branch2b/relu
I0628 19:46:16.753024  5852 net.cpp:251] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 64 256 14 14 (3211264)
I0628 19:46:16.753026  5852 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0628 19:46:16.753029  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.753033  5852 net.cpp:183] Created Layer pool4 (29)
I0628 19:46:16.753036  5852 net.cpp:560] pool4 <- res4a_branch2b
I0628 19:46:16.753041  5852 net.cpp:529] pool4 -> pool4
I0628 19:46:16.753085  5852 net.cpp:244] Setting up pool4
I0628 19:46:16.753089  5852 net.cpp:251] TRAIN Top shape for layer 29 'pool4' 64 256 7 7 (802816)
I0628 19:46:16.753093  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0628 19:46:16.753094  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.753100  5852 net.cpp:183] Created Layer res5a_branch2a (30)
I0628 19:46:16.753103  5852 net.cpp:560] res5a_branch2a <- pool4
I0628 19:46:16.753104  5852 net.cpp:529] res5a_branch2a -> res5a_branch2a
I0628 19:46:16.810206  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 3  (limit 7.14G, req 0G)
I0628 19:46:16.810232  5852 net.cpp:244] Setting up res5a_branch2a
I0628 19:46:16.810240  5852 net.cpp:251] TRAIN Top shape for layer 30 'res5a_branch2a' 64 512 7 7 (1605632)
I0628 19:46:16.810247  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.810250  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.810257  5852 net.cpp:183] Created Layer res5a_branch2a/bn (31)
I0628 19:46:16.810273  5852 net.cpp:560] res5a_branch2a/bn <- res5a_branch2a
I0628 19:46:16.810278  5852 net.cpp:512] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0628 19:46:16.810794  5852 net.cpp:244] Setting up res5a_branch2a/bn
I0628 19:46:16.810801  5852 net.cpp:251] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 64 512 7 7 (1605632)
I0628 19:46:16.810807  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.810809  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.810813  5852 net.cpp:183] Created Layer res5a_branch2a/relu (32)
I0628 19:46:16.810816  5852 net.cpp:560] res5a_branch2a/relu <- res5a_branch2a
I0628 19:46:16.810818  5852 net.cpp:512] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0628 19:46:16.810822  5852 net.cpp:244] Setting up res5a_branch2a/relu
I0628 19:46:16.810824  5852 net.cpp:251] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 64 512 7 7 (1605632)
I0628 19:46:16.810827  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0628 19:46:16.810828  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.810837  5852 net.cpp:183] Created Layer res5a_branch2b (33)
I0628 19:46:16.810839  5852 net.cpp:560] res5a_branch2b <- res5a_branch2a
I0628 19:46:16.810842  5852 net.cpp:529] res5a_branch2b -> res5a_branch2b
I0628 19:46:16.832038  5852 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 1  (limit 7.12G, req 0G)
I0628 19:46:16.832057  5852 net.cpp:244] Setting up res5a_branch2b
I0628 19:46:16.832065  5852 net.cpp:251] TRAIN Top shape for layer 33 'res5a_branch2b' 64 512 7 7 (1605632)
I0628 19:46:16.832077  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.832082  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.832092  5852 net.cpp:183] Created Layer res5a_branch2b/bn (34)
I0628 19:46:16.832094  5852 net.cpp:560] res5a_branch2b/bn <- res5a_branch2b
I0628 19:46:16.832099  5852 net.cpp:512] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0628 19:46:16.832625  5852 net.cpp:244] Setting up res5a_branch2b/bn
I0628 19:46:16.832633  5852 net.cpp:251] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 64 512 7 7 (1605632)
I0628 19:46:16.832643  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.832648  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.832653  5852 net.cpp:183] Created Layer res5a_branch2b/relu (35)
I0628 19:46:16.832655  5852 net.cpp:560] res5a_branch2b/relu <- res5a_branch2b
I0628 19:46:16.832659  5852 net.cpp:512] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0628 19:46:16.832665  5852 net.cpp:244] Setting up res5a_branch2b/relu
I0628 19:46:16.832670  5852 net.cpp:251] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 64 512 7 7 (1605632)
I0628 19:46:16.832674  5852 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0628 19:46:16.832679  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.832685  5852 net.cpp:183] Created Layer pool5 (36)
I0628 19:46:16.832689  5852 net.cpp:560] pool5 <- res5a_branch2b
I0628 19:46:16.832692  5852 net.cpp:529] pool5 -> pool5
I0628 19:46:16.832717  5852 net.cpp:244] Setting up pool5
I0628 19:46:16.832722  5852 net.cpp:251] TRAIN Top shape for layer 36 'pool5' 64 512 1 1 (32768)
I0628 19:46:16.832727  5852 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0628 19:46:16.832731  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.832739  5852 net.cpp:183] Created Layer fc1000 (37)
I0628 19:46:16.832742  5852 net.cpp:560] fc1000 <- pool5
I0628 19:46:16.832746  5852 net.cpp:529] fc1000 -> fc1000
I0628 19:46:16.843626  5852 net.cpp:244] Setting up fc1000
I0628 19:46:16.843650  5852 net.cpp:251] TRAIN Top shape for layer 37 'fc1000' 64 1000 (64000)
I0628 19:46:16.843674  5852 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0628 19:46:16.843680  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.843696  5852 net.cpp:183] Created Layer loss (38)
I0628 19:46:16.843701  5852 net.cpp:560] loss <- fc1000
I0628 19:46:16.843709  5852 net.cpp:560] loss <- label
I0628 19:46:16.843720  5852 net.cpp:529] loss -> loss
I0628 19:46:16.843890  5852 net.cpp:244] Setting up loss
I0628 19:46:16.843897  5852 net.cpp:251] TRAIN Top shape for layer 38 'loss' (1)
I0628 19:46:16.843901  5852 net.cpp:255]     with loss weight 1
I0628 19:46:16.843909  5852 net.cpp:322] loss needs backward computation.
I0628 19:46:16.843914  5852 net.cpp:322] fc1000 needs backward computation.
I0628 19:46:16.843917  5852 net.cpp:322] pool5 needs backward computation.
I0628 19:46:16.843921  5852 net.cpp:322] res5a_branch2b/relu needs backward computation.
I0628 19:46:16.843925  5852 net.cpp:322] res5a_branch2b/bn needs backward computation.
I0628 19:46:16.843928  5852 net.cpp:322] res5a_branch2b needs backward computation.
I0628 19:46:16.843932  5852 net.cpp:322] res5a_branch2a/relu needs backward computation.
I0628 19:46:16.843936  5852 net.cpp:322] res5a_branch2a/bn needs backward computation.
I0628 19:46:16.843940  5852 net.cpp:322] res5a_branch2a needs backward computation.
I0628 19:46:16.843943  5852 net.cpp:322] pool4 needs backward computation.
I0628 19:46:16.843947  5852 net.cpp:322] res4a_branch2b/relu needs backward computation.
I0628 19:46:16.843950  5852 net.cpp:322] res4a_branch2b/bn needs backward computation.
I0628 19:46:16.843953  5852 net.cpp:322] res4a_branch2b needs backward computation.
I0628 19:46:16.843957  5852 net.cpp:322] res4a_branch2a/relu needs backward computation.
I0628 19:46:16.843961  5852 net.cpp:322] res4a_branch2a/bn needs backward computation.
I0628 19:46:16.843966  5852 net.cpp:322] res4a_branch2a needs backward computation.
I0628 19:46:16.843969  5852 net.cpp:322] pool3 needs backward computation.
I0628 19:46:16.843973  5852 net.cpp:322] res3a_branch2b/relu needs backward computation.
I0628 19:46:16.843977  5852 net.cpp:322] res3a_branch2b/bn needs backward computation.
I0628 19:46:16.843981  5852 net.cpp:322] res3a_branch2b needs backward computation.
I0628 19:46:16.843986  5852 net.cpp:322] res3a_branch2a/relu needs backward computation.
I0628 19:46:16.843988  5852 net.cpp:322] res3a_branch2a/bn needs backward computation.
I0628 19:46:16.843992  5852 net.cpp:322] res3a_branch2a needs backward computation.
I0628 19:46:16.843997  5852 net.cpp:322] pool2 needs backward computation.
I0628 19:46:16.844000  5852 net.cpp:322] res2a_branch2b/relu needs backward computation.
I0628 19:46:16.844004  5852 net.cpp:322] res2a_branch2b/bn needs backward computation.
I0628 19:46:16.844007  5852 net.cpp:322] res2a_branch2b needs backward computation.
I0628 19:46:16.844012  5852 net.cpp:322] res2a_branch2a/relu needs backward computation.
I0628 19:46:16.844014  5852 net.cpp:322] res2a_branch2a/bn needs backward computation.
I0628 19:46:16.844018  5852 net.cpp:322] res2a_branch2a needs backward computation.
I0628 19:46:16.844022  5852 net.cpp:322] pool1 needs backward computation.
I0628 19:46:16.844027  5852 net.cpp:322] conv1b/relu needs backward computation.
I0628 19:46:16.844030  5852 net.cpp:322] conv1b/bn needs backward computation.
I0628 19:46:16.844033  5852 net.cpp:322] conv1b needs backward computation.
I0628 19:46:16.844038  5852 net.cpp:322] conv1a/relu needs backward computation.
I0628 19:46:16.844041  5852 net.cpp:322] conv1a/bn needs backward computation.
I0628 19:46:16.844045  5852 net.cpp:322] conv1a needs backward computation.
I0628 19:46:16.844048  5852 net.cpp:324] data/bias does not need backward computation.
I0628 19:46:16.844053  5852 net.cpp:324] data does not need backward computation.
I0628 19:46:16.844056  5852 net.cpp:366] This network produces output loss
I0628 19:46:16.844089  5852 net.cpp:388] Top memory (TRAIN) required for data: 1194590208 diff: 1194590216
I0628 19:46:16.844097  5852 net.cpp:391] Bottom memory (TRAIN) required for data: 1194590208 diff: 1194590208
I0628 19:46:16.844101  5852 net.cpp:394] Shared (in-place) memory (TRAIN) by data: 796393472 diff: 796393472
I0628 19:46:16.844105  5852 net.cpp:397] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0628 19:46:16.844108  5852 net.cpp:400] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0628 19:46:16.844111  5852 net.cpp:406] Network initialization done.
I0628 19:46:16.844483  5852 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/test.prototxt
I0628 19:46:16.844653  5852 net.cpp:77] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/ilsvrc12_val_lmdb"
    batch_size: 25
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0628 19:46:16.844753  5852 net.cpp:108] Using FLOAT as default forward math type
I0628 19:46:16.844758  5852 net.cpp:114] Using FLOAT as default backward math type
I0628 19:46:16.844760  5852 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0628 19:46:16.844764  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.844781  5852 net.cpp:183] Created Layer data (0)
I0628 19:46:16.844785  5852 net.cpp:529] data -> data
I0628 19:46:16.844790  5852 net.cpp:529] data -> label
I0628 19:46:16.844799  5852 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 25
I0628 19:46:16.844810  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 19:46:16.846181  5888 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0628 19:46:16.846700  5852 data_layer.cpp:188] ReshapePrefetch 25, 3, 224, 224
I0628 19:46:16.846756  5852 data_layer.cpp:206] Output data size: 25, 3, 224, 224
I0628 19:46:16.846761  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 19:46:16.846777  5852 net.cpp:244] Setting up data
I0628 19:46:16.846782  5852 net.cpp:251] TEST Top shape for layer 0 'data' 25 3 224 224 (3763200)
I0628 19:46:16.846786  5852 net.cpp:251] TEST Top shape for layer 0 'data' 25 (25)
I0628 19:46:16.846787  5852 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0628 19:46:16.846791  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.846796  5852 net.cpp:183] Created Layer label_data_1_split (1)
I0628 19:46:16.846797  5852 net.cpp:560] label_data_1_split <- label
I0628 19:46:16.846801  5852 net.cpp:529] label_data_1_split -> label_data_1_split_0
I0628 19:46:16.846806  5852 net.cpp:529] label_data_1_split -> label_data_1_split_1
I0628 19:46:16.846808  5852 net.cpp:529] label_data_1_split -> label_data_1_split_2
I0628 19:46:16.846853  5852 net.cpp:244] Setting up label_data_1_split
I0628 19:46:16.846863  5852 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 19:46:16.846868  5852 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 19:46:16.846870  5852 net.cpp:251] TEST Top shape for layer 1 'label_data_1_split' 25 (25)
I0628 19:46:16.846873  5852 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0628 19:46:16.846875  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.846884  5852 net.cpp:183] Created Layer data/bias (2)
I0628 19:46:16.846886  5852 net.cpp:560] data/bias <- data
I0628 19:46:16.846889  5852 net.cpp:529] data/bias -> data/bias
I0628 19:46:16.847036  5852 net.cpp:244] Setting up data/bias
I0628 19:46:16.847043  5852 net.cpp:251] TEST Top shape for layer 2 'data/bias' 25 3 224 224 (3763200)
I0628 19:46:16.847049  5852 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0628 19:46:16.847053  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.847059  5852 net.cpp:183] Created Layer conv1a (3)
I0628 19:46:16.847061  5852 net.cpp:560] conv1a <- data/bias
I0628 19:46:16.847064  5852 net.cpp:529] conv1a -> conv1a
I0628 19:46:16.847883  5889 data_layer.cpp:188] ReshapePrefetch 25, 3, 224, 224
I0628 19:46:16.847893  5889 data_layer.cpp:206] Output data size: 25, 3, 224, 224
I0628 19:46:16.852985  5889 data_layer.cpp:110] [0] Parser threads: 1
I0628 19:46:16.852999  5889 data_layer.cpp:112] [0] Transformer threads: 1
I0628 19:46:16.853144  5852 net.cpp:244] Setting up conv1a
I0628 19:46:16.853157  5852 net.cpp:251] TEST Top shape for layer 3 'conv1a' 25 32 112 112 (10035200)
I0628 19:46:16.853168  5852 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0628 19:46:16.853171  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.853179  5852 net.cpp:183] Created Layer conv1a/bn (4)
I0628 19:46:16.853183  5852 net.cpp:560] conv1a/bn <- conv1a
I0628 19:46:16.853185  5852 net.cpp:512] conv1a/bn -> conv1a (in-place)
I0628 19:46:16.854475  5852 net.cpp:244] Setting up conv1a/bn
I0628 19:46:16.854482  5852 net.cpp:251] TEST Top shape for layer 4 'conv1a/bn' 25 32 112 112 (10035200)
I0628 19:46:16.854490  5852 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0628 19:46:16.854493  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.854552  5852 net.cpp:183] Created Layer conv1a/relu (5)
I0628 19:46:16.854555  5852 net.cpp:560] conv1a/relu <- conv1a
I0628 19:46:16.854557  5852 net.cpp:512] conv1a/relu -> conv1a (in-place)
I0628 19:46:16.854562  5852 net.cpp:244] Setting up conv1a/relu
I0628 19:46:16.854565  5852 net.cpp:251] TEST Top shape for layer 5 'conv1a/relu' 25 32 112 112 (10035200)
I0628 19:46:16.854568  5852 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0628 19:46:16.854570  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.854578  5852 net.cpp:183] Created Layer conv1b (6)
I0628 19:46:16.854579  5852 net.cpp:560] conv1b <- conv1a
I0628 19:46:16.854581  5852 net.cpp:529] conv1b -> conv1b
I0628 19:46:16.859441  5852 net.cpp:244] Setting up conv1b
I0628 19:46:16.859452  5852 net.cpp:251] TEST Top shape for layer 6 'conv1b' 25 32 112 112 (10035200)
I0628 19:46:16.859457  5852 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0628 19:46:16.859460  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.859465  5852 net.cpp:183] Created Layer conv1b/bn (7)
I0628 19:46:16.859467  5852 net.cpp:560] conv1b/bn <- conv1b
I0628 19:46:16.859469  5852 net.cpp:512] conv1b/bn -> conv1b (in-place)
I0628 19:46:16.860575  5852 net.cpp:244] Setting up conv1b/bn
I0628 19:46:16.860584  5852 net.cpp:251] TEST Top shape for layer 7 'conv1b/bn' 25 32 112 112 (10035200)
I0628 19:46:16.860590  5852 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0628 19:46:16.860600  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.860605  5852 net.cpp:183] Created Layer conv1b/relu (8)
I0628 19:46:16.860607  5852 net.cpp:560] conv1b/relu <- conv1b
I0628 19:46:16.860610  5852 net.cpp:512] conv1b/relu -> conv1b (in-place)
I0628 19:46:16.860613  5852 net.cpp:244] Setting up conv1b/relu
I0628 19:46:16.860616  5852 net.cpp:251] TEST Top shape for layer 8 'conv1b/relu' 25 32 112 112 (10035200)
I0628 19:46:16.860618  5852 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0628 19:46:16.860621  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.860625  5852 net.cpp:183] Created Layer pool1 (9)
I0628 19:46:16.860628  5852 net.cpp:560] pool1 <- conv1b
I0628 19:46:16.860630  5852 net.cpp:529] pool1 -> pool1
I0628 19:46:16.860687  5852 net.cpp:244] Setting up pool1
I0628 19:46:16.860690  5852 net.cpp:251] TEST Top shape for layer 9 'pool1' 25 32 56 56 (2508800)
I0628 19:46:16.860693  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0628 19:46:16.860695  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.860702  5852 net.cpp:183] Created Layer res2a_branch2a (10)
I0628 19:46:16.860705  5852 net.cpp:560] res2a_branch2a <- pool1
I0628 19:46:16.860707  5852 net.cpp:529] res2a_branch2a -> res2a_branch2a
I0628 19:46:16.865917  5852 net.cpp:244] Setting up res2a_branch2a
I0628 19:46:16.865928  5852 net.cpp:251] TEST Top shape for layer 10 'res2a_branch2a' 25 64 56 56 (5017600)
I0628 19:46:16.865934  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.865937  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.865942  5852 net.cpp:183] Created Layer res2a_branch2a/bn (11)
I0628 19:46:16.865944  5852 net.cpp:560] res2a_branch2a/bn <- res2a_branch2a
I0628 19:46:16.865947  5852 net.cpp:512] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0628 19:46:16.866961  5852 net.cpp:244] Setting up res2a_branch2a/bn
I0628 19:46:16.866969  5852 net.cpp:251] TEST Top shape for layer 11 'res2a_branch2a/bn' 25 64 56 56 (5017600)
I0628 19:46:16.866976  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.866978  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.866981  5852 net.cpp:183] Created Layer res2a_branch2a/relu (12)
I0628 19:46:16.866983  5852 net.cpp:560] res2a_branch2a/relu <- res2a_branch2a
I0628 19:46:16.866986  5852 net.cpp:512] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0628 19:46:16.866989  5852 net.cpp:244] Setting up res2a_branch2a/relu
I0628 19:46:16.866992  5852 net.cpp:251] TEST Top shape for layer 12 'res2a_branch2a/relu' 25 64 56 56 (5017600)
I0628 19:46:16.866994  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0628 19:46:16.866997  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.867002  5852 net.cpp:183] Created Layer res2a_branch2b (13)
I0628 19:46:16.867005  5852 net.cpp:560] res2a_branch2b <- res2a_branch2a
I0628 19:46:16.867007  5852 net.cpp:529] res2a_branch2b -> res2a_branch2b
I0628 19:46:16.870131  5852 net.cpp:244] Setting up res2a_branch2b
I0628 19:46:16.870148  5852 net.cpp:251] TEST Top shape for layer 13 'res2a_branch2b' 25 64 56 56 (5017600)
I0628 19:46:16.870160  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.870167  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.870232  5852 net.cpp:183] Created Layer res2a_branch2b/bn (14)
I0628 19:46:16.870239  5852 net.cpp:560] res2a_branch2b/bn <- res2a_branch2b
I0628 19:46:16.870244  5852 net.cpp:512] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0628 19:46:16.871386  5852 net.cpp:244] Setting up res2a_branch2b/bn
I0628 19:46:16.871394  5852 net.cpp:251] TEST Top shape for layer 14 'res2a_branch2b/bn' 25 64 56 56 (5017600)
I0628 19:46:16.871402  5852 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.871404  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.871407  5852 net.cpp:183] Created Layer res2a_branch2b/relu (15)
I0628 19:46:16.871410  5852 net.cpp:560] res2a_branch2b/relu <- res2a_branch2b
I0628 19:46:16.871412  5852 net.cpp:512] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0628 19:46:16.871417  5852 net.cpp:244] Setting up res2a_branch2b/relu
I0628 19:46:16.871419  5852 net.cpp:251] TEST Top shape for layer 15 'res2a_branch2b/relu' 25 64 56 56 (5017600)
I0628 19:46:16.871421  5852 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0628 19:46:16.871423  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.871428  5852 net.cpp:183] Created Layer pool2 (16)
I0628 19:46:16.871433  5852 net.cpp:560] pool2 <- res2a_branch2b
I0628 19:46:16.871434  5852 net.cpp:529] pool2 -> pool2
I0628 19:46:16.871490  5852 net.cpp:244] Setting up pool2
I0628 19:46:16.871493  5852 net.cpp:251] TEST Top shape for layer 16 'pool2' 25 64 28 28 (1254400)
I0628 19:46:16.871495  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0628 19:46:16.871498  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.871505  5852 net.cpp:183] Created Layer res3a_branch2a (17)
I0628 19:46:16.871507  5852 net.cpp:560] res3a_branch2a <- pool2
I0628 19:46:16.871510  5852 net.cpp:529] res3a_branch2a -> res3a_branch2a
I0628 19:46:16.877359  5852 net.cpp:244] Setting up res3a_branch2a
I0628 19:46:16.877373  5852 net.cpp:251] TEST Top shape for layer 17 'res3a_branch2a' 25 128 28 28 (2508800)
I0628 19:46:16.877380  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.877384  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.877390  5852 net.cpp:183] Created Layer res3a_branch2a/bn (18)
I0628 19:46:16.877394  5852 net.cpp:560] res3a_branch2a/bn <- res3a_branch2a
I0628 19:46:16.877396  5852 net.cpp:512] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0628 19:46:16.879582  5852 net.cpp:244] Setting up res3a_branch2a/bn
I0628 19:46:16.879591  5852 net.cpp:251] TEST Top shape for layer 18 'res3a_branch2a/bn' 25 128 28 28 (2508800)
I0628 19:46:16.879600  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.879602  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.879608  5852 net.cpp:183] Created Layer res3a_branch2a/relu (19)
I0628 19:46:16.879611  5852 net.cpp:560] res3a_branch2a/relu <- res3a_branch2a
I0628 19:46:16.879613  5852 net.cpp:512] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0628 19:46:16.879617  5852 net.cpp:244] Setting up res3a_branch2a/relu
I0628 19:46:16.879621  5852 net.cpp:251] TEST Top shape for layer 19 'res3a_branch2a/relu' 25 128 28 28 (2508800)
I0628 19:46:16.879623  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0628 19:46:16.879626  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.879632  5852 net.cpp:183] Created Layer res3a_branch2b (20)
I0628 19:46:16.879636  5852 net.cpp:560] res3a_branch2b <- res3a_branch2a
I0628 19:46:16.879637  5852 net.cpp:529] res3a_branch2b -> res3a_branch2b
I0628 19:46:16.882172  5852 net.cpp:244] Setting up res3a_branch2b
I0628 19:46:16.882184  5852 net.cpp:251] TEST Top shape for layer 20 'res3a_branch2b' 25 128 28 28 (2508800)
I0628 19:46:16.882189  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.882192  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.882205  5852 net.cpp:183] Created Layer res3a_branch2b/bn (21)
I0628 19:46:16.882208  5852 net.cpp:560] res3a_branch2b/bn <- res3a_branch2b
I0628 19:46:16.882211  5852 net.cpp:512] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0628 19:46:16.883177  5852 net.cpp:244] Setting up res3a_branch2b/bn
I0628 19:46:16.883186  5852 net.cpp:251] TEST Top shape for layer 21 'res3a_branch2b/bn' 25 128 28 28 (2508800)
I0628 19:46:16.883193  5852 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.883196  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.883199  5852 net.cpp:183] Created Layer res3a_branch2b/relu (22)
I0628 19:46:16.883203  5852 net.cpp:560] res3a_branch2b/relu <- res3a_branch2b
I0628 19:46:16.883205  5852 net.cpp:512] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0628 19:46:16.883209  5852 net.cpp:244] Setting up res3a_branch2b/relu
I0628 19:46:16.883213  5852 net.cpp:251] TEST Top shape for layer 22 'res3a_branch2b/relu' 25 128 28 28 (2508800)
I0628 19:46:16.883215  5852 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0628 19:46:16.883219  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.883222  5852 net.cpp:183] Created Layer pool3 (23)
I0628 19:46:16.883224  5852 net.cpp:560] pool3 <- res3a_branch2b
I0628 19:46:16.883226  5852 net.cpp:529] pool3 -> pool3
I0628 19:46:16.883278  5852 net.cpp:244] Setting up pool3
I0628 19:46:16.883282  5852 net.cpp:251] TEST Top shape for layer 23 'pool3' 25 128 14 14 (627200)
I0628 19:46:16.883285  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0628 19:46:16.883287  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.883293  5852 net.cpp:183] Created Layer res4a_branch2a (24)
I0628 19:46:16.883296  5852 net.cpp:560] res4a_branch2a <- pool3
I0628 19:46:16.883299  5852 net.cpp:529] res4a_branch2a -> res4a_branch2a
I0628 19:46:16.892428  5852 net.cpp:244] Setting up res4a_branch2a
I0628 19:46:16.892438  5852 net.cpp:251] TEST Top shape for layer 24 'res4a_branch2a' 25 256 14 14 (1254400)
I0628 19:46:16.892444  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.892447  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.892452  5852 net.cpp:183] Created Layer res4a_branch2a/bn (25)
I0628 19:46:16.892455  5852 net.cpp:560] res4a_branch2a/bn <- res4a_branch2a
I0628 19:46:16.892457  5852 net.cpp:512] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0628 19:46:16.893401  5852 net.cpp:244] Setting up res4a_branch2a/bn
I0628 19:46:16.893409  5852 net.cpp:251] TEST Top shape for layer 25 'res4a_branch2a/bn' 25 256 14 14 (1254400)
I0628 19:46:16.893417  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.893420  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.893424  5852 net.cpp:183] Created Layer res4a_branch2a/relu (26)
I0628 19:46:16.893426  5852 net.cpp:560] res4a_branch2a/relu <- res4a_branch2a
I0628 19:46:16.893429  5852 net.cpp:512] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0628 19:46:16.893432  5852 net.cpp:244] Setting up res4a_branch2a/relu
I0628 19:46:16.893436  5852 net.cpp:251] TEST Top shape for layer 26 'res4a_branch2a/relu' 25 256 14 14 (1254400)
I0628 19:46:16.893438  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0628 19:46:16.893441  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.893446  5852 net.cpp:183] Created Layer res4a_branch2b (27)
I0628 19:46:16.893448  5852 net.cpp:560] res4a_branch2b <- res4a_branch2a
I0628 19:46:16.893451  5852 net.cpp:529] res4a_branch2b -> res4a_branch2b
I0628 19:46:16.897747  5852 net.cpp:244] Setting up res4a_branch2b
I0628 19:46:16.897764  5852 net.cpp:251] TEST Top shape for layer 27 'res4a_branch2b' 25 256 14 14 (1254400)
I0628 19:46:16.897770  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.897773  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.897778  5852 net.cpp:183] Created Layer res4a_branch2b/bn (28)
I0628 19:46:16.897781  5852 net.cpp:560] res4a_branch2b/bn <- res4a_branch2b
I0628 19:46:16.897784  5852 net.cpp:512] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0628 19:46:16.898746  5852 net.cpp:244] Setting up res4a_branch2b/bn
I0628 19:46:16.898754  5852 net.cpp:251] TEST Top shape for layer 28 'res4a_branch2b/bn' 25 256 14 14 (1254400)
I0628 19:46:16.898761  5852 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.898764  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.898767  5852 net.cpp:183] Created Layer res4a_branch2b/relu (29)
I0628 19:46:16.898771  5852 net.cpp:560] res4a_branch2b/relu <- res4a_branch2b
I0628 19:46:16.898773  5852 net.cpp:512] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0628 19:46:16.898777  5852 net.cpp:244] Setting up res4a_branch2b/relu
I0628 19:46:16.898780  5852 net.cpp:251] TEST Top shape for layer 29 'res4a_branch2b/relu' 25 256 14 14 (1254400)
I0628 19:46:16.898783  5852 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0628 19:46:16.898785  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.898793  5852 net.cpp:183] Created Layer pool4 (30)
I0628 19:46:16.898797  5852 net.cpp:560] pool4 <- res4a_branch2b
I0628 19:46:16.898798  5852 net.cpp:529] pool4 -> pool4
I0628 19:46:16.898852  5852 net.cpp:244] Setting up pool4
I0628 19:46:16.898856  5852 net.cpp:251] TEST Top shape for layer 30 'pool4' 25 256 7 7 (313600)
I0628 19:46:16.898860  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0628 19:46:16.898864  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.898874  5852 net.cpp:183] Created Layer res5a_branch2a (31)
I0628 19:46:16.898876  5852 net.cpp:560] res5a_branch2a <- pool4
I0628 19:46:16.898879  5852 net.cpp:529] res5a_branch2a -> res5a_branch2a
I0628 19:46:16.929250  5852 net.cpp:244] Setting up res5a_branch2a
I0628 19:46:16.929275  5852 net.cpp:251] TEST Top shape for layer 31 'res5a_branch2a' 25 512 7 7 (627200)
I0628 19:46:16.929286  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0628 19:46:16.929291  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.929303  5852 net.cpp:183] Created Layer res5a_branch2a/bn (32)
I0628 19:46:16.929308  5852 net.cpp:560] res5a_branch2a/bn <- res5a_branch2a
I0628 19:46:16.929316  5852 net.cpp:512] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0628 19:46:16.930868  5852 net.cpp:244] Setting up res5a_branch2a/bn
I0628 19:46:16.930905  5852 net.cpp:251] TEST Top shape for layer 32 'res5a_branch2a/bn' 25 512 7 7 (627200)
I0628 19:46:16.930929  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0628 19:46:16.930960  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.930974  5852 net.cpp:183] Created Layer res5a_branch2a/relu (33)
I0628 19:46:16.930982  5852 net.cpp:560] res5a_branch2a/relu <- res5a_branch2a
I0628 19:46:16.930989  5852 net.cpp:512] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0628 19:46:16.931004  5852 net.cpp:244] Setting up res5a_branch2a/relu
I0628 19:46:16.931010  5852 net.cpp:251] TEST Top shape for layer 33 'res5a_branch2a/relu' 25 512 7 7 (627200)
I0628 19:46:16.931015  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0628 19:46:16.931020  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.931052  5852 net.cpp:183] Created Layer res5a_branch2b (34)
I0628 19:46:16.931058  5852 net.cpp:560] res5a_branch2b <- res5a_branch2a
I0628 19:46:16.931062  5852 net.cpp:529] res5a_branch2b -> res5a_branch2b
I0628 19:46:16.949712  5852 net.cpp:244] Setting up res5a_branch2b
I0628 19:46:16.949730  5852 net.cpp:251] TEST Top shape for layer 34 'res5a_branch2b' 25 512 7 7 (627200)
I0628 19:46:16.949744  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0628 19:46:16.949749  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.949759  5852 net.cpp:183] Created Layer res5a_branch2b/bn (35)
I0628 19:46:16.949764  5852 net.cpp:560] res5a_branch2b/bn <- res5a_branch2b
I0628 19:46:16.949769  5852 net.cpp:512] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0628 19:46:16.950767  5852 net.cpp:244] Setting up res5a_branch2b/bn
I0628 19:46:16.950778  5852 net.cpp:251] TEST Top shape for layer 35 'res5a_branch2b/bn' 25 512 7 7 (627200)
I0628 19:46:16.950788  5852 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0628 19:46:16.950793  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.950798  5852 net.cpp:183] Created Layer res5a_branch2b/relu (36)
I0628 19:46:16.950801  5852 net.cpp:560] res5a_branch2b/relu <- res5a_branch2b
I0628 19:46:16.950806  5852 net.cpp:512] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0628 19:46:16.950814  5852 net.cpp:244] Setting up res5a_branch2b/relu
I0628 19:46:16.950817  5852 net.cpp:251] TEST Top shape for layer 36 'res5a_branch2b/relu' 25 512 7 7 (627200)
I0628 19:46:16.950821  5852 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0628 19:46:16.950825  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.950837  5852 net.cpp:183] Created Layer pool5 (37)
I0628 19:46:16.950841  5852 net.cpp:560] pool5 <- res5a_branch2b
I0628 19:46:16.950845  5852 net.cpp:529] pool5 -> pool5
I0628 19:46:16.950875  5852 net.cpp:244] Setting up pool5
I0628 19:46:16.950880  5852 net.cpp:251] TEST Top shape for layer 37 'pool5' 25 512 1 1 (12800)
I0628 19:46:16.950883  5852 layer_factory.hpp:136] Creating layer 'fc1000' of type 'InnerProduct'
I0628 19:46:16.950888  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.950894  5852 net.cpp:183] Created Layer fc1000 (38)
I0628 19:46:16.950897  5852 net.cpp:560] fc1000 <- pool5
I0628 19:46:16.950902  5852 net.cpp:529] fc1000 -> fc1000
I0628 19:46:16.961813  5852 net.cpp:244] Setting up fc1000
I0628 19:46:16.961834  5852 net.cpp:251] TEST Top shape for layer 38 'fc1000' 25 1000 (25000)
I0628 19:46:16.961844  5852 layer_factory.hpp:136] Creating layer 'fc1000_fc1000_0_split' of type 'Split'
I0628 19:46:16.961850  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.961858  5852 net.cpp:183] Created Layer fc1000_fc1000_0_split (39)
I0628 19:46:16.961863  5852 net.cpp:560] fc1000_fc1000_0_split <- fc1000
I0628 19:46:16.961869  5852 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_0
I0628 19:46:16.961874  5852 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_1
I0628 19:46:16.961880  5852 net.cpp:529] fc1000_fc1000_0_split -> fc1000_fc1000_0_split_2
I0628 19:46:16.961938  5852 net.cpp:244] Setting up fc1000_fc1000_0_split
I0628 19:46:16.961944  5852 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 25 1000 (25000)
I0628 19:46:16.961949  5852 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 25 1000 (25000)
I0628 19:46:16.961953  5852 net.cpp:251] TEST Top shape for layer 39 'fc1000_fc1000_0_split' 25 1000 (25000)
I0628 19:46:16.961957  5852 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0628 19:46:16.961961  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.961977  5852 net.cpp:183] Created Layer loss (40)
I0628 19:46:16.961982  5852 net.cpp:560] loss <- fc1000_fc1000_0_split_0
I0628 19:46:16.961985  5852 net.cpp:560] loss <- label_data_1_split_0
I0628 19:46:16.961989  5852 net.cpp:529] loss -> loss
I0628 19:46:16.962146  5852 net.cpp:244] Setting up loss
I0628 19:46:16.962152  5852 net.cpp:251] TEST Top shape for layer 40 'loss' (1)
I0628 19:46:16.962157  5852 net.cpp:255]     with loss weight 1
I0628 19:46:16.962164  5852 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0628 19:46:16.962168  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.962182  5852 net.cpp:183] Created Layer accuracy/top1 (41)
I0628 19:46:16.962185  5852 net.cpp:560] accuracy/top1 <- fc1000_fc1000_0_split_1
I0628 19:46:16.962189  5852 net.cpp:560] accuracy/top1 <- label_data_1_split_1
I0628 19:46:16.962194  5852 net.cpp:529] accuracy/top1 -> accuracy/top1
I0628 19:46:16.962201  5852 net.cpp:244] Setting up accuracy/top1
I0628 19:46:16.962205  5852 net.cpp:251] TEST Top shape for layer 41 'accuracy/top1' (1)
I0628 19:46:16.962209  5852 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0628 19:46:16.962213  5852 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0628 19:46:16.962218  5852 net.cpp:183] Created Layer accuracy/top5 (42)
I0628 19:46:16.962222  5852 net.cpp:560] accuracy/top5 <- fc1000_fc1000_0_split_2
I0628 19:46:16.962226  5852 net.cpp:560] accuracy/top5 <- label_data_1_split_2
I0628 19:46:16.962230  5852 net.cpp:529] accuracy/top5 -> accuracy/top5
I0628 19:46:16.962237  5852 net.cpp:244] Setting up accuracy/top5
I0628 19:46:16.962241  5852 net.cpp:251] TEST Top shape for layer 42 'accuracy/top5' (1)
I0628 19:46:16.962245  5852 net.cpp:324] accuracy/top5 does not need backward computation.
I0628 19:46:16.962249  5852 net.cpp:324] accuracy/top1 does not need backward computation.
I0628 19:46:16.962254  5852 net.cpp:322] loss needs backward computation.
I0628 19:46:16.962258  5852 net.cpp:322] fc1000_fc1000_0_split needs backward computation.
I0628 19:46:16.962261  5852 net.cpp:322] fc1000 needs backward computation.
I0628 19:46:16.962265  5852 net.cpp:322] pool5 needs backward computation.
I0628 19:46:16.962270  5852 net.cpp:322] res5a_branch2b/relu needs backward computation.
I0628 19:46:16.962273  5852 net.cpp:322] res5a_branch2b/bn needs backward computation.
I0628 19:46:16.962276  5852 net.cpp:322] res5a_branch2b needs backward computation.
I0628 19:46:16.962280  5852 net.cpp:322] res5a_branch2a/relu needs backward computation.
I0628 19:46:16.962285  5852 net.cpp:322] res5a_branch2a/bn needs backward computation.
I0628 19:46:16.962288  5852 net.cpp:322] res5a_branch2a needs backward computation.
I0628 19:46:16.962292  5852 net.cpp:322] pool4 needs backward computation.
I0628 19:46:16.962299  5852 net.cpp:322] res4a_branch2b/relu needs backward computation.
I0628 19:46:16.962302  5852 net.cpp:322] res4a_branch2b/bn needs backward computation.
I0628 19:46:16.962306  5852 net.cpp:322] res4a_branch2b needs backward computation.
I0628 19:46:16.962311  5852 net.cpp:322] res4a_branch2a/relu needs backward computation.
I0628 19:46:16.962314  5852 net.cpp:322] res4a_branch2a/bn needs backward computation.
I0628 19:46:16.962317  5852 net.cpp:322] res4a_branch2a needs backward computation.
I0628 19:46:16.962322  5852 net.cpp:322] pool3 needs backward computation.
I0628 19:46:16.962326  5852 net.cpp:322] res3a_branch2b/relu needs backward computation.
I0628 19:46:16.962329  5852 net.cpp:322] res3a_branch2b/bn needs backward computation.
I0628 19:46:16.962333  5852 net.cpp:322] res3a_branch2b needs backward computation.
I0628 19:46:16.962337  5852 net.cpp:322] res3a_branch2a/relu needs backward computation.
I0628 19:46:16.962340  5852 net.cpp:322] res3a_branch2a/bn needs backward computation.
I0628 19:46:16.962344  5852 net.cpp:322] res3a_branch2a needs backward computation.
I0628 19:46:16.962347  5852 net.cpp:322] pool2 needs backward computation.
I0628 19:46:16.962357  5852 net.cpp:322] res2a_branch2b/relu needs backward computation.
I0628 19:46:16.962360  5852 net.cpp:322] res2a_branch2b/bn needs backward computation.
I0628 19:46:16.962363  5852 net.cpp:322] res2a_branch2b needs backward computation.
I0628 19:46:16.962368  5852 net.cpp:322] res2a_branch2a/relu needs backward computation.
I0628 19:46:16.962371  5852 net.cpp:322] res2a_branch2a/bn needs backward computation.
I0628 19:46:16.962374  5852 net.cpp:322] res2a_branch2a needs backward computation.
I0628 19:46:16.962379  5852 net.cpp:322] pool1 needs backward computation.
I0628 19:46:16.962383  5852 net.cpp:322] conv1b/relu needs backward computation.
I0628 19:46:16.962388  5852 net.cpp:322] conv1b/bn needs backward computation.
I0628 19:46:16.962390  5852 net.cpp:322] conv1b needs backward computation.
I0628 19:46:16.962394  5852 net.cpp:322] conv1a/relu needs backward computation.
I0628 19:46:16.962399  5852 net.cpp:322] conv1a/bn needs backward computation.
I0628 19:46:16.962401  5852 net.cpp:322] conv1a needs backward computation.
I0628 19:46:16.962406  5852 net.cpp:324] data/bias does not need backward computation.
I0628 19:46:16.962410  5852 net.cpp:324] label_data_1_split does not need backward computation.
I0628 19:46:16.962415  5852 net.cpp:324] data does not need backward computation.
I0628 19:46:16.962419  5852 net.cpp:366] This network produces output accuracy/top1
I0628 19:46:16.962422  5852 net.cpp:366] This network produces output accuracy/top5
I0628 19:46:16.962426  5852 net.cpp:366] This network produces output loss
I0628 19:46:16.962457  5852 net.cpp:388] Top memory (TEST) required for data: 466636800 diff: 311091208
I0628 19:46:16.962460  5852 net.cpp:391] Bottom memory (TEST) required for data: 466636800 diff: 466636800
I0628 19:46:16.962463  5852 net.cpp:394] Shared (in-place) memory (TEST) by data: 311091200 diff: 311091200
I0628 19:46:16.962467  5852 net.cpp:397] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0628 19:46:16.962471  5852 net.cpp:400] Parameters shared memory (TEST) by data: 0 diff: 0
I0628 19:46:16.962474  5852 net.cpp:406] Network initialization done.
I0628 19:46:16.962532  5852 solver.cpp:56] Solver scaffolding done.
I0628 19:46:16.965543  5852 caffe.cpp:137] Finetuning from training/imagenet_jacintonet11v2_2017-06-28_19-45-45/initial/imagenet_jacintonet11v2_iter_100.caffemodel
I0628 19:46:16.970211  5852 net.cpp:1087] Copying source layer data Type:Data #blobs=0
I0628 19:46:16.970228  5852 net.cpp:1087] Copying source layer data/bias Type:Bias #blobs=1
I0628 19:46:16.970258  5852 net.cpp:1087] Copying source layer conv1a Type:Convolution #blobs=2
I0628 19:46:16.970271  5852 net.cpp:1087] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.970654  5852 net.cpp:1087] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0628 19:46:16.970660  5852 net.cpp:1087] Copying source layer conv1b Type:Convolution #blobs=2
I0628 19:46:16.970669  5852 net.cpp:1087] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.970943  5852 net.cpp:1087] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0628 19:46:16.970948  5852 net.cpp:1087] Copying source layer pool1 Type:Pooling #blobs=0
I0628 19:46:16.970950  5852 net.cpp:1087] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.970965  5852 net.cpp:1087] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.971237  5852 net.cpp:1087] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.971241  5852 net.cpp:1087] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.971253  5852 net.cpp:1087] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.971513  5852 net.cpp:1087] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.971516  5852 net.cpp:1087] Copying source layer pool2 Type:Pooling #blobs=0
I0628 19:46:16.971519  5852 net.cpp:1087] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.971556  5852 net.cpp:1087] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.971822  5852 net.cpp:1087] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.971827  5852 net.cpp:1087] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.971849  5852 net.cpp:1087] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.972092  5852 net.cpp:1087] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.972096  5852 net.cpp:1087] Copying source layer pool3 Type:Pooling #blobs=0
I0628 19:46:16.972100  5852 net.cpp:1087] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.972213  5852 net.cpp:1087] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.972462  5852 net.cpp:1087] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.972466  5852 net.cpp:1087] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.972523  5852 net.cpp:1087] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.972767  5852 net.cpp:1087] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.972772  5852 net.cpp:1087] Copying source layer pool4 Type:Pooling #blobs=0
I0628 19:46:16.972775  5852 net.cpp:1087] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.973139  5852 net.cpp:1087] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.973397  5852 net.cpp:1087] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.973402  5852 net.cpp:1087] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.973600  5852 net.cpp:1087] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.973850  5852 net.cpp:1087] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.973853  5852 net.cpp:1087] Copying source layer pool5 Type:Pooling #blobs=0
I0628 19:46:16.973855  5852 net.cpp:1087] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0628 19:46:16.973966  5852 net.cpp:1087] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0628 19:46:16.976938  5852 net.cpp:1087] Copying source layer data Type:Data #blobs=0
I0628 19:46:16.976955  5852 net.cpp:1087] Copying source layer data/bias Type:Bias #blobs=1
I0628 19:46:16.976979  5852 net.cpp:1087] Copying source layer conv1a Type:Convolution #blobs=2
I0628 19:46:16.976987  5852 net.cpp:1087] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.977363  5852 net.cpp:1087] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0628 19:46:16.977370  5852 net.cpp:1087] Copying source layer conv1b Type:Convolution #blobs=2
I0628 19:46:16.977377  5852 net.cpp:1087] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.977663  5852 net.cpp:1087] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0628 19:46:16.977669  5852 net.cpp:1087] Copying source layer pool1 Type:Pooling #blobs=0
I0628 19:46:16.977672  5852 net.cpp:1087] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.977686  5852 net.cpp:1087] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.977959  5852 net.cpp:1087] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.977964  5852 net.cpp:1087] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.977975  5852 net.cpp:1087] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.978242  5852 net.cpp:1087] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.978246  5852 net.cpp:1087] Copying source layer pool2 Type:Pooling #blobs=0
I0628 19:46:16.978250  5852 net.cpp:1087] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.978287  5852 net.cpp:1087] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.978543  5852 net.cpp:1087] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.978549  5852 net.cpp:1087] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.978580  5852 net.cpp:1087] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.978829  5852 net.cpp:1087] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.978834  5852 net.cpp:1087] Copying source layer pool3 Type:Pooling #blobs=0
I0628 19:46:16.978837  5852 net.cpp:1087] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.978948  5852 net.cpp:1087] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.979202  5852 net.cpp:1087] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.979207  5852 net.cpp:1087] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.979261  5852 net.cpp:1087] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.979511  5852 net.cpp:1087] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.979516  5852 net.cpp:1087] Copying source layer pool4 Type:Pooling #blobs=0
I0628 19:46:16.979518  5852 net.cpp:1087] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0628 19:46:16.979889  5852 net.cpp:1087] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0628 19:46:16.980137  5852 net.cpp:1087] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0628 19:46:16.980142  5852 net.cpp:1087] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0628 19:46:16.980314  5852 net.cpp:1087] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0628 19:46:16.980563  5852 net.cpp:1087] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0628 19:46:16.980568  5852 net.cpp:1087] Copying source layer pool5 Type:Pooling #blobs=0
I0628 19:46:16.980571  5852 net.cpp:1087] Copying source layer fc1000 Type:InnerProduct #blobs=2
I0628 19:46:16.980698  5852 net.cpp:1087] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0628 19:46:16.980761  5852 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0628 19:46:16.980764  5852 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0628 19:46:16.980767  5852 parallel.cpp:59] Starting Optimization
I0628 19:46:16.980768  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0628 19:46:16.980795  5852 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 19:46:16.981379  5893 device_alternate.hpp:116] NVML initialized on thread 139551194244864
I0628 19:46:16.993780  5893 common.cpp:563] NVML succeeded to set CPU affinity on device 0
I0628 19:46:16.993841  5894 device_alternate.hpp:116] NVML initialized on thread 139551185852160
I0628 19:46:16.994849  5894 common.cpp:563] NVML succeeded to set CPU affinity on device 1
I0628 19:46:16.998958  5894 solver.cpp:42] Solver data type: FLOAT
I0628 19:46:16.999387  5894 net.cpp:108] Using FLOAT as default forward math type
I0628 19:46:16.999393  5894 net.cpp:114] Using FLOAT as default backward math type
I0628 19:46:16.999426  5894 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 64
I0628 19:46:16.999444  5894 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 19:46:17.000151  5895 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_train_lmdb
I0628 19:46:17.001458  5894 data_layer.cpp:188] ReshapePrefetch 64, 3, 224, 224
I0628 19:46:17.001523  5894 data_layer.cpp:206] Output data size: 64, 3, 224, 224
I0628 19:46:17.001528  5894 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 19:46:17.318044  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 1  (limit 7.97G, req 0G)
I0628 19:46:17.347208  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 7.76G, req 0G)
I0628 19:46:17.381317  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.6G, req 0G)
I0628 19:46:17.399363  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 7.49G, req 0G)
I0628 19:46:17.432257  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 7.41G, req 0G)
I0628 19:46:17.446805  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.35G, req 0G)
I0628 19:46:17.486758  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.3G, req 0G)
I0628 19:46:17.501725  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.27G, req 0G)
I0628 19:46:17.566381  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 7.24G, req 0G)
I0628 19:46:17.589220  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 1  (limit 7.22G, req 0G)
I0628 19:46:17.601323  5894 solver.cpp:176] Creating test net (#0) specified by test_net file: training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/test.prototxt
I0628 19:46:17.601449  5894 net.cpp:108] Using FLOAT as default forward math type
I0628 19:46:17.601455  5894 net.cpp:114] Using FLOAT as default backward math type
I0628 19:46:17.601475  5894 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 25
I0628 19:46:17.601481  5894 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 19:46:17.602176  5910 db_lmdb.cpp:35] Opened lmdb ./data/ilsvrc12_val_lmdb
I0628 19:46:17.602890  5894 data_layer.cpp:188] ReshapePrefetch 25, 3, 224, 224
I0628 19:46:17.602955  5894 data_layer.cpp:206] Output data size: 25, 3, 224, 224
I0628 19:46:17.602962  5894 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0628 19:46:17.604609  5911 data_layer.cpp:188] ReshapePrefetch 25, 3, 224, 224
I0628 19:46:17.604619  5911 data_layer.cpp:206] Output data size: 25, 3, 224, 224
I0628 19:46:17.610676  5911 data_layer.cpp:110] [1] Parser threads: 1
I0628 19:46:17.610689  5911 data_layer.cpp:112] [1] Transformer threads: 1
I0628 19:46:17.717134  5894 solver.cpp:56] Solver scaffolding done.
I0628 19:46:17.733417  5894 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0628 19:46:17.733417  5893 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0628 19:46:17.833147  5894 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:46:17.833171  5893 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:46:17.836166  5894 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:46:17.838927  5894 solver.cpp:474] Solving jacintonet11v2_train
I0628 19:46:17.838943  5894 solver.cpp:475] Learning Rate Policy: poly
I0628 19:46:17.845163  5893 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:46:17.847910  5893 solver.cpp:474] Solving jacintonet11v2_train
I0628 19:46:17.847919  5893 solver.cpp:475] Learning Rate Policy: poly
I0628 19:46:17.853741  5893 solver.cpp:268] Starting Optimization on GPU 0
I0628 19:46:17.853744  5894 solver.cpp:268] Starting Optimization on GPU 1
I0628 19:46:17.853895  5912 device_alternate.hpp:116] NVML initialized on thread 139480262076160
I0628 19:46:17.853895  5893 solver.cpp:545] Iteration 0, Testing net (#0)
I0628 19:46:17.853917  5912 common.cpp:563] NVML succeeded to set CPU affinity on device 1
I0628 19:46:17.853935  5913 device_alternate.hpp:116] NVML initialized on thread 139480270468864
I0628 19:46:17.853953  5913 common.cpp:563] NVML succeeded to set CPU affinity on device 0
I0628 19:46:17.924871  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.52
I0628 19:46:17.924890  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.76
I0628 19:46:17.924893  5893 solver.cpp:630]     Test net output #2: loss = 2.03524 (* 1 = 2.03524 loss)
I0628 19:46:17.924897  5893 solver.cpp:295] [MultiGPU] Initial Test completed
I0628 19:46:17.924909  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 19:46:18.039353  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 6.23G, req 0G)
I0628 19:46:18.039790  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 6.31G, req 0G)
I0628 19:46:18.074092  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.03G, req 0G)
I0628 19:46:18.074283  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 6.1G, req 0G)
I0628 19:46:18.116564  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 5.8G, req 0G)
I0628 19:46:18.116703  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 5.87G, req 0G)
I0628 19:46:18.134948  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 5.69G, req 0G)
I0628 19:46:18.135239  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 5.76G, req 0G)
I0628 19:46:18.163748  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 5.64G, req 0G)
I0628 19:46:18.164275  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 5.57G, req 0G)
I0628 19:46:18.175712  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 5.59G, req 0G)
I0628 19:46:18.176242  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 1 4 3  (limit 5.52G, req 0G)
I0628 19:46:18.200623  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 5.53G, req 0G)
I0628 19:46:18.201176  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 5.45G, req 0G)
I0628 19:46:18.209803  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 5.42G, req 0G)
I0628 19:46:18.210002  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 5.5G, req 0G)
I0628 19:46:18.243017  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 5.46G, req 0G)
I0628 19:46:18.244040  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 5.39G, req 0G)
I0628 19:46:18.255853  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 3  (limit 5.37G, req 0G)
I0628 19:46:18.256345  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 1  (limit 5.45G, req 0G)
I0628 19:46:18.331495  5876 data_layer.cpp:188] ReshapePrefetch 64, 3, 224, 224
I0628 19:46:18.331512  5876 data_layer.cpp:206] Output data size: 64, 3, 224, 224
I0628 19:46:18.331552  5896 data_layer.cpp:188] ReshapePrefetch 64, 3, 224, 224
I0628 19:46:18.331567  5896 data_layer.cpp:206] Output data size: 64, 3, 224, 224
I0628 19:46:18.337468  5876 data_layer.cpp:110] [0] Parser threads: 1
I0628 19:46:18.337473  5876 data_layer.cpp:112] [0] Transformer threads: 1
I0628 19:46:18.337522  5896 data_layer.cpp:110] [1] Parser threads: 1
I0628 19:46:18.337527  5896 data_layer.cpp:112] [1] Transformer threads: 1
I0628 19:46:18.442276  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 4.94G, req 0G)
I0628 19:46:18.442904  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 1  (limit 5.02G, req 0G)
I0628 19:46:18.472646  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 4.94G, req 0G)
I0628 19:46:18.473165  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 6 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.509291  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 4.94G, req 0G)
I0628 19:46:18.509778  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.526551  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 4.94G, req 0G)
I0628 19:46:18.527040  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 0  (limit 5.02G, req 0G)
I0628 19:46:18.551466  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 1  (limit 4.94G, req 0G)
I0628 19:46:18.552170  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.561969  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 1 4 3  (limit 4.94G, req 0G)
I0628 19:46:18.562511  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 1 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.585119  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 4.94G, req 0G)
I0628 19:46:18.585269  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 5.02G, req 0G)
I0628 19:46:18.592551  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 4.94G, req 0G)
I0628 19:46:18.593046  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.623641  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 4.94G, req 0G)
I0628 19:46:18.623848  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 1 1 1  (limit 5.02G, req 0G)
I0628 19:46:18.631480  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 3  (limit 4.94G, req 0G)
I0628 19:46:18.631872  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 3  (limit 5.02G, req 0G)
I0628 19:46:18.696266  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.01
I0628 19:46:18.735853  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.78G/1 1 0 1  (limit 4.23G, req 0G)
I0628 19:46:18.792990  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.57G/2 6 4 3  (limit 3.45G, req 0G)
I0628 19:46:18.856400  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.57G/1 6 4 3  (limit 3.45G, req 0G)
I0628 19:46:18.882175  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.57G/2 6 4 0  (limit 3.45G, req 0G)
I0628 19:46:18.918507  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.57G/1 6 4 1  (limit 3.45G, req 0G)
I0628 19:46:18.931516  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.57G/2 1 4 3  (limit 3.45G, req 0G)
I0628 19:46:18.970207  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.57G/1 6 4 5  (limit 3.45G, req 0.06G)
I0628 19:46:18.980765  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.57G/2 6 4 3  (limit 3.45G, req 0.06G)
I0628 19:46:19.038497  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.57G/1 7 5 5  (limit 3.45G, req 0.06G)
I0628 19:46:19.050978  5894 cudnn_conv_layer.cpp:833] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.57G/2 7 5 5  (limit 3.45G, req 0.06G)
I0628 19:46:19.204886  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:46:19.208132  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:46:19.209180  5893 solver.cpp:354] Iteration 0 (1.28412 s), loss = 1.14481
I0628 19:46:19.209197  5893 solver.cpp:371]     Train net output #0: loss = 1.16442 (* 1 = 1.16442 loss)
I0628 19:46:19.209203  5893 sgd_solver.cpp:137] Iteration 0, lr = 0.01, m = 0.9
I0628 19:46:19.248414  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.78G/1 1 0 1  (limit 4.12G, req 0G)
I0628 19:46:19.302955  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.57G/2 6 4 3  (limit 3.34G, req 0G)
I0628 19:46:19.366585  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.57G/1 6 4 3  (limit 3.34G, req 0G)
I0628 19:46:19.393816  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.57G/2 6 4 0  (limit 3.34G, req 0G)
I0628 19:46:19.431293  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.57G/1 6 4 1  (limit 3.34G, req 0G)
I0628 19:46:19.448050  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.57G/2 6 4 3  (limit 3.34G, req 0G)
I0628 19:46:19.484071  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.57G/1 6 4 5  (limit 3.34G, req 0.06G)
I0628 19:46:19.496600  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.57G/2 6 4 3  (limit 3.34G, req 0.06G)
I0628 19:46:19.556473  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.57G/1 7 5 5  (limit 3.34G, req 0.06G)
I0628 19:46:19.576511  5893 cudnn_conv_layer.cpp:833] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.57G/2 7 5 5  (limit 3.34G, req 0.06G)
I0628 19:46:19.727735  5893 solver.cpp:354] Iteration 1 (0.51845 s), loss = 1.16145
I0628 19:46:19.727756  5893 solver.cpp:371]     Train net output #0: loss = 1.25085 (* 1 = 1.25085 loss)
I0628 19:46:19.911859  5893 solver.cpp:349] Iteration 2 (5.43276 iter/s, 0.184068s/100 iter), loss = 1.36039
I0628 19:46:19.911881  5893 solver.cpp:371]     Train net output #0: loss = 1.24964 (* 1 = 1.24964 loss)
I0628 19:46:20.289191  5894 cudnn_conv_layer.cpp:283] [1] Layer 'conv1a' reallocating workspace: 1.57G -> 0.12G
I0628 19:46:20.289258  5893 cudnn_conv_layer.cpp:283] [0] Layer 'conv1a' reallocating workspace: 1.57G -> 0.12G
I0628 19:46:37.852921  5893 solver.cpp:349] Iteration 100 (5.46297 iter/s, 17.939s/100 iter), loss = 1.13846
I0628 19:46:37.852944  5893 solver.cpp:371]     Train net output #0: loss = 1.20337 (* 1 = 1.20337 loss)
I0628 19:46:37.852948  5893 sgd_solver.cpp:137] Iteration 100, lr = 0.00999375, m = 0.9
I0628 19:46:56.180171  5893 solver.cpp:349] Iteration 200 (5.45701 iter/s, 18.3251s/100 iter), loss = 1.39082
I0628 19:46:56.180222  5893 solver.cpp:371]     Train net output #0: loss = 1.4948 (* 1 = 1.4948 loss)
I0628 19:46:56.180225  5893 sgd_solver.cpp:137] Iteration 200, lr = 0.0099875, m = 0.9
I0628 19:47:14.508884  5893 solver.cpp:349] Iteration 300 (5.45658 iter/s, 18.3265s/100 iter), loss = 1.62595
I0628 19:47:14.508908  5893 solver.cpp:371]     Train net output #0: loss = 1.7162 (* 1 = 1.7162 loss)
I0628 19:47:14.508911  5893 sgd_solver.cpp:137] Iteration 300, lr = 0.00998125, m = 0.9
I0628 19:47:32.847826  5893 solver.cpp:349] Iteration 400 (5.45354 iter/s, 18.3367s/100 iter), loss = 1.45173
I0628 19:47:32.847913  5893 solver.cpp:371]     Train net output #0: loss = 1.42119 (* 1 = 1.42119 loss)
I0628 19:47:32.847918  5893 sgd_solver.cpp:137] Iteration 400, lr = 0.009975, m = 0.9
I0628 19:47:51.184387  5893 solver.cpp:349] Iteration 500 (5.45428 iter/s, 18.3342s/100 iter), loss = 1.43333
I0628 19:47:51.184411  5893 solver.cpp:371]     Train net output #0: loss = 1.33737 (* 1 = 1.33737 loss)
I0628 19:47:51.184414  5893 sgd_solver.cpp:137] Iteration 500, lr = 0.00996875, m = 0.9
I0628 19:48:09.549808  5893 solver.cpp:349] Iteration 600 (5.44569 iter/s, 18.3631s/100 iter), loss = 1.49211
I0628 19:48:09.549852  5893 solver.cpp:371]     Train net output #0: loss = 1.64714 (* 1 = 1.64714 loss)
I0628 19:48:09.549859  5893 sgd_solver.cpp:137] Iteration 600, lr = 0.0099625, m = 0.9
I0628 19:48:27.910881  5893 solver.cpp:349] Iteration 700 (5.44699 iter/s, 18.3588s/100 iter), loss = 1.53047
I0628 19:48:27.910904  5893 solver.cpp:371]     Train net output #0: loss = 1.4815 (* 1 = 1.4815 loss)
I0628 19:48:27.910908  5893 sgd_solver.cpp:137] Iteration 700, lr = 0.00995625, m = 0.9
I0628 19:48:46.271548  5893 solver.cpp:349] Iteration 800 (5.44711 iter/s, 18.3584s/100 iter), loss = 1.60885
I0628 19:48:46.271639  5893 solver.cpp:371]     Train net output #0: loss = 1.55021 (* 1 = 1.55021 loss)
I0628 19:48:46.271646  5893 sgd_solver.cpp:137] Iteration 800, lr = 0.00995, m = 0.9
I0628 19:49:04.638108  5893 solver.cpp:349] Iteration 900 (5.44539 iter/s, 18.3642s/100 iter), loss = 1.26546
I0628 19:49:04.638134  5893 solver.cpp:371]     Train net output #0: loss = 1.27034 (* 1 = 1.27034 loss)
I0628 19:49:04.638139  5893 sgd_solver.cpp:137] Iteration 900, lr = 0.00994375, m = 0.9
I0628 19:49:22.836282  5893 solver.cpp:401] Sparsity after update:
I0628 19:49:22.844318  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 19:49:22.844336  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 19:49:22.844346  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 19:49:22.844348  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 19:49:22.844349  5893 net.cpp:2170] res2a_branch2a_param_0(0.00998) 
I0628 19:49:22.844352  5893 net.cpp:2170] res2a_branch2b_param_0(0.00998) 
I0628 19:49:22.844354  5893 net.cpp:2170] res3a_branch2a_param_0(0.00998) 
I0628 19:49:22.844357  5893 net.cpp:2170] res3a_branch2b_param_0(0.00998) 
I0628 19:49:22.844358  5893 net.cpp:2170] res4a_branch2a_param_0(0.00999) 
I0628 19:49:22.844360  5893 net.cpp:2170] res4a_branch2b_param_0(0.00999) 
I0628 19:49:22.844362  5893 net.cpp:2170] res5a_branch2a_param_0(0.01) 
I0628 19:49:22.844363  5893 net.cpp:2170] res5a_branch2b_param_0(0.00999) 
I0628 19:49:22.844367  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (23482/2.86678e+06) 0.00819
I0628 19:49:22.844375  5893 solver.cpp:545] Iteration 1000, Testing net (#0)
I0628 19:49:47.058897  5888 data_reader.cpp:262] Starting prefetch of epoch 1
I0628 19:49:47.282210  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55416
I0628 19:49:47.282232  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7932
I0628 19:49:47.282236  5893 solver.cpp:630]     Test net output #2: loss = 1.94563 (* 1 = 1.94563 loss)
I0628 19:49:47.282255  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4348s
I0628 19:49:47.467224  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.02
I0628 19:49:47.715313  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:49:47.716789  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:49:47.717473  5893 solver.cpp:349] Iteration 1000 (2.32159 iter/s, 43.0739s/100 iter), loss = 1.27798
I0628 19:49:47.717490  5893 solver.cpp:371]     Train net output #0: loss = 1.09823 (* 1 = 1.09823 loss)
I0628 19:49:47.717496  5893 sgd_solver.cpp:137] Iteration 1000, lr = 0.0099375, m = 0.9
I0628 19:50:06.117158  5893 solver.cpp:349] Iteration 1100 (5.43534 iter/s, 18.3981s/100 iter), loss = 1.637
I0628 19:50:06.117260  5893 solver.cpp:371]     Train net output #0: loss = 1.40301 (* 1 = 1.40301 loss)
I0628 19:50:06.117267  5893 sgd_solver.cpp:137] Iteration 1100, lr = 0.00993125, m = 0.9
I0628 19:50:24.558684  5893 solver.cpp:349] Iteration 1200 (5.42259 iter/s, 18.4414s/100 iter), loss = 1.58763
I0628 19:50:24.558708  5893 solver.cpp:371]     Train net output #0: loss = 1.80645 (* 1 = 1.80645 loss)
I0628 19:50:24.558712  5893 sgd_solver.cpp:137] Iteration 1200, lr = 0.009925, m = 0.9
I0628 19:50:42.984122  5893 solver.cpp:349] Iteration 1300 (5.42732 iter/s, 18.4253s/100 iter), loss = 1.37909
I0628 19:50:42.984220  5893 solver.cpp:371]     Train net output #0: loss = 1.49049 (* 1 = 1.49049 loss)
I0628 19:50:42.984227  5893 sgd_solver.cpp:137] Iteration 1300, lr = 0.00991875, m = 0.9
I0628 19:51:01.404222  5893 solver.cpp:349] Iteration 1400 (5.42895 iter/s, 18.4198s/100 iter), loss = 1.51964
I0628 19:51:01.404247  5893 solver.cpp:371]     Train net output #0: loss = 1.77202 (* 1 = 1.77202 loss)
I0628 19:51:01.404253  5893 sgd_solver.cpp:137] Iteration 1400, lr = 0.0099125, m = 0.9
I0628 19:51:19.825880  5893 solver.cpp:349] Iteration 1500 (5.42851 iter/s, 18.4213s/100 iter), loss = 1.6038
I0628 19:51:19.825994  5893 solver.cpp:371]     Train net output #0: loss = 1.72533 (* 1 = 1.72533 loss)
I0628 19:51:19.826001  5893 sgd_solver.cpp:137] Iteration 1500, lr = 0.00990625, m = 0.9
I0628 19:51:38.237061  5893 solver.cpp:349] Iteration 1600 (5.43165 iter/s, 18.4106s/100 iter), loss = 1.40055
I0628 19:51:38.237084  5893 solver.cpp:371]     Train net output #0: loss = 1.50886 (* 1 = 1.50886 loss)
I0628 19:51:38.237088  5893 sgd_solver.cpp:137] Iteration 1600, lr = 0.0099, m = 0.9
I0628 19:51:56.643909  5893 solver.cpp:349] Iteration 1700 (5.43292 iter/s, 18.4063s/100 iter), loss = 1.47619
I0628 19:51:56.644014  5893 solver.cpp:371]     Train net output #0: loss = 1.54655 (* 1 = 1.54655 loss)
I0628 19:51:56.644021  5893 sgd_solver.cpp:137] Iteration 1700, lr = 0.00989375, m = 0.9
I0628 19:52:15.082783  5893 solver.cpp:349] Iteration 1800 (5.42352 iter/s, 18.4382s/100 iter), loss = 1.56139
I0628 19:52:15.082805  5893 solver.cpp:371]     Train net output #0: loss = 1.477 (* 1 = 1.477 loss)
I0628 19:52:15.082809  5893 sgd_solver.cpp:137] Iteration 1800, lr = 0.0098875, m = 0.9
I0628 19:52:33.502902  5893 solver.cpp:349] Iteration 1900 (5.42904 iter/s, 18.4195s/100 iter), loss = 1.46788
I0628 19:52:33.503010  5893 solver.cpp:371]     Train net output #0: loss = 1.6508 (* 1 = 1.6508 loss)
I0628 19:52:33.503016  5893 sgd_solver.cpp:137] Iteration 1900, lr = 0.00988125, m = 0.9
I0628 19:52:51.744149  5893 solver.cpp:401] Sparsity after update:
I0628 19:52:51.749141  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 19:52:51.749179  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 19:52:51.749189  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 19:52:51.749191  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 19:52:51.749193  5893 net.cpp:2170] res2a_branch2a_param_0(0.02) 
I0628 19:52:51.749197  5893 net.cpp:2170] res2a_branch2b_param_0(0.02) 
I0628 19:52:51.749198  5893 net.cpp:2170] res3a_branch2a_param_0(0.02) 
I0628 19:52:51.749199  5893 net.cpp:2170] res3a_branch2b_param_0(0.02) 
I0628 19:52:51.749202  5893 net.cpp:2170] res4a_branch2a_param_0(0.02) 
I0628 19:52:51.749203  5893 net.cpp:2170] res4a_branch2b_param_0(0.02) 
I0628 19:52:51.749205  5893 net.cpp:2170] res5a_branch2a_param_0(0.02) 
I0628 19:52:51.749207  5893 net.cpp:2170] res5a_branch2b_param_0(0.02) 
I0628 19:52:51.749209  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (46979/2.86678e+06) 0.0164
I0628 19:52:51.749219  5893 solver.cpp:545] Iteration 2000, Testing net (#0)
I0628 19:53:16.099639  5888 data_reader.cpp:262] Starting prefetch of epoch 2
I0628 19:53:16.162798  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54824
I0628 19:53:16.162825  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79068
I0628 19:53:16.162834  5893 solver.cpp:630]     Test net output #2: loss = 1.96426 (* 1 = 1.96426 loss)
I0628 19:53:16.162856  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4127s
I0628 19:53:16.347069  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.03
I0628 19:53:16.595612  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:53:16.597093  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:53:16.597770  5893 solver.cpp:349] Iteration 2000 (2.32056 iter/s, 43.0931s/100 iter), loss = 1.2877
I0628 19:53:16.597789  5893 solver.cpp:371]     Train net output #0: loss = 1.421 (* 1 = 1.421 loss)
I0628 19:53:16.597793  5893 sgd_solver.cpp:137] Iteration 2000, lr = 0.009875, m = 0.9
I0628 19:53:35.003120  5893 solver.cpp:349] Iteration 2100 (5.43344 iter/s, 18.4045s/100 iter), loss = 1.43172
I0628 19:53:35.003144  5893 solver.cpp:371]     Train net output #0: loss = 1.16385 (* 1 = 1.16385 loss)
I0628 19:53:35.003147  5893 sgd_solver.cpp:137] Iteration 2100, lr = 0.00986875, m = 0.9
I0628 19:53:53.405443  5893 solver.cpp:349] Iteration 2200 (5.43436 iter/s, 18.4014s/100 iter), loss = 1.49235
I0628 19:53:53.405519  5893 solver.cpp:371]     Train net output #0: loss = 1.60001 (* 1 = 1.60001 loss)
I0628 19:53:53.405526  5893 sgd_solver.cpp:137] Iteration 2200, lr = 0.0098625, m = 0.9
I0628 19:54:11.826470  5893 solver.cpp:349] Iteration 2300 (5.42887 iter/s, 18.42s/100 iter), loss = 1.3438
I0628 19:54:11.826493  5893 solver.cpp:371]     Train net output #0: loss = 1.33731 (* 1 = 1.33731 loss)
I0628 19:54:11.826496  5893 sgd_solver.cpp:137] Iteration 2300, lr = 0.00985625, m = 0.9
I0628 19:54:30.243340  5893 solver.cpp:349] Iteration 2400 (5.43009 iter/s, 18.4159s/100 iter), loss = 1.36803
I0628 19:54:30.243445  5893 solver.cpp:371]     Train net output #0: loss = 1.51559 (* 1 = 1.51559 loss)
I0628 19:54:30.243453  5893 sgd_solver.cpp:137] Iteration 2400, lr = 0.00985, m = 0.9
I0628 19:54:48.645037  5893 solver.cpp:349] Iteration 2500 (5.43461 iter/s, 18.4006s/100 iter), loss = 1.36824
I0628 19:54:48.645061  5893 solver.cpp:371]     Train net output #0: loss = 1.47433 (* 1 = 1.47433 loss)
I0628 19:54:48.645064  5893 sgd_solver.cpp:137] Iteration 2500, lr = 0.00984375, m = 0.9
I0628 19:55:07.070827  5893 solver.cpp:349] Iteration 2600 (5.42749 iter/s, 18.4247s/100 iter), loss = 1.4651
I0628 19:55:07.070925  5893 solver.cpp:371]     Train net output #0: loss = 1.33134 (* 1 = 1.33134 loss)
I0628 19:55:07.070931  5893 sgd_solver.cpp:137] Iteration 2600, lr = 0.0098375, m = 0.9
I0628 19:55:25.484545  5893 solver.cpp:349] Iteration 2700 (5.43107 iter/s, 18.4126s/100 iter), loss = 1.34798
I0628 19:55:25.484568  5893 solver.cpp:371]     Train net output #0: loss = 1.36317 (* 1 = 1.36317 loss)
I0628 19:55:25.484573  5893 sgd_solver.cpp:137] Iteration 2700, lr = 0.00983125, m = 0.9
I0628 19:55:43.892237  5893 solver.cpp:349] Iteration 2800 (5.43251 iter/s, 18.4077s/100 iter), loss = 1.28655
I0628 19:55:43.892334  5893 solver.cpp:371]     Train net output #0: loss = 1.16264 (* 1 = 1.16264 loss)
I0628 19:55:43.892341  5893 sgd_solver.cpp:137] Iteration 2800, lr = 0.009825, m = 0.9
I0628 19:56:02.346227  5893 solver.cpp:349] Iteration 2900 (5.41892 iter/s, 18.4538s/100 iter), loss = 1.29118
I0628 19:56:02.346251  5893 solver.cpp:371]     Train net output #0: loss = 1.44033 (* 1 = 1.44033 loss)
I0628 19:56:02.346256  5893 sgd_solver.cpp:137] Iteration 2900, lr = 0.00981875, m = 0.9
I0628 19:56:20.592260  5893 solver.cpp:401] Sparsity after update:
I0628 19:56:20.597530  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 19:56:20.597540  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 19:56:20.597555  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 19:56:20.597558  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 19:56:20.597561  5893 net.cpp:2170] res2a_branch2a_param_0(0.0299) 
I0628 19:56:20.597565  5893 net.cpp:2170] res2a_branch2b_param_0(0.0299) 
I0628 19:56:20.597568  5893 net.cpp:2170] res3a_branch2a_param_0(0.03) 
I0628 19:56:20.597571  5893 net.cpp:2170] res3a_branch2b_param_0(0.03) 
I0628 19:56:20.597575  5893 net.cpp:2170] res4a_branch2a_param_0(0.03) 
I0628 19:56:20.597579  5893 net.cpp:2170] res4a_branch2b_param_0(0.03) 
I0628 19:56:20.597582  5893 net.cpp:2170] res5a_branch2a_param_0(0.03) 
I0628 19:56:20.597586  5893 net.cpp:2170] res5a_branch2b_param_0(0.03) 
I0628 19:56:20.597590  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (70478/2.86678e+06) 0.0246
I0628 19:56:20.597600  5893 solver.cpp:545] Iteration 3000, Testing net (#0)
I0628 19:56:44.900061  5888 data_reader.cpp:262] Starting prefetch of epoch 3
I0628 19:56:45.036602  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54388
I0628 19:56:45.036623  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.783359
I0628 19:56:45.036628  5893 solver.cpp:630]     Test net output #2: loss = 2.01611 (* 1 = 2.01611 loss)
I0628 19:56:45.036650  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4388s
I0628 19:56:45.222995  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.04
I0628 19:56:45.473706  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 19:56:45.475179  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 19:56:45.475852  5893 solver.cpp:349] Iteration 3000 (2.31861 iter/s, 43.1292s/100 iter), loss = 1.73404
I0628 19:56:45.475868  5893 solver.cpp:371]     Train net output #0: loss = 1.52866 (* 1 = 1.52866 loss)
I0628 19:56:45.475873  5893 sgd_solver.cpp:137] Iteration 3000, lr = 0.0098125, m = 0.9
I0628 19:57:03.880460  5893 solver.cpp:349] Iteration 3100 (5.43351 iter/s, 18.4043s/100 iter), loss = 1.32634
I0628 19:57:03.880575  5893 solver.cpp:371]     Train net output #0: loss = 1.40731 (* 1 = 1.40731 loss)
I0628 19:57:03.880584  5893 sgd_solver.cpp:137] Iteration 3100, lr = 0.00980625, m = 0.9
I0628 19:57:10.361425  5876 blocking_queue.cpp:40] Waiting for datum
I0628 19:57:22.554710  5893 solver.cpp:349] Iteration 3200 (5.3551 iter/s, 18.6738s/100 iter), loss = 1.30103
I0628 19:57:22.554734  5893 solver.cpp:371]     Train net output #0: loss = 1.41858 (* 1 = 1.41858 loss)
I0628 19:57:22.554738  5893 sgd_solver.cpp:137] Iteration 3200, lr = 0.0098, m = 0.9
I0628 19:57:40.975461  5893 solver.cpp:349] Iteration 3300 (5.42871 iter/s, 18.4206s/100 iter), loss = 1.33013
I0628 19:57:40.975642  5893 solver.cpp:371]     Train net output #0: loss = 1.14677 (* 1 = 1.14677 loss)
I0628 19:57:40.975651  5893 sgd_solver.cpp:137] Iteration 3300, lr = 0.00979375, m = 0.9
I0628 19:57:59.387868  5893 solver.cpp:349] Iteration 3400 (5.43102 iter/s, 18.4128s/100 iter), loss = 1.52237
I0628 19:57:59.387890  5893 solver.cpp:371]     Train net output #0: loss = 1.46596 (* 1 = 1.46596 loss)
I0628 19:57:59.387895  5893 sgd_solver.cpp:137] Iteration 3400, lr = 0.0097875, m = 0.9
I0628 19:58:17.794162  5893 solver.cpp:349] Iteration 3500 (5.4328 iter/s, 18.4067s/100 iter), loss = 1.597
I0628 19:58:17.794270  5893 solver.cpp:371]     Train net output #0: loss = 1.62866 (* 1 = 1.62866 loss)
I0628 19:58:17.794276  5893 sgd_solver.cpp:137] Iteration 3500, lr = 0.00978125, m = 0.9
I0628 19:58:36.208179  5893 solver.cpp:349] Iteration 3600 (5.43058 iter/s, 18.4143s/100 iter), loss = 1.48215
I0628 19:58:36.208205  5893 solver.cpp:371]     Train net output #0: loss = 1.58425 (* 1 = 1.58425 loss)
I0628 19:58:36.208212  5893 sgd_solver.cpp:137] Iteration 3600, lr = 0.009775, m = 0.9
I0628 19:58:54.609937  5893 solver.cpp:349] Iteration 3700 (5.43419 iter/s, 18.402s/100 iter), loss = 1.56428
I0628 19:58:54.610044  5893 solver.cpp:371]     Train net output #0: loss = 1.48821 (* 1 = 1.48821 loss)
I0628 19:58:54.610050  5893 sgd_solver.cpp:137] Iteration 3700, lr = 0.00976875, m = 0.9
I0628 19:59:13.050292  5893 solver.cpp:349] Iteration 3800 (5.42287 iter/s, 18.4404s/100 iter), loss = 1.45729
I0628 19:59:13.050312  5893 solver.cpp:371]     Train net output #0: loss = 1.44741 (* 1 = 1.44741 loss)
I0628 19:59:13.050317  5893 sgd_solver.cpp:137] Iteration 3800, lr = 0.0097625, m = 0.9
I0628 19:59:31.488982  5893 solver.cpp:349] Iteration 3900 (5.42336 iter/s, 18.4388s/100 iter), loss = 1.34306
I0628 19:59:31.489084  5893 solver.cpp:371]     Train net output #0: loss = 1.38362 (* 1 = 1.38362 loss)
I0628 19:59:31.489091  5893 sgd_solver.cpp:137] Iteration 3900, lr = 0.00975625, m = 0.9
I0628 19:59:49.744957  5893 solver.cpp:401] Sparsity after update:
I0628 19:59:49.750195  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 19:59:49.750203  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 19:59:49.750211  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 19:59:49.750216  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 19:59:49.750221  5893 net.cpp:2170] res2a_branch2a_param_0(0.04) 
I0628 19:59:49.750226  5893 net.cpp:2170] res2a_branch2b_param_0(0.0399) 
I0628 19:59:49.750231  5893 net.cpp:2170] res3a_branch2a_param_0(0.04) 
I0628 19:59:49.750234  5893 net.cpp:2170] res3a_branch2b_param_0(0.04) 
I0628 19:59:49.750237  5893 net.cpp:2170] res4a_branch2a_param_0(0.04) 
I0628 19:59:49.750241  5893 net.cpp:2170] res4a_branch2b_param_0(0.04) 
I0628 19:59:49.750247  5893 net.cpp:2170] res5a_branch2a_param_0(0.04) 
I0628 19:59:49.750249  5893 net.cpp:2170] res5a_branch2b_param_0(0.04) 
I0628 19:59:49.750252  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (93962/2.86678e+06) 0.0328
I0628 19:59:49.750263  5893 solver.cpp:545] Iteration 4000, Testing net (#0)
I0628 20:00:14.143666  5888 data_reader.cpp:262] Starting prefetch of epoch 4
I0628 20:00:14.365262  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5502
I0628 20:00:14.365281  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79284
I0628 20:00:14.365286  5893 solver.cpp:630]     Test net output #2: loss = 1.94653 (* 1 = 1.94653 loss)
I0628 20:00:14.365303  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.615s
I0628 20:00:14.549654  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.05
I0628 20:00:14.807871  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:00:14.809343  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:00:14.810022  5893 solver.cpp:349] Iteration 4000 (2.30836 iter/s, 43.3209s/100 iter), loss = 1.36986
I0628 20:00:14.810040  5893 solver.cpp:371]     Train net output #0: loss = 1.16168 (* 1 = 1.16168 loss)
I0628 20:00:14.810050  5893 sgd_solver.cpp:137] Iteration 4000, lr = 0.00975, m = 0.9
I0628 20:00:33.236002  5893 solver.cpp:349] Iteration 4100 (5.42717 iter/s, 18.4258s/100 iter), loss = 1.60279
I0628 20:00:33.236027  5893 solver.cpp:371]     Train net output #0: loss = 1.84588 (* 1 = 1.84588 loss)
I0628 20:00:33.236032  5893 sgd_solver.cpp:137] Iteration 4100, lr = 0.00974375, m = 0.9
I0628 20:00:51.639488  5893 solver.cpp:349] Iteration 4200 (5.43383 iter/s, 18.4032s/100 iter), loss = 1.74128
I0628 20:00:51.639559  5893 solver.cpp:371]     Train net output #0: loss = 1.80214 (* 1 = 1.80214 loss)
I0628 20:00:51.639565  5893 sgd_solver.cpp:137] Iteration 4200, lr = 0.0097375, m = 0.9
I0628 20:01:10.056773  5893 solver.cpp:349] Iteration 4300 (5.42979 iter/s, 18.4169s/100 iter), loss = 1.62279
I0628 20:01:10.056794  5893 solver.cpp:371]     Train net output #0: loss = 1.86745 (* 1 = 1.86745 loss)
I0628 20:01:10.056800  5893 sgd_solver.cpp:137] Iteration 4300, lr = 0.00973125, m = 0.9
I0628 20:01:28.482295  5893 solver.cpp:349] Iteration 4400 (5.42737 iter/s, 18.4251s/100 iter), loss = 1.25817
I0628 20:01:28.482394  5893 solver.cpp:371]     Train net output #0: loss = 1.10101 (* 1 = 1.10101 loss)
I0628 20:01:28.482401  5893 sgd_solver.cpp:137] Iteration 4400, lr = 0.009725, m = 0.9
I0628 20:01:46.898310  5893 solver.cpp:349] Iteration 4500 (5.43021 iter/s, 18.4155s/100 iter), loss = 1.47481
I0628 20:01:46.898334  5893 solver.cpp:371]     Train net output #0: loss = 1.21026 (* 1 = 1.21026 loss)
I0628 20:01:46.898339  5893 sgd_solver.cpp:137] Iteration 4500, lr = 0.00971875, m = 0.9
I0628 20:02:05.335861  5893 solver.cpp:349] Iteration 4600 (5.42386 iter/s, 18.4371s/100 iter), loss = 1.66247
I0628 20:02:05.335948  5893 solver.cpp:371]     Train net output #0: loss = 1.52065 (* 1 = 1.52065 loss)
I0628 20:02:05.335954  5893 sgd_solver.cpp:137] Iteration 4600, lr = 0.0097125, m = 0.9
I0628 20:02:23.793732  5893 solver.cpp:349] Iteration 4700 (5.41793 iter/s, 18.4572s/100 iter), loss = 1.42495
I0628 20:02:23.793752  5893 solver.cpp:371]     Train net output #0: loss = 1.3907 (* 1 = 1.3907 loss)
I0628 20:02:23.793756  5893 sgd_solver.cpp:137] Iteration 4700, lr = 0.00970625, m = 0.9
I0628 20:02:42.214973  5893 solver.cpp:349] Iteration 4800 (5.4287 iter/s, 18.4206s/100 iter), loss = 1.76505
I0628 20:02:42.215077  5893 solver.cpp:371]     Train net output #0: loss = 2.16784 (* 1 = 2.16784 loss)
I0628 20:02:42.215085  5893 sgd_solver.cpp:137] Iteration 4800, lr = 0.0097, m = 0.9
I0628 20:03:00.641204  5893 solver.cpp:349] Iteration 4900 (5.42727 iter/s, 18.4255s/100 iter), loss = 1.46808
I0628 20:03:00.641229  5893 solver.cpp:371]     Train net output #0: loss = 1.57483 (* 1 = 1.57483 loss)
I0628 20:03:00.641234  5893 sgd_solver.cpp:137] Iteration 4900, lr = 0.00969375, m = 0.9
I0628 20:03:18.909361  5893 solver.cpp:401] Sparsity after update:
I0628 20:03:18.914605  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:03:18.914613  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:03:18.914619  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 20:03:18.914621  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:03:18.914623  5893 net.cpp:2170] res2a_branch2a_param_0(0.05) 
I0628 20:03:18.914625  5893 net.cpp:2170] res2a_branch2b_param_0(0.0499) 
I0628 20:03:18.914628  5893 net.cpp:2170] res3a_branch2a_param_0(0.05) 
I0628 20:03:18.914629  5893 net.cpp:2170] res3a_branch2b_param_0(0.05) 
I0628 20:03:18.914631  5893 net.cpp:2170] res4a_branch2a_param_0(0.05) 
I0628 20:03:18.914633  5893 net.cpp:2170] res4a_branch2b_param_0(0.05) 
I0628 20:03:18.914635  5893 net.cpp:2170] res5a_branch2a_param_0(0.05) 
I0628 20:03:18.914638  5893 net.cpp:2170] res5a_branch2b_param_0(0.05) 
I0628 20:03:18.914639  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (117484/2.86678e+06) 0.041
I0628 20:03:18.914646  5893 solver.cpp:545] Iteration 5000, Testing net (#0)
I0628 20:03:43.324445  5888 data_reader.cpp:262] Starting prefetch of epoch 5
I0628 20:03:43.418546  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54416
I0628 20:03:43.418566  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78264
I0628 20:03:43.418571  5893 solver.cpp:630]     Test net output #2: loss = 2.01838 (* 1 = 2.01838 loss)
I0628 20:03:43.418586  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.503s
I0628 20:03:43.602846  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.06
I0628 20:03:43.846048  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:03:43.847517  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:03:43.848184  5893 solver.cpp:349] Iteration 5000 (2.31453 iter/s, 43.2053s/100 iter), loss = 1.36061
I0628 20:03:43.848201  5893 solver.cpp:371]     Train net output #0: loss = 1.42307 (* 1 = 1.42307 loss)
I0628 20:03:43.848206  5893 sgd_solver.cpp:137] Iteration 5000, lr = 0.0096875, m = 0.9
I0628 20:03:44.324545  5875 data_reader.cpp:262] Starting prefetch of epoch 1
I0628 20:04:02.249652  5893 solver.cpp:349] Iteration 5100 (5.43459 iter/s, 18.4006s/100 iter), loss = 1.55587
I0628 20:04:02.249759  5893 solver.cpp:371]     Train net output #0: loss = 1.45128 (* 1 = 1.45128 loss)
I0628 20:04:02.249765  5893 sgd_solver.cpp:137] Iteration 5100, lr = 0.00968125, m = 0.9
I0628 20:04:20.656389  5893 solver.cpp:349] Iteration 5200 (5.43308 iter/s, 18.4058s/100 iter), loss = 1.39076
I0628 20:04:20.656410  5893 solver.cpp:371]     Train net output #0: loss = 1.41913 (* 1 = 1.41913 loss)
I0628 20:04:20.656414  5893 sgd_solver.cpp:137] Iteration 5200, lr = 0.009675, m = 0.9
I0628 20:04:39.099089  5893 solver.cpp:349] Iteration 5300 (5.42247 iter/s, 18.4418s/100 iter), loss = 1.52031
I0628 20:04:39.099190  5893 solver.cpp:371]     Train net output #0: loss = 2.06006 (* 1 = 2.06006 loss)
I0628 20:04:39.099196  5893 sgd_solver.cpp:137] Iteration 5300, lr = 0.00966875, m = 0.9
I0628 20:04:57.509280  5893 solver.cpp:349] Iteration 5400 (5.43208 iter/s, 18.4091s/100 iter), loss = 1.51122
I0628 20:04:57.509299  5893 solver.cpp:371]     Train net output #0: loss = 1.49657 (* 1 = 1.49657 loss)
I0628 20:04:57.509305  5893 sgd_solver.cpp:137] Iteration 5400, lr = 0.0096625, m = 0.9
I0628 20:05:15.925226  5893 solver.cpp:349] Iteration 5500 (5.43037 iter/s, 18.4149s/100 iter), loss = 1.79972
I0628 20:05:15.925328  5893 solver.cpp:371]     Train net output #0: loss = 1.90926 (* 1 = 1.90926 loss)
I0628 20:05:15.925333  5893 sgd_solver.cpp:137] Iteration 5500, lr = 0.00965625, m = 0.9
I0628 20:05:34.327730  5893 solver.cpp:349] Iteration 5600 (5.43438 iter/s, 18.4014s/100 iter), loss = 1.4688
I0628 20:05:34.327754  5893 solver.cpp:371]     Train net output #0: loss = 1.50661 (* 1 = 1.50661 loss)
I0628 20:05:34.327757  5893 sgd_solver.cpp:137] Iteration 5600, lr = 0.00965, m = 0.9
I0628 20:05:52.749568  5893 solver.cpp:349] Iteration 5700 (5.42866 iter/s, 18.4207s/100 iter), loss = 1.86585
I0628 20:05:52.749683  5893 solver.cpp:371]     Train net output #0: loss = 1.81486 (* 1 = 1.81486 loss)
I0628 20:05:52.749691  5893 sgd_solver.cpp:137] Iteration 5700, lr = 0.00964375, m = 0.9
I0628 20:06:11.186200  5893 solver.cpp:349] Iteration 5800 (5.42434 iter/s, 18.4354s/100 iter), loss = 1.47765
I0628 20:06:11.186223  5893 solver.cpp:371]     Train net output #0: loss = 1.27164 (* 1 = 1.27164 loss)
I0628 20:06:11.186228  5893 sgd_solver.cpp:137] Iteration 5800, lr = 0.0096375, m = 0.9
I0628 20:06:29.609551  5893 solver.cpp:349] Iteration 5900 (5.42824 iter/s, 18.4222s/100 iter), loss = 1.46101
I0628 20:06:29.609655  5893 solver.cpp:371]     Train net output #0: loss = 1.44049 (* 1 = 1.44049 loss)
I0628 20:06:29.609663  5893 sgd_solver.cpp:137] Iteration 5900, lr = 0.00963125, m = 0.9
I0628 20:06:47.855811  5893 solver.cpp:401] Sparsity after update:
I0628 20:06:47.860993  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:06:47.861009  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:06:47.861016  5893 net.cpp:2170] conv1b_param_0(0) 
I0628 20:06:47.861018  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:06:47.861021  5893 net.cpp:2170] res2a_branch2a_param_0(0.06) 
I0628 20:06:47.861023  5893 net.cpp:2170] res2a_branch2b_param_0(0.0599) 
I0628 20:06:47.861026  5893 net.cpp:2170] res3a_branch2a_param_0(0.06) 
I0628 20:06:47.861027  5893 net.cpp:2170] res3a_branch2b_param_0(0.06) 
I0628 20:06:47.861032  5893 net.cpp:2170] res4a_branch2a_param_0(0.06) 
I0628 20:06:47.861033  5893 net.cpp:2170] res4a_branch2b_param_0(0.06) 
I0628 20:06:47.861035  5893 net.cpp:2170] res5a_branch2a_param_0(0.06) 
I0628 20:06:47.861037  5893 net.cpp:2170] res5a_branch2b_param_0(0.06) 
I0628 20:06:47.861038  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (140974/2.86678e+06) 0.0492
I0628 20:06:47.861047  5893 solver.cpp:545] Iteration 6000, Testing net (#0)
I0628 20:06:47.917199  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 20:07:12.139336  5888 data_reader.cpp:262] Starting prefetch of epoch 6
I0628 20:07:12.201336  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54308
I0628 20:07:12.201361  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78444
I0628 20:07:12.201366  5893 solver.cpp:630]     Test net output #2: loss = 2.01092 (* 1 = 2.01092 loss)
I0628 20:07:12.201392  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3388s
I0628 20:07:12.386250  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.07
I0628 20:07:12.634026  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:07:12.635502  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:07:12.636178  5893 solver.cpp:349] Iteration 6000 (2.3243 iter/s, 43.0238s/100 iter), loss = 1.26658
I0628 20:07:12.636195  5893 solver.cpp:371]     Train net output #0: loss = 1.41858 (* 1 = 1.41858 loss)
I0628 20:07:12.636199  5893 sgd_solver.cpp:137] Iteration 6000, lr = 0.009625, m = 0.9
I0628 20:07:31.047026  5893 solver.cpp:349] Iteration 6100 (5.43195 iter/s, 18.4096s/100 iter), loss = 1.20681
I0628 20:07:31.047047  5893 solver.cpp:371]     Train net output #0: loss = 1.23435 (* 1 = 1.23435 loss)
I0628 20:07:31.047051  5893 sgd_solver.cpp:137] Iteration 6100, lr = 0.00961875, m = 0.9
I0628 20:07:49.464284  5893 solver.cpp:349] Iteration 6200 (5.43007 iter/s, 18.416s/100 iter), loss = 1.47993
I0628 20:07:49.464380  5893 solver.cpp:371]     Train net output #0: loss = 1.50531 (* 1 = 1.50531 loss)
I0628 20:07:49.464386  5893 sgd_solver.cpp:137] Iteration 6200, lr = 0.0096125, m = 0.9
I0628 20:08:07.880688  5893 solver.cpp:349] Iteration 6300 (5.43036 iter/s, 18.415s/100 iter), loss = 1.44574
I0628 20:08:07.880707  5893 solver.cpp:371]     Train net output #0: loss = 1.58388 (* 1 = 1.58388 loss)
I0628 20:08:07.880712  5893 sgd_solver.cpp:137] Iteration 6300, lr = 0.00960625, m = 0.9
I0628 20:08:26.292512  5893 solver.cpp:349] Iteration 6400 (5.43169 iter/s, 18.4105s/100 iter), loss = 1.26332
I0628 20:08:26.292621  5893 solver.cpp:371]     Train net output #0: loss = 1.66208 (* 1 = 1.66208 loss)
I0628 20:08:26.292629  5893 sgd_solver.cpp:137] Iteration 6400, lr = 0.0096, m = 0.9
I0628 20:08:44.697742  5893 solver.cpp:349] Iteration 6500 (5.43368 iter/s, 18.4037s/100 iter), loss = 1.29312
I0628 20:08:44.697767  5893 solver.cpp:371]     Train net output #0: loss = 1.25775 (* 1 = 1.25775 loss)
I0628 20:08:44.697772  5893 sgd_solver.cpp:137] Iteration 6500, lr = 0.00959375, m = 0.9
I0628 20:09:03.177265  5893 solver.cpp:349] Iteration 6600 (5.41181 iter/s, 18.4781s/100 iter), loss = 1.42948
I0628 20:09:03.177371  5893 solver.cpp:371]     Train net output #0: loss = 1.14792 (* 1 = 1.14792 loss)
I0628 20:09:03.177377  5893 sgd_solver.cpp:137] Iteration 6600, lr = 0.0095875, m = 0.9
I0628 20:09:21.609946  5893 solver.cpp:349] Iteration 6700 (5.4256 iter/s, 18.4312s/100 iter), loss = 1.51948
I0628 20:09:21.609968  5893 solver.cpp:371]     Train net output #0: loss = 1.58706 (* 1 = 1.58706 loss)
I0628 20:09:21.609973  5893 sgd_solver.cpp:137] Iteration 6700, lr = 0.00958125, m = 0.9
I0628 20:09:40.040824  5893 solver.cpp:349] Iteration 6800 (5.42611 iter/s, 18.4294s/100 iter), loss = 1.5087
I0628 20:09:40.040930  5893 solver.cpp:371]     Train net output #0: loss = 1.65543 (* 1 = 1.65543 loss)
I0628 20:09:40.040936  5893 sgd_solver.cpp:137] Iteration 6800, lr = 0.009575, m = 0.9
I0628 20:09:58.485525  5893 solver.cpp:349] Iteration 6900 (5.42208 iter/s, 18.4431s/100 iter), loss = 1.42793
I0628 20:09:58.485554  5893 solver.cpp:371]     Train net output #0: loss = 1.23096 (* 1 = 1.23096 loss)
I0628 20:09:58.485560  5893 sgd_solver.cpp:137] Iteration 6900, lr = 0.00956875, m = 0.9
I0628 20:10:16.729370  5893 solver.cpp:401] Sparsity after update:
I0628 20:10:16.734619  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:10:16.734627  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:10:16.734633  5893 net.cpp:2170] conv1b_param_0(0.0699) 
I0628 20:10:16.734635  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:10:16.734637  5893 net.cpp:2170] res2a_branch2a_param_0(0.07) 
I0628 20:10:16.734639  5893 net.cpp:2170] res2a_branch2b_param_0(0.07) 
I0628 20:10:16.734642  5893 net.cpp:2170] res3a_branch2a_param_0(0.07) 
I0628 20:10:16.734643  5893 net.cpp:2170] res3a_branch2b_param_0(0.07) 
I0628 20:10:16.734645  5893 net.cpp:2170] res4a_branch2a_param_0(0.07) 
I0628 20:10:16.734647  5893 net.cpp:2170] res4a_branch2b_param_0(0.07) 
I0628 20:10:16.734649  5893 net.cpp:2170] res5a_branch2a_param_0(0.07) 
I0628 20:10:16.734652  5893 net.cpp:2170] res5a_branch2b_param_0(0.07) 
I0628 20:10:16.734652  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (164649/2.86678e+06) 0.0574
I0628 20:10:16.734659  5893 solver.cpp:545] Iteration 7000, Testing net (#0)
I0628 20:10:41.157335  5888 data_reader.cpp:262] Starting prefetch of epoch 7
I0628 20:10:41.219365  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54996
I0628 20:10:41.219389  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.788921
I0628 20:10:41.219394  5893 solver.cpp:630]     Test net output #2: loss = 1.96081 (* 1 = 1.96081 loss)
I0628 20:10:41.219411  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4828s
I0628 20:10:41.406447  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.08
I0628 20:10:41.662822  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:10:41.664304  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:10:41.664984  5893 solver.cpp:349] Iteration 7000 (2.31611 iter/s, 43.1759s/100 iter), loss = 1.11219
I0628 20:10:41.665002  5893 solver.cpp:371]     Train net output #0: loss = 0.924493 (* 1 = 0.924493 loss)
I0628 20:10:41.665007  5893 sgd_solver.cpp:137] Iteration 7000, lr = 0.0095625, m = 0.9
I0628 20:11:00.077855  5893 solver.cpp:349] Iteration 7100 (5.43086 iter/s, 18.4133s/100 iter), loss = 1.19385
I0628 20:11:00.077898  5893 solver.cpp:371]     Train net output #0: loss = 1.33585 (* 1 = 1.33585 loss)
I0628 20:11:00.077903  5893 sgd_solver.cpp:137] Iteration 7100, lr = 0.00955625, m = 0.9
I0628 20:11:18.491232  5893 solver.cpp:349] Iteration 7200 (5.43057 iter/s, 18.4143s/100 iter), loss = 1.21853
I0628 20:11:18.491255  5893 solver.cpp:371]     Train net output #0: loss = 1.05265 (* 1 = 1.05265 loss)
I0628 20:11:18.491259  5893 sgd_solver.cpp:137] Iteration 7200, lr = 0.00955, m = 0.9
I0628 20:11:36.915020  5893 solver.cpp:349] Iteration 7300 (5.42752 iter/s, 18.4246s/100 iter), loss = 1.49933
I0628 20:11:36.915103  5893 solver.cpp:371]     Train net output #0: loss = 1.54982 (* 1 = 1.54982 loss)
I0628 20:11:36.915108  5893 sgd_solver.cpp:137] Iteration 7300, lr = 0.00954375, m = 0.9
I0628 20:11:55.316087  5893 solver.cpp:349] Iteration 7400 (5.43427 iter/s, 18.4017s/100 iter), loss = 1.22673
I0628 20:11:55.316112  5893 solver.cpp:371]     Train net output #0: loss = 1.24693 (* 1 = 1.24693 loss)
I0628 20:11:55.316118  5893 sgd_solver.cpp:137] Iteration 7400, lr = 0.0095375, m = 0.9
I0628 20:12:13.722890  5893 solver.cpp:349] Iteration 7500 (5.43259 iter/s, 18.4074s/100 iter), loss = 1.4576
I0628 20:12:13.722995  5893 solver.cpp:371]     Train net output #0: loss = 1.49428 (* 1 = 1.49428 loss)
I0628 20:12:13.723002  5893 sgd_solver.cpp:137] Iteration 7500, lr = 0.00953125, m = 0.9
I0628 20:12:32.140389  5893 solver.cpp:349] Iteration 7600 (5.42949 iter/s, 18.418s/100 iter), loss = 1.43671
I0628 20:12:32.140413  5893 solver.cpp:371]     Train net output #0: loss = 1.41861 (* 1 = 1.41861 loss)
I0628 20:12:32.140419  5893 sgd_solver.cpp:137] Iteration 7600, lr = 0.009525, m = 0.9
I0628 20:12:50.573068  5893 solver.cpp:349] Iteration 7700 (5.42501 iter/s, 18.4331s/100 iter), loss = 1.68033
I0628 20:12:50.573555  5893 solver.cpp:371]     Train net output #0: loss = 1.58175 (* 1 = 1.58175 loss)
I0628 20:12:50.573563  5893 sgd_solver.cpp:137] Iteration 7700, lr = 0.00951875, m = 0.9
I0628 20:13:08.994273  5893 solver.cpp:349] Iteration 7800 (5.42855 iter/s, 18.4211s/100 iter), loss = 1.49948
I0628 20:13:08.994295  5893 solver.cpp:371]     Train net output #0: loss = 1.34415 (* 1 = 1.34415 loss)
I0628 20:13:08.994299  5893 sgd_solver.cpp:137] Iteration 7800, lr = 0.0095125, m = 0.9
I0628 20:13:27.424644  5893 solver.cpp:349] Iteration 7900 (5.42574 iter/s, 18.4307s/100 iter), loss = 1.38732
I0628 20:13:27.424743  5893 solver.cpp:371]     Train net output #0: loss = 1.48752 (* 1 = 1.48752 loss)
I0628 20:13:27.424751  5893 sgd_solver.cpp:137] Iteration 7900, lr = 0.00950625, m = 0.9
I0628 20:13:45.646581  5893 solver.cpp:401] Sparsity after update:
I0628 20:13:45.651734  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:13:45.651742  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:13:45.651748  5893 net.cpp:2170] conv1b_param_0(0.0799) 
I0628 20:13:45.651751  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:13:45.651753  5893 net.cpp:2170] res2a_branch2a_param_0(0.08) 
I0628 20:13:45.651756  5893 net.cpp:2170] res2a_branch2b_param_0(0.08) 
I0628 20:13:45.651757  5893 net.cpp:2170] res3a_branch2a_param_0(0.08) 
I0628 20:13:45.651758  5893 net.cpp:2170] res3a_branch2b_param_0(0.08) 
I0628 20:13:45.651760  5893 net.cpp:2170] res4a_branch2a_param_0(0.08) 
I0628 20:13:45.651762  5893 net.cpp:2170] res4a_branch2b_param_0(0.08) 
I0628 20:13:45.651764  5893 net.cpp:2170] res5a_branch2a_param_0(0.08) 
I0628 20:13:45.651767  5893 net.cpp:2170] res5a_branch2b_param_0(0.08) 
I0628 20:13:45.651768  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (188172/2.86678e+06) 0.0656
I0628 20:13:45.651774  5893 solver.cpp:545] Iteration 8000, Testing net (#0)
I0628 20:14:09.946404  5888 data_reader.cpp:262] Starting prefetch of epoch 8
I0628 20:14:10.016263  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.560561
I0628 20:14:10.016285  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79708
I0628 20:14:10.016293  5893 solver.cpp:630]     Test net output #2: loss = 1.92671 (* 1 = 1.92671 loss)
I0628 20:14:10.016311  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3648s
I0628 20:14:10.201738  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.09
I0628 20:14:10.462569  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:14:10.464046  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:14:10.464726  5893 solver.cpp:349] Iteration 8000 (2.3234 iter/s, 43.0405s/100 iter), loss = 1.55301
I0628 20:14:10.464745  5893 solver.cpp:371]     Train net output #0: loss = 1.16596 (* 1 = 1.16596 loss)
I0628 20:14:10.464749  5893 sgd_solver.cpp:137] Iteration 8000, lr = 0.0095, m = 0.9
I0628 20:14:28.879214  5893 solver.cpp:349] Iteration 8100 (5.43049 iter/s, 18.4145s/100 iter), loss = 1.36227
I0628 20:14:28.879236  5893 solver.cpp:371]     Train net output #0: loss = 1.1523 (* 1 = 1.1523 loss)
I0628 20:14:28.879242  5893 sgd_solver.cpp:137] Iteration 8100, lr = 0.00949375, m = 0.9
I0628 20:14:47.330025  5893 solver.cpp:349] Iteration 8200 (5.41982 iter/s, 18.4508s/100 iter), loss = 1.33706
I0628 20:14:47.330080  5893 solver.cpp:371]     Train net output #0: loss = 1.44589 (* 1 = 1.44589 loss)
I0628 20:14:47.330085  5893 sgd_solver.cpp:137] Iteration 8200, lr = 0.0094875, m = 0.9
I0628 20:15:05.754632  5893 solver.cpp:349] Iteration 8300 (5.42756 iter/s, 18.4245s/100 iter), loss = 1.62826
I0628 20:15:05.754655  5893 solver.cpp:371]     Train net output #0: loss = 1.8642 (* 1 = 1.8642 loss)
I0628 20:15:05.754659  5893 sgd_solver.cpp:137] Iteration 8300, lr = 0.00948125, m = 0.9
I0628 20:15:24.180197  5893 solver.cpp:349] Iteration 8400 (5.42728 iter/s, 18.4254s/100 iter), loss = 1.65398
I0628 20:15:24.180297  5893 solver.cpp:371]     Train net output #0: loss = 1.74857 (* 1 = 1.74857 loss)
I0628 20:15:24.180304  5893 sgd_solver.cpp:137] Iteration 8400, lr = 0.009475, m = 0.9
I0628 20:15:42.591439  5893 solver.cpp:349] Iteration 8500 (5.43155 iter/s, 18.411s/100 iter), loss = 1.63913
I0628 20:15:42.591462  5893 solver.cpp:371]     Train net output #0: loss = 1.52394 (* 1 = 1.52394 loss)
I0628 20:15:42.591466  5893 sgd_solver.cpp:137] Iteration 8500, lr = 0.00946875, m = 0.9
I0628 20:16:01.001802  5893 solver.cpp:349] Iteration 8600 (5.4318 iter/s, 18.4101s/100 iter), loss = 1.28699
I0628 20:16:01.001852  5893 solver.cpp:371]     Train net output #0: loss = 1.26068 (* 1 = 1.26068 loss)
I0628 20:16:01.001857  5893 sgd_solver.cpp:137] Iteration 8600, lr = 0.0094625, m = 0.9
I0628 20:16:19.432749  5893 solver.cpp:349] Iteration 8700 (5.42576 iter/s, 18.4306s/100 iter), loss = 1.13096
I0628 20:16:19.432773  5893 solver.cpp:371]     Train net output #0: loss = 1.07897 (* 1 = 1.07897 loss)
I0628 20:16:19.432777  5893 sgd_solver.cpp:137] Iteration 8700, lr = 0.00945625, m = 0.9
I0628 20:16:37.859885  5893 solver.cpp:349] Iteration 8800 (5.42689 iter/s, 18.4268s/100 iter), loss = 1.37235
I0628 20:16:37.859989  5893 solver.cpp:371]     Train net output #0: loss = 1.54264 (* 1 = 1.54264 loss)
I0628 20:16:37.859997  5893 sgd_solver.cpp:137] Iteration 8800, lr = 0.00945, m = 0.9
I0628 20:16:56.287444  5893 solver.cpp:349] Iteration 8900 (5.42681 iter/s, 18.427s/100 iter), loss = 1.44607
I0628 20:16:56.287468  5893 solver.cpp:371]     Train net output #0: loss = 1.48897 (* 1 = 1.48897 loss)
I0628 20:16:56.287472  5893 sgd_solver.cpp:137] Iteration 8900, lr = 0.00944375, m = 0.9
I0628 20:17:14.556325  5893 solver.cpp:401] Sparsity after update:
I0628 20:17:14.561558  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:17:14.561566  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:17:14.561574  5893 net.cpp:2170] conv1b_param_0(0.0898) 
I0628 20:17:14.561578  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:17:14.561581  5893 net.cpp:2170] res2a_branch2a_param_0(0.09) 
I0628 20:17:14.561585  5893 net.cpp:2170] res2a_branch2b_param_0(0.09) 
I0628 20:17:14.561589  5893 net.cpp:2170] res3a_branch2a_param_0(0.09) 
I0628 20:17:14.561591  5893 net.cpp:2170] res3a_branch2b_param_0(0.09) 
I0628 20:17:14.561594  5893 net.cpp:2170] res4a_branch2a_param_0(0.09) 
I0628 20:17:14.561597  5893 net.cpp:2170] res4a_branch2b_param_0(0.09) 
I0628 20:17:14.561600  5893 net.cpp:2170] res5a_branch2a_param_0(0.09) 
I0628 20:17:14.561602  5893 net.cpp:2170] res5a_branch2b_param_0(0.09) 
I0628 20:17:14.561606  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (211693/2.86678e+06) 0.0738
I0628 20:17:14.561616  5893 solver.cpp:545] Iteration 9000, Testing net (#0)
I0628 20:17:39.028079  5888 data_reader.cpp:262] Starting prefetch of epoch 9
I0628 20:17:39.090649  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55544
I0628 20:17:39.090672  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798601
I0628 20:17:39.090680  5893 solver.cpp:630]     Test net output #2: loss = 1.91885 (* 1 = 1.91885 loss)
I0628 20:17:39.090700  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5284s
I0628 20:17:39.275641  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.1
I0628 20:17:39.529342  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:17:39.530823  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:17:39.531500  5893 solver.cpp:349] Iteration 9000 (2.31252 iter/s, 43.2429s/100 iter), loss = 1.46376
I0628 20:17:39.531519  5893 solver.cpp:371]     Train net output #0: loss = 1.4648 (* 1 = 1.4648 loss)
I0628 20:17:39.531527  5893 sgd_solver.cpp:137] Iteration 9000, lr = 0.0094375, m = 0.9
I0628 20:17:57.953948  5893 solver.cpp:349] Iteration 9100 (5.42834 iter/s, 18.4219s/100 iter), loss = 1.3565
I0628 20:17:57.954046  5893 solver.cpp:371]     Train net output #0: loss = 1.39812 (* 1 = 1.39812 loss)
I0628 20:17:57.954054  5893 sgd_solver.cpp:137] Iteration 9100, lr = 0.00943125, m = 0.9
I0628 20:18:16.370678  5893 solver.cpp:349] Iteration 9200 (5.43006 iter/s, 18.416s/100 iter), loss = 1.3387
I0628 20:18:16.370700  5893 solver.cpp:371]     Train net output #0: loss = 1.3429 (* 1 = 1.3429 loss)
I0628 20:18:16.370704  5893 sgd_solver.cpp:137] Iteration 9200, lr = 0.009425, m = 0.9
I0628 20:18:34.780158  5893 solver.cpp:349] Iteration 9300 (5.43218 iter/s, 18.4088s/100 iter), loss = 1.40787
I0628 20:18:34.780256  5893 solver.cpp:371]     Train net output #0: loss = 1.37097 (* 1 = 1.37097 loss)
I0628 20:18:34.780262  5893 sgd_solver.cpp:137] Iteration 9300, lr = 0.00941875, m = 0.9
I0628 20:18:53.203760  5893 solver.cpp:349] Iteration 9400 (5.42806 iter/s, 18.4228s/100 iter), loss = 1.47107
I0628 20:18:53.203783  5893 solver.cpp:371]     Train net output #0: loss = 1.65507 (* 1 = 1.65507 loss)
I0628 20:18:53.203788  5893 sgd_solver.cpp:137] Iteration 9400, lr = 0.0094125, m = 0.9
I0628 20:19:11.609975  5893 solver.cpp:349] Iteration 9500 (5.43317 iter/s, 18.4055s/100 iter), loss = 1.36382
I0628 20:19:11.610074  5893 solver.cpp:371]     Train net output #0: loss = 1.44516 (* 1 = 1.44516 loss)
I0628 20:19:11.610081  5893 sgd_solver.cpp:137] Iteration 9500, lr = 0.00940625, m = 0.9
I0628 20:19:30.009707  5893 solver.cpp:349] Iteration 9600 (5.43512 iter/s, 18.3989s/100 iter), loss = 1.31641
I0628 20:19:30.009730  5893 solver.cpp:371]     Train net output #0: loss = 1.42953 (* 1 = 1.42953 loss)
I0628 20:19:30.009734  5893 sgd_solver.cpp:137] Iteration 9600, lr = 0.0094, m = 0.9
I0628 20:19:48.411181  5893 solver.cpp:349] Iteration 9700 (5.43459 iter/s, 18.4006s/100 iter), loss = 1.51858
I0628 20:19:48.411279  5893 solver.cpp:371]     Train net output #0: loss = 1.43852 (* 1 = 1.43852 loss)
I0628 20:19:48.411286  5893 sgd_solver.cpp:137] Iteration 9700, lr = 0.00939375, m = 0.9
I0628 20:20:06.821403  5893 solver.cpp:349] Iteration 9800 (5.43205 iter/s, 18.4093s/100 iter), loss = 1.60515
I0628 20:20:06.821425  5893 solver.cpp:371]     Train net output #0: loss = 1.54538 (* 1 = 1.54538 loss)
I0628 20:20:06.821429  5893 sgd_solver.cpp:137] Iteration 9800, lr = 0.0093875, m = 0.9
I0628 20:20:25.220484  5893 solver.cpp:349] Iteration 9900 (5.43532 iter/s, 18.3982s/100 iter), loss = 1.69192
I0628 20:20:25.220552  5893 solver.cpp:371]     Train net output #0: loss = 1.87869 (* 1 = 1.87869 loss)
I0628 20:20:25.220561  5893 sgd_solver.cpp:137] Iteration 9900, lr = 0.00938125, m = 0.9
I0628 20:20:43.474344  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_10000.caffemodel
I0628 20:20:43.490418  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_10000.solverstate
I0628 20:20:43.494618  5893 solver.cpp:401] Sparsity after update:
I0628 20:20:43.495463  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:20:43.495471  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:20:43.495478  5893 net.cpp:2170] conv1b_param_0(0.0998) 
I0628 20:20:43.495481  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:20:43.495482  5893 net.cpp:2170] res2a_branch2a_param_0(0.0999) 
I0628 20:20:43.495484  5893 net.cpp:2170] res2a_branch2b_param_0(0.0999) 
I0628 20:20:43.495487  5893 net.cpp:2170] res3a_branch2a_param_0(0.1) 
I0628 20:20:43.495489  5893 net.cpp:2170] res3a_branch2b_param_0(0.1) 
I0628 20:20:43.495491  5893 net.cpp:2170] res4a_branch2a_param_0(0.1) 
I0628 20:20:43.495494  5893 net.cpp:2170] res4a_branch2b_param_0(0.1) 
I0628 20:20:43.495496  5893 net.cpp:2170] res5a_branch2a_param_0(0.1) 
I0628 20:20:43.495498  5893 net.cpp:2170] res5a_branch2b_param_0(0.1) 
I0628 20:20:43.495501  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (235222/2.86678e+06) 0.0821
I0628 20:20:43.495512  5893 solver.cpp:545] Iteration 10000, Testing net (#0)
I0628 20:21:07.739558  5888 data_reader.cpp:262] Starting prefetch of epoch 10
I0628 20:21:07.801625  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55308
I0628 20:21:07.801651  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79388
I0628 20:21:07.801656  5893 solver.cpp:630]     Test net output #2: loss = 1.9401 (* 1 = 1.9401 loss)
I0628 20:21:07.801677  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3049s
I0628 20:21:07.986075  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.11
I0628 20:21:08.244266  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:21:08.245745  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:21:08.246428  5893 solver.cpp:349] Iteration 10000 (2.3243 iter/s, 43.0237s/100 iter), loss = 1.33177
I0628 20:21:08.246443  5893 solver.cpp:371]     Train net output #0: loss = 1.41086 (* 1 = 1.41086 loss)
I0628 20:21:08.246448  5893 sgd_solver.cpp:137] Iteration 10000, lr = 0.009375, m = 0.9
I0628 20:21:09.561663  5875 data_reader.cpp:262] Starting prefetch of epoch 2
I0628 20:21:26.655855  5893 solver.cpp:349] Iteration 10100 (5.4323 iter/s, 18.4084s/100 iter), loss = 1.51622
I0628 20:21:26.655879  5893 solver.cpp:371]     Train net output #0: loss = 1.40224 (* 1 = 1.40224 loss)
I0628 20:21:26.655882  5893 sgd_solver.cpp:137] Iteration 10100, lr = 0.00936875, m = 0.9
I0628 20:21:45.063501  5893 solver.cpp:349] Iteration 10200 (5.43283 iter/s, 18.4066s/100 iter), loss = 1.4259
I0628 20:21:45.063575  5893 solver.cpp:371]     Train net output #0: loss = 1.42464 (* 1 = 1.42464 loss)
I0628 20:21:45.063582  5893 sgd_solver.cpp:137] Iteration 10200, lr = 0.0093625, m = 0.9
I0628 20:22:03.468744  5893 solver.cpp:349] Iteration 10300 (5.43357 iter/s, 18.4041s/100 iter), loss = 1.36956
I0628 20:22:03.468768  5893 solver.cpp:371]     Train net output #0: loss = 1.39407 (* 1 = 1.39407 loss)
I0628 20:22:03.468772  5893 sgd_solver.cpp:137] Iteration 10300, lr = 0.00935625, m = 0.9
I0628 20:22:21.876541  5893 solver.cpp:349] Iteration 10400 (5.43281 iter/s, 18.4067s/100 iter), loss = 1.4583
I0628 20:22:21.876641  5893 solver.cpp:371]     Train net output #0: loss = 1.49594 (* 1 = 1.49594 loss)
I0628 20:22:21.876648  5893 sgd_solver.cpp:137] Iteration 10400, lr = 0.00935, m = 0.9
I0628 20:22:40.315160  5893 solver.cpp:349] Iteration 10500 (5.42376 iter/s, 18.4374s/100 iter), loss = 1.37749
I0628 20:22:40.315183  5893 solver.cpp:371]     Train net output #0: loss = 1.37643 (* 1 = 1.37643 loss)
I0628 20:22:40.315187  5893 sgd_solver.cpp:137] Iteration 10500, lr = 0.00934375, m = 0.9
I0628 20:22:58.760267  5893 solver.cpp:349] Iteration 10600 (5.42183 iter/s, 18.4439s/100 iter), loss = 1.26327
I0628 20:22:58.760378  5893 solver.cpp:371]     Train net output #0: loss = 1.29336 (* 1 = 1.29336 loss)
I0628 20:22:58.760385  5893 sgd_solver.cpp:137] Iteration 10600, lr = 0.0093375, m = 0.9
I0628 20:23:17.185850  5893 solver.cpp:349] Iteration 10700 (5.42761 iter/s, 18.4243s/100 iter), loss = 1.37422
I0628 20:23:17.185873  5893 solver.cpp:371]     Train net output #0: loss = 1.28071 (* 1 = 1.28071 loss)
I0628 20:23:17.185878  5893 sgd_solver.cpp:137] Iteration 10700, lr = 0.00933125, m = 0.9
I0628 20:23:35.618705  5893 solver.cpp:349] Iteration 10800 (5.42545 iter/s, 18.4316s/100 iter), loss = 1.60144
I0628 20:23:35.618813  5893 solver.cpp:371]     Train net output #0: loss = 1.66318 (* 1 = 1.66318 loss)
I0628 20:23:35.618819  5893 sgd_solver.cpp:137] Iteration 10800, lr = 0.009325, m = 0.9
I0628 20:23:54.043174  5893 solver.cpp:349] Iteration 10900 (5.42795 iter/s, 18.4231s/100 iter), loss = 1.40593
I0628 20:23:54.043192  5893 solver.cpp:371]     Train net output #0: loss = 1.27402 (* 1 = 1.27402 loss)
I0628 20:23:54.043197  5893 sgd_solver.cpp:137] Iteration 10900, lr = 0.00931875, m = 0.9
I0628 20:24:12.301234  5893 solver.cpp:401] Sparsity after update:
I0628 20:24:12.306437  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:24:12.306445  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:24:12.306450  5893 net.cpp:2170] conv1b_param_0(0.11) 
I0628 20:24:12.306453  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:24:12.306455  5893 net.cpp:2170] res2a_branch2a_param_0(0.11) 
I0628 20:24:12.306457  5893 net.cpp:2170] res2a_branch2b_param_0(0.11) 
I0628 20:24:12.306459  5893 net.cpp:2170] res3a_branch2a_param_0(0.11) 
I0628 20:24:12.306462  5893 net.cpp:2170] res3a_branch2b_param_0(0.11) 
I0628 20:24:12.306463  5893 net.cpp:2170] res4a_branch2a_param_0(0.11) 
I0628 20:24:12.306466  5893 net.cpp:2170] res4a_branch2b_param_0(0.11) 
I0628 20:24:12.306468  5893 net.cpp:2170] res5a_branch2a_param_0(0.11) 
I0628 20:24:12.306470  5893 net.cpp:2170] res5a_branch2b_param_0(0.11) 
I0628 20:24:12.306473  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (258751/2.86678e+06) 0.0903
I0628 20:24:12.306483  5893 solver.cpp:545] Iteration 11000, Testing net (#0)
I0628 20:24:12.484334  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 20:24:36.549237  5888 data_reader.cpp:262] Starting prefetch of epoch 11
I0628 20:24:36.678174  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55512
I0628 20:24:36.678195  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79204
I0628 20:24:36.678200  5893 solver.cpp:630]     Test net output #2: loss = 1.95892 (* 1 = 1.95892 loss)
I0628 20:24:36.678217  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3701s
I0628 20:24:36.863163  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.12
I0628 20:24:37.126569  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:24:37.128046  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:24:37.128720  5893 solver.cpp:349] Iteration 11000 (2.32112 iter/s, 43.0826s/100 iter), loss = 1.6139
I0628 20:24:37.128736  5893 solver.cpp:371]     Train net output #0: loss = 1.75021 (* 1 = 1.75021 loss)
I0628 20:24:37.128742  5893 sgd_solver.cpp:137] Iteration 11000, lr = 0.0093125, m = 0.9
I0628 20:24:55.553936  5893 solver.cpp:349] Iteration 11100 (5.42773 iter/s, 18.4239s/100 iter), loss = 1.22464
I0628 20:24:55.554026  5893 solver.cpp:371]     Train net output #0: loss = 1.16861 (* 1 = 1.16861 loss)
I0628 20:24:55.554033  5893 sgd_solver.cpp:137] Iteration 11100, lr = 0.00930625, m = 0.9
I0628 20:25:13.993460  5893 solver.cpp:349] Iteration 11200 (5.42354 iter/s, 18.4381s/100 iter), loss = 1.58039
I0628 20:25:13.993484  5893 solver.cpp:371]     Train net output #0: loss = 1.5494 (* 1 = 1.5494 loss)
I0628 20:25:13.993487  5893 sgd_solver.cpp:137] Iteration 11200, lr = 0.0093, m = 0.9
I0628 20:25:32.411015  5893 solver.cpp:349] Iteration 11300 (5.43 iter/s, 18.4162s/100 iter), loss = 1.29047
I0628 20:25:32.411068  5893 solver.cpp:371]     Train net output #0: loss = 1.40385 (* 1 = 1.40385 loss)
I0628 20:25:32.411073  5893 sgd_solver.cpp:137] Iteration 11300, lr = 0.00929375, m = 0.9
I0628 20:25:50.839136  5893 solver.cpp:349] Iteration 11400 (5.4269 iter/s, 18.4267s/100 iter), loss = 1.55584
I0628 20:25:50.839159  5893 solver.cpp:371]     Train net output #0: loss = 1.56109 (* 1 = 1.56109 loss)
I0628 20:25:50.839164  5893 sgd_solver.cpp:137] Iteration 11400, lr = 0.0092875, m = 0.9
I0628 20:26:09.263463  5893 solver.cpp:349] Iteration 11500 (5.42801 iter/s, 18.4229s/100 iter), loss = 1.09978
I0628 20:26:09.263571  5893 solver.cpp:371]     Train net output #0: loss = 1.08239 (* 1 = 1.08239 loss)
I0628 20:26:09.263577  5893 sgd_solver.cpp:137] Iteration 11500, lr = 0.00928125, m = 0.9
I0628 20:26:27.694622  5893 solver.cpp:349] Iteration 11600 (5.42603 iter/s, 18.4297s/100 iter), loss = 1.40744
I0628 20:26:27.694644  5893 solver.cpp:371]     Train net output #0: loss = 1.25427 (* 1 = 1.25427 loss)
I0628 20:26:27.694648  5893 sgd_solver.cpp:137] Iteration 11600, lr = 0.009275, m = 0.9
I0628 20:26:46.126170  5893 solver.cpp:349] Iteration 11700 (5.4259 iter/s, 18.4301s/100 iter), loss = 1.45122
I0628 20:26:46.126281  5893 solver.cpp:371]     Train net output #0: loss = 1.67591 (* 1 = 1.67591 loss)
I0628 20:26:46.126288  5893 sgd_solver.cpp:137] Iteration 11700, lr = 0.00926875, m = 0.9
I0628 20:27:04.551853  5893 solver.cpp:349] Iteration 11800 (5.42766 iter/s, 18.4242s/100 iter), loss = 1.2823
I0628 20:27:04.551877  5893 solver.cpp:371]     Train net output #0: loss = 1.24807 (* 1 = 1.24807 loss)
I0628 20:27:04.551882  5893 sgd_solver.cpp:137] Iteration 11800, lr = 0.0092625, m = 0.9
I0628 20:27:22.979522  5893 solver.cpp:349] Iteration 11900 (5.42705 iter/s, 18.4262s/100 iter), loss = 1.41276
I0628 20:27:22.979589  5893 solver.cpp:371]     Train net output #0: loss = 1.42941 (* 1 = 1.42941 loss)
I0628 20:27:22.979593  5893 sgd_solver.cpp:137] Iteration 11900, lr = 0.00925625, m = 0.9
I0628 20:27:41.224827  5893 solver.cpp:401] Sparsity after update:
I0628 20:27:41.230027  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:27:41.230036  5893 net.cpp:2170] conv1a_param_0(0) 
I0628 20:27:41.230042  5893 net.cpp:2170] conv1b_param_0(0.12) 
I0628 20:27:41.230044  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:27:41.230046  5893 net.cpp:2170] res2a_branch2a_param_0(0.12) 
I0628 20:27:41.230048  5893 net.cpp:2170] res2a_branch2b_param_0(0.12) 
I0628 20:27:41.230051  5893 net.cpp:2170] res3a_branch2a_param_0(0.12) 
I0628 20:27:41.230053  5893 net.cpp:2170] res3a_branch2b_param_0(0.12) 
I0628 20:27:41.230056  5893 net.cpp:2170] res4a_branch2a_param_0(0.12) 
I0628 20:27:41.230057  5893 net.cpp:2170] res4a_branch2b_param_0(0.12) 
I0628 20:27:41.230060  5893 net.cpp:2170] res5a_branch2a_param_0(0.12) 
I0628 20:27:41.230062  5893 net.cpp:2170] res5a_branch2b_param_0(0.12) 
I0628 20:27:41.230064  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (282271/2.86678e+06) 0.0985
I0628 20:27:41.230072  5893 solver.cpp:545] Iteration 12000, Testing net (#0)
I0628 20:28:05.655143  5888 data_reader.cpp:262] Starting prefetch of epoch 12
I0628 20:28:05.881219  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.557321
I0628 20:28:05.881240  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.792
I0628 20:28:05.881245  5893 solver.cpp:630]     Test net output #2: loss = 1.93788 (* 1 = 1.93788 loss)
I0628 20:28:05.881263  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6493s
I0628 20:28:06.066408  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.13
I0628 20:28:06.333016  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:28:06.334501  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:28:06.335178  5893 solver.cpp:349] Iteration 12000 (2.30669 iter/s, 43.3522s/100 iter), loss = 1.31701
I0628 20:28:06.335201  5893 solver.cpp:371]     Train net output #0: loss = 1.39533 (* 1 = 1.39533 loss)
I0628 20:28:06.335209  5893 sgd_solver.cpp:137] Iteration 12000, lr = 0.00925, m = 0.9
I0628 20:28:24.762768  5893 solver.cpp:349] Iteration 12100 (5.42709 iter/s, 18.4261s/100 iter), loss = 1.35384
I0628 20:28:24.762790  5893 solver.cpp:371]     Train net output #0: loss = 1.14396 (* 1 = 1.14396 loss)
I0628 20:28:24.762795  5893 sgd_solver.cpp:137] Iteration 12100, lr = 0.00924375, m = 0.9
I0628 20:28:43.177726  5893 solver.cpp:349] Iteration 12200 (5.43081 iter/s, 18.4135s/100 iter), loss = 1.67492
I0628 20:28:43.177809  5893 solver.cpp:371]     Train net output #0: loss = 1.82881 (* 1 = 1.82881 loss)
I0628 20:28:43.177814  5893 sgd_solver.cpp:137] Iteration 12200, lr = 0.0092375, m = 0.9
I0628 20:29:01.600813  5893 solver.cpp:349] Iteration 12300 (5.42844 iter/s, 18.4215s/100 iter), loss = 1.47613
I0628 20:29:01.600837  5893 solver.cpp:371]     Train net output #0: loss = 1.74139 (* 1 = 1.74139 loss)
I0628 20:29:01.600841  5893 sgd_solver.cpp:137] Iteration 12300, lr = 0.00923125, m = 0.9
I0628 20:29:20.005129  5893 solver.cpp:349] Iteration 12400 (5.43396 iter/s, 18.4028s/100 iter), loss = 1.1911
I0628 20:29:20.005213  5893 solver.cpp:371]     Train net output #0: loss = 1.00198 (* 1 = 1.00198 loss)
I0628 20:29:20.005218  5893 sgd_solver.cpp:137] Iteration 12400, lr = 0.009225, m = 0.9
I0628 20:29:38.426760  5893 solver.cpp:349] Iteration 12500 (5.42887 iter/s, 18.42s/100 iter), loss = 1.24118
I0628 20:29:38.426780  5893 solver.cpp:371]     Train net output #0: loss = 0.939966 (* 1 = 0.939966 loss)
I0628 20:29:38.426784  5893 sgd_solver.cpp:137] Iteration 12500, lr = 0.00921875, m = 0.9
I0628 20:29:56.841713  5893 solver.cpp:349] Iteration 12600 (5.43083 iter/s, 18.4134s/100 iter), loss = 1.37099
I0628 20:29:56.841758  5893 solver.cpp:371]     Train net output #0: loss = 1.35322 (* 1 = 1.35322 loss)
I0628 20:29:56.841763  5893 sgd_solver.cpp:137] Iteration 12600, lr = 0.0092125, m = 0.9
I0628 20:30:15.254359  5893 solver.cpp:349] Iteration 12700 (5.43152 iter/s, 18.4111s/100 iter), loss = 1.39442
I0628 20:30:15.254382  5893 solver.cpp:371]     Train net output #0: loss = 1.37047 (* 1 = 1.37047 loss)
I0628 20:30:15.254389  5893 sgd_solver.cpp:137] Iteration 12700, lr = 0.00920625, m = 0.9
I0628 20:30:33.670940  5893 solver.cpp:349] Iteration 12800 (5.43036 iter/s, 18.415s/100 iter), loss = 1.3589
I0628 20:30:33.671027  5893 solver.cpp:371]     Train net output #0: loss = 1.33593 (* 1 = 1.33593 loss)
I0628 20:30:33.671032  5893 sgd_solver.cpp:137] Iteration 12800, lr = 0.0092, m = 0.9
I0628 20:30:52.107475  5893 solver.cpp:349] Iteration 12900 (5.4245 iter/s, 18.4349s/100 iter), loss = 1.3494
I0628 20:30:52.107497  5893 solver.cpp:371]     Train net output #0: loss = 1.40127 (* 1 = 1.40127 loss)
I0628 20:30:52.107501  5893 sgd_solver.cpp:137] Iteration 12900, lr = 0.00919375, m = 0.9
I0628 20:31:10.347124  5893 solver.cpp:401] Sparsity after update:
I0628 20:31:10.352303  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:31:10.352310  5893 net.cpp:2170] conv1a_param_0(0.0646) 
I0628 20:31:10.352316  5893 net.cpp:2170] conv1b_param_0(0.13) 
I0628 20:31:10.352319  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:31:10.352320  5893 net.cpp:2170] res2a_branch2a_param_0(0.13) 
I0628 20:31:10.352322  5893 net.cpp:2170] res2a_branch2b_param_0(0.13) 
I0628 20:31:10.352324  5893 net.cpp:2170] res3a_branch2a_param_0(0.13) 
I0628 20:31:10.352326  5893 net.cpp:2170] res3a_branch2b_param_0(0.13) 
I0628 20:31:10.352329  5893 net.cpp:2170] res4a_branch2a_param_0(0.13) 
I0628 20:31:10.352330  5893 net.cpp:2170] res4a_branch2b_param_0(0.13) 
I0628 20:31:10.352331  5893 net.cpp:2170] res5a_branch2a_param_0(0.13) 
I0628 20:31:10.352334  5893 net.cpp:2170] res5a_branch2b_param_0(0.13) 
I0628 20:31:10.352335  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (305953/2.86678e+06) 0.107
I0628 20:31:10.352342  5893 solver.cpp:545] Iteration 13000, Testing net (#0)
I0628 20:31:34.653177  5888 data_reader.cpp:262] Starting prefetch of epoch 13
I0628 20:31:34.715843  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56388
I0628 20:31:34.715864  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.799001
I0628 20:31:34.715869  5893 solver.cpp:630]     Test net output #2: loss = 1.91076 (* 1 = 1.91076 loss)
I0628 20:31:34.715888  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3615s
I0628 20:31:34.900095  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.14
I0628 20:31:35.179335  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:31:35.180809  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:31:35.181490  5893 solver.cpp:349] Iteration 13000 (2.32178 iter/s, 43.0703s/100 iter), loss = 1.51255
I0628 20:31:35.181507  5893 solver.cpp:371]     Train net output #0: loss = 1.46853 (* 1 = 1.46853 loss)
I0628 20:31:35.181511  5893 sgd_solver.cpp:137] Iteration 13000, lr = 0.0091875, m = 0.9
I0628 20:31:53.600136  5893 solver.cpp:349] Iteration 13100 (5.42976 iter/s, 18.417s/100 iter), loss = 1.50169
I0628 20:31:53.600193  5893 solver.cpp:371]     Train net output #0: loss = 1.33672 (* 1 = 1.33672 loss)
I0628 20:31:53.600198  5893 sgd_solver.cpp:137] Iteration 13100, lr = 0.00918125, m = 0.9
I0628 20:32:12.061633  5893 solver.cpp:349] Iteration 13200 (5.41717 iter/s, 18.4598s/100 iter), loss = 1.22516
I0628 20:32:12.061655  5893 solver.cpp:371]     Train net output #0: loss = 1.14986 (* 1 = 1.14986 loss)
I0628 20:32:12.061660  5893 sgd_solver.cpp:137] Iteration 13200, lr = 0.009175, m = 0.9
I0628 20:32:30.481076  5893 solver.cpp:349] Iteration 13300 (5.42953 iter/s, 18.4178s/100 iter), loss = 1.42907
I0628 20:32:30.481144  5893 solver.cpp:371]     Train net output #0: loss = 1.33487 (* 1 = 1.33487 loss)
I0628 20:32:30.481149  5893 sgd_solver.cpp:137] Iteration 13300, lr = 0.00916875, m = 0.9
I0628 20:32:48.887643  5893 solver.cpp:349] Iteration 13400 (5.43334 iter/s, 18.4049s/100 iter), loss = 1.46801
I0628 20:32:48.887667  5893 solver.cpp:371]     Train net output #0: loss = 1.33229 (* 1 = 1.33229 loss)
I0628 20:32:48.887671  5893 sgd_solver.cpp:137] Iteration 13400, lr = 0.0091625, m = 0.9
I0628 20:33:07.295116  5893 solver.cpp:349] Iteration 13500 (5.43306 iter/s, 18.4058s/100 iter), loss = 1.68021
I0628 20:33:07.295217  5893 solver.cpp:371]     Train net output #0: loss = 1.93205 (* 1 = 1.93205 loss)
I0628 20:33:07.295222  5893 sgd_solver.cpp:137] Iteration 13500, lr = 0.00915625, m = 0.9
I0628 20:33:25.702275  5893 solver.cpp:349] Iteration 13600 (5.43318 iter/s, 18.4054s/100 iter), loss = 1.1727
I0628 20:33:25.702301  5893 solver.cpp:371]     Train net output #0: loss = 1.17131 (* 1 = 1.17131 loss)
I0628 20:33:25.702304  5893 sgd_solver.cpp:137] Iteration 13600, lr = 0.00915, m = 0.9
I0628 20:33:44.104625  5893 solver.cpp:349] Iteration 13700 (5.43458 iter/s, 18.4007s/100 iter), loss = 1.73464
I0628 20:33:44.104703  5893 solver.cpp:371]     Train net output #0: loss = 1.7648 (* 1 = 1.7648 loss)
I0628 20:33:44.104707  5893 sgd_solver.cpp:137] Iteration 13700, lr = 0.00914375, m = 0.9
I0628 20:34:02.530234  5893 solver.cpp:349] Iteration 13800 (5.42774 iter/s, 18.4239s/100 iter), loss = 1.35483
I0628 20:34:02.530257  5893 solver.cpp:371]     Train net output #0: loss = 1.41628 (* 1 = 1.41628 loss)
I0628 20:34:02.530261  5893 sgd_solver.cpp:137] Iteration 13800, lr = 0.0091375, m = 0.9
I0628 20:34:20.962245  5893 solver.cpp:349] Iteration 13900 (5.42584 iter/s, 18.4303s/100 iter), loss = 1.64642
I0628 20:34:20.962332  5893 solver.cpp:371]     Train net output #0: loss = 1.54263 (* 1 = 1.54263 loss)
I0628 20:34:20.962337  5893 sgd_solver.cpp:137] Iteration 13900, lr = 0.00913125, m = 0.9
I0628 20:34:39.197031  5893 solver.cpp:401] Sparsity after update:
I0628 20:34:39.202234  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:34:39.202242  5893 net.cpp:2170] conv1a_param_0(0.0696) 
I0628 20:34:39.202250  5893 net.cpp:2170] conv1b_param_0(0.14) 
I0628 20:34:39.202251  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:34:39.202253  5893 net.cpp:2170] res2a_branch2a_param_0(0.14) 
I0628 20:34:39.202255  5893 net.cpp:2170] res2a_branch2b_param_0(0.14) 
I0628 20:34:39.202257  5893 net.cpp:2170] res3a_branch2a_param_0(0.14) 
I0628 20:34:39.202260  5893 net.cpp:2170] res3a_branch2b_param_0(0.14) 
I0628 20:34:39.202260  5893 net.cpp:2170] res4a_branch2a_param_0(0.14) 
I0628 20:34:39.202262  5893 net.cpp:2170] res4a_branch2b_param_0(0.14) 
I0628 20:34:39.202265  5893 net.cpp:2170] res5a_branch2a_param_0(0.14) 
I0628 20:34:39.202266  5893 net.cpp:2170] res5a_branch2b_param_0(0.14) 
I0628 20:34:39.202268  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (329486/2.86678e+06) 0.115
I0628 20:34:39.202275  5893 solver.cpp:545] Iteration 14000, Testing net (#0)
I0628 20:35:03.406155  5888 data_reader.cpp:262] Starting prefetch of epoch 14
I0628 20:35:03.471393  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5502
I0628 20:35:03.471410  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7928
I0628 20:35:03.471417  5893 solver.cpp:630]     Test net output #2: loss = 1.94668 (* 1 = 1.94668 loss)
I0628 20:35:03.471436  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.267s
I0628 20:35:03.656378  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.15
I0628 20:35:03.937185  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:35:03.938652  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:35:03.939330  5893 solver.cpp:349] Iteration 14000 (2.32704 iter/s, 42.9731s/100 iter), loss = 1.50847
I0628 20:35:03.939348  5893 solver.cpp:371]     Train net output #0: loss = 1.55173 (* 1 = 1.55173 loss)
I0628 20:35:03.939357  5893 sgd_solver.cpp:137] Iteration 14000, lr = 0.009125, m = 0.9
I0628 20:35:22.357167  5893 solver.cpp:349] Iteration 14100 (5.43002 iter/s, 18.4161s/100 iter), loss = 1.16576
I0628 20:35:22.357189  5893 solver.cpp:371]     Train net output #0: loss = 1.2872 (* 1 = 1.2872 loss)
I0628 20:35:22.357193  5893 sgd_solver.cpp:137] Iteration 14100, lr = 0.00911875, m = 0.9
I0628 20:35:40.766484  5893 solver.cpp:349] Iteration 14200 (5.43254 iter/s, 18.4076s/100 iter), loss = 1.31572
I0628 20:35:40.766587  5893 solver.cpp:371]     Train net output #0: loss = 1.26393 (* 1 = 1.26393 loss)
I0628 20:35:40.766592  5893 sgd_solver.cpp:137] Iteration 14200, lr = 0.0091125, m = 0.9
I0628 20:35:59.186491  5893 solver.cpp:349] Iteration 14300 (5.42941 iter/s, 18.4182s/100 iter), loss = 1.14629
I0628 20:35:59.186513  5893 solver.cpp:371]     Train net output #0: loss = 0.992654 (* 1 = 0.992654 loss)
I0628 20:35:59.186517  5893 sgd_solver.cpp:137] Iteration 14300, lr = 0.00910625, m = 0.9
I0628 20:36:17.612637  5893 solver.cpp:349] Iteration 14400 (5.42758 iter/s, 18.4244s/100 iter), loss = 1.52304
I0628 20:36:17.612740  5893 solver.cpp:371]     Train net output #0: loss = 1.78463 (* 1 = 1.78463 loss)
I0628 20:36:17.612746  5893 sgd_solver.cpp:137] Iteration 14400, lr = 0.0091, m = 0.9
I0628 20:36:36.030225  5893 solver.cpp:349] Iteration 14500 (5.43013 iter/s, 18.4158s/100 iter), loss = 1.21301
I0628 20:36:36.030246  5893 solver.cpp:371]     Train net output #0: loss = 1.50315 (* 1 = 1.50315 loss)
I0628 20:36:36.030249  5893 sgd_solver.cpp:137] Iteration 14500, lr = 0.00909375, m = 0.9
I0628 20:36:54.446228  5893 solver.cpp:349] Iteration 14600 (5.43057 iter/s, 18.4143s/100 iter), loss = 1.51235
I0628 20:36:54.446331  5893 solver.cpp:371]     Train net output #0: loss = 1.65355 (* 1 = 1.65355 loss)
I0628 20:36:54.446337  5893 sgd_solver.cpp:137] Iteration 14600, lr = 0.0090875, m = 0.9
I0628 20:37:12.869305  5893 solver.cpp:349] Iteration 14700 (5.42851 iter/s, 18.4213s/100 iter), loss = 1.49426
I0628 20:37:12.869329  5893 solver.cpp:371]     Train net output #0: loss = 1.75611 (* 1 = 1.75611 loss)
I0628 20:37:12.869333  5893 sgd_solver.cpp:137] Iteration 14700, lr = 0.00908125, m = 0.9
I0628 20:37:31.295058  5893 solver.cpp:349] Iteration 14800 (5.4277 iter/s, 18.424s/100 iter), loss = 1.42387
I0628 20:37:31.295171  5893 solver.cpp:371]     Train net output #0: loss = 1.74952 (* 1 = 1.74952 loss)
I0628 20:37:31.295177  5893 sgd_solver.cpp:137] Iteration 14800, lr = 0.009075, m = 0.9
I0628 20:37:49.703482  5893 solver.cpp:349] Iteration 14900 (5.43284 iter/s, 18.4066s/100 iter), loss = 1.51329
I0628 20:37:49.703506  5893 solver.cpp:371]     Train net output #0: loss = 1.38799 (* 1 = 1.38799 loss)
I0628 20:37:49.703510  5893 sgd_solver.cpp:137] Iteration 14900, lr = 0.00906875, m = 0.9
I0628 20:38:07.936410  5893 solver.cpp:401] Sparsity after update:
I0628 20:38:07.941048  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:38:07.941056  5893 net.cpp:2170] conv1a_param_0(0.0746) 
I0628 20:38:07.941061  5893 net.cpp:2170] conv1b_param_0(0.15) 
I0628 20:38:07.941063  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:38:07.941066  5893 net.cpp:2170] res2a_branch2a_param_0(0.15) 
I0628 20:38:07.941068  5893 net.cpp:2170] res2a_branch2b_param_0(0.15) 
I0628 20:38:07.941069  5893 net.cpp:2170] res3a_branch2a_param_0(0.15) 
I0628 20:38:07.941071  5893 net.cpp:2170] res3a_branch2b_param_0(0.15) 
I0628 20:38:07.941073  5893 net.cpp:2170] res4a_branch2a_param_0(0.15) 
I0628 20:38:07.941076  5893 net.cpp:2170] res4a_branch2b_param_0(0.15) 
I0628 20:38:07.941077  5893 net.cpp:2170] res5a_branch2a_param_0(0.15) 
I0628 20:38:07.941079  5893 net.cpp:2170] res5a_branch2b_param_0(0.15) 
I0628 20:38:07.941082  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (353023/2.86678e+06) 0.123
I0628 20:38:07.941088  5893 solver.cpp:545] Iteration 15000, Testing net (#0)
I0628 20:38:32.185473  5888 data_reader.cpp:262] Starting prefetch of epoch 15
I0628 20:38:32.309690  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55928
I0628 20:38:32.309713  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79752
I0628 20:38:32.309718  5893 solver.cpp:630]     Test net output #2: loss = 1.91895 (* 1 = 1.91895 loss)
I0628 20:38:32.309734  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3677s
I0628 20:38:32.497844  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.16
I0628 20:38:32.778028  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:38:32.779507  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:38:32.780184  5893 solver.cpp:349] Iteration 15000 (2.32158 iter/s, 43.0741s/100 iter), loss = 1.719
I0628 20:38:32.780201  5893 solver.cpp:371]     Train net output #0: loss = 1.59681 (* 1 = 1.59681 loss)
I0628 20:38:32.780206  5893 sgd_solver.cpp:137] Iteration 15000, lr = 0.0090625, m = 0.9
I0628 20:38:34.953748  5875 data_reader.cpp:262] Starting prefetch of epoch 3
I0628 20:38:51.187424  5893 solver.cpp:349] Iteration 15100 (5.43274 iter/s, 18.4069s/100 iter), loss = 1.6307
I0628 20:38:51.187541  5893 solver.cpp:371]     Train net output #0: loss = 1.65751 (* 1 = 1.65751 loss)
I0628 20:38:51.187548  5893 sgd_solver.cpp:137] Iteration 15100, lr = 0.00905625, m = 0.9
I0628 20:39:09.615150  5893 solver.cpp:349] Iteration 15200 (5.42674 iter/s, 18.4273s/100 iter), loss = 1.30005
I0628 20:39:09.615175  5893 solver.cpp:371]     Train net output #0: loss = 1.62223 (* 1 = 1.62223 loss)
I0628 20:39:09.615180  5893 sgd_solver.cpp:137] Iteration 15200, lr = 0.00905, m = 0.9
I0628 20:39:28.045562  5893 solver.cpp:349] Iteration 15300 (5.42593 iter/s, 18.43s/100 iter), loss = 1.57889
I0628 20:39:28.045658  5893 solver.cpp:371]     Train net output #0: loss = 1.48909 (* 1 = 1.48909 loss)
I0628 20:39:28.045665  5893 sgd_solver.cpp:137] Iteration 15300, lr = 0.00904375, m = 0.9
I0628 20:39:46.476158  5893 solver.cpp:349] Iteration 15400 (5.4259 iter/s, 18.4301s/100 iter), loss = 1.42401
I0628 20:39:46.476182  5893 solver.cpp:371]     Train net output #0: loss = 1.41909 (* 1 = 1.41909 loss)
I0628 20:39:46.476188  5893 sgd_solver.cpp:137] Iteration 15400, lr = 0.0090375, m = 0.9
I0628 20:40:04.906401  5893 solver.cpp:349] Iteration 15500 (5.42599 iter/s, 18.4298s/100 iter), loss = 1.22063
I0628 20:40:04.906483  5893 solver.cpp:371]     Train net output #0: loss = 1.04253 (* 1 = 1.04253 loss)
I0628 20:40:04.906488  5893 sgd_solver.cpp:137] Iteration 15500, lr = 0.00903125, m = 0.9
I0628 20:40:23.350611  5893 solver.cpp:349] Iteration 15600 (5.4219 iter/s, 18.4437s/100 iter), loss = 1.32971
I0628 20:40:23.350634  5893 solver.cpp:371]     Train net output #0: loss = 1.28914 (* 1 = 1.28914 loss)
I0628 20:40:23.350638  5893 sgd_solver.cpp:137] Iteration 15600, lr = 0.009025, m = 0.9
I0628 20:40:41.776198  5893 solver.cpp:349] Iteration 15700 (5.42737 iter/s, 18.4251s/100 iter), loss = 1.51807
I0628 20:40:41.776312  5893 solver.cpp:371]     Train net output #0: loss = 1.58225 (* 1 = 1.58225 loss)
I0628 20:40:41.776319  5893 sgd_solver.cpp:137] Iteration 15700, lr = 0.00901875, m = 0.9
I0628 20:41:00.210788  5893 solver.cpp:349] Iteration 15800 (5.42476 iter/s, 18.434s/100 iter), loss = 1.26648
I0628 20:41:00.210811  5893 solver.cpp:371]     Train net output #0: loss = 1.49757 (* 1 = 1.49757 loss)
I0628 20:41:00.210815  5893 sgd_solver.cpp:137] Iteration 15800, lr = 0.0090125, m = 0.9
I0628 20:41:18.647627  5893 solver.cpp:349] Iteration 15900 (5.42407 iter/s, 18.4363s/100 iter), loss = 1.3627
I0628 20:41:18.653575  5893 solver.cpp:371]     Train net output #0: loss = 1.2558 (* 1 = 1.2558 loss)
I0628 20:41:18.653586  5893 sgd_solver.cpp:137] Iteration 15900, lr = 0.00900625, m = 0.9
I0628 20:41:36.893757  5893 solver.cpp:401] Sparsity after update:
I0628 20:41:36.898958  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:41:36.898967  5893 net.cpp:2170] conv1a_param_0(0.08) 
I0628 20:41:36.898972  5893 net.cpp:2170] conv1b_param_0(0.16) 
I0628 20:41:36.898974  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:41:36.898977  5893 net.cpp:2170] res2a_branch2a_param_0(0.16) 
I0628 20:41:36.898980  5893 net.cpp:2170] res2a_branch2b_param_0(0.16) 
I0628 20:41:36.898983  5893 net.cpp:2170] res3a_branch2a_param_0(0.16) 
I0628 20:41:36.898984  5893 net.cpp:2170] res3a_branch2b_param_0(0.16) 
I0628 20:41:36.898985  5893 net.cpp:2170] res4a_branch2a_param_0(0.16) 
I0628 20:41:36.898988  5893 net.cpp:2170] res4a_branch2b_param_0(0.16) 
I0628 20:41:36.898989  5893 net.cpp:2170] res5a_branch2a_param_0(0.16) 
I0628 20:41:36.898993  5893 net.cpp:2170] res5a_branch2b_param_0(0.16) 
I0628 20:41:36.898994  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (376565/2.86678e+06) 0.131
I0628 20:41:36.899003  5893 solver.cpp:545] Iteration 16000, Testing net (#0)
I0628 20:41:37.224009  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 20:42:01.471068  5888 data_reader.cpp:262] Starting prefetch of epoch 16
I0628 20:42:01.533476  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56296
I0628 20:42:01.533495  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7994
I0628 20:42:01.533500  5893 solver.cpp:630]     Test net output #2: loss = 1.90824 (* 1 = 1.90824 loss)
I0628 20:42:01.533515  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6338s
I0628 20:42:01.718236  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.17
I0628 20:42:01.997150  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:42:01.998631  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:42:01.999313  5893 solver.cpp:349] Iteration 16000 (2.3071 iter/s, 43.3445s/100 iter), loss = 1.19646
I0628 20:42:01.999330  5893 solver.cpp:371]     Train net output #0: loss = 1.06685 (* 1 = 1.06685 loss)
I0628 20:42:01.999335  5893 sgd_solver.cpp:137] Iteration 16000, lr = 0.009, m = 0.9
I0628 20:42:20.410115  5893 solver.cpp:349] Iteration 16100 (5.43176 iter/s, 18.4102s/100 iter), loss = 1.10802
I0628 20:42:20.410135  5893 solver.cpp:371]     Train net output #0: loss = 0.906142 (* 1 = 0.906142 loss)
I0628 20:42:20.410140  5893 sgd_solver.cpp:137] Iteration 16100, lr = 0.00899375, m = 0.9
I0628 20:42:38.817975  5893 solver.cpp:349] Iteration 16200 (5.43264 iter/s, 18.4073s/100 iter), loss = 1.43542
I0628 20:42:38.818078  5893 solver.cpp:371]     Train net output #0: loss = 1.3555 (* 1 = 1.3555 loss)
I0628 20:42:38.818084  5893 sgd_solver.cpp:137] Iteration 16200, lr = 0.0089875, m = 0.9
I0628 20:42:57.245649  5893 solver.cpp:349] Iteration 16300 (5.42683 iter/s, 18.427s/100 iter), loss = 1.31449
I0628 20:42:57.245673  5893 solver.cpp:371]     Train net output #0: loss = 1.33519 (* 1 = 1.33519 loss)
I0628 20:42:57.245677  5893 sgd_solver.cpp:137] Iteration 16300, lr = 0.00898125, m = 0.9
I0628 20:43:15.674908  5893 solver.cpp:349] Iteration 16400 (5.42634 iter/s, 18.4286s/100 iter), loss = 1.50503
I0628 20:43:15.675024  5893 solver.cpp:371]     Train net output #0: loss = 1.56156 (* 1 = 1.56156 loss)
I0628 20:43:15.675031  5893 sgd_solver.cpp:137] Iteration 16400, lr = 0.008975, m = 0.9
I0628 20:43:34.095510  5893 solver.cpp:349] Iteration 16500 (5.42893 iter/s, 18.4198s/100 iter), loss = 1.55043
I0628 20:43:34.095532  5893 solver.cpp:371]     Train net output #0: loss = 1.43009 (* 1 = 1.43009 loss)
I0628 20:43:34.095536  5893 sgd_solver.cpp:137] Iteration 16500, lr = 0.00896875, m = 0.9
I0628 20:43:52.508105  5893 solver.cpp:349] Iteration 16600 (5.43126 iter/s, 18.4119s/100 iter), loss = 1.33264
I0628 20:43:52.508200  5893 solver.cpp:371]     Train net output #0: loss = 1.31199 (* 1 = 1.31199 loss)
I0628 20:43:52.508206  5893 sgd_solver.cpp:137] Iteration 16600, lr = 0.0089625, m = 0.9
I0628 20:44:10.918822  5893 solver.cpp:349] Iteration 16700 (5.43185 iter/s, 18.4099s/100 iter), loss = 1.36905
I0628 20:44:10.918843  5893 solver.cpp:371]     Train net output #0: loss = 1.77057 (* 1 = 1.77057 loss)
I0628 20:44:10.918848  5893 sgd_solver.cpp:137] Iteration 16700, lr = 0.00895625, m = 0.9
I0628 20:44:29.339926  5893 solver.cpp:349] Iteration 16800 (5.42877 iter/s, 18.4204s/100 iter), loss = 1.54588
I0628 20:44:29.339970  5893 solver.cpp:371]     Train net output #0: loss = 1.40083 (* 1 = 1.40083 loss)
I0628 20:44:29.339977  5893 sgd_solver.cpp:137] Iteration 16800, lr = 0.00895, m = 0.9
I0628 20:44:47.759169  5893 solver.cpp:349] Iteration 16900 (5.42933 iter/s, 18.4185s/100 iter), loss = 1.38691
I0628 20:44:47.759192  5893 solver.cpp:371]     Train net output #0: loss = 1.7623 (* 1 = 1.7623 loss)
I0628 20:44:47.759196  5893 sgd_solver.cpp:137] Iteration 16900, lr = 0.00894375, m = 0.9
I0628 20:45:06.020273  5893 solver.cpp:401] Sparsity after update:
I0628 20:45:06.025480  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:45:06.025493  5893 net.cpp:2170] conv1a_param_0(0.085) 
I0628 20:45:06.025501  5893 net.cpp:2170] conv1b_param_0(0.17) 
I0628 20:45:06.025506  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:45:06.025508  5893 net.cpp:2170] res2a_branch2a_param_0(0.17) 
I0628 20:45:06.025511  5893 net.cpp:2170] res2a_branch2b_param_0(0.17) 
I0628 20:45:06.025516  5893 net.cpp:2170] res3a_branch2a_param_0(0.17) 
I0628 20:45:06.025518  5893 net.cpp:2170] res3a_branch2b_param_0(0.17) 
I0628 20:45:06.025521  5893 net.cpp:2170] res4a_branch2a_param_0(0.17) 
I0628 20:45:06.025524  5893 net.cpp:2170] res4a_branch2b_param_0(0.17) 
I0628 20:45:06.025527  5893 net.cpp:2170] res5a_branch2a_param_0(0.17) 
I0628 20:45:06.025532  5893 net.cpp:2170] res5a_branch2b_param_0(0.17) 
I0628 20:45:06.025535  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (400097/2.86678e+06) 0.14
I0628 20:45:06.025552  5893 solver.cpp:545] Iteration 17000, Testing net (#0)
I0628 20:45:30.169221  5888 data_reader.cpp:262] Starting prefetch of epoch 17
I0628 20:45:30.277699  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55868
I0628 20:45:30.277719  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.794401
I0628 20:45:30.277724  5893 solver.cpp:630]     Test net output #2: loss = 1.93568 (* 1 = 1.93568 loss)
I0628 20:45:30.277740  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2512s
I0628 20:45:30.461596  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.18
I0628 20:45:30.743438  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:45:30.744906  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:45:30.745599  5893 solver.cpp:349] Iteration 17000 (2.32641 iter/s, 42.9847s/100 iter), loss = 1.37525
I0628 20:45:30.745615  5893 solver.cpp:371]     Train net output #0: loss = 1.36467 (* 1 = 1.36467 loss)
I0628 20:45:30.745620  5893 sgd_solver.cpp:137] Iteration 17000, lr = 0.0089375, m = 0.9
I0628 20:45:49.210749  5893 solver.cpp:349] Iteration 17100 (5.41584 iter/s, 18.4644s/100 iter), loss = 1.40529
I0628 20:45:49.210873  5893 solver.cpp:371]     Train net output #0: loss = 1.41394 (* 1 = 1.41394 loss)
I0628 20:45:49.210880  5893 sgd_solver.cpp:137] Iteration 17100, lr = 0.00893125, m = 0.9
I0628 20:46:07.651365  5893 solver.cpp:349] Iteration 17200 (5.42308 iter/s, 18.4397s/100 iter), loss = 1.24285
I0628 20:46:07.651386  5893 solver.cpp:371]     Train net output #0: loss = 1.15908 (* 1 = 1.15908 loss)
I0628 20:46:07.651391  5893 sgd_solver.cpp:137] Iteration 17200, lr = 0.008925, m = 0.9
I0628 20:46:26.092187  5893 solver.cpp:349] Iteration 17300 (5.423 iter/s, 18.44s/100 iter), loss = 1.28501
I0628 20:46:26.092283  5893 solver.cpp:371]     Train net output #0: loss = 1.25588 (* 1 = 1.25588 loss)
I0628 20:46:26.092288  5893 sgd_solver.cpp:137] Iteration 17300, lr = 0.00891875, m = 0.9
I0628 20:46:44.495626  5893 solver.cpp:349] Iteration 17400 (5.43404 iter/s, 18.4025s/100 iter), loss = 1.29283
I0628 20:46:44.495649  5893 solver.cpp:371]     Train net output #0: loss = 1.47886 (* 1 = 1.47886 loss)
I0628 20:46:44.495653  5893 sgd_solver.cpp:137] Iteration 17400, lr = 0.0089125, m = 0.9
I0628 20:47:02.919653  5893 solver.cpp:349] Iteration 17500 (5.42795 iter/s, 18.4232s/100 iter), loss = 1.16894
I0628 20:47:02.919752  5893 solver.cpp:371]     Train net output #0: loss = 0.948946 (* 1 = 0.948946 loss)
I0628 20:47:02.919759  5893 sgd_solver.cpp:137] Iteration 17500, lr = 0.00890625, m = 0.9
I0628 20:47:21.336971  5893 solver.cpp:349] Iteration 17600 (5.42995 iter/s, 18.4164s/100 iter), loss = 1.31407
I0628 20:47:21.336993  5893 solver.cpp:371]     Train net output #0: loss = 1.22138 (* 1 = 1.22138 loss)
I0628 20:47:21.336997  5893 sgd_solver.cpp:137] Iteration 17600, lr = 0.0089, m = 0.9
I0628 20:47:39.778934  5893 solver.cpp:349] Iteration 17700 (5.42268 iter/s, 18.4411s/100 iter), loss = 1.44951
I0628 20:47:39.779029  5893 solver.cpp:371]     Train net output #0: loss = 1.17213 (* 1 = 1.17213 loss)
I0628 20:47:39.779036  5893 sgd_solver.cpp:137] Iteration 17700, lr = 0.00889375, m = 0.9
I0628 20:47:58.208173  5893 solver.cpp:349] Iteration 17800 (5.42645 iter/s, 18.4283s/100 iter), loss = 1.51525
I0628 20:47:58.208196  5893 solver.cpp:371]     Train net output #0: loss = 1.45162 (* 1 = 1.45162 loss)
I0628 20:47:58.208200  5893 sgd_solver.cpp:137] Iteration 17800, lr = 0.0088875, m = 0.9
I0628 20:48:16.619228  5893 solver.cpp:349] Iteration 17900 (5.43179 iter/s, 18.4101s/100 iter), loss = 1.55523
I0628 20:48:16.619297  5893 solver.cpp:371]     Train net output #0: loss = 1.82397 (* 1 = 1.82397 loss)
I0628 20:48:16.619302  5893 sgd_solver.cpp:137] Iteration 17900, lr = 0.00888125, m = 0.9
I0628 20:48:34.852125  5893 solver.cpp:401] Sparsity after update:
I0628 20:48:34.857367  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:48:34.857376  5893 net.cpp:2170] conv1a_param_0(0.09) 
I0628 20:48:34.857384  5893 net.cpp:2170] conv1b_param_0(0.18) 
I0628 20:48:34.857388  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:48:34.857391  5893 net.cpp:2170] res2a_branch2a_param_0(0.18) 
I0628 20:48:34.857394  5893 net.cpp:2170] res2a_branch2b_param_0(0.18) 
I0628 20:48:34.857398  5893 net.cpp:2170] res3a_branch2a_param_0(0.18) 
I0628 20:48:34.857400  5893 net.cpp:2170] res3a_branch2b_param_0(0.18) 
I0628 20:48:34.857403  5893 net.cpp:2170] res4a_branch2a_param_0(0.18) 
I0628 20:48:34.857406  5893 net.cpp:2170] res4a_branch2b_param_0(0.18) 
I0628 20:48:34.857409  5893 net.cpp:2170] res5a_branch2a_param_0(0.18) 
I0628 20:48:34.857412  5893 net.cpp:2170] res5a_branch2b_param_0(0.18) 
I0628 20:48:34.857415  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (423632/2.86678e+06) 0.148
I0628 20:48:34.857425  5893 solver.cpp:545] Iteration 18000, Testing net (#0)
I0628 20:48:59.105980  5888 data_reader.cpp:262] Starting prefetch of epoch 18
I0628 20:48:59.217947  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56448
I0628 20:48:59.217967  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.799
I0628 20:48:59.217972  5893 solver.cpp:630]     Test net output #2: loss = 1.8918 (* 1 = 1.8918 loss)
I0628 20:48:59.217986  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3594s
I0628 20:48:59.402245  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.19
I0628 20:48:59.686870  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:48:59.688338  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:48:59.689008  5893 solver.cpp:349] Iteration 18000 (2.32193 iter/s, 43.0676s/100 iter), loss = 1.16516
I0628 20:48:59.689025  5893 solver.cpp:371]     Train net output #0: loss = 0.942087 (* 1 = 0.942087 loss)
I0628 20:48:59.689031  5893 sgd_solver.cpp:137] Iteration 18000, lr = 0.008875, m = 0.9
I0628 20:49:18.102778  5893 solver.cpp:349] Iteration 18100 (5.431 iter/s, 18.4128s/100 iter), loss = 1.12244
I0628 20:49:18.102800  5893 solver.cpp:371]     Train net output #0: loss = 1.25966 (* 1 = 1.25966 loss)
I0628 20:49:18.102804  5893 sgd_solver.cpp:137] Iteration 18100, lr = 0.00886875, m = 0.9
I0628 20:49:36.530695  5893 solver.cpp:349] Iteration 18200 (5.42684 iter/s, 18.4269s/100 iter), loss = 1.45284
I0628 20:49:36.530803  5893 solver.cpp:371]     Train net output #0: loss = 1.34177 (* 1 = 1.34177 loss)
I0628 20:49:36.530812  5893 sgd_solver.cpp:137] Iteration 18200, lr = 0.0088625, m = 0.9
I0628 20:49:54.968029  5893 solver.cpp:349] Iteration 18300 (5.4241 iter/s, 18.4362s/100 iter), loss = 1.38009
I0628 20:49:54.968051  5893 solver.cpp:371]     Train net output #0: loss = 1.41264 (* 1 = 1.41264 loss)
I0628 20:49:54.968057  5893 sgd_solver.cpp:137] Iteration 18300, lr = 0.00885625, m = 0.9
I0628 20:50:13.404691  5893 solver.cpp:349] Iteration 18400 (5.42427 iter/s, 18.4357s/100 iter), loss = 1.55945
I0628 20:50:13.404796  5893 solver.cpp:371]     Train net output #0: loss = 1.66884 (* 1 = 1.66884 loss)
I0628 20:50:13.404803  5893 sgd_solver.cpp:137] Iteration 18400, lr = 0.00885, m = 0.9
I0628 20:50:31.811636  5893 solver.cpp:349] Iteration 18500 (5.43306 iter/s, 18.4058s/100 iter), loss = 1.39374
I0628 20:50:31.811656  5893 solver.cpp:371]     Train net output #0: loss = 1.2066 (* 1 = 1.2066 loss)
I0628 20:50:31.811661  5893 sgd_solver.cpp:137] Iteration 18500, lr = 0.00884375, m = 0.9
I0628 20:50:50.252707  5893 solver.cpp:349] Iteration 18600 (5.42298 iter/s, 18.44s/100 iter), loss = 1.34128
I0628 20:50:50.252779  5893 solver.cpp:371]     Train net output #0: loss = 1.19771 (* 1 = 1.19771 loss)
I0628 20:50:50.252784  5893 sgd_solver.cpp:137] Iteration 18600, lr = 0.0088375, m = 0.9
I0628 20:51:08.672993  5893 solver.cpp:349] Iteration 18700 (5.42912 iter/s, 18.4192s/100 iter), loss = 1.40135
I0628 20:51:08.673017  5893 solver.cpp:371]     Train net output #0: loss = 1.69073 (* 1 = 1.69073 loss)
I0628 20:51:08.673022  5893 sgd_solver.cpp:137] Iteration 18700, lr = 0.00883125, m = 0.9
I0628 20:51:27.100164  5893 solver.cpp:349] Iteration 18800 (5.42708 iter/s, 18.4261s/100 iter), loss = 1.57118
I0628 20:51:27.100265  5893 solver.cpp:371]     Train net output #0: loss = 1.6009 (* 1 = 1.6009 loss)
I0628 20:51:27.100271  5893 sgd_solver.cpp:137] Iteration 18800, lr = 0.008825, m = 0.9
I0628 20:51:45.512306  5893 solver.cpp:349] Iteration 18900 (5.43154 iter/s, 18.411s/100 iter), loss = 1.39955
I0628 20:51:45.512328  5893 solver.cpp:371]     Train net output #0: loss = 1.60534 (* 1 = 1.60534 loss)
I0628 20:51:45.512331  5893 sgd_solver.cpp:137] Iteration 18900, lr = 0.00881875, m = 0.9
I0628 20:52:03.767585  5893 solver.cpp:401] Sparsity after update:
I0628 20:52:03.772881  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:52:03.772888  5893 net.cpp:2170] conv1a_param_0(0.095) 
I0628 20:52:03.772895  5893 net.cpp:2170] conv1b_param_0(0.19) 
I0628 20:52:03.772897  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:52:03.772899  5893 net.cpp:2170] res2a_branch2a_param_0(0.19) 
I0628 20:52:03.772902  5893 net.cpp:2170] res2a_branch2b_param_0(0.19) 
I0628 20:52:03.772903  5893 net.cpp:2170] res3a_branch2a_param_0(0.19) 
I0628 20:52:03.772905  5893 net.cpp:2170] res3a_branch2b_param_0(0.19) 
I0628 20:52:03.772907  5893 net.cpp:2170] res4a_branch2a_param_0(0.19) 
I0628 20:52:03.772908  5893 net.cpp:2170] res4a_branch2b_param_0(0.19) 
I0628 20:52:03.772910  5893 net.cpp:2170] res5a_branch2a_param_0(0.19) 
I0628 20:52:03.772912  5893 net.cpp:2170] res5a_branch2b_param_0(0.19) 
I0628 20:52:03.772914  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (447171/2.86678e+06) 0.156
I0628 20:52:03.772922  5893 solver.cpp:545] Iteration 19000, Testing net (#0)
I0628 20:52:27.969575  5888 data_reader.cpp:262] Starting prefetch of epoch 19
I0628 20:52:28.130769  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.558601
I0628 20:52:28.130786  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79612
I0628 20:52:28.130791  5893 solver.cpp:630]     Test net output #2: loss = 1.91446 (* 1 = 1.91446 loss)
I0628 20:52:28.130808  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3565s
I0628 20:52:28.315539  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.2
I0628 20:52:28.602636  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:52:28.604100  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:52:28.604784  5893 solver.cpp:349] Iteration 19000 (2.32072 iter/s, 43.09s/100 iter), loss = 1.14601
I0628 20:52:28.604801  5893 solver.cpp:371]     Train net output #0: loss = 1.15644 (* 1 = 1.15644 loss)
I0628 20:52:28.604805  5893 sgd_solver.cpp:137] Iteration 19000, lr = 0.0088125, m = 0.9
I0628 20:52:47.033268  5893 solver.cpp:349] Iteration 19100 (5.42671 iter/s, 18.4274s/100 iter), loss = 1.46712
I0628 20:52:47.033363  5893 solver.cpp:371]     Train net output #0: loss = 1.66324 (* 1 = 1.66324 loss)
I0628 20:52:47.033368  5893 sgd_solver.cpp:137] Iteration 19100, lr = 0.00880625, m = 0.9
I0628 20:53:05.443749  5893 solver.cpp:349] Iteration 19200 (5.43204 iter/s, 18.4093s/100 iter), loss = 1.20133
I0628 20:53:05.443774  5893 solver.cpp:371]     Train net output #0: loss = 1.1394 (* 1 = 1.1394 loss)
I0628 20:53:05.443779  5893 sgd_solver.cpp:137] Iteration 19200, lr = 0.0088, m = 0.9
I0628 20:53:23.855650  5893 solver.cpp:349] Iteration 19300 (5.4316 iter/s, 18.4108s/100 iter), loss = 1.18454
I0628 20:53:23.855752  5893 solver.cpp:371]     Train net output #0: loss = 1.14788 (* 1 = 1.14788 loss)
I0628 20:53:23.855758  5893 sgd_solver.cpp:137] Iteration 19300, lr = 0.00879375, m = 0.9
I0628 20:53:42.264022  5893 solver.cpp:349] Iteration 19400 (5.43267 iter/s, 18.4072s/100 iter), loss = 1.31545
I0628 20:53:42.264046  5893 solver.cpp:371]     Train net output #0: loss = 1.17672 (* 1 = 1.17672 loss)
I0628 20:53:42.264050  5893 sgd_solver.cpp:137] Iteration 19400, lr = 0.0087875, m = 0.9
I0628 20:54:00.675422  5893 solver.cpp:349] Iteration 19500 (5.43176 iter/s, 18.4102s/100 iter), loss = 1.65421
I0628 20:54:00.675479  5893 solver.cpp:371]     Train net output #0: loss = 1.54894 (* 1 = 1.54894 loss)
I0628 20:54:00.675484  5893 sgd_solver.cpp:137] Iteration 19500, lr = 0.00878125, m = 0.9
I0628 20:54:19.095134  5893 solver.cpp:349] Iteration 19600 (5.42932 iter/s, 18.4185s/100 iter), loss = 1.74641
I0628 20:54:19.095155  5893 solver.cpp:371]     Train net output #0: loss = 1.37615 (* 1 = 1.37615 loss)
I0628 20:54:19.095158  5893 sgd_solver.cpp:137] Iteration 19600, lr = 0.008775, m = 0.9
I0628 20:54:37.537447  5893 solver.cpp:349] Iteration 19700 (5.42266 iter/s, 18.4411s/100 iter), loss = 1.73966
I0628 20:54:37.537554  5893 solver.cpp:371]     Train net output #0: loss = 1.86575 (* 1 = 1.86575 loss)
I0628 20:54:37.537560  5893 sgd_solver.cpp:137] Iteration 19700, lr = 0.00876875, m = 0.9
I0628 20:54:55.977391  5893 solver.cpp:349] Iteration 19800 (5.42338 iter/s, 18.4387s/100 iter), loss = 1.58464
I0628 20:54:55.977414  5893 solver.cpp:371]     Train net output #0: loss = 1.73704 (* 1 = 1.73704 loss)
I0628 20:54:55.977421  5893 sgd_solver.cpp:137] Iteration 19800, lr = 0.0087625, m = 0.9
I0628 20:55:14.390691  5893 solver.cpp:349] Iteration 19900 (5.43121 iter/s, 18.4121s/100 iter), loss = 1.34354
I0628 20:55:14.390786  5893 solver.cpp:371]     Train net output #0: loss = 1.37314 (* 1 = 1.37314 loss)
I0628 20:55:14.390792  5893 sgd_solver.cpp:137] Iteration 19900, lr = 0.00875625, m = 0.9
I0628 20:55:32.663911  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_20000.caffemodel
I0628 20:55:32.675987  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_20000.solverstate
I0628 20:55:32.681669  5893 solver.cpp:401] Sparsity after update:
I0628 20:55:32.682754  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:55:32.682762  5893 net.cpp:2170] conv1a_param_0(0.1) 
I0628 20:55:32.682770  5893 net.cpp:2170] conv1b_param_0(0.2) 
I0628 20:55:32.682773  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:55:32.682776  5893 net.cpp:2170] res2a_branch2a_param_0(0.2) 
I0628 20:55:32.682780  5893 net.cpp:2170] res2a_branch2b_param_0(0.2) 
I0628 20:55:32.682783  5893 net.cpp:2170] res3a_branch2a_param_0(0.2) 
I0628 20:55:32.682786  5893 net.cpp:2170] res3a_branch2b_param_0(0.2) 
I0628 20:55:32.682790  5893 net.cpp:2170] res4a_branch2a_param_0(0.2) 
I0628 20:55:32.682792  5893 net.cpp:2170] res4a_branch2b_param_0(0.2) 
I0628 20:55:32.682796  5893 net.cpp:2170] res5a_branch2a_param_0(0.2) 
I0628 20:55:32.682799  5893 net.cpp:2170] res5a_branch2b_param_0(0.2) 
I0628 20:55:32.682803  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (470702/2.86678e+06) 0.164
I0628 20:55:32.682816  5893 solver.cpp:545] Iteration 20000, Testing net (#0)
I0628 20:55:56.848304  5888 data_reader.cpp:262] Starting prefetch of epoch 20
I0628 20:55:56.910321  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57228
I0628 20:55:56.910344  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.805001
I0628 20:55:56.910351  5893 solver.cpp:630]     Test net output #2: loss = 1.86023 (* 1 = 1.86023 loss)
I0628 20:55:56.910367  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.226s
I0628 20:55:57.095034  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.21
I0628 20:55:57.398442  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:55:57.399915  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:55:57.400593  5893 solver.cpp:349] Iteration 20000 (2.3252 iter/s, 43.0071s/100 iter), loss = 1.48602
I0628 20:55:57.400612  5893 solver.cpp:371]     Train net output #0: loss = 1.21941 (* 1 = 1.21941 loss)
I0628 20:55:57.400620  5893 sgd_solver.cpp:137] Iteration 20000, lr = 0.00875, m = 0.9
I0628 20:56:00.402297  5875 data_reader.cpp:262] Starting prefetch of epoch 4
I0628 20:56:15.834779  5893 solver.cpp:349] Iteration 20100 (5.42506 iter/s, 18.433s/100 iter), loss = 1.7558
I0628 20:56:15.834800  5893 solver.cpp:371]     Train net output #0: loss = 1.91011 (* 1 = 1.91011 loss)
I0628 20:56:15.834805  5893 sgd_solver.cpp:137] Iteration 20100, lr = 0.00874375, m = 0.9
I0628 20:56:34.265980  5893 solver.cpp:349] Iteration 20200 (5.42594 iter/s, 18.43s/100 iter), loss = 1.52127
I0628 20:56:34.266098  5893 solver.cpp:371]     Train net output #0: loss = 1.41375 (* 1 = 1.41375 loss)
I0628 20:56:34.266104  5893 sgd_solver.cpp:137] Iteration 20200, lr = 0.0087375, m = 0.9
I0628 20:56:52.674923  5893 solver.cpp:349] Iteration 20300 (5.43254 iter/s, 18.4076s/100 iter), loss = 1.29643
I0628 20:56:52.674947  5893 solver.cpp:371]     Train net output #0: loss = 1.20229 (* 1 = 1.20229 loss)
I0628 20:56:52.674950  5893 sgd_solver.cpp:137] Iteration 20300, lr = 0.00873125, m = 0.9
I0628 20:57:11.104728  5893 solver.cpp:349] Iteration 20400 (5.42636 iter/s, 18.4286s/100 iter), loss = 1.15059
I0628 20:57:11.104820  5893 solver.cpp:371]     Train net output #0: loss = 1.14547 (* 1 = 1.14547 loss)
I0628 20:57:11.104825  5893 sgd_solver.cpp:137] Iteration 20400, lr = 0.008725, m = 0.9
I0628 20:57:29.566447  5893 solver.cpp:349] Iteration 20500 (5.417 iter/s, 18.4604s/100 iter), loss = 1.39133
I0628 20:57:29.566469  5893 solver.cpp:371]     Train net output #0: loss = 1.51175 (* 1 = 1.51175 loss)
I0628 20:57:29.566473  5893 sgd_solver.cpp:137] Iteration 20500, lr = 0.00871875, m = 0.9
I0628 20:57:48.001868  5893 solver.cpp:349] Iteration 20600 (5.42471 iter/s, 18.4342s/100 iter), loss = 1.39391
I0628 20:57:48.001976  5893 solver.cpp:371]     Train net output #0: loss = 1.19906 (* 1 = 1.19906 loss)
I0628 20:57:48.001982  5893 sgd_solver.cpp:137] Iteration 20600, lr = 0.0087125, m = 0.9
I0628 20:58:06.436748  5893 solver.cpp:349] Iteration 20700 (5.4249 iter/s, 18.4335s/100 iter), loss = 1.2852
I0628 20:58:06.436769  5893 solver.cpp:371]     Train net output #0: loss = 1.47695 (* 1 = 1.47695 loss)
I0628 20:58:06.436774  5893 sgd_solver.cpp:137] Iteration 20700, lr = 0.00870625, m = 0.9
I0628 20:58:24.851454  5893 solver.cpp:349] Iteration 20800 (5.43082 iter/s, 18.4134s/100 iter), loss = 1.4329
I0628 20:58:24.851555  5893 solver.cpp:371]     Train net output #0: loss = 1.37516 (* 1 = 1.37516 loss)
I0628 20:58:24.851562  5893 sgd_solver.cpp:137] Iteration 20800, lr = 0.0087, m = 0.9
I0628 20:58:43.285261  5893 solver.cpp:349] Iteration 20900 (5.42522 iter/s, 18.4324s/100 iter), loss = 1.40604
I0628 20:58:43.285285  5893 solver.cpp:371]     Train net output #0: loss = 1.37205 (* 1 = 1.37205 loss)
I0628 20:58:43.285291  5893 sgd_solver.cpp:137] Iteration 20900, lr = 0.00869375, m = 0.9
I0628 20:59:01.528614  5893 solver.cpp:401] Sparsity after update:
I0628 20:59:01.533835  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 20:59:01.533845  5893 net.cpp:2170] conv1a_param_0(0.105) 
I0628 20:59:01.533854  5893 net.cpp:2170] conv1b_param_0(0.21) 
I0628 20:59:01.533857  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 20:59:01.533860  5893 net.cpp:2170] res2a_branch2a_param_0(0.21) 
I0628 20:59:01.533864  5893 net.cpp:2170] res2a_branch2b_param_0(0.21) 
I0628 20:59:01.533866  5893 net.cpp:2170] res3a_branch2a_param_0(0.21) 
I0628 20:59:01.533869  5893 net.cpp:2170] res3a_branch2b_param_0(0.21) 
I0628 20:59:01.533872  5893 net.cpp:2170] res4a_branch2a_param_0(0.21) 
I0628 20:59:01.533875  5893 net.cpp:2170] res4a_branch2b_param_0(0.21) 
I0628 20:59:01.533879  5893 net.cpp:2170] res5a_branch2a_param_0(0.21) 
I0628 20:59:01.533881  5893 net.cpp:2170] res5a_branch2b_param_0(0.21) 
I0628 20:59:01.533885  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (494245/2.86678e+06) 0.172
I0628 20:59:01.533898  5893 solver.cpp:545] Iteration 21000, Testing net (#0)
I0628 20:59:01.986672  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 20:59:25.731374  5888 data_reader.cpp:262] Starting prefetch of epoch 21
I0628 20:59:25.793432  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56692
I0628 20:59:25.793457  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.802041
I0628 20:59:25.793463  5893 solver.cpp:630]     Test net output #2: loss = 1.88143 (* 1 = 1.88143 loss)
I0628 20:59:25.793481  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2579s
I0628 20:59:25.978623  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.22
I0628 20:59:26.279487  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 20:59:26.280956  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 20:59:26.281638  5893 solver.cpp:349] Iteration 21000 (2.32594 iter/s, 42.9934s/100 iter), loss = 1.43031
I0628 20:59:26.281657  5893 solver.cpp:371]     Train net output #0: loss = 1.39654 (* 1 = 1.39654 loss)
I0628 20:59:26.281666  5893 sgd_solver.cpp:137] Iteration 21000, lr = 0.0086875, m = 0.9
I0628 20:59:44.699030  5893 solver.cpp:349] Iteration 21100 (5.43004 iter/s, 18.4161s/100 iter), loss = 1.44667
I0628 20:59:44.699142  5893 solver.cpp:371]     Train net output #0: loss = 1.36952 (* 1 = 1.36952 loss)
I0628 20:59:44.699148  5893 sgd_solver.cpp:137] Iteration 21100, lr = 0.00868125, m = 0.9
I0628 21:00:03.124673  5893 solver.cpp:349] Iteration 21200 (5.42764 iter/s, 18.4242s/100 iter), loss = 1.20483
I0628 21:00:03.124696  5893 solver.cpp:371]     Train net output #0: loss = 1.20019 (* 1 = 1.20019 loss)
I0628 21:00:03.124701  5893 sgd_solver.cpp:137] Iteration 21200, lr = 0.008675, m = 0.9
I0628 21:00:21.549146  5893 solver.cpp:349] Iteration 21300 (5.42791 iter/s, 18.4233s/100 iter), loss = 1.44548
I0628 21:00:21.549195  5893 solver.cpp:371]     Train net output #0: loss = 1.46976 (* 1 = 1.46976 loss)
I0628 21:00:21.549199  5893 sgd_solver.cpp:137] Iteration 21300, lr = 0.00866875, m = 0.9
I0628 21:00:39.973107  5893 solver.cpp:349] Iteration 21400 (5.42759 iter/s, 18.4244s/100 iter), loss = 1.33891
I0628 21:00:39.973129  5893 solver.cpp:371]     Train net output #0: loss = 1.39467 (* 1 = 1.39467 loss)
I0628 21:00:39.973134  5893 sgd_solver.cpp:137] Iteration 21400, lr = 0.0086625, m = 0.9
I0628 21:00:58.379889  5893 solver.cpp:349] Iteration 21500 (5.43266 iter/s, 18.4072s/100 iter), loss = 1.59429
I0628 21:00:58.379990  5893 solver.cpp:371]     Train net output #0: loss = 1.3886 (* 1 = 1.3886 loss)
I0628 21:00:58.379997  5893 sgd_solver.cpp:137] Iteration 21500, lr = 0.00865625, m = 0.9
I0628 21:01:16.781967  5893 solver.cpp:349] Iteration 21600 (5.43409 iter/s, 18.4024s/100 iter), loss = 1.30438
I0628 21:01:16.781988  5893 solver.cpp:371]     Train net output #0: loss = 1.1735 (* 1 = 1.1735 loss)
I0628 21:01:16.781992  5893 sgd_solver.cpp:137] Iteration 21600, lr = 0.00865, m = 0.9
I0628 21:01:35.243741  5893 solver.cpp:349] Iteration 21700 (5.4165 iter/s, 18.4621s/100 iter), loss = 1.16757
I0628 21:01:35.243814  5893 solver.cpp:371]     Train net output #0: loss = 1.08453 (* 1 = 1.08453 loss)
I0628 21:01:35.243819  5893 sgd_solver.cpp:137] Iteration 21700, lr = 0.00864375, m = 0.9
I0628 21:01:53.674129  5893 solver.cpp:349] Iteration 21800 (5.42575 iter/s, 18.4306s/100 iter), loss = 1.27053
I0628 21:01:53.674154  5893 solver.cpp:371]     Train net output #0: loss = 1.14985 (* 1 = 1.14985 loss)
I0628 21:01:53.674157  5893 sgd_solver.cpp:137] Iteration 21800, lr = 0.0086375, m = 0.9
I0628 21:02:12.117725  5893 solver.cpp:349] Iteration 21900 (5.42186 iter/s, 18.4439s/100 iter), loss = 1.16776
I0628 21:02:12.117831  5893 solver.cpp:371]     Train net output #0: loss = 1.28303 (* 1 = 1.28303 loss)
I0628 21:02:12.117838  5893 sgd_solver.cpp:137] Iteration 21900, lr = 0.00863125, m = 0.9
I0628 21:02:30.346150  5893 solver.cpp:401] Sparsity after update:
I0628 21:02:30.351347  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:02:30.351356  5893 net.cpp:2170] conv1a_param_0(0.11) 
I0628 21:02:30.351362  5893 net.cpp:2170] conv1b_param_0(0.22) 
I0628 21:02:30.351364  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:02:30.351366  5893 net.cpp:2170] res2a_branch2a_param_0(0.22) 
I0628 21:02:30.351368  5893 net.cpp:2170] res2a_branch2b_param_0(0.22) 
I0628 21:02:30.351371  5893 net.cpp:2170] res3a_branch2a_param_0(0.22) 
I0628 21:02:30.351372  5893 net.cpp:2170] res3a_branch2b_param_0(0.22) 
I0628 21:02:30.351374  5893 net.cpp:2170] res4a_branch2a_param_0(0.22) 
I0628 21:02:30.351377  5893 net.cpp:2170] res4a_branch2b_param_0(0.22) 
I0628 21:02:30.351378  5893 net.cpp:2170] res5a_branch2a_param_0(0.22) 
I0628 21:02:30.351380  5893 net.cpp:2170] res5a_branch2b_param_0(0.22) 
I0628 21:02:30.351382  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (517779/2.86678e+06) 0.181
I0628 21:02:30.351392  5893 solver.cpp:545] Iteration 22000, Testing net (#0)
I0628 21:02:54.696308  5888 data_reader.cpp:262] Starting prefetch of epoch 22
I0628 21:02:54.900118  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57008
I0628 21:02:54.900136  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80316
I0628 21:02:54.900144  5893 solver.cpp:630]     Test net output #2: loss = 1.87142 (* 1 = 1.87142 loss)
I0628 21:02:54.900164  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5491s
I0628 21:02:55.084722  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.23
I0628 21:02:55.386662  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:02:55.388128  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:02:55.388797  5893 solver.cpp:349] Iteration 22000 (2.31099 iter/s, 43.2715s/100 iter), loss = 1.34353
I0628 21:02:55.388813  5893 solver.cpp:371]     Train net output #0: loss = 1.35364 (* 1 = 1.35364 loss)
I0628 21:02:55.388816  5893 sgd_solver.cpp:137] Iteration 22000, lr = 0.008625, m = 0.9
I0628 21:03:13.812759  5893 solver.cpp:349] Iteration 22100 (5.42767 iter/s, 18.4241s/100 iter), loss = 1.53045
I0628 21:03:13.812783  5893 solver.cpp:371]     Train net output #0: loss = 1.50655 (* 1 = 1.50655 loss)
I0628 21:03:13.812786  5893 sgd_solver.cpp:137] Iteration 22100, lr = 0.00861875, m = 0.9
I0628 21:03:32.239718  5893 solver.cpp:349] Iteration 22200 (5.42679 iter/s, 18.4271s/100 iter), loss = 1.73687
I0628 21:03:32.239801  5893 solver.cpp:371]     Train net output #0: loss = 1.86471 (* 1 = 1.86471 loss)
I0628 21:03:32.239809  5893 sgd_solver.cpp:137] Iteration 22200, lr = 0.0086125, m = 0.9
I0628 21:03:50.664325  5893 solver.cpp:349] Iteration 22300 (5.42752 iter/s, 18.4246s/100 iter), loss = 1.22101
I0628 21:03:50.664346  5893 solver.cpp:371]     Train net output #0: loss = 0.967341 (* 1 = 0.967341 loss)
I0628 21:03:50.664350  5893 sgd_solver.cpp:137] Iteration 22300, lr = 0.00860625, m = 0.9
I0628 21:04:09.069200  5893 solver.cpp:349] Iteration 22400 (5.43332 iter/s, 18.4049s/100 iter), loss = 1.24025
I0628 21:04:09.069296  5893 solver.cpp:371]     Train net output #0: loss = 1.35568 (* 1 = 1.35568 loss)
I0628 21:04:09.069303  5893 sgd_solver.cpp:137] Iteration 22400, lr = 0.0086, m = 0.9
I0628 21:04:27.484860  5893 solver.cpp:349] Iteration 22500 (5.43017 iter/s, 18.4156s/100 iter), loss = 1.45845
I0628 21:04:27.484882  5893 solver.cpp:371]     Train net output #0: loss = 1.84498 (* 1 = 1.84498 loss)
I0628 21:04:27.484886  5893 sgd_solver.cpp:137] Iteration 22500, lr = 0.00859375, m = 0.9
I0628 21:04:45.918689  5893 solver.cpp:349] Iteration 22600 (5.42481 iter/s, 18.4338s/100 iter), loss = 1.3592
I0628 21:04:45.918761  5893 solver.cpp:371]     Train net output #0: loss = 1.55889 (* 1 = 1.55889 loss)
I0628 21:04:45.918766  5893 sgd_solver.cpp:137] Iteration 22600, lr = 0.0085875, m = 0.9
I0628 21:05:04.331015  5893 solver.cpp:349] Iteration 22700 (5.43116 iter/s, 18.4123s/100 iter), loss = 1.26866
I0628 21:05:04.331038  5893 solver.cpp:371]     Train net output #0: loss = 1.55471 (* 1 = 1.55471 loss)
I0628 21:05:04.331043  5893 sgd_solver.cpp:137] Iteration 22700, lr = 0.00858125, m = 0.9
I0628 21:05:22.747598  5893 solver.cpp:349] Iteration 22800 (5.4299 iter/s, 18.4165s/100 iter), loss = 1.48338
I0628 21:05:22.747699  5893 solver.cpp:371]     Train net output #0: loss = 1.17342 (* 1 = 1.17342 loss)
I0628 21:05:22.747705  5893 sgd_solver.cpp:137] Iteration 22800, lr = 0.008575, m = 0.9
I0628 21:05:41.181762  5893 solver.cpp:349] Iteration 22900 (5.42476 iter/s, 18.434s/100 iter), loss = 1.3209
I0628 21:05:41.181787  5893 solver.cpp:371]     Train net output #0: loss = 1.33311 (* 1 = 1.33311 loss)
I0628 21:05:41.181790  5893 sgd_solver.cpp:137] Iteration 22900, lr = 0.00856875, m = 0.9
I0628 21:05:59.432912  5893 solver.cpp:401] Sparsity after update:
I0628 21:05:59.438082  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:05:59.438091  5893 net.cpp:2170] conv1a_param_0(0.115) 
I0628 21:05:59.438097  5893 net.cpp:2170] conv1b_param_0(0.23) 
I0628 21:05:59.438099  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:05:59.438102  5893 net.cpp:2170] res2a_branch2a_param_0(0.23) 
I0628 21:05:59.438103  5893 net.cpp:2170] res2a_branch2b_param_0(0.23) 
I0628 21:05:59.438105  5893 net.cpp:2170] res3a_branch2a_param_0(0.23) 
I0628 21:05:59.438107  5893 net.cpp:2170] res3a_branch2b_param_0(0.23) 
I0628 21:05:59.438108  5893 net.cpp:2170] res4a_branch2a_param_0(0.23) 
I0628 21:05:59.438110  5893 net.cpp:2170] res4a_branch2b_param_0(0.23) 
I0628 21:05:59.438112  5893 net.cpp:2170] res5a_branch2a_param_0(0.23) 
I0628 21:05:59.438114  5893 net.cpp:2170] res5a_branch2b_param_0(0.23) 
I0628 21:05:59.438117  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (541312/2.86678e+06) 0.189
I0628 21:05:59.438123  5893 solver.cpp:545] Iteration 23000, Testing net (#0)
I0628 21:06:23.863734  5888 data_reader.cpp:262] Starting prefetch of epoch 23
I0628 21:06:23.926774  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56064
I0628 21:06:23.926795  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79832
I0628 21:06:23.926800  5893 solver.cpp:630]     Test net output #2: loss = 1.91191 (* 1 = 1.91191 loss)
I0628 21:06:23.926817  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4886s
I0628 21:06:24.111310  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.24
I0628 21:06:24.423166  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:06:24.424641  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:06:24.425319  5893 solver.cpp:349] Iteration 23000 (2.3125 iter/s, 43.2433s/100 iter), loss = 1.53496
I0628 21:06:24.425338  5893 solver.cpp:371]     Train net output #0: loss = 1.57003 (* 1 = 1.57003 loss)
I0628 21:06:24.425346  5893 sgd_solver.cpp:137] Iteration 23000, lr = 0.0085625, m = 0.9
I0628 21:06:42.839102  5893 solver.cpp:349] Iteration 23100 (5.43076 iter/s, 18.4136s/100 iter), loss = 1.34326
I0628 21:06:42.839192  5893 solver.cpp:371]     Train net output #0: loss = 1.17251 (* 1 = 1.17251 loss)
I0628 21:06:42.839197  5893 sgd_solver.cpp:137] Iteration 23100, lr = 0.00855625, m = 0.9
I0628 21:07:01.249825  5893 solver.cpp:349] Iteration 23200 (5.43169 iter/s, 18.4105s/100 iter), loss = 1.37728
I0628 21:07:01.249846  5893 solver.cpp:371]     Train net output #0: loss = 1.35083 (* 1 = 1.35083 loss)
I0628 21:07:01.249850  5893 sgd_solver.cpp:137] Iteration 23200, lr = 0.00855, m = 0.9
I0628 21:07:19.695526  5893 solver.cpp:349] Iteration 23300 (5.42138 iter/s, 18.4455s/100 iter), loss = 1.36632
I0628 21:07:19.695619  5893 solver.cpp:371]     Train net output #0: loss = 1.30717 (* 1 = 1.30717 loss)
I0628 21:07:19.695626  5893 sgd_solver.cpp:137] Iteration 23300, lr = 0.00854375, m = 0.9
I0628 21:07:38.098541  5893 solver.cpp:349] Iteration 23400 (5.43398 iter/s, 18.4027s/100 iter), loss = 1.66969
I0628 21:07:38.098563  5893 solver.cpp:371]     Train net output #0: loss = 1.56062 (* 1 = 1.56062 loss)
I0628 21:07:38.098567  5893 sgd_solver.cpp:137] Iteration 23400, lr = 0.0085375, m = 0.9
I0628 21:07:56.533725  5893 solver.cpp:349] Iteration 23500 (5.42449 iter/s, 18.4349s/100 iter), loss = 1.40975
I0628 21:07:56.533810  5893 solver.cpp:371]     Train net output #0: loss = 1.45824 (* 1 = 1.45824 loss)
I0628 21:07:56.533814  5893 sgd_solver.cpp:137] Iteration 23500, lr = 0.00853125, m = 0.9
I0628 21:08:14.975448  5893 solver.cpp:349] Iteration 23600 (5.42259 iter/s, 18.4414s/100 iter), loss = 1.24854
I0628 21:08:14.975471  5893 solver.cpp:371]     Train net output #0: loss = 1.11292 (* 1 = 1.11292 loss)
I0628 21:08:14.975476  5893 sgd_solver.cpp:137] Iteration 23600, lr = 0.008525, m = 0.9
I0628 21:08:33.403508  5893 solver.cpp:349] Iteration 23700 (5.4266 iter/s, 18.4278s/100 iter), loss = 1.32543
I0628 21:08:33.403614  5893 solver.cpp:371]     Train net output #0: loss = 1.26432 (* 1 = 1.26432 loss)
I0628 21:08:33.403620  5893 sgd_solver.cpp:137] Iteration 23700, lr = 0.00851875, m = 0.9
I0628 21:08:51.853899  5893 solver.cpp:349] Iteration 23800 (5.42006 iter/s, 18.45s/100 iter), loss = 1.1993
I0628 21:08:51.853922  5893 solver.cpp:371]     Train net output #0: loss = 1.15459 (* 1 = 1.15459 loss)
I0628 21:08:51.853929  5893 sgd_solver.cpp:137] Iteration 23800, lr = 0.0085125, m = 0.9
I0628 21:09:10.267299  5893 solver.cpp:349] Iteration 23900 (5.43093 iter/s, 18.413s/100 iter), loss = 1.30266
I0628 21:09:10.267410  5893 solver.cpp:371]     Train net output #0: loss = 1.47663 (* 1 = 1.47663 loss)
I0628 21:09:10.267416  5893 sgd_solver.cpp:137] Iteration 23900, lr = 0.00850625, m = 0.9
I0628 21:09:28.495425  5893 solver.cpp:401] Sparsity after update:
I0628 21:09:28.500640  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:09:28.500648  5893 net.cpp:2170] conv1a_param_0(0.12) 
I0628 21:09:28.500654  5893 net.cpp:2170] conv1b_param_0(0.24) 
I0628 21:09:28.500656  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:09:28.500658  5893 net.cpp:2170] res2a_branch2a_param_0(0.24) 
I0628 21:09:28.500660  5893 net.cpp:2170] res2a_branch2b_param_0(0.24) 
I0628 21:09:28.500663  5893 net.cpp:2170] res3a_branch2a_param_0(0.24) 
I0628 21:09:28.500664  5893 net.cpp:2170] res3a_branch2b_param_0(0.24) 
I0628 21:09:28.500666  5893 net.cpp:2170] res4a_branch2a_param_0(0.24) 
I0628 21:09:28.500669  5893 net.cpp:2170] res4a_branch2b_param_0(0.24) 
I0628 21:09:28.500670  5893 net.cpp:2170] res5a_branch2a_param_0(0.24) 
I0628 21:09:28.500671  5893 net.cpp:2170] res5a_branch2b_param_0(0.24) 
I0628 21:09:28.500674  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (564851/2.86678e+06) 0.197
I0628 21:09:28.500681  5893 solver.cpp:545] Iteration 24000, Testing net (#0)
I0628 21:09:52.804896  5888 data_reader.cpp:262] Starting prefetch of epoch 24
I0628 21:09:53.071307  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56324
I0628 21:09:53.071327  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798721
I0628 21:09:53.071332  5893 solver.cpp:630]     Test net output #2: loss = 1.90329 (* 1 = 1.90329 loss)
I0628 21:09:53.071349  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5702s
I0628 21:09:53.256161  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.25
I0628 21:09:53.571806  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:09:53.573282  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:09:53.573962  5893 solver.cpp:349] Iteration 24000 (2.30916 iter/s, 43.3057s/100 iter), loss = 1.59334
I0628 21:09:53.573982  5893 solver.cpp:371]     Train net output #0: loss = 1.58692 (* 1 = 1.58692 loss)
I0628 21:09:53.573990  5893 sgd_solver.cpp:137] Iteration 24000, lr = 0.0085, m = 0.9
I0628 21:10:12.020380  5893 solver.cpp:349] Iteration 24100 (5.42123 iter/s, 18.446s/100 iter), loss = 1.52482
I0628 21:10:12.020403  5893 solver.cpp:371]     Train net output #0: loss = 1.49875 (* 1 = 1.49875 loss)
I0628 21:10:12.020407  5893 sgd_solver.cpp:137] Iteration 24100, lr = 0.00849375, m = 0.9
I0628 21:10:30.423142  5893 solver.cpp:349] Iteration 24200 (5.4341 iter/s, 18.4023s/100 iter), loss = 1.34796
I0628 21:10:30.423185  5893 solver.cpp:371]     Train net output #0: loss = 1.35053 (* 1 = 1.35053 loss)
I0628 21:10:30.423190  5893 sgd_solver.cpp:137] Iteration 24200, lr = 0.0084875, m = 0.9
I0628 21:10:48.837877  5893 solver.cpp:349] Iteration 24300 (5.43058 iter/s, 18.4143s/100 iter), loss = 1.55708
I0628 21:10:48.837899  5893 solver.cpp:371]     Train net output #0: loss = 1.55376 (* 1 = 1.55376 loss)
I0628 21:10:48.837903  5893 sgd_solver.cpp:137] Iteration 24300, lr = 0.00848125, m = 0.9
I0628 21:11:07.267575  5893 solver.cpp:349] Iteration 24400 (5.42617 iter/s, 18.4292s/100 iter), loss = 1.37854
I0628 21:11:07.267655  5893 solver.cpp:371]     Train net output #0: loss = 1.37712 (* 1 = 1.37712 loss)
I0628 21:11:07.267660  5893 sgd_solver.cpp:137] Iteration 24400, lr = 0.008475, m = 0.9
I0628 21:11:25.704566  5893 solver.cpp:349] Iteration 24500 (5.42404 iter/s, 18.4364s/100 iter), loss = 1.40087
I0628 21:11:25.704588  5893 solver.cpp:371]     Train net output #0: loss = 1.32158 (* 1 = 1.32158 loss)
I0628 21:11:25.704592  5893 sgd_solver.cpp:137] Iteration 24500, lr = 0.00846875, m = 0.9
I0628 21:11:44.105418  5893 solver.cpp:349] Iteration 24600 (5.43468 iter/s, 18.4003s/100 iter), loss = 1.40071
I0628 21:11:44.105522  5893 solver.cpp:371]     Train net output #0: loss = 1.59439 (* 1 = 1.59439 loss)
I0628 21:11:44.105528  5893 sgd_solver.cpp:137] Iteration 24600, lr = 0.0084625, m = 0.9
I0628 21:12:02.523427  5893 solver.cpp:349] Iteration 24700 (5.42965 iter/s, 18.4174s/100 iter), loss = 1.43525
I0628 21:12:02.523453  5893 solver.cpp:371]     Train net output #0: loss = 1.363 (* 1 = 1.363 loss)
I0628 21:12:02.523458  5893 sgd_solver.cpp:137] Iteration 24700, lr = 0.00845625, m = 0.9
I0628 21:12:20.952635  5893 solver.cpp:349] Iteration 24800 (5.4263 iter/s, 18.4288s/100 iter), loss = 1.22398
I0628 21:12:20.952754  5893 solver.cpp:371]     Train net output #0: loss = 1.43351 (* 1 = 1.43351 loss)
I0628 21:12:20.952760  5893 sgd_solver.cpp:137] Iteration 24800, lr = 0.00845, m = 0.9
I0628 21:12:39.385076  5893 solver.cpp:349] Iteration 24900 (5.42506 iter/s, 18.433s/100 iter), loss = 1.40656
I0628 21:12:39.385100  5893 solver.cpp:371]     Train net output #0: loss = 1.54981 (* 1 = 1.54981 loss)
I0628 21:12:39.385105  5893 sgd_solver.cpp:137] Iteration 24900, lr = 0.00844375, m = 0.9
I0628 21:12:57.624699  5893 solver.cpp:401] Sparsity after update:
I0628 21:12:57.629650  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:12:57.629658  5893 net.cpp:2170] conv1a_param_0(0.125) 
I0628 21:12:57.629664  5893 net.cpp:2170] conv1b_param_0(0.25) 
I0628 21:12:57.629667  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:12:57.629668  5893 net.cpp:2170] res2a_branch2a_param_0(0.25) 
I0628 21:12:57.629670  5893 net.cpp:2170] res2a_branch2b_param_0(0.25) 
I0628 21:12:57.629673  5893 net.cpp:2170] res3a_branch2a_param_0(0.25) 
I0628 21:12:57.629674  5893 net.cpp:2170] res3a_branch2b_param_0(0.25) 
I0628 21:12:57.629675  5893 net.cpp:2170] res4a_branch2a_param_0(0.25) 
I0628 21:12:57.629678  5893 net.cpp:2170] res4a_branch2b_param_0(0.25) 
I0628 21:12:57.629679  5893 net.cpp:2170] res5a_branch2a_param_0(0.25) 
I0628 21:12:57.629681  5893 net.cpp:2170] res5a_branch2b_param_0(0.25) 
I0628 21:12:57.629683  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (588388/2.86678e+06) 0.205
I0628 21:12:57.629690  5893 solver.cpp:545] Iteration 25000, Testing net (#0)
I0628 21:13:22.012672  5888 data_reader.cpp:262] Starting prefetch of epoch 25
I0628 21:13:22.074542  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56608
I0628 21:13:22.074563  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79876
I0628 21:13:22.074568  5893 solver.cpp:630]     Test net output #2: loss = 1.89314 (* 1 = 1.89314 loss)
I0628 21:13:22.074637  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4457s
I0628 21:13:22.259641  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.26
I0628 21:13:22.590191  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:13:22.591670  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:13:22.592340  5893 solver.cpp:349] Iteration 25000 (2.31435 iter/s, 43.2087s/100 iter), loss = 1.4836
I0628 21:13:22.592360  5893 solver.cpp:371]     Train net output #0: loss = 1.49519 (* 1 = 1.49519 loss)
I0628 21:13:22.592366  5893 sgd_solver.cpp:137] Iteration 25000, lr = 0.0084375, m = 0.9
I0628 21:13:26.430124  5875 data_reader.cpp:262] Starting prefetch of epoch 5
I0628 21:13:41.022619  5893 solver.cpp:349] Iteration 25100 (5.4257 iter/s, 18.4308s/100 iter), loss = 1.44338
I0628 21:13:41.022699  5893 solver.cpp:371]     Train net output #0: loss = 1.44985 (* 1 = 1.44985 loss)
I0628 21:13:41.022707  5893 sgd_solver.cpp:137] Iteration 25100, lr = 0.00843125, m = 0.9
I0628 21:13:59.445442  5893 solver.cpp:349] Iteration 25200 (5.42793 iter/s, 18.4232s/100 iter), loss = 1.4397
I0628 21:13:59.445466  5893 solver.cpp:371]     Train net output #0: loss = 1.48792 (* 1 = 1.48792 loss)
I0628 21:13:59.445471  5893 sgd_solver.cpp:137] Iteration 25200, lr = 0.008425, m = 0.9
I0628 21:14:17.856289  5893 solver.cpp:349] Iteration 25300 (5.43145 iter/s, 18.4113s/100 iter), loss = 1.10922
I0628 21:14:17.856362  5893 solver.cpp:371]     Train net output #0: loss = 1.21413 (* 1 = 1.21413 loss)
I0628 21:14:17.856367  5893 sgd_solver.cpp:137] Iteration 25300, lr = 0.00841875, m = 0.9
I0628 21:14:36.260749  5893 solver.cpp:349] Iteration 25400 (5.43336 iter/s, 18.4048s/100 iter), loss = 1.47658
I0628 21:14:36.260772  5893 solver.cpp:371]     Train net output #0: loss = 1.36772 (* 1 = 1.36772 loss)
I0628 21:14:36.260776  5893 sgd_solver.cpp:137] Iteration 25400, lr = 0.0084125, m = 0.9
I0628 21:14:54.684044  5893 solver.cpp:349] Iteration 25500 (5.4278 iter/s, 18.4237s/100 iter), loss = 1.2134
I0628 21:14:54.684156  5893 solver.cpp:371]     Train net output #0: loss = 1.16635 (* 1 = 1.16635 loss)
I0628 21:14:54.684164  5893 sgd_solver.cpp:137] Iteration 25500, lr = 0.00840625, m = 0.9
I0628 21:15:13.131445  5893 solver.cpp:349] Iteration 25600 (5.42074 iter/s, 18.4477s/100 iter), loss = 1.46809
I0628 21:15:13.131467  5893 solver.cpp:371]     Train net output #0: loss = 1.38877 (* 1 = 1.38877 loss)
I0628 21:15:13.131471  5893 sgd_solver.cpp:137] Iteration 25600, lr = 0.0084, m = 0.9
I0628 21:15:31.574554  5893 solver.cpp:349] Iteration 25700 (5.42199 iter/s, 18.4434s/100 iter), loss = 1.84881
I0628 21:15:31.574657  5893 solver.cpp:371]     Train net output #0: loss = 1.98429 (* 1 = 1.98429 loss)
I0628 21:15:31.574664  5893 sgd_solver.cpp:137] Iteration 25700, lr = 0.00839375, m = 0.9
I0628 21:15:50.001098  5893 solver.cpp:349] Iteration 25800 (5.4269 iter/s, 18.4267s/100 iter), loss = 1.49418
I0628 21:15:50.001121  5893 solver.cpp:371]     Train net output #0: loss = 1.29432 (* 1 = 1.29432 loss)
I0628 21:15:50.001126  5893 sgd_solver.cpp:137] Iteration 25800, lr = 0.0083875, m = 0.9
I0628 21:16:08.422668  5893 solver.cpp:349] Iteration 25900 (5.42835 iter/s, 18.4218s/100 iter), loss = 1.376
I0628 21:16:08.422771  5893 solver.cpp:371]     Train net output #0: loss = 1.45652 (* 1 = 1.45652 loss)
I0628 21:16:08.422778  5893 sgd_solver.cpp:137] Iteration 25900, lr = 0.00838125, m = 0.9
I0628 21:16:26.668285  5893 solver.cpp:401] Sparsity after update:
I0628 21:16:26.673468  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:16:26.673476  5893 net.cpp:2170] conv1a_param_0(0.13) 
I0628 21:16:26.673482  5893 net.cpp:2170] conv1b_param_0(0.26) 
I0628 21:16:26.673485  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:16:26.673486  5893 net.cpp:2170] res2a_branch2a_param_0(0.26) 
I0628 21:16:26.673488  5893 net.cpp:2170] res2a_branch2b_param_0(0.26) 
I0628 21:16:26.673491  5893 net.cpp:2170] res3a_branch2a_param_0(0.26) 
I0628 21:16:26.673491  5893 net.cpp:2170] res3a_branch2b_param_0(0.26) 
I0628 21:16:26.673493  5893 net.cpp:2170] res4a_branch2a_param_0(0.26) 
I0628 21:16:26.673496  5893 net.cpp:2170] res4a_branch2b_param_0(0.26) 
I0628 21:16:26.673497  5893 net.cpp:2170] res5a_branch2a_param_0(0.26) 
I0628 21:16:26.673499  5893 net.cpp:2170] res5a_branch2b_param_0(0.26) 
I0628 21:16:26.673501  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (611929/2.86678e+06) 0.213
I0628 21:16:26.673508  5893 solver.cpp:545] Iteration 26000, Testing net (#0)
I0628 21:16:27.268297  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 21:16:50.868453  5888 data_reader.cpp:262] Starting prefetch of epoch 26
I0628 21:16:50.984356  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57084
I0628 21:16:50.984378  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.803201
I0628 21:16:50.984383  5893 solver.cpp:630]     Test net output #2: loss = 1.87273 (* 1 = 1.87273 loss)
I0628 21:16:50.984400  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3108s
I0628 21:16:51.168763  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.27
I0628 21:16:51.499505  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:16:51.500969  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:16:51.501642  5893 solver.cpp:349] Iteration 26000 (2.32131 iter/s, 43.0791s/100 iter), loss = 1.34818
I0628 21:16:51.501659  5893 solver.cpp:371]     Train net output #0: loss = 1.40334 (* 1 = 1.40334 loss)
I0628 21:16:51.501664  5893 sgd_solver.cpp:137] Iteration 26000, lr = 0.008375, m = 0.9
I0628 21:17:09.981914  5893 solver.cpp:349] Iteration 26100 (5.41131 iter/s, 18.4798s/100 iter), loss = 1.24542
I0628 21:17:09.981936  5893 solver.cpp:371]     Train net output #0: loss = 1.48811 (* 1 = 1.48811 loss)
I0628 21:17:09.981940  5893 sgd_solver.cpp:137] Iteration 26100, lr = 0.00836875, m = 0.9
I0628 21:17:28.419912  5893 solver.cpp:349] Iteration 26200 (5.42372 iter/s, 18.4375s/100 iter), loss = 1.53077
I0628 21:17:28.420017  5893 solver.cpp:371]     Train net output #0: loss = 1.55424 (* 1 = 1.55424 loss)
I0628 21:17:28.420027  5893 sgd_solver.cpp:137] Iteration 26200, lr = 0.0083625, m = 0.9
I0628 21:17:46.854544  5893 solver.cpp:349] Iteration 26300 (5.42474 iter/s, 18.4341s/100 iter), loss = 1.375
I0628 21:17:46.854568  5893 solver.cpp:371]     Train net output #0: loss = 1.202 (* 1 = 1.202 loss)
I0628 21:17:46.854571  5893 sgd_solver.cpp:137] Iteration 26300, lr = 0.00835625, m = 0.9
I0628 21:18:05.280026  5893 solver.cpp:349] Iteration 26400 (5.42741 iter/s, 18.425s/100 iter), loss = 1.4207
I0628 21:18:05.280135  5893 solver.cpp:371]     Train net output #0: loss = 1.48888 (* 1 = 1.48888 loss)
I0628 21:18:05.280143  5893 sgd_solver.cpp:137] Iteration 26400, lr = 0.00835, m = 0.9
I0628 21:18:23.703402  5893 solver.cpp:349] Iteration 26500 (5.42806 iter/s, 18.4228s/100 iter), loss = 1.1544
I0628 21:18:23.703425  5893 solver.cpp:371]     Train net output #0: loss = 0.930602 (* 1 = 0.930602 loss)
I0628 21:18:23.703429  5893 sgd_solver.cpp:137] Iteration 26500, lr = 0.00834375, m = 0.9
I0628 21:18:42.127638  5893 solver.cpp:349] Iteration 26600 (5.42778 iter/s, 18.4237s/100 iter), loss = 1.40374
I0628 21:18:42.127740  5893 solver.cpp:371]     Train net output #0: loss = 1.60847 (* 1 = 1.60847 loss)
I0628 21:18:42.127748  5893 sgd_solver.cpp:137] Iteration 26600, lr = 0.0083375, m = 0.9
I0628 21:19:00.548709  5893 solver.cpp:349] Iteration 26700 (5.42874 iter/s, 18.4205s/100 iter), loss = 1.49659
I0628 21:19:00.548732  5893 solver.cpp:371]     Train net output #0: loss = 1.47222 (* 1 = 1.47222 loss)
I0628 21:19:00.548737  5893 sgd_solver.cpp:137] Iteration 26700, lr = 0.00833125, m = 0.9
I0628 21:19:18.951099  5893 solver.cpp:349] Iteration 26800 (5.43423 iter/s, 18.4019s/100 iter), loss = 1.43988
I0628 21:19:18.951170  5893 solver.cpp:371]     Train net output #0: loss = 1.43208 (* 1 = 1.43208 loss)
I0628 21:19:18.951175  5893 sgd_solver.cpp:137] Iteration 26800, lr = 0.008325, m = 0.9
I0628 21:19:37.395889  5893 solver.cpp:349] Iteration 26900 (5.42176 iter/s, 18.4442s/100 iter), loss = 1.36724
I0628 21:19:37.395911  5893 solver.cpp:371]     Train net output #0: loss = 1.42058 (* 1 = 1.42058 loss)
I0628 21:19:37.395915  5893 sgd_solver.cpp:137] Iteration 26900, lr = 0.00831875, m = 0.9
I0628 21:19:55.645412  5893 solver.cpp:401] Sparsity after update:
I0628 21:19:55.650612  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:19:55.650620  5893 net.cpp:2170] conv1a_param_0(0.135) 
I0628 21:19:55.650626  5893 net.cpp:2170] conv1b_param_0(0.27) 
I0628 21:19:55.650629  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:19:55.650630  5893 net.cpp:2170] res2a_branch2a_param_0(0.27) 
I0628 21:19:55.650635  5893 net.cpp:2170] res2a_branch2b_param_0(0.27) 
I0628 21:19:55.650636  5893 net.cpp:2170] res3a_branch2a_param_0(0.27) 
I0628 21:19:55.650638  5893 net.cpp:2170] res3a_branch2b_param_0(0.27) 
I0628 21:19:55.650640  5893 net.cpp:2170] res4a_branch2a_param_0(0.27) 
I0628 21:19:55.650642  5893 net.cpp:2170] res4a_branch2b_param_0(0.27) 
I0628 21:19:55.650643  5893 net.cpp:2170] res5a_branch2a_param_0(0.27) 
I0628 21:19:55.650645  5893 net.cpp:2170] res5a_branch2b_param_0(0.27) 
I0628 21:19:55.650647  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (635457/2.86678e+06) 0.222
I0628 21:19:55.650655  5893 solver.cpp:545] Iteration 27000, Testing net (#0)
I0628 21:20:19.923038  5888 data_reader.cpp:262] Starting prefetch of epoch 27
I0628 21:20:19.985144  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56928
I0628 21:20:19.985168  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80348
I0628 21:20:19.985173  5893 solver.cpp:630]     Test net output #2: loss = 1.86584 (* 1 = 1.86584 loss)
I0628 21:20:19.985191  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3339s
I0628 21:20:20.170567  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.28
I0628 21:20:20.505756  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:20:20.507236  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:20:20.507906  5893 solver.cpp:349] Iteration 27000 (2.3196 iter/s, 43.1108s/100 iter), loss = 1.36361
I0628 21:20:20.507925  5893 solver.cpp:371]     Train net output #0: loss = 1.02713 (* 1 = 1.02713 loss)
I0628 21:20:20.507932  5893 sgd_solver.cpp:137] Iteration 27000, lr = 0.0083125, m = 0.9
I0628 21:20:38.986979  5893 solver.cpp:349] Iteration 27100 (5.41169 iter/s, 18.4785s/100 iter), loss = 1.33086
I0628 21:20:38.987072  5893 solver.cpp:371]     Train net output #0: loss = 1.39418 (* 1 = 1.39418 loss)
I0628 21:20:38.987078  5893 sgd_solver.cpp:137] Iteration 27100, lr = 0.00830625, m = 0.9
I0628 21:20:57.431287  5893 solver.cpp:349] Iteration 27200 (5.42192 iter/s, 18.4437s/100 iter), loss = 1.06064
I0628 21:20:57.431310  5893 solver.cpp:371]     Train net output #0: loss = 0.867146 (* 1 = 0.867146 loss)
I0628 21:20:57.431314  5893 sgd_solver.cpp:137] Iteration 27200, lr = 0.0083, m = 0.9
I0628 21:21:15.845592  5893 solver.cpp:349] Iteration 27300 (5.43073 iter/s, 18.4137s/100 iter), loss = 1.46758
I0628 21:21:15.845693  5893 solver.cpp:371]     Train net output #0: loss = 1.39147 (* 1 = 1.39147 loss)
I0628 21:21:15.845700  5893 sgd_solver.cpp:137] Iteration 27300, lr = 0.00829375, m = 0.9
I0628 21:21:34.289237  5893 solver.cpp:349] Iteration 27400 (5.42212 iter/s, 18.443s/100 iter), loss = 1.77545
I0628 21:21:34.289260  5893 solver.cpp:371]     Train net output #0: loss = 1.5239 (* 1 = 1.5239 loss)
I0628 21:21:34.289265  5893 sgd_solver.cpp:137] Iteration 27400, lr = 0.0082875, m = 0.9
I0628 21:21:52.711283  5893 solver.cpp:349] Iteration 27500 (5.42845 iter/s, 18.4215s/100 iter), loss = 1.5662
I0628 21:21:52.711392  5893 solver.cpp:371]     Train net output #0: loss = 1.50754 (* 1 = 1.50754 loss)
I0628 21:21:52.711400  5893 sgd_solver.cpp:137] Iteration 27500, lr = 0.00828125, m = 0.9
I0628 21:22:11.134423  5893 solver.cpp:349] Iteration 27600 (5.42816 iter/s, 18.4224s/100 iter), loss = 1.51129
I0628 21:22:11.134446  5893 solver.cpp:371]     Train net output #0: loss = 1.6967 (* 1 = 1.6967 loss)
I0628 21:22:11.134449  5893 sgd_solver.cpp:137] Iteration 27600, lr = 0.008275, m = 0.9
I0628 21:22:29.593152  5893 solver.cpp:349] Iteration 27700 (5.41767 iter/s, 18.4581s/100 iter), loss = 1.11457
I0628 21:22:29.593255  5893 solver.cpp:371]     Train net output #0: loss = 1.06039 (* 1 = 1.06039 loss)
I0628 21:22:29.593261  5893 sgd_solver.cpp:137] Iteration 27700, lr = 0.00826875, m = 0.9
I0628 21:22:48.006551  5893 solver.cpp:349] Iteration 27800 (5.43103 iter/s, 18.4127s/100 iter), loss = 1.36515
I0628 21:22:48.006573  5893 solver.cpp:371]     Train net output #0: loss = 1.10099 (* 1 = 1.10099 loss)
I0628 21:22:48.006578  5893 sgd_solver.cpp:137] Iteration 27800, lr = 0.0082625, m = 0.9
I0628 21:23:06.436615  5893 solver.cpp:349] Iteration 27900 (5.4261 iter/s, 18.4294s/100 iter), loss = 1.22843
I0628 21:23:06.436697  5893 solver.cpp:371]     Train net output #0: loss = 0.961972 (* 1 = 0.961972 loss)
I0628 21:23:06.436702  5893 sgd_solver.cpp:137] Iteration 27900, lr = 0.00825625, m = 0.9
I0628 21:23:24.681982  5893 solver.cpp:401] Sparsity after update:
I0628 21:23:24.687186  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:23:24.687194  5893 net.cpp:2170] conv1a_param_0(0.14) 
I0628 21:23:24.687201  5893 net.cpp:2170] conv1b_param_0(0.28) 
I0628 21:23:24.687202  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:23:24.687204  5893 net.cpp:2170] res2a_branch2a_param_0(0.28) 
I0628 21:23:24.687207  5893 net.cpp:2170] res2a_branch2b_param_0(0.28) 
I0628 21:23:24.687209  5893 net.cpp:2170] res3a_branch2a_param_0(0.28) 
I0628 21:23:24.687211  5893 net.cpp:2170] res3a_branch2b_param_0(0.28) 
I0628 21:23:24.687213  5893 net.cpp:2170] res4a_branch2a_param_0(0.28) 
I0628 21:23:24.687216  5893 net.cpp:2170] res4a_branch2b_param_0(0.28) 
I0628 21:23:24.687217  5893 net.cpp:2170] res5a_branch2a_param_0(0.28) 
I0628 21:23:24.687219  5893 net.cpp:2170] res5a_branch2b_param_0(0.28) 
I0628 21:23:24.687222  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (658988/2.86678e+06) 0.23
I0628 21:23:24.687229  5893 solver.cpp:545] Iteration 28000, Testing net (#0)
I0628 21:23:49.086076  5888 data_reader.cpp:262] Starting prefetch of epoch 28
I0628 21:23:49.252470  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57484
I0628 21:23:49.252488  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.807801
I0628 21:23:49.252493  5893 solver.cpp:630]     Test net output #2: loss = 1.84387 (* 1 = 1.84387 loss)
I0628 21:23:49.252511  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5645s
I0628 21:23:49.436995  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.29
I0628 21:23:49.767024  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:23:49.768496  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:23:49.769170  5893 solver.cpp:349] Iteration 28000 (2.30781 iter/s, 43.3311s/100 iter), loss = 1.43038
I0628 21:23:49.769186  5893 solver.cpp:371]     Train net output #0: loss = 1.56791 (* 1 = 1.56791 loss)
I0628 21:23:49.769191  5893 sgd_solver.cpp:137] Iteration 28000, lr = 0.00825, m = 0.9
I0628 21:24:08.216223  5893 solver.cpp:349] Iteration 28100 (5.42111 iter/s, 18.4464s/100 iter), loss = 1.37371
I0628 21:24:08.216244  5893 solver.cpp:371]     Train net output #0: loss = 1.2225 (* 1 = 1.2225 loss)
I0628 21:24:08.216248  5893 sgd_solver.cpp:137] Iteration 28100, lr = 0.00824375, m = 0.9
I0628 21:24:26.643955  5893 solver.cpp:349] Iteration 28200 (5.4268 iter/s, 18.4271s/100 iter), loss = 1.33201
I0628 21:24:26.644062  5893 solver.cpp:371]     Train net output #0: loss = 1.46272 (* 1 = 1.46272 loss)
I0628 21:24:26.644068  5893 sgd_solver.cpp:137] Iteration 28200, lr = 0.0082375, m = 0.9
I0628 21:24:45.071290  5893 solver.cpp:349] Iteration 28300 (5.42694 iter/s, 18.4266s/100 iter), loss = 1.45393
I0628 21:24:45.071311  5893 solver.cpp:371]     Train net output #0: loss = 1.37131 (* 1 = 1.37131 loss)
I0628 21:24:45.071316  5893 sgd_solver.cpp:137] Iteration 28300, lr = 0.00823125, m = 0.9
I0628 21:25:03.512585  5893 solver.cpp:349] Iteration 28400 (5.42281 iter/s, 18.4406s/100 iter), loss = 1.70714
I0628 21:25:03.512658  5893 solver.cpp:371]     Train net output #0: loss = 1.79395 (* 1 = 1.79395 loss)
I0628 21:25:03.512663  5893 sgd_solver.cpp:137] Iteration 28400, lr = 0.008225, m = 0.9
I0628 21:25:21.953011  5893 solver.cpp:349] Iteration 28500 (5.42308 iter/s, 18.4397s/100 iter), loss = 1.29014
I0628 21:25:21.953032  5893 solver.cpp:371]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0628 21:25:21.953037  5893 sgd_solver.cpp:137] Iteration 28500, lr = 0.00821875, m = 0.9
I0628 21:25:40.408773  5893 solver.cpp:349] Iteration 28600 (5.41856 iter/s, 18.4551s/100 iter), loss = 1.01043
I0628 21:25:40.408874  5893 solver.cpp:371]     Train net output #0: loss = 1.25749 (* 1 = 1.25749 loss)
I0628 21:25:40.408881  5893 sgd_solver.cpp:137] Iteration 28600, lr = 0.0082125, m = 0.9
I0628 21:25:58.843569  5893 solver.cpp:349] Iteration 28700 (5.42475 iter/s, 18.434s/100 iter), loss = 1.16577
I0628 21:25:58.843592  5893 solver.cpp:371]     Train net output #0: loss = 1.25655 (* 1 = 1.25655 loss)
I0628 21:25:58.843596  5893 sgd_solver.cpp:137] Iteration 28700, lr = 0.00820625, m = 0.9
I0628 21:26:17.286325  5893 solver.cpp:349] Iteration 28800 (5.42239 iter/s, 18.4421s/100 iter), loss = 1.05678
I0628 21:26:17.286420  5893 solver.cpp:371]     Train net output #0: loss = 1.15354 (* 1 = 1.15354 loss)
I0628 21:26:17.286427  5893 sgd_solver.cpp:137] Iteration 28800, lr = 0.0082, m = 0.9
I0628 21:26:35.698848  5893 solver.cpp:349] Iteration 28900 (5.43132 iter/s, 18.4117s/100 iter), loss = 1.50086
I0628 21:26:35.698873  5893 solver.cpp:371]     Train net output #0: loss = 1.52586 (* 1 = 1.52586 loss)
I0628 21:26:35.698879  5893 sgd_solver.cpp:137] Iteration 28900, lr = 0.00819375, m = 0.9
I0628 21:26:53.942436  5893 solver.cpp:401] Sparsity after update:
I0628 21:26:53.947616  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:26:53.947624  5893 net.cpp:2170] conv1a_param_0(0.145) 
I0628 21:26:53.947630  5893 net.cpp:2170] conv1b_param_0(0.29) 
I0628 21:26:53.947633  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:26:53.947634  5893 net.cpp:2170] res2a_branch2a_param_0(0.29) 
I0628 21:26:53.947636  5893 net.cpp:2170] res2a_branch2b_param_0(0.29) 
I0628 21:26:53.947638  5893 net.cpp:2170] res3a_branch2a_param_0(0.29) 
I0628 21:26:53.947641  5893 net.cpp:2170] res3a_branch2b_param_0(0.29) 
I0628 21:26:53.947643  5893 net.cpp:2170] res4a_branch2a_param_0(0.29) 
I0628 21:26:53.947645  5893 net.cpp:2170] res4a_branch2b_param_0(0.29) 
I0628 21:26:53.947648  5893 net.cpp:2170] res5a_branch2a_param_0(0.29) 
I0628 21:26:53.947649  5893 net.cpp:2170] res5a_branch2b_param_0(0.29) 
I0628 21:26:53.947651  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (682528/2.86678e+06) 0.238
I0628 21:26:53.947659  5893 solver.cpp:545] Iteration 29000, Testing net (#0)
I0628 21:27:18.530062  5888 data_reader.cpp:262] Starting prefetch of epoch 29
I0628 21:27:18.592147  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57228
I0628 21:27:18.592170  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.806121
I0628 21:27:18.592175  5893 solver.cpp:630]     Test net output #2: loss = 1.85139 (* 1 = 1.85139 loss)
I0628 21:27:18.592192  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6436s
I0628 21:27:18.778012  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.3
I0628 21:27:19.129288  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:27:19.130760  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:27:19.131436  5893 solver.cpp:349] Iteration 29000 (2.30251 iter/s, 43.4309s/100 iter), loss = 1.35011
I0628 21:27:19.131454  5893 solver.cpp:371]     Train net output #0: loss = 1.26966 (* 1 = 1.26966 loss)
I0628 21:27:19.131459  5893 sgd_solver.cpp:137] Iteration 29000, lr = 0.0081875, m = 0.9
I0628 21:27:37.603869  5893 solver.cpp:349] Iteration 29100 (5.41368 iter/s, 18.4717s/100 iter), loss = 1.28617
I0628 21:27:37.603955  5893 solver.cpp:371]     Train net output #0: loss = 1.20414 (* 1 = 1.20414 loss)
I0628 21:27:37.603960  5893 sgd_solver.cpp:137] Iteration 29100, lr = 0.00818125, m = 0.9
I0628 21:27:56.024976  5893 solver.cpp:349] Iteration 29200 (5.42879 iter/s, 18.4203s/100 iter), loss = 1.75095
I0628 21:27:56.024994  5893 solver.cpp:371]     Train net output #0: loss = 1.61706 (* 1 = 1.61706 loss)
I0628 21:27:56.024998  5893 sgd_solver.cpp:137] Iteration 29200, lr = 0.008175, m = 0.9
I0628 21:28:14.458314  5893 solver.cpp:349] Iteration 29300 (5.42517 iter/s, 18.4326s/100 iter), loss = 1.41603
I0628 21:28:14.458425  5893 solver.cpp:371]     Train net output #0: loss = 1.54063 (* 1 = 1.54063 loss)
I0628 21:28:14.458431  5893 sgd_solver.cpp:137] Iteration 29300, lr = 0.00816875, m = 0.9
I0628 21:28:32.875913  5893 solver.cpp:349] Iteration 29400 (5.42984 iter/s, 18.4168s/100 iter), loss = 1.38017
I0628 21:28:32.875938  5893 solver.cpp:371]     Train net output #0: loss = 1.30985 (* 1 = 1.30985 loss)
I0628 21:28:32.875943  5893 sgd_solver.cpp:137] Iteration 29400, lr = 0.0081625, m = 0.9
I0628 21:28:51.322778  5893 solver.cpp:349] Iteration 29500 (5.4212 iter/s, 18.4461s/100 iter), loss = 1.15867
I0628 21:28:51.322877  5893 solver.cpp:371]     Train net output #0: loss = 1.12589 (* 1 = 1.12589 loss)
I0628 21:28:51.322883  5893 sgd_solver.cpp:137] Iteration 29500, lr = 0.00815625, m = 0.9
I0628 21:29:09.752331  5893 solver.cpp:349] Iteration 29600 (5.42632 iter/s, 18.4287s/100 iter), loss = 1.31455
I0628 21:29:09.752353  5893 solver.cpp:371]     Train net output #0: loss = 1.5299 (* 1 = 1.5299 loss)
I0628 21:29:09.752357  5893 sgd_solver.cpp:137] Iteration 29600, lr = 0.00815, m = 0.9
I0628 21:29:28.201493  5893 solver.cpp:349] Iteration 29700 (5.42053 iter/s, 18.4484s/100 iter), loss = 1.57178
I0628 21:29:28.201604  5893 solver.cpp:371]     Train net output #0: loss = 1.15852 (* 1 = 1.15852 loss)
I0628 21:29:28.201613  5893 sgd_solver.cpp:137] Iteration 29700, lr = 0.00814375, m = 0.9
I0628 21:29:46.650602  5893 solver.cpp:349] Iteration 29800 (5.42057 iter/s, 18.4482s/100 iter), loss = 1.15214
I0628 21:29:46.650626  5893 solver.cpp:371]     Train net output #0: loss = 1.30461 (* 1 = 1.30461 loss)
I0628 21:29:46.650631  5893 sgd_solver.cpp:137] Iteration 29800, lr = 0.0081375, m = 0.9
I0628 21:30:05.082204  5893 solver.cpp:349] Iteration 29900 (5.42569 iter/s, 18.4308s/100 iter), loss = 1.29095
I0628 21:30:05.082309  5893 solver.cpp:371]     Train net output #0: loss = 1.11808 (* 1 = 1.11808 loss)
I0628 21:30:05.082315  5893 sgd_solver.cpp:137] Iteration 29900, lr = 0.00813125, m = 0.9
I0628 21:30:23.321223  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_30000.caffemodel
I0628 21:30:23.347889  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_30000.solverstate
I0628 21:30:23.352488  5893 solver.cpp:401] Sparsity after update:
I0628 21:30:23.354966  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:30:23.354975  5893 net.cpp:2170] conv1a_param_0(0.15) 
I0628 21:30:23.354984  5893 net.cpp:2170] conv1b_param_0(0.3) 
I0628 21:30:23.354985  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:30:23.354987  5893 net.cpp:2170] res2a_branch2a_param_0(0.3) 
I0628 21:30:23.354990  5893 net.cpp:2170] res2a_branch2b_param_0(0.3) 
I0628 21:30:23.354995  5893 net.cpp:2170] res3a_branch2a_param_0(0.3) 
I0628 21:30:23.354997  5893 net.cpp:2170] res3a_branch2b_param_0(0.3) 
I0628 21:30:23.355000  5893 net.cpp:2170] res4a_branch2a_param_0(0.3) 
I0628 21:30:23.355003  5893 net.cpp:2170] res4a_branch2b_param_0(0.3) 
I0628 21:30:23.355015  5893 net.cpp:2170] res5a_branch2a_param_0(0.3) 
I0628 21:30:23.355022  5893 net.cpp:2170] res5a_branch2b_param_0(0.3) 
I0628 21:30:23.355026  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (706062/2.86678e+06) 0.246
I0628 21:30:23.355037  5893 solver.cpp:545] Iteration 30000, Testing net (#0)
I0628 21:30:47.584971  5888 data_reader.cpp:262] Starting prefetch of epoch 30
I0628 21:30:47.647227  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57244
I0628 21:30:47.647251  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.805921
I0628 21:30:47.647258  5893 solver.cpp:630]     Test net output #2: loss = 1.84854 (* 1 = 1.84854 loss)
I0628 21:30:47.647279  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2912s
I0628 21:30:47.832382  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.31
I0628 21:30:48.176086  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:30:48.177556  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:30:48.178236  5893 solver.cpp:349] Iteration 30000 (2.3205 iter/s, 43.0942s/100 iter), loss = 1.53992
I0628 21:30:48.178254  5893 solver.cpp:371]     Train net output #0: loss = 1.63472 (* 1 = 1.63472 loss)
I0628 21:30:48.178259  5893 sgd_solver.cpp:137] Iteration 30000, lr = 0.008125, m = 0.9
I0628 21:30:52.851707  5875 data_reader.cpp:262] Starting prefetch of epoch 6
I0628 21:31:06.627279  5893 solver.cpp:349] Iteration 30100 (5.42057 iter/s, 18.4482s/100 iter), loss = 1.46249
I0628 21:31:06.627302  5893 solver.cpp:371]     Train net output #0: loss = 1.30739 (* 1 = 1.30739 loss)
I0628 21:31:06.627306  5893 sgd_solver.cpp:137] Iteration 30100, lr = 0.00811875, m = 0.9
I0628 21:31:25.043190  5893 solver.cpp:349] Iteration 30200 (5.43033 iter/s, 18.4151s/100 iter), loss = 1.42416
I0628 21:31:25.043267  5893 solver.cpp:371]     Train net output #0: loss = 1.25867 (* 1 = 1.25867 loss)
I0628 21:31:25.043272  5893 sgd_solver.cpp:137] Iteration 30200, lr = 0.0081125, m = 0.9
I0628 21:31:43.458412  5893 solver.cpp:349] Iteration 30300 (5.43055 iter/s, 18.4144s/100 iter), loss = 1.39283
I0628 21:31:43.458436  5893 solver.cpp:371]     Train net output #0: loss = 1.46449 (* 1 = 1.46449 loss)
I0628 21:31:43.458441  5893 sgd_solver.cpp:137] Iteration 30300, lr = 0.00810625, m = 0.9
I0628 21:32:01.866402  5893 solver.cpp:349] Iteration 30400 (5.43267 iter/s, 18.4072s/100 iter), loss = 1.31865
I0628 21:32:01.866490  5893 solver.cpp:371]     Train net output #0: loss = 1.20302 (* 1 = 1.20302 loss)
I0628 21:32:01.866495  5893 sgd_solver.cpp:137] Iteration 30400, lr = 0.0081, m = 0.9
I0628 21:32:20.269080  5893 solver.cpp:349] Iteration 30500 (5.43425 iter/s, 18.4018s/100 iter), loss = 1.14536
I0628 21:32:20.269105  5893 solver.cpp:371]     Train net output #0: loss = 1.26112 (* 1 = 1.26112 loss)
I0628 21:32:20.269109  5893 sgd_solver.cpp:137] Iteration 30500, lr = 0.00809375, m = 0.9
I0628 21:32:38.695653  5893 solver.cpp:349] Iteration 30600 (5.42719 iter/s, 18.4257s/100 iter), loss = 1.53599
I0628 21:32:38.695755  5893 solver.cpp:371]     Train net output #0: loss = 1.44626 (* 1 = 1.44626 loss)
I0628 21:32:38.695761  5893 sgd_solver.cpp:137] Iteration 30600, lr = 0.0080875, m = 0.9
I0628 21:32:57.110659  5893 solver.cpp:349] Iteration 30700 (5.43062 iter/s, 18.4141s/100 iter), loss = 1.32637
I0628 21:32:57.110682  5893 solver.cpp:371]     Train net output #0: loss = 1.19554 (* 1 = 1.19554 loss)
I0628 21:32:57.110687  5893 sgd_solver.cpp:137] Iteration 30700, lr = 0.00808125, m = 0.9
I0628 21:33:15.537374  5893 solver.cpp:349] Iteration 30800 (5.42715 iter/s, 18.4259s/100 iter), loss = 1.54922
I0628 21:33:15.537474  5893 solver.cpp:371]     Train net output #0: loss = 1.47733 (* 1 = 1.47733 loss)
I0628 21:33:15.537482  5893 sgd_solver.cpp:137] Iteration 30800, lr = 0.008075, m = 0.9
I0628 21:33:33.979979  5893 solver.cpp:349] Iteration 30900 (5.4225 iter/s, 18.4417s/100 iter), loss = 1.48348
I0628 21:33:33.980001  5893 solver.cpp:371]     Train net output #0: loss = 1.38575 (* 1 = 1.38575 loss)
I0628 21:33:33.980005  5893 sgd_solver.cpp:137] Iteration 30900, lr = 0.00806875, m = 0.9
I0628 21:33:52.223661  5893 solver.cpp:401] Sparsity after update:
I0628 21:33:52.228832  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:33:52.228840  5893 net.cpp:2170] conv1a_param_0(0.155) 
I0628 21:33:52.228847  5893 net.cpp:2170] conv1b_param_0(0.31) 
I0628 21:33:52.228848  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:33:52.228850  5893 net.cpp:2170] res2a_branch2a_param_0(0.31) 
I0628 21:33:52.228852  5893 net.cpp:2170] res2a_branch2b_param_0(0.31) 
I0628 21:33:52.228854  5893 net.cpp:2170] res3a_branch2a_param_0(0.31) 
I0628 21:33:52.228857  5893 net.cpp:2170] res3a_branch2b_param_0(0.31) 
I0628 21:33:52.228858  5893 net.cpp:2170] res4a_branch2a_param_0(0.31) 
I0628 21:33:52.228860  5893 net.cpp:2170] res4a_branch2b_param_0(0.31) 
I0628 21:33:52.228863  5893 net.cpp:2170] res5a_branch2a_param_0(0.31) 
I0628 21:33:52.228863  5893 net.cpp:2170] res5a_branch2b_param_0(0.31) 
I0628 21:33:52.228865  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (729601/2.86678e+06) 0.255
I0628 21:33:52.228873  5893 solver.cpp:545] Iteration 31000, Testing net (#0)
I0628 21:33:52.937428  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 21:34:16.654569  5888 data_reader.cpp:262] Starting prefetch of epoch 31
I0628 21:34:16.716603  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56908
I0628 21:34:16.716629  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.804321
I0628 21:34:16.716634  5893 solver.cpp:630]     Test net output #2: loss = 1.86355 (* 1 = 1.86355 loss)
I0628 21:34:16.716650  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4867s
I0628 21:34:16.901507  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.32
I0628 21:34:17.263056  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:34:17.264536  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:34:17.265214  5893 solver.cpp:349] Iteration 31000 (2.31036 iter/s, 43.2833s/100 iter), loss = 1.26953
I0628 21:34:17.265231  5893 solver.cpp:371]     Train net output #0: loss = 1.22295 (* 1 = 1.22295 loss)
I0628 21:34:17.265236  5893 sgd_solver.cpp:137] Iteration 31000, lr = 0.0080625, m = 0.9
I0628 21:34:35.684309  5893 solver.cpp:349] Iteration 31100 (5.4294 iter/s, 18.4182s/100 iter), loss = 1.645
I0628 21:34:35.684424  5893 solver.cpp:371]     Train net output #0: loss = 1.73691 (* 1 = 1.73691 loss)
I0628 21:34:35.684432  5893 sgd_solver.cpp:137] Iteration 31100, lr = 0.00805625, m = 0.9
I0628 21:34:54.092564  5893 solver.cpp:349] Iteration 31200 (5.43263 iter/s, 18.4073s/100 iter), loss = 1.32724
I0628 21:34:54.092586  5893 solver.cpp:371]     Train net output #0: loss = 1.28115 (* 1 = 1.28115 loss)
I0628 21:34:54.092591  5893 sgd_solver.cpp:137] Iteration 31200, lr = 0.00805, m = 0.9
I0628 21:35:12.511128  5893 solver.cpp:349] Iteration 31300 (5.42956 iter/s, 18.4177s/100 iter), loss = 1.25527
I0628 21:35:12.511222  5893 solver.cpp:371]     Train net output #0: loss = 1.24324 (* 1 = 1.24324 loss)
I0628 21:35:12.511226  5893 sgd_solver.cpp:137] Iteration 31300, lr = 0.00804375, m = 0.9
I0628 21:35:30.924820  5893 solver.cpp:349] Iteration 31400 (5.43102 iter/s, 18.4127s/100 iter), loss = 1.27949
I0628 21:35:30.924844  5893 solver.cpp:371]     Train net output #0: loss = 1.03845 (* 1 = 1.03845 loss)
I0628 21:35:30.924846  5893 sgd_solver.cpp:137] Iteration 31400, lr = 0.0080375, m = 0.9
I0628 21:35:49.363935  5893 solver.cpp:349] Iteration 31500 (5.42351 iter/s, 18.4382s/100 iter), loss = 1.47922
I0628 21:35:49.364038  5893 solver.cpp:371]     Train net output #0: loss = 1.53649 (* 1 = 1.53649 loss)
I0628 21:35:49.364045  5893 sgd_solver.cpp:137] Iteration 31500, lr = 0.00803125, m = 0.9
I0628 21:36:07.813983  5893 solver.cpp:349] Iteration 31600 (5.42033 iter/s, 18.4491s/100 iter), loss = 1.18196
I0628 21:36:07.814007  5893 solver.cpp:371]     Train net output #0: loss = 1.19871 (* 1 = 1.19871 loss)
I0628 21:36:07.814010  5893 sgd_solver.cpp:137] Iteration 31600, lr = 0.008025, m = 0.9
I0628 21:36:26.241281  5893 solver.cpp:349] Iteration 31700 (5.427 iter/s, 18.4264s/100 iter), loss = 1.62841
I0628 21:36:26.241384  5893 solver.cpp:371]     Train net output #0: loss = 1.70397 (* 1 = 1.70397 loss)
I0628 21:36:26.241390  5893 sgd_solver.cpp:137] Iteration 31700, lr = 0.00801875, m = 0.9
I0628 21:36:44.707578  5893 solver.cpp:349] Iteration 31800 (5.41556 iter/s, 18.4653s/100 iter), loss = 1.2471
I0628 21:36:44.707602  5893 solver.cpp:371]     Train net output #0: loss = 1.3926 (* 1 = 1.3926 loss)
I0628 21:36:44.707605  5893 sgd_solver.cpp:137] Iteration 31800, lr = 0.0080125, m = 0.9
I0628 21:37:03.151109  5893 solver.cpp:349] Iteration 31900 (5.42222 iter/s, 18.4426s/100 iter), loss = 1.41714
I0628 21:37:03.151185  5893 solver.cpp:371]     Train net output #0: loss = 1.6008 (* 1 = 1.6008 loss)
I0628 21:37:03.151188  5893 sgd_solver.cpp:137] Iteration 31900, lr = 0.00800625, m = 0.9
I0628 21:37:21.398129  5893 solver.cpp:401] Sparsity after update:
I0628 21:37:21.403385  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:37:21.403393  5893 net.cpp:2170] conv1a_param_0(0.16) 
I0628 21:37:21.403398  5893 net.cpp:2170] conv1b_param_0(0.32) 
I0628 21:37:21.403401  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:37:21.403403  5893 net.cpp:2170] res2a_branch2a_param_0(0.32) 
I0628 21:37:21.403405  5893 net.cpp:2170] res2a_branch2b_param_0(0.32) 
I0628 21:37:21.403408  5893 net.cpp:2170] res3a_branch2a_param_0(0.32) 
I0628 21:37:21.403409  5893 net.cpp:2170] res3a_branch2b_param_0(0.32) 
I0628 21:37:21.403410  5893 net.cpp:2170] res4a_branch2a_param_0(0.32) 
I0628 21:37:21.403412  5893 net.cpp:2170] res4a_branch2b_param_0(0.32) 
I0628 21:37:21.403414  5893 net.cpp:2170] res5a_branch2a_param_0(0.32) 
I0628 21:37:21.403416  5893 net.cpp:2170] res5a_branch2b_param_0(0.32) 
I0628 21:37:21.403419  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (753137/2.86678e+06) 0.263
I0628 21:37:21.403426  5893 solver.cpp:545] Iteration 32000, Testing net (#0)
I0628 21:37:45.667131  5888 data_reader.cpp:262] Starting prefetch of epoch 32
I0628 21:37:45.729337  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5678
I0628 21:37:45.729362  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80384
I0628 21:37:45.729369  5893 solver.cpp:630]     Test net output #2: loss = 1.87469 (* 1 = 1.87469 loss)
I0628 21:37:45.729388  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3248s
I0628 21:37:45.913419  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.33
I0628 21:37:46.274055  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:37:46.275523  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:37:46.276202  5893 solver.cpp:349] Iteration 32000 (2.31895 iter/s, 43.1229s/100 iter), loss = 1.2903
I0628 21:37:46.276219  5893 solver.cpp:371]     Train net output #0: loss = 1.33676 (* 1 = 1.33676 loss)
I0628 21:37:46.276227  5893 sgd_solver.cpp:137] Iteration 32000, lr = 0.008, m = 0.9
I0628 21:38:04.694947  5893 solver.cpp:349] Iteration 32100 (5.42952 iter/s, 18.4178s/100 iter), loss = 1.4034
I0628 21:38:04.694970  5893 solver.cpp:371]     Train net output #0: loss = 1.27798 (* 1 = 1.27798 loss)
I0628 21:38:04.694974  5893 sgd_solver.cpp:137] Iteration 32100, lr = 0.00799375, m = 0.9
I0628 21:38:23.129211  5893 solver.cpp:349] Iteration 32200 (5.42495 iter/s, 18.4333s/100 iter), loss = 1.58874
I0628 21:38:23.129310  5893 solver.cpp:371]     Train net output #0: loss = 1.80275 (* 1 = 1.80275 loss)
I0628 21:38:23.129317  5893 sgd_solver.cpp:137] Iteration 32200, lr = 0.0079875, m = 0.9
I0628 21:38:41.554293  5893 solver.cpp:349] Iteration 32300 (5.42768 iter/s, 18.4241s/100 iter), loss = 1.32144
I0628 21:38:41.554317  5893 solver.cpp:371]     Train net output #0: loss = 1.40755 (* 1 = 1.40755 loss)
I0628 21:38:41.554322  5893 sgd_solver.cpp:137] Iteration 32300, lr = 0.00798125, m = 0.9
I0628 21:38:59.996753  5893 solver.cpp:349] Iteration 32400 (5.42255 iter/s, 18.4415s/100 iter), loss = 1.27295
I0628 21:38:59.996861  5893 solver.cpp:371]     Train net output #0: loss = 1.27244 (* 1 = 1.27244 loss)
I0628 21:38:59.996870  5893 sgd_solver.cpp:137] Iteration 32400, lr = 0.007975, m = 0.9
I0628 21:39:18.440376  5893 solver.cpp:349] Iteration 32500 (5.42223 iter/s, 18.4426s/100 iter), loss = 1.54821
I0628 21:39:18.440398  5893 solver.cpp:371]     Train net output #0: loss = 1.42996 (* 1 = 1.42996 loss)
I0628 21:39:18.440402  5893 sgd_solver.cpp:137] Iteration 32500, lr = 0.00796875, m = 0.9
I0628 21:39:36.870479  5893 solver.cpp:349] Iteration 32600 (5.42618 iter/s, 18.4292s/100 iter), loss = 1.58609
I0628 21:39:36.870563  5893 solver.cpp:371]     Train net output #0: loss = 1.8447 (* 1 = 1.8447 loss)
I0628 21:39:36.870570  5893 sgd_solver.cpp:137] Iteration 32600, lr = 0.0079625, m = 0.9
I0628 21:39:55.292150  5893 solver.cpp:349] Iteration 32700 (5.42869 iter/s, 18.4207s/100 iter), loss = 1.37582
I0628 21:39:55.292173  5893 solver.cpp:371]     Train net output #0: loss = 1.21829 (* 1 = 1.21829 loss)
I0628 21:39:55.292177  5893 sgd_solver.cpp:137] Iteration 32700, lr = 0.00795625, m = 0.9
I0628 21:40:13.769955  5893 solver.cpp:349] Iteration 32800 (5.41218 iter/s, 18.4768s/100 iter), loss = 1.48497
I0628 21:40:13.770059  5893 solver.cpp:371]     Train net output #0: loss = 1.48117 (* 1 = 1.48117 loss)
I0628 21:40:13.770066  5893 sgd_solver.cpp:137] Iteration 32800, lr = 0.00795, m = 0.9
I0628 21:40:32.205183  5893 solver.cpp:349] Iteration 32900 (5.42471 iter/s, 18.4342s/100 iter), loss = 1.46406
I0628 21:40:32.205207  5893 solver.cpp:371]     Train net output #0: loss = 1.48293 (* 1 = 1.48293 loss)
I0628 21:40:32.205211  5893 sgd_solver.cpp:137] Iteration 32900, lr = 0.00794375, m = 0.9
I0628 21:40:50.473819  5893 solver.cpp:401] Sparsity after update:
I0628 21:40:50.479028  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:40:50.479037  5893 net.cpp:2170] conv1a_param_0(0.165) 
I0628 21:40:50.479043  5893 net.cpp:2170] conv1b_param_0(0.33) 
I0628 21:40:50.479044  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:40:50.479046  5893 net.cpp:2170] res2a_branch2a_param_0(0.33) 
I0628 21:40:50.479048  5893 net.cpp:2170] res2a_branch2b_param_0(0.33) 
I0628 21:40:50.479050  5893 net.cpp:2170] res3a_branch2a_param_0(0.33) 
I0628 21:40:50.479053  5893 net.cpp:2170] res3a_branch2b_param_0(0.33) 
I0628 21:40:50.479054  5893 net.cpp:2170] res4a_branch2a_param_0(0.33) 
I0628 21:40:50.479056  5893 net.cpp:2170] res4a_branch2b_param_0(0.33) 
I0628 21:40:50.479058  5893 net.cpp:2170] res5a_branch2a_param_0(0.33) 
I0628 21:40:50.479060  5893 net.cpp:2170] res5a_branch2b_param_0(0.33) 
I0628 21:40:50.479063  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (776672/2.86678e+06) 0.271
I0628 21:40:50.479069  5893 solver.cpp:545] Iteration 33000, Testing net (#0)
I0628 21:41:14.942349  5888 data_reader.cpp:262] Starting prefetch of epoch 33
I0628 21:41:15.009729  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57884
I0628 21:41:15.009752  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80812
I0628 21:41:15.009757  5893 solver.cpp:630]     Test net output #2: loss = 1.84103 (* 1 = 1.84103 loss)
I0628 21:41:15.009771  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5295s
I0628 21:41:15.193727  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.34
I0628 21:41:15.565564  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:41:15.567039  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:41:15.567720  5893 solver.cpp:349] Iteration 33000 (2.30626 iter/s, 43.3603s/100 iter), loss = 1.51407
I0628 21:41:15.567739  5893 solver.cpp:371]     Train net output #0: loss = 1.44134 (* 1 = 1.44134 loss)
I0628 21:41:15.567744  5893 sgd_solver.cpp:137] Iteration 33000, lr = 0.0079375, m = 0.9
I0628 21:41:33.995844  5893 solver.cpp:349] Iteration 33100 (5.42677 iter/s, 18.4272s/100 iter), loss = 1.33903
I0628 21:41:33.995964  5893 solver.cpp:371]     Train net output #0: loss = 1.19146 (* 1 = 1.19146 loss)
I0628 21:41:33.995972  5893 sgd_solver.cpp:137] Iteration 33100, lr = 0.00793125, m = 0.9
I0628 21:41:52.429234  5893 solver.cpp:349] Iteration 33200 (5.42526 iter/s, 18.4323s/100 iter), loss = 1.78462
I0628 21:41:52.429258  5893 solver.cpp:371]     Train net output #0: loss = 1.78075 (* 1 = 1.78075 loss)
I0628 21:41:52.429262  5893 sgd_solver.cpp:137] Iteration 33200, lr = 0.007925, m = 0.9
I0628 21:42:10.874951  5893 solver.cpp:349] Iteration 33300 (5.4216 iter/s, 18.4447s/100 iter), loss = 1.68918
I0628 21:42:10.875056  5893 solver.cpp:371]     Train net output #0: loss = 1.69489 (* 1 = 1.69489 loss)
I0628 21:42:10.875063  5893 sgd_solver.cpp:137] Iteration 33300, lr = 0.00791875, m = 0.9
I0628 21:42:29.314692  5893 solver.cpp:349] Iteration 33400 (5.42339 iter/s, 18.4387s/100 iter), loss = 1.6059
I0628 21:42:29.314714  5893 solver.cpp:371]     Train net output #0: loss = 1.82021 (* 1 = 1.82021 loss)
I0628 21:42:29.314718  5893 sgd_solver.cpp:137] Iteration 33400, lr = 0.0079125, m = 0.9
I0628 21:42:47.738736  5893 solver.cpp:349] Iteration 33500 (5.42798 iter/s, 18.423s/100 iter), loss = 1.29302
I0628 21:42:47.738836  5893 solver.cpp:371]     Train net output #0: loss = 1.3392 (* 1 = 1.3392 loss)
I0628 21:42:47.738842  5893 sgd_solver.cpp:137] Iteration 33500, lr = 0.00790625, m = 0.9
I0628 21:43:06.183944  5893 solver.cpp:349] Iteration 33600 (5.42178 iter/s, 18.4441s/100 iter), loss = 1.31012
I0628 21:43:06.183967  5893 solver.cpp:371]     Train net output #0: loss = 1.20099 (* 1 = 1.20099 loss)
I0628 21:43:06.183971  5893 sgd_solver.cpp:137] Iteration 33600, lr = 0.0079, m = 0.9
I0628 21:43:24.592824  5893 solver.cpp:349] Iteration 33700 (5.43246 iter/s, 18.4079s/100 iter), loss = 1.53563
I0628 21:43:24.592911  5893 solver.cpp:371]     Train net output #0: loss = 1.55467 (* 1 = 1.55467 loss)
I0628 21:43:24.592917  5893 sgd_solver.cpp:137] Iteration 33700, lr = 0.00789375, m = 0.9
I0628 21:43:43.032001  5893 solver.cpp:349] Iteration 33800 (5.42355 iter/s, 18.4381s/100 iter), loss = 1.33265
I0628 21:43:43.032021  5893 solver.cpp:371]     Train net output #0: loss = 1.3748 (* 1 = 1.3748 loss)
I0628 21:43:43.032024  5893 sgd_solver.cpp:137] Iteration 33800, lr = 0.0078875, m = 0.9
I0628 21:44:01.481876  5893 solver.cpp:349] Iteration 33900 (5.42039 iter/s, 18.4489s/100 iter), loss = 1.3036
I0628 21:44:01.481988  5893 solver.cpp:371]     Train net output #0: loss = 1.10362 (* 1 = 1.10362 loss)
I0628 21:44:01.481995  5893 sgd_solver.cpp:137] Iteration 33900, lr = 0.00788125, m = 0.9
I0628 21:44:19.706018  5893 solver.cpp:401] Sparsity after update:
I0628 21:44:19.710952  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:44:19.710959  5893 net.cpp:2170] conv1a_param_0(0.17) 
I0628 21:44:19.710965  5893 net.cpp:2170] conv1b_param_0(0.34) 
I0628 21:44:19.710968  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:44:19.710969  5893 net.cpp:2170] res2a_branch2a_param_0(0.34) 
I0628 21:44:19.710974  5893 net.cpp:2170] res2a_branch2b_param_0(0.34) 
I0628 21:44:19.710978  5893 net.cpp:2170] res3a_branch2a_param_0(0.34) 
I0628 21:44:19.710983  5893 net.cpp:2170] res3a_branch2b_param_0(0.34) 
I0628 21:44:19.710985  5893 net.cpp:2170] res4a_branch2a_param_0(0.34) 
I0628 21:44:19.710988  5893 net.cpp:2170] res4a_branch2b_param_0(0.34) 
I0628 21:44:19.710988  5893 net.cpp:2170] res5a_branch2a_param_0(0.34) 
I0628 21:44:19.710990  5893 net.cpp:2170] res5a_branch2b_param_0(0.34) 
I0628 21:44:19.710992  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (800208/2.86678e+06) 0.279
I0628 21:44:19.711000  5893 solver.cpp:545] Iteration 34000, Testing net (#0)
I0628 21:44:43.981452  5888 data_reader.cpp:262] Starting prefetch of epoch 34
I0628 21:44:44.043794  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57716
I0628 21:44:44.043817  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809281
I0628 21:44:44.043823  5893 solver.cpp:630]     Test net output #2: loss = 1.83155 (* 1 = 1.83155 loss)
I0628 21:44:44.043848  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3315s
I0628 21:44:44.230754  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.35
I0628 21:44:44.596421  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:44:44.597889  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:44:44.598567  5893 solver.cpp:349] Iteration 34000 (2.31942 iter/s, 43.1143s/100 iter), loss = 1.27411
I0628 21:44:44.598585  5893 solver.cpp:371]     Train net output #0: loss = 1.21665 (* 1 = 1.21665 loss)
I0628 21:44:44.598593  5893 sgd_solver.cpp:137] Iteration 34000, lr = 0.007875, m = 0.9
I0628 21:45:03.032771  5893 solver.cpp:349] Iteration 34100 (5.425 iter/s, 18.4332s/100 iter), loss = 1.13656
I0628 21:45:03.032793  5893 solver.cpp:371]     Train net output #0: loss = 1.14418 (* 1 = 1.14418 loss)
I0628 21:45:03.032799  5893 sgd_solver.cpp:137] Iteration 34100, lr = 0.00786875, m = 0.9
I0628 21:45:21.459852  5893 solver.cpp:349] Iteration 34200 (5.4271 iter/s, 18.4261s/100 iter), loss = 1.60615
I0628 21:45:21.459952  5893 solver.cpp:371]     Train net output #0: loss = 1.57437 (* 1 = 1.57437 loss)
I0628 21:45:21.459959  5893 sgd_solver.cpp:137] Iteration 34200, lr = 0.0078625, m = 0.9
I0628 21:45:39.869673  5893 solver.cpp:349] Iteration 34300 (5.43221 iter/s, 18.4087s/100 iter), loss = 1.85869
I0628 21:45:39.869696  5893 solver.cpp:371]     Train net output #0: loss = 1.81384 (* 1 = 1.81384 loss)
I0628 21:45:39.869700  5893 sgd_solver.cpp:137] Iteration 34300, lr = 0.00785625, m = 0.9
I0628 21:45:58.282487  5893 solver.cpp:349] Iteration 34400 (5.43131 iter/s, 18.4118s/100 iter), loss = 1.26746
I0628 21:45:58.282591  5893 solver.cpp:371]     Train net output #0: loss = 1.4592 (* 1 = 1.4592 loss)
I0628 21:45:58.282598  5893 sgd_solver.cpp:137] Iteration 34400, lr = 0.00785, m = 0.9
I0628 21:46:16.699306  5893 solver.cpp:349] Iteration 34500 (5.43015 iter/s, 18.4157s/100 iter), loss = 1.50923
I0628 21:46:16.699329  5893 solver.cpp:371]     Train net output #0: loss = 1.70818 (* 1 = 1.70818 loss)
I0628 21:46:16.699333  5893 sgd_solver.cpp:137] Iteration 34500, lr = 0.00784375, m = 0.9
I0628 21:46:35.154739  5893 solver.cpp:349] Iteration 34600 (5.41877 iter/s, 18.4544s/100 iter), loss = 1.449
I0628 21:46:35.154848  5893 solver.cpp:371]     Train net output #0: loss = 1.56723 (* 1 = 1.56723 loss)
I0628 21:46:35.154858  5893 sgd_solver.cpp:137] Iteration 34600, lr = 0.0078375, m = 0.9
I0628 21:46:53.608675  5893 solver.cpp:349] Iteration 34700 (5.41923 iter/s, 18.4528s/100 iter), loss = 1.47651
I0628 21:46:53.608698  5893 solver.cpp:371]     Train net output #0: loss = 1.29165 (* 1 = 1.29165 loss)
I0628 21:46:53.608702  5893 sgd_solver.cpp:137] Iteration 34700, lr = 0.00783125, m = 0.9
I0628 21:47:12.051019  5893 solver.cpp:349] Iteration 34800 (5.42261 iter/s, 18.4413s/100 iter), loss = 1.29019
I0628 21:47:12.051079  5893 solver.cpp:371]     Train net output #0: loss = 1.12404 (* 1 = 1.12404 loss)
I0628 21:47:12.051085  5893 sgd_solver.cpp:137] Iteration 34800, lr = 0.007825, m = 0.9
I0628 21:47:30.500728  5893 solver.cpp:349] Iteration 34900 (5.42046 iter/s, 18.4486s/100 iter), loss = 1.23361
I0628 21:47:30.500751  5893 solver.cpp:371]     Train net output #0: loss = 1.16496 (* 1 = 1.16496 loss)
I0628 21:47:30.500754  5893 sgd_solver.cpp:137] Iteration 34900, lr = 0.00781875, m = 0.9
I0628 21:47:48.762689  5893 solver.cpp:401] Sparsity after update:
I0628 21:47:48.767557  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:47:48.767565  5893 net.cpp:2170] conv1a_param_0(0.175) 
I0628 21:47:48.767571  5893 net.cpp:2170] conv1b_param_0(0.35) 
I0628 21:47:48.767573  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:47:48.767575  5893 net.cpp:2170] res2a_branch2a_param_0(0.35) 
I0628 21:47:48.767577  5893 net.cpp:2170] res2a_branch2b_param_0(0.35) 
I0628 21:47:48.767580  5893 net.cpp:2170] res3a_branch2a_param_0(0.35) 
I0628 21:47:48.767581  5893 net.cpp:2170] res3a_branch2b_param_0(0.35) 
I0628 21:47:48.767583  5893 net.cpp:2170] res4a_branch2a_param_0(0.35) 
I0628 21:47:48.767586  5893 net.cpp:2170] res4a_branch2b_param_0(0.35) 
I0628 21:47:48.767588  5893 net.cpp:2170] res5a_branch2a_param_0(0.35) 
I0628 21:47:48.767590  5893 net.cpp:2170] res5a_branch2b_param_0(0.35) 
I0628 21:47:48.767592  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (823747/2.86678e+06) 0.287
I0628 21:47:48.767601  5893 solver.cpp:545] Iteration 35000, Testing net (#0)
I0628 21:48:13.555505  5888 data_reader.cpp:262] Starting prefetch of epoch 35
I0628 21:48:13.617507  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5738
I0628 21:48:13.617532  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809401
I0628 21:48:13.617537  5893 solver.cpp:630]     Test net output #2: loss = 1.85355 (* 1 = 1.85355 loss)
I0628 21:48:13.617558  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.8486s
I0628 21:48:13.802789  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.36
I0628 21:48:14.176494  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:48:14.177970  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:48:14.178647  5893 solver.cpp:349] Iteration 35000 (2.28962 iter/s, 43.6755s/100 iter), loss = 1.39553
I0628 21:48:14.178665  5893 solver.cpp:371]     Train net output #0: loss = 1.3073 (* 1 = 1.3073 loss)
I0628 21:48:14.178671  5893 sgd_solver.cpp:137] Iteration 35000, lr = 0.0078125, m = 0.9
I0628 21:48:19.693423  5875 data_reader.cpp:262] Starting prefetch of epoch 7
I0628 21:48:32.600026  5893 solver.cpp:349] Iteration 35100 (5.42879 iter/s, 18.4203s/100 iter), loss = 1.23589
I0628 21:48:32.600049  5893 solver.cpp:371]     Train net output #0: loss = 1.26875 (* 1 = 1.26875 loss)
I0628 21:48:32.600054  5893 sgd_solver.cpp:137] Iteration 35100, lr = 0.00780625, m = 0.9
I0628 21:48:51.051559  5893 solver.cpp:349] Iteration 35200 (5.41992 iter/s, 18.4505s/100 iter), loss = 1.26238
I0628 21:48:51.051669  5893 solver.cpp:371]     Train net output #0: loss = 1.34393 (* 1 = 1.34393 loss)
I0628 21:48:51.051676  5893 sgd_solver.cpp:137] Iteration 35200, lr = 0.0078, m = 0.9
I0628 21:49:09.518379  5893 solver.cpp:349] Iteration 35300 (5.41546 iter/s, 18.4657s/100 iter), loss = 1.2888
I0628 21:49:09.518402  5893 solver.cpp:371]     Train net output #0: loss = 1.55707 (* 1 = 1.55707 loss)
I0628 21:49:09.518409  5893 sgd_solver.cpp:137] Iteration 35300, lr = 0.00779375, m = 0.9
I0628 21:49:27.949604  5893 solver.cpp:349] Iteration 35400 (5.42589 iter/s, 18.4301s/100 iter), loss = 1.44113
I0628 21:49:27.949687  5893 solver.cpp:371]     Train net output #0: loss = 1.55668 (* 1 = 1.55668 loss)
I0628 21:49:27.949692  5893 sgd_solver.cpp:137] Iteration 35400, lr = 0.0077875, m = 0.9
I0628 21:49:46.395319  5893 solver.cpp:349] Iteration 35500 (5.42165 iter/s, 18.4446s/100 iter), loss = 1.45147
I0628 21:49:46.395341  5893 solver.cpp:371]     Train net output #0: loss = 1.46407 (* 1 = 1.46407 loss)
I0628 21:49:46.395344  5893 sgd_solver.cpp:137] Iteration 35500, lr = 0.00778125, m = 0.9
I0628 21:50:04.830325  5893 solver.cpp:349] Iteration 35600 (5.42478 iter/s, 18.4339s/100 iter), loss = 1.13657
I0628 21:50:04.830443  5893 solver.cpp:371]     Train net output #0: loss = 1.18749 (* 1 = 1.18749 loss)
I0628 21:50:04.830451  5893 sgd_solver.cpp:137] Iteration 35600, lr = 0.007775, m = 0.9
I0628 21:50:23.261157  5893 solver.cpp:349] Iteration 35700 (5.42604 iter/s, 18.4296s/100 iter), loss = 1.23661
I0628 21:50:23.261180  5893 solver.cpp:371]     Train net output #0: loss = 1.16751 (* 1 = 1.16751 loss)
I0628 21:50:23.261184  5893 sgd_solver.cpp:137] Iteration 35700, lr = 0.00776875, m = 0.9
I0628 21:50:41.696673  5893 solver.cpp:349] Iteration 35800 (5.42463 iter/s, 18.4344s/100 iter), loss = 1.17191
I0628 21:50:41.696774  5893 solver.cpp:371]     Train net output #0: loss = 0.801665 (* 1 = 0.801665 loss)
I0628 21:50:41.696780  5893 sgd_solver.cpp:137] Iteration 35800, lr = 0.0077625, m = 0.9
I0628 21:51:00.126802  5893 solver.cpp:349] Iteration 35900 (5.42624 iter/s, 18.429s/100 iter), loss = 1.36849
I0628 21:51:00.126824  5893 solver.cpp:371]     Train net output #0: loss = 1.36242 (* 1 = 1.36242 loss)
I0628 21:51:00.126827  5893 sgd_solver.cpp:137] Iteration 35900, lr = 0.00775625, m = 0.9
I0628 21:51:18.367709  5893 solver.cpp:401] Sparsity after update:
I0628 21:51:18.372975  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:51:18.372987  5893 net.cpp:2170] conv1a_param_0(0.18) 
I0628 21:51:18.372993  5893 net.cpp:2170] conv1b_param_0(0.36) 
I0628 21:51:18.372997  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:51:18.373000  5893 net.cpp:2170] res2a_branch2a_param_0(0.36) 
I0628 21:51:18.373003  5893 net.cpp:2170] res2a_branch2b_param_0(0.36) 
I0628 21:51:18.373006  5893 net.cpp:2170] res3a_branch2a_param_0(0.36) 
I0628 21:51:18.373009  5893 net.cpp:2170] res3a_branch2b_param_0(0.36) 
I0628 21:51:18.373013  5893 net.cpp:2170] res4a_branch2a_param_0(0.36) 
I0628 21:51:18.373015  5893 net.cpp:2170] res4a_branch2b_param_0(0.36) 
I0628 21:51:18.373018  5893 net.cpp:2170] res5a_branch2a_param_0(0.36) 
I0628 21:51:18.373021  5893 net.cpp:2170] res5a_branch2b_param_0(0.36) 
I0628 21:51:18.373025  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (847279/2.86678e+06) 0.296
I0628 21:51:18.373035  5893 solver.cpp:545] Iteration 36000, Testing net (#0)
I0628 21:51:19.245473  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 21:51:42.640947  5888 data_reader.cpp:262] Starting prefetch of epoch 36
I0628 21:51:42.702881  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57964
I0628 21:51:42.702904  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811441
I0628 21:51:42.702909  5893 solver.cpp:630]     Test net output #2: loss = 1.81734 (* 1 = 1.81734 loss)
I0628 21:51:42.702926  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.329s
I0628 21:51:42.887261  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.37
I0628 21:51:43.259588  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:51:43.261061  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:51:43.261744  5893 solver.cpp:349] Iteration 36000 (2.31841 iter/s, 43.133s/100 iter), loss = 1.48643
I0628 21:51:43.261762  5893 solver.cpp:371]     Train net output #0: loss = 0.931596 (* 1 = 0.931596 loss)
I0628 21:51:43.261771  5893 sgd_solver.cpp:137] Iteration 36000, lr = 0.00775, m = 0.9
I0628 21:52:01.711383  5893 solver.cpp:349] Iteration 36100 (5.42024 iter/s, 18.4494s/100 iter), loss = 1.7535
I0628 21:52:01.711505  5893 solver.cpp:371]     Train net output #0: loss = 1.79673 (* 1 = 1.79673 loss)
I0628 21:52:01.711513  5893 sgd_solver.cpp:137] Iteration 36100, lr = 0.00774375, m = 0.9
I0628 21:52:20.146136  5893 solver.cpp:349] Iteration 36200 (5.42465 iter/s, 18.4344s/100 iter), loss = 1.53213
I0628 21:52:20.146158  5893 solver.cpp:371]     Train net output #0: loss = 1.41518 (* 1 = 1.41518 loss)
I0628 21:52:20.146164  5893 sgd_solver.cpp:137] Iteration 36200, lr = 0.0077375, m = 0.9
I0628 21:52:38.577487  5893 solver.cpp:349] Iteration 36300 (5.42563 iter/s, 18.4311s/100 iter), loss = 1.34215
I0628 21:52:38.577591  5893 solver.cpp:371]     Train net output #0: loss = 1.35775 (* 1 = 1.35775 loss)
I0628 21:52:38.577599  5893 sgd_solver.cpp:137] Iteration 36300, lr = 0.00773125, m = 0.9
I0628 21:52:57.015027  5893 solver.cpp:349] Iteration 36400 (5.42383 iter/s, 18.4372s/100 iter), loss = 1.39659
I0628 21:52:57.015048  5893 solver.cpp:371]     Train net output #0: loss = 1.44745 (* 1 = 1.44745 loss)
I0628 21:52:57.015053  5893 sgd_solver.cpp:137] Iteration 36400, lr = 0.007725, m = 0.9
I0628 21:53:15.445709  5893 solver.cpp:349] Iteration 36500 (5.42583 iter/s, 18.4304s/100 iter), loss = 1.59833
I0628 21:53:15.445812  5893 solver.cpp:371]     Train net output #0: loss = 1.56459 (* 1 = 1.56459 loss)
I0628 21:53:15.445819  5893 sgd_solver.cpp:137] Iteration 36500, lr = 0.00771875, m = 0.9
I0628 21:53:33.853240  5893 solver.cpp:349] Iteration 36600 (5.43268 iter/s, 18.4071s/100 iter), loss = 1.26857
I0628 21:53:33.853263  5893 solver.cpp:371]     Train net output #0: loss = 1.2498 (* 1 = 1.2498 loss)
I0628 21:53:33.853267  5893 sgd_solver.cpp:137] Iteration 36600, lr = 0.0077125, m = 0.9
I0628 21:53:52.297220  5893 solver.cpp:349] Iteration 36700 (5.42192 iter/s, 18.4437s/100 iter), loss = 1.51429
I0628 21:53:52.297322  5893 solver.cpp:371]     Train net output #0: loss = 1.71574 (* 1 = 1.71574 loss)
I0628 21:53:52.297327  5893 sgd_solver.cpp:137] Iteration 36700, lr = 0.00770625, m = 0.9
I0628 21:54:10.764899  5893 solver.cpp:349] Iteration 36800 (5.41499 iter/s, 18.4673s/100 iter), loss = 1.37102
I0628 21:54:10.764922  5893 solver.cpp:371]     Train net output #0: loss = 1.25377 (* 1 = 1.25377 loss)
I0628 21:54:10.764926  5893 sgd_solver.cpp:137] Iteration 36800, lr = 0.0077, m = 0.9
I0628 21:54:29.185281  5893 solver.cpp:349] Iteration 36900 (5.42887 iter/s, 18.42s/100 iter), loss = 1.46849
I0628 21:54:29.185385  5893 solver.cpp:371]     Train net output #0: loss = 1.18602 (* 1 = 1.18602 loss)
I0628 21:54:29.185391  5893 sgd_solver.cpp:137] Iteration 36900, lr = 0.00769375, m = 0.9
I0628 21:54:47.436880  5893 solver.cpp:401] Sparsity after update:
I0628 21:54:47.442091  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:54:47.442098  5893 net.cpp:2170] conv1a_param_0(0.185) 
I0628 21:54:47.442106  5893 net.cpp:2170] conv1b_param_0(0.37) 
I0628 21:54:47.442107  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:54:47.442109  5893 net.cpp:2170] res2a_branch2a_param_0(0.37) 
I0628 21:54:47.442111  5893 net.cpp:2170] res2a_branch2b_param_0(0.37) 
I0628 21:54:47.442113  5893 net.cpp:2170] res3a_branch2a_param_0(0.37) 
I0628 21:54:47.442116  5893 net.cpp:2170] res3a_branch2b_param_0(0.37) 
I0628 21:54:47.442116  5893 net.cpp:2170] res4a_branch2a_param_0(0.37) 
I0628 21:54:47.442118  5893 net.cpp:2170] res4a_branch2b_param_0(0.37) 
I0628 21:54:47.442121  5893 net.cpp:2170] res5a_branch2a_param_0(0.37) 
I0628 21:54:47.442122  5893 net.cpp:2170] res5a_branch2b_param_0(0.37) 
I0628 21:54:47.442124  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (870813/2.86678e+06) 0.304
I0628 21:54:47.442131  5893 solver.cpp:545] Iteration 37000, Testing net (#0)
I0628 21:55:11.816035  5888 data_reader.cpp:262] Starting prefetch of epoch 37
I0628 21:55:11.877905  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57284
I0628 21:55:11.877928  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8054
I0628 21:55:11.877933  5893 solver.cpp:630]     Test net output #2: loss = 1.84157 (* 1 = 1.84157 loss)
I0628 21:55:11.877950  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4354s
I0628 21:55:12.066779  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.38
I0628 21:55:12.459012  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:55:12.460484  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:55:12.461163  5893 solver.cpp:349] Iteration 37000 (2.3108 iter/s, 43.275s/100 iter), loss = 1.2615
I0628 21:55:12.461180  5893 solver.cpp:371]     Train net output #0: loss = 1.1251 (* 1 = 1.1251 loss)
I0628 21:55:12.461185  5893 sgd_solver.cpp:137] Iteration 37000, lr = 0.0076875, m = 0.9
I0628 21:55:30.917603  5893 solver.cpp:349] Iteration 37100 (5.41827 iter/s, 18.4561s/100 iter), loss = 1.36811
I0628 21:55:30.917625  5893 solver.cpp:371]     Train net output #0: loss = 1.44223 (* 1 = 1.44223 loss)
I0628 21:55:30.917630  5893 sgd_solver.cpp:137] Iteration 37100, lr = 0.00768125, m = 0.9
I0628 21:55:49.338459  5893 solver.cpp:349] Iteration 37200 (5.42874 iter/s, 18.4205s/100 iter), loss = 1.47226
I0628 21:55:49.338541  5893 solver.cpp:371]     Train net output #0: loss = 1.31569 (* 1 = 1.31569 loss)
I0628 21:55:49.338546  5893 sgd_solver.cpp:137] Iteration 37200, lr = 0.007675, m = 0.9
I0628 21:56:07.772332  5893 solver.cpp:349] Iteration 37300 (5.42493 iter/s, 18.4334s/100 iter), loss = 1.27992
I0628 21:56:07.772352  5893 solver.cpp:371]     Train net output #0: loss = 1.24375 (* 1 = 1.24375 loss)
I0628 21:56:07.772356  5893 sgd_solver.cpp:137] Iteration 37300, lr = 0.00766875, m = 0.9
I0628 21:56:26.210263  5893 solver.cpp:349] Iteration 37400 (5.42371 iter/s, 18.4375s/100 iter), loss = 1.41475
I0628 21:56:26.210307  5893 solver.cpp:371]     Train net output #0: loss = 1.47517 (* 1 = 1.47517 loss)
I0628 21:56:26.210312  5893 sgd_solver.cpp:137] Iteration 37400, lr = 0.0076625, m = 0.9
I0628 21:56:44.651772  5893 solver.cpp:349] Iteration 37500 (5.42263 iter/s, 18.4412s/100 iter), loss = 1.39095
I0628 21:56:44.651798  5893 solver.cpp:371]     Train net output #0: loss = 1.43248 (* 1 = 1.43248 loss)
I0628 21:56:44.651803  5893 sgd_solver.cpp:137] Iteration 37500, lr = 0.00765625, m = 0.9
I0628 21:57:03.088459  5893 solver.cpp:349] Iteration 37600 (5.42404 iter/s, 18.4364s/100 iter), loss = 1.21901
I0628 21:57:03.088532  5893 solver.cpp:371]     Train net output #0: loss = 1.19907 (* 1 = 1.19907 loss)
I0628 21:57:03.088538  5893 sgd_solver.cpp:137] Iteration 37600, lr = 0.00765, m = 0.9
I0628 21:57:21.525077  5893 solver.cpp:349] Iteration 37700 (5.42408 iter/s, 18.4363s/100 iter), loss = 1.57049
I0628 21:57:21.525101  5893 solver.cpp:371]     Train net output #0: loss = 1.51662 (* 1 = 1.51662 loss)
I0628 21:57:21.525106  5893 sgd_solver.cpp:137] Iteration 37700, lr = 0.00764375, m = 0.9
I0628 21:57:39.972774  5893 solver.cpp:349] Iteration 37800 (5.42081 iter/s, 18.4474s/100 iter), loss = 1.36717
I0628 21:57:39.972885  5893 solver.cpp:371]     Train net output #0: loss = 1.42697 (* 1 = 1.42697 loss)
I0628 21:57:39.972894  5893 sgd_solver.cpp:137] Iteration 37800, lr = 0.0076375, m = 0.9
I0628 21:57:58.403157  5893 solver.cpp:349] Iteration 37900 (5.42593 iter/s, 18.43s/100 iter), loss = 1.44035
I0628 21:57:58.403180  5893 solver.cpp:371]     Train net output #0: loss = 1.55303 (* 1 = 1.55303 loss)
I0628 21:57:58.403184  5893 sgd_solver.cpp:137] Iteration 37900, lr = 0.00763125, m = 0.9
I0628 21:58:16.631177  5893 solver.cpp:401] Sparsity after update:
I0628 21:58:16.636430  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 21:58:16.636438  5893 net.cpp:2170] conv1a_param_0(0.19) 
I0628 21:58:16.636446  5893 net.cpp:2170] conv1b_param_0(0.38) 
I0628 21:58:16.636451  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 21:58:16.636454  5893 net.cpp:2170] res2a_branch2a_param_0(0.38) 
I0628 21:58:16.636458  5893 net.cpp:2170] res2a_branch2b_param_0(0.38) 
I0628 21:58:16.636463  5893 net.cpp:2170] res3a_branch2a_param_0(0.38) 
I0628 21:58:16.636466  5893 net.cpp:2170] res3a_branch2b_param_0(0.38) 
I0628 21:58:16.636471  5893 net.cpp:2170] res4a_branch2a_param_0(0.38) 
I0628 21:58:16.636474  5893 net.cpp:2170] res4a_branch2b_param_0(0.38) 
I0628 21:58:16.636478  5893 net.cpp:2170] res5a_branch2a_param_0(0.38) 
I0628 21:58:16.636482  5893 net.cpp:2170] res5a_branch2b_param_0(0.38) 
I0628 21:58:16.636485  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (894355/2.86678e+06) 0.312
I0628 21:58:16.636497  5893 solver.cpp:545] Iteration 38000, Testing net (#0)
I0628 21:58:41.025352  5888 data_reader.cpp:262] Starting prefetch of epoch 38
I0628 21:58:41.106353  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58128
I0628 21:58:41.106374  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.812281
I0628 21:58:41.106379  5893 solver.cpp:630]     Test net output #2: loss = 1.81714 (* 1 = 1.81714 loss)
I0628 21:58:41.106398  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4696s
I0628 21:58:41.290613  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.39
I0628 21:58:41.681200  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 21:58:41.682668  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 21:58:41.683344  5893 solver.cpp:349] Iteration 38000 (2.31056 iter/s, 43.2796s/100 iter), loss = 1.52512
I0628 21:58:41.683362  5893 solver.cpp:371]     Train net output #0: loss = 1.66422 (* 1 = 1.66422 loss)
I0628 21:58:41.683367  5893 sgd_solver.cpp:137] Iteration 38000, lr = 0.007625, m = 0.9
I0628 21:59:00.131542  5893 solver.cpp:349] Iteration 38100 (5.42067 iter/s, 18.4479s/100 iter), loss = 1.43
I0628 21:59:00.131644  5893 solver.cpp:371]     Train net output #0: loss = 1.23404 (* 1 = 1.23404 loss)
I0628 21:59:00.131650  5893 sgd_solver.cpp:137] Iteration 38100, lr = 0.00761875, m = 0.9
I0628 21:59:18.584978  5893 solver.cpp:349] Iteration 38200 (5.41916 iter/s, 18.4531s/100 iter), loss = 1.38134
I0628 21:59:18.585001  5893 solver.cpp:371]     Train net output #0: loss = 1.13832 (* 1 = 1.13832 loss)
I0628 21:59:18.585005  5893 sgd_solver.cpp:137] Iteration 38200, lr = 0.0076125, m = 0.9
I0628 21:59:37.030249  5893 solver.cpp:349] Iteration 38300 (5.42153 iter/s, 18.445s/100 iter), loss = 1.4484
I0628 21:59:37.030333  5893 solver.cpp:371]     Train net output #0: loss = 1.34031 (* 1 = 1.34031 loss)
I0628 21:59:37.030339  5893 sgd_solver.cpp:137] Iteration 38300, lr = 0.00760625, m = 0.9
I0628 21:59:55.459012  5893 solver.cpp:349] Iteration 38400 (5.42641 iter/s, 18.4284s/100 iter), loss = 1.27089
I0628 21:59:55.459036  5893 solver.cpp:371]     Train net output #0: loss = 1.48258 (* 1 = 1.48258 loss)
I0628 21:59:55.459040  5893 sgd_solver.cpp:137] Iteration 38400, lr = 0.0076, m = 0.9
I0628 22:00:13.905763  5893 solver.cpp:349] Iteration 38500 (5.4211 iter/s, 18.4464s/100 iter), loss = 1.28387
I0628 22:00:13.905870  5893 solver.cpp:371]     Train net output #0: loss = 1.29062 (* 1 = 1.29062 loss)
I0628 22:00:13.905879  5893 sgd_solver.cpp:137] Iteration 38500, lr = 0.00759375, m = 0.9
I0628 22:00:32.337110  5893 solver.cpp:349] Iteration 38600 (5.42566 iter/s, 18.4309s/100 iter), loss = 1.28454
I0628 22:00:32.337133  5893 solver.cpp:371]     Train net output #0: loss = 1.40025 (* 1 = 1.40025 loss)
I0628 22:00:32.337139  5893 sgd_solver.cpp:137] Iteration 38600, lr = 0.0075875, m = 0.9
I0628 22:00:50.775787  5893 solver.cpp:349] Iteration 38700 (5.42348 iter/s, 18.4383s/100 iter), loss = 1.30223
I0628 22:00:50.775846  5893 solver.cpp:371]     Train net output #0: loss = 1.37958 (* 1 = 1.37958 loss)
I0628 22:00:50.775853  5893 sgd_solver.cpp:137] Iteration 38700, lr = 0.00758125, m = 0.9
I0628 22:01:09.229528  5893 solver.cpp:349] Iteration 38800 (5.41907 iter/s, 18.4534s/100 iter), loss = 1.37985
I0628 22:01:09.229557  5893 solver.cpp:371]     Train net output #0: loss = 1.35668 (* 1 = 1.35668 loss)
I0628 22:01:09.229562  5893 sgd_solver.cpp:137] Iteration 38800, lr = 0.007575, m = 0.9
I0628 22:01:27.684191  5893 solver.cpp:349] Iteration 38900 (5.41879 iter/s, 18.4543s/100 iter), loss = 1.17316
I0628 22:01:27.684299  5893 solver.cpp:371]     Train net output #0: loss = 1.09306 (* 1 = 1.09306 loss)
I0628 22:01:27.684309  5893 sgd_solver.cpp:137] Iteration 38900, lr = 0.00756875, m = 0.9
I0628 22:01:45.944047  5893 solver.cpp:401] Sparsity after update:
I0628 22:01:45.949267  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:01:45.949275  5893 net.cpp:2170] conv1a_param_0(0.195) 
I0628 22:01:45.949285  5893 net.cpp:2170] conv1b_param_0(0.39) 
I0628 22:01:45.949290  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:01:45.949292  5893 net.cpp:2170] res2a_branch2a_param_0(0.39) 
I0628 22:01:45.949297  5893 net.cpp:2170] res2a_branch2b_param_0(0.39) 
I0628 22:01:45.949301  5893 net.cpp:2170] res3a_branch2a_param_0(0.39) 
I0628 22:01:45.949306  5893 net.cpp:2170] res3a_branch2b_param_0(0.39) 
I0628 22:01:45.949309  5893 net.cpp:2170] res4a_branch2a_param_0(0.39) 
I0628 22:01:45.949313  5893 net.cpp:2170] res4a_branch2b_param_0(0.39) 
I0628 22:01:45.949317  5893 net.cpp:2170] res5a_branch2a_param_0(0.39) 
I0628 22:01:45.949321  5893 net.cpp:2170] res5a_branch2b_param_0(0.39) 
I0628 22:01:45.949326  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (917888/2.86678e+06) 0.32
I0628 22:01:45.949337  5893 solver.cpp:545] Iteration 39000, Testing net (#0)
I0628 22:02:10.269042  5888 data_reader.cpp:262] Starting prefetch of epoch 39
I0628 22:02:10.330833  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57972
I0628 22:02:10.330854  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811841
I0628 22:02:10.330859  5893 solver.cpp:630]     Test net output #2: loss = 1.82112 (* 1 = 1.82112 loss)
I0628 22:02:10.330875  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3812s
I0628 22:02:10.515552  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.4
I0628 22:02:10.914779  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:02:10.916259  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:02:10.916942  5893 solver.cpp:349] Iteration 39000 (2.3131 iter/s, 43.232s/100 iter), loss = 1.43492
I0628 22:02:10.916960  5893 solver.cpp:371]     Train net output #0: loss = 1.30469 (* 1 = 1.30469 loss)
I0628 22:02:10.916967  5893 sgd_solver.cpp:137] Iteration 39000, lr = 0.0075625, m = 0.9
I0628 22:02:29.329097  5893 solver.cpp:349] Iteration 39100 (5.43126 iter/s, 18.4119s/100 iter), loss = 1.54888
I0628 22:02:29.329119  5893 solver.cpp:371]     Train net output #0: loss = 1.52897 (* 1 = 1.52897 loss)
I0628 22:02:29.329123  5893 sgd_solver.cpp:137] Iteration 39100, lr = 0.00755625, m = 0.9
I0628 22:02:47.761901  5893 solver.cpp:349] Iteration 39200 (5.42518 iter/s, 18.4326s/100 iter), loss = 1.32442
I0628 22:02:47.761971  5893 solver.cpp:371]     Train net output #0: loss = 1.33041 (* 1 = 1.33041 loss)
I0628 22:02:47.761977  5893 sgd_solver.cpp:137] Iteration 39200, lr = 0.00755, m = 0.9
I0628 22:03:06.227608  5893 solver.cpp:349] Iteration 39300 (5.41553 iter/s, 18.4654s/100 iter), loss = 1.34552
I0628 22:03:06.227628  5893 solver.cpp:371]     Train net output #0: loss = 1.31185 (* 1 = 1.31185 loss)
I0628 22:03:06.227632  5893 sgd_solver.cpp:137] Iteration 39300, lr = 0.00754375, m = 0.9
I0628 22:03:24.687592  5893 solver.cpp:349] Iteration 39400 (5.41719 iter/s, 18.4597s/100 iter), loss = 1.44375
I0628 22:03:24.687683  5893 solver.cpp:371]     Train net output #0: loss = 1.54256 (* 1 = 1.54256 loss)
I0628 22:03:24.687690  5893 sgd_solver.cpp:137] Iteration 39400, lr = 0.0075375, m = 0.9
I0628 22:03:43.124089  5893 solver.cpp:349] Iteration 39500 (5.42412 iter/s, 18.4362s/100 iter), loss = 1.26111
I0628 22:03:43.124112  5893 solver.cpp:371]     Train net output #0: loss = 1.11554 (* 1 = 1.11554 loss)
I0628 22:03:43.124116  5893 sgd_solver.cpp:137] Iteration 39500, lr = 0.00753125, m = 0.9
I0628 22:04:01.574054  5893 solver.cpp:349] Iteration 39600 (5.42014 iter/s, 18.4497s/100 iter), loss = 1.47088
I0628 22:04:01.574152  5893 solver.cpp:371]     Train net output #0: loss = 1.64771 (* 1 = 1.64771 loss)
I0628 22:04:01.574159  5893 sgd_solver.cpp:137] Iteration 39600, lr = 0.007525, m = 0.9
I0628 22:04:20.007172  5893 solver.cpp:349] Iteration 39700 (5.42512 iter/s, 18.4328s/100 iter), loss = 1.39748
I0628 22:04:20.007195  5893 solver.cpp:371]     Train net output #0: loss = 1.39062 (* 1 = 1.39062 loss)
I0628 22:04:20.007201  5893 sgd_solver.cpp:137] Iteration 39700, lr = 0.00751875, m = 0.9
I0628 22:04:38.450803  5893 solver.cpp:349] Iteration 39800 (5.42201 iter/s, 18.4433s/100 iter), loss = 1.52153
I0628 22:04:38.450875  5893 solver.cpp:371]     Train net output #0: loss = 1.57444 (* 1 = 1.57444 loss)
I0628 22:04:38.450878  5893 sgd_solver.cpp:137] Iteration 39800, lr = 0.0075125, m = 0.9
I0628 22:04:56.890630  5893 solver.cpp:349] Iteration 39900 (5.42314 iter/s, 18.4395s/100 iter), loss = 1.05698
I0628 22:04:56.890653  5893 solver.cpp:371]     Train net output #0: loss = 1.14304 (* 1 = 1.14304 loss)
I0628 22:04:56.890657  5893 sgd_solver.cpp:137] Iteration 39900, lr = 0.00750625, m = 0.9
I0628 22:05:15.181884  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_40000.caffemodel
I0628 22:05:15.193171  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_40000.solverstate
I0628 22:05:15.197844  5893 solver.cpp:401] Sparsity after update:
I0628 22:05:15.198653  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:05:15.198660  5893 net.cpp:2170] conv1a_param_0(0.2) 
I0628 22:05:15.198668  5893 net.cpp:2170] conv1b_param_0(0.4) 
I0628 22:05:15.198669  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:05:15.198671  5893 net.cpp:2170] res2a_branch2a_param_0(0.4) 
I0628 22:05:15.198673  5893 net.cpp:2170] res2a_branch2b_param_0(0.4) 
I0628 22:05:15.198675  5893 net.cpp:2170] res3a_branch2a_param_0(0.4) 
I0628 22:05:15.198678  5893 net.cpp:2170] res3a_branch2b_param_0(0.4) 
I0628 22:05:15.198678  5893 net.cpp:2170] res4a_branch2a_param_0(0.4) 
I0628 22:05:15.198680  5893 net.cpp:2170] res4a_branch2b_param_0(0.4) 
I0628 22:05:15.198683  5893 net.cpp:2170] res5a_branch2a_param_0(0.4) 
I0628 22:05:15.198684  5893 net.cpp:2170] res5a_branch2b_param_0(0.4) 
I0628 22:05:15.198686  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (941426/2.86678e+06) 0.328
I0628 22:05:15.198693  5893 solver.cpp:545] Iteration 40000, Testing net (#0)
I0628 22:05:39.559249  5888 data_reader.cpp:262] Starting prefetch of epoch 40
I0628 22:05:39.623114  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57516
I0628 22:05:39.623139  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809482
I0628 22:05:39.623145  5893 solver.cpp:630]     Test net output #2: loss = 1.83915 (* 1 = 1.83915 loss)
I0628 22:05:39.623163  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4241s
I0628 22:05:39.807835  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.41
I0628 22:05:40.216620  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:05:40.218096  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:05:40.218768  5893 solver.cpp:349] Iteration 40000 (2.308 iter/s, 43.3275s/100 iter), loss = 1.39429
I0628 22:05:40.218786  5893 solver.cpp:371]     Train net output #0: loss = 1.42127 (* 1 = 1.42127 loss)
I0628 22:05:40.218791  5893 sgd_solver.cpp:137] Iteration 40000, lr = 0.0075, m = 0.9
I0628 22:05:46.539686  5875 data_reader.cpp:262] Starting prefetch of epoch 8
I0628 22:05:58.634757  5893 solver.cpp:349] Iteration 40100 (5.43016 iter/s, 18.4157s/100 iter), loss = 1.40187
I0628 22:05:58.634780  5893 solver.cpp:371]     Train net output #0: loss = 0.996566 (* 1 = 0.996566 loss)
I0628 22:05:58.634784  5893 sgd_solver.cpp:137] Iteration 40100, lr = 0.00749375, m = 0.9
I0628 22:06:17.085753  5893 solver.cpp:349] Iteration 40200 (5.41986 iter/s, 18.4507s/100 iter), loss = 1.47828
I0628 22:06:17.085832  5893 solver.cpp:371]     Train net output #0: loss = 1.27249 (* 1 = 1.27249 loss)
I0628 22:06:17.085837  5893 sgd_solver.cpp:137] Iteration 40200, lr = 0.0074875, m = 0.9
I0628 22:06:35.536201  5893 solver.cpp:349] Iteration 40300 (5.42004 iter/s, 18.4501s/100 iter), loss = 1.34865
I0628 22:06:35.536224  5893 solver.cpp:371]     Train net output #0: loss = 1.2932 (* 1 = 1.2932 loss)
I0628 22:06:35.536228  5893 sgd_solver.cpp:137] Iteration 40300, lr = 0.00748125, m = 0.9
I0628 22:06:53.951696  5893 solver.cpp:349] Iteration 40400 (5.43031 iter/s, 18.4152s/100 iter), loss = 1.46621
I0628 22:06:53.951779  5893 solver.cpp:371]     Train net output #0: loss = 1.42687 (* 1 = 1.42687 loss)
I0628 22:06:53.951784  5893 sgd_solver.cpp:137] Iteration 40400, lr = 0.007475, m = 0.9
I0628 22:07:12.383433  5893 solver.cpp:349] Iteration 40500 (5.42554 iter/s, 18.4313s/100 iter), loss = 1.48928
I0628 22:07:12.383457  5893 solver.cpp:371]     Train net output #0: loss = 1.46032 (* 1 = 1.46032 loss)
I0628 22:07:12.383461  5893 sgd_solver.cpp:137] Iteration 40500, lr = 0.00746875, m = 0.9
I0628 22:07:30.790192  5893 solver.cpp:349] Iteration 40600 (5.43289 iter/s, 18.4064s/100 iter), loss = 1.36074
I0628 22:07:30.790279  5893 solver.cpp:371]     Train net output #0: loss = 1.27812 (* 1 = 1.27812 loss)
I0628 22:07:30.790284  5893 sgd_solver.cpp:137] Iteration 40600, lr = 0.0074625, m = 0.9
I0628 22:07:49.209653  5893 solver.cpp:349] Iteration 40700 (5.42917 iter/s, 18.419s/100 iter), loss = 1.68496
I0628 22:07:49.209676  5893 solver.cpp:371]     Train net output #0: loss = 2.00586 (* 1 = 2.00586 loss)
I0628 22:07:49.209679  5893 sgd_solver.cpp:137] Iteration 40700, lr = 0.00745625, m = 0.9
I0628 22:08:07.641865  5893 solver.cpp:349] Iteration 40800 (5.42539 iter/s, 18.4318s/100 iter), loss = 1.6144
I0628 22:08:07.641968  5893 solver.cpp:371]     Train net output #0: loss = 1.60628 (* 1 = 1.60628 loss)
I0628 22:08:07.641974  5893 sgd_solver.cpp:137] Iteration 40800, lr = 0.00745, m = 0.9
I0628 22:08:26.074129  5893 solver.cpp:349] Iteration 40900 (5.4254 iter/s, 18.4318s/100 iter), loss = 1.58411
I0628 22:08:26.074149  5893 solver.cpp:371]     Train net output #0: loss = 1.36532 (* 1 = 1.36532 loss)
I0628 22:08:26.074154  5893 sgd_solver.cpp:137] Iteration 40900, lr = 0.00744375, m = 0.9
I0628 22:08:44.358233  5893 solver.cpp:401] Sparsity after update:
I0628 22:08:44.363142  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:08:44.363148  5893 net.cpp:2170] conv1a_param_0(0.205) 
I0628 22:08:44.363154  5893 net.cpp:2170] conv1b_param_0(0.41) 
I0628 22:08:44.363157  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:08:44.363158  5893 net.cpp:2170] res2a_branch2a_param_0(0.41) 
I0628 22:08:44.363160  5893 net.cpp:2170] res2a_branch2b_param_0(0.41) 
I0628 22:08:44.363162  5893 net.cpp:2170] res3a_branch2a_param_0(0.41) 
I0628 22:08:44.363164  5893 net.cpp:2170] res3a_branch2b_param_0(0.41) 
I0628 22:08:44.363167  5893 net.cpp:2170] res4a_branch2a_param_0(0.41) 
I0628 22:08:44.363168  5893 net.cpp:2170] res4a_branch2b_param_0(0.41) 
I0628 22:08:44.363170  5893 net.cpp:2170] res5a_branch2a_param_0(0.41) 
I0628 22:08:44.363173  5893 net.cpp:2170] res5a_branch2b_param_0(0.41) 
I0628 22:08:44.363174  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (964961/2.86678e+06) 0.337
I0628 22:08:44.363181  5893 solver.cpp:545] Iteration 41000, Testing net (#0)
I0628 22:08:45.323520  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 22:09:08.686002  5888 data_reader.cpp:262] Starting prefetch of epoch 41
I0628 22:09:08.747925  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.570921
I0628 22:09:08.747949  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80472
I0628 22:09:08.747956  5893 solver.cpp:630]     Test net output #2: loss = 1.85733 (* 1 = 1.85733 loss)
I0628 22:09:08.747974  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3843s
I0628 22:09:08.934576  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.42
I0628 22:09:09.345401  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:09:09.346871  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:09:09.347549  5893 solver.cpp:349] Iteration 41000 (2.31093 iter/s, 43.2726s/100 iter), loss = 1.29908
I0628 22:09:09.347568  5893 solver.cpp:371]     Train net output #0: loss = 1.31243 (* 1 = 1.31243 loss)
I0628 22:09:09.347576  5893 sgd_solver.cpp:137] Iteration 41000, lr = 0.0074375, m = 0.9
I0628 22:09:27.766564  5893 solver.cpp:349] Iteration 41100 (5.42929 iter/s, 18.4186s/100 iter), loss = 1.38676
I0628 22:09:27.766659  5893 solver.cpp:371]     Train net output #0: loss = 1.34837 (* 1 = 1.34837 loss)
I0628 22:09:27.766664  5893 sgd_solver.cpp:137] Iteration 41100, lr = 0.00743125, m = 0.9
I0628 22:09:46.202530  5893 solver.cpp:349] Iteration 41200 (5.42432 iter/s, 18.4355s/100 iter), loss = 1.27249
I0628 22:09:46.202554  5893 solver.cpp:371]     Train net output #0: loss = 1.39695 (* 1 = 1.39695 loss)
I0628 22:09:46.202560  5893 sgd_solver.cpp:137] Iteration 41200, lr = 0.007425, m = 0.9
I0628 22:10:04.649617  5893 solver.cpp:349] Iteration 41300 (5.42103 iter/s, 18.4467s/100 iter), loss = 1.21636
I0628 22:10:04.649711  5893 solver.cpp:371]     Train net output #0: loss = 1.63542 (* 1 = 1.63542 loss)
I0628 22:10:04.649718  5893 sgd_solver.cpp:137] Iteration 41300, lr = 0.00741875, m = 0.9
I0628 22:10:23.091572  5893 solver.cpp:349] Iteration 41400 (5.42256 iter/s, 18.4415s/100 iter), loss = 1.77395
I0628 22:10:23.091593  5893 solver.cpp:371]     Train net output #0: loss = 1.54081 (* 1 = 1.54081 loss)
I0628 22:10:23.091596  5893 sgd_solver.cpp:137] Iteration 41400, lr = 0.0074125, m = 0.9
I0628 22:10:41.505839  5893 solver.cpp:349] Iteration 41500 (5.4307 iter/s, 18.4138s/100 iter), loss = 1.55388
I0628 22:10:41.505910  5893 solver.cpp:371]     Train net output #0: loss = 1.29012 (* 1 = 1.29012 loss)
I0628 22:10:41.505915  5893 sgd_solver.cpp:137] Iteration 41500, lr = 0.00740625, m = 0.9
I0628 22:10:59.951524  5893 solver.cpp:349] Iteration 41600 (5.42146 iter/s, 18.4452s/100 iter), loss = 1.21748
I0628 22:10:59.951545  5893 solver.cpp:371]     Train net output #0: loss = 1.40312 (* 1 = 1.40312 loss)
I0628 22:10:59.951550  5893 sgd_solver.cpp:137] Iteration 41600, lr = 0.0074, m = 0.9
I0628 22:11:18.379992  5893 solver.cpp:349] Iteration 41700 (5.42652 iter/s, 18.428s/100 iter), loss = 1.32545
I0628 22:11:18.380077  5893 solver.cpp:371]     Train net output #0: loss = 1.38636 (* 1 = 1.38636 loss)
I0628 22:11:18.380081  5893 sgd_solver.cpp:137] Iteration 41700, lr = 0.00739375, m = 0.9
I0628 22:11:36.782739  5893 solver.cpp:349] Iteration 41800 (5.43412 iter/s, 18.4022s/100 iter), loss = 1.2967
I0628 22:11:36.782763  5893 solver.cpp:371]     Train net output #0: loss = 1.36848 (* 1 = 1.36848 loss)
I0628 22:11:36.782766  5893 sgd_solver.cpp:137] Iteration 41800, lr = 0.0073875, m = 0.9
I0628 22:11:55.203735  5893 solver.cpp:349] Iteration 41900 (5.42872 iter/s, 18.4205s/100 iter), loss = 1.45418
I0628 22:11:55.209571  5893 solver.cpp:371]     Train net output #0: loss = 1.58929 (* 1 = 1.58929 loss)
I0628 22:11:55.209584  5893 sgd_solver.cpp:137] Iteration 41900, lr = 0.00738125, m = 0.9
I0628 22:12:13.457020  5893 solver.cpp:401] Sparsity after update:
I0628 22:12:13.462225  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:12:13.462234  5893 net.cpp:2170] conv1a_param_0(0.21) 
I0628 22:12:13.462239  5893 net.cpp:2170] conv1b_param_0(0.42) 
I0628 22:12:13.462241  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:12:13.462244  5893 net.cpp:2170] res2a_branch2a_param_0(0.42) 
I0628 22:12:13.462245  5893 net.cpp:2170] res2a_branch2b_param_0(0.42) 
I0628 22:12:13.462247  5893 net.cpp:2170] res3a_branch2a_param_0(0.42) 
I0628 22:12:13.462249  5893 net.cpp:2170] res3a_branch2b_param_0(0.42) 
I0628 22:12:13.462250  5893 net.cpp:2170] res4a_branch2a_param_0(0.42) 
I0628 22:12:13.462252  5893 net.cpp:2170] res4a_branch2b_param_0(0.42) 
I0628 22:12:13.462255  5893 net.cpp:2170] res5a_branch2a_param_0(0.42) 
I0628 22:12:13.462256  5893 net.cpp:2170] res5a_branch2b_param_0(0.42) 
I0628 22:12:13.462258  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (988498/2.86678e+06) 0.345
I0628 22:12:13.462265  5893 solver.cpp:545] Iteration 42000, Testing net (#0)
I0628 22:12:37.708755  5888 data_reader.cpp:262] Starting prefetch of epoch 42
I0628 22:12:37.770752  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57604
I0628 22:12:37.770778  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80856
I0628 22:12:37.770782  5893 solver.cpp:630]     Test net output #2: loss = 1.83935 (* 1 = 1.83935 loss)
I0628 22:12:37.770802  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.308s
I0628 22:12:37.955942  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.43
I0628 22:12:38.372210  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:12:38.373684  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:12:38.374356  5893 solver.cpp:349] Iteration 42000 (2.31676 iter/s, 43.1638s/100 iter), loss = 1.32903
I0628 22:12:38.374375  5893 solver.cpp:371]     Train net output #0: loss = 1.3203 (* 1 = 1.3203 loss)
I0628 22:12:38.374383  5893 sgd_solver.cpp:137] Iteration 42000, lr = 0.007375, m = 0.9
I0628 22:12:56.856173  5893 solver.cpp:349] Iteration 42100 (5.41086 iter/s, 18.4813s/100 iter), loss = 1.18013
I0628 22:12:56.856194  5893 solver.cpp:371]     Train net output #0: loss = 1.29875 (* 1 = 1.29875 loss)
I0628 22:12:56.856199  5893 sgd_solver.cpp:137] Iteration 42100, lr = 0.00736875, m = 0.9
I0628 22:13:15.309006  5893 solver.cpp:349] Iteration 42200 (5.41936 iter/s, 18.4524s/100 iter), loss = 1.81357
I0628 22:13:15.309105  5893 solver.cpp:371]     Train net output #0: loss = 1.31978 (* 1 = 1.31978 loss)
I0628 22:13:15.309111  5893 sgd_solver.cpp:137] Iteration 42200, lr = 0.0073625, m = 0.9
I0628 22:13:33.780356  5893 solver.cpp:349] Iteration 42300 (5.41396 iter/s, 18.4708s/100 iter), loss = 1.0612
I0628 22:13:33.780385  5893 solver.cpp:371]     Train net output #0: loss = 0.950753 (* 1 = 0.950753 loss)
I0628 22:13:33.780388  5893 sgd_solver.cpp:137] Iteration 42300, lr = 0.00735625, m = 0.9
I0628 22:13:52.244204  5893 solver.cpp:349] Iteration 42400 (5.41613 iter/s, 18.4634s/100 iter), loss = 1.38301
I0628 22:13:52.244292  5893 solver.cpp:371]     Train net output #0: loss = 1.40823 (* 1 = 1.40823 loss)
I0628 22:13:52.244295  5893 sgd_solver.cpp:137] Iteration 42400, lr = 0.00735, m = 0.9
I0628 22:14:10.714834  5893 solver.cpp:349] Iteration 42500 (5.41417 iter/s, 18.4701s/100 iter), loss = 1.45674
I0628 22:14:10.714859  5893 solver.cpp:371]     Train net output #0: loss = 1.94657 (* 1 = 1.94657 loss)
I0628 22:14:10.714864  5893 sgd_solver.cpp:137] Iteration 42500, lr = 0.00734375, m = 0.9
I0628 22:14:29.151854  5893 solver.cpp:349] Iteration 42600 (5.42402 iter/s, 18.4365s/100 iter), loss = 1.51717
I0628 22:14:29.151952  5893 solver.cpp:371]     Train net output #0: loss = 1.44463 (* 1 = 1.44463 loss)
I0628 22:14:29.151959  5893 sgd_solver.cpp:137] Iteration 42600, lr = 0.0073375, m = 0.9
I0628 22:14:47.601872  5893 solver.cpp:349] Iteration 42700 (5.42022 iter/s, 18.4494s/100 iter), loss = 1.64406
I0628 22:14:47.601898  5893 solver.cpp:371]     Train net output #0: loss = 1.70229 (* 1 = 1.70229 loss)
I0628 22:14:47.601904  5893 sgd_solver.cpp:137] Iteration 42700, lr = 0.00733125, m = 0.9
I0628 22:15:06.018824  5893 solver.cpp:349] Iteration 42800 (5.42993 iter/s, 18.4164s/100 iter), loss = 1.51392
I0628 22:15:06.018934  5893 solver.cpp:371]     Train net output #0: loss = 1.63601 (* 1 = 1.63601 loss)
I0628 22:15:06.018940  5893 sgd_solver.cpp:137] Iteration 42800, lr = 0.007325, m = 0.9
I0628 22:15:24.451236  5893 solver.cpp:349] Iteration 42900 (5.42541 iter/s, 18.4318s/100 iter), loss = 1.29998
I0628 22:15:24.451261  5893 solver.cpp:371]     Train net output #0: loss = 1.51598 (* 1 = 1.51598 loss)
I0628 22:15:24.451266  5893 sgd_solver.cpp:137] Iteration 42900, lr = 0.00731875, m = 0.9
I0628 22:15:42.684085  5893 solver.cpp:401] Sparsity after update:
I0628 22:15:42.689262  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:15:42.689270  5893 net.cpp:2170] conv1a_param_0(0.215) 
I0628 22:15:42.689276  5893 net.cpp:2170] conv1b_param_0(0.43) 
I0628 22:15:42.689280  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:15:42.689281  5893 net.cpp:2170] res2a_branch2a_param_0(0.43) 
I0628 22:15:42.689283  5893 net.cpp:2170] res2a_branch2b_param_0(0.43) 
I0628 22:15:42.689285  5893 net.cpp:2170] res3a_branch2a_param_0(0.43) 
I0628 22:15:42.689286  5893 net.cpp:2170] res3a_branch2b_param_0(0.43) 
I0628 22:15:42.689288  5893 net.cpp:2170] res4a_branch2a_param_0(0.43) 
I0628 22:15:42.689291  5893 net.cpp:2170] res4a_branch2b_param_0(0.43) 
I0628 22:15:42.689292  5893 net.cpp:2170] res5a_branch2a_param_0(0.43) 
I0628 22:15:42.689294  5893 net.cpp:2170] res5a_branch2b_param_0(0.43) 
I0628 22:15:42.689296  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.01203e+06/2.86678e+06) 0.353
I0628 22:15:42.689302  5893 solver.cpp:545] Iteration 43000, Testing net (#0)
I0628 22:16:06.996803  5888 data_reader.cpp:262] Starting prefetch of epoch 43
I0628 22:16:07.180330  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58004
I0628 22:16:07.180347  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.813561
I0628 22:16:07.180353  5893 solver.cpp:630]     Test net output #2: loss = 1.82363 (* 1 = 1.82363 loss)
I0628 22:16:07.180375  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4904s
I0628 22:16:07.364456  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.44
I0628 22:16:07.791337  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:16:07.792809  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:16:07.793489  5893 solver.cpp:349] Iteration 43000 (2.30728 iter/s, 43.3411s/100 iter), loss = 1.46258
I0628 22:16:07.793505  5893 solver.cpp:371]     Train net output #0: loss = 1.4022 (* 1 = 1.4022 loss)
I0628 22:16:07.793510  5893 sgd_solver.cpp:137] Iteration 43000, lr = 0.0073125, m = 0.9
I0628 22:16:26.204481  5893 solver.cpp:349] Iteration 43100 (5.43169 iter/s, 18.4105s/100 iter), loss = 1.47092
I0628 22:16:26.204524  5893 solver.cpp:371]     Train net output #0: loss = 1.26671 (* 1 = 1.26671 loss)
I0628 22:16:26.204529  5893 sgd_solver.cpp:137] Iteration 43100, lr = 0.00730625, m = 0.9
I0628 22:16:44.620901  5893 solver.cpp:349] Iteration 43200 (5.4301 iter/s, 18.4159s/100 iter), loss = 1.26927
I0628 22:16:44.620924  5893 solver.cpp:371]     Train net output #0: loss = 1.13688 (* 1 = 1.13688 loss)
I0628 22:16:44.620929  5893 sgd_solver.cpp:137] Iteration 43200, lr = 0.0073, m = 0.9
I0628 22:17:03.067797  5893 solver.cpp:349] Iteration 43300 (5.42113 iter/s, 18.4463s/100 iter), loss = 1.44707
I0628 22:17:03.067900  5893 solver.cpp:371]     Train net output #0: loss = 1.51185 (* 1 = 1.51185 loss)
I0628 22:17:03.067906  5893 sgd_solver.cpp:137] Iteration 43300, lr = 0.00729375, m = 0.9
I0628 22:17:21.488695  5893 solver.cpp:349] Iteration 43400 (5.42881 iter/s, 18.4203s/100 iter), loss = 1.32368
I0628 22:17:21.488719  5893 solver.cpp:371]     Train net output #0: loss = 1.63857 (* 1 = 1.63857 loss)
I0628 22:17:21.488723  5893 sgd_solver.cpp:137] Iteration 43400, lr = 0.0072875, m = 0.9
I0628 22:17:39.914508  5893 solver.cpp:349] Iteration 43500 (5.42734 iter/s, 18.4252s/100 iter), loss = 1.71602
I0628 22:17:39.914577  5893 solver.cpp:371]     Train net output #0: loss = 1.49268 (* 1 = 1.49268 loss)
I0628 22:17:39.914583  5893 sgd_solver.cpp:137] Iteration 43500, lr = 0.00728125, m = 0.9
I0628 22:17:58.346326  5893 solver.cpp:349] Iteration 43600 (5.42558 iter/s, 18.4312s/100 iter), loss = 1.44736
I0628 22:17:58.346346  5893 solver.cpp:371]     Train net output #0: loss = 1.44492 (* 1 = 1.44492 loss)
I0628 22:17:58.346350  5893 sgd_solver.cpp:137] Iteration 43600, lr = 0.007275, m = 0.9
I0628 22:18:16.807904  5893 solver.cpp:349] Iteration 43700 (5.41682 iter/s, 18.461s/100 iter), loss = 1.51531
I0628 22:18:16.807958  5893 solver.cpp:371]     Train net output #0: loss = 1.44428 (* 1 = 1.44428 loss)
I0628 22:18:16.807963  5893 sgd_solver.cpp:137] Iteration 43700, lr = 0.00726875, m = 0.9
I0628 22:18:35.213346  5893 solver.cpp:349] Iteration 43800 (5.43336 iter/s, 18.4048s/100 iter), loss = 1.45144
I0628 22:18:35.213369  5893 solver.cpp:371]     Train net output #0: loss = 1.36543 (* 1 = 1.36543 loss)
I0628 22:18:35.213373  5893 sgd_solver.cpp:137] Iteration 43800, lr = 0.0072625, m = 0.9
I0628 22:18:53.641412  5893 solver.cpp:349] Iteration 43900 (5.42668 iter/s, 18.4275s/100 iter), loss = 1.40491
I0628 22:18:53.641501  5893 solver.cpp:371]     Train net output #0: loss = 1.45017 (* 1 = 1.45017 loss)
I0628 22:18:53.641506  5893 sgd_solver.cpp:137] Iteration 43900, lr = 0.00725625, m = 0.9
I0628 22:19:11.908800  5893 solver.cpp:401] Sparsity after update:
I0628 22:19:11.914011  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:19:11.914018  5893 net.cpp:2170] conv1a_param_0(0.22) 
I0628 22:19:11.914024  5893 net.cpp:2170] conv1b_param_0(0.44) 
I0628 22:19:11.914026  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:19:11.914028  5893 net.cpp:2170] res2a_branch2a_param_0(0.44) 
I0628 22:19:11.914031  5893 net.cpp:2170] res2a_branch2b_param_0(0.44) 
I0628 22:19:11.914032  5893 net.cpp:2170] res3a_branch2a_param_0(0.44) 
I0628 22:19:11.914034  5893 net.cpp:2170] res3a_branch2b_param_0(0.44) 
I0628 22:19:11.914036  5893 net.cpp:2170] res4a_branch2a_param_0(0.44) 
I0628 22:19:11.914038  5893 net.cpp:2170] res4a_branch2b_param_0(0.44) 
I0628 22:19:11.914039  5893 net.cpp:2170] res5a_branch2a_param_0(0.44) 
I0628 22:19:11.914041  5893 net.cpp:2170] res5a_branch2b_param_0(0.44) 
I0628 22:19:11.914043  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.03557e+06/2.86678e+06) 0.361
I0628 22:19:11.914052  5893 solver.cpp:545] Iteration 44000, Testing net (#0)
I0628 22:19:36.226709  5888 data_reader.cpp:262] Starting prefetch of epoch 44
I0628 22:19:36.364598  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57948
I0628 22:19:36.364624  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811761
I0628 22:19:36.364629  5893 solver.cpp:630]     Test net output #2: loss = 1.82223 (* 1 = 1.82223 loss)
I0628 22:19:36.364645  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4499s
I0628 22:19:36.549562  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.45
I0628 22:19:36.990151  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:19:36.991623  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:19:36.992297  5893 solver.cpp:349] Iteration 44000 (2.30683 iter/s, 43.3495s/100 iter), loss = 1.22407
I0628 22:19:36.992317  5893 solver.cpp:371]     Train net output #0: loss = 1.12461 (* 1 = 1.12461 loss)
I0628 22:19:36.992326  5893 sgd_solver.cpp:137] Iteration 44000, lr = 0.00725, m = 0.9
I0628 22:19:55.448163  5893 solver.cpp:349] Iteration 44100 (5.41851 iter/s, 18.4553s/100 iter), loss = 1.65877
I0628 22:19:55.448181  5893 solver.cpp:371]     Train net output #0: loss = 1.57419 (* 1 = 1.57419 loss)
I0628 22:19:55.448185  5893 sgd_solver.cpp:137] Iteration 44100, lr = 0.00724375, m = 0.9
I0628 22:20:13.893157  5893 solver.cpp:349] Iteration 44200 (5.4217 iter/s, 18.4444s/100 iter), loss = 1.22047
I0628 22:20:13.893234  5893 solver.cpp:371]     Train net output #0: loss = 1.26593 (* 1 = 1.26593 loss)
I0628 22:20:13.893237  5893 sgd_solver.cpp:137] Iteration 44200, lr = 0.0072375, m = 0.9
I0628 22:20:32.313485  5893 solver.cpp:349] Iteration 44300 (5.42898 iter/s, 18.4197s/100 iter), loss = 1.32505
I0628 22:20:32.313510  5893 solver.cpp:371]     Train net output #0: loss = 0.987809 (* 1 = 0.987809 loss)
I0628 22:20:32.313514  5893 sgd_solver.cpp:137] Iteration 44300, lr = 0.00723125, m = 0.9
I0628 22:20:50.771718  5893 solver.cpp:349] Iteration 44400 (5.41782 iter/s, 18.4576s/100 iter), loss = 1.171
I0628 22:20:50.771828  5893 solver.cpp:371]     Train net output #0: loss = 1.36134 (* 1 = 1.36134 loss)
I0628 22:20:50.771836  5893 sgd_solver.cpp:137] Iteration 44400, lr = 0.007225, m = 0.9
I0628 22:21:09.218376  5893 solver.cpp:349] Iteration 44500 (5.42125 iter/s, 18.4459s/100 iter), loss = 1.40861
I0628 22:21:09.218399  5893 solver.cpp:371]     Train net output #0: loss = 1.31744 (* 1 = 1.31744 loss)
I0628 22:21:09.218402  5893 sgd_solver.cpp:137] Iteration 44500, lr = 0.00721875, m = 0.9
I0628 22:21:27.634300  5893 solver.cpp:349] Iteration 44600 (5.43027 iter/s, 18.4153s/100 iter), loss = 1.54049
I0628 22:21:27.634387  5893 solver.cpp:371]     Train net output #0: loss = 1.16451 (* 1 = 1.16451 loss)
I0628 22:21:27.634392  5893 sgd_solver.cpp:137] Iteration 44600, lr = 0.0072125, m = 0.9
I0628 22:21:46.063827  5893 solver.cpp:349] Iteration 44700 (5.42628 iter/s, 18.4288s/100 iter), loss = 1.4323
I0628 22:21:46.063846  5893 solver.cpp:371]     Train net output #0: loss = 1.53199 (* 1 = 1.53199 loss)
I0628 22:21:46.063850  5893 sgd_solver.cpp:137] Iteration 44700, lr = 0.00720625, m = 0.9
I0628 22:22:04.505955  5893 solver.cpp:349] Iteration 44800 (5.42255 iter/s, 18.4415s/100 iter), loss = 1.44077
I0628 22:22:04.506045  5893 solver.cpp:371]     Train net output #0: loss = 1.64541 (* 1 = 1.64541 loss)
I0628 22:22:04.506050  5893 sgd_solver.cpp:137] Iteration 44800, lr = 0.0072, m = 0.9
I0628 22:22:22.966555  5893 solver.cpp:349] Iteration 44900 (5.41715 iter/s, 18.4599s/100 iter), loss = 1.37863
I0628 22:22:22.966575  5893 solver.cpp:371]     Train net output #0: loss = 1.29952 (* 1 = 1.29952 loss)
I0628 22:22:22.966580  5893 sgd_solver.cpp:137] Iteration 44900, lr = 0.00719375, m = 0.9
I0628 22:22:41.266718  5893 solver.cpp:401] Sparsity after update:
I0628 22:22:41.271925  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:22:41.271932  5893 net.cpp:2170] conv1a_param_0(0.225) 
I0628 22:22:41.271939  5893 net.cpp:2170] conv1b_param_0(0.45) 
I0628 22:22:41.271941  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:22:41.271944  5893 net.cpp:2170] res2a_branch2a_param_0(0.45) 
I0628 22:22:41.271945  5893 net.cpp:2170] res2a_branch2b_param_0(0.45) 
I0628 22:22:41.271947  5893 net.cpp:2170] res3a_branch2a_param_0(0.45) 
I0628 22:22:41.271948  5893 net.cpp:2170] res3a_branch2b_param_0(0.45) 
I0628 22:22:41.271950  5893 net.cpp:2170] res4a_branch2a_param_0(0.45) 
I0628 22:22:41.271952  5893 net.cpp:2170] res4a_branch2b_param_0(0.45) 
I0628 22:22:41.271955  5893 net.cpp:2170] res5a_branch2a_param_0(0.45) 
I0628 22:22:41.271956  5893 net.cpp:2170] res5a_branch2b_param_0(0.45) 
I0628 22:22:41.271958  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.05911e+06/2.86678e+06) 0.369
I0628 22:22:41.271965  5893 solver.cpp:545] Iteration 45000, Testing net (#0)
I0628 22:23:05.502239  5888 data_reader.cpp:262] Starting prefetch of epoch 45
I0628 22:23:05.566100  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57912
I0628 22:23:05.566124  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811201
I0628 22:23:05.566129  5893 solver.cpp:630]     Test net output #2: loss = 1.82761 (* 1 = 1.82761 loss)
I0628 22:23:05.566145  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2934s
I0628 22:23:05.752934  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.46
I0628 22:23:06.184958  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:23:06.186429  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:23:06.187105  5893 solver.cpp:349] Iteration 45000 (2.31379 iter/s, 43.2191s/100 iter), loss = 1.36937
I0628 22:23:06.187121  5893 solver.cpp:371]     Train net output #0: loss = 1.32009 (* 1 = 1.32009 loss)
I0628 22:23:06.187126  5893 sgd_solver.cpp:137] Iteration 45000, lr = 0.0071875, m = 0.9
I0628 22:23:13.382239  5875 data_reader.cpp:262] Starting prefetch of epoch 9
I0628 22:23:24.625336  5893 solver.cpp:349] Iteration 45100 (5.42371 iter/s, 18.4376s/100 iter), loss = 1.34903
I0628 22:23:24.625360  5893 solver.cpp:371]     Train net output #0: loss = 1.41674 (* 1 = 1.41674 loss)
I0628 22:23:24.625363  5893 sgd_solver.cpp:137] Iteration 45100, lr = 0.00718125, m = 0.9
I0628 22:23:43.063760  5893 solver.cpp:349] Iteration 45200 (5.42365 iter/s, 18.4378s/100 iter), loss = 1.58781
I0628 22:23:43.063781  5893 solver.cpp:371]     Train net output #0: loss = 1.43206 (* 1 = 1.43206 loss)
I0628 22:23:43.063786  5893 sgd_solver.cpp:137] Iteration 45200, lr = 0.007175, m = 0.9
I0628 22:24:01.483826  5893 solver.cpp:349] Iteration 45300 (5.42906 iter/s, 18.4194s/100 iter), loss = 1.40948
I0628 22:24:01.483930  5893 solver.cpp:371]     Train net output #0: loss = 1.34895 (* 1 = 1.34895 loss)
I0628 22:24:01.483937  5893 sgd_solver.cpp:137] Iteration 45300, lr = 0.00716875, m = 0.9
I0628 22:24:19.936483  5893 solver.cpp:349] Iteration 45400 (5.4195 iter/s, 18.4519s/100 iter), loss = 1.28038
I0628 22:24:19.936506  5893 solver.cpp:371]     Train net output #0: loss = 1.21734 (* 1 = 1.21734 loss)
I0628 22:24:19.936509  5893 sgd_solver.cpp:137] Iteration 45400, lr = 0.0071625, m = 0.9
I0628 22:24:38.372956  5893 solver.cpp:349] Iteration 45500 (5.42423 iter/s, 18.4358s/100 iter), loss = 1.42808
I0628 22:24:38.373054  5893 solver.cpp:371]     Train net output #0: loss = 1.31626 (* 1 = 1.31626 loss)
I0628 22:24:38.373060  5893 sgd_solver.cpp:137] Iteration 45500, lr = 0.00715625, m = 0.9
I0628 22:24:56.813426  5893 solver.cpp:349] Iteration 45600 (5.42308 iter/s, 18.4397s/100 iter), loss = 1.40228
I0628 22:24:56.813446  5893 solver.cpp:371]     Train net output #0: loss = 1.09161 (* 1 = 1.09161 loss)
I0628 22:24:56.813449  5893 sgd_solver.cpp:137] Iteration 45600, lr = 0.00715, m = 0.9
I0628 22:25:15.235221  5893 solver.cpp:349] Iteration 45700 (5.42855 iter/s, 18.4211s/100 iter), loss = 1.41581
I0628 22:25:15.235322  5893 solver.cpp:371]     Train net output #0: loss = 1.52275 (* 1 = 1.52275 loss)
I0628 22:25:15.235329  5893 sgd_solver.cpp:137] Iteration 45700, lr = 0.00714375, m = 0.9
I0628 22:25:33.669569  5893 solver.cpp:349] Iteration 45800 (5.42488 iter/s, 18.4336s/100 iter), loss = 1.42878
I0628 22:25:33.669592  5893 solver.cpp:371]     Train net output #0: loss = 1.45664 (* 1 = 1.45664 loss)
I0628 22:25:33.669596  5893 sgd_solver.cpp:137] Iteration 45800, lr = 0.0071375, m = 0.9
I0628 22:25:52.113785  5893 solver.cpp:349] Iteration 45900 (5.42196 iter/s, 18.4435s/100 iter), loss = 1.36189
I0628 22:25:52.113885  5893 solver.cpp:371]     Train net output #0: loss = 1.37365 (* 1 = 1.37365 loss)
I0628 22:25:52.113893  5893 sgd_solver.cpp:137] Iteration 45900, lr = 0.00713125, m = 0.9
I0628 22:26:10.350689  5893 solver.cpp:401] Sparsity after update:
I0628 22:26:10.355901  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:26:10.355909  5893 net.cpp:2170] conv1a_param_0(0.23) 
I0628 22:26:10.355916  5893 net.cpp:2170] conv1b_param_0(0.46) 
I0628 22:26:10.355918  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:26:10.355921  5893 net.cpp:2170] res2a_branch2a_param_0(0.46) 
I0628 22:26:10.355922  5893 net.cpp:2170] res2a_branch2b_param_0(0.46) 
I0628 22:26:10.355924  5893 net.cpp:2170] res3a_branch2a_param_0(0.46) 
I0628 22:26:10.355926  5893 net.cpp:2170] res3a_branch2b_param_0(0.46) 
I0628 22:26:10.355927  5893 net.cpp:2170] res4a_branch2a_param_0(0.46) 
I0628 22:26:10.355931  5893 net.cpp:2170] res4a_branch2b_param_0(0.46) 
I0628 22:26:10.355932  5893 net.cpp:2170] res5a_branch2a_param_0(0.46) 
I0628 22:26:10.355934  5893 net.cpp:2170] res5a_branch2b_param_0(0.46) 
I0628 22:26:10.355937  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.08264e+06/2.86678e+06) 0.378
I0628 22:26:10.355944  5893 solver.cpp:545] Iteration 46000, Testing net (#0)
I0628 22:26:11.565264  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 22:26:34.732426  5888 data_reader.cpp:262] Starting prefetch of epoch 46
I0628 22:26:34.794452  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57508
I0628 22:26:34.794474  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.807961
I0628 22:26:34.794479  5893 solver.cpp:630]     Test net output #2: loss = 1.84194 (* 1 = 1.84194 loss)
I0628 22:26:34.794497  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4377s
I0628 22:26:34.979735  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.47
I0628 22:26:35.426863  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:26:35.428329  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:26:35.429008  5893 solver.cpp:349] Iteration 46000 (2.30875 iter/s, 43.3135s/100 iter), loss = 1.16309
I0628 22:26:35.429026  5893 solver.cpp:371]     Train net output #0: loss = 1.07626 (* 1 = 1.07626 loss)
I0628 22:26:35.429035  5893 sgd_solver.cpp:137] Iteration 46000, lr = 0.007125, m = 0.9
I0628 22:26:53.860947  5893 solver.cpp:349] Iteration 46100 (5.42557 iter/s, 18.4312s/100 iter), loss = 1.34368
I0628 22:26:53.860971  5893 solver.cpp:371]     Train net output #0: loss = 1.62467 (* 1 = 1.62467 loss)
I0628 22:26:53.860975  5893 sgd_solver.cpp:137] Iteration 46100, lr = 0.00711875, m = 0.9
I0628 22:27:12.273612  5893 solver.cpp:349] Iteration 46200 (5.43125 iter/s, 18.412s/100 iter), loss = 1.42867
I0628 22:27:12.273715  5893 solver.cpp:371]     Train net output #0: loss = 1.77048 (* 1 = 1.77048 loss)
I0628 22:27:12.273720  5893 sgd_solver.cpp:137] Iteration 46200, lr = 0.0071125, m = 0.9
I0628 22:27:30.714248  5893 solver.cpp:349] Iteration 46300 (5.42304 iter/s, 18.4398s/100 iter), loss = 1.07729
I0628 22:27:30.714272  5893 solver.cpp:371]     Train net output #0: loss = 1.3827 (* 1 = 1.3827 loss)
I0628 22:27:30.714275  5893 sgd_solver.cpp:137] Iteration 46300, lr = 0.00710625, m = 0.9
I0628 22:27:49.132422  5893 solver.cpp:349] Iteration 46400 (5.42963 iter/s, 18.4175s/100 iter), loss = 1.12429
I0628 22:27:49.132524  5893 solver.cpp:371]     Train net output #0: loss = 1.17148 (* 1 = 1.17148 loss)
I0628 22:27:49.132532  5893 sgd_solver.cpp:137] Iteration 46400, lr = 0.0071, m = 0.9
I0628 22:28:07.574977  5893 solver.cpp:349] Iteration 46500 (5.42248 iter/s, 18.4417s/100 iter), loss = 1.39051
I0628 22:28:07.575001  5893 solver.cpp:371]     Train net output #0: loss = 1.38208 (* 1 = 1.38208 loss)
I0628 22:28:07.575004  5893 sgd_solver.cpp:137] Iteration 46500, lr = 0.00709375, m = 0.9
I0628 22:28:26.016770  5893 solver.cpp:349] Iteration 46600 (5.42268 iter/s, 18.4411s/100 iter), loss = 1.49129
I0628 22:28:26.016851  5893 solver.cpp:371]     Train net output #0: loss = 1.47933 (* 1 = 1.47933 loss)
I0628 22:28:26.016856  5893 sgd_solver.cpp:137] Iteration 46600, lr = 0.0070875, m = 0.9
I0628 22:28:44.433207  5893 solver.cpp:349] Iteration 46700 (5.43017 iter/s, 18.4156s/100 iter), loss = 1.24471
I0628 22:28:44.433230  5893 solver.cpp:371]     Train net output #0: loss = 1.30408 (* 1 = 1.30408 loss)
I0628 22:28:44.433235  5893 sgd_solver.cpp:137] Iteration 46700, lr = 0.00708125, m = 0.9
I0628 22:29:02.908054  5893 solver.cpp:349] Iteration 46800 (5.41298 iter/s, 18.4741s/100 iter), loss = 1.30063
I0628 22:29:02.908159  5893 solver.cpp:371]     Train net output #0: loss = 1.21006 (* 1 = 1.21006 loss)
I0628 22:29:02.908165  5893 sgd_solver.cpp:137] Iteration 46800, lr = 0.007075, m = 0.9
I0628 22:29:21.391336  5893 solver.cpp:349] Iteration 46900 (5.41054 iter/s, 18.4825s/100 iter), loss = 1.37261
I0628 22:29:21.391358  5893 solver.cpp:371]     Train net output #0: loss = 1.20743 (* 1 = 1.20743 loss)
I0628 22:29:21.391362  5893 sgd_solver.cpp:137] Iteration 46900, lr = 0.00706875, m = 0.9
I0628 22:29:39.616443  5893 solver.cpp:401] Sparsity after update:
I0628 22:29:39.621642  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:29:39.621651  5893 net.cpp:2170] conv1a_param_0(0.235) 
I0628 22:29:39.621657  5893 net.cpp:2170] conv1b_param_0(0.47) 
I0628 22:29:39.621659  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:29:39.621662  5893 net.cpp:2170] res2a_branch2a_param_0(0.47) 
I0628 22:29:39.621665  5893 net.cpp:2170] res2a_branch2b_param_0(0.47) 
I0628 22:29:39.621666  5893 net.cpp:2170] res3a_branch2a_param_0(0.47) 
I0628 22:29:39.621667  5893 net.cpp:2170] res3a_branch2b_param_0(0.47) 
I0628 22:29:39.621670  5893 net.cpp:2170] res4a_branch2a_param_0(0.47) 
I0628 22:29:39.621671  5893 net.cpp:2170] res4a_branch2b_param_0(0.47) 
I0628 22:29:39.621675  5893 net.cpp:2170] res5a_branch2a_param_0(0.47) 
I0628 22:29:39.621676  5893 net.cpp:2170] res5a_branch2b_param_0(0.47) 
I0628 22:29:39.621678  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.10618e+06/2.86678e+06) 0.386
I0628 22:29:39.621686  5893 solver.cpp:545] Iteration 47000, Testing net (#0)
I0628 22:30:03.823163  5888 data_reader.cpp:262] Starting prefetch of epoch 47
I0628 22:30:03.885244  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58096
I0628 22:30:03.885267  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809761
I0628 22:30:03.885272  5893 solver.cpp:630]     Test net output #2: loss = 1.8231 (* 1 = 1.8231 loss)
I0628 22:30:03.885288  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2627s
I0628 22:30:04.070286  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.48
I0628 22:30:04.524981  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:30:04.526468  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:30:04.527148  5893 solver.cpp:349] Iteration 47000 (2.31835 iter/s, 43.1341s/100 iter), loss = 1.38782
I0628 22:30:04.527166  5893 solver.cpp:371]     Train net output #0: loss = 1.21923 (* 1 = 1.21923 loss)
I0628 22:30:04.527171  5893 sgd_solver.cpp:137] Iteration 47000, lr = 0.0070625, m = 0.9
I0628 22:30:22.989792  5893 solver.cpp:349] Iteration 47100 (5.41656 iter/s, 18.4619s/100 iter), loss = 1.32184
I0628 22:30:22.989899  5893 solver.cpp:371]     Train net output #0: loss = 1.2703 (* 1 = 1.2703 loss)
I0628 22:30:22.989908  5893 sgd_solver.cpp:137] Iteration 47100, lr = 0.00705625, m = 0.9
I0628 22:30:41.453519  5893 solver.cpp:349] Iteration 47200 (5.41627 iter/s, 18.4629s/100 iter), loss = 1.05797
I0628 22:30:41.453541  5893 solver.cpp:371]     Train net output #0: loss = 1.02232 (* 1 = 1.02232 loss)
I0628 22:30:41.453544  5893 sgd_solver.cpp:137] Iteration 47200, lr = 0.00705, m = 0.9
I0628 22:30:59.867756  5893 solver.cpp:349] Iteration 47300 (5.43081 iter/s, 18.4135s/100 iter), loss = 1.12399
I0628 22:30:59.867842  5893 solver.cpp:371]     Train net output #0: loss = 0.893886 (* 1 = 0.893886 loss)
I0628 22:30:59.867847  5893 sgd_solver.cpp:137] Iteration 47300, lr = 0.00704375, m = 0.9
I0628 22:31:18.299278  5893 solver.cpp:349] Iteration 47400 (5.42573 iter/s, 18.4307s/100 iter), loss = 1.44896
I0628 22:31:18.299298  5893 solver.cpp:371]     Train net output #0: loss = 1.54036 (* 1 = 1.54036 loss)
I0628 22:31:18.299304  5893 sgd_solver.cpp:137] Iteration 47400, lr = 0.0070375, m = 0.9
I0628 22:31:36.737540  5893 solver.cpp:349] Iteration 47500 (5.42373 iter/s, 18.4375s/100 iter), loss = 1.41898
I0628 22:31:36.737632  5893 solver.cpp:371]     Train net output #0: loss = 1.5999 (* 1 = 1.5999 loss)
I0628 22:31:36.737637  5893 sgd_solver.cpp:137] Iteration 47500, lr = 0.00703125, m = 0.9
I0628 22:31:55.179215  5893 solver.cpp:349] Iteration 47600 (5.42275 iter/s, 18.4408s/100 iter), loss = 1.47344
I0628 22:31:55.179236  5893 solver.cpp:371]     Train net output #0: loss = 1.40686 (* 1 = 1.40686 loss)
I0628 22:31:55.179240  5893 sgd_solver.cpp:137] Iteration 47600, lr = 0.007025, m = 0.9
I0628 22:32:13.620724  5893 solver.cpp:349] Iteration 47700 (5.42278 iter/s, 18.4407s/100 iter), loss = 1.43132
I0628 22:32:13.620766  5893 solver.cpp:371]     Train net output #0: loss = 1.30909 (* 1 = 1.30909 loss)
I0628 22:32:13.620771  5893 sgd_solver.cpp:137] Iteration 47700, lr = 0.00701875, m = 0.9
I0628 22:32:32.059352  5893 solver.cpp:349] Iteration 47800 (5.42363 iter/s, 18.4378s/100 iter), loss = 1.44402
I0628 22:32:32.059372  5893 solver.cpp:371]     Train net output #0: loss = 1.70425 (* 1 = 1.70425 loss)
I0628 22:32:32.059376  5893 sgd_solver.cpp:137] Iteration 47800, lr = 0.0070125, m = 0.9
I0628 22:32:50.494374  5893 solver.cpp:349] Iteration 47900 (5.42469 iter/s, 18.4342s/100 iter), loss = 1.43752
I0628 22:32:50.494453  5893 solver.cpp:371]     Train net output #0: loss = 1.83078 (* 1 = 1.83078 loss)
I0628 22:32:50.494458  5893 sgd_solver.cpp:137] Iteration 47900, lr = 0.00700625, m = 0.9
I0628 22:33:08.726521  5893 solver.cpp:401] Sparsity after update:
I0628 22:33:08.731490  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:33:08.731499  5893 net.cpp:2170] conv1a_param_0(0.24) 
I0628 22:33:08.731508  5893 net.cpp:2170] conv1b_param_0(0.48) 
I0628 22:33:08.731510  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:33:08.731513  5893 net.cpp:2170] res2a_branch2a_param_0(0.48) 
I0628 22:33:08.731518  5893 net.cpp:2170] res2a_branch2b_param_0(0.48) 
I0628 22:33:08.731520  5893 net.cpp:2170] res3a_branch2a_param_0(0.48) 
I0628 22:33:08.731523  5893 net.cpp:2170] res3a_branch2b_param_0(0.48) 
I0628 22:33:08.731526  5893 net.cpp:2170] res4a_branch2a_param_0(0.48) 
I0628 22:33:08.731529  5893 net.cpp:2170] res4a_branch2b_param_0(0.48) 
I0628 22:33:08.731533  5893 net.cpp:2170] res5a_branch2a_param_0(0.48) 
I0628 22:33:08.731535  5893 net.cpp:2170] res5a_branch2b_param_0(0.48) 
I0628 22:33:08.731539  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.12971e+06/2.86678e+06) 0.394
I0628 22:33:08.731549  5893 solver.cpp:545] Iteration 48000, Testing net (#0)
I0628 22:33:32.905071  5888 data_reader.cpp:262] Starting prefetch of epoch 48
I0628 22:33:33.238881  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.580081
I0628 22:33:33.238905  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811001
I0628 22:33:33.238910  5893 solver.cpp:630]     Test net output #2: loss = 1.82476 (* 1 = 1.82476 loss)
I0628 22:33:33.238927  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5064s
I0628 22:33:33.426086  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.49
I0628 22:33:33.891175  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:33:33.892654  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:33:33.893333  5893 solver.cpp:349] Iteration 48000 (2.3043 iter/s, 43.3971s/100 iter), loss = 1.20965
I0628 22:33:33.893352  5893 solver.cpp:371]     Train net output #0: loss = 1.21964 (* 1 = 1.21964 loss)
I0628 22:33:33.893357  5893 sgd_solver.cpp:137] Iteration 48000, lr = 0.007, m = 0.9
I0628 22:33:52.311946  5893 solver.cpp:349] Iteration 48100 (5.42952 iter/s, 18.4178s/100 iter), loss = 1.3964
I0628 22:33:52.311969  5893 solver.cpp:371]     Train net output #0: loss = 1.63412 (* 1 = 1.63412 loss)
I0628 22:33:52.311974  5893 sgd_solver.cpp:137] Iteration 48100, lr = 0.00699375, m = 0.9
I0628 22:34:10.757251  5893 solver.cpp:349] Iteration 48200 (5.42167 iter/s, 18.4445s/100 iter), loss = 1.27012
I0628 22:34:10.757355  5893 solver.cpp:371]     Train net output #0: loss = 1.35716 (* 1 = 1.35716 loss)
I0628 22:34:10.757362  5893 sgd_solver.cpp:137] Iteration 48200, lr = 0.0069875, m = 0.9
I0628 22:34:29.199268  5893 solver.cpp:349] Iteration 48300 (5.42266 iter/s, 18.4411s/100 iter), loss = 1.28275
I0628 22:34:29.199291  5893 solver.cpp:371]     Train net output #0: loss = 1.50972 (* 1 = 1.50972 loss)
I0628 22:34:29.199295  5893 sgd_solver.cpp:137] Iteration 48300, lr = 0.00698125, m = 0.9
I0628 22:34:47.619601  5893 solver.cpp:349] Iteration 48400 (5.42902 iter/s, 18.4195s/100 iter), loss = 1.80852
I0628 22:34:47.619649  5893 solver.cpp:371]     Train net output #0: loss = 1.71636 (* 1 = 1.71636 loss)
I0628 22:34:47.619653  5893 sgd_solver.cpp:137] Iteration 48400, lr = 0.006975, m = 0.9
I0628 22:35:06.053637  5893 solver.cpp:349] Iteration 48500 (5.42499 iter/s, 18.4332s/100 iter), loss = 1.43518
I0628 22:35:06.053658  5893 solver.cpp:371]     Train net output #0: loss = 1.34767 (* 1 = 1.34767 loss)
I0628 22:35:06.053663  5893 sgd_solver.cpp:137] Iteration 48500, lr = 0.00696875, m = 0.9
I0628 22:35:24.478132  5893 solver.cpp:349] Iteration 48600 (5.4278 iter/s, 18.4237s/100 iter), loss = 1.2675
I0628 22:35:24.478184  5893 solver.cpp:371]     Train net output #0: loss = 1.47067 (* 1 = 1.47067 loss)
I0628 22:35:24.478190  5893 sgd_solver.cpp:137] Iteration 48600, lr = 0.0069625, m = 0.9
I0628 22:35:42.889777  5893 solver.cpp:349] Iteration 48700 (5.43159 iter/s, 18.4108s/100 iter), loss = 0.986753
I0628 22:35:42.889801  5893 solver.cpp:371]     Train net output #0: loss = 1.01049 (* 1 = 1.01049 loss)
I0628 22:35:42.889806  5893 sgd_solver.cpp:137] Iteration 48700, lr = 0.00695625, m = 0.9
I0628 22:36:01.316184  5893 solver.cpp:349] Iteration 48800 (5.42724 iter/s, 18.4256s/100 iter), loss = 1.69989
I0628 22:36:01.316287  5893 solver.cpp:371]     Train net output #0: loss = 1.57628 (* 1 = 1.57628 loss)
I0628 22:36:01.316293  5893 sgd_solver.cpp:137] Iteration 48800, lr = 0.00695, m = 0.9
I0628 22:36:19.732336  5893 solver.cpp:349] Iteration 48900 (5.43028 iter/s, 18.4153s/100 iter), loss = 1.22625
I0628 22:36:19.732360  5893 solver.cpp:371]     Train net output #0: loss = 1.07907 (* 1 = 1.07907 loss)
I0628 22:36:19.732365  5893 sgd_solver.cpp:137] Iteration 48900, lr = 0.00694375, m = 0.9
I0628 22:36:38.006263  5893 solver.cpp:401] Sparsity after update:
I0628 22:36:38.011497  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:36:38.011505  5893 net.cpp:2170] conv1a_param_0(0.245) 
I0628 22:36:38.011512  5893 net.cpp:2170] conv1b_param_0(0.49) 
I0628 22:36:38.011513  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:36:38.011515  5893 net.cpp:2170] res2a_branch2a_param_0(0.49) 
I0628 22:36:38.011518  5893 net.cpp:2170] res2a_branch2b_param_0(0.49) 
I0628 22:36:38.011519  5893 net.cpp:2170] res3a_branch2a_param_0(0.49) 
I0628 22:36:38.011521  5893 net.cpp:2170] res3a_branch2b_param_0(0.49) 
I0628 22:36:38.011523  5893 net.cpp:2170] res4a_branch2a_param_0(0.49) 
I0628 22:36:38.011524  5893 net.cpp:2170] res4a_branch2b_param_0(0.49) 
I0628 22:36:38.011526  5893 net.cpp:2170] res5a_branch2a_param_0(0.49) 
I0628 22:36:38.011528  5893 net.cpp:2170] res5a_branch2b_param_0(0.49) 
I0628 22:36:38.011530  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.15324e+06/2.86678e+06) 0.402
I0628 22:36:38.011538  5893 solver.cpp:545] Iteration 49000, Testing net (#0)
I0628 22:37:02.370445  5888 data_reader.cpp:262] Starting prefetch of epoch 49
I0628 22:37:02.432464  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58428
I0628 22:37:02.432487  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.814441
I0628 22:37:02.432493  5893 solver.cpp:630]     Test net output #2: loss = 1.79438 (* 1 = 1.79438 loss)
I0628 22:37:02.432512  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4202s
I0628 22:37:02.616858  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.5
I0628 22:37:03.084794  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:37:03.086264  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:37:03.086940  5893 solver.cpp:349] Iteration 49000 (2.30665 iter/s, 43.353s/100 iter), loss = 1.26293
I0628 22:37:03.086958  5893 solver.cpp:371]     Train net output #0: loss = 1.32218 (* 1 = 1.32218 loss)
I0628 22:37:03.086966  5893 sgd_solver.cpp:137] Iteration 49000, lr = 0.0069375, m = 0.9
I0628 22:37:21.526149  5893 solver.cpp:349] Iteration 49100 (5.42339 iter/s, 18.4386s/100 iter), loss = 1.59308
I0628 22:37:21.526252  5893 solver.cpp:371]     Train net output #0: loss = 1.36309 (* 1 = 1.36309 loss)
I0628 22:37:21.526259  5893 sgd_solver.cpp:137] Iteration 49100, lr = 0.00693125, m = 0.9
I0628 22:37:39.957777  5893 solver.cpp:349] Iteration 49200 (5.42565 iter/s, 18.431s/100 iter), loss = 1.37957
I0628 22:37:39.957798  5893 solver.cpp:371]     Train net output #0: loss = 1.28084 (* 1 = 1.28084 loss)
I0628 22:37:39.957803  5893 sgd_solver.cpp:137] Iteration 49200, lr = 0.006925, m = 0.9
I0628 22:37:58.362359  5893 solver.cpp:349] Iteration 49300 (5.4336 iter/s, 18.404s/100 iter), loss = 1.25997
I0628 22:37:58.362473  5893 solver.cpp:371]     Train net output #0: loss = 1.04725 (* 1 = 1.04725 loss)
I0628 22:37:58.362479  5893 sgd_solver.cpp:137] Iteration 49300, lr = 0.00691875, m = 0.9
I0628 22:38:16.795238  5893 solver.cpp:349] Iteration 49400 (5.42528 iter/s, 18.4322s/100 iter), loss = 1.30964
I0628 22:38:16.795256  5893 solver.cpp:371]     Train net output #0: loss = 1.23791 (* 1 = 1.23791 loss)
I0628 22:38:16.795260  5893 sgd_solver.cpp:137] Iteration 49400, lr = 0.0069125, m = 0.9
I0628 22:38:35.243321  5893 solver.cpp:349] Iteration 49500 (5.42078 iter/s, 18.4475s/100 iter), loss = 1.40421
I0628 22:38:35.243428  5893 solver.cpp:371]     Train net output #0: loss = 1.40609 (* 1 = 1.40609 loss)
I0628 22:38:35.243434  5893 sgd_solver.cpp:137] Iteration 49500, lr = 0.00690625, m = 0.9
I0628 22:38:53.709004  5893 solver.cpp:349] Iteration 49600 (5.41564 iter/s, 18.465s/100 iter), loss = 1.67354
I0628 22:38:53.709026  5893 solver.cpp:371]     Train net output #0: loss = 1.47157 (* 1 = 1.47157 loss)
I0628 22:38:53.709030  5893 sgd_solver.cpp:137] Iteration 49600, lr = 0.0069, m = 0.9
I0628 22:39:12.128547  5893 solver.cpp:349] Iteration 49700 (5.42918 iter/s, 18.419s/100 iter), loss = 1.51884
I0628 22:39:12.128649  5893 solver.cpp:371]     Train net output #0: loss = 1.28019 (* 1 = 1.28019 loss)
I0628 22:39:12.128656  5893 sgd_solver.cpp:137] Iteration 49700, lr = 0.00689375, m = 0.9
I0628 22:39:30.560096  5893 solver.cpp:349] Iteration 49800 (5.42567 iter/s, 18.4309s/100 iter), loss = 1.30872
I0628 22:39:30.560117  5893 solver.cpp:371]     Train net output #0: loss = 1.04947 (* 1 = 1.04947 loss)
I0628 22:39:30.560122  5893 sgd_solver.cpp:137] Iteration 49800, lr = 0.0068875, m = 0.9
I0628 22:39:48.992700  5893 solver.cpp:349] Iteration 49900 (5.42534 iter/s, 18.432s/100 iter), loss = 1.53974
I0628 22:39:48.992746  5893 solver.cpp:371]     Train net output #0: loss = 2.01679 (* 1 = 2.01679 loss)
I0628 22:39:48.992751  5893 sgd_solver.cpp:137] Iteration 49900, lr = 0.00688125, m = 0.9
I0628 22:40:07.242177  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_50000.caffemodel
I0628 22:40:07.278054  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_50000.solverstate
I0628 22:40:07.282423  5893 solver.cpp:401] Sparsity after update:
I0628 22:40:07.283257  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:40:07.283264  5893 net.cpp:2170] conv1a_param_0(0.25) 
I0628 22:40:07.283270  5893 net.cpp:2170] conv1b_param_0(0.5) 
I0628 22:40:07.283272  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:40:07.283274  5893 net.cpp:2170] res2a_branch2a_param_0(0.5) 
I0628 22:40:07.283277  5893 net.cpp:2170] res2a_branch2b_param_0(0.5) 
I0628 22:40:07.283278  5893 net.cpp:2170] res3a_branch2a_param_0(0.5) 
I0628 22:40:07.283280  5893 net.cpp:2170] res3a_branch2b_param_0(0.5) 
I0628 22:40:07.283282  5893 net.cpp:2170] res4a_branch2a_param_0(0.5) 
I0628 22:40:07.283284  5893 net.cpp:2170] res4a_branch2b_param_0(0.5) 
I0628 22:40:07.283287  5893 net.cpp:2170] res5a_branch2a_param_0(0.5) 
I0628 22:40:07.283288  5893 net.cpp:2170] res5a_branch2b_param_0(0.5) 
I0628 22:40:07.283290  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.17678e+06/2.86678e+06) 0.41
I0628 22:40:07.283298  5893 solver.cpp:545] Iteration 50000, Testing net (#0)
I0628 22:40:31.516515  5888 data_reader.cpp:262] Starting prefetch of epoch 50
I0628 22:40:31.578357  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57936
I0628 22:40:31.578380  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.810641
I0628 22:40:31.578385  5893 solver.cpp:630]     Test net output #2: loss = 1.82872 (* 1 = 1.82872 loss)
I0628 22:40:31.578407  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2944s
I0628 22:40:31.763551  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.51
I0628 22:40:32.231014  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:40:32.232486  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:40:32.233160  5893 solver.cpp:349] Iteration 50000 (2.31272 iter/s, 43.2391s/100 iter), loss = 1.24228
I0628 22:40:32.233177  5893 solver.cpp:371]     Train net output #0: loss = 1.12958 (* 1 = 1.12958 loss)
I0628 22:40:32.233186  5893 sgd_solver.cpp:137] Iteration 50000, lr = 0.006875, m = 0.9
I0628 22:40:40.267210  5875 data_reader.cpp:262] Starting prefetch of epoch 10
I0628 22:40:50.662359  5893 solver.cpp:349] Iteration 50100 (5.42634 iter/s, 18.4286s/100 iter), loss = 1.55599
I0628 22:40:50.662384  5893 solver.cpp:371]     Train net output #0: loss = 1.35074 (* 1 = 1.35074 loss)
I0628 22:40:50.662387  5893 sgd_solver.cpp:137] Iteration 50100, lr = 0.00686875, m = 0.9
I0628 22:41:09.067394  5893 solver.cpp:349] Iteration 50200 (5.43347 iter/s, 18.4045s/100 iter), loss = 1.2063
I0628 22:41:09.067519  5893 solver.cpp:371]     Train net output #0: loss = 1.11209 (* 1 = 1.11209 loss)
I0628 22:41:09.067528  5893 sgd_solver.cpp:137] Iteration 50200, lr = 0.0068625, m = 0.9
I0628 22:41:27.466660  5893 solver.cpp:349] Iteration 50300 (5.43521 iter/s, 18.3986s/100 iter), loss = 1.07267
I0628 22:41:27.466682  5893 solver.cpp:371]     Train net output #0: loss = 0.963215 (* 1 = 0.963215 loss)
I0628 22:41:27.466687  5893 sgd_solver.cpp:137] Iteration 50300, lr = 0.00685625, m = 0.9
I0628 22:41:45.908943  5893 solver.cpp:349] Iteration 50400 (5.42249 iter/s, 18.4417s/100 iter), loss = 1.29164
I0628 22:41:45.909014  5893 solver.cpp:371]     Train net output #0: loss = 1.48866 (* 1 = 1.48866 loss)
I0628 22:41:45.909019  5893 sgd_solver.cpp:137] Iteration 50400, lr = 0.00685, m = 0.9
I0628 22:42:04.366143  5893 solver.cpp:349] Iteration 50500 (5.41813 iter/s, 18.4566s/100 iter), loss = 1.25073
I0628 22:42:04.366168  5893 solver.cpp:371]     Train net output #0: loss = 1.40463 (* 1 = 1.40463 loss)
I0628 22:42:04.366173  5893 sgd_solver.cpp:137] Iteration 50500, lr = 0.00684375, m = 0.9
I0628 22:42:22.785874  5893 solver.cpp:349] Iteration 50600 (5.42914 iter/s, 18.4191s/100 iter), loss = 1.24432
I0628 22:42:22.785959  5893 solver.cpp:371]     Train net output #0: loss = 1.31563 (* 1 = 1.31563 loss)
I0628 22:42:22.785965  5893 sgd_solver.cpp:137] Iteration 50600, lr = 0.0068375, m = 0.9
I0628 22:42:41.220391  5893 solver.cpp:349] Iteration 50700 (5.4248 iter/s, 18.4339s/100 iter), loss = 1.28858
I0628 22:42:41.220412  5893 solver.cpp:371]     Train net output #0: loss = 1.40688 (* 1 = 1.40688 loss)
I0628 22:42:41.220417  5893 sgd_solver.cpp:137] Iteration 50700, lr = 0.00683125, m = 0.9
I0628 22:42:59.669881  5893 solver.cpp:349] Iteration 50800 (5.42038 iter/s, 18.4489s/100 iter), loss = 1.42254
I0628 22:42:59.670902  5893 solver.cpp:371]     Train net output #0: loss = 1.32634 (* 1 = 1.32634 loss)
I0628 22:42:59.670907  5893 sgd_solver.cpp:137] Iteration 50800, lr = 0.006825, m = 0.9
I0628 22:43:18.130946  5893 solver.cpp:349] Iteration 50900 (5.41727 iter/s, 18.4595s/100 iter), loss = 0.876127
I0628 22:43:18.130969  5893 solver.cpp:371]     Train net output #0: loss = 0.910501 (* 1 = 0.910501 loss)
I0628 22:43:18.130972  5893 sgd_solver.cpp:137] Iteration 50900, lr = 0.00681875, m = 0.9
I0628 22:43:36.378842  5893 solver.cpp:401] Sparsity after update:
I0628 22:43:36.384030  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:43:36.384037  5893 net.cpp:2170] conv1a_param_0(0.255) 
I0628 22:43:36.384044  5893 net.cpp:2170] conv1b_param_0(0.51) 
I0628 22:43:36.384047  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:43:36.384048  5893 net.cpp:2170] res2a_branch2a_param_0(0.51) 
I0628 22:43:36.384050  5893 net.cpp:2170] res2a_branch2b_param_0(0.51) 
I0628 22:43:36.384053  5893 net.cpp:2170] res3a_branch2a_param_0(0.51) 
I0628 22:43:36.384055  5893 net.cpp:2170] res3a_branch2b_param_0(0.51) 
I0628 22:43:36.384057  5893 net.cpp:2170] res4a_branch2a_param_0(0.51) 
I0628 22:43:36.384059  5893 net.cpp:2170] res4a_branch2b_param_0(0.51) 
I0628 22:43:36.384061  5893 net.cpp:2170] res5a_branch2a_param_0(0.51) 
I0628 22:43:36.384063  5893 net.cpp:2170] res5a_branch2b_param_0(0.51) 
I0628 22:43:36.384065  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.20032e+06/2.86678e+06) 0.419
I0628 22:43:36.384073  5893 solver.cpp:545] Iteration 51000, Testing net (#0)
I0628 22:43:37.591012  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 22:44:00.544595  5888 data_reader.cpp:262] Starting prefetch of epoch 51
I0628 22:44:00.638592  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57728
I0628 22:44:00.638613  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811281
I0628 22:44:00.638618  5893 solver.cpp:630]     Test net output #2: loss = 1.82111 (* 1 = 1.82111 loss)
I0628 22:44:00.638634  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2538s
I0628 22:44:00.828846  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.52
I0628 22:44:01.302000  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:44:01.303457  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:44:01.304129  5893 solver.cpp:349] Iteration 51000 (2.31632 iter/s, 43.1718s/100 iter), loss = 1.38578
I0628 22:44:01.304143  5893 solver.cpp:371]     Train net output #0: loss = 1.19525 (* 1 = 1.19525 loss)
I0628 22:44:01.304148  5893 sgd_solver.cpp:137] Iteration 51000, lr = 0.0068125, m = 0.9
I0628 22:44:19.755718  5893 solver.cpp:349] Iteration 51100 (5.41976 iter/s, 18.451s/100 iter), loss = 1.60254
I0628 22:44:19.755796  5893 solver.cpp:371]     Train net output #0: loss = 1.82048 (* 1 = 1.82048 loss)
I0628 22:44:19.755801  5893 sgd_solver.cpp:137] Iteration 51100, lr = 0.00680625, m = 0.9
I0628 22:44:38.169082  5893 solver.cpp:349] Iteration 51200 (5.43103 iter/s, 18.4127s/100 iter), loss = 1.46355
I0628 22:44:38.169106  5893 solver.cpp:371]     Train net output #0: loss = 1.70745 (* 1 = 1.70745 loss)
I0628 22:44:38.169109  5893 sgd_solver.cpp:137] Iteration 51200, lr = 0.0068, m = 0.9
I0628 22:44:56.592890  5893 solver.cpp:349] Iteration 51300 (5.42794 iter/s, 18.4232s/100 iter), loss = 1.28653
I0628 22:44:56.592991  5893 solver.cpp:371]     Train net output #0: loss = 1.02033 (* 1 = 1.02033 loss)
I0628 22:44:56.592998  5893 sgd_solver.cpp:137] Iteration 51300, lr = 0.00679375, m = 0.9
I0628 22:45:15.027415  5893 solver.cpp:349] Iteration 51400 (5.42481 iter/s, 18.4338s/100 iter), loss = 1.37522
I0628 22:45:15.027436  5893 solver.cpp:371]     Train net output #0: loss = 1.51813 (* 1 = 1.51813 loss)
I0628 22:45:15.027441  5893 sgd_solver.cpp:137] Iteration 51400, lr = 0.0067875, m = 0.9
I0628 22:45:33.466042  5893 solver.cpp:349] Iteration 51500 (5.42358 iter/s, 18.438s/100 iter), loss = 1.37476
I0628 22:45:33.466141  5893 solver.cpp:371]     Train net output #0: loss = 1.46876 (* 1 = 1.46876 loss)
I0628 22:45:33.466148  5893 sgd_solver.cpp:137] Iteration 51500, lr = 0.00678125, m = 0.9
I0628 22:45:51.903791  5893 solver.cpp:349] Iteration 51600 (5.42386 iter/s, 18.4371s/100 iter), loss = 1.26944
I0628 22:45:51.903813  5893 solver.cpp:371]     Train net output #0: loss = 0.996726 (* 1 = 0.996726 loss)
I0628 22:45:51.903817  5893 sgd_solver.cpp:137] Iteration 51600, lr = 0.006775, m = 0.9
I0628 22:46:10.335206  5893 solver.cpp:349] Iteration 51700 (5.4257 iter/s, 18.4308s/100 iter), loss = 1.36111
I0628 22:46:10.335286  5893 solver.cpp:371]     Train net output #0: loss = 1.48133 (* 1 = 1.48133 loss)
I0628 22:46:10.335291  5893 sgd_solver.cpp:137] Iteration 51700, lr = 0.00676875, m = 0.9
I0628 22:46:28.764233  5893 solver.cpp:349] Iteration 51800 (5.42642 iter/s, 18.4284s/100 iter), loss = 1.19958
I0628 22:46:28.764257  5893 solver.cpp:371]     Train net output #0: loss = 1.23573 (* 1 = 1.23573 loss)
I0628 22:46:28.764261  5893 sgd_solver.cpp:137] Iteration 51800, lr = 0.0067625, m = 0.9
I0628 22:46:47.198581  5893 solver.cpp:349] Iteration 51900 (5.42484 iter/s, 18.4337s/100 iter), loss = 1.54487
I0628 22:46:47.198668  5893 solver.cpp:371]     Train net output #0: loss = 1.41528 (* 1 = 1.41528 loss)
I0628 22:46:47.198673  5893 sgd_solver.cpp:137] Iteration 51900, lr = 0.00675625, m = 0.9
I0628 22:47:05.461570  5893 solver.cpp:401] Sparsity after update:
I0628 22:47:05.466815  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:47:05.466832  5893 net.cpp:2170] conv1a_param_0(0.26) 
I0628 22:47:05.466837  5893 net.cpp:2170] conv1b_param_0(0.52) 
I0628 22:47:05.466840  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:47:05.466842  5893 net.cpp:2170] res2a_branch2a_param_0(0.52) 
I0628 22:47:05.466845  5893 net.cpp:2170] res2a_branch2b_param_0(0.52) 
I0628 22:47:05.466845  5893 net.cpp:2170] res3a_branch2a_param_0(0.52) 
I0628 22:47:05.466848  5893 net.cpp:2170] res3a_branch2b_param_0(0.52) 
I0628 22:47:05.466850  5893 net.cpp:2170] res4a_branch2a_param_0(0.52) 
I0628 22:47:05.466851  5893 net.cpp:2170] res4a_branch2b_param_0(0.52) 
I0628 22:47:05.466853  5893 net.cpp:2170] res5a_branch2a_param_0(0.52) 
I0628 22:47:05.466857  5893 net.cpp:2170] res5a_branch2b_param_0(0.52) 
I0628 22:47:05.466859  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.22386e+06/2.86678e+06) 0.427
I0628 22:47:05.466868  5893 solver.cpp:545] Iteration 52000, Testing net (#0)
I0628 22:47:29.649271  5888 data_reader.cpp:262] Starting prefetch of epoch 52
I0628 22:47:29.795852  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58256
I0628 22:47:29.795873  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.811881
I0628 22:47:29.795881  5893 solver.cpp:630]     Test net output #2: loss = 1.82138 (* 1 = 1.82138 loss)
I0628 22:47:29.795899  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3283s
I0628 22:47:29.980509  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.53
I0628 22:47:30.463692  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:47:30.465163  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:47:30.465850  5893 solver.cpp:349] Iteration 52000 (2.31129 iter/s, 43.2658s/100 iter), loss = 1.56429
I0628 22:47:30.465867  5893 solver.cpp:371]     Train net output #0: loss = 1.39707 (* 1 = 1.39707 loss)
I0628 22:47:30.465870  5893 sgd_solver.cpp:137] Iteration 52000, lr = 0.00675, m = 0.9
I0628 22:47:48.885143  5893 solver.cpp:349] Iteration 52100 (5.42927 iter/s, 18.4187s/100 iter), loss = 1.20889
I0628 22:47:48.885167  5893 solver.cpp:371]     Train net output #0: loss = 1.1871 (* 1 = 1.1871 loss)
I0628 22:47:48.885171  5893 sgd_solver.cpp:137] Iteration 52100, lr = 0.00674375, m = 0.9
I0628 22:48:07.317603  5893 solver.cpp:349] Iteration 52200 (5.4254 iter/s, 18.4318s/100 iter), loss = 1.51136
I0628 22:48:07.317713  5893 solver.cpp:371]     Train net output #0: loss = 1.34152 (* 1 = 1.34152 loss)
I0628 22:48:07.317721  5893 sgd_solver.cpp:137] Iteration 52200, lr = 0.0067375, m = 0.9
I0628 22:48:25.771039  5893 solver.cpp:349] Iteration 52300 (5.41926 iter/s, 18.4527s/100 iter), loss = 1.5122
I0628 22:48:25.771061  5893 solver.cpp:371]     Train net output #0: loss = 1.55252 (* 1 = 1.55252 loss)
I0628 22:48:25.771065  5893 sgd_solver.cpp:137] Iteration 52300, lr = 0.00673125, m = 0.9
I0628 22:48:44.216447  5893 solver.cpp:349] Iteration 52400 (5.42159 iter/s, 18.4448s/100 iter), loss = 1.80847
I0628 22:48:44.216547  5893 solver.cpp:371]     Train net output #0: loss = 1.61617 (* 1 = 1.61617 loss)
I0628 22:48:44.216553  5893 sgd_solver.cpp:137] Iteration 52400, lr = 0.006725, m = 0.9
I0628 22:49:02.629534  5893 solver.cpp:349] Iteration 52500 (5.43113 iter/s, 18.4124s/100 iter), loss = 1.52248
I0628 22:49:02.629562  5893 solver.cpp:371]     Train net output #0: loss = 1.37598 (* 1 = 1.37598 loss)
I0628 22:49:02.629566  5893 sgd_solver.cpp:137] Iteration 52500, lr = 0.00671875, m = 0.9
I0628 22:49:21.040686  5893 solver.cpp:349] Iteration 52600 (5.43168 iter/s, 18.4105s/100 iter), loss = 1.39117
I0628 22:49:21.040796  5893 solver.cpp:371]     Train net output #0: loss = 1.36698 (* 1 = 1.36698 loss)
I0628 22:49:21.040803  5893 sgd_solver.cpp:137] Iteration 52600, lr = 0.0067125, m = 0.9
I0628 22:49:39.457280  5893 solver.cpp:349] Iteration 52700 (5.4301 iter/s, 18.4159s/100 iter), loss = 1.51644
I0628 22:49:39.457305  5893 solver.cpp:371]     Train net output #0: loss = 1.47921 (* 1 = 1.47921 loss)
I0628 22:49:39.457310  5893 sgd_solver.cpp:137] Iteration 52700, lr = 0.00670625, m = 0.9
I0628 22:49:57.900231  5893 solver.cpp:349] Iteration 52800 (5.42231 iter/s, 18.4423s/100 iter), loss = 1.32429
I0628 22:49:57.900319  5893 solver.cpp:371]     Train net output #0: loss = 1.34797 (* 1 = 1.34797 loss)
I0628 22:49:57.900324  5893 sgd_solver.cpp:137] Iteration 52800, lr = 0.0067, m = 0.9
I0628 22:50:16.333225  5893 solver.cpp:349] Iteration 52900 (5.42526 iter/s, 18.4323s/100 iter), loss = 1.48715
I0628 22:50:16.333250  5893 solver.cpp:371]     Train net output #0: loss = 1.31444 (* 1 = 1.31444 loss)
I0628 22:50:16.333253  5893 sgd_solver.cpp:137] Iteration 52900, lr = 0.00669375, m = 0.9
I0628 22:50:34.590497  5893 solver.cpp:401] Sparsity after update:
I0628 22:50:34.595695  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:50:34.595703  5893 net.cpp:2170] conv1a_param_0(0.265) 
I0628 22:50:34.595710  5893 net.cpp:2170] conv1b_param_0(0.53) 
I0628 22:50:34.595712  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:50:34.595715  5893 net.cpp:2170] res2a_branch2a_param_0(0.53) 
I0628 22:50:34.595716  5893 net.cpp:2170] res2a_branch2b_param_0(0.53) 
I0628 22:50:34.595718  5893 net.cpp:2170] res3a_branch2a_param_0(0.53) 
I0628 22:50:34.595721  5893 net.cpp:2170] res3a_branch2b_param_0(0.53) 
I0628 22:50:34.595721  5893 net.cpp:2170] res4a_branch2a_param_0(0.53) 
I0628 22:50:34.595723  5893 net.cpp:2170] res4a_branch2b_param_0(0.53) 
I0628 22:50:34.595726  5893 net.cpp:2170] res5a_branch2a_param_0(0.53) 
I0628 22:50:34.595727  5893 net.cpp:2170] res5a_branch2b_param_0(0.53) 
I0628 22:50:34.595729  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.24739e+06/2.86678e+06) 0.435
I0628 22:50:34.595736  5893 solver.cpp:545] Iteration 53000, Testing net (#0)
I0628 22:50:58.850898  5888 data_reader.cpp:262] Starting prefetch of epoch 53
I0628 22:50:58.950300  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5764
I0628 22:50:58.950320  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809201
I0628 22:50:58.950325  5893 solver.cpp:630]     Test net output #2: loss = 1.83115 (* 1 = 1.83115 loss)
I0628 22:50:58.950341  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3538s
I0628 22:50:59.134598  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.54
I0628 22:50:59.625696  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:50:59.627169  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:50:59.627846  5893 solver.cpp:349] Iteration 53000 (2.30983 iter/s, 43.2932s/100 iter), loss = 1.23174
I0628 22:50:59.627864  5893 solver.cpp:371]     Train net output #0: loss = 1.10483 (* 1 = 1.10483 loss)
I0628 22:50:59.627869  5893 sgd_solver.cpp:137] Iteration 53000, lr = 0.0066875, m = 0.9
I0628 22:51:18.067733  5893 solver.cpp:349] Iteration 53100 (5.42321 iter/s, 18.4393s/100 iter), loss = 1.39911
I0628 22:51:18.067816  5893 solver.cpp:371]     Train net output #0: loss = 1.38965 (* 1 = 1.38965 loss)
I0628 22:51:18.067821  5893 sgd_solver.cpp:137] Iteration 53100, lr = 0.00668125, m = 0.9
I0628 22:51:36.492640  5893 solver.cpp:349] Iteration 53200 (5.42764 iter/s, 18.4242s/100 iter), loss = 1.27981
I0628 22:51:36.492664  5893 solver.cpp:371]     Train net output #0: loss = 1.32651 (* 1 = 1.32651 loss)
I0628 22:51:36.492668  5893 sgd_solver.cpp:137] Iteration 53200, lr = 0.006675, m = 0.9
I0628 22:51:54.928853  5893 solver.cpp:349] Iteration 53300 (5.4243 iter/s, 18.4356s/100 iter), loss = 1.36541
I0628 22:51:54.928942  5893 solver.cpp:371]     Train net output #0: loss = 1.34721 (* 1 = 1.34721 loss)
I0628 22:51:54.928947  5893 sgd_solver.cpp:137] Iteration 53300, lr = 0.00666875, m = 0.9
I0628 22:52:13.347690  5893 solver.cpp:349] Iteration 53400 (5.42943 iter/s, 18.4181s/100 iter), loss = 1.63744
I0628 22:52:13.347714  5893 solver.cpp:371]     Train net output #0: loss = 1.96728 (* 1 = 1.96728 loss)
I0628 22:52:13.347719  5893 sgd_solver.cpp:137] Iteration 53400, lr = 0.0066625, m = 0.9
I0628 22:52:31.781884  5893 solver.cpp:349] Iteration 53500 (5.42489 iter/s, 18.4335s/100 iter), loss = 1.60176
I0628 22:52:31.781998  5893 solver.cpp:371]     Train net output #0: loss = 1.68997 (* 1 = 1.68997 loss)
I0628 22:52:31.782006  5893 sgd_solver.cpp:137] Iteration 53500, lr = 0.00665625, m = 0.9
I0628 22:52:50.235582  5893 solver.cpp:349] Iteration 53600 (5.41919 iter/s, 18.453s/100 iter), loss = 1.63474
I0628 22:52:50.235607  5893 solver.cpp:371]     Train net output #0: loss = 1.56947 (* 1 = 1.56947 loss)
I0628 22:52:50.235611  5893 sgd_solver.cpp:137] Iteration 53600, lr = 0.00665, m = 0.9
I0628 22:53:08.671404  5893 solver.cpp:349] Iteration 53700 (5.42441 iter/s, 18.4352s/100 iter), loss = 1.37832
I0628 22:53:08.671504  5893 solver.cpp:371]     Train net output #0: loss = 1.41375 (* 1 = 1.41375 loss)
I0628 22:53:08.671511  5893 sgd_solver.cpp:137] Iteration 53700, lr = 0.00664375, m = 0.9
I0628 22:53:27.073011  5893 solver.cpp:349] Iteration 53800 (5.43452 iter/s, 18.4009s/100 iter), loss = 1.6944
I0628 22:53:27.073034  5893 solver.cpp:371]     Train net output #0: loss = 1.51505 (* 1 = 1.51505 loss)
I0628 22:53:27.073037  5893 sgd_solver.cpp:137] Iteration 53800, lr = 0.0066375, m = 0.9
I0628 22:53:45.479439  5893 solver.cpp:349] Iteration 53900 (5.43307 iter/s, 18.4058s/100 iter), loss = 1.44157
I0628 22:53:45.479542  5893 solver.cpp:371]     Train net output #0: loss = 1.7111 (* 1 = 1.7111 loss)
I0628 22:53:45.479550  5893 sgd_solver.cpp:137] Iteration 53900, lr = 0.00663125, m = 0.9
I0628 22:54:03.709501  5893 solver.cpp:401] Sparsity after update:
I0628 22:54:03.714758  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:54:03.714766  5893 net.cpp:2170] conv1a_param_0(0.27) 
I0628 22:54:03.714773  5893 net.cpp:2170] conv1b_param_0(0.54) 
I0628 22:54:03.714776  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:54:03.714777  5893 net.cpp:2170] res2a_branch2a_param_0(0.54) 
I0628 22:54:03.714779  5893 net.cpp:2170] res2a_branch2b_param_0(0.54) 
I0628 22:54:03.714781  5893 net.cpp:2170] res3a_branch2a_param_0(0.54) 
I0628 22:54:03.714783  5893 net.cpp:2170] res3a_branch2b_param_0(0.54) 
I0628 22:54:03.714785  5893 net.cpp:2170] res4a_branch2a_param_0(0.54) 
I0628 22:54:03.714787  5893 net.cpp:2170] res4a_branch2b_param_0(0.54) 
I0628 22:54:03.714788  5893 net.cpp:2170] res5a_branch2a_param_0(0.54) 
I0628 22:54:03.714790  5893 net.cpp:2170] res5a_branch2b_param_0(0.54) 
I0628 22:54:03.714792  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.27093e+06/2.86678e+06) 0.443
I0628 22:54:03.714799  5893 solver.cpp:545] Iteration 54000, Testing net (#0)
I0628 22:54:27.933884  5888 data_reader.cpp:262] Starting prefetch of epoch 54
I0628 22:54:27.997228  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5832
I0628 22:54:27.997251  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.81308
I0628 22:54:27.997256  5893 solver.cpp:630]     Test net output #2: loss = 1.80756 (* 1 = 1.80756 loss)
I0628 22:54:27.997275  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2817s
I0628 22:54:28.181598  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.55
I0628 22:54:28.688285  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:54:28.689767  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:54:28.690443  5893 solver.cpp:349] Iteration 54000 (2.31431 iter/s, 43.2094s/100 iter), loss = 1.50763
I0628 22:54:28.690461  5893 solver.cpp:371]     Train net output #0: loss = 1.54662 (* 1 = 1.54662 loss)
I0628 22:54:28.690466  5893 sgd_solver.cpp:137] Iteration 54000, lr = 0.006625, m = 0.9
I0628 22:54:47.104488  5893 solver.cpp:349] Iteration 54100 (5.43083 iter/s, 18.4134s/100 iter), loss = 1.25651
I0628 22:54:47.104512  5893 solver.cpp:371]     Train net output #0: loss = 1.14655 (* 1 = 1.14655 loss)
I0628 22:54:47.104516  5893 sgd_solver.cpp:137] Iteration 54100, lr = 0.00661875, m = 0.9
I0628 22:55:05.526394  5893 solver.cpp:349] Iteration 54200 (5.42851 iter/s, 18.4213s/100 iter), loss = 1.54199
I0628 22:55:05.526494  5893 solver.cpp:371]     Train net output #0: loss = 1.42512 (* 1 = 1.42512 loss)
I0628 22:55:05.526500  5893 sgd_solver.cpp:137] Iteration 54200, lr = 0.0066125, m = 0.9
I0628 22:55:23.944228  5893 solver.cpp:349] Iteration 54300 (5.42974 iter/s, 18.4171s/100 iter), loss = 1.65801
I0628 22:55:23.944250  5893 solver.cpp:371]     Train net output #0: loss = 1.39235 (* 1 = 1.39235 loss)
I0628 22:55:23.944254  5893 sgd_solver.cpp:137] Iteration 54300, lr = 0.00660625, m = 0.9
I0628 22:55:42.370654  5893 solver.cpp:349] Iteration 54400 (5.42718 iter/s, 18.4258s/100 iter), loss = 1.31015
I0628 22:55:42.370739  5893 solver.cpp:371]     Train net output #0: loss = 1.2599 (* 1 = 1.2599 loss)
I0628 22:55:42.370745  5893 sgd_solver.cpp:137] Iteration 54400, lr = 0.0066, m = 0.9
I0628 22:56:00.780414  5893 solver.cpp:349] Iteration 54500 (5.43211 iter/s, 18.409s/100 iter), loss = 1.3523
I0628 22:56:00.780437  5893 solver.cpp:371]     Train net output #0: loss = 1.25773 (* 1 = 1.25773 loss)
I0628 22:56:00.780441  5893 sgd_solver.cpp:137] Iteration 54500, lr = 0.00659375, m = 0.9
I0628 22:56:19.202884  5893 solver.cpp:349] Iteration 54600 (5.42835 iter/s, 18.4218s/100 iter), loss = 1.65608
I0628 22:56:19.202975  5893 solver.cpp:371]     Train net output #0: loss = 1.55767 (* 1 = 1.55767 loss)
I0628 22:56:19.202980  5893 sgd_solver.cpp:137] Iteration 54600, lr = 0.0065875, m = 0.9
I0628 22:56:37.643362  5893 solver.cpp:349] Iteration 54700 (5.42307 iter/s, 18.4397s/100 iter), loss = 1.31003
I0628 22:56:37.643385  5893 solver.cpp:371]     Train net output #0: loss = 1.45098 (* 1 = 1.45098 loss)
I0628 22:56:37.643389  5893 sgd_solver.cpp:137] Iteration 54700, lr = 0.00658125, m = 0.9
I0628 22:56:56.098523  5893 solver.cpp:349] Iteration 54800 (5.41873 iter/s, 18.4545s/100 iter), loss = 1.55326
I0628 22:56:56.098619  5893 solver.cpp:371]     Train net output #0: loss = 1.71262 (* 1 = 1.71262 loss)
I0628 22:56:56.098625  5893 sgd_solver.cpp:137] Iteration 54800, lr = 0.006575, m = 0.9
I0628 22:57:14.566627  5893 solver.cpp:349] Iteration 54900 (5.41496 iter/s, 18.4674s/100 iter), loss = 1.60306
I0628 22:57:14.566650  5893 solver.cpp:371]     Train net output #0: loss = 1.56718 (* 1 = 1.56718 loss)
I0628 22:57:14.566654  5893 sgd_solver.cpp:137] Iteration 54900, lr = 0.00656875, m = 0.9
I0628 22:57:32.812038  5893 solver.cpp:401] Sparsity after update:
I0628 22:57:32.817266  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 22:57:32.817275  5893 net.cpp:2170] conv1a_param_0(0.275) 
I0628 22:57:32.817281  5893 net.cpp:2170] conv1b_param_0(0.55) 
I0628 22:57:32.817283  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 22:57:32.817286  5893 net.cpp:2170] res2a_branch2a_param_0(0.55) 
I0628 22:57:32.817287  5893 net.cpp:2170] res2a_branch2b_param_0(0.55) 
I0628 22:57:32.817289  5893 net.cpp:2170] res3a_branch2a_param_0(0.55) 
I0628 22:57:32.817291  5893 net.cpp:2170] res3a_branch2b_param_0(0.55) 
I0628 22:57:32.817292  5893 net.cpp:2170] res4a_branch2a_param_0(0.55) 
I0628 22:57:32.817294  5893 net.cpp:2170] res4a_branch2b_param_0(0.55) 
I0628 22:57:32.817296  5893 net.cpp:2170] res5a_branch2a_param_0(0.55) 
I0628 22:57:32.817298  5893 net.cpp:2170] res5a_branch2b_param_0(0.55) 
I0628 22:57:32.817301  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.29446e+06/2.86678e+06) 0.452
I0628 22:57:32.817307  5893 solver.cpp:545] Iteration 55000, Testing net (#0)
I0628 22:57:57.065068  5888 data_reader.cpp:262] Starting prefetch of epoch 55
I0628 22:57:57.130991  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.58188
I0628 22:57:57.131016  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.814521
I0628 22:57:57.131022  5893 solver.cpp:630]     Test net output #2: loss = 1.80848 (* 1 = 1.80848 loss)
I0628 22:57:57.131047  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3129s
I0628 22:57:57.315945  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.56
I0628 22:57:57.830695  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 22:57:57.832172  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 22:57:57.832856  5893 solver.cpp:349] Iteration 55000 (2.31135 iter/s, 43.2647s/100 iter), loss = 1.13138
I0628 22:57:57.832875  5893 solver.cpp:371]     Train net output #0: loss = 1.13815 (* 1 = 1.13815 loss)
I0628 22:57:57.832883  5893 sgd_solver.cpp:137] Iteration 55000, lr = 0.0065625, m = 0.9
I0628 22:58:06.702502  5875 data_reader.cpp:262] Starting prefetch of epoch 11
I0628 22:58:16.254398  5893 solver.cpp:349] Iteration 55100 (5.42863 iter/s, 18.4209s/100 iter), loss = 1.71719
I0628 22:58:16.254417  5893 solver.cpp:371]     Train net output #0: loss = 1.52919 (* 1 = 1.52919 loss)
I0628 22:58:16.254421  5893 sgd_solver.cpp:137] Iteration 55100, lr = 0.00655625, m = 0.9
I0628 22:58:34.666651  5893 solver.cpp:349] Iteration 55200 (5.43136 iter/s, 18.4116s/100 iter), loss = 1.6443
I0628 22:58:34.666673  5893 solver.cpp:371]     Train net output #0: loss = 1.99037 (* 1 = 1.99037 loss)
I0628 22:58:34.666677  5893 sgd_solver.cpp:137] Iteration 55200, lr = 0.00655, m = 0.9
I0628 22:58:53.076985  5893 solver.cpp:349] Iteration 55300 (5.43193 iter/s, 18.4097s/100 iter), loss = 1.40882
I0628 22:58:53.077080  5893 solver.cpp:371]     Train net output #0: loss = 1.24946 (* 1 = 1.24946 loss)
I0628 22:58:53.077086  5893 sgd_solver.cpp:137] Iteration 55300, lr = 0.00654375, m = 0.9
I0628 22:59:11.485752  5893 solver.cpp:349] Iteration 55400 (5.43242 iter/s, 18.408s/100 iter), loss = 1.57025
I0628 22:59:11.485775  5893 solver.cpp:371]     Train net output #0: loss = 1.8632 (* 1 = 1.8632 loss)
I0628 22:59:11.485780  5893 sgd_solver.cpp:137] Iteration 55400, lr = 0.0065375, m = 0.9
I0628 22:59:29.907923  5893 solver.cpp:349] Iteration 55500 (5.42844 iter/s, 18.4215s/100 iter), loss = 1.49048
I0628 22:59:29.908881  5893 solver.cpp:371]     Train net output #0: loss = 1.37834 (* 1 = 1.37834 loss)
I0628 22:59:29.908905  5893 sgd_solver.cpp:137] Iteration 55500, lr = 0.00653125, m = 0.9
I0628 22:59:48.324612  5893 solver.cpp:349] Iteration 55600 (5.43034 iter/s, 18.415s/100 iter), loss = 1.36426
I0628 22:59:48.324637  5893 solver.cpp:371]     Train net output #0: loss = 1.30503 (* 1 = 1.30503 loss)
I0628 22:59:48.324641  5893 sgd_solver.cpp:137] Iteration 55600, lr = 0.006525, m = 0.9
I0628 23:00:06.730885  5893 solver.cpp:349] Iteration 55700 (5.43313 iter/s, 18.4056s/100 iter), loss = 1.42302
I0628 23:00:06.730978  5893 solver.cpp:371]     Train net output #0: loss = 1.2875 (* 1 = 1.2875 loss)
I0628 23:00:06.730985  5893 sgd_solver.cpp:137] Iteration 55700, lr = 0.00651875, m = 0.9
I0628 23:00:25.179402  5893 solver.cpp:349] Iteration 55800 (5.42071 iter/s, 18.4478s/100 iter), loss = 1.32529
I0628 23:00:25.179426  5893 solver.cpp:371]     Train net output #0: loss = 1.50852 (* 1 = 1.50852 loss)
I0628 23:00:25.179430  5893 sgd_solver.cpp:137] Iteration 55800, lr = 0.0065125, m = 0.9
I0628 23:00:43.618242  5893 solver.cpp:349] Iteration 55900 (5.42353 iter/s, 18.4382s/100 iter), loss = 1.25658
I0628 23:00:43.618324  5893 solver.cpp:371]     Train net output #0: loss = 1.18437 (* 1 = 1.18437 loss)
I0628 23:00:43.618329  5893 sgd_solver.cpp:137] Iteration 55900, lr = 0.00650625, m = 0.9
I0628 23:01:01.873939  5893 solver.cpp:401] Sparsity after update:
I0628 23:01:01.879137  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:01:01.879145  5893 net.cpp:2170] conv1a_param_0(0.28) 
I0628 23:01:01.879151  5893 net.cpp:2170] conv1b_param_0(0.56) 
I0628 23:01:01.879153  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:01:01.879156  5893 net.cpp:2170] res2a_branch2a_param_0(0.56) 
I0628 23:01:01.879158  5893 net.cpp:2170] res2a_branch2b_param_0(0.56) 
I0628 23:01:01.879160  5893 net.cpp:2170] res3a_branch2a_param_0(0.56) 
I0628 23:01:01.879161  5893 net.cpp:2170] res3a_branch2b_param_0(0.56) 
I0628 23:01:01.879163  5893 net.cpp:2170] res4a_branch2a_param_0(0.56) 
I0628 23:01:01.879165  5893 net.cpp:2170] res4a_branch2b_param_0(0.56) 
I0628 23:01:01.879168  5893 net.cpp:2170] res5a_branch2a_param_0(0.56) 
I0628 23:01:01.879169  5893 net.cpp:2170] res5a_branch2b_param_0(0.56) 
I0628 23:01:01.879171  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.318e+06/2.86678e+06) 0.46
I0628 23:01:01.879179  5893 solver.cpp:545] Iteration 56000, Testing net (#0)
I0628 23:01:03.252087  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 23:01:26.098739  5888 data_reader.cpp:262] Starting prefetch of epoch 56
I0628 23:01:26.161335  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5752
I0628 23:01:26.161357  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809001
I0628 23:01:26.161363  5893 solver.cpp:630]     Test net output #2: loss = 1.84084 (* 1 = 1.84084 loss)
I0628 23:01:26.161383  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2814s
I0628 23:01:26.346421  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.57
I0628 23:01:26.858904  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:01:26.860370  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:01:26.861043  5893 solver.cpp:349] Iteration 56000 (2.31261 iter/s, 43.2412s/100 iter), loss = 1.52409
I0628 23:01:26.861063  5893 solver.cpp:371]     Train net output #0: loss = 1.51644 (* 1 = 1.51644 loss)
I0628 23:01:26.861070  5893 sgd_solver.cpp:137] Iteration 56000, lr = 0.0065, m = 0.9
I0628 23:01:45.296022  5893 solver.cpp:349] Iteration 56100 (5.42467 iter/s, 18.4343s/100 iter), loss = 1.1044
I0628 23:01:45.296046  5893 solver.cpp:371]     Train net output #0: loss = 1.03641 (* 1 = 1.03641 loss)
I0628 23:01:45.296051  5893 sgd_solver.cpp:137] Iteration 56100, lr = 0.00649375, m = 0.9
I0628 23:02:03.703930  5893 solver.cpp:349] Iteration 56200 (5.43265 iter/s, 18.4072s/100 iter), loss = 1.26752
I0628 23:02:03.703979  5893 solver.cpp:371]     Train net output #0: loss = 1.38856 (* 1 = 1.38856 loss)
I0628 23:02:03.703984  5893 sgd_solver.cpp:137] Iteration 56200, lr = 0.0064875, m = 0.9
I0628 23:02:22.130585  5893 solver.cpp:349] Iteration 56300 (5.42713 iter/s, 18.4259s/100 iter), loss = 1.60561
I0628 23:02:22.130607  5893 solver.cpp:371]     Train net output #0: loss = 1.8615 (* 1 = 1.8615 loss)
I0628 23:02:22.130611  5893 sgd_solver.cpp:137] Iteration 56300, lr = 0.00648125, m = 0.9
I0628 23:02:40.604658  5893 solver.cpp:349] Iteration 56400 (5.41319 iter/s, 18.4734s/100 iter), loss = 1.23509
I0628 23:02:40.604725  5893 solver.cpp:371]     Train net output #0: loss = 1.18722 (* 1 = 1.18722 loss)
I0628 23:02:40.604730  5893 sgd_solver.cpp:137] Iteration 56400, lr = 0.006475, m = 0.9
I0628 23:02:59.057703  5893 solver.cpp:349] Iteration 56500 (5.41938 iter/s, 18.4523s/100 iter), loss = 1.34162
I0628 23:02:59.057725  5893 solver.cpp:371]     Train net output #0: loss = 1.08993 (* 1 = 1.08993 loss)
I0628 23:02:59.057730  5893 sgd_solver.cpp:137] Iteration 56500, lr = 0.00646875, m = 0.9
I0628 23:03:17.504956  5893 solver.cpp:349] Iteration 56600 (5.42107 iter/s, 18.4466s/100 iter), loss = 1.37632
I0628 23:03:17.505056  5893 solver.cpp:371]     Train net output #0: loss = 1.53783 (* 1 = 1.53783 loss)
I0628 23:03:17.505064  5893 sgd_solver.cpp:137] Iteration 56600, lr = 0.0064625, m = 0.9
I0628 23:03:35.945381  5893 solver.cpp:349] Iteration 56700 (5.4231 iter/s, 18.4396s/100 iter), loss = 1.26229
I0628 23:03:35.945402  5893 solver.cpp:371]     Train net output #0: loss = 1.12439 (* 1 = 1.12439 loss)
I0628 23:03:35.945406  5893 sgd_solver.cpp:137] Iteration 56700, lr = 0.00645625, m = 0.9
I0628 23:03:54.370277  5893 solver.cpp:349] Iteration 56800 (5.42764 iter/s, 18.4242s/100 iter), loss = 1.37543
I0628 23:03:54.370349  5893 solver.cpp:371]     Train net output #0: loss = 1.50668 (* 1 = 1.50668 loss)
I0628 23:03:54.370354  5893 sgd_solver.cpp:137] Iteration 56800, lr = 0.00645, m = 0.9
I0628 23:04:12.804956  5893 solver.cpp:349] Iteration 56900 (5.42478 iter/s, 18.4339s/100 iter), loss = 1.47775
I0628 23:04:12.804980  5893 solver.cpp:371]     Train net output #0: loss = 1.36051 (* 1 = 1.36051 loss)
I0628 23:04:12.804983  5893 sgd_solver.cpp:137] Iteration 56900, lr = 0.00644375, m = 0.9
I0628 23:04:31.040046  5893 solver.cpp:401] Sparsity after update:
I0628 23:04:31.045269  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:04:31.045279  5893 net.cpp:2170] conv1a_param_0(0.285) 
I0628 23:04:31.045289  5893 net.cpp:2170] conv1b_param_0(0.57) 
I0628 23:04:31.045294  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:04:31.045296  5893 net.cpp:2170] res2a_branch2a_param_0(0.57) 
I0628 23:04:31.045300  5893 net.cpp:2170] res2a_branch2b_param_0(0.57) 
I0628 23:04:31.045303  5893 net.cpp:2170] res3a_branch2a_param_0(0.57) 
I0628 23:04:31.045320  5893 net.cpp:2170] res3a_branch2b_param_0(0.57) 
I0628 23:04:31.045325  5893 net.cpp:2170] res4a_branch2a_param_0(0.57) 
I0628 23:04:31.045328  5893 net.cpp:2170] res4a_branch2b_param_0(0.57) 
I0628 23:04:31.045331  5893 net.cpp:2170] res5a_branch2a_param_0(0.57) 
I0628 23:04:31.045336  5893 net.cpp:2170] res5a_branch2b_param_0(0.57) 
I0628 23:04:31.045339  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.34153e+06/2.86678e+06) 0.468
I0628 23:04:31.045351  5893 solver.cpp:545] Iteration 57000, Testing net (#0)
I0628 23:04:55.248399  5888 data_reader.cpp:262] Starting prefetch of epoch 57
I0628 23:04:55.399225  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57532
I0628 23:04:55.399248  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80752
I0628 23:04:55.399253  5893 solver.cpp:630]     Test net output #2: loss = 1.84062 (* 1 = 1.84062 loss)
I0628 23:04:55.399271  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.353s
I0628 23:04:55.584054  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.58
I0628 23:04:56.101959  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:04:56.103425  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:04:56.104122  5893 solver.cpp:349] Iteration 57000 (2.3096 iter/s, 43.2976s/100 iter), loss = 1.38629
I0628 23:04:56.104138  5893 solver.cpp:371]     Train net output #0: loss = 1.56005 (* 1 = 1.56005 loss)
I0628 23:04:56.104143  5893 sgd_solver.cpp:137] Iteration 57000, lr = 0.0064375, m = 0.9
I0628 23:05:14.529925  5893 solver.cpp:349] Iteration 57100 (5.42738 iter/s, 18.4251s/100 iter), loss = 1.51981
I0628 23:05:14.530032  5893 solver.cpp:371]     Train net output #0: loss = 1.51735 (* 1 = 1.51735 loss)
I0628 23:05:14.530038  5893 sgd_solver.cpp:137] Iteration 57100, lr = 0.00643125, m = 0.9
I0628 23:05:32.945086  5893 solver.cpp:349] Iteration 57200 (5.43054 iter/s, 18.4144s/100 iter), loss = 1.43627
I0628 23:05:32.945108  5893 solver.cpp:371]     Train net output #0: loss = 1.24434 (* 1 = 1.24434 loss)
I0628 23:05:32.945112  5893 sgd_solver.cpp:137] Iteration 57200, lr = 0.006425, m = 0.9
I0628 23:05:51.394765  5893 solver.cpp:349] Iteration 57300 (5.42035 iter/s, 18.449s/100 iter), loss = 1.5443
I0628 23:05:51.394867  5893 solver.cpp:371]     Train net output #0: loss = 1.48467 (* 1 = 1.48467 loss)
I0628 23:05:51.394875  5893 sgd_solver.cpp:137] Iteration 57300, lr = 0.00641875, m = 0.9
I0628 23:06:09.835230  5893 solver.cpp:349] Iteration 57400 (5.42309 iter/s, 18.4397s/100 iter), loss = 1.46497
I0628 23:06:09.835248  5893 solver.cpp:371]     Train net output #0: loss = 1.51379 (* 1 = 1.51379 loss)
I0628 23:06:09.835253  5893 sgd_solver.cpp:137] Iteration 57400, lr = 0.0064125, m = 0.9
I0628 23:06:28.275944  5893 solver.cpp:349] Iteration 57500 (5.42299 iter/s, 18.44s/100 iter), loss = 1.45268
I0628 23:06:28.276048  5893 solver.cpp:371]     Train net output #0: loss = 1.64166 (* 1 = 1.64166 loss)
I0628 23:06:28.276056  5893 sgd_solver.cpp:137] Iteration 57500, lr = 0.00640625, m = 0.9
I0628 23:06:46.693428  5893 solver.cpp:349] Iteration 57600 (5.42986 iter/s, 18.4167s/100 iter), loss = 1.54685
I0628 23:06:46.693446  5893 solver.cpp:371]     Train net output #0: loss = 1.29677 (* 1 = 1.29677 loss)
I0628 23:06:46.693450  5893 sgd_solver.cpp:137] Iteration 57600, lr = 0.0064, m = 0.9
I0628 23:07:05.138073  5893 solver.cpp:349] Iteration 57700 (5.42183 iter/s, 18.4439s/100 iter), loss = 1.36611
I0628 23:07:05.138161  5893 solver.cpp:371]     Train net output #0: loss = 1.25075 (* 1 = 1.25075 loss)
I0628 23:07:05.138167  5893 sgd_solver.cpp:137] Iteration 57700, lr = 0.00639375, m = 0.9
I0628 23:07:23.589982  5893 solver.cpp:349] Iteration 57800 (5.41972 iter/s, 18.4511s/100 iter), loss = 1.45656
I0628 23:07:23.590004  5893 solver.cpp:371]     Train net output #0: loss = 1.64623 (* 1 = 1.64623 loss)
I0628 23:07:23.590009  5893 sgd_solver.cpp:137] Iteration 57800, lr = 0.0063875, m = 0.9
I0628 23:07:41.995803  5893 solver.cpp:349] Iteration 57900 (5.43327 iter/s, 18.4051s/100 iter), loss = 1.50227
I0628 23:07:41.995892  5893 solver.cpp:371]     Train net output #0: loss = 1.51292 (* 1 = 1.51292 loss)
I0628 23:07:41.995898  5893 sgd_solver.cpp:137] Iteration 57900, lr = 0.00638125, m = 0.9
I0628 23:08:00.289103  5893 solver.cpp:401] Sparsity after update:
I0628 23:08:00.294308  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:08:00.294317  5893 net.cpp:2170] conv1a_param_0(0.29) 
I0628 23:08:00.294322  5893 net.cpp:2170] conv1b_param_0(0.58) 
I0628 23:08:00.294324  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:08:00.294327  5893 net.cpp:2170] res2a_branch2a_param_0(0.58) 
I0628 23:08:00.294328  5893 net.cpp:2170] res2a_branch2b_param_0(0.58) 
I0628 23:08:00.294330  5893 net.cpp:2170] res3a_branch2a_param_0(0.58) 
I0628 23:08:00.294332  5893 net.cpp:2170] res3a_branch2b_param_0(0.58) 
I0628 23:08:00.294334  5893 net.cpp:2170] res4a_branch2a_param_0(0.58) 
I0628 23:08:00.294337  5893 net.cpp:2170] res4a_branch2b_param_0(0.58) 
I0628 23:08:00.294338  5893 net.cpp:2170] res5a_branch2a_param_0(0.58) 
I0628 23:08:00.294339  5893 net.cpp:2170] res5a_branch2b_param_0(0.58) 
I0628 23:08:00.294342  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.36507e+06/2.86678e+06) 0.476
I0628 23:08:00.294349  5893 solver.cpp:545] Iteration 58000, Testing net (#0)
I0628 23:08:24.693323  5888 data_reader.cpp:262] Starting prefetch of epoch 58
I0628 23:08:24.755419  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57872
I0628 23:08:24.755441  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.809161
I0628 23:08:24.755446  5893 solver.cpp:630]     Test net output #2: loss = 1.82769 (* 1 = 1.82769 loss)
I0628 23:08:24.755462  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4602s
I0628 23:08:24.940315  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.59
I0628 23:08:25.471103  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:08:25.472582  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:08:25.473263  5893 solver.cpp:349] Iteration 58000 (2.30013 iter/s, 43.4758s/100 iter), loss = 1.55595
I0628 23:08:25.473278  5893 solver.cpp:371]     Train net output #0: loss = 1.9039 (* 1 = 1.9039 loss)
I0628 23:08:25.473282  5893 sgd_solver.cpp:137] Iteration 58000, lr = 0.006375, m = 0.9
I0628 23:08:43.892784  5893 solver.cpp:349] Iteration 58100 (5.42923 iter/s, 18.4188s/100 iter), loss = 1.42175
I0628 23:08:43.892805  5893 solver.cpp:371]     Train net output #0: loss = 1.1403 (* 1 = 1.1403 loss)
I0628 23:08:43.892809  5893 sgd_solver.cpp:137] Iteration 58100, lr = 0.00636875, m = 0.9
I0628 23:09:02.320487  5893 solver.cpp:349] Iteration 58200 (5.42682 iter/s, 18.427s/100 iter), loss = 1.64285
I0628 23:09:02.320596  5893 solver.cpp:371]     Train net output #0: loss = 1.30972 (* 1 = 1.30972 loss)
I0628 23:09:02.320602  5893 sgd_solver.cpp:137] Iteration 58200, lr = 0.0063625, m = 0.9
I0628 23:09:20.742419  5893 solver.cpp:349] Iteration 58300 (5.42855 iter/s, 18.4211s/100 iter), loss = 1.27807
I0628 23:09:20.742441  5893 solver.cpp:371]     Train net output #0: loss = 1.25866 (* 1 = 1.25866 loss)
I0628 23:09:20.742445  5893 sgd_solver.cpp:137] Iteration 58300, lr = 0.00635625, m = 0.9
I0628 23:09:39.175230  5893 solver.cpp:349] Iteration 58400 (5.42532 iter/s, 18.4321s/100 iter), loss = 1.55544
I0628 23:09:39.175343  5893 solver.cpp:371]     Train net output #0: loss = 1.47667 (* 1 = 1.47667 loss)
I0628 23:09:39.175349  5893 sgd_solver.cpp:137] Iteration 58400, lr = 0.00635, m = 0.9
I0628 23:09:57.585834  5893 solver.cpp:349] Iteration 58500 (5.43189 iter/s, 18.4098s/100 iter), loss = 1.71686
I0628 23:09:57.585857  5893 solver.cpp:371]     Train net output #0: loss = 1.53559 (* 1 = 1.53559 loss)
I0628 23:09:57.585861  5893 sgd_solver.cpp:137] Iteration 58500, lr = 0.00634375, m = 0.9
I0628 23:10:16.003221  5893 solver.cpp:349] Iteration 58600 (5.42983 iter/s, 18.4168s/100 iter), loss = 1.50782
I0628 23:10:16.003320  5893 solver.cpp:371]     Train net output #0: loss = 1.82702 (* 1 = 1.82702 loss)
I0628 23:10:16.003326  5893 sgd_solver.cpp:137] Iteration 58600, lr = 0.0063375, m = 0.9
I0628 23:10:34.420238  5893 solver.cpp:349] Iteration 58700 (5.42995 iter/s, 18.4164s/100 iter), loss = 1.44853
I0628 23:10:34.420261  5893 solver.cpp:371]     Train net output #0: loss = 1.60107 (* 1 = 1.60107 loss)
I0628 23:10:34.420266  5893 sgd_solver.cpp:137] Iteration 58700, lr = 0.00633125, m = 0.9
I0628 23:10:52.830090  5893 solver.cpp:349] Iteration 58800 (5.43204 iter/s, 18.4093s/100 iter), loss = 1.38177
I0628 23:10:52.830186  5893 solver.cpp:371]     Train net output #0: loss = 1.37946 (* 1 = 1.37946 loss)
I0628 23:10:52.830193  5893 sgd_solver.cpp:137] Iteration 58800, lr = 0.006325, m = 0.9
I0628 23:11:11.269001  5893 solver.cpp:349] Iteration 58900 (5.4235 iter/s, 18.4383s/100 iter), loss = 1.52538
I0628 23:11:11.269024  5893 solver.cpp:371]     Train net output #0: loss = 1.71869 (* 1 = 1.71869 loss)
I0628 23:11:11.269028  5893 sgd_solver.cpp:137] Iteration 58900, lr = 0.00631875, m = 0.9
I0628 23:11:29.511538  5893 solver.cpp:401] Sparsity after update:
I0628 23:11:29.516746  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:11:29.516753  5893 net.cpp:2170] conv1a_param_0(0.295) 
I0628 23:11:29.516759  5893 net.cpp:2170] conv1b_param_0(0.59) 
I0628 23:11:29.516762  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:11:29.516763  5893 net.cpp:2170] res2a_branch2a_param_0(0.59) 
I0628 23:11:29.516765  5893 net.cpp:2170] res2a_branch2b_param_0(0.59) 
I0628 23:11:29.516767  5893 net.cpp:2170] res3a_branch2a_param_0(0.59) 
I0628 23:11:29.516769  5893 net.cpp:2170] res3a_branch2b_param_0(0.59) 
I0628 23:11:29.516772  5893 net.cpp:2170] res4a_branch2a_param_0(0.59) 
I0628 23:11:29.516773  5893 net.cpp:2170] res4a_branch2b_param_0(0.59) 
I0628 23:11:29.516775  5893 net.cpp:2170] res5a_branch2a_param_0(0.59) 
I0628 23:11:29.516777  5893 net.cpp:2170] res5a_branch2b_param_0(0.59) 
I0628 23:11:29.516779  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.3886e+06/2.86678e+06) 0.484
I0628 23:11:29.516786  5893 solver.cpp:545] Iteration 59000, Testing net (#0)
I0628 23:11:53.699244  5888 data_reader.cpp:262] Starting prefetch of epoch 59
I0628 23:11:53.761144  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57912
I0628 23:11:53.761169  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.810241
I0628 23:11:53.761174  5893 solver.cpp:630]     Test net output #2: loss = 1.82672 (* 1 = 1.82672 loss)
I0628 23:11:53.761194  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2437s
I0628 23:11:53.946682  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.6
I0628 23:11:54.482882  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:11:54.484350  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:11:54.485020  5893 solver.cpp:349] Iteration 59000 (2.31402 iter/s, 43.2148s/100 iter), loss = 1.40162
I0628 23:11:54.485038  5893 solver.cpp:371]     Train net output #0: loss = 1.28145 (* 1 = 1.28145 loss)
I0628 23:11:54.485044  5893 sgd_solver.cpp:137] Iteration 59000, lr = 0.0063125, m = 0.9
I0628 23:12:12.901698  5893 solver.cpp:349] Iteration 59100 (5.43003 iter/s, 18.4161s/100 iter), loss = 1.41737
I0628 23:12:12.901811  5893 solver.cpp:371]     Train net output #0: loss = 1.3648 (* 1 = 1.3648 loss)
I0628 23:12:12.901818  5893 sgd_solver.cpp:137] Iteration 59100, lr = 0.00630625, m = 0.9
I0628 23:12:31.368813  5893 solver.cpp:349] Iteration 59200 (5.41523 iter/s, 18.4665s/100 iter), loss = 1.63177
I0628 23:12:31.368834  5893 solver.cpp:371]     Train net output #0: loss = 1.51005 (* 1 = 1.51005 loss)
I0628 23:12:31.368837  5893 sgd_solver.cpp:137] Iteration 59200, lr = 0.0063, m = 0.9
I0628 23:12:49.804159  5893 solver.cpp:349] Iteration 59300 (5.42453 iter/s, 18.4348s/100 iter), loss = 1.46269
I0628 23:12:49.804261  5893 solver.cpp:371]     Train net output #0: loss = 1.35441 (* 1 = 1.35441 loss)
I0628 23:12:49.804267  5893 sgd_solver.cpp:137] Iteration 59300, lr = 0.00629375, m = 0.9
I0628 23:13:08.264538  5893 solver.cpp:349] Iteration 59400 (5.4172 iter/s, 18.4597s/100 iter), loss = 1.5639
I0628 23:13:08.264561  5893 solver.cpp:371]     Train net output #0: loss = 1.60846 (* 1 = 1.60846 loss)
I0628 23:13:08.264565  5893 sgd_solver.cpp:137] Iteration 59400, lr = 0.0062875, m = 0.9
I0628 23:13:26.672897  5893 solver.cpp:349] Iteration 59500 (5.43248 iter/s, 18.4078s/100 iter), loss = 1.25863
I0628 23:13:26.672987  5893 solver.cpp:371]     Train net output #0: loss = 1.45411 (* 1 = 1.45411 loss)
I0628 23:13:26.672992  5893 sgd_solver.cpp:137] Iteration 59500, lr = 0.00628125, m = 0.9
I0628 23:13:45.133066  5893 solver.cpp:349] Iteration 59600 (5.41726 iter/s, 18.4595s/100 iter), loss = 1.31849
I0628 23:13:45.133088  5893 solver.cpp:371]     Train net output #0: loss = 1.20303 (* 1 = 1.20303 loss)
I0628 23:13:45.133092  5893 sgd_solver.cpp:137] Iteration 59600, lr = 0.006275, m = 0.9
I0628 23:14:03.571583  5893 solver.cpp:349] Iteration 59700 (5.4236 iter/s, 18.4379s/100 iter), loss = 1.84267
I0628 23:14:03.571630  5893 solver.cpp:371]     Train net output #0: loss = 1.74858 (* 1 = 1.74858 loss)
I0628 23:14:03.571635  5893 sgd_solver.cpp:137] Iteration 59700, lr = 0.00626875, m = 0.9
I0628 23:14:22.006124  5893 solver.cpp:349] Iteration 59800 (5.42478 iter/s, 18.4339s/100 iter), loss = 1.466
I0628 23:14:22.006146  5893 solver.cpp:371]     Train net output #0: loss = 1.38374 (* 1 = 1.38374 loss)
I0628 23:14:22.006150  5893 sgd_solver.cpp:137] Iteration 59800, lr = 0.0062625, m = 0.9
I0628 23:14:40.444849  5893 solver.cpp:349] Iteration 59900 (5.42354 iter/s, 18.4381s/100 iter), loss = 1.353
I0628 23:14:40.444952  5893 solver.cpp:371]     Train net output #0: loss = 1.37924 (* 1 = 1.37924 loss)
I0628 23:14:40.444958  5893 sgd_solver.cpp:137] Iteration 59900, lr = 0.00625625, m = 0.9
I0628 23:14:58.732494  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_60000.caffemodel
I0628 23:14:58.743147  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_60000.solverstate
I0628 23:14:58.747545  5893 solver.cpp:401] Sparsity after update:
I0628 23:14:58.748435  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:14:58.748445  5893 net.cpp:2170] conv1a_param_0(0.3) 
I0628 23:14:58.748450  5893 net.cpp:2170] conv1b_param_0(0.6) 
I0628 23:14:58.748452  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:14:58.748455  5893 net.cpp:2170] res2a_branch2a_param_0(0.6) 
I0628 23:14:58.748456  5893 net.cpp:2170] res2a_branch2b_param_0(0.6) 
I0628 23:14:58.748458  5893 net.cpp:2170] res3a_branch2a_param_0(0.6) 
I0628 23:14:58.748461  5893 net.cpp:2170] res3a_branch2b_param_0(0.6) 
I0628 23:14:58.748463  5893 net.cpp:2170] res4a_branch2a_param_0(0.6) 
I0628 23:14:58.748466  5893 net.cpp:2170] res4a_branch2b_param_0(0.6) 
I0628 23:14:58.748467  5893 net.cpp:2170] res5a_branch2a_param_0(0.6) 
I0628 23:14:58.748468  5893 net.cpp:2170] res5a_branch2b_param_0(0.6) 
I0628 23:14:58.748471  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.41214e+06/2.86678e+06) 0.493
I0628 23:14:58.748479  5893 solver.cpp:545] Iteration 60000, Testing net (#0)
I0628 23:15:22.925834  5888 data_reader.cpp:262] Starting prefetch of epoch 60
I0628 23:15:23.020309  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57904
I0628 23:15:23.020334  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.808241
I0628 23:15:23.020342  5893 solver.cpp:630]     Test net output #2: loss = 1.83016 (* 1 = 1.83016 loss)
I0628 23:15:23.020367  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2712s
I0628 23:15:23.207069  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.61
I0628 23:15:23.755759  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:15:23.757225  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:15:23.757899  5893 solver.cpp:349] Iteration 60000 (2.30885 iter/s, 43.3117s/100 iter), loss = 1.76337
I0628 23:15:23.757917  5893 solver.cpp:371]     Train net output #0: loss = 1.74104 (* 1 = 1.74104 loss)
I0628 23:15:23.757922  5893 sgd_solver.cpp:137] Iteration 60000, lr = 0.00625, m = 0.9
I0628 23:15:33.494967  5875 data_reader.cpp:262] Starting prefetch of epoch 12
I0628 23:15:42.193490  5893 solver.cpp:349] Iteration 60100 (5.42446 iter/s, 18.435s/100 iter), loss = 1.36612
I0628 23:15:42.193514  5893 solver.cpp:371]     Train net output #0: loss = 1.52056 (* 1 = 1.52056 loss)
I0628 23:15:42.193518  5893 sgd_solver.cpp:137] Iteration 60100, lr = 0.00624375, m = 0.9
I0628 23:16:00.632884  5893 solver.cpp:349] Iteration 60200 (5.42334 iter/s, 18.4388s/100 iter), loss = 1.4337
I0628 23:16:00.632985  5893 solver.cpp:371]     Train net output #0: loss = 1.37237 (* 1 = 1.37237 loss)
I0628 23:16:00.632992  5893 sgd_solver.cpp:137] Iteration 60200, lr = 0.0062375, m = 0.9
I0628 23:16:19.058619  5893 solver.cpp:349] Iteration 60300 (5.42739 iter/s, 18.4251s/100 iter), loss = 1.39353
I0628 23:16:19.058639  5893 solver.cpp:371]     Train net output #0: loss = 1.51899 (* 1 = 1.51899 loss)
I0628 23:16:19.058642  5893 sgd_solver.cpp:137] Iteration 60300, lr = 0.00623125, m = 0.9
I0628 23:16:37.499415  5893 solver.cpp:349] Iteration 60400 (5.42293 iter/s, 18.4402s/100 iter), loss = 1.60636
I0628 23:16:37.499492  5893 solver.cpp:371]     Train net output #0: loss = 1.49541 (* 1 = 1.49541 loss)
I0628 23:16:37.499496  5893 sgd_solver.cpp:137] Iteration 60400, lr = 0.006225, m = 0.9
I0628 23:16:55.949084  5893 solver.cpp:349] Iteration 60500 (5.42034 iter/s, 18.449s/100 iter), loss = 1.59982
I0628 23:16:55.949105  5893 solver.cpp:371]     Train net output #0: loss = 1.48012 (* 1 = 1.48012 loss)
I0628 23:16:55.949110  5893 sgd_solver.cpp:137] Iteration 60500, lr = 0.00621875, m = 0.9
I0628 23:17:14.384897  5893 solver.cpp:349] Iteration 60600 (5.4244 iter/s, 18.4352s/100 iter), loss = 1.47224
I0628 23:17:14.385009  5893 solver.cpp:371]     Train net output #0: loss = 1.49939 (* 1 = 1.49939 loss)
I0628 23:17:14.385015  5893 sgd_solver.cpp:137] Iteration 60600, lr = 0.0062125, m = 0.9
I0628 23:17:32.797911  5893 solver.cpp:349] Iteration 60700 (5.43114 iter/s, 18.4123s/100 iter), loss = 1.37787
I0628 23:17:32.797935  5893 solver.cpp:371]     Train net output #0: loss = 1.51414 (* 1 = 1.51414 loss)
I0628 23:17:32.797940  5893 sgd_solver.cpp:137] Iteration 60700, lr = 0.00620625, m = 0.9
I0628 23:17:51.219460  5893 solver.cpp:349] Iteration 60800 (5.4286 iter/s, 18.421s/100 iter), loss = 1.70651
I0628 23:17:51.219560  5893 solver.cpp:371]     Train net output #0: loss = 1.69771 (* 1 = 1.69771 loss)
I0628 23:17:51.219568  5893 sgd_solver.cpp:137] Iteration 60800, lr = 0.0062, m = 0.9
I0628 23:18:09.658711  5893 solver.cpp:349] Iteration 60900 (5.42341 iter/s, 18.4386s/100 iter), loss = 1.50197
I0628 23:18:09.658732  5893 solver.cpp:371]     Train net output #0: loss = 1.78151 (* 1 = 1.78151 loss)
I0628 23:18:09.658737  5893 sgd_solver.cpp:137] Iteration 60900, lr = 0.00619375, m = 0.9
I0628 23:18:27.891291  5893 solver.cpp:401] Sparsity after update:
I0628 23:18:27.896463  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:18:27.896472  5893 net.cpp:2170] conv1a_param_0(0.305) 
I0628 23:18:27.896481  5893 net.cpp:2170] conv1b_param_0(0.61) 
I0628 23:18:27.896482  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:18:27.896484  5893 net.cpp:2170] res2a_branch2a_param_0(0.61) 
I0628 23:18:27.896486  5893 net.cpp:2170] res2a_branch2b_param_0(0.61) 
I0628 23:18:27.896488  5893 net.cpp:2170] res3a_branch2a_param_0(0.61) 
I0628 23:18:27.896491  5893 net.cpp:2170] res3a_branch2b_param_0(0.61) 
I0628 23:18:27.896499  5893 net.cpp:2170] res4a_branch2a_param_0(0.61) 
I0628 23:18:27.896500  5893 net.cpp:2170] res4a_branch2b_param_0(0.61) 
I0628 23:18:27.896502  5893 net.cpp:2170] res5a_branch2a_param_0(0.61) 
I0628 23:18:27.896504  5893 net.cpp:2170] res5a_branch2b_param_0(0.61) 
I0628 23:18:27.896509  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.43568e+06/2.86678e+06) 0.501
I0628 23:18:27.896518  5893 solver.cpp:545] Iteration 61000, Testing net (#0)
I0628 23:18:29.376669  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 23:18:52.221181  5888 data_reader.cpp:262] Starting prefetch of epoch 61
I0628 23:18:52.283445  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57192
I0628 23:18:52.283469  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.805881
I0628 23:18:52.283474  5893 solver.cpp:630]     Test net output #2: loss = 1.84461 (* 1 = 1.84461 loss)
I0628 23:18:52.283491  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3862s
I0628 23:18:52.469831  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.62
I0628 23:18:53.023248  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:18:53.024713  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:18:53.025390  5893 solver.cpp:349] Iteration 61000 (2.30599 iter/s, 43.3653s/100 iter), loss = 1.31016
I0628 23:18:53.025408  5893 solver.cpp:371]     Train net output #0: loss = 1.38771 (* 1 = 1.38771 loss)
I0628 23:18:53.025414  5893 sgd_solver.cpp:137] Iteration 61000, lr = 0.0061875, m = 0.9
I0628 23:19:11.454665  5893 solver.cpp:349] Iteration 61100 (5.42632 iter/s, 18.4287s/100 iter), loss = 1.17845
I0628 23:19:11.454710  5893 solver.cpp:371]     Train net output #0: loss = 1.27865 (* 1 = 1.27865 loss)
I0628 23:19:11.454715  5893 sgd_solver.cpp:137] Iteration 61100, lr = 0.00618125, m = 0.9
I0628 23:19:29.888088  5893 solver.cpp:349] Iteration 61200 (5.42511 iter/s, 18.4328s/100 iter), loss = 1.70063
I0628 23:19:29.888111  5893 solver.cpp:371]     Train net output #0: loss = 1.68614 (* 1 = 1.68614 loss)
I0628 23:19:29.888116  5893 sgd_solver.cpp:137] Iteration 61200, lr = 0.006175, m = 0.9
I0628 23:19:48.300627  5893 solver.cpp:349] Iteration 61300 (5.43126 iter/s, 18.4119s/100 iter), loss = 1.61063
I0628 23:19:48.300701  5893 solver.cpp:371]     Train net output #0: loss = 1.31536 (* 1 = 1.31536 loss)
I0628 23:19:48.300706  5893 sgd_solver.cpp:137] Iteration 61300, lr = 0.00616875, m = 0.9
I0628 23:20:06.704519  5893 solver.cpp:349] Iteration 61400 (5.43383 iter/s, 18.4032s/100 iter), loss = 1.51156
I0628 23:20:06.704543  5893 solver.cpp:371]     Train net output #0: loss = 1.49905 (* 1 = 1.49905 loss)
I0628 23:20:06.704547  5893 sgd_solver.cpp:137] Iteration 61400, lr = 0.0061625, m = 0.9
I0628 23:20:25.110013  5893 solver.cpp:349] Iteration 61500 (5.43334 iter/s, 18.4049s/100 iter), loss = 1.32507
I0628 23:20:25.110097  5893 solver.cpp:371]     Train net output #0: loss = 1.36689 (* 1 = 1.36689 loss)
I0628 23:20:25.110102  5893 sgd_solver.cpp:137] Iteration 61500, lr = 0.00615625, m = 0.9
I0628 23:20:43.545728  5893 solver.cpp:349] Iteration 61600 (5.42445 iter/s, 18.435s/100 iter), loss = 1.42727
I0628 23:20:43.545753  5893 solver.cpp:371]     Train net output #0: loss = 1.34973 (* 1 = 1.34973 loss)
I0628 23:20:43.545756  5893 sgd_solver.cpp:137] Iteration 61600, lr = 0.00615, m = 0.9
I0628 23:21:01.992504  5893 solver.cpp:349] Iteration 61700 (5.42118 iter/s, 18.4462s/100 iter), loss = 1.32428
I0628 23:21:01.992599  5893 solver.cpp:371]     Train net output #0: loss = 1.30141 (* 1 = 1.30141 loss)
I0628 23:21:01.992604  5893 sgd_solver.cpp:137] Iteration 61700, lr = 0.00614375, m = 0.9
I0628 23:21:20.420131  5893 solver.cpp:349] Iteration 61800 (5.42684 iter/s, 18.4269s/100 iter), loss = 1.5378
I0628 23:21:20.420156  5893 solver.cpp:371]     Train net output #0: loss = 1.35481 (* 1 = 1.35481 loss)
I0628 23:21:20.420161  5893 sgd_solver.cpp:137] Iteration 61800, lr = 0.0061375, m = 0.9
I0628 23:21:38.892024  5893 solver.cpp:349] Iteration 61900 (5.4138 iter/s, 18.4713s/100 iter), loss = 1.37297
I0628 23:21:38.892096  5893 solver.cpp:371]     Train net output #0: loss = 1.47374 (* 1 = 1.47374 loss)
I0628 23:21:38.892102  5893 sgd_solver.cpp:137] Iteration 61900, lr = 0.00613125, m = 0.9
I0628 23:21:57.145814  5893 solver.cpp:401] Sparsity after update:
I0628 23:21:57.151059  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:21:57.151068  5893 net.cpp:2170] conv1a_param_0(0.31) 
I0628 23:21:57.151074  5893 net.cpp:2170] conv1b_param_0(0.62) 
I0628 23:21:57.151077  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:21:57.151078  5893 net.cpp:2170] res2a_branch2a_param_0(0.62) 
I0628 23:21:57.151080  5893 net.cpp:2170] res2a_branch2b_param_0(0.62) 
I0628 23:21:57.151082  5893 net.cpp:2170] res3a_branch2a_param_0(0.62) 
I0628 23:21:57.151084  5893 net.cpp:2170] res3a_branch2b_param_0(0.62) 
I0628 23:21:57.151087  5893 net.cpp:2170] res4a_branch2a_param_0(0.62) 
I0628 23:21:57.151088  5893 net.cpp:2170] res4a_branch2b_param_0(0.62) 
I0628 23:21:57.151089  5893 net.cpp:2170] res5a_branch2a_param_0(0.62) 
I0628 23:21:57.151091  5893 net.cpp:2170] res5a_branch2b_param_0(0.62) 
I0628 23:21:57.151093  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.45921e+06/2.86678e+06) 0.509
I0628 23:21:57.151100  5893 solver.cpp:545] Iteration 62000, Testing net (#0)
I0628 23:22:21.483557  5888 data_reader.cpp:262] Starting prefetch of epoch 62
I0628 23:22:21.575130  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57552
I0628 23:22:21.575150  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80624
I0628 23:22:21.575155  5893 solver.cpp:630]     Test net output #2: loss = 1.84715 (* 1 = 1.84715 loss)
I0628 23:22:21.575171  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4234s
I0628 23:22:21.760211  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.63
I0628 23:22:22.321135  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:22:22.322613  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:22:22.323287  5893 solver.cpp:349] Iteration 62000 (2.30256 iter/s, 43.43s/100 iter), loss = 1.48273
I0628 23:22:22.323305  5893 solver.cpp:371]     Train net output #0: loss = 1.60829 (* 1 = 1.60829 loss)
I0628 23:22:22.323310  5893 sgd_solver.cpp:137] Iteration 62000, lr = 0.006125, m = 0.9
I0628 23:22:40.733757  5893 solver.cpp:349] Iteration 62100 (5.43186 iter/s, 18.4099s/100 iter), loss = 1.39747
I0628 23:22:40.733777  5893 solver.cpp:371]     Train net output #0: loss = 1.34484 (* 1 = 1.34484 loss)
I0628 23:22:40.733781  5893 sgd_solver.cpp:137] Iteration 62100, lr = 0.00611875, m = 0.9
I0628 23:22:59.164119  5893 solver.cpp:349] Iteration 62200 (5.42599 iter/s, 18.4298s/100 iter), loss = 1.50526
I0628 23:22:59.164227  5893 solver.cpp:371]     Train net output #0: loss = 1.62627 (* 1 = 1.62627 loss)
I0628 23:22:59.164233  5893 sgd_solver.cpp:137] Iteration 62200, lr = 0.0061125, m = 0.9
I0628 23:23:17.591015  5893 solver.cpp:349] Iteration 62300 (5.42704 iter/s, 18.4262s/100 iter), loss = 1.3655
I0628 23:23:17.591039  5893 solver.cpp:371]     Train net output #0: loss = 1.20087 (* 1 = 1.20087 loss)
I0628 23:23:17.591043  5893 sgd_solver.cpp:137] Iteration 62300, lr = 0.00610625, m = 0.9
I0628 23:23:36.035025  5893 solver.cpp:349] Iteration 62400 (5.42198 iter/s, 18.4434s/100 iter), loss = 1.40636
I0628 23:23:36.035102  5893 solver.cpp:371]     Train net output #0: loss = 1.39832 (* 1 = 1.39832 loss)
I0628 23:23:36.035107  5893 sgd_solver.cpp:137] Iteration 62400, lr = 0.0061, m = 0.9
I0628 23:23:54.476029  5893 solver.cpp:349] Iteration 62500 (5.42288 iter/s, 18.4404s/100 iter), loss = 0.897665
I0628 23:23:54.476053  5893 solver.cpp:371]     Train net output #0: loss = 0.91848 (* 1 = 0.91848 loss)
I0628 23:23:54.476058  5893 sgd_solver.cpp:137] Iteration 62500, lr = 0.00609375, m = 0.9
I0628 23:24:12.916751  5893 solver.cpp:349] Iteration 62600 (5.42295 iter/s, 18.4402s/100 iter), loss = 1.26474
I0628 23:24:12.916854  5893 solver.cpp:371]     Train net output #0: loss = 1.43049 (* 1 = 1.43049 loss)
I0628 23:24:12.916860  5893 sgd_solver.cpp:137] Iteration 62600, lr = 0.0060875, m = 0.9
I0628 23:24:31.361822  5893 solver.cpp:349] Iteration 62700 (5.4217 iter/s, 18.4444s/100 iter), loss = 1.46133
I0628 23:24:31.361846  5893 solver.cpp:371]     Train net output #0: loss = 1.49534 (* 1 = 1.49534 loss)
I0628 23:24:31.361852  5893 sgd_solver.cpp:137] Iteration 62700, lr = 0.00608125, m = 0.9
I0628 23:24:49.777387  5893 solver.cpp:349] Iteration 62800 (5.43036 iter/s, 18.415s/100 iter), loss = 1.53529
I0628 23:24:49.777490  5893 solver.cpp:371]     Train net output #0: loss = 1.62279 (* 1 = 1.62279 loss)
I0628 23:24:49.777498  5893 sgd_solver.cpp:137] Iteration 62800, lr = 0.006075, m = 0.9
I0628 23:25:08.220631  5893 solver.cpp:349] Iteration 62900 (5.42223 iter/s, 18.4426s/100 iter), loss = 1.23175
I0628 23:25:08.220651  5893 solver.cpp:371]     Train net output #0: loss = 1.18854 (* 1 = 1.18854 loss)
I0628 23:25:08.220655  5893 sgd_solver.cpp:137] Iteration 62900, lr = 0.00606875, m = 0.9
I0628 23:25:26.479395  5893 solver.cpp:401] Sparsity after update:
I0628 23:25:26.484586  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:25:26.484593  5893 net.cpp:2170] conv1a_param_0(0.315) 
I0628 23:25:26.484599  5893 net.cpp:2170] conv1b_param_0(0.63) 
I0628 23:25:26.484601  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:25:26.484604  5893 net.cpp:2170] res2a_branch2a_param_0(0.63) 
I0628 23:25:26.484606  5893 net.cpp:2170] res2a_branch2b_param_0(0.63) 
I0628 23:25:26.484607  5893 net.cpp:2170] res3a_branch2a_param_0(0.63) 
I0628 23:25:26.484609  5893 net.cpp:2170] res3a_branch2b_param_0(0.63) 
I0628 23:25:26.484611  5893 net.cpp:2170] res4a_branch2a_param_0(0.63) 
I0628 23:25:26.484613  5893 net.cpp:2170] res4a_branch2b_param_0(0.63) 
I0628 23:25:26.484616  5893 net.cpp:2170] res5a_branch2a_param_0(0.63) 
I0628 23:25:26.484617  5893 net.cpp:2170] res5a_branch2b_param_0(0.63) 
I0628 23:25:26.484619  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.48275e+06/2.86678e+06) 0.517
I0628 23:25:26.484627  5893 solver.cpp:545] Iteration 63000, Testing net (#0)
I0628 23:25:50.738765  5888 data_reader.cpp:262] Starting prefetch of epoch 63
I0628 23:25:50.800698  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57468
I0628 23:25:50.800724  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.806001
I0628 23:25:50.800729  5893 solver.cpp:630]     Test net output #2: loss = 1.85216 (* 1 = 1.85216 loss)
I0628 23:25:50.800745  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3154s
I0628 23:25:50.984757  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.64
I0628 23:25:51.565281  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:25:51.566745  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:25:51.567422  5893 solver.cpp:349] Iteration 63000 (2.30705 iter/s, 43.3455s/100 iter), loss = 1.58062
I0628 23:25:51.567440  5893 solver.cpp:371]     Train net output #0: loss = 1.51279 (* 1 = 1.51279 loss)
I0628 23:25:51.567445  5893 sgd_solver.cpp:137] Iteration 63000, lr = 0.0060625, m = 0.9
I0628 23:26:10.001060  5893 solver.cpp:349] Iteration 63100 (5.42504 iter/s, 18.4331s/100 iter), loss = 1.29217
I0628 23:26:10.001157  5893 solver.cpp:371]     Train net output #0: loss = 1.26827 (* 1 = 1.26827 loss)
I0628 23:26:10.001163  5893 sgd_solver.cpp:137] Iteration 63100, lr = 0.00605625, m = 0.9
I0628 23:26:28.440256  5893 solver.cpp:349] Iteration 63200 (5.42342 iter/s, 18.4385s/100 iter), loss = 1.59656
I0628 23:26:28.440281  5893 solver.cpp:371]     Train net output #0: loss = 1.4833 (* 1 = 1.4833 loss)
I0628 23:26:28.440286  5893 sgd_solver.cpp:137] Iteration 63200, lr = 0.00605, m = 0.9
I0628 23:26:46.853134  5893 solver.cpp:349] Iteration 63300 (5.43116 iter/s, 18.4123s/100 iter), loss = 1.37991
I0628 23:26:46.853245  5893 solver.cpp:371]     Train net output #0: loss = 1.37751 (* 1 = 1.37751 loss)
I0628 23:26:46.853251  5893 sgd_solver.cpp:137] Iteration 63300, lr = 0.00604375, m = 0.9
I0628 23:27:05.297596  5893 solver.cpp:349] Iteration 63400 (5.42188 iter/s, 18.4438s/100 iter), loss = 1.49697
I0628 23:27:05.297624  5893 solver.cpp:371]     Train net output #0: loss = 1.5103 (* 1 = 1.5103 loss)
I0628 23:27:05.297631  5893 sgd_solver.cpp:137] Iteration 63400, lr = 0.0060375, m = 0.9
I0628 23:27:23.731400  5893 solver.cpp:349] Iteration 63500 (5.42499 iter/s, 18.4332s/100 iter), loss = 1.1265
I0628 23:27:23.731518  5893 solver.cpp:371]     Train net output #0: loss = 1.02332 (* 1 = 1.02332 loss)
I0628 23:27:23.731525  5893 sgd_solver.cpp:137] Iteration 63500, lr = 0.00603125, m = 0.9
I0628 23:27:42.158598  5893 solver.cpp:349] Iteration 63600 (5.42696 iter/s, 18.4265s/100 iter), loss = 1.49519
I0628 23:27:42.158622  5893 solver.cpp:371]     Train net output #0: loss = 1.59483 (* 1 = 1.59483 loss)
I0628 23:27:42.158625  5893 sgd_solver.cpp:137] Iteration 63600, lr = 0.006025, m = 0.9
I0628 23:28:00.579681  5893 solver.cpp:349] Iteration 63700 (5.42874 iter/s, 18.4205s/100 iter), loss = 1.31921
I0628 23:28:00.579782  5893 solver.cpp:371]     Train net output #0: loss = 1.32164 (* 1 = 1.32164 loss)
I0628 23:28:00.579789  5893 sgd_solver.cpp:137] Iteration 63700, lr = 0.00601875, m = 0.9
I0628 23:28:18.998219  5893 solver.cpp:349] Iteration 63800 (5.42951 iter/s, 18.4179s/100 iter), loss = 1.61795
I0628 23:28:18.998242  5893 solver.cpp:371]     Train net output #0: loss = 1.73215 (* 1 = 1.73215 loss)
I0628 23:28:18.998247  5893 sgd_solver.cpp:137] Iteration 63800, lr = 0.0060125, m = 0.9
I0628 23:28:37.405009  5893 solver.cpp:349] Iteration 63900 (5.43295 iter/s, 18.4062s/100 iter), loss = 1.27616
I0628 23:28:37.405110  5893 solver.cpp:371]     Train net output #0: loss = 1.44467 (* 1 = 1.44467 loss)
I0628 23:28:37.405117  5893 sgd_solver.cpp:137] Iteration 63900, lr = 0.00600625, m = 0.9
I0628 23:28:55.637362  5893 solver.cpp:401] Sparsity after update:
I0628 23:28:55.642711  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:28:55.642720  5893 net.cpp:2170] conv1a_param_0(0.32) 
I0628 23:28:55.642726  5893 net.cpp:2170] conv1b_param_0(0.64) 
I0628 23:28:55.642729  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:28:55.642730  5893 net.cpp:2170] res2a_branch2a_param_0(0.64) 
I0628 23:28:55.642732  5893 net.cpp:2170] res2a_branch2b_param_0(0.64) 
I0628 23:28:55.642735  5893 net.cpp:2170] res3a_branch2a_param_0(0.64) 
I0628 23:28:55.642736  5893 net.cpp:2170] res3a_branch2b_param_0(0.64) 
I0628 23:28:55.642738  5893 net.cpp:2170] res4a_branch2a_param_0(0.64) 
I0628 23:28:55.642740  5893 net.cpp:2170] res4a_branch2b_param_0(0.64) 
I0628 23:28:55.642741  5893 net.cpp:2170] res5a_branch2a_param_0(0.64) 
I0628 23:28:55.642743  5893 net.cpp:2170] res5a_branch2b_param_0(0.64) 
I0628 23:28:55.642745  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.50628e+06/2.86678e+06) 0.525
I0628 23:28:55.642752  5893 solver.cpp:545] Iteration 64000, Testing net (#0)
I0628 23:29:19.937981  5888 data_reader.cpp:262] Starting prefetch of epoch 64
I0628 23:29:20.000365  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5758
I0628 23:29:20.000388  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.806601
I0628 23:29:20.000393  5893 solver.cpp:630]     Test net output #2: loss = 1.84017 (* 1 = 1.84017 loss)
I0628 23:29:20.000412  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3569s
I0628 23:29:20.184415  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.65
I0628 23:29:20.759939  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:29:20.761399  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:29:20.762078  5893 solver.cpp:349] Iteration 64000 (2.30651 iter/s, 43.3556s/100 iter), loss = 1.60793
I0628 23:29:20.762094  5893 solver.cpp:371]     Train net output #0: loss = 1.76693 (* 1 = 1.76693 loss)
I0628 23:29:20.762099  5893 sgd_solver.cpp:137] Iteration 64000, lr = 0.006, m = 0.9
I0628 23:29:39.202306  5893 solver.cpp:349] Iteration 64100 (5.4231 iter/s, 18.4396s/100 iter), loss = 1.28571
I0628 23:29:39.202327  5893 solver.cpp:371]     Train net output #0: loss = 1.32972 (* 1 = 1.32972 loss)
I0628 23:29:39.202332  5893 sgd_solver.cpp:137] Iteration 64100, lr = 0.00599375, m = 0.9
I0628 23:29:57.621887  5893 solver.cpp:349] Iteration 64200 (5.42918 iter/s, 18.419s/100 iter), loss = 1.40045
I0628 23:29:57.621990  5893 solver.cpp:371]     Train net output #0: loss = 1.53224 (* 1 = 1.53224 loss)
I0628 23:29:57.621995  5893 sgd_solver.cpp:137] Iteration 64200, lr = 0.0059875, m = 0.9
I0628 23:30:16.048367  5893 solver.cpp:349] Iteration 64300 (5.42717 iter/s, 18.4258s/100 iter), loss = 1.34781
I0628 23:30:16.048388  5893 solver.cpp:371]     Train net output #0: loss = 1.56741 (* 1 = 1.56741 loss)
I0628 23:30:16.048391  5893 sgd_solver.cpp:137] Iteration 64300, lr = 0.00598125, m = 0.9
I0628 23:30:34.450798  5893 solver.cpp:349] Iteration 64400 (5.43424 iter/s, 18.4018s/100 iter), loss = 1.44635
I0628 23:30:34.450902  5893 solver.cpp:371]     Train net output #0: loss = 1.47371 (* 1 = 1.47371 loss)
I0628 23:30:34.450908  5893 sgd_solver.cpp:137] Iteration 64400, lr = 0.005975, m = 0.9
I0628 23:30:52.897519  5893 solver.cpp:349] Iteration 64500 (5.42122 iter/s, 18.446s/100 iter), loss = 1.3426
I0628 23:30:52.897541  5893 solver.cpp:371]     Train net output #0: loss = 1.57132 (* 1 = 1.57132 loss)
I0628 23:30:52.897544  5893 sgd_solver.cpp:137] Iteration 64500, lr = 0.00596875, m = 0.9
I0628 23:31:11.330902  5893 solver.cpp:349] Iteration 64600 (5.42512 iter/s, 18.4328s/100 iter), loss = 1.53187
I0628 23:31:11.330978  5893 solver.cpp:371]     Train net output #0: loss = 1.47828 (* 1 = 1.47828 loss)
I0628 23:31:11.330983  5893 sgd_solver.cpp:137] Iteration 64600, lr = 0.0059625, m = 0.9
I0628 23:31:29.743613  5893 solver.cpp:349] Iteration 64700 (5.43123 iter/s, 18.412s/100 iter), loss = 1.4694
I0628 23:31:29.743635  5893 solver.cpp:371]     Train net output #0: loss = 1.35728 (* 1 = 1.35728 loss)
I0628 23:31:29.743639  5893 sgd_solver.cpp:137] Iteration 64700, lr = 0.00595625, m = 0.9
I0628 23:31:48.155108  5893 solver.cpp:349] Iteration 64800 (5.43157 iter/s, 18.4109s/100 iter), loss = 1.40606
I0628 23:31:48.155202  5893 solver.cpp:371]     Train net output #0: loss = 1.65836 (* 1 = 1.65836 loss)
I0628 23:31:48.155207  5893 sgd_solver.cpp:137] Iteration 64800, lr = 0.00595, m = 0.9
I0628 23:32:06.578104  5893 solver.cpp:349] Iteration 64900 (5.4282 iter/s, 18.4223s/100 iter), loss = 1.34666
I0628 23:32:06.578127  5893 solver.cpp:371]     Train net output #0: loss = 1.27683 (* 1 = 1.27683 loss)
I0628 23:32:06.578131  5893 sgd_solver.cpp:137] Iteration 64900, lr = 0.00594375, m = 0.9
I0628 23:32:24.827812  5893 solver.cpp:401] Sparsity after update:
I0628 23:32:24.833029  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:32:24.833037  5893 net.cpp:2170] conv1a_param_0(0.325) 
I0628 23:32:24.833046  5893 net.cpp:2170] conv1b_param_0(0.65) 
I0628 23:32:24.833050  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:32:24.833055  5893 net.cpp:2170] res2a_branch2a_param_0(0.65) 
I0628 23:32:24.833060  5893 net.cpp:2170] res2a_branch2b_param_0(0.65) 
I0628 23:32:24.833062  5893 net.cpp:2170] res3a_branch2a_param_0(0.65) 
I0628 23:32:24.833065  5893 net.cpp:2170] res3a_branch2b_param_0(0.65) 
I0628 23:32:24.833070  5893 net.cpp:2170] res4a_branch2a_param_0(0.65) 
I0628 23:32:24.833073  5893 net.cpp:2170] res4a_branch2b_param_0(0.65) 
I0628 23:32:24.833077  5893 net.cpp:2170] res5a_branch2a_param_0(0.65) 
I0628 23:32:24.833081  5893 net.cpp:2170] res5a_branch2b_param_0(0.65) 
I0628 23:32:24.833084  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.52982e+06/2.86678e+06) 0.534
I0628 23:32:24.833094  5893 solver.cpp:545] Iteration 65000, Testing net (#0)
I0628 23:32:49.150121  5888 data_reader.cpp:262] Starting prefetch of epoch 65
I0628 23:32:49.284523  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57144
I0628 23:32:49.284543  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8052
I0628 23:32:49.284550  5893 solver.cpp:630]     Test net output #2: loss = 1.85736 (* 1 = 1.85736 loss)
I0628 23:32:49.284569  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4507s
I0628 23:32:49.468899  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.66
I0628 23:32:50.055297  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:32:50.056772  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:32:50.057445  5893 solver.cpp:349] Iteration 65000 (2.30002 iter/s, 43.4779s/100 iter), loss = 1.37947
I0628 23:32:50.057466  5893 solver.cpp:371]     Train net output #0: loss = 1.37141 (* 1 = 1.37141 loss)
I0628 23:32:50.057476  5893 sgd_solver.cpp:137] Iteration 65000, lr = 0.0059375, m = 0.9
I0628 23:33:00.635414  5875 data_reader.cpp:262] Starting prefetch of epoch 13
I0628 23:33:08.511863  5893 solver.cpp:349] Iteration 65100 (5.41894 iter/s, 18.4538s/100 iter), loss = 1.66316
I0628 23:33:08.511886  5893 solver.cpp:371]     Train net output #0: loss = 1.80147 (* 1 = 1.80147 loss)
I0628 23:33:08.511890  5893 sgd_solver.cpp:137] Iteration 65100, lr = 0.00593125, m = 0.9
I0628 23:33:26.950784  5893 solver.cpp:349] Iteration 65200 (5.42349 iter/s, 18.4383s/100 iter), loss = 1.33673
I0628 23:33:26.950808  5893 solver.cpp:371]     Train net output #0: loss = 1.36975 (* 1 = 1.36975 loss)
I0628 23:33:26.950811  5893 sgd_solver.cpp:137] Iteration 65200, lr = 0.005925, m = 0.9
I0628 23:33:45.385136  5893 solver.cpp:349] Iteration 65300 (5.42484 iter/s, 18.4337s/100 iter), loss = 1.73946
I0628 23:33:45.385211  5893 solver.cpp:371]     Train net output #0: loss = 1.74586 (* 1 = 1.74586 loss)
I0628 23:33:45.385217  5893 sgd_solver.cpp:137] Iteration 65300, lr = 0.00591875, m = 0.9
I0628 23:34:03.838691  5893 solver.cpp:349] Iteration 65400 (5.41921 iter/s, 18.4529s/100 iter), loss = 1.50162
I0628 23:34:03.838714  5893 solver.cpp:371]     Train net output #0: loss = 1.39854 (* 1 = 1.39854 loss)
I0628 23:34:03.838721  5893 sgd_solver.cpp:137] Iteration 65400, lr = 0.0059125, m = 0.9
I0628 23:34:22.269604  5893 solver.cpp:349] Iteration 65500 (5.42585 iter/s, 18.4303s/100 iter), loss = 1.66445
I0628 23:34:22.269681  5893 solver.cpp:371]     Train net output #0: loss = 1.81372 (* 1 = 1.81372 loss)
I0628 23:34:22.269687  5893 sgd_solver.cpp:137] Iteration 65500, lr = 0.00590625, m = 0.9
I0628 23:34:40.740800  5893 solver.cpp:349] Iteration 65600 (5.41404 iter/s, 18.4705s/100 iter), loss = 1.3717
I0628 23:34:40.740823  5893 solver.cpp:371]     Train net output #0: loss = 1.11749 (* 1 = 1.11749 loss)
I0628 23:34:40.740828  5893 sgd_solver.cpp:137] Iteration 65600, lr = 0.0059, m = 0.9
I0628 23:34:59.188894  5893 solver.cpp:349] Iteration 65700 (5.4208 iter/s, 18.4475s/100 iter), loss = 1.92745
I0628 23:34:59.188980  5893 solver.cpp:371]     Train net output #0: loss = 2.06753 (* 1 = 2.06753 loss)
I0628 23:34:59.188985  5893 sgd_solver.cpp:137] Iteration 65700, lr = 0.00589375, m = 0.9
I0628 23:35:17.626811  5893 solver.cpp:349] Iteration 65800 (5.42381 iter/s, 18.4372s/100 iter), loss = 1.45711
I0628 23:35:17.626833  5893 solver.cpp:371]     Train net output #0: loss = 1.57457 (* 1 = 1.57457 loss)
I0628 23:35:17.626837  5893 sgd_solver.cpp:137] Iteration 65800, lr = 0.0058875, m = 0.9
I0628 23:35:36.064502  5893 solver.cpp:349] Iteration 65900 (5.42386 iter/s, 18.4371s/100 iter), loss = 1.36084
I0628 23:35:36.064599  5893 solver.cpp:371]     Train net output #0: loss = 1.4053 (* 1 = 1.4053 loss)
I0628 23:35:36.064606  5893 sgd_solver.cpp:137] Iteration 65900, lr = 0.00588125, m = 0.9
I0628 23:35:54.336369  5893 solver.cpp:401] Sparsity after update:
I0628 23:35:54.341579  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:35:54.341588  5893 net.cpp:2170] conv1a_param_0(0.33) 
I0628 23:35:54.341593  5893 net.cpp:2170] conv1b_param_0(0.66) 
I0628 23:35:54.341595  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:35:54.341598  5893 net.cpp:2170] res2a_branch2a_param_0(0.66) 
I0628 23:35:54.341599  5893 net.cpp:2170] res2a_branch2b_param_0(0.66) 
I0628 23:35:54.341601  5893 net.cpp:2170] res3a_branch2a_param_0(0.66) 
I0628 23:35:54.341603  5893 net.cpp:2170] res3a_branch2b_param_0(0.66) 
I0628 23:35:54.341605  5893 net.cpp:2170] res4a_branch2a_param_0(0.66) 
I0628 23:35:54.341608  5893 net.cpp:2170] res4a_branch2b_param_0(0.66) 
I0628 23:35:54.341609  5893 net.cpp:2170] res5a_branch2a_param_0(0.66) 
I0628 23:35:54.341610  5893 net.cpp:2170] res5a_branch2b_param_0(0.66) 
I0628 23:35:54.341612  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.55336e+06/2.86678e+06) 0.542
I0628 23:35:54.341620  5893 solver.cpp:545] Iteration 66000, Testing net (#0)
I0628 23:35:55.960698  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 23:36:18.558073  5888 data_reader.cpp:262] Starting prefetch of epoch 66
I0628 23:36:18.620260  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.572
I0628 23:36:18.620280  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.804841
I0628 23:36:18.620285  5893 solver.cpp:630]     Test net output #2: loss = 1.861 (* 1 = 1.861 loss)
I0628 23:36:18.620301  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2779s
I0628 23:36:18.804633  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.67
I0628 23:36:19.414088  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:36:19.415565  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:36:19.416245  5893 solver.cpp:349] Iteration 66000 (2.30679 iter/s, 43.3502s/100 iter), loss = 1.29465
I0628 23:36:19.416265  5893 solver.cpp:371]     Train net output #0: loss = 1.30608 (* 1 = 1.30608 loss)
I0628 23:36:19.416272  5893 sgd_solver.cpp:137] Iteration 66000, lr = 0.005875, m = 0.9
I0628 23:36:37.871475  5893 solver.cpp:349] Iteration 66100 (5.41871 iter/s, 18.4546s/100 iter), loss = 1.49185
I0628 23:36:37.871498  5893 solver.cpp:371]     Train net output #0: loss = 1.44559 (* 1 = 1.44559 loss)
I0628 23:36:37.871502  5893 sgd_solver.cpp:137] Iteration 66100, lr = 0.00586875, m = 0.9
I0628 23:36:56.310448  5893 solver.cpp:349] Iteration 66200 (5.42348 iter/s, 18.4383s/100 iter), loss = 1.7385
I0628 23:36:56.310551  5893 solver.cpp:371]     Train net output #0: loss = 1.86323 (* 1 = 1.86323 loss)
I0628 23:36:56.310557  5893 sgd_solver.cpp:137] Iteration 66200, lr = 0.0058625, m = 0.9
I0628 23:37:14.722932  5893 solver.cpp:349] Iteration 66300 (5.43131 iter/s, 18.4118s/100 iter), loss = 1.51346
I0628 23:37:14.722955  5893 solver.cpp:371]     Train net output #0: loss = 1.53163 (* 1 = 1.53163 loss)
I0628 23:37:14.722959  5893 sgd_solver.cpp:137] Iteration 66300, lr = 0.00585625, m = 0.9
I0628 23:37:33.150943  5893 solver.cpp:349] Iteration 66400 (5.42671 iter/s, 18.4274s/100 iter), loss = 1.57784
I0628 23:37:33.151041  5893 solver.cpp:371]     Train net output #0: loss = 1.1839 (* 1 = 1.1839 loss)
I0628 23:37:33.151048  5893 sgd_solver.cpp:137] Iteration 66400, lr = 0.00585, m = 0.9
I0628 23:37:51.562060  5893 solver.cpp:349] Iteration 66500 (5.43171 iter/s, 18.4104s/100 iter), loss = 1.38315
I0628 23:37:51.562083  5893 solver.cpp:371]     Train net output #0: loss = 1.27216 (* 1 = 1.27216 loss)
I0628 23:37:51.562088  5893 sgd_solver.cpp:137] Iteration 66500, lr = 0.00584375, m = 0.9
I0628 23:38:09.968008  5893 solver.cpp:349] Iteration 66600 (5.43322 iter/s, 18.4053s/100 iter), loss = 1.43819
I0628 23:38:09.968636  5893 solver.cpp:371]     Train net output #0: loss = 1.39064 (* 1 = 1.39064 loss)
I0628 23:38:09.968643  5893 sgd_solver.cpp:137] Iteration 66600, lr = 0.0058375, m = 0.9
I0628 23:38:28.398957  5893 solver.cpp:349] Iteration 66700 (5.42603 iter/s, 18.4297s/100 iter), loss = 1.12299
I0628 23:38:28.398980  5893 solver.cpp:371]     Train net output #0: loss = 1.19122 (* 1 = 1.19122 loss)
I0628 23:38:28.398984  5893 sgd_solver.cpp:137] Iteration 66700, lr = 0.00583125, m = 0.9
I0628 23:38:46.807799  5893 solver.cpp:349] Iteration 66800 (5.43236 iter/s, 18.4082s/100 iter), loss = 1.15537
I0628 23:38:46.807901  5893 solver.cpp:371]     Train net output #0: loss = 0.868284 (* 1 = 0.868284 loss)
I0628 23:38:46.807906  5893 sgd_solver.cpp:137] Iteration 66800, lr = 0.005825, m = 0.9
I0628 23:39:05.222632  5893 solver.cpp:349] Iteration 66900 (5.43062 iter/s, 18.4141s/100 iter), loss = 1.51767
I0628 23:39:05.222652  5893 solver.cpp:371]     Train net output #0: loss = 1.17834 (* 1 = 1.17834 loss)
I0628 23:39:05.222656  5893 sgd_solver.cpp:137] Iteration 66900, lr = 0.00581875, m = 0.9
I0628 23:39:23.473748  5893 solver.cpp:401] Sparsity after update:
I0628 23:39:23.478996  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:39:23.479007  5893 net.cpp:2170] conv1a_param_0(0.335) 
I0628 23:39:23.479014  5893 net.cpp:2170] conv1b_param_0(0.67) 
I0628 23:39:23.479018  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:39:23.479022  5893 net.cpp:2170] res2a_branch2a_param_0(0.67) 
I0628 23:39:23.479024  5893 net.cpp:2170] res2a_branch2b_param_0(0.67) 
I0628 23:39:23.479027  5893 net.cpp:2170] res3a_branch2a_param_0(0.67) 
I0628 23:39:23.479030  5893 net.cpp:2170] res3a_branch2b_param_0(0.67) 
I0628 23:39:23.479034  5893 net.cpp:2170] res4a_branch2a_param_0(0.67) 
I0628 23:39:23.479038  5893 net.cpp:2170] res4a_branch2b_param_0(0.67) 
I0628 23:39:23.479040  5893 net.cpp:2170] res5a_branch2a_param_0(0.67) 
I0628 23:39:23.479044  5893 net.cpp:2170] res5a_branch2b_param_0(0.67) 
I0628 23:39:23.479048  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.57689e+06/2.86678e+06) 0.55
I0628 23:39:23.479058  5893 solver.cpp:545] Iteration 67000, Testing net (#0)
I0628 23:39:47.834245  5888 data_reader.cpp:262] Starting prefetch of epoch 67
I0628 23:39:48.056637  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57416
I0628 23:39:48.056655  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80348
I0628 23:39:48.056663  5893 solver.cpp:630]     Test net output #2: loss = 1.86505 (* 1 = 1.86505 loss)
I0628 23:39:48.056684  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5768s
I0628 23:39:48.241677  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.68
I0628 23:39:48.870120  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:39:48.871587  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:39:48.872275  5893 solver.cpp:349] Iteration 67000 (2.29105 iter/s, 43.6482s/100 iter), loss = 1.49478
I0628 23:39:48.872292  5893 solver.cpp:371]     Train net output #0: loss = 1.75543 (* 1 = 1.75543 loss)
I0628 23:39:48.872298  5893 sgd_solver.cpp:137] Iteration 67000, lr = 0.0058125, m = 0.9
I0628 23:40:07.333756  5893 solver.cpp:349] Iteration 67100 (5.41687 iter/s, 18.4608s/100 iter), loss = 1.47699
I0628 23:40:07.333796  5893 solver.cpp:371]     Train net output #0: loss = 1.55076 (* 1 = 1.55076 loss)
I0628 23:40:07.333802  5893 sgd_solver.cpp:137] Iteration 67100, lr = 0.00580625, m = 0.9
I0628 23:40:25.772202  5893 solver.cpp:349] Iteration 67200 (5.42365 iter/s, 18.4378s/100 iter), loss = 1.49577
I0628 23:40:25.772225  5893 solver.cpp:371]     Train net output #0: loss = 1.52928 (* 1 = 1.52928 loss)
I0628 23:40:25.772229  5893 sgd_solver.cpp:137] Iteration 67200, lr = 0.0058, m = 0.9
I0628 23:40:44.220705  5893 solver.cpp:349] Iteration 67300 (5.42069 iter/s, 18.4478s/100 iter), loss = 1.34137
I0628 23:40:44.220782  5893 solver.cpp:371]     Train net output #0: loss = 1.24668 (* 1 = 1.24668 loss)
I0628 23:40:44.220787  5893 sgd_solver.cpp:137] Iteration 67300, lr = 0.00579375, m = 0.9
I0628 23:41:02.658006  5893 solver.cpp:349] Iteration 67400 (5.424 iter/s, 18.4366s/100 iter), loss = 1.58085
I0628 23:41:02.658030  5893 solver.cpp:371]     Train net output #0: loss = 1.81991 (* 1 = 1.81991 loss)
I0628 23:41:02.658035  5893 sgd_solver.cpp:137] Iteration 67400, lr = 0.0057875, m = 0.9
I0628 23:41:21.112663  5893 solver.cpp:349] Iteration 67500 (5.41888 iter/s, 18.454s/100 iter), loss = 1.63619
I0628 23:41:21.112731  5893 solver.cpp:371]     Train net output #0: loss = 1.68466 (* 1 = 1.68466 loss)
I0628 23:41:21.112737  5893 sgd_solver.cpp:137] Iteration 67500, lr = 0.00578125, m = 0.9
I0628 23:41:39.592737  5893 solver.cpp:349] Iteration 67600 (5.41144 iter/s, 18.4794s/100 iter), loss = 1.2181
I0628 23:41:39.592761  5893 solver.cpp:371]     Train net output #0: loss = 1.29378 (* 1 = 1.29378 loss)
I0628 23:41:39.592764  5893 sgd_solver.cpp:137] Iteration 67600, lr = 0.005775, m = 0.9
I0628 23:41:58.040885  5893 solver.cpp:349] Iteration 67700 (5.42079 iter/s, 18.4475s/100 iter), loss = 1.3507
I0628 23:41:58.040964  5893 solver.cpp:371]     Train net output #0: loss = 1.1544 (* 1 = 1.1544 loss)
I0628 23:41:58.040971  5893 sgd_solver.cpp:137] Iteration 67700, lr = 0.00576875, m = 0.9
I0628 23:42:16.479044  5893 solver.cpp:349] Iteration 67800 (5.42375 iter/s, 18.4374s/100 iter), loss = 1.54135
I0628 23:42:16.479063  5893 solver.cpp:371]     Train net output #0: loss = 1.60883 (* 1 = 1.60883 loss)
I0628 23:42:16.479066  5893 sgd_solver.cpp:137] Iteration 67800, lr = 0.0057625, m = 0.9
I0628 23:42:34.888301  5893 solver.cpp:349] Iteration 67900 (5.43224 iter/s, 18.4086s/100 iter), loss = 1.69004
I0628 23:42:34.888371  5893 solver.cpp:371]     Train net output #0: loss = 1.55702 (* 1 = 1.55702 loss)
I0628 23:42:34.888376  5893 sgd_solver.cpp:137] Iteration 67900, lr = 0.00575625, m = 0.9
I0628 23:42:53.135661  5893 solver.cpp:401] Sparsity after update:
I0628 23:42:53.140892  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:42:53.140902  5893 net.cpp:2170] conv1a_param_0(0.34) 
I0628 23:42:53.140909  5893 net.cpp:2170] conv1b_param_0(0.68) 
I0628 23:42:53.140913  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:42:53.140915  5893 net.cpp:2170] res2a_branch2a_param_0(0.68) 
I0628 23:42:53.140919  5893 net.cpp:2170] res2a_branch2b_param_0(0.68) 
I0628 23:42:53.140923  5893 net.cpp:2170] res3a_branch2a_param_0(0.68) 
I0628 23:42:53.140925  5893 net.cpp:2170] res3a_branch2b_param_0(0.68) 
I0628 23:42:53.140928  5893 net.cpp:2170] res4a_branch2a_param_0(0.68) 
I0628 23:42:53.140931  5893 net.cpp:2170] res4a_branch2b_param_0(0.68) 
I0628 23:42:53.140934  5893 net.cpp:2170] res5a_branch2a_param_0(0.68) 
I0628 23:42:53.140938  5893 net.cpp:2170] res5a_branch2b_param_0(0.68) 
I0628 23:42:53.140943  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.60043e+06/2.86678e+06) 0.558
I0628 23:42:53.140952  5893 solver.cpp:545] Iteration 68000, Testing net (#0)
I0628 23:43:17.593197  5888 data_reader.cpp:262] Starting prefetch of epoch 68
I0628 23:43:17.657622  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56468
I0628 23:43:17.657642  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798761
I0628 23:43:17.657647  5893 solver.cpp:630]     Test net output #2: loss = 1.89551 (* 1 = 1.89551 loss)
I0628 23:43:17.657662  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5159s
I0628 23:43:17.846482  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.69
I0628 23:43:18.465247  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:43:18.466712  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:43:18.467384  5893 solver.cpp:349] Iteration 68000 (2.29476 iter/s, 43.5775s/100 iter), loss = 1.85243
I0628 23:43:18.467401  5893 solver.cpp:371]     Train net output #0: loss = 1.70667 (* 1 = 1.70667 loss)
I0628 23:43:18.467406  5893 sgd_solver.cpp:137] Iteration 68000, lr = 0.00575, m = 0.9
I0628 23:43:36.909701  5893 solver.cpp:349] Iteration 68100 (5.42251 iter/s, 18.4417s/100 iter), loss = 1.39577
I0628 23:43:36.909725  5893 solver.cpp:371]     Train net output #0: loss = 1.38044 (* 1 = 1.38044 loss)
I0628 23:43:36.909729  5893 sgd_solver.cpp:137] Iteration 68100, lr = 0.00574375, m = 0.9
I0628 23:43:55.320543  5893 solver.cpp:349] Iteration 68200 (5.43178 iter/s, 18.4102s/100 iter), loss = 1.53891
I0628 23:43:55.320621  5893 solver.cpp:371]     Train net output #0: loss = 1.6703 (* 1 = 1.6703 loss)
I0628 23:43:55.320626  5893 sgd_solver.cpp:137] Iteration 68200, lr = 0.0057375, m = 0.9
I0628 23:44:13.743530  5893 solver.cpp:349] Iteration 68300 (5.42822 iter/s, 18.4223s/100 iter), loss = 1.38202
I0628 23:44:13.743551  5893 solver.cpp:371]     Train net output #0: loss = 1.36618 (* 1 = 1.36618 loss)
I0628 23:44:13.743556  5893 sgd_solver.cpp:137] Iteration 68300, lr = 0.00573125, m = 0.9
I0628 23:44:32.210767  5893 solver.cpp:349] Iteration 68400 (5.41519 iter/s, 18.4666s/100 iter), loss = 1.83048
I0628 23:44:32.210834  5893 solver.cpp:371]     Train net output #0: loss = 1.9264 (* 1 = 1.9264 loss)
I0628 23:44:32.210840  5893 sgd_solver.cpp:137] Iteration 68400, lr = 0.005725, m = 0.9
I0628 23:44:50.631083  5893 solver.cpp:349] Iteration 68500 (5.429 iter/s, 18.4196s/100 iter), loss = 1.07259
I0628 23:44:50.631105  5893 solver.cpp:371]     Train net output #0: loss = 1.29775 (* 1 = 1.29775 loss)
I0628 23:44:50.631110  5893 sgd_solver.cpp:137] Iteration 68500, lr = 0.00571875, m = 0.9
I0628 23:45:09.046811  5893 solver.cpp:349] Iteration 68600 (5.43034 iter/s, 18.4151s/100 iter), loss = 1.70197
I0628 23:45:09.046877  5893 solver.cpp:371]     Train net output #0: loss = 1.87493 (* 1 = 1.87493 loss)
I0628 23:45:09.046885  5893 sgd_solver.cpp:137] Iteration 68600, lr = 0.0057125, m = 0.9
I0628 23:45:27.476488  5893 solver.cpp:349] Iteration 68700 (5.42624 iter/s, 18.429s/100 iter), loss = 1.47851
I0628 23:45:27.476511  5893 solver.cpp:371]     Train net output #0: loss = 1.41163 (* 1 = 1.41163 loss)
I0628 23:45:27.476516  5893 sgd_solver.cpp:137] Iteration 68700, lr = 0.00570625, m = 0.9
I0628 23:45:45.936027  5893 solver.cpp:349] Iteration 68800 (5.41745 iter/s, 18.4589s/100 iter), loss = 1.32526
I0628 23:45:45.936132  5893 solver.cpp:371]     Train net output #0: loss = 1.57129 (* 1 = 1.57129 loss)
I0628 23:45:45.936138  5893 sgd_solver.cpp:137] Iteration 68800, lr = 0.0057, m = 0.9
I0628 23:46:04.423475  5893 solver.cpp:349] Iteration 68900 (5.4093 iter/s, 18.4867s/100 iter), loss = 1.48495
I0628 23:46:04.423497  5893 solver.cpp:371]     Train net output #0: loss = 1.50071 (* 1 = 1.50071 loss)
I0628 23:46:04.423501  5893 sgd_solver.cpp:137] Iteration 68900, lr = 0.00569375, m = 0.9
I0628 23:46:22.666132  5893 solver.cpp:401] Sparsity after update:
I0628 23:46:22.671339  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:46:22.671346  5893 net.cpp:2170] conv1a_param_0(0.345) 
I0628 23:46:22.671355  5893 net.cpp:2170] conv1b_param_0(0.69) 
I0628 23:46:22.671358  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:46:22.671362  5893 net.cpp:2170] res2a_branch2a_param_0(0.69) 
I0628 23:46:22.671366  5893 net.cpp:2170] res2a_branch2b_param_0(0.69) 
I0628 23:46:22.671371  5893 net.cpp:2170] res3a_branch2a_param_0(0.69) 
I0628 23:46:22.671375  5893 net.cpp:2170] res3a_branch2b_param_0(0.69) 
I0628 23:46:22.671380  5893 net.cpp:2170] res4a_branch2a_param_0(0.69) 
I0628 23:46:22.671383  5893 net.cpp:2170] res4a_branch2b_param_0(0.69) 
I0628 23:46:22.671387  5893 net.cpp:2170] res5a_branch2a_param_0(0.69) 
I0628 23:46:22.671391  5893 net.cpp:2170] res5a_branch2b_param_0(0.69) 
I0628 23:46:22.671396  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.62396e+06/2.86678e+06) 0.566
I0628 23:46:22.671406  5893 solver.cpp:545] Iteration 69000, Testing net (#0)
I0628 23:46:46.935972  5888 data_reader.cpp:262] Starting prefetch of epoch 69
I0628 23:46:46.998001  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5692
I0628 23:46:46.998025  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8026
I0628 23:46:46.998030  5893 solver.cpp:630]     Test net output #2: loss = 1.87084 (* 1 = 1.87084 loss)
I0628 23:46:46.998045  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3258s
I0628 23:46:47.185060  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.7
I0628 23:46:47.810008  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:46:47.811480  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:46:47.812156  5893 solver.cpp:349] Iteration 69000 (2.30483 iter/s, 43.3871s/100 iter), loss = 1.84715
I0628 23:46:47.812175  5893 solver.cpp:371]     Train net output #0: loss = 1.87554 (* 1 = 1.87554 loss)
I0628 23:46:47.812180  5893 sgd_solver.cpp:137] Iteration 69000, lr = 0.0056875, m = 0.9
I0628 23:47:06.249142  5893 solver.cpp:349] Iteration 69100 (5.42408 iter/s, 18.4363s/100 iter), loss = 1.69992
I0628 23:47:06.249277  5893 solver.cpp:371]     Train net output #0: loss = 1.87823 (* 1 = 1.87823 loss)
I0628 23:47:06.249284  5893 sgd_solver.cpp:137] Iteration 69100, lr = 0.00568125, m = 0.9
I0628 23:47:24.673238  5893 solver.cpp:349] Iteration 69200 (5.42791 iter/s, 18.4233s/100 iter), loss = 1.58886
I0628 23:47:24.673262  5893 solver.cpp:371]     Train net output #0: loss = 1.14836 (* 1 = 1.14836 loss)
I0628 23:47:24.673266  5893 sgd_solver.cpp:137] Iteration 69200, lr = 0.005675, m = 0.9
I0628 23:47:43.092469  5893 solver.cpp:349] Iteration 69300 (5.4293 iter/s, 18.4186s/100 iter), loss = 1.58574
I0628 23:47:43.092574  5893 solver.cpp:371]     Train net output #0: loss = 1.6108 (* 1 = 1.6108 loss)
I0628 23:47:43.092581  5893 sgd_solver.cpp:137] Iteration 69300, lr = 0.00566875, m = 0.9
I0628 23:48:01.531359  5893 solver.cpp:349] Iteration 69400 (5.42351 iter/s, 18.4382s/100 iter), loss = 1.42939
I0628 23:48:01.531383  5893 solver.cpp:371]     Train net output #0: loss = 1.17603 (* 1 = 1.17603 loss)
I0628 23:48:01.531388  5893 sgd_solver.cpp:137] Iteration 69400, lr = 0.0056625, m = 0.9
I0628 23:48:19.946943  5893 solver.cpp:349] Iteration 69500 (5.43035 iter/s, 18.415s/100 iter), loss = 1.55826
I0628 23:48:19.947039  5893 solver.cpp:371]     Train net output #0: loss = 1.54573 (* 1 = 1.54573 loss)
I0628 23:48:19.947046  5893 sgd_solver.cpp:137] Iteration 69500, lr = 0.00565625, m = 0.9
I0628 23:48:38.388450  5893 solver.cpp:349] Iteration 69600 (5.42274 iter/s, 18.4409s/100 iter), loss = 1.36593
I0628 23:48:38.388473  5893 solver.cpp:371]     Train net output #0: loss = 1.27927 (* 1 = 1.27927 loss)
I0628 23:48:38.388476  5893 sgd_solver.cpp:137] Iteration 69600, lr = 0.00565, m = 0.9
I0628 23:48:56.834915  5893 solver.cpp:349] Iteration 69700 (5.42126 iter/s, 18.4459s/100 iter), loss = 1.51889
I0628 23:48:56.835019  5893 solver.cpp:371]     Train net output #0: loss = 1.55353 (* 1 = 1.55353 loss)
I0628 23:48:56.835026  5893 sgd_solver.cpp:137] Iteration 69700, lr = 0.00564375, m = 0.9
I0628 23:49:15.280680  5893 solver.cpp:349] Iteration 69800 (5.42149 iter/s, 18.4451s/100 iter), loss = 1.98324
I0628 23:49:15.280704  5893 solver.cpp:371]     Train net output #0: loss = 1.865 (* 1 = 1.865 loss)
I0628 23:49:15.280709  5893 sgd_solver.cpp:137] Iteration 69800, lr = 0.0056375, m = 0.9
I0628 23:49:33.701486  5893 solver.cpp:349] Iteration 69900 (5.42882 iter/s, 18.4202s/100 iter), loss = 1.41718
I0628 23:49:33.701587  5893 solver.cpp:371]     Train net output #0: loss = 1.53885 (* 1 = 1.53885 loss)
I0628 23:49:33.701593  5893 sgd_solver.cpp:137] Iteration 69900, lr = 0.00563125, m = 0.9
I0628 23:49:51.997859  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_70000.caffemodel
I0628 23:49:52.044432  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_70000.solverstate
I0628 23:49:52.048866  5893 solver.cpp:401] Sparsity after update:
I0628 23:49:52.053182  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:49:52.053190  5893 net.cpp:2170] conv1a_param_0(0.35) 
I0628 23:49:52.053196  5893 net.cpp:2170] conv1b_param_0(0.7) 
I0628 23:49:52.053200  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:49:52.053201  5893 net.cpp:2170] res2a_branch2a_param_0(0.7) 
I0628 23:49:52.053203  5893 net.cpp:2170] res2a_branch2b_param_0(0.7) 
I0628 23:49:52.053205  5893 net.cpp:2170] res3a_branch2a_param_0(0.7) 
I0628 23:49:52.053207  5893 net.cpp:2170] res3a_branch2b_param_0(0.7) 
I0628 23:49:52.053210  5893 net.cpp:2170] res4a_branch2a_param_0(0.7) 
I0628 23:49:52.053210  5893 net.cpp:2170] res4a_branch2b_param_0(0.7) 
I0628 23:49:52.053212  5893 net.cpp:2170] res5a_branch2a_param_0(0.7) 
I0628 23:49:52.053216  5893 net.cpp:2170] res5a_branch2b_param_0(0.7) 
I0628 23:49:52.053218  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.6475e+06/2.86678e+06) 0.575
I0628 23:49:52.053226  5893 solver.cpp:545] Iteration 70000, Testing net (#0)
I0628 23:50:16.385100  5888 data_reader.cpp:262] Starting prefetch of epoch 70
I0628 23:50:16.447221  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5662
I0628 23:50:16.447245  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7996
I0628 23:50:16.447250  5893 solver.cpp:630]     Test net output #2: loss = 1.88775 (* 1 = 1.88775 loss)
I0628 23:50:16.447266  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3933s
I0628 23:50:16.634570  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.71
I0628 23:50:17.271551  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:50:17.273015  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:50:17.273685  5893 solver.cpp:349] Iteration 70000 (2.29512 iter/s, 43.5708s/100 iter), loss = 1.56727
I0628 23:50:17.273702  5893 solver.cpp:371]     Train net output #0: loss = 1.16326 (* 1 = 1.16326 loss)
I0628 23:50:17.273707  5893 sgd_solver.cpp:137] Iteration 70000, lr = 0.005625, m = 0.9
I0628 23:50:28.720760  5875 data_reader.cpp:262] Starting prefetch of epoch 14
I0628 23:50:35.749915  5893 solver.cpp:349] Iteration 70100 (5.41253 iter/s, 18.4756s/100 iter), loss = 1.35364
I0628 23:50:35.749938  5893 solver.cpp:371]     Train net output #0: loss = 1.29076 (* 1 = 1.29076 loss)
I0628 23:50:35.749943  5893 sgd_solver.cpp:137] Iteration 70100, lr = 0.00561875, m = 0.9
I0628 23:50:54.186413  5893 solver.cpp:349] Iteration 70200 (5.4242 iter/s, 18.4359s/100 iter), loss = 1.4855
I0628 23:50:54.186483  5893 solver.cpp:371]     Train net output #0: loss = 1.45194 (* 1 = 1.45194 loss)
I0628 23:50:54.186487  5893 sgd_solver.cpp:137] Iteration 70200, lr = 0.0056125, m = 0.9
I0628 23:51:12.616825  5893 solver.cpp:349] Iteration 70300 (5.426 iter/s, 18.4298s/100 iter), loss = 1.55442
I0628 23:51:12.616848  5893 solver.cpp:371]     Train net output #0: loss = 1.65286 (* 1 = 1.65286 loss)
I0628 23:51:12.616852  5893 sgd_solver.cpp:137] Iteration 70300, lr = 0.00560625, m = 0.9
I0628 23:51:31.068799  5893 solver.cpp:349] Iteration 70400 (5.41965 iter/s, 18.4514s/100 iter), loss = 1.7172
I0628 23:51:31.068915  5893 solver.cpp:371]     Train net output #0: loss = 1.31611 (* 1 = 1.31611 loss)
I0628 23:51:31.068922  5893 sgd_solver.cpp:137] Iteration 70400, lr = 0.0056, m = 0.9
I0628 23:51:49.529388  5893 solver.cpp:349] Iteration 70500 (5.41715 iter/s, 18.4599s/100 iter), loss = 1.44913
I0628 23:51:49.529412  5893 solver.cpp:371]     Train net output #0: loss = 1.59752 (* 1 = 1.59752 loss)
I0628 23:51:49.529415  5893 sgd_solver.cpp:137] Iteration 70500, lr = 0.00559375, m = 0.9
I0628 23:52:07.943202  5893 solver.cpp:349] Iteration 70600 (5.43088 iter/s, 18.4132s/100 iter), loss = 1.40854
I0628 23:52:07.943287  5893 solver.cpp:371]     Train net output #0: loss = 1.05818 (* 1 = 1.05818 loss)
I0628 23:52:07.943292  5893 sgd_solver.cpp:137] Iteration 70600, lr = 0.0055875, m = 0.9
I0628 23:52:26.374353  5893 solver.cpp:349] Iteration 70700 (5.42579 iter/s, 18.4305s/100 iter), loss = 1.72081
I0628 23:52:26.374378  5893 solver.cpp:371]     Train net output #0: loss = 1.86787 (* 1 = 1.86787 loss)
I0628 23:52:26.374384  5893 sgd_solver.cpp:137] Iteration 70700, lr = 0.00558125, m = 0.9
I0628 23:52:44.818511  5893 solver.cpp:349] Iteration 70800 (5.42195 iter/s, 18.4436s/100 iter), loss = 1.91019
I0628 23:52:44.818606  5893 solver.cpp:371]     Train net output #0: loss = 1.69872 (* 1 = 1.69872 loss)
I0628 23:52:44.818611  5893 sgd_solver.cpp:137] Iteration 70800, lr = 0.005575, m = 0.9
I0628 23:53:03.252410  5893 solver.cpp:349] Iteration 70900 (5.42499 iter/s, 18.4332s/100 iter), loss = 1.81012
I0628 23:53:03.252430  5893 solver.cpp:371]     Train net output #0: loss = 1.94923 (* 1 = 1.94923 loss)
I0628 23:53:03.252436  5893 sgd_solver.cpp:137] Iteration 70900, lr = 0.00556875, m = 0.9
I0628 23:53:21.505983  5893 solver.cpp:401] Sparsity after update:
I0628 23:53:21.511203  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:53:21.511210  5893 net.cpp:2170] conv1a_param_0(0.355) 
I0628 23:53:21.511219  5893 net.cpp:2170] conv1b_param_0(0.71) 
I0628 23:53:21.511224  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:53:21.511229  5893 net.cpp:2170] res2a_branch2a_param_0(0.71) 
I0628 23:53:21.511238  5893 net.cpp:2170] res2a_branch2b_param_0(0.71) 
I0628 23:53:21.511241  5893 net.cpp:2170] res3a_branch2a_param_0(0.71) 
I0628 23:53:21.511245  5893 net.cpp:2170] res3a_branch2b_param_0(0.71) 
I0628 23:53:21.511247  5893 net.cpp:2170] res4a_branch2a_param_0(0.71) 
I0628 23:53:21.511253  5893 net.cpp:2170] res4a_branch2b_param_0(0.71) 
I0628 23:53:21.511256  5893 net.cpp:2170] res5a_branch2a_param_0(0.71) 
I0628 23:53:21.511260  5893 net.cpp:2170] res5a_branch2b_param_0(0.71) 
I0628 23:53:21.511263  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.67103e+06/2.86678e+06) 0.583
I0628 23:53:21.511274  5893 solver.cpp:545] Iteration 71000, Testing net (#0)
I0628 23:53:23.316766  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0628 23:53:45.740958  5888 data_reader.cpp:262] Starting prefetch of epoch 71
I0628 23:53:45.836541  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56512
I0628 23:53:45.836565  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7978
I0628 23:53:45.836570  5893 solver.cpp:630]     Test net output #2: loss = 1.90189 (* 1 = 1.90189 loss)
I0628 23:53:45.836586  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3246s
I0628 23:53:46.022053  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.72
I0628 23:53:46.677441  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:53:46.678917  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:53:46.679594  5893 solver.cpp:349] Iteration 71000 (2.30278 iter/s, 43.4258s/100 iter), loss = 1.23993
I0628 23:53:46.679613  5893 solver.cpp:371]     Train net output #0: loss = 1.40429 (* 1 = 1.40429 loss)
I0628 23:53:46.679618  5893 sgd_solver.cpp:137] Iteration 71000, lr = 0.0055625, m = 0.9
I0628 23:54:05.109968  5893 solver.cpp:349] Iteration 71100 (5.426 iter/s, 18.4298s/100 iter), loss = 1.23668
I0628 23:54:05.110052  5893 solver.cpp:371]     Train net output #0: loss = 0.990068 (* 1 = 0.990068 loss)
I0628 23:54:05.110059  5893 sgd_solver.cpp:137] Iteration 71100, lr = 0.00555625, m = 0.9
I0628 23:54:23.527158  5893 solver.cpp:349] Iteration 71200 (5.42991 iter/s, 18.4165s/100 iter), loss = 1.31239
I0628 23:54:23.527180  5893 solver.cpp:371]     Train net output #0: loss = 1.25132 (* 1 = 1.25132 loss)
I0628 23:54:23.527184  5893 sgd_solver.cpp:137] Iteration 71200, lr = 0.00555, m = 0.9
I0628 23:54:41.941882  5893 solver.cpp:349] Iteration 71300 (5.43062 iter/s, 18.4141s/100 iter), loss = 1.41337
I0628 23:54:41.941952  5893 solver.cpp:371]     Train net output #0: loss = 1.4648 (* 1 = 1.4648 loss)
I0628 23:54:41.941957  5893 sgd_solver.cpp:137] Iteration 71300, lr = 0.00554375, m = 0.9
I0628 23:55:00.381067  5893 solver.cpp:349] Iteration 71400 (5.42343 iter/s, 18.4385s/100 iter), loss = 1.33786
I0628 23:55:00.381088  5893 solver.cpp:371]     Train net output #0: loss = 1.31771 (* 1 = 1.31771 loss)
I0628 23:55:00.381094  5893 sgd_solver.cpp:137] Iteration 71400, lr = 0.0055375, m = 0.9
I0628 23:55:18.820616  5893 solver.cpp:349] Iteration 71500 (5.42331 iter/s, 18.4389s/100 iter), loss = 1.57922
I0628 23:55:18.820705  5893 solver.cpp:371]     Train net output #0: loss = 1.60231 (* 1 = 1.60231 loss)
I0628 23:55:18.820710  5893 sgd_solver.cpp:137] Iteration 71500, lr = 0.00553125, m = 0.9
I0628 23:55:37.232277  5893 solver.cpp:349] Iteration 71600 (5.43154 iter/s, 18.411s/100 iter), loss = 1.7614
I0628 23:55:37.232300  5893 solver.cpp:371]     Train net output #0: loss = 1.78138 (* 1 = 1.78138 loss)
I0628 23:55:37.232305  5893 sgd_solver.cpp:137] Iteration 71600, lr = 0.005525, m = 0.9
I0628 23:55:55.656812  5893 solver.cpp:349] Iteration 71700 (5.42773 iter/s, 18.4239s/100 iter), loss = 1.6739
I0628 23:55:55.656916  5893 solver.cpp:371]     Train net output #0: loss = 1.50832 (* 1 = 1.50832 loss)
I0628 23:55:55.656925  5893 sgd_solver.cpp:137] Iteration 71700, lr = 0.00551875, m = 0.9
I0628 23:56:14.100569  5893 solver.cpp:349] Iteration 71800 (5.4221 iter/s, 18.4431s/100 iter), loss = 1.60087
I0628 23:56:14.100592  5893 solver.cpp:371]     Train net output #0: loss = 1.41148 (* 1 = 1.41148 loss)
I0628 23:56:14.100596  5893 sgd_solver.cpp:137] Iteration 71800, lr = 0.0055125, m = 0.9
I0628 23:56:32.536216  5893 solver.cpp:349] Iteration 71900 (5.42446 iter/s, 18.435s/100 iter), loss = 1.4386
I0628 23:56:32.536257  5893 solver.cpp:371]     Train net output #0: loss = 1.47547 (* 1 = 1.47547 loss)
I0628 23:56:32.536260  5893 sgd_solver.cpp:137] Iteration 71900, lr = 0.00550625, m = 0.9
I0628 23:56:50.793905  5893 solver.cpp:401] Sparsity after update:
I0628 23:56:50.799150  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0628 23:56:50.799163  5893 net.cpp:2170] conv1a_param_0(0.36) 
I0628 23:56:50.799168  5893 net.cpp:2170] conv1b_param_0(0.72) 
I0628 23:56:50.799170  5893 net.cpp:2170] fc1000_param_0(0) 
I0628 23:56:50.799175  5893 net.cpp:2170] res2a_branch2a_param_0(0.72) 
I0628 23:56:50.799177  5893 net.cpp:2170] res2a_branch2b_param_0(0.72) 
I0628 23:56:50.799188  5893 net.cpp:2170] res3a_branch2a_param_0(0.72) 
I0628 23:56:50.799195  5893 net.cpp:2170] res3a_branch2b_param_0(0.72) 
I0628 23:56:50.799199  5893 net.cpp:2170] res4a_branch2a_param_0(0.72) 
I0628 23:56:50.799204  5893 net.cpp:2170] res4a_branch2b_param_0(0.72) 
I0628 23:56:50.799209  5893 net.cpp:2170] res5a_branch2a_param_0(0.72) 
I0628 23:56:50.799214  5893 net.cpp:2170] res5a_branch2b_param_0(0.72) 
I0628 23:56:50.799218  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.69457e+06/2.86678e+06) 0.591
I0628 23:56:50.799230  5893 solver.cpp:545] Iteration 72000, Testing net (#0)
I0628 23:57:15.002768  5888 data_reader.cpp:262] Starting prefetch of epoch 72
I0628 23:57:15.202965  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.569361
I0628 23:57:15.202985  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.797841
I0628 23:57:15.202989  5893 solver.cpp:630]     Test net output #2: loss = 1.89838 (* 1 = 1.89838 loss)
I0628 23:57:15.203006  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.403s
I0628 23:57:15.387141  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.73
I0628 23:57:16.041611  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0628 23:57:16.043072  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0628 23:57:16.043752  5893 solver.cpp:349] Iteration 72000 (2.29853 iter/s, 43.5061s/100 iter), loss = 1.91422
I0628 23:57:16.043769  5893 solver.cpp:371]     Train net output #0: loss = 1.79855 (* 1 = 1.79855 loss)
I0628 23:57:16.043774  5893 sgd_solver.cpp:137] Iteration 72000, lr = 0.0055, m = 0.9
I0628 23:57:34.475078  5893 solver.cpp:349] Iteration 72100 (5.42571 iter/s, 18.4308s/100 iter), loss = 1.25163
I0628 23:57:34.475102  5893 solver.cpp:371]     Train net output #0: loss = 1.49663 (* 1 = 1.49663 loss)
I0628 23:57:34.475106  5893 sgd_solver.cpp:137] Iteration 72100, lr = 0.00549375, m = 0.9
I0628 23:57:52.917409  5893 solver.cpp:349] Iteration 72200 (5.42248 iter/s, 18.4417s/100 iter), loss = 1.42011
I0628 23:57:52.917527  5893 solver.cpp:371]     Train net output #0: loss = 1.3589 (* 1 = 1.3589 loss)
I0628 23:57:52.917536  5893 sgd_solver.cpp:137] Iteration 72200, lr = 0.0054875, m = 0.9
I0628 23:58:11.334501  5893 solver.cpp:349] Iteration 72300 (5.42994 iter/s, 18.4164s/100 iter), loss = 1.50063
I0628 23:58:11.334524  5893 solver.cpp:371]     Train net output #0: loss = 1.17918 (* 1 = 1.17918 loss)
I0628 23:58:11.334528  5893 sgd_solver.cpp:137] Iteration 72300, lr = 0.00548125, m = 0.9
I0628 23:58:29.754679  5893 solver.cpp:349] Iteration 72400 (5.429 iter/s, 18.4196s/100 iter), loss = 1.58598
I0628 23:58:29.754748  5893 solver.cpp:371]     Train net output #0: loss = 1.60995 (* 1 = 1.60995 loss)
I0628 23:58:29.754753  5893 sgd_solver.cpp:137] Iteration 72400, lr = 0.005475, m = 0.9
I0628 23:58:48.173954  5893 solver.cpp:349] Iteration 72500 (5.42928 iter/s, 18.4186s/100 iter), loss = 1.49717
I0628 23:58:48.173976  5893 solver.cpp:371]     Train net output #0: loss = 1.49033 (* 1 = 1.49033 loss)
I0628 23:58:48.173980  5893 sgd_solver.cpp:137] Iteration 72500, lr = 0.00546875, m = 0.9
I0628 23:59:06.595268  5893 solver.cpp:349] Iteration 72600 (5.42867 iter/s, 18.4207s/100 iter), loss = 1.65451
I0628 23:59:06.595368  5893 solver.cpp:371]     Train net output #0: loss = 1.76397 (* 1 = 1.76397 loss)
I0628 23:59:06.595374  5893 sgd_solver.cpp:137] Iteration 72600, lr = 0.0054625, m = 0.9
I0628 23:59:25.048758  5893 solver.cpp:349] Iteration 72700 (5.41923 iter/s, 18.4528s/100 iter), loss = 1.75065
I0628 23:59:25.048777  5893 solver.cpp:371]     Train net output #0: loss = 1.82105 (* 1 = 1.82105 loss)
I0628 23:59:25.048781  5893 sgd_solver.cpp:137] Iteration 72700, lr = 0.00545625, m = 0.9
I0628 23:59:43.502790  5893 solver.cpp:349] Iteration 72800 (5.41904 iter/s, 18.4534s/100 iter), loss = 1.41211
I0628 23:59:43.502837  5893 solver.cpp:371]     Train net output #0: loss = 1.53128 (* 1 = 1.53128 loss)
I0628 23:59:43.502842  5893 sgd_solver.cpp:137] Iteration 72800, lr = 0.00545, m = 0.9
I0629 00:00:01.938791  5893 solver.cpp:349] Iteration 72900 (5.42435 iter/s, 18.4354s/100 iter), loss = 1.40867
I0629 00:00:01.938814  5893 solver.cpp:371]     Train net output #0: loss = 1.43867 (* 1 = 1.43867 loss)
I0629 00:00:01.938820  5893 sgd_solver.cpp:137] Iteration 72900, lr = 0.00544375, m = 0.9
I0629 00:00:20.254581  5893 solver.cpp:401] Sparsity after update:
I0629 00:00:20.259798  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:00:20.259806  5893 net.cpp:2170] conv1a_param_0(0.365) 
I0629 00:00:20.259815  5893 net.cpp:2170] conv1b_param_0(0.726) 
I0629 00:00:20.259819  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:00:20.259821  5893 net.cpp:2170] res2a_branch2a_param_0(0.73) 
I0629 00:00:20.259824  5893 net.cpp:2170] res2a_branch2b_param_0(0.73) 
I0629 00:00:20.259827  5893 net.cpp:2170] res3a_branch2a_param_0(0.73) 
I0629 00:00:20.259831  5893 net.cpp:2170] res3a_branch2b_param_0(0.73) 
I0629 00:00:20.259835  5893 net.cpp:2170] res4a_branch2a_param_0(0.73) 
I0629 00:00:20.259837  5893 net.cpp:2170] res4a_branch2b_param_0(0.73) 
I0629 00:00:20.259840  5893 net.cpp:2170] res5a_branch2a_param_0(0.73) 
I0629 00:00:20.259845  5893 net.cpp:2170] res5a_branch2b_param_0(0.73) 
I0629 00:00:20.259848  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.71809e+06/2.86678e+06) 0.599
I0629 00:00:20.259858  5893 solver.cpp:545] Iteration 73000, Testing net (#0)
I0629 00:00:44.596365  5888 data_reader.cpp:262] Starting prefetch of epoch 73
I0629 00:00:44.661204  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56176
I0629 00:00:44.661227  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79664
I0629 00:00:44.661232  5893 solver.cpp:630]     Test net output #2: loss = 1.90788 (* 1 = 1.90788 loss)
I0629 00:00:44.661250  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4007s
I0629 00:00:44.851132  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.74
I0629 00:00:45.513687  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:00:45.515156  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:00:45.515837  5893 solver.cpp:349] Iteration 73000 (2.29486 iter/s, 43.5757s/100 iter), loss = 1.53729
I0629 00:00:45.515856  5893 solver.cpp:371]     Train net output #0: loss = 1.49699 (* 1 = 1.49699 loss)
I0629 00:00:45.515861  5893 sgd_solver.cpp:137] Iteration 73000, lr = 0.0054375, m = 0.9
I0629 00:01:03.949659  5893 solver.cpp:349] Iteration 73100 (5.42498 iter/s, 18.4332s/100 iter), loss = 1.65244
I0629 00:01:03.949767  5893 solver.cpp:371]     Train net output #0: loss = 1.9811 (* 1 = 1.9811 loss)
I0629 00:01:03.949774  5893 sgd_solver.cpp:137] Iteration 73100, lr = 0.00543125, m = 0.9
I0629 00:01:22.370816  5893 solver.cpp:349] Iteration 73200 (5.42874 iter/s, 18.4205s/100 iter), loss = 1.61887
I0629 00:01:22.370839  5893 solver.cpp:371]     Train net output #0: loss = 1.71665 (* 1 = 1.71665 loss)
I0629 00:01:22.370844  5893 sgd_solver.cpp:137] Iteration 73200, lr = 0.005425, m = 0.9
I0629 00:01:40.807380  5893 solver.cpp:349] Iteration 73300 (5.42418 iter/s, 18.436s/100 iter), loss = 1.44115
I0629 00:01:40.807489  5893 solver.cpp:371]     Train net output #0: loss = 1.25407 (* 1 = 1.25407 loss)
I0629 00:01:40.807497  5893 sgd_solver.cpp:137] Iteration 73300, lr = 0.00541875, m = 0.9
I0629 00:01:59.262622  5893 solver.cpp:349] Iteration 73400 (5.41872 iter/s, 18.4546s/100 iter), loss = 1.64341
I0629 00:01:59.262646  5893 solver.cpp:371]     Train net output #0: loss = 1.74614 (* 1 = 1.74614 loss)
I0629 00:01:59.262650  5893 sgd_solver.cpp:137] Iteration 73400, lr = 0.0054125, m = 0.9
I0629 00:02:17.681886  5893 solver.cpp:349] Iteration 73500 (5.42927 iter/s, 18.4187s/100 iter), loss = 1.8262
I0629 00:02:17.681993  5893 solver.cpp:371]     Train net output #0: loss = 1.70238 (* 1 = 1.70238 loss)
I0629 00:02:17.682000  5893 sgd_solver.cpp:137] Iteration 73500, lr = 0.00540625, m = 0.9
I0629 00:02:36.108788  5893 solver.cpp:349] Iteration 73600 (5.42705 iter/s, 18.4262s/100 iter), loss = 1.41721
I0629 00:02:36.108811  5893 solver.cpp:371]     Train net output #0: loss = 1.55105 (* 1 = 1.55105 loss)
I0629 00:02:36.108815  5893 sgd_solver.cpp:137] Iteration 73600, lr = 0.0054, m = 0.9
I0629 00:02:54.555920  5893 solver.cpp:349] Iteration 73700 (5.42107 iter/s, 18.4465s/100 iter), loss = 1.48938
I0629 00:02:54.556020  5893 solver.cpp:371]     Train net output #0: loss = 1.18092 (* 1 = 1.18092 loss)
I0629 00:02:54.556026  5893 sgd_solver.cpp:137] Iteration 73700, lr = 0.00539375, m = 0.9
I0629 00:03:12.968456  5893 solver.cpp:349] Iteration 73800 (5.43128 iter/s, 18.4119s/100 iter), loss = 1.59427
I0629 00:03:12.968480  5893 solver.cpp:371]     Train net output #0: loss = 1.72482 (* 1 = 1.72482 loss)
I0629 00:03:12.968484  5893 sgd_solver.cpp:137] Iteration 73800, lr = 0.0053875, m = 0.9
I0629 00:03:31.438190  5893 solver.cpp:349] Iteration 73900 (5.41444 iter/s, 18.4691s/100 iter), loss = 1.38853
I0629 00:03:31.438277  5893 solver.cpp:371]     Train net output #0: loss = 1.36956 (* 1 = 1.36956 loss)
I0629 00:03:31.438282  5893 sgd_solver.cpp:137] Iteration 73900, lr = 0.00538125, m = 0.9
I0629 00:03:49.725705  5893 solver.cpp:401] Sparsity after update:
I0629 00:03:49.730744  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:03:49.730757  5893 net.cpp:2170] conv1a_param_0(0.37) 
I0629 00:03:49.730763  5893 net.cpp:2170] conv1b_param_0(0.729) 
I0629 00:03:49.730767  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:03:49.730770  5893 net.cpp:2170] res2a_branch2a_param_0(0.74) 
I0629 00:03:49.730773  5893 net.cpp:2170] res2a_branch2b_param_0(0.74) 
I0629 00:03:49.730777  5893 net.cpp:2170] res3a_branch2a_param_0(0.74) 
I0629 00:03:49.730780  5893 net.cpp:2170] res3a_branch2b_param_0(0.74) 
I0629 00:03:49.730783  5893 net.cpp:2170] res4a_branch2a_param_0(0.74) 
I0629 00:03:49.730787  5893 net.cpp:2170] res4a_branch2b_param_0(0.74) 
I0629 00:03:49.730789  5893 net.cpp:2170] res5a_branch2a_param_0(0.74) 
I0629 00:03:49.730792  5893 net.cpp:2170] res5a_branch2b_param_0(0.74) 
I0629 00:03:49.730798  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.74162e+06/2.86678e+06) 0.608
I0629 00:03:49.730806  5893 solver.cpp:545] Iteration 74000, Testing net (#0)
I0629 00:04:14.123296  5888 data_reader.cpp:262] Starting prefetch of epoch 74
I0629 00:04:14.185449  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56468
I0629 00:04:14.185474  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79416
I0629 00:04:14.185482  5893 solver.cpp:630]     Test net output #2: loss = 1.913 (* 1 = 1.913 loss)
I0629 00:04:14.185500  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4539s
I0629 00:04:14.369614  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.75
I0629 00:04:15.055734  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:04:15.057291  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:04:15.057981  5893 solver.cpp:349] Iteration 74000 (2.29261 iter/s, 43.6183s/100 iter), loss = 1.61277
I0629 00:04:15.058001  5893 solver.cpp:371]     Train net output #0: loss = 1.35098 (* 1 = 1.35098 loss)
I0629 00:04:15.058007  5893 sgd_solver.cpp:137] Iteration 74000, lr = 0.005375, m = 0.9
I0629 00:04:33.464522  5893 solver.cpp:349] Iteration 74100 (5.43303 iter/s, 18.4059s/100 iter), loss = 1.60993
I0629 00:04:33.464546  5893 solver.cpp:371]     Train net output #0: loss = 1.40706 (* 1 = 1.40706 loss)
I0629 00:04:33.464550  5893 sgd_solver.cpp:137] Iteration 74100, lr = 0.00536875, m = 0.9
I0629 00:04:51.890208  5893 solver.cpp:349] Iteration 74200 (5.42739 iter/s, 18.4251s/100 iter), loss = 1.78186
I0629 00:04:51.890310  5893 solver.cpp:371]     Train net output #0: loss = 1.62173 (* 1 = 1.62173 loss)
I0629 00:04:51.890316  5893 sgd_solver.cpp:137] Iteration 74200, lr = 0.0053625, m = 0.9
I0629 00:05:10.363334  5893 solver.cpp:349] Iteration 74300 (5.41347 iter/s, 18.4724s/100 iter), loss = 1.5752
I0629 00:05:10.363358  5893 solver.cpp:371]     Train net output #0: loss = 1.52956 (* 1 = 1.52956 loss)
I0629 00:05:10.363361  5893 sgd_solver.cpp:137] Iteration 74300, lr = 0.00535625, m = 0.9
I0629 00:05:28.790644  5893 solver.cpp:349] Iteration 74400 (5.42691 iter/s, 18.4267s/100 iter), loss = 1.53238
I0629 00:05:28.790748  5893 solver.cpp:371]     Train net output #0: loss = 1.55012 (* 1 = 1.55012 loss)
I0629 00:05:28.790755  5893 sgd_solver.cpp:137] Iteration 74400, lr = 0.00535, m = 0.9
I0629 00:05:47.244355  5893 solver.cpp:349] Iteration 74500 (5.41917 iter/s, 18.453s/100 iter), loss = 1.58006
I0629 00:05:47.244379  5893 solver.cpp:371]     Train net output #0: loss = 1.5378 (* 1 = 1.5378 loss)
I0629 00:05:47.244382  5893 sgd_solver.cpp:137] Iteration 74500, lr = 0.00534375, m = 0.9
I0629 00:06:05.687988  5893 solver.cpp:349] Iteration 74600 (5.42211 iter/s, 18.443s/100 iter), loss = 1.3832
I0629 00:06:05.688060  5893 solver.cpp:371]     Train net output #0: loss = 1.48299 (* 1 = 1.48299 loss)
I0629 00:06:05.688066  5893 sgd_solver.cpp:137] Iteration 74600, lr = 0.0053375, m = 0.9
I0629 00:06:24.151078  5893 solver.cpp:349] Iteration 74700 (5.41641 iter/s, 18.4624s/100 iter), loss = 1.48209
I0629 00:06:24.151101  5893 solver.cpp:371]     Train net output #0: loss = 1.58657 (* 1 = 1.58657 loss)
I0629 00:06:24.151105  5893 sgd_solver.cpp:137] Iteration 74700, lr = 0.00533125, m = 0.9
I0629 00:06:42.568658  5893 solver.cpp:349] Iteration 74800 (5.42978 iter/s, 18.417s/100 iter), loss = 1.69488
I0629 00:06:42.568759  5893 solver.cpp:371]     Train net output #0: loss = 1.7547 (* 1 = 1.7547 loss)
I0629 00:06:42.568766  5893 sgd_solver.cpp:137] Iteration 74800, lr = 0.005325, m = 0.9
I0629 00:07:01.031245  5893 solver.cpp:349] Iteration 74900 (5.41657 iter/s, 18.4619s/100 iter), loss = 1.6921
I0629 00:07:01.031265  5893 solver.cpp:371]     Train net output #0: loss = 1.7674 (* 1 = 1.7674 loss)
I0629 00:07:01.031270  5893 sgd_solver.cpp:137] Iteration 74900, lr = 0.00531875, m = 0.9
I0629 00:07:19.298812  5893 solver.cpp:401] Sparsity after update:
I0629 00:07:19.304038  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:07:19.304046  5893 net.cpp:2170] conv1a_param_0(0.375) 
I0629 00:07:19.304051  5893 net.cpp:2170] conv1b_param_0(0.729) 
I0629 00:07:19.304054  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:07:19.304055  5893 net.cpp:2170] res2a_branch2a_param_0(0.75) 
I0629 00:07:19.304057  5893 net.cpp:2170] res2a_branch2b_param_0(0.75) 
I0629 00:07:19.304059  5893 net.cpp:2170] res3a_branch2a_param_0(0.75) 
I0629 00:07:19.304061  5893 net.cpp:2170] res3a_branch2b_param_0(0.75) 
I0629 00:07:19.304064  5893 net.cpp:2170] res4a_branch2a_param_0(0.75) 
I0629 00:07:19.304065  5893 net.cpp:2170] res4a_branch2b_param_0(0.75) 
I0629 00:07:19.304067  5893 net.cpp:2170] res5a_branch2a_param_0(0.75) 
I0629 00:07:19.304069  5893 net.cpp:2170] res5a_branch2b_param_0(0.75) 
I0629 00:07:19.304070  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.76513e+06/2.86678e+06) 0.616
I0629 00:07:19.304077  5893 solver.cpp:545] Iteration 75000, Testing net (#0)
I0629 00:07:43.781272  5888 data_reader.cpp:262] Starting prefetch of epoch 75
I0629 00:07:43.842972  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56052
I0629 00:07:43.842995  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79384
I0629 00:07:43.843000  5893 solver.cpp:630]     Test net output #2: loss = 1.93025 (* 1 = 1.93025 loss)
I0629 00:07:43.843016  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5382s
I0629 00:07:44.028082  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.76
I0629 00:07:44.705827  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:07:44.707293  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:07:44.707965  5893 solver.cpp:349] Iteration 75000 (2.28962 iter/s, 43.6753s/100 iter), loss = 1.63308
I0629 00:07:44.707983  5893 solver.cpp:371]     Train net output #0: loss = 1.74976 (* 1 = 1.74976 loss)
I0629 00:07:44.707988  5893 sgd_solver.cpp:137] Iteration 75000, lr = 0.0053125, m = 0.9
I0629 00:07:56.929818  5875 data_reader.cpp:262] Starting prefetch of epoch 15
I0629 00:08:03.139782  5893 solver.cpp:349] Iteration 75100 (5.42558 iter/s, 18.4312s/100 iter), loss = 1.48759
I0629 00:08:03.139807  5893 solver.cpp:371]     Train net output #0: loss = 1.63583 (* 1 = 1.63583 loss)
I0629 00:08:03.139812  5893 sgd_solver.cpp:137] Iteration 75100, lr = 0.00530625, m = 0.9
I0629 00:08:21.580965  5893 solver.cpp:349] Iteration 75200 (5.42283 iter/s, 18.4405s/100 iter), loss = 1.58769
I0629 00:08:21.580987  5893 solver.cpp:371]     Train net output #0: loss = 1.7001 (* 1 = 1.7001 loss)
I0629 00:08:21.580991  5893 sgd_solver.cpp:137] Iteration 75200, lr = 0.0053, m = 0.9
I0629 00:08:40.018584  5893 solver.cpp:349] Iteration 75300 (5.42388 iter/s, 18.437s/100 iter), loss = 1.65346
I0629 00:08:40.018689  5893 solver.cpp:371]     Train net output #0: loss = 1.76941 (* 1 = 1.76941 loss)
I0629 00:08:40.018697  5893 sgd_solver.cpp:137] Iteration 75300, lr = 0.00529375, m = 0.9
I0629 00:08:58.448844  5893 solver.cpp:349] Iteration 75400 (5.42607 iter/s, 18.4295s/100 iter), loss = 1.70073
I0629 00:08:58.448863  5893 solver.cpp:371]     Train net output #0: loss = 1.85939 (* 1 = 1.85939 loss)
I0629 00:08:58.448868  5893 sgd_solver.cpp:137] Iteration 75400, lr = 0.0052875, m = 0.9
I0629 00:09:16.858850  5893 solver.cpp:349] Iteration 75500 (5.43201 iter/s, 18.4094s/100 iter), loss = 1.33396
I0629 00:09:16.858960  5893 solver.cpp:371]     Train net output #0: loss = 1.29225 (* 1 = 1.29225 loss)
I0629 00:09:16.858968  5893 sgd_solver.cpp:137] Iteration 75500, lr = 0.00528125, m = 0.9
I0629 00:09:35.285197  5893 solver.cpp:349] Iteration 75600 (5.42723 iter/s, 18.4256s/100 iter), loss = 1.58314
I0629 00:09:35.285221  5893 solver.cpp:371]     Train net output #0: loss = 1.6957 (* 1 = 1.6957 loss)
I0629 00:09:35.285225  5893 sgd_solver.cpp:137] Iteration 75600, lr = 0.005275, m = 0.9
I0629 00:09:53.737205  5893 solver.cpp:349] Iteration 75700 (5.41965 iter/s, 18.4514s/100 iter), loss = 1.78171
I0629 00:09:53.737303  5893 solver.cpp:371]     Train net output #0: loss = 1.89132 (* 1 = 1.89132 loss)
I0629 00:09:53.737310  5893 sgd_solver.cpp:137] Iteration 75700, lr = 0.00526875, m = 0.9
I0629 00:10:12.199467  5893 solver.cpp:349] Iteration 75800 (5.41667 iter/s, 18.4615s/100 iter), loss = 1.44734
I0629 00:10:12.199491  5893 solver.cpp:371]     Train net output #0: loss = 1.19245 (* 1 = 1.19245 loss)
I0629 00:10:12.199494  5893 sgd_solver.cpp:137] Iteration 75800, lr = 0.0052625, m = 0.9
I0629 00:10:30.653820  5893 solver.cpp:349] Iteration 75900 (5.41896 iter/s, 18.4537s/100 iter), loss = 1.28634
I0629 00:10:30.653934  5893 solver.cpp:371]     Train net output #0: loss = 1.18317 (* 1 = 1.18317 loss)
I0629 00:10:30.653939  5893 sgd_solver.cpp:137] Iteration 75900, lr = 0.00525625, m = 0.9
I0629 00:10:48.934856  5893 solver.cpp:401] Sparsity after update:
I0629 00:10:48.940064  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:10:48.940073  5893 net.cpp:2170] conv1a_param_0(0.38) 
I0629 00:10:48.940078  5893 net.cpp:2170] conv1b_param_0(0.732) 
I0629 00:10:48.940080  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:10:48.940083  5893 net.cpp:2170] res2a_branch2a_param_0(0.76) 
I0629 00:10:48.940084  5893 net.cpp:2170] res2a_branch2b_param_0(0.76) 
I0629 00:10:48.940086  5893 net.cpp:2170] res3a_branch2a_param_0(0.76) 
I0629 00:10:48.940088  5893 net.cpp:2170] res3a_branch2b_param_0(0.76) 
I0629 00:10:48.940090  5893 net.cpp:2170] res4a_branch2a_param_0(0.76) 
I0629 00:10:48.940093  5893 net.cpp:2170] res4a_branch2b_param_0(0.76) 
I0629 00:10:48.940094  5893 net.cpp:2170] res5a_branch2a_param_0(0.76) 
I0629 00:10:48.940096  5893 net.cpp:2170] res5a_branch2b_param_0(0.76) 
I0629 00:10:48.940098  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.78865e+06/2.86678e+06) 0.624
I0629 00:10:48.940105  5893 solver.cpp:545] Iteration 76000, Testing net (#0)
I0629 00:10:50.834995  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 00:11:13.248014  5888 data_reader.cpp:262] Starting prefetch of epoch 76
I0629 00:11:13.312911  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55936
I0629 00:11:13.312935  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79312
I0629 00:11:13.312940  5893 solver.cpp:630]     Test net output #2: loss = 1.92707 (* 1 = 1.92707 loss)
I0629 00:11:13.312959  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3721s
I0629 00:11:13.503001  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.77
I0629 00:11:14.203976  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:11:14.205446  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:11:14.206126  5893 solver.cpp:349] Iteration 76000 (2.29617 iter/s, 43.5508s/100 iter), loss = 1.89173
I0629 00:11:14.206143  5893 solver.cpp:371]     Train net output #0: loss = 2.47266 (* 1 = 2.47266 loss)
I0629 00:11:14.206149  5893 sgd_solver.cpp:137] Iteration 76000, lr = 0.00525, m = 0.9
I0629 00:11:32.644418  5893 solver.cpp:349] Iteration 76100 (5.42368 iter/s, 18.4377s/100 iter), loss = 1.61381
I0629 00:11:32.644438  5893 solver.cpp:371]     Train net output #0: loss = 1.37087 (* 1 = 1.37087 loss)
I0629 00:11:32.644444  5893 sgd_solver.cpp:137] Iteration 76100, lr = 0.00524375, m = 0.9
I0629 00:11:51.071173  5893 solver.cpp:349] Iteration 76200 (5.42708 iter/s, 18.4261s/100 iter), loss = 1.73684
I0629 00:11:51.071270  5893 solver.cpp:371]     Train net output #0: loss = 1.5791 (* 1 = 1.5791 loss)
I0629 00:11:51.071277  5893 sgd_solver.cpp:137] Iteration 76200, lr = 0.0052375, m = 0.9
I0629 00:12:09.542356  5893 solver.cpp:349] Iteration 76300 (5.41405 iter/s, 18.4705s/100 iter), loss = 1.57978
I0629 00:12:09.542378  5893 solver.cpp:371]     Train net output #0: loss = 1.41384 (* 1 = 1.41384 loss)
I0629 00:12:09.542382  5893 sgd_solver.cpp:137] Iteration 76300, lr = 0.00523125, m = 0.9
I0629 00:12:27.973994  5893 solver.cpp:349] Iteration 76400 (5.42564 iter/s, 18.431s/100 iter), loss = 1.74752
I0629 00:12:27.974071  5893 solver.cpp:371]     Train net output #0: loss = 1.37598 (* 1 = 1.37598 loss)
I0629 00:12:27.974077  5893 sgd_solver.cpp:137] Iteration 76400, lr = 0.005225, m = 0.9
I0629 00:12:46.400044  5893 solver.cpp:349] Iteration 76500 (5.42731 iter/s, 18.4253s/100 iter), loss = 1.37247
I0629 00:12:46.400074  5893 solver.cpp:371]     Train net output #0: loss = 1.45949 (* 1 = 1.45949 loss)
I0629 00:12:46.400077  5893 sgd_solver.cpp:137] Iteration 76500, lr = 0.00521875, m = 0.9
I0629 00:13:04.834851  5893 solver.cpp:349] Iteration 76600 (5.42471 iter/s, 18.4342s/100 iter), loss = 1.58856
I0629 00:13:04.834975  5893 solver.cpp:371]     Train net output #0: loss = 1.5915 (* 1 = 1.5915 loss)
I0629 00:13:04.834981  5893 sgd_solver.cpp:137] Iteration 76600, lr = 0.0052125, m = 0.9
I0629 00:13:23.284852  5893 solver.cpp:349] Iteration 76700 (5.42028 iter/s, 18.4492s/100 iter), loss = 1.41337
I0629 00:13:23.284874  5893 solver.cpp:371]     Train net output #0: loss = 1.54074 (* 1 = 1.54074 loss)
I0629 00:13:23.284878  5893 sgd_solver.cpp:137] Iteration 76700, lr = 0.00520625, m = 0.9
I0629 00:13:41.720098  5893 solver.cpp:349] Iteration 76800 (5.42458 iter/s, 18.4346s/100 iter), loss = 1.36832
I0629 00:13:41.720145  5893 solver.cpp:371]     Train net output #0: loss = 1.43639 (* 1 = 1.43639 loss)
I0629 00:13:41.720150  5893 sgd_solver.cpp:137] Iteration 76800, lr = 0.0052, m = 0.9
I0629 00:14:00.172652  5893 solver.cpp:349] Iteration 76900 (5.4195 iter/s, 18.4519s/100 iter), loss = 1.58477
I0629 00:14:00.172675  5893 solver.cpp:371]     Train net output #0: loss = 1.6973 (* 1 = 1.6973 loss)
I0629 00:14:00.172679  5893 sgd_solver.cpp:137] Iteration 76900, lr = 0.00519375, m = 0.9
I0629 00:14:18.462220  5893 solver.cpp:401] Sparsity after update:
I0629 00:14:18.467447  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:14:18.467461  5893 net.cpp:2170] conv1a_param_0(0.385) 
I0629 00:14:18.467468  5893 net.cpp:2170] conv1b_param_0(0.734) 
I0629 00:14:18.467471  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:14:18.467475  5893 net.cpp:2170] res2a_branch2a_param_0(0.77) 
I0629 00:14:18.467478  5893 net.cpp:2170] res2a_branch2b_param_0(0.77) 
I0629 00:14:18.467481  5893 net.cpp:2170] res3a_branch2a_param_0(0.77) 
I0629 00:14:18.467484  5893 net.cpp:2170] res3a_branch2b_param_0(0.77) 
I0629 00:14:18.467489  5893 net.cpp:2170] res4a_branch2a_param_0(0.77) 
I0629 00:14:18.467491  5893 net.cpp:2170] res4a_branch2b_param_0(0.77) 
I0629 00:14:18.467494  5893 net.cpp:2170] res5a_branch2a_param_0(0.77) 
I0629 00:14:18.467497  5893 net.cpp:2170] res5a_branch2b_param_0(0.77) 
I0629 00:14:18.467500  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.81217e+06/2.86678e+06) 0.632
I0629 00:14:18.467512  5893 solver.cpp:545] Iteration 77000, Testing net (#0)
I0629 00:14:42.734259  5888 data_reader.cpp:262] Starting prefetch of epoch 77
I0629 00:14:43.242710  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55536
I0629 00:14:43.242733  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78972
I0629 00:14:43.242738  5893 solver.cpp:630]     Test net output #2: loss = 1.94822 (* 1 = 1.94822 loss)
I0629 00:14:43.242755  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.7744s
I0629 00:14:43.427179  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.78
I0629 00:14:44.134199  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:14:44.135668  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:14:44.136340  5893 solver.cpp:349] Iteration 77000 (2.27468 iter/s, 43.9622s/100 iter), loss = 1.38826
I0629 00:14:44.136356  5893 solver.cpp:371]     Train net output #0: loss = 1.31728 (* 1 = 1.31728 loss)
I0629 00:14:44.136361  5893 sgd_solver.cpp:137] Iteration 77000, lr = 0.0051875, m = 0.9
I0629 00:15:02.560034  5893 solver.cpp:349] Iteration 77100 (5.42799 iter/s, 18.423s/100 iter), loss = 1.68858
I0629 00:15:02.560137  5893 solver.cpp:371]     Train net output #0: loss = 1.63572 (* 1 = 1.63572 loss)
I0629 00:15:02.560145  5893 sgd_solver.cpp:137] Iteration 77100, lr = 0.00518125, m = 0.9
I0629 00:15:20.982810  5893 solver.cpp:349] Iteration 77200 (5.42828 iter/s, 18.422s/100 iter), loss = 1.46168
I0629 00:15:20.982834  5893 solver.cpp:371]     Train net output #0: loss = 1.60133 (* 1 = 1.60133 loss)
I0629 00:15:20.982839  5893 sgd_solver.cpp:137] Iteration 77200, lr = 0.005175, m = 0.9
I0629 00:15:39.395144  5893 solver.cpp:349] Iteration 77300 (5.43134 iter/s, 18.4117s/100 iter), loss = 1.6836
I0629 00:15:39.395267  5893 solver.cpp:371]     Train net output #0: loss = 1.62671 (* 1 = 1.62671 loss)
I0629 00:15:39.395274  5893 sgd_solver.cpp:137] Iteration 77300, lr = 0.00516875, m = 0.9
I0629 00:15:57.855309  5893 solver.cpp:349] Iteration 77400 (5.41729 iter/s, 18.4594s/100 iter), loss = 1.50693
I0629 00:15:57.855331  5893 solver.cpp:371]     Train net output #0: loss = 1.61173 (* 1 = 1.61173 loss)
I0629 00:15:57.855336  5893 sgd_solver.cpp:137] Iteration 77400, lr = 0.0051625, m = 0.9
I0629 00:16:16.280645  5893 solver.cpp:349] Iteration 77500 (5.4275 iter/s, 18.4247s/100 iter), loss = 1.511
I0629 00:16:16.280746  5893 solver.cpp:371]     Train net output #0: loss = 1.36921 (* 1 = 1.36921 loss)
I0629 00:16:16.280753  5893 sgd_solver.cpp:137] Iteration 77500, lr = 0.00515625, m = 0.9
I0629 00:16:34.720266  5893 solver.cpp:349] Iteration 77600 (5.42332 iter/s, 18.4389s/100 iter), loss = 1.52827
I0629 00:16:34.720288  5893 solver.cpp:371]     Train net output #0: loss = 1.42711 (* 1 = 1.42711 loss)
I0629 00:16:34.720293  5893 sgd_solver.cpp:137] Iteration 77600, lr = 0.00515, m = 0.9
I0629 00:16:53.160696  5893 solver.cpp:349] Iteration 77700 (5.42306 iter/s, 18.4398s/100 iter), loss = 1.38512
I0629 00:16:53.160797  5893 solver.cpp:371]     Train net output #0: loss = 1.6058 (* 1 = 1.6058 loss)
I0629 00:16:53.160804  5893 sgd_solver.cpp:137] Iteration 77700, lr = 0.00514375, m = 0.9
I0629 00:17:11.619505  5893 solver.cpp:349] Iteration 77800 (5.41769 iter/s, 18.4581s/100 iter), loss = 1.91772
I0629 00:17:11.619529  5893 solver.cpp:371]     Train net output #0: loss = 1.80502 (* 1 = 1.80502 loss)
I0629 00:17:11.619534  5893 sgd_solver.cpp:137] Iteration 77800, lr = 0.0051375, m = 0.9
I0629 00:17:30.075094  5893 solver.cpp:349] Iteration 77900 (5.41861 iter/s, 18.4549s/100 iter), loss = 1.40354
I0629 00:17:30.075196  5893 solver.cpp:371]     Train net output #0: loss = 1.39135 (* 1 = 1.39135 loss)
I0629 00:17:30.075203  5893 sgd_solver.cpp:137] Iteration 77900, lr = 0.00513125, m = 0.9
I0629 00:17:48.324024  5893 solver.cpp:401] Sparsity after update:
I0629 00:17:48.328104  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:17:48.328111  5893 net.cpp:2170] conv1a_param_0(0.39) 
I0629 00:17:48.328117  5893 net.cpp:2170] conv1b_param_0(0.735) 
I0629 00:17:48.328120  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:17:48.328122  5893 net.cpp:2170] res2a_branch2a_param_0(0.78) 
I0629 00:17:48.328125  5893 net.cpp:2170] res2a_branch2b_param_0(0.78) 
I0629 00:17:48.328126  5893 net.cpp:2170] res3a_branch2a_param_0(0.78) 
I0629 00:17:48.328127  5893 net.cpp:2170] res3a_branch2b_param_0(0.78) 
I0629 00:17:48.328130  5893 net.cpp:2170] res4a_branch2a_param_0(0.78) 
I0629 00:17:48.328131  5893 net.cpp:2170] res4a_branch2b_param_0(0.78) 
I0629 00:17:48.328133  5893 net.cpp:2170] res5a_branch2a_param_0(0.78) 
I0629 00:17:48.328135  5893 net.cpp:2170] res5a_branch2b_param_0(0.78) 
I0629 00:17:48.328137  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.83568e+06/2.86678e+06) 0.64
I0629 00:17:48.328145  5893 solver.cpp:545] Iteration 78000, Testing net (#0)
I0629 00:18:12.756705  5888 data_reader.cpp:262] Starting prefetch of epoch 78
I0629 00:18:12.818958  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5526
I0629 00:18:12.818982  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78716
I0629 00:18:12.818989  5893 solver.cpp:630]     Test net output #2: loss = 1.95084 (* 1 = 1.95084 loss)
I0629 00:18:12.819008  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.49s
I0629 00:18:13.003921  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.79
I0629 00:18:13.718555  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:18:13.720027  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:18:13.720700  5893 solver.cpp:349] Iteration 78000 (2.29127 iter/s, 43.644s/100 iter), loss = 1.53117
I0629 00:18:13.720718  5893 solver.cpp:371]     Train net output #0: loss = 1.611 (* 1 = 1.611 loss)
I0629 00:18:13.720726  5893 sgd_solver.cpp:137] Iteration 78000, lr = 0.005125, m = 0.9
I0629 00:18:32.171563  5893 solver.cpp:349] Iteration 78100 (5.42 iter/s, 18.4502s/100 iter), loss = 1.78052
I0629 00:18:32.171586  5893 solver.cpp:371]     Train net output #0: loss = 1.98947 (* 1 = 1.98947 loss)
I0629 00:18:32.171589  5893 sgd_solver.cpp:137] Iteration 78100, lr = 0.00511875, m = 0.9
I0629 00:18:50.627280  5893 solver.cpp:349] Iteration 78200 (5.41857 iter/s, 18.455s/100 iter), loss = 1.54768
I0629 00:18:50.627396  5893 solver.cpp:371]     Train net output #0: loss = 1.19156 (* 1 = 1.19156 loss)
I0629 00:18:50.627403  5893 sgd_solver.cpp:137] Iteration 78200, lr = 0.0051125, m = 0.9
I0629 00:19:09.049672  5893 solver.cpp:349] Iteration 78300 (5.4284 iter/s, 18.4216s/100 iter), loss = 1.56255
I0629 00:19:09.049690  5893 solver.cpp:371]     Train net output #0: loss = 1.4034 (* 1 = 1.4034 loss)
I0629 00:19:09.049695  5893 sgd_solver.cpp:137] Iteration 78300, lr = 0.00510625, m = 0.9
I0629 00:19:27.466892  5893 solver.cpp:349] Iteration 78400 (5.4299 iter/s, 18.4166s/100 iter), loss = 1.80151
I0629 00:19:27.466990  5893 solver.cpp:371]     Train net output #0: loss = 1.66541 (* 1 = 1.66541 loss)
I0629 00:19:27.466996  5893 sgd_solver.cpp:137] Iteration 78400, lr = 0.0051, m = 0.9
I0629 00:19:45.904283  5893 solver.cpp:349] Iteration 78500 (5.42398 iter/s, 18.4366s/100 iter), loss = 1.63173
I0629 00:19:45.904306  5893 solver.cpp:371]     Train net output #0: loss = 1.90825 (* 1 = 1.90825 loss)
I0629 00:19:45.904311  5893 sgd_solver.cpp:137] Iteration 78500, lr = 0.00509375, m = 0.9
I0629 00:20:04.346701  5893 solver.cpp:349] Iteration 78600 (5.42246 iter/s, 18.4418s/100 iter), loss = 1.74035
I0629 00:20:04.346745  5893 solver.cpp:371]     Train net output #0: loss = 1.68988 (* 1 = 1.68988 loss)
I0629 00:20:04.346750  5893 sgd_solver.cpp:137] Iteration 78600, lr = 0.0050875, m = 0.9
I0629 00:20:22.765602  5893 solver.cpp:349] Iteration 78700 (5.42939 iter/s, 18.4183s/100 iter), loss = 1.50641
I0629 00:20:22.765627  5893 solver.cpp:371]     Train net output #0: loss = 1.46514 (* 1 = 1.46514 loss)
I0629 00:20:22.765632  5893 sgd_solver.cpp:137] Iteration 78700, lr = 0.00508125, m = 0.9
I0629 00:20:41.190943  5893 solver.cpp:349] Iteration 78800 (5.42748 iter/s, 18.4247s/100 iter), loss = 1.61337
I0629 00:20:41.191056  5893 solver.cpp:371]     Train net output #0: loss = 1.6514 (* 1 = 1.6514 loss)
I0629 00:20:41.191061  5893 sgd_solver.cpp:137] Iteration 78800, lr = 0.005075, m = 0.9
I0629 00:20:59.627209  5893 solver.cpp:349] Iteration 78900 (5.42429 iter/s, 18.4356s/100 iter), loss = 1.75658
I0629 00:20:59.627233  5893 solver.cpp:371]     Train net output #0: loss = 1.96378 (* 1 = 1.96378 loss)
I0629 00:20:59.627238  5893 sgd_solver.cpp:137] Iteration 78900, lr = 0.00506875, m = 0.9
I0629 00:21:17.873805  5893 solver.cpp:401] Sparsity after update:
I0629 00:21:17.878988  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:21:17.878996  5893 net.cpp:2170] conv1a_param_0(0.395) 
I0629 00:21:17.879003  5893 net.cpp:2170] conv1b_param_0(0.736) 
I0629 00:21:17.879004  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:21:17.879006  5893 net.cpp:2170] res2a_branch2a_param_0(0.79) 
I0629 00:21:17.879009  5893 net.cpp:2170] res2a_branch2b_param_0(0.79) 
I0629 00:21:17.879010  5893 net.cpp:2170] res3a_branch2a_param_0(0.79) 
I0629 00:21:17.879012  5893 net.cpp:2170] res3a_branch2b_param_0(0.79) 
I0629 00:21:17.879014  5893 net.cpp:2170] res4a_branch2a_param_0(0.79) 
I0629 00:21:17.879016  5893 net.cpp:2170] res4a_branch2b_param_0(0.79) 
I0629 00:21:17.879019  5893 net.cpp:2170] res5a_branch2a_param_0(0.79) 
I0629 00:21:17.879019  5893 net.cpp:2170] res5a_branch2b_param_0(0.79) 
I0629 00:21:17.879021  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.8592e+06/2.86678e+06) 0.649
I0629 00:21:17.879029  5893 solver.cpp:545] Iteration 79000, Testing net (#0)
I0629 00:21:42.101747  5888 data_reader.cpp:262] Starting prefetch of epoch 79
I0629 00:21:42.238453  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55328
I0629 00:21:42.238474  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78988
I0629 00:21:42.238479  5893 solver.cpp:630]     Test net output #2: loss = 1.95354 (* 1 = 1.95354 loss)
I0629 00:21:42.238498  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3587s
I0629 00:21:42.426661  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.8
I0629 00:21:43.153259  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:21:43.154731  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:21:43.155411  5893 solver.cpp:349] Iteration 79000 (2.29743 iter/s, 43.5268s/100 iter), loss = 1.64754
I0629 00:21:43.155426  5893 solver.cpp:371]     Train net output #0: loss = 2.0332 (* 1 = 2.0332 loss)
I0629 00:21:43.155429  5893 sgd_solver.cpp:137] Iteration 79000, lr = 0.0050625, m = 0.9
I0629 00:22:01.609174  5893 solver.cpp:349] Iteration 79100 (5.41912 iter/s, 18.4532s/100 iter), loss = 1.86273
I0629 00:22:01.609275  5893 solver.cpp:371]     Train net output #0: loss = 2.10169 (* 1 = 2.10169 loss)
I0629 00:22:01.609280  5893 sgd_solver.cpp:137] Iteration 79100, lr = 0.00505625, m = 0.9
I0629 00:22:20.038782  5893 solver.cpp:349] Iteration 79200 (5.42625 iter/s, 18.4289s/100 iter), loss = 1.68714
I0629 00:22:20.038803  5893 solver.cpp:371]     Train net output #0: loss = 1.52447 (* 1 = 1.52447 loss)
I0629 00:22:20.038810  5893 sgd_solver.cpp:137] Iteration 79200, lr = 0.00505, m = 0.9
I0629 00:22:38.490068  5893 solver.cpp:349] Iteration 79300 (5.41986 iter/s, 18.4507s/100 iter), loss = 1.46721
I0629 00:22:38.490175  5893 solver.cpp:371]     Train net output #0: loss = 1.50864 (* 1 = 1.50864 loss)
I0629 00:22:38.490181  5893 sgd_solver.cpp:137] Iteration 79300, lr = 0.00504375, m = 0.9
I0629 00:22:56.937357  5893 solver.cpp:349] Iteration 79400 (5.42105 iter/s, 18.4466s/100 iter), loss = 1.40704
I0629 00:22:56.937381  5893 solver.cpp:371]     Train net output #0: loss = 1.47017 (* 1 = 1.47017 loss)
I0629 00:22:56.937384  5893 sgd_solver.cpp:137] Iteration 79400, lr = 0.0050375, m = 0.9
I0629 00:23:15.397792  5893 solver.cpp:349] Iteration 79500 (5.41717 iter/s, 18.4598s/100 iter), loss = 1.25265
I0629 00:23:15.397893  5893 solver.cpp:371]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0629 00:23:15.397900  5893 sgd_solver.cpp:137] Iteration 79500, lr = 0.00503125, m = 0.9
I0629 00:23:33.866627  5893 solver.cpp:349] Iteration 79600 (5.41473 iter/s, 18.4681s/100 iter), loss = 1.97342
I0629 00:23:33.866650  5893 solver.cpp:371]     Train net output #0: loss = 2.07876 (* 1 = 2.07876 loss)
I0629 00:23:33.866654  5893 sgd_solver.cpp:137] Iteration 79600, lr = 0.005025, m = 0.9
I0629 00:23:52.329315  5893 solver.cpp:349] Iteration 79700 (5.41651 iter/s, 18.4621s/100 iter), loss = 1.90762
I0629 00:23:52.329414  5893 solver.cpp:371]     Train net output #0: loss = 2.07667 (* 1 = 2.07667 loss)
I0629 00:23:52.329421  5893 sgd_solver.cpp:137] Iteration 79700, lr = 0.00501875, m = 0.9
I0629 00:24:10.750785  5893 solver.cpp:349] Iteration 79800 (5.42865 iter/s, 18.4208s/100 iter), loss = 1.46547
I0629 00:24:10.750808  5893 solver.cpp:371]     Train net output #0: loss = 1.52524 (* 1 = 1.52524 loss)
I0629 00:24:10.750813  5893 sgd_solver.cpp:137] Iteration 79800, lr = 0.0050125, m = 0.9
I0629 00:24:29.166950  5893 solver.cpp:349] Iteration 79900 (5.43019 iter/s, 18.4156s/100 iter), loss = 1.64627
I0629 00:24:29.167024  5893 solver.cpp:371]     Train net output #0: loss = 1.62786 (* 1 = 1.62786 loss)
I0629 00:24:29.167031  5893 sgd_solver.cpp:137] Iteration 79900, lr = 0.00500625, m = 0.9
I0629 00:24:47.425392  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_80000.caffemodel
I0629 00:24:47.438350  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_80000.solverstate
I0629 00:24:47.443409  5893 solver.cpp:401] Sparsity after update:
I0629 00:24:47.444248  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:24:47.444257  5893 net.cpp:2170] conv1a_param_0(0.4) 
I0629 00:24:47.444264  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:24:47.444267  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:24:47.444268  5893 net.cpp:2170] res2a_branch2a_param_0(0.8) 
I0629 00:24:47.444270  5893 net.cpp:2170] res2a_branch2b_param_0(0.8) 
I0629 00:24:47.444272  5893 net.cpp:2170] res3a_branch2a_param_0(0.8) 
I0629 00:24:47.444274  5893 net.cpp:2170] res3a_branch2b_param_0(0.8) 
I0629 00:24:47.444277  5893 net.cpp:2170] res4a_branch2a_param_0(0.8) 
I0629 00:24:47.444278  5893 net.cpp:2170] res4a_branch2b_param_0(0.8) 
I0629 00:24:47.444279  5893 net.cpp:2170] res5a_branch2a_param_0(0.8) 
I0629 00:24:47.444281  5893 net.cpp:2170] res5a_branch2b_param_0(0.8) 
I0629 00:24:47.444283  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.88271e+06/2.86678e+06) 0.657
I0629 00:24:47.444291  5893 solver.cpp:545] Iteration 80000, Testing net (#0)
I0629 00:25:11.885519  5888 data_reader.cpp:262] Starting prefetch of epoch 80
I0629 00:25:11.947518  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54788
I0629 00:25:11.947542  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78456
I0629 00:25:11.947547  5893 solver.cpp:630]     Test net output #2: loss = 1.97445 (* 1 = 1.97445 loss)
I0629 00:25:11.947566  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5025s
I0629 00:25:12.132172  5913 solver.cpp:446] Finding and applying thresholds. Target sparsity = 0.81
I0629 00:25:12.860296  5913 net.cpp:2177] All zero weights of convolution layers are frozen
I0629 00:25:12.861779  5913 inner_product_layer.cpp:14] all zero weights of fc1000 are frozen
I0629 00:25:12.862459  5893 solver.cpp:349] Iteration 80000 (2.28864 iter/s, 43.694s/100 iter), loss = 1.57903
I0629 00:25:12.862478  5893 solver.cpp:371]     Train net output #0: loss = 1.61746 (* 1 = 1.61746 loss)
I0629 00:25:12.862483  5893 sgd_solver.cpp:137] Iteration 80000, lr = 0.005, m = 0.9
I0629 00:25:25.921878  5875 data_reader.cpp:262] Starting prefetch of epoch 16
I0629 00:25:31.303122  5893 solver.cpp:349] Iteration 80100 (5.42298 iter/s, 18.44s/100 iter), loss = 1.66223
I0629 00:25:31.303143  5893 solver.cpp:371]     Train net output #0: loss = 1.53901 (* 1 = 1.53901 loss)
I0629 00:25:31.303148  5893 sgd_solver.cpp:137] Iteration 80100, lr = 0.00499375, m = 0.9
I0629 00:25:49.749560  5893 solver.cpp:349] Iteration 80200 (5.42128 iter/s, 18.4458s/100 iter), loss = 1.66454
I0629 00:25:49.749662  5893 solver.cpp:371]     Train net output #0: loss = 1.30141 (* 1 = 1.30141 loss)
I0629 00:25:49.749671  5893 sgd_solver.cpp:137] Iteration 80200, lr = 0.0049875, m = 0.9
I0629 00:26:08.192975  5893 solver.cpp:349] Iteration 80300 (5.4222 iter/s, 18.4427s/100 iter), loss = 1.95612
I0629 00:26:08.192998  5893 solver.cpp:371]     Train net output #0: loss = 2.00798 (* 1 = 2.00798 loss)
I0629 00:26:08.193003  5893 sgd_solver.cpp:137] Iteration 80300, lr = 0.00498125, m = 0.9
I0629 00:26:26.694475  5893 solver.cpp:349] Iteration 80400 (5.40515 iter/s, 18.5009s/100 iter), loss = 1.42843
I0629 00:26:26.694545  5893 solver.cpp:371]     Train net output #0: loss = 1.47587 (* 1 = 1.47587 loss)
I0629 00:26:26.694550  5893 sgd_solver.cpp:137] Iteration 80400, lr = 0.004975, m = 0.9
I0629 00:26:45.134918  5893 solver.cpp:349] Iteration 80500 (5.42306 iter/s, 18.4398s/100 iter), loss = 1.88764
I0629 00:26:45.134943  5893 solver.cpp:371]     Train net output #0: loss = 2.00717 (* 1 = 2.00717 loss)
I0629 00:26:45.134948  5893 sgd_solver.cpp:137] Iteration 80500, lr = 0.00496875, m = 0.9
I0629 00:27:03.572243  5893 solver.cpp:349] Iteration 80600 (5.42397 iter/s, 18.4367s/100 iter), loss = 1.87524
I0629 00:27:03.572325  5893 solver.cpp:371]     Train net output #0: loss = 1.73195 (* 1 = 1.73195 loss)
I0629 00:27:03.572330  5893 sgd_solver.cpp:137] Iteration 80600, lr = 0.0049625, m = 0.9
I0629 00:27:22.004897  5893 solver.cpp:349] Iteration 80700 (5.42536 iter/s, 18.432s/100 iter), loss = 1.6878
I0629 00:27:22.004920  5893 solver.cpp:371]     Train net output #0: loss = 1.91774 (* 1 = 1.91774 loss)
I0629 00:27:22.004925  5893 sgd_solver.cpp:137] Iteration 80700, lr = 0.00495625, m = 0.9
I0629 00:27:40.441179  5893 solver.cpp:349] Iteration 80800 (5.42427 iter/s, 18.4356s/100 iter), loss = 1.89874
I0629 00:27:40.441283  5893 solver.cpp:371]     Train net output #0: loss = 1.76117 (* 1 = 1.76117 loss)
I0629 00:27:40.441290  5893 sgd_solver.cpp:137] Iteration 80800, lr = 0.00495, m = 0.9
I0629 00:27:58.893712  5893 solver.cpp:349] Iteration 80900 (5.41952 iter/s, 18.4518s/100 iter), loss = 1.18248
I0629 00:27:58.893735  5893 solver.cpp:371]     Train net output #0: loss = 1.17412 (* 1 = 1.17412 loss)
I0629 00:27:58.893739  5893 sgd_solver.cpp:137] Iteration 80900, lr = 0.00494375, m = 0.9
I0629 00:28:17.162520  5893 solver.cpp:401] Sparsity after update:
I0629 00:28:17.167717  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:28:17.167726  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:28:17.167732  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:28:17.167733  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:28:17.167737  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:28:17.167738  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:28:17.167742  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:28:17.167743  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:28:17.167745  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:28:17.167748  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:28:17.167750  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:28:17.167752  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:28:17.167753  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:28:17.167762  5893 solver.cpp:545] Iteration 81000, Testing net (#0)
I0629 00:28:19.164082  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 00:28:41.350461  5888 data_reader.cpp:262] Starting prefetch of epoch 81
I0629 00:28:41.414933  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54768
I0629 00:28:41.414954  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7824
I0629 00:28:41.414959  5893 solver.cpp:630]     Test net output #2: loss = 2.00236 (* 1 = 2.00236 loss)
I0629 00:28:41.414974  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2464s
I0629 00:28:41.599499  5893 solver.cpp:349] Iteration 81000 (2.34168 iter/s, 42.7044s/100 iter), loss = 1.82237
I0629 00:28:41.599524  5893 solver.cpp:371]     Train net output #0: loss = 1.78939 (* 1 = 1.78939 loss)
I0629 00:28:41.599527  5893 sgd_solver.cpp:137] Iteration 81000, lr = 0.0049375, m = 0.9
I0629 00:29:00.031208  5893 solver.cpp:349] Iteration 81100 (5.42562 iter/s, 18.4311s/100 iter), loss = 1.70165
I0629 00:29:00.031276  5893 solver.cpp:371]     Train net output #0: loss = 1.76057 (* 1 = 1.76057 loss)
I0629 00:29:00.031282  5893 sgd_solver.cpp:137] Iteration 81100, lr = 0.00493125, m = 0.9
I0629 00:29:18.456678  5893 solver.cpp:349] Iteration 81200 (5.42747 iter/s, 18.4248s/100 iter), loss = 1.72617
I0629 00:29:18.456701  5893 solver.cpp:371]     Train net output #0: loss = 1.80807 (* 1 = 1.80807 loss)
I0629 00:29:18.456704  5893 sgd_solver.cpp:137] Iteration 81200, lr = 0.004925, m = 0.9
I0629 00:29:36.891232  5893 solver.cpp:349] Iteration 81300 (5.42478 iter/s, 18.4339s/100 iter), loss = 1.94771
I0629 00:29:36.891331  5893 solver.cpp:371]     Train net output #0: loss = 1.91624 (* 1 = 1.91624 loss)
I0629 00:29:36.891337  5893 sgd_solver.cpp:137] Iteration 81300, lr = 0.00491875, m = 0.9
I0629 00:29:55.325312  5893 solver.cpp:349] Iteration 81400 (5.42495 iter/s, 18.4334s/100 iter), loss = 1.75912
I0629 00:29:55.325336  5893 solver.cpp:371]     Train net output #0: loss = 1.91965 (* 1 = 1.91965 loss)
I0629 00:29:55.325340  5893 sgd_solver.cpp:137] Iteration 81400, lr = 0.0049125, m = 0.9
I0629 00:30:13.772544  5893 solver.cpp:349] Iteration 81500 (5.42106 iter/s, 18.4466s/100 iter), loss = 1.43928
I0629 00:30:13.772660  5893 solver.cpp:371]     Train net output #0: loss = 1.60272 (* 1 = 1.60272 loss)
I0629 00:30:13.772665  5893 sgd_solver.cpp:137] Iteration 81500, lr = 0.00490625, m = 0.9
I0629 00:30:32.216847  5893 solver.cpp:349] Iteration 81600 (5.42195 iter/s, 18.4436s/100 iter), loss = 1.70168
I0629 00:30:32.216871  5893 solver.cpp:371]     Train net output #0: loss = 1.57555 (* 1 = 1.57555 loss)
I0629 00:30:32.216876  5893 sgd_solver.cpp:137] Iteration 81600, lr = 0.0049, m = 0.9
I0629 00:30:50.641490  5893 solver.cpp:349] Iteration 81700 (5.4277 iter/s, 18.424s/100 iter), loss = 1.65514
I0629 00:30:50.641580  5893 solver.cpp:371]     Train net output #0: loss = 1.67946 (* 1 = 1.67946 loss)
I0629 00:30:50.641585  5893 sgd_solver.cpp:137] Iteration 81700, lr = 0.00489375, m = 0.9
I0629 00:31:09.084481  5893 solver.cpp:349] Iteration 81800 (5.42232 iter/s, 18.4423s/100 iter), loss = 1.49991
I0629 00:31:09.084503  5893 solver.cpp:371]     Train net output #0: loss = 1.54512 (* 1 = 1.54512 loss)
I0629 00:31:09.084507  5893 sgd_solver.cpp:137] Iteration 81800, lr = 0.0048875, m = 0.9
I0629 00:31:27.561213  5893 solver.cpp:349] Iteration 81900 (5.4124 iter/s, 18.4761s/100 iter), loss = 1.86345
I0629 00:31:27.561313  5893 solver.cpp:371]     Train net output #0: loss = 1.85544 (* 1 = 1.85544 loss)
I0629 00:31:27.561321  5893 sgd_solver.cpp:137] Iteration 81900, lr = 0.00488125, m = 0.9
I0629 00:31:45.907935  5893 solver.cpp:401] Sparsity after update:
I0629 00:31:45.912897  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:31:45.912911  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:31:45.912916  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:31:45.912919  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:31:45.912920  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:31:45.912922  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:31:45.912925  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:31:45.912925  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:31:45.912927  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:31:45.912930  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:31:45.912931  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:31:45.912933  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:31:45.912935  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:31:45.912943  5893 solver.cpp:545] Iteration 82000, Testing net (#0)
I0629 00:32:10.263180  5888 data_reader.cpp:262] Starting prefetch of epoch 82
I0629 00:32:10.325425  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.54868
I0629 00:32:10.325448  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7858
I0629 00:32:10.325453  5893 solver.cpp:630]     Test net output #2: loss = 1.98015 (* 1 = 1.98015 loss)
I0629 00:32:10.325469  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4117s
I0629 00:32:10.510149  5893 solver.cpp:349] Iteration 82000 (2.32843 iter/s, 42.9474s/100 iter), loss = 1.48375
I0629 00:32:10.510175  5893 solver.cpp:371]     Train net output #0: loss = 1.47199 (* 1 = 1.47199 loss)
I0629 00:32:10.510180  5893 sgd_solver.cpp:137] Iteration 82000, lr = 0.004875, m = 0.9
I0629 00:32:28.950314  5893 solver.cpp:349] Iteration 82100 (5.42314 iter/s, 18.4395s/100 iter), loss = 1.4366
I0629 00:32:28.950335  5893 solver.cpp:371]     Train net output #0: loss = 1.46892 (* 1 = 1.46892 loss)
I0629 00:32:28.950340  5893 sgd_solver.cpp:137] Iteration 82100, lr = 0.00486875, m = 0.9
I0629 00:32:47.397361  5893 solver.cpp:349] Iteration 82200 (5.42111 iter/s, 18.4464s/100 iter), loss = 1.75642
I0629 00:32:47.397455  5893 solver.cpp:371]     Train net output #0: loss = 1.5152 (* 1 = 1.5152 loss)
I0629 00:32:47.397460  5893 sgd_solver.cpp:137] Iteration 82200, lr = 0.0048625, m = 0.9
I0629 00:33:05.828454  5893 solver.cpp:349] Iteration 82300 (5.42581 iter/s, 18.4304s/100 iter), loss = 1.91182
I0629 00:33:05.828477  5893 solver.cpp:371]     Train net output #0: loss = 1.64216 (* 1 = 1.64216 loss)
I0629 00:33:05.828481  5893 sgd_solver.cpp:137] Iteration 82300, lr = 0.00485625, m = 0.9
I0629 00:33:24.240262  5893 solver.cpp:349] Iteration 82400 (5.43147 iter/s, 18.4112s/100 iter), loss = 1.50056
I0629 00:33:24.240329  5893 solver.cpp:371]     Train net output #0: loss = 1.17201 (* 1 = 1.17201 loss)
I0629 00:33:24.240334  5893 sgd_solver.cpp:137] Iteration 82400, lr = 0.00485, m = 0.9
I0629 00:33:42.655220  5893 solver.cpp:349] Iteration 82500 (5.43056 iter/s, 18.4143s/100 iter), loss = 1.83866
I0629 00:33:42.655244  5893 solver.cpp:371]     Train net output #0: loss = 1.74025 (* 1 = 1.74025 loss)
I0629 00:33:42.655248  5893 sgd_solver.cpp:137] Iteration 82500, lr = 0.00484375, m = 0.9
I0629 00:34:01.085152  5893 solver.cpp:349] Iteration 82600 (5.42613 iter/s, 18.4293s/100 iter), loss = 1.71154
I0629 00:34:01.085258  5893 solver.cpp:371]     Train net output #0: loss = 1.5019 (* 1 = 1.5019 loss)
I0629 00:34:01.085266  5893 sgd_solver.cpp:137] Iteration 82600, lr = 0.0048375, m = 0.9
I0629 00:34:19.520066  5893 solver.cpp:349] Iteration 82700 (5.42469 iter/s, 18.4342s/100 iter), loss = 1.66495
I0629 00:34:19.520088  5893 solver.cpp:371]     Train net output #0: loss = 1.74533 (* 1 = 1.74533 loss)
I0629 00:34:19.520092  5893 sgd_solver.cpp:137] Iteration 82700, lr = 0.00483125, m = 0.9
I0629 00:34:37.940119  5893 solver.cpp:349] Iteration 82800 (5.42904 iter/s, 18.4194s/100 iter), loss = 1.50104
I0629 00:34:37.940219  5893 solver.cpp:371]     Train net output #0: loss = 1.6518 (* 1 = 1.6518 loss)
I0629 00:34:37.940227  5893 sgd_solver.cpp:137] Iteration 82800, lr = 0.004825, m = 0.9
I0629 00:34:56.408965  5893 solver.cpp:349] Iteration 82900 (5.41473 iter/s, 18.4682s/100 iter), loss = 1.59705
I0629 00:34:56.408988  5893 solver.cpp:371]     Train net output #0: loss = 1.66787 (* 1 = 1.66787 loss)
I0629 00:34:56.408993  5893 sgd_solver.cpp:137] Iteration 82900, lr = 0.00481875, m = 0.9
I0629 00:35:14.731189  5893 solver.cpp:401] Sparsity after update:
I0629 00:35:14.740084  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:35:14.740093  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:35:14.740103  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:35:14.740105  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:35:14.740108  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:35:14.740113  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:35:14.740115  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:35:14.740118  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:35:14.740123  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:35:14.740125  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:35:14.740128  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:35:14.740133  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:35:14.740136  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:35:14.740147  5893 solver.cpp:545] Iteration 83000, Testing net (#0)
I0629 00:35:39.117450  5888 data_reader.cpp:262] Starting prefetch of epoch 83
I0629 00:35:39.179260  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.550601
I0629 00:35:39.179283  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.785519
I0629 00:35:39.179288  5893 solver.cpp:630]     Test net output #2: loss = 1.97679 (* 1 = 1.97679 loss)
I0629 00:35:39.179307  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4384s
I0629 00:35:39.364037  5893 solver.cpp:349] Iteration 83000 (2.32809 iter/s, 42.9537s/100 iter), loss = 1.89768
I0629 00:35:39.364055  5893 solver.cpp:371]     Train net output #0: loss = 1.92247 (* 1 = 1.92247 loss)
I0629 00:35:39.364059  5893 sgd_solver.cpp:137] Iteration 83000, lr = 0.0048125, m = 0.9
I0629 00:35:57.809813  5893 solver.cpp:349] Iteration 83100 (5.42147 iter/s, 18.4452s/100 iter), loss = 1.74253
I0629 00:35:57.809875  5893 solver.cpp:371]     Train net output #0: loss = 1.67281 (* 1 = 1.67281 loss)
I0629 00:35:57.809880  5893 sgd_solver.cpp:137] Iteration 83100, lr = 0.00480625, m = 0.9
I0629 00:36:16.255353  5893 solver.cpp:349] Iteration 83200 (5.42156 iter/s, 18.4449s/100 iter), loss = 1.64208
I0629 00:36:16.255378  5893 solver.cpp:371]     Train net output #0: loss = 1.7177 (* 1 = 1.7177 loss)
I0629 00:36:16.255383  5893 sgd_solver.cpp:137] Iteration 83200, lr = 0.0048, m = 0.9
I0629 00:36:34.681473  5893 solver.cpp:349] Iteration 83300 (5.42726 iter/s, 18.4255s/100 iter), loss = 1.66915
I0629 00:36:34.681574  5893 solver.cpp:371]     Train net output #0: loss = 1.59789 (* 1 = 1.59789 loss)
I0629 00:36:34.681581  5893 sgd_solver.cpp:137] Iteration 83300, lr = 0.00479375, m = 0.9
I0629 00:36:53.109580  5893 solver.cpp:349] Iteration 83400 (5.4267 iter/s, 18.4274s/100 iter), loss = 1.54765
I0629 00:36:53.109602  5893 solver.cpp:371]     Train net output #0: loss = 1.55994 (* 1 = 1.55994 loss)
I0629 00:36:53.109606  5893 sgd_solver.cpp:137] Iteration 83400, lr = 0.0047875, m = 0.9
I0629 00:37:11.539301  5893 solver.cpp:349] Iteration 83500 (5.4262 iter/s, 18.4291s/100 iter), loss = 1.38246
I0629 00:37:11.539408  5893 solver.cpp:371]     Train net output #0: loss = 1.1443 (* 1 = 1.1443 loss)
I0629 00:37:11.539414  5893 sgd_solver.cpp:137] Iteration 83500, lr = 0.00478125, m = 0.9
I0629 00:37:29.945154  5893 solver.cpp:349] Iteration 83600 (5.43326 iter/s, 18.4051s/100 iter), loss = 1.74695
I0629 00:37:29.945175  5893 solver.cpp:371]     Train net output #0: loss = 1.78385 (* 1 = 1.78385 loss)
I0629 00:37:29.945180  5893 sgd_solver.cpp:137] Iteration 83600, lr = 0.004775, m = 0.9
I0629 00:37:48.352646  5893 solver.cpp:349] Iteration 83700 (5.43275 iter/s, 18.4069s/100 iter), loss = 1.44324
I0629 00:37:48.352751  5893 solver.cpp:371]     Train net output #0: loss = 1.69333 (* 1 = 1.69333 loss)
I0629 00:37:48.352758  5893 sgd_solver.cpp:137] Iteration 83700, lr = 0.00476875, m = 0.9
I0629 00:38:06.786079  5893 solver.cpp:349] Iteration 83800 (5.42514 iter/s, 18.4327s/100 iter), loss = 1.57046
I0629 00:38:06.786103  5893 solver.cpp:371]     Train net output #0: loss = 1.66553 (* 1 = 1.66553 loss)
I0629 00:38:06.786106  5893 sgd_solver.cpp:137] Iteration 83800, lr = 0.0047625, m = 0.9
I0629 00:38:25.198350  5893 solver.cpp:349] Iteration 83900 (5.43134 iter/s, 18.4116s/100 iter), loss = 1.836
I0629 00:38:25.198456  5893 solver.cpp:371]     Train net output #0: loss = 1.97883 (* 1 = 1.97883 loss)
I0629 00:38:25.198462  5893 sgd_solver.cpp:137] Iteration 83900, lr = 0.00475625, m = 0.9
I0629 00:38:43.436729  5893 solver.cpp:401] Sparsity after update:
I0629 00:38:43.442026  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:38:43.442036  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:38:43.442044  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:38:43.442047  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:38:43.442051  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:38:43.442055  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:38:43.442059  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:38:43.442062  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:38:43.442066  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:38:43.442070  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:38:43.442073  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:38:43.442076  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:38:43.442080  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:38:43.442091  5893 solver.cpp:545] Iteration 84000, Testing net (#0)
I0629 00:39:07.786201  5888 data_reader.cpp:262] Starting prefetch of epoch 84
I0629 00:39:07.957710  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55216
I0629 00:39:07.957731  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78644
I0629 00:39:07.957736  5893 solver.cpp:630]     Test net output #2: loss = 1.97308 (* 1 = 1.97308 loss)
I0629 00:39:07.957756  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5149s
I0629 00:39:08.142484  5893 solver.cpp:349] Iteration 84000 (2.32869 iter/s, 42.9426s/100 iter), loss = 1.736
I0629 00:39:08.142508  5893 solver.cpp:371]     Train net output #0: loss = 1.84519 (* 1 = 1.84519 loss)
I0629 00:39:08.142513  5893 sgd_solver.cpp:137] Iteration 84000, lr = 0.00475, m = 0.9
I0629 00:39:26.581116  5893 solver.cpp:349] Iteration 84100 (5.42358 iter/s, 18.438s/100 iter), loss = 1.64195
I0629 00:39:26.581136  5893 solver.cpp:371]     Train net output #0: loss = 1.45062 (* 1 = 1.45062 loss)
I0629 00:39:26.581140  5893 sgd_solver.cpp:137] Iteration 84100, lr = 0.00474375, m = 0.9
I0629 00:39:45.025336  5893 solver.cpp:349] Iteration 84200 (5.42194 iter/s, 18.4436s/100 iter), loss = 1.8996
I0629 00:39:45.025413  5893 solver.cpp:371]     Train net output #0: loss = 1.85757 (* 1 = 1.85757 loss)
I0629 00:39:45.025418  5893 sgd_solver.cpp:137] Iteration 84200, lr = 0.0047375, m = 0.9
I0629 00:40:03.466526  5893 solver.cpp:349] Iteration 84300 (5.42285 iter/s, 18.4405s/100 iter), loss = 1.70335
I0629 00:40:03.466552  5893 solver.cpp:371]     Train net output #0: loss = 1.45551 (* 1 = 1.45551 loss)
I0629 00:40:03.466557  5893 sgd_solver.cpp:137] Iteration 84300, lr = 0.00473125, m = 0.9
I0629 00:40:21.905099  5893 solver.cpp:349] Iteration 84400 (5.4236 iter/s, 18.4379s/100 iter), loss = 1.56992
I0629 00:40:21.905185  5893 solver.cpp:371]     Train net output #0: loss = 1.81537 (* 1 = 1.81537 loss)
I0629 00:40:21.905191  5893 sgd_solver.cpp:137] Iteration 84400, lr = 0.004725, m = 0.9
I0629 00:40:40.316848  5893 solver.cpp:349] Iteration 84500 (5.43152 iter/s, 18.411s/100 iter), loss = 1.85676
I0629 00:40:40.316870  5893 solver.cpp:371]     Train net output #0: loss = 1.86246 (* 1 = 1.86246 loss)
I0629 00:40:40.316874  5893 sgd_solver.cpp:137] Iteration 84500, lr = 0.00471875, m = 0.9
I0629 00:40:58.739243  5893 solver.cpp:349] Iteration 84600 (5.42836 iter/s, 18.4218s/100 iter), loss = 1.6488
I0629 00:40:58.739338  5893 solver.cpp:371]     Train net output #0: loss = 1.66267 (* 1 = 1.66267 loss)
I0629 00:40:58.739346  5893 sgd_solver.cpp:137] Iteration 84600, lr = 0.0047125, m = 0.9
I0629 00:41:17.181999  5893 solver.cpp:349] Iteration 84700 (5.42239 iter/s, 18.442s/100 iter), loss = 1.6663
I0629 00:41:17.182023  5893 solver.cpp:371]     Train net output #0: loss = 1.45979 (* 1 = 1.45979 loss)
I0629 00:41:17.182026  5893 sgd_solver.cpp:137] Iteration 84700, lr = 0.00470625, m = 0.9
I0629 00:41:35.600322  5893 solver.cpp:349] Iteration 84800 (5.42956 iter/s, 18.4177s/100 iter), loss = 1.21518
I0629 00:41:35.600392  5893 solver.cpp:371]     Train net output #0: loss = 1.41987 (* 1 = 1.41987 loss)
I0629 00:41:35.600397  5893 sgd_solver.cpp:137] Iteration 84800, lr = 0.0047, m = 0.9
I0629 00:41:54.139128  5893 solver.cpp:349] Iteration 84900 (5.39429 iter/s, 18.5381s/100 iter), loss = 1.47777
I0629 00:41:54.139150  5893 solver.cpp:371]     Train net output #0: loss = 1.26453 (* 1 = 1.26453 loss)
I0629 00:41:54.139154  5893 sgd_solver.cpp:137] Iteration 84900, lr = 0.00469375, m = 0.9
I0629 00:42:12.413230  5893 solver.cpp:401] Sparsity after update:
I0629 00:42:12.418393  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:42:12.418402  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:42:12.418411  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:42:12.418416  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:42:12.418418  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:42:12.418422  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:42:12.418426  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:42:12.418429  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:42:12.418433  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:42:12.418437  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:42:12.418442  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:42:12.418444  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:42:12.418448  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:42:12.418459  5893 solver.cpp:545] Iteration 85000, Testing net (#0)
I0629 00:42:36.769421  5888 data_reader.cpp:262] Starting prefetch of epoch 85
I0629 00:42:36.831786  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55016
I0629 00:42:36.831805  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.78504
I0629 00:42:36.831810  5893 solver.cpp:630]     Test net output #2: loss = 1.97161 (* 1 = 1.97161 loss)
I0629 00:42:36.831838  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4126s
I0629 00:42:37.016422  5893 solver.cpp:349] Iteration 85000 (2.33231 iter/s, 42.8759s/100 iter), loss = 1.54852
I0629 00:42:37.016444  5893 solver.cpp:371]     Train net output #0: loss = 1.44507 (* 1 = 1.44507 loss)
I0629 00:42:37.016448  5893 sgd_solver.cpp:137] Iteration 85000, lr = 0.0046875, m = 0.9
I0629 00:42:50.907449  5875 data_reader.cpp:262] Starting prefetch of epoch 17
I0629 00:42:55.447851  5893 solver.cpp:349] Iteration 85100 (5.42571 iter/s, 18.4308s/100 iter), loss = 1.66599
I0629 00:42:55.447875  5893 solver.cpp:371]     Train net output #0: loss = 1.51277 (* 1 = 1.51277 loss)
I0629 00:42:55.447878  5893 sgd_solver.cpp:137] Iteration 85100, lr = 0.00468125, m = 0.9
I0629 00:43:13.870311  5893 solver.cpp:349] Iteration 85200 (5.42835 iter/s, 18.4218s/100 iter), loss = 1.33575
I0629 00:43:13.870352  5893 solver.cpp:371]     Train net output #0: loss = 1.3293 (* 1 = 1.3293 loss)
I0629 00:43:13.870358  5893 sgd_solver.cpp:137] Iteration 85200, lr = 0.004675, m = 0.9
I0629 00:43:32.314296  5893 solver.cpp:349] Iteration 85300 (5.42202 iter/s, 18.4433s/100 iter), loss = 1.89965
I0629 00:43:32.314399  5893 solver.cpp:371]     Train net output #0: loss = 1.83697 (* 1 = 1.83697 loss)
I0629 00:43:32.314405  5893 sgd_solver.cpp:137] Iteration 85300, lr = 0.00466875, m = 0.9
I0629 00:43:50.750725  5893 solver.cpp:349] Iteration 85400 (5.42426 iter/s, 18.4357s/100 iter), loss = 1.66795
I0629 00:43:50.750747  5893 solver.cpp:371]     Train net output #0: loss = 1.77058 (* 1 = 1.77058 loss)
I0629 00:43:50.750753  5893 sgd_solver.cpp:137] Iteration 85400, lr = 0.0046625, m = 0.9
I0629 00:44:09.248050  5893 solver.cpp:349] Iteration 85500 (5.40638 iter/s, 18.4967s/100 iter), loss = 1.92942
I0629 00:44:09.248150  5893 solver.cpp:371]     Train net output #0: loss = 2.2169 (* 1 = 2.2169 loss)
I0629 00:44:09.248157  5893 sgd_solver.cpp:137] Iteration 85500, lr = 0.00465625, m = 0.9
I0629 00:44:27.719286  5893 solver.cpp:349] Iteration 85600 (5.41404 iter/s, 18.4705s/100 iter), loss = 1.47559
I0629 00:44:27.719310  5893 solver.cpp:371]     Train net output #0: loss = 1.59996 (* 1 = 1.59996 loss)
I0629 00:44:27.719313  5893 sgd_solver.cpp:137] Iteration 85600, lr = 0.00465, m = 0.9
I0629 00:44:46.182873  5893 solver.cpp:349] Iteration 85700 (5.41626 iter/s, 18.4629s/100 iter), loss = 1.51874
I0629 00:44:46.183341  5893 solver.cpp:371]     Train net output #0: loss = 1.35782 (* 1 = 1.35782 loss)
I0629 00:44:46.183347  5893 sgd_solver.cpp:137] Iteration 85700, lr = 0.00464375, m = 0.9
I0629 00:45:04.638628  5893 solver.cpp:349] Iteration 85800 (5.41869 iter/s, 18.4547s/100 iter), loss = 1.88656
I0629 00:45:04.638650  5893 solver.cpp:371]     Train net output #0: loss = 1.65433 (* 1 = 1.65433 loss)
I0629 00:45:04.638654  5893 sgd_solver.cpp:137] Iteration 85800, lr = 0.0046375, m = 0.9
I0629 00:45:23.150990  5893 solver.cpp:349] Iteration 85900 (5.40199 iter/s, 18.5117s/100 iter), loss = 1.75459
I0629 00:45:23.151087  5893 solver.cpp:371]     Train net output #0: loss = 1.72255 (* 1 = 1.72255 loss)
I0629 00:45:23.151094  5893 sgd_solver.cpp:137] Iteration 85900, lr = 0.00463125, m = 0.9
I0629 00:45:41.528842  5893 solver.cpp:401] Sparsity after update:
I0629 00:45:41.534061  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:45:41.534070  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:45:41.534075  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:45:41.534077  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:45:41.534080  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:45:41.534081  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:45:41.534083  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:45:41.534085  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:45:41.534087  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:45:41.534090  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:45:41.534091  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:45:41.534092  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:45:41.534095  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:45:41.534101  5893 solver.cpp:545] Iteration 86000, Testing net (#0)
I0629 00:45:43.674173  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 00:46:05.987936  5888 data_reader.cpp:262] Starting prefetch of epoch 86
I0629 00:46:06.097265  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5526
I0629 00:46:06.097281  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.787
I0629 00:46:06.097286  5893 solver.cpp:630]     Test net output #2: loss = 1.97185 (* 1 = 1.97185 loss)
I0629 00:46:06.097308  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5624s
I0629 00:46:06.281790  5893 solver.cpp:349] Iteration 86000 (2.31861 iter/s, 43.1292s/100 iter), loss = 1.68353
I0629 00:46:06.281812  5893 solver.cpp:371]     Train net output #0: loss = 1.62617 (* 1 = 1.62617 loss)
I0629 00:46:06.281816  5893 sgd_solver.cpp:137] Iteration 86000, lr = 0.004625, m = 0.9
I0629 00:46:24.703385  5893 solver.cpp:349] Iteration 86100 (5.42861 iter/s, 18.4209s/100 iter), loss = 1.89368
I0629 00:46:24.703409  5893 solver.cpp:371]     Train net output #0: loss = 2.00713 (* 1 = 2.00713 loss)
I0629 00:46:24.703413  5893 sgd_solver.cpp:137] Iteration 86100, lr = 0.00461875, m = 0.9
I0629 00:46:43.153331  5893 solver.cpp:349] Iteration 86200 (5.42026 iter/s, 18.4493s/100 iter), loss = 1.68471
I0629 00:46:43.153385  5893 solver.cpp:371]     Train net output #0: loss = 1.55458 (* 1 = 1.55458 loss)
I0629 00:46:43.153390  5893 sgd_solver.cpp:137] Iteration 86200, lr = 0.0046125, m = 0.9
I0629 00:47:01.602735  5893 solver.cpp:349] Iteration 86300 (5.42043 iter/s, 18.4487s/100 iter), loss = 1.61271
I0629 00:47:01.602759  5893 solver.cpp:371]     Train net output #0: loss = 1.33873 (* 1 = 1.33873 loss)
I0629 00:47:01.602763  5893 sgd_solver.cpp:137] Iteration 86300, lr = 0.00460625, m = 0.9
I0629 00:47:20.040310  5893 solver.cpp:349] Iteration 86400 (5.4239 iter/s, 18.4369s/100 iter), loss = 1.79827
I0629 00:47:20.040413  5893 solver.cpp:371]     Train net output #0: loss = 2.02256 (* 1 = 2.02256 loss)
I0629 00:47:20.040419  5893 sgd_solver.cpp:137] Iteration 86400, lr = 0.0046, m = 0.9
I0629 00:47:38.470376  5893 solver.cpp:349] Iteration 86500 (5.42614 iter/s, 18.4293s/100 iter), loss = 1.78893
I0629 00:47:38.470399  5893 solver.cpp:371]     Train net output #0: loss = 1.93941 (* 1 = 1.93941 loss)
I0629 00:47:38.470403  5893 sgd_solver.cpp:137] Iteration 86500, lr = 0.00459375, m = 0.9
I0629 00:47:56.878674  5893 solver.cpp:349] Iteration 86600 (5.43253 iter/s, 18.4076s/100 iter), loss = 1.46011
I0629 00:47:56.878774  5893 solver.cpp:371]     Train net output #0: loss = 1.40576 (* 1 = 1.40576 loss)
I0629 00:47:56.878782  5893 sgd_solver.cpp:137] Iteration 86600, lr = 0.0045875, m = 0.9
I0629 00:48:15.337133  5893 solver.cpp:349] Iteration 86700 (5.41779 iter/s, 18.4577s/100 iter), loss = 1.33392
I0629 00:48:15.337157  5893 solver.cpp:371]     Train net output #0: loss = 1.55711 (* 1 = 1.55711 loss)
I0629 00:48:15.337160  5893 sgd_solver.cpp:137] Iteration 86700, lr = 0.00458125, m = 0.9
I0629 00:48:33.782419  5893 solver.cpp:349] Iteration 86800 (5.42164 iter/s, 18.4446s/100 iter), loss = 1.25429
I0629 00:48:33.782516  5893 solver.cpp:371]     Train net output #0: loss = 1.40699 (* 1 = 1.40699 loss)
I0629 00:48:33.782521  5893 sgd_solver.cpp:137] Iteration 86800, lr = 0.004575, m = 0.9
I0629 00:48:52.229053  5893 solver.cpp:349] Iteration 86900 (5.42126 iter/s, 18.4459s/100 iter), loss = 1.63526
I0629 00:48:52.229075  5893 solver.cpp:371]     Train net output #0: loss = 1.9309 (* 1 = 1.9309 loss)
I0629 00:48:52.229080  5893 sgd_solver.cpp:137] Iteration 86900, lr = 0.00456875, m = 0.9
I0629 00:49:10.531242  5893 solver.cpp:401] Sparsity after update:
I0629 00:49:10.537143  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:49:10.537153  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:49:10.537160  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:49:10.537165  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:49:10.537169  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:49:10.537173  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:49:10.537178  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:49:10.537181  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:49:10.537185  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:49:10.537189  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:49:10.537192  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:49:10.537197  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:49:10.537200  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:49:10.537211  5893 solver.cpp:545] Iteration 87000, Testing net (#0)
I0629 00:49:34.787550  5888 data_reader.cpp:262] Starting prefetch of epoch 87
I0629 00:49:34.849647  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5546
I0629 00:49:34.849673  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7882
I0629 00:49:34.849680  5893 solver.cpp:630]     Test net output #2: loss = 1.96121 (* 1 = 1.96121 loss)
I0629 00:49:34.849699  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3116s
I0629 00:49:35.035835  5893 solver.cpp:349] Iteration 87000 (2.33616 iter/s, 42.8053s/100 iter), loss = 1.92852
I0629 00:49:35.035856  5893 solver.cpp:371]     Train net output #0: loss = 1.74319 (* 1 = 1.74319 loss)
I0629 00:49:35.035862  5893 sgd_solver.cpp:137] Iteration 87000, lr = 0.0045625, m = 0.9
I0629 00:49:53.466540  5893 solver.cpp:349] Iteration 87100 (5.42593 iter/s, 18.43s/100 iter), loss = 1.63768
I0629 00:49:53.466642  5893 solver.cpp:371]     Train net output #0: loss = 1.74835 (* 1 = 1.74835 loss)
I0629 00:49:53.466648  5893 sgd_solver.cpp:137] Iteration 87100, lr = 0.00455625, m = 0.9
I0629 00:50:11.909656  5893 solver.cpp:349] Iteration 87200 (5.4223 iter/s, 18.4424s/100 iter), loss = 1.42984
I0629 00:50:11.909679  5893 solver.cpp:371]     Train net output #0: loss = 1.3361 (* 1 = 1.3361 loss)
I0629 00:50:11.909683  5893 sgd_solver.cpp:137] Iteration 87200, lr = 0.00455, m = 0.9
I0629 00:50:30.344153  5893 solver.cpp:349] Iteration 87300 (5.42481 iter/s, 18.4338s/100 iter), loss = 1.67574
I0629 00:50:30.344239  5893 solver.cpp:371]     Train net output #0: loss = 1.27783 (* 1 = 1.27783 loss)
I0629 00:50:30.344245  5893 sgd_solver.cpp:137] Iteration 87300, lr = 0.00454375, m = 0.9
I0629 00:50:48.775445  5893 solver.cpp:349] Iteration 87400 (5.42577 iter/s, 18.4306s/100 iter), loss = 1.67481
I0629 00:50:48.775468  5893 solver.cpp:371]     Train net output #0: loss = 1.72363 (* 1 = 1.72363 loss)
I0629 00:50:48.775472  5893 sgd_solver.cpp:137] Iteration 87400, lr = 0.0045375, m = 0.9
I0629 00:51:07.214920  5893 solver.cpp:349] Iteration 87500 (5.42335 iter/s, 18.4388s/100 iter), loss = 1.85055
I0629 00:51:07.215006  5893 solver.cpp:371]     Train net output #0: loss = 1.69117 (* 1 = 1.69117 loss)
I0629 00:51:07.215011  5893 sgd_solver.cpp:137] Iteration 87500, lr = 0.00453125, m = 0.9
I0629 00:51:25.658442  5893 solver.cpp:349] Iteration 87600 (5.42218 iter/s, 18.4428s/100 iter), loss = 1.66764
I0629 00:51:25.658464  5893 solver.cpp:371]     Train net output #0: loss = 1.57884 (* 1 = 1.57884 loss)
I0629 00:51:25.658468  5893 sgd_solver.cpp:137] Iteration 87600, lr = 0.004525, m = 0.9
I0629 00:51:44.101708  5893 solver.cpp:349] Iteration 87700 (5.42223 iter/s, 18.4426s/100 iter), loss = 1.75774
I0629 00:51:44.101820  5893 solver.cpp:371]     Train net output #0: loss = 1.64225 (* 1 = 1.64225 loss)
I0629 00:51:44.101828  5893 sgd_solver.cpp:137] Iteration 87700, lr = 0.00451875, m = 0.9
I0629 00:52:02.544759  5893 solver.cpp:349] Iteration 87800 (5.42233 iter/s, 18.4423s/100 iter), loss = 1.72554
I0629 00:52:02.544778  5893 solver.cpp:371]     Train net output #0: loss = 1.85476 (* 1 = 1.85476 loss)
I0629 00:52:02.544782  5893 sgd_solver.cpp:137] Iteration 87800, lr = 0.0045125, m = 0.9
I0629 00:52:21.094363  5893 solver.cpp:349] Iteration 87900 (5.39115 iter/s, 18.5489s/100 iter), loss = 1.40734
I0629 00:52:21.094461  5893 solver.cpp:371]     Train net output #0: loss = 1.42974 (* 1 = 1.42974 loss)
I0629 00:52:21.094468  5893 sgd_solver.cpp:137] Iteration 87900, lr = 0.00450625, m = 0.9
I0629 00:52:39.386715  5893 solver.cpp:401] Sparsity after update:
I0629 00:52:39.391973  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:52:39.391985  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:52:39.391993  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:52:39.391997  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:52:39.392009  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:52:39.392019  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:52:39.392029  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:52:39.392037  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:52:39.392046  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:52:39.392055  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:52:39.392063  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:52:39.392072  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:52:39.392082  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:52:39.392102  5893 solver.cpp:545] Iteration 88000, Testing net (#0)
I0629 00:53:03.691588  5888 data_reader.cpp:262] Starting prefetch of epoch 88
I0629 00:53:03.756717  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55732
I0629 00:53:03.756741  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7898
I0629 00:53:03.756745  5893 solver.cpp:630]     Test net output #2: loss = 1.94612 (* 1 = 1.94612 loss)
I0629 00:53:03.756765  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3638s
I0629 00:53:03.941756  5893 solver.cpp:349] Iteration 88000 (2.33395 iter/s, 42.8458s/100 iter), loss = 1.6672
I0629 00:53:03.941778  5893 solver.cpp:371]     Train net output #0: loss = 1.78498 (* 1 = 1.78498 loss)
I0629 00:53:03.941782  5893 sgd_solver.cpp:137] Iteration 88000, lr = 0.0045, m = 0.9
I0629 00:53:22.379179  5893 solver.cpp:349] Iteration 88100 (5.42395 iter/s, 18.4367s/100 iter), loss = 1.88205
I0629 00:53:22.379199  5893 solver.cpp:371]     Train net output #0: loss = 2.20273 (* 1 = 2.20273 loss)
I0629 00:53:22.379204  5893 sgd_solver.cpp:137] Iteration 88100, lr = 0.00449375, m = 0.9
I0629 00:53:40.799559  5893 solver.cpp:349] Iteration 88200 (5.42897 iter/s, 18.4197s/100 iter), loss = 1.66151
I0629 00:53:40.799636  5893 solver.cpp:371]     Train net output #0: loss = 1.73712 (* 1 = 1.73712 loss)
I0629 00:53:40.799643  5893 sgd_solver.cpp:137] Iteration 88200, lr = 0.0044875, m = 0.9
I0629 00:53:59.219220  5893 solver.cpp:349] Iteration 88300 (5.4292 iter/s, 18.4189s/100 iter), loss = 1.65378
I0629 00:53:59.219241  5893 solver.cpp:371]     Train net output #0: loss = 1.76634 (* 1 = 1.76634 loss)
I0629 00:53:59.219246  5893 sgd_solver.cpp:137] Iteration 88300, lr = 0.00448125, m = 0.9
I0629 00:54:17.639663  5893 solver.cpp:349] Iteration 88400 (5.42895 iter/s, 18.4198s/100 iter), loss = 1.79404
I0629 00:54:17.639766  5893 solver.cpp:371]     Train net output #0: loss = 1.77986 (* 1 = 1.77986 loss)
I0629 00:54:17.639775  5893 sgd_solver.cpp:137] Iteration 88400, lr = 0.004475, m = 0.9
I0629 00:54:36.054092  5893 solver.cpp:349] Iteration 88500 (5.43075 iter/s, 18.4137s/100 iter), loss = 1.46206
I0629 00:54:36.054111  5893 solver.cpp:371]     Train net output #0: loss = 1.53912 (* 1 = 1.53912 loss)
I0629 00:54:36.054116  5893 sgd_solver.cpp:137] Iteration 88500, lr = 0.00446875, m = 0.9
I0629 00:54:54.464912  5893 solver.cpp:349] Iteration 88600 (5.43179 iter/s, 18.4101s/100 iter), loss = 1.87859
I0629 00:54:54.465023  5893 solver.cpp:371]     Train net output #0: loss = 2.26209 (* 1 = 2.26209 loss)
I0629 00:54:54.465029  5893 sgd_solver.cpp:137] Iteration 88600, lr = 0.0044625, m = 0.9
I0629 00:55:12.918856  5893 solver.cpp:349] Iteration 88700 (5.41913 iter/s, 18.4532s/100 iter), loss = 1.46651
I0629 00:55:12.918879  5893 solver.cpp:371]     Train net output #0: loss = 1.36779 (* 1 = 1.36779 loss)
I0629 00:55:12.918884  5893 sgd_solver.cpp:137] Iteration 88700, lr = 0.00445625, m = 0.9
I0629 00:55:31.366612  5893 solver.cpp:349] Iteration 88800 (5.42092 iter/s, 18.4471s/100 iter), loss = 1.9159
I0629 00:55:31.366683  5893 solver.cpp:371]     Train net output #0: loss = 2.04799 (* 1 = 2.04799 loss)
I0629 00:55:31.366686  5893 sgd_solver.cpp:137] Iteration 88800, lr = 0.00445, m = 0.9
I0629 00:55:49.891016  5893 solver.cpp:349] Iteration 88900 (5.3985 iter/s, 18.5237s/100 iter), loss = 1.73147
I0629 00:55:49.891037  5893 solver.cpp:371]     Train net output #0: loss = 1.58045 (* 1 = 1.58045 loss)
I0629 00:55:49.891042  5893 sgd_solver.cpp:137] Iteration 88900, lr = 0.00444375, m = 0.9
I0629 00:56:08.161765  5893 solver.cpp:401] Sparsity after update:
I0629 00:56:08.166944  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:56:08.166952  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:56:08.166957  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:56:08.166960  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:56:08.166962  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:56:08.166965  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:56:08.166966  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:56:08.166967  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:56:08.166970  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:56:08.166971  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:56:08.166973  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:56:08.166975  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:56:08.166977  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:56:08.166985  5893 solver.cpp:545] Iteration 89000, Testing net (#0)
I0629 00:56:32.687399  5888 data_reader.cpp:262] Starting prefetch of epoch 89
I0629 00:56:32.749557  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5582
I0629 00:56:32.749580  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79012
I0629 00:56:32.749585  5893 solver.cpp:630]     Test net output #2: loss = 1.94862 (* 1 = 1.94862 loss)
I0629 00:56:32.749601  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5817s
I0629 00:56:32.934758  5893 solver.cpp:349] Iteration 89000 (2.3233 iter/s, 43.0422s/100 iter), loss = 1.62027
I0629 00:56:32.934780  5893 solver.cpp:371]     Train net output #0: loss = 1.62954 (* 1 = 1.62954 loss)
I0629 00:56:32.934785  5893 sgd_solver.cpp:137] Iteration 89000, lr = 0.0044375, m = 0.9
I0629 00:56:51.371007  5893 solver.cpp:349] Iteration 89100 (5.4243 iter/s, 18.4356s/100 iter), loss = 1.69454
I0629 00:56:51.371105  5893 solver.cpp:371]     Train net output #0: loss = 1.80885 (* 1 = 1.80885 loss)
I0629 00:56:51.371111  5893 sgd_solver.cpp:137] Iteration 89100, lr = 0.00443125, m = 0.9
I0629 00:57:09.799758  5893 solver.cpp:349] Iteration 89200 (5.42653 iter/s, 18.428s/100 iter), loss = 1.7629
I0629 00:57:09.799782  5893 solver.cpp:371]     Train net output #0: loss = 1.90999 (* 1 = 1.90999 loss)
I0629 00:57:09.799788  5893 sgd_solver.cpp:137] Iteration 89200, lr = 0.004425, m = 0.9
I0629 00:57:28.234784  5893 solver.cpp:349] Iteration 89300 (5.42466 iter/s, 18.4343s/100 iter), loss = 1.70618
I0629 00:57:28.234894  5893 solver.cpp:371]     Train net output #0: loss = 1.66972 (* 1 = 1.66972 loss)
I0629 00:57:28.234900  5893 sgd_solver.cpp:137] Iteration 89300, lr = 0.00441875, m = 0.9
I0629 00:57:46.671980  5893 solver.cpp:349] Iteration 89400 (5.42405 iter/s, 18.4364s/100 iter), loss = 1.36567
I0629 00:57:46.672003  5893 solver.cpp:371]     Train net output #0: loss = 1.22103 (* 1 = 1.22103 loss)
I0629 00:57:46.672008  5893 sgd_solver.cpp:137] Iteration 89400, lr = 0.0044125, m = 0.9
I0629 00:58:05.121969  5893 solver.cpp:349] Iteration 89500 (5.42026 iter/s, 18.4493s/100 iter), loss = 1.51226
I0629 00:58:05.122040  5893 solver.cpp:371]     Train net output #0: loss = 1.59087 (* 1 = 1.59087 loss)
I0629 00:58:05.122045  5893 sgd_solver.cpp:137] Iteration 89500, lr = 0.00440625, m = 0.9
I0629 00:58:23.537890  5893 solver.cpp:349] Iteration 89600 (5.4303 iter/s, 18.4152s/100 iter), loss = 1.84243
I0629 00:58:23.537914  5893 solver.cpp:371]     Train net output #0: loss = 1.88475 (* 1 = 1.88475 loss)
I0629 00:58:23.537917  5893 sgd_solver.cpp:137] Iteration 89600, lr = 0.0044, m = 0.9
I0629 00:58:42.003913  5893 solver.cpp:349] Iteration 89700 (5.41553 iter/s, 18.4654s/100 iter), loss = 1.93476
I0629 00:58:42.004012  5893 solver.cpp:371]     Train net output #0: loss = 1.64135 (* 1 = 1.64135 loss)
I0629 00:58:42.004019  5893 sgd_solver.cpp:137] Iteration 89700, lr = 0.00439375, m = 0.9
I0629 00:59:00.500183  5893 solver.cpp:349] Iteration 89800 (5.4067 iter/s, 18.4956s/100 iter), loss = 1.75192
I0629 00:59:00.500205  5893 solver.cpp:371]     Train net output #0: loss = 1.66127 (* 1 = 1.66127 loss)
I0629 00:59:00.500211  5893 sgd_solver.cpp:137] Iteration 89800, lr = 0.0043875, m = 0.9
I0629 00:59:18.931248  5893 solver.cpp:349] Iteration 89900 (5.4258 iter/s, 18.4305s/100 iter), loss = 1.90959
I0629 00:59:18.931355  5893 solver.cpp:371]     Train net output #0: loss = 1.8148 (* 1 = 1.8148 loss)
I0629 00:59:18.931362  5893 sgd_solver.cpp:137] Iteration 89900, lr = 0.00438125, m = 0.9
I0629 00:59:37.255295  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_90000.caffemodel
I0629 00:59:37.290362  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_90000.solverstate
I0629 00:59:37.294653  5893 solver.cpp:401] Sparsity after update:
I0629 00:59:37.295485  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 00:59:37.295492  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 00:59:37.295498  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 00:59:37.295500  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 00:59:37.295502  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 00:59:37.295506  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 00:59:37.295508  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 00:59:37.295511  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 00:59:37.295512  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 00:59:37.295516  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 00:59:37.295517  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 00:59:37.295519  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 00:59:37.295521  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 00:59:37.295529  5893 solver.cpp:545] Iteration 90000, Testing net (#0)
I0629 01:00:01.532766  5888 data_reader.cpp:262] Starting prefetch of epoch 90
I0629 01:00:01.599004  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55792
I0629 01:00:01.599025  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79036
I0629 01:00:01.599030  5893 solver.cpp:630]     Test net output #2: loss = 1.94139 (* 1 = 1.94139 loss)
I0629 01:00:01.599046  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3028s
I0629 01:00:01.783828  5893 solver.cpp:349] Iteration 90000 (2.33366 iter/s, 42.8511s/100 iter), loss = 1.41775
I0629 01:00:01.783849  5893 solver.cpp:371]     Train net output #0: loss = 1.38559 (* 1 = 1.38559 loss)
I0629 01:00:01.783854  5893 sgd_solver.cpp:137] Iteration 90000, lr = 0.004375, m = 0.9
I0629 01:00:16.562891  5875 data_reader.cpp:262] Starting prefetch of epoch 18
I0629 01:00:20.227978  5893 solver.cpp:349] Iteration 90100 (5.42195 iter/s, 18.4435s/100 iter), loss = 1.71953
I0629 01:00:20.228000  5893 solver.cpp:371]     Train net output #0: loss = 2.19709 (* 1 = 2.19709 loss)
I0629 01:00:20.228004  5893 sgd_solver.cpp:137] Iteration 90100, lr = 0.00436875, m = 0.9
I0629 01:00:38.664577  5893 solver.cpp:349] Iteration 90200 (5.42418 iter/s, 18.436s/100 iter), loss = 1.40683
I0629 01:00:38.664674  5893 solver.cpp:371]     Train net output #0: loss = 1.23103 (* 1 = 1.23103 loss)
I0629 01:00:38.664681  5893 sgd_solver.cpp:137] Iteration 90200, lr = 0.0043625, m = 0.9
I0629 01:00:57.104985  5893 solver.cpp:349] Iteration 90300 (5.42308 iter/s, 18.4397s/100 iter), loss = 1.81204
I0629 01:00:57.105007  5893 solver.cpp:371]     Train net output #0: loss = 1.72527 (* 1 = 1.72527 loss)
I0629 01:00:57.105011  5893 sgd_solver.cpp:137] Iteration 90300, lr = 0.00435625, m = 0.9
I0629 01:01:15.547030  5893 solver.cpp:349] Iteration 90400 (5.42257 iter/s, 18.4414s/100 iter), loss = 1.28946
I0629 01:01:15.547078  5893 solver.cpp:371]     Train net output #0: loss = 1.29309 (* 1 = 1.29309 loss)
I0629 01:01:15.547083  5893 sgd_solver.cpp:137] Iteration 90400, lr = 0.00435, m = 0.9
I0629 01:01:34.007156  5893 solver.cpp:349] Iteration 90500 (5.41727 iter/s, 18.4595s/100 iter), loss = 1.49769
I0629 01:01:34.007179  5893 solver.cpp:371]     Train net output #0: loss = 1.47933 (* 1 = 1.47933 loss)
I0629 01:01:34.007182  5893 sgd_solver.cpp:137] Iteration 90500, lr = 0.00434375, m = 0.9
I0629 01:01:52.461947  5893 solver.cpp:349] Iteration 90600 (5.41883 iter/s, 18.4542s/100 iter), loss = 1.64707
I0629 01:01:52.462054  5893 solver.cpp:371]     Train net output #0: loss = 1.7097 (* 1 = 1.7097 loss)
I0629 01:01:52.462061  5893 sgd_solver.cpp:137] Iteration 90600, lr = 0.0043375, m = 0.9
I0629 01:02:10.899397  5893 solver.cpp:349] Iteration 90700 (5.42395 iter/s, 18.4367s/100 iter), loss = 1.37815
I0629 01:02:10.899420  5893 solver.cpp:371]     Train net output #0: loss = 1.43856 (* 1 = 1.43856 loss)
I0629 01:02:10.899425  5893 sgd_solver.cpp:137] Iteration 90700, lr = 0.00433125, m = 0.9
I0629 01:02:29.335029  5893 solver.cpp:349] Iteration 90800 (5.42446 iter/s, 18.435s/100 iter), loss = 1.5284
I0629 01:02:29.335122  5893 solver.cpp:371]     Train net output #0: loss = 1.58204 (* 1 = 1.58204 loss)
I0629 01:02:29.335132  5893 sgd_solver.cpp:137] Iteration 90800, lr = 0.004325, m = 0.9
I0629 01:02:47.883980  5893 solver.cpp:349] Iteration 90900 (5.39135 iter/s, 18.5482s/100 iter), loss = 1.67649
I0629 01:02:47.884002  5893 solver.cpp:371]     Train net output #0: loss = 1.69268 (* 1 = 1.69268 loss)
I0629 01:02:47.884006  5893 sgd_solver.cpp:137] Iteration 90900, lr = 0.00431875, m = 0.9
I0629 01:03:06.210775  5893 solver.cpp:401] Sparsity after update:
I0629 01:03:06.216002  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:03:06.216012  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:03:06.216020  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:03:06.216023  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:03:06.216027  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:03:06.216029  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:03:06.216032  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:03:06.216035  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:03:06.216038  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:03:06.216042  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:03:06.216045  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:03:06.216049  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:03:06.216053  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:03:06.216063  5893 solver.cpp:545] Iteration 91000, Testing net (#0)
I0629 01:03:08.459138  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 01:03:30.502207  5888 data_reader.cpp:262] Starting prefetch of epoch 91
I0629 01:03:30.564087  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55708
I0629 01:03:30.564110  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79076
I0629 01:03:30.564116  5893 solver.cpp:630]     Test net output #2: loss = 1.94225 (* 1 = 1.94225 loss)
I0629 01:03:30.564131  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3473s
I0629 01:03:30.748921  5893 solver.cpp:349] Iteration 91000 (2.33299 iter/s, 42.8635s/100 iter), loss = 1.47578
I0629 01:03:30.748946  5893 solver.cpp:371]     Train net output #0: loss = 1.49666 (* 1 = 1.49666 loss)
I0629 01:03:30.748952  5893 sgd_solver.cpp:137] Iteration 91000, lr = 0.0043125, m = 0.9
I0629 01:03:49.170457  5893 solver.cpp:349] Iteration 91100 (5.42862 iter/s, 18.4209s/100 iter), loss = 1.67089
I0629 01:03:49.170577  5893 solver.cpp:371]     Train net output #0: loss = 1.51029 (* 1 = 1.51029 loss)
I0629 01:03:49.170583  5893 sgd_solver.cpp:137] Iteration 91100, lr = 0.00430625, m = 0.9
I0629 01:04:07.606889  5893 solver.cpp:349] Iteration 91200 (5.42426 iter/s, 18.4357s/100 iter), loss = 1.67885
I0629 01:04:07.606914  5893 solver.cpp:371]     Train net output #0: loss = 1.98305 (* 1 = 1.98305 loss)
I0629 01:04:07.606920  5893 sgd_solver.cpp:137] Iteration 91200, lr = 0.0043, m = 0.9
I0629 01:04:26.058316  5893 solver.cpp:349] Iteration 91300 (5.41982 iter/s, 18.4508s/100 iter), loss = 1.37706
I0629 01:04:26.058390  5893 solver.cpp:371]     Train net output #0: loss = 1.11455 (* 1 = 1.11455 loss)
I0629 01:04:26.058395  5893 sgd_solver.cpp:137] Iteration 91300, lr = 0.00429375, m = 0.9
I0629 01:04:44.495563  5893 solver.cpp:349] Iteration 91400 (5.42401 iter/s, 18.4366s/100 iter), loss = 1.78202
I0629 01:04:44.495582  5893 solver.cpp:371]     Train net output #0: loss = 1.77389 (* 1 = 1.77389 loss)
I0629 01:04:44.495587  5893 sgd_solver.cpp:137] Iteration 91400, lr = 0.0042875, m = 0.9
I0629 01:05:02.932595  5893 solver.cpp:349] Iteration 91500 (5.42405 iter/s, 18.4364s/100 iter), loss = 1.51976
I0629 01:05:02.932696  5893 solver.cpp:371]     Train net output #0: loss = 1.47472 (* 1 = 1.47472 loss)
I0629 01:05:02.932705  5893 sgd_solver.cpp:137] Iteration 91500, lr = 0.00428125, m = 0.9
I0629 01:05:21.400498  5893 solver.cpp:349] Iteration 91600 (5.41501 iter/s, 18.4672s/100 iter), loss = 1.77689
I0629 01:05:21.400521  5893 solver.cpp:371]     Train net output #0: loss = 1.64823 (* 1 = 1.64823 loss)
I0629 01:05:21.400527  5893 sgd_solver.cpp:137] Iteration 91600, lr = 0.004275, m = 0.9
I0629 01:05:39.881714  5893 solver.cpp:349] Iteration 91700 (5.41109 iter/s, 18.4806s/100 iter), loss = 1.46425
I0629 01:05:39.881800  5893 solver.cpp:371]     Train net output #0: loss = 1.31912 (* 1 = 1.31912 loss)
I0629 01:05:39.881805  5893 sgd_solver.cpp:137] Iteration 91700, lr = 0.00426875, m = 0.9
I0629 01:05:58.304527  5893 solver.cpp:349] Iteration 91800 (5.42826 iter/s, 18.4221s/100 iter), loss = 1.6847
I0629 01:05:58.304549  5893 solver.cpp:371]     Train net output #0: loss = 1.62495 (* 1 = 1.62495 loss)
I0629 01:05:58.304553  5893 sgd_solver.cpp:137] Iteration 91800, lr = 0.0042625, m = 0.9
I0629 01:06:16.731979  5893 solver.cpp:349] Iteration 91900 (5.42688 iter/s, 18.4268s/100 iter), loss = 1.3963
I0629 01:06:16.732087  5893 solver.cpp:371]     Train net output #0: loss = 1.3716 (* 1 = 1.3716 loss)
I0629 01:06:16.732095  5893 sgd_solver.cpp:137] Iteration 91900, lr = 0.00425625, m = 0.9
I0629 01:06:35.039573  5893 solver.cpp:401] Sparsity after update:
I0629 01:06:35.044752  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:06:35.044761  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:06:35.044767  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:06:35.044770  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:06:35.044772  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:06:35.044775  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:06:35.044776  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:06:35.044777  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:06:35.044780  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:06:35.044781  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:06:35.044783  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:06:35.044785  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:06:35.044787  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:06:35.044795  5893 solver.cpp:545] Iteration 92000, Testing net (#0)
I0629 01:06:59.559160  5888 data_reader.cpp:262] Starting prefetch of epoch 92
I0629 01:06:59.621423  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.557399
I0629 01:06:59.621443  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79064
I0629 01:06:59.621448  5893 solver.cpp:630]     Test net output #2: loss = 1.94319 (* 1 = 1.94319 loss)
I0629 01:06:59.621472  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5759s
I0629 01:06:59.806182  5893 solver.cpp:349] Iteration 92000 (2.32166 iter/s, 43.0727s/100 iter), loss = 1.50142
I0629 01:06:59.806206  5893 solver.cpp:371]     Train net output #0: loss = 1.7242 (* 1 = 1.7242 loss)
I0629 01:06:59.806210  5893 sgd_solver.cpp:137] Iteration 92000, lr = 0.00425, m = 0.9
I0629 01:07:18.257381  5893 solver.cpp:349] Iteration 92100 (5.41989 iter/s, 18.4505s/100 iter), loss = 1.78965
I0629 01:07:18.257406  5893 solver.cpp:371]     Train net output #0: loss = 1.87762 (* 1 = 1.87762 loss)
I0629 01:07:18.257411  5893 sgd_solver.cpp:137] Iteration 92100, lr = 0.00424375, m = 0.9
I0629 01:07:36.689069  5893 solver.cpp:349] Iteration 92200 (5.42563 iter/s, 18.431s/100 iter), loss = 1.87455
I0629 01:07:36.689113  5893 solver.cpp:371]     Train net output #0: loss = 2.09412 (* 1 = 2.09412 loss)
I0629 01:07:36.689118  5893 sgd_solver.cpp:137] Iteration 92200, lr = 0.0042375, m = 0.9
I0629 01:07:55.109884  5893 solver.cpp:349] Iteration 92300 (5.42884 iter/s, 18.4201s/100 iter), loss = 1.63581
I0629 01:07:55.109905  5893 solver.cpp:371]     Train net output #0: loss = 1.51749 (* 1 = 1.51749 loss)
I0629 01:07:55.109910  5893 sgd_solver.cpp:137] Iteration 92300, lr = 0.00423125, m = 0.9
I0629 01:08:13.523566  5893 solver.cpp:349] Iteration 92400 (5.43094 iter/s, 18.413s/100 iter), loss = 1.62468
I0629 01:08:13.523666  5893 solver.cpp:371]     Train net output #0: loss = 1.63087 (* 1 = 1.63087 loss)
I0629 01:08:13.523674  5893 sgd_solver.cpp:137] Iteration 92400, lr = 0.004225, m = 0.9
I0629 01:08:31.955158  5893 solver.cpp:349] Iteration 92500 (5.42568 iter/s, 18.4309s/100 iter), loss = 1.54336
I0629 01:08:31.955179  5893 solver.cpp:371]     Train net output #0: loss = 1.34629 (* 1 = 1.34629 loss)
I0629 01:08:31.955183  5893 sgd_solver.cpp:137] Iteration 92500, lr = 0.00421875, m = 0.9
I0629 01:08:50.424607  5893 solver.cpp:349] Iteration 92600 (5.41454 iter/s, 18.4688s/100 iter), loss = 1.46003
I0629 01:08:50.424702  5893 solver.cpp:371]     Train net output #0: loss = 1.35219 (* 1 = 1.35219 loss)
I0629 01:08:50.424710  5893 sgd_solver.cpp:137] Iteration 92600, lr = 0.0042125, m = 0.9
I0629 01:09:08.872622  5893 solver.cpp:349] Iteration 92700 (5.42085 iter/s, 18.4473s/100 iter), loss = 1.35048
I0629 01:09:08.872645  5893 solver.cpp:371]     Train net output #0: loss = 1.54958 (* 1 = 1.54958 loss)
I0629 01:09:08.872649  5893 sgd_solver.cpp:137] Iteration 92700, lr = 0.00420625, m = 0.9
I0629 01:09:27.285941  5893 solver.cpp:349] Iteration 92800 (5.43104 iter/s, 18.4127s/100 iter), loss = 1.57247
I0629 01:09:27.286041  5893 solver.cpp:371]     Train net output #0: loss = 1.76386 (* 1 = 1.76386 loss)
I0629 01:09:27.286051  5893 sgd_solver.cpp:137] Iteration 92800, lr = 0.0042, m = 0.9
I0629 01:09:45.812896  5893 solver.cpp:349] Iteration 92900 (5.39776 iter/s, 18.5262s/100 iter), loss = 1.44089
I0629 01:09:45.812918  5893 solver.cpp:371]     Train net output #0: loss = 1.35722 (* 1 = 1.35722 loss)
I0629 01:09:45.812922  5893 sgd_solver.cpp:137] Iteration 92900, lr = 0.00419375, m = 0.9
I0629 01:10:04.140017  5893 solver.cpp:401] Sparsity after update:
I0629 01:10:04.145215  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:10:04.145223  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:10:04.145231  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:10:04.145232  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:10:04.145236  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:10:04.145237  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:10:04.145239  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:10:04.145242  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:10:04.145244  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:10:04.145247  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:10:04.145249  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:10:04.145251  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:10:04.145253  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:10:04.145262  5893 solver.cpp:545] Iteration 93000, Testing net (#0)
I0629 01:10:28.853543  5888 data_reader.cpp:262] Starting prefetch of epoch 93
I0629 01:10:28.916030  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55888
I0629 01:10:28.916046  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.789559
I0629 01:10:28.916051  5893 solver.cpp:630]     Test net output #2: loss = 1.93684 (* 1 = 1.93684 loss)
I0629 01:10:28.916066  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.77s
I0629 01:10:29.100970  5893 solver.cpp:349] Iteration 93000 (2.31018 iter/s, 43.2866s/100 iter), loss = 1.38205
I0629 01:10:29.100991  5893 solver.cpp:371]     Train net output #0: loss = 1.31352 (* 1 = 1.31352 loss)
I0629 01:10:29.100996  5893 sgd_solver.cpp:137] Iteration 93000, lr = 0.0041875, m = 0.9
I0629 01:10:47.526304  5893 solver.cpp:349] Iteration 93100 (5.4275 iter/s, 18.4247s/100 iter), loss = 1.69352
I0629 01:10:47.526391  5893 solver.cpp:371]     Train net output #0: loss = 1.52779 (* 1 = 1.52779 loss)
I0629 01:10:47.526396  5893 sgd_solver.cpp:137] Iteration 93100, lr = 0.00418125, m = 0.9
I0629 01:11:05.961805  5893 solver.cpp:349] Iteration 93200 (5.42453 iter/s, 18.4348s/100 iter), loss = 1.69022
I0629 01:11:05.961824  5893 solver.cpp:371]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0629 01:11:05.961828  5893 sgd_solver.cpp:137] Iteration 93200, lr = 0.004175, m = 0.9
I0629 01:11:24.404783  5893 solver.cpp:349] Iteration 93300 (5.42231 iter/s, 18.4423s/100 iter), loss = 1.46833
I0629 01:11:24.404882  5893 solver.cpp:371]     Train net output #0: loss = 1.363 (* 1 = 1.363 loss)
I0629 01:11:24.404889  5893 sgd_solver.cpp:137] Iteration 93300, lr = 0.00416875, m = 0.9
I0629 01:11:42.892426  5893 solver.cpp:349] Iteration 93400 (5.40924 iter/s, 18.4869s/100 iter), loss = 1.52197
I0629 01:11:42.892448  5893 solver.cpp:371]     Train net output #0: loss = 1.27805 (* 1 = 1.27805 loss)
I0629 01:11:42.892452  5893 sgd_solver.cpp:137] Iteration 93400, lr = 0.0041625, m = 0.9
I0629 01:12:01.330355  5893 solver.cpp:349] Iteration 93500 (5.4238 iter/s, 18.4373s/100 iter), loss = 1.81299
I0629 01:12:01.330457  5893 solver.cpp:371]     Train net output #0: loss = 2.00869 (* 1 = 2.00869 loss)
I0629 01:12:01.330466  5893 sgd_solver.cpp:137] Iteration 93500, lr = 0.00415625, m = 0.9
I0629 01:12:19.786708  5893 solver.cpp:349] Iteration 93600 (5.41841 iter/s, 18.4556s/100 iter), loss = 1.48377
I0629 01:12:19.786732  5893 solver.cpp:371]     Train net output #0: loss = 1.42822 (* 1 = 1.42822 loss)
I0629 01:12:19.786736  5893 sgd_solver.cpp:137] Iteration 93600, lr = 0.00415, m = 0.9
I0629 01:12:38.201388  5893 solver.cpp:349] Iteration 93700 (5.43065 iter/s, 18.414s/100 iter), loss = 1.69629
I0629 01:12:38.201474  5893 solver.cpp:371]     Train net output #0: loss = 1.60925 (* 1 = 1.60925 loss)
I0629 01:12:38.201479  5893 sgd_solver.cpp:137] Iteration 93700, lr = 0.00414375, m = 0.9
I0629 01:12:56.609405  5893 solver.cpp:349] Iteration 93800 (5.43263 iter/s, 18.4073s/100 iter), loss = 1.7179
I0629 01:12:56.609429  5893 solver.cpp:371]     Train net output #0: loss = 1.73985 (* 1 = 1.73985 loss)
I0629 01:12:56.609436  5893 sgd_solver.cpp:137] Iteration 93800, lr = 0.0041375, m = 0.9
I0629 01:13:15.065663  5893 solver.cpp:349] Iteration 93900 (5.41842 iter/s, 18.4556s/100 iter), loss = 1.58656
I0629 01:13:15.065783  5893 solver.cpp:371]     Train net output #0: loss = 1.73677 (* 1 = 1.73677 loss)
I0629 01:13:15.065793  5893 sgd_solver.cpp:137] Iteration 93900, lr = 0.00413125, m = 0.9
I0629 01:13:33.427474  5893 solver.cpp:401] Sparsity after update:
I0629 01:13:33.432778  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:13:33.432790  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:13:33.432797  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:13:33.432801  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:13:33.432803  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:13:33.432807  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:13:33.432811  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:13:33.432813  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:13:33.432816  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:13:33.432819  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:13:33.432823  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:13:33.432826  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:13:33.432829  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:13:33.432840  5893 solver.cpp:545] Iteration 94000, Testing net (#0)
I0629 01:13:57.679188  5888 data_reader.cpp:262] Starting prefetch of epoch 94
I0629 01:13:57.741613  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.560961
I0629 01:13:57.741639  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79008
I0629 01:13:57.741644  5893 solver.cpp:630]     Test net output #2: loss = 1.93361 (* 1 = 1.93361 loss)
I0629 01:13:57.741660  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.308s
I0629 01:13:57.929527  5893 solver.cpp:349] Iteration 94000 (2.33306 iter/s, 42.8622s/100 iter), loss = 1.79396
I0629 01:13:57.929558  5893 solver.cpp:371]     Train net output #0: loss = 2.07795 (* 1 = 2.07795 loss)
I0629 01:13:57.929561  5893 sgd_solver.cpp:137] Iteration 94000, lr = 0.004125, m = 0.9
I0629 01:14:16.357273  5893 solver.cpp:349] Iteration 94100 (5.4268 iter/s, 18.4271s/100 iter), loss = 1.73628
I0629 01:14:16.357296  5893 solver.cpp:371]     Train net output #0: loss = 1.64645 (* 1 = 1.64645 loss)
I0629 01:14:16.357300  5893 sgd_solver.cpp:137] Iteration 94100, lr = 0.00411875, m = 0.9
I0629 01:14:34.785130  5893 solver.cpp:349] Iteration 94200 (5.42677 iter/s, 18.4272s/100 iter), loss = 1.72102
I0629 01:14:34.785233  5893 solver.cpp:371]     Train net output #0: loss = 1.65996 (* 1 = 1.65996 loss)
I0629 01:14:34.785239  5893 sgd_solver.cpp:137] Iteration 94200, lr = 0.0041125, m = 0.9
I0629 01:14:53.226449  5893 solver.cpp:349] Iteration 94300 (5.42283 iter/s, 18.4406s/100 iter), loss = 1.26904
I0629 01:14:53.226469  5893 solver.cpp:371]     Train net output #0: loss = 1.29636 (* 1 = 1.29636 loss)
I0629 01:14:53.226474  5893 sgd_solver.cpp:137] Iteration 94300, lr = 0.00410625, m = 0.9
I0629 01:15:11.670159  5893 solver.cpp:349] Iteration 94400 (5.4221 iter/s, 18.443s/100 iter), loss = 1.70174
I0629 01:15:11.670258  5893 solver.cpp:371]     Train net output #0: loss = 1.90865 (* 1 = 1.90865 loss)
I0629 01:15:11.670264  5893 sgd_solver.cpp:137] Iteration 94400, lr = 0.0041, m = 0.9
I0629 01:15:30.104511  5893 solver.cpp:349] Iteration 94500 (5.42488 iter/s, 18.4336s/100 iter), loss = 1.69512
I0629 01:15:30.104532  5893 solver.cpp:371]     Train net output #0: loss = 1.79739 (* 1 = 1.79739 loss)
I0629 01:15:30.104537  5893 sgd_solver.cpp:137] Iteration 94500, lr = 0.00409375, m = 0.9
I0629 01:15:48.529745  5893 solver.cpp:349] Iteration 94600 (5.42754 iter/s, 18.4246s/100 iter), loss = 1.89845
I0629 01:15:48.529855  5893 solver.cpp:371]     Train net output #0: loss = 1.71892 (* 1 = 1.71892 loss)
I0629 01:15:48.529860  5893 sgd_solver.cpp:137] Iteration 94600, lr = 0.0040875, m = 0.9
I0629 01:16:06.978137  5893 solver.cpp:349] Iteration 94700 (5.42075 iter/s, 18.4476s/100 iter), loss = 1.59849
I0629 01:16:06.978159  5893 solver.cpp:371]     Train net output #0: loss = 1.90456 (* 1 = 1.90456 loss)
I0629 01:16:06.978163  5893 sgd_solver.cpp:137] Iteration 94700, lr = 0.00408125, m = 0.9
I0629 01:16:25.529503  5893 solver.cpp:349] Iteration 94800 (5.39064 iter/s, 18.5507s/100 iter), loss = 1.63515
I0629 01:16:25.529561  5893 solver.cpp:371]     Train net output #0: loss = 1.35342 (* 1 = 1.35342 loss)
I0629 01:16:25.529567  5893 sgd_solver.cpp:137] Iteration 94800, lr = 0.004075, m = 0.9
I0629 01:16:44.035570  5893 solver.cpp:349] Iteration 94900 (5.40384 iter/s, 18.5053s/100 iter), loss = 1.84396
I0629 01:16:44.035589  5893 solver.cpp:371]     Train net output #0: loss = 2.12124 (* 1 = 2.12124 loss)
I0629 01:16:44.035593  5893 sgd_solver.cpp:137] Iteration 94900, lr = 0.00406875, m = 0.9
I0629 01:17:02.335675  5893 solver.cpp:401] Sparsity after update:
I0629 01:17:02.340898  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:17:02.340905  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:17:02.340912  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:17:02.340914  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:17:02.340917  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:17:02.340920  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:17:02.340922  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:17:02.340924  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:17:02.340926  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:17:02.340929  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:17:02.340931  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:17:02.340934  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:17:02.340935  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:17:02.340942  5893 solver.cpp:545] Iteration 95000, Testing net (#0)
I0629 01:17:26.558078  5888 data_reader.cpp:262] Starting prefetch of epoch 95
I0629 01:17:26.620259  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56028
I0629 01:17:26.620285  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79244
I0629 01:17:26.620291  5893 solver.cpp:630]     Test net output #2: loss = 1.92875 (* 1 = 1.92875 loss)
I0629 01:17:26.620309  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2785s
I0629 01:17:26.804807  5893 solver.cpp:349] Iteration 95000 (2.33821 iter/s, 42.7677s/100 iter), loss = 1.62837
I0629 01:17:26.804831  5893 solver.cpp:371]     Train net output #0: loss = 1.99281 (* 1 = 1.99281 loss)
I0629 01:17:26.804834  5893 sgd_solver.cpp:137] Iteration 95000, lr = 0.0040625, m = 0.9
I0629 01:17:42.406674  5875 data_reader.cpp:262] Starting prefetch of epoch 19
I0629 01:17:45.241053  5893 solver.cpp:349] Iteration 95100 (5.4243 iter/s, 18.4356s/100 iter), loss = 1.72251
I0629 01:17:45.241075  5893 solver.cpp:371]     Train net output #0: loss = 1.98881 (* 1 = 1.98881 loss)
I0629 01:17:45.241080  5893 sgd_solver.cpp:137] Iteration 95100, lr = 0.00405625, m = 0.9
I0629 01:18:03.710424  5893 solver.cpp:349] Iteration 95200 (5.41457 iter/s, 18.4687s/100 iter), loss = 1.41769
I0629 01:18:03.710448  5893 solver.cpp:371]     Train net output #0: loss = 1.50119 (* 1 = 1.50119 loss)
I0629 01:18:03.710453  5893 sgd_solver.cpp:137] Iteration 95200, lr = 0.00405, m = 0.9
I0629 01:18:22.129328  5893 solver.cpp:349] Iteration 95300 (5.42941 iter/s, 18.4182s/100 iter), loss = 1.73791
I0629 01:18:22.129426  5893 solver.cpp:371]     Train net output #0: loss = 1.83328 (* 1 = 1.83328 loss)
I0629 01:18:22.129432  5893 sgd_solver.cpp:137] Iteration 95300, lr = 0.00404375, m = 0.9
I0629 01:18:40.546557  5893 solver.cpp:349] Iteration 95400 (5.42992 iter/s, 18.4165s/100 iter), loss = 1.62432
I0629 01:18:40.546577  5893 solver.cpp:371]     Train net output #0: loss = 1.70103 (* 1 = 1.70103 loss)
I0629 01:18:40.546583  5893 sgd_solver.cpp:137] Iteration 95400, lr = 0.0040375, m = 0.9
I0629 01:18:58.987968  5893 solver.cpp:349] Iteration 95500 (5.42278 iter/s, 18.4407s/100 iter), loss = 1.54912
I0629 01:18:58.988087  5893 solver.cpp:371]     Train net output #0: loss = 1.69779 (* 1 = 1.69779 loss)
I0629 01:18:58.988095  5893 sgd_solver.cpp:137] Iteration 95500, lr = 0.00403125, m = 0.9
I0629 01:19:17.422022  5893 solver.cpp:349] Iteration 95600 (5.42498 iter/s, 18.4333s/100 iter), loss = 1.45477
I0629 01:19:17.422045  5893 solver.cpp:371]     Train net output #0: loss = 1.258 (* 1 = 1.258 loss)
I0629 01:19:17.422049  5893 sgd_solver.cpp:137] Iteration 95600, lr = 0.004025, m = 0.9
I0629 01:19:35.835171  5893 solver.cpp:349] Iteration 95700 (5.43111 iter/s, 18.4125s/100 iter), loss = 1.53154
I0629 01:19:35.835268  5893 solver.cpp:371]     Train net output #0: loss = 1.63211 (* 1 = 1.63211 loss)
I0629 01:19:35.835274  5893 sgd_solver.cpp:137] Iteration 95700, lr = 0.00401875, m = 0.9
I0629 01:19:54.387934  5893 solver.cpp:349] Iteration 95800 (5.39026 iter/s, 18.552s/100 iter), loss = 1.73686
I0629 01:19:54.387958  5893 solver.cpp:371]     Train net output #0: loss = 1.62286 (* 1 = 1.62286 loss)
I0629 01:19:54.387960  5893 sgd_solver.cpp:137] Iteration 95800, lr = 0.0040125, m = 0.9
I0629 01:20:12.889710  5893 solver.cpp:349] Iteration 95900 (5.40509 iter/s, 18.5011s/100 iter), loss = 1.64447
I0629 01:20:12.889789  5893 solver.cpp:371]     Train net output #0: loss = 1.85342 (* 1 = 1.85342 loss)
I0629 01:20:12.889794  5893 sgd_solver.cpp:137] Iteration 95900, lr = 0.00400625, m = 0.9
I0629 01:20:31.168064  5893 solver.cpp:401] Sparsity after update:
I0629 01:20:31.173272  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:20:31.173280  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:20:31.173285  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:20:31.173288  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:20:31.173290  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:20:31.173292  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:20:31.173293  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:20:31.173295  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:20:31.173297  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:20:31.173300  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:20:31.173301  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:20:31.173303  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:20:31.173305  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:20:31.173312  5893 solver.cpp:545] Iteration 96000, Testing net (#0)
I0629 01:20:33.488706  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 01:20:55.435977  5888 data_reader.cpp:262] Starting prefetch of epoch 96
I0629 01:20:55.583781  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.55996
I0629 01:20:55.583801  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.788961
I0629 01:20:55.583806  5893 solver.cpp:630]     Test net output #2: loss = 1.93925 (* 1 = 1.93925 loss)
I0629 01:20:55.583822  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4096s
I0629 01:20:55.768546  5893 solver.cpp:349] Iteration 96000 (2.33224 iter/s, 42.8772s/100 iter), loss = 1.51565
I0629 01:20:55.768569  5893 solver.cpp:371]     Train net output #0: loss = 1.48894 (* 1 = 1.48894 loss)
I0629 01:20:55.768573  5893 sgd_solver.cpp:137] Iteration 96000, lr = 0.004, m = 0.9
I0629 01:21:14.226135  5893 solver.cpp:349] Iteration 96100 (5.41803 iter/s, 18.4569s/100 iter), loss = 1.61945
I0629 01:21:14.226158  5893 solver.cpp:371]     Train net output #0: loss = 1.64454 (* 1 = 1.64454 loss)
I0629 01:21:14.226162  5893 sgd_solver.cpp:137] Iteration 96100, lr = 0.00399375, m = 0.9
I0629 01:21:32.667956  5893 solver.cpp:349] Iteration 96200 (5.42266 iter/s, 18.4411s/100 iter), loss = 1.57659
I0629 01:21:32.668054  5893 solver.cpp:371]     Train net output #0: loss = 1.55036 (* 1 = 1.55036 loss)
I0629 01:21:32.668059  5893 sgd_solver.cpp:137] Iteration 96200, lr = 0.0039875, m = 0.9
I0629 01:21:51.125788  5893 solver.cpp:349] Iteration 96300 (5.41798 iter/s, 18.4571s/100 iter), loss = 1.40895
I0629 01:21:51.125810  5893 solver.cpp:371]     Train net output #0: loss = 1.43462 (* 1 = 1.43462 loss)
I0629 01:21:51.125814  5893 sgd_solver.cpp:137] Iteration 96300, lr = 0.00398125, m = 0.9
I0629 01:22:09.550631  5893 solver.cpp:349] Iteration 96400 (5.42766 iter/s, 18.4241s/100 iter), loss = 1.88371
I0629 01:22:09.550745  5893 solver.cpp:371]     Train net output #0: loss = 2.02703 (* 1 = 2.02703 loss)
I0629 01:22:09.550751  5893 sgd_solver.cpp:137] Iteration 96400, lr = 0.003975, m = 0.9
I0629 01:22:27.980738  5893 solver.cpp:349] Iteration 96500 (5.42614 iter/s, 18.4293s/100 iter), loss = 1.66297
I0629 01:22:27.980761  5893 solver.cpp:371]     Train net output #0: loss = 2.03033 (* 1 = 2.03033 loss)
I0629 01:22:27.980764  5893 sgd_solver.cpp:137] Iteration 96500, lr = 0.00396875, m = 0.9
I0629 01:22:46.403354  5893 solver.cpp:349] Iteration 96600 (5.42832 iter/s, 18.4219s/100 iter), loss = 1.53724
I0629 01:22:46.403441  5893 solver.cpp:371]     Train net output #0: loss = 1.70537 (* 1 = 1.70537 loss)
I0629 01:22:46.403446  5893 sgd_solver.cpp:137] Iteration 96600, lr = 0.0039625, m = 0.9
I0629 01:23:04.859046  5893 solver.cpp:349] Iteration 96700 (5.41861 iter/s, 18.4549s/100 iter), loss = 1.43426
I0629 01:23:04.859066  5893 solver.cpp:371]     Train net output #0: loss = 1.48813 (* 1 = 1.48813 loss)
I0629 01:23:04.859071  5893 sgd_solver.cpp:137] Iteration 96700, lr = 0.00395625, m = 0.9
I0629 01:23:23.294801  5893 solver.cpp:349] Iteration 96800 (5.42445 iter/s, 18.4351s/100 iter), loss = 1.64326
I0629 01:23:23.294888  5893 solver.cpp:371]     Train net output #0: loss = 1.36713 (* 1 = 1.36713 loss)
I0629 01:23:23.294893  5893 sgd_solver.cpp:137] Iteration 96800, lr = 0.00395, m = 0.9
I0629 01:23:41.819440  5893 solver.cpp:349] Iteration 96900 (5.39844 iter/s, 18.5239s/100 iter), loss = 1.70227
I0629 01:23:41.819464  5893 solver.cpp:371]     Train net output #0: loss = 1.68435 (* 1 = 1.68435 loss)
I0629 01:23:41.819468  5893 sgd_solver.cpp:137] Iteration 96900, lr = 0.00394375, m = 0.9
I0629 01:24:00.150851  5893 solver.cpp:401] Sparsity after update:
I0629 01:24:00.156071  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:24:00.156080  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:24:00.156088  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:24:00.156101  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:24:00.156118  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:24:00.156124  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:24:00.156127  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:24:00.156131  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:24:00.156136  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:24:00.156139  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:24:00.156144  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:24:00.156148  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:24:00.156152  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:24:00.156164  5893 solver.cpp:545] Iteration 97000, Testing net (#0)
I0629 01:24:24.423059  5888 data_reader.cpp:262] Starting prefetch of epoch 97
I0629 01:24:24.485067  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56088
I0629 01:24:24.485091  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7922
I0629 01:24:24.485096  5893 solver.cpp:630]     Test net output #2: loss = 1.93461 (* 1 = 1.93461 loss)
I0629 01:24:24.485112  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3281s
I0629 01:24:24.670285  5893 solver.cpp:349] Iteration 97000 (2.33376 iter/s, 42.8493s/100 iter), loss = 1.51912
I0629 01:24:24.670308  5893 solver.cpp:371]     Train net output #0: loss = 1.22863 (* 1 = 1.22863 loss)
I0629 01:24:24.670312  5893 sgd_solver.cpp:137] Iteration 97000, lr = 0.0039375, m = 0.9
I0629 01:24:43.079941  5893 solver.cpp:349] Iteration 97100 (5.43214 iter/s, 18.4089s/100 iter), loss = 1.62045
I0629 01:24:43.080051  5893 solver.cpp:371]     Train net output #0: loss = 1.59517 (* 1 = 1.59517 loss)
I0629 01:24:43.080058  5893 sgd_solver.cpp:137] Iteration 97100, lr = 0.00393125, m = 0.9
I0629 01:25:01.501850  5893 solver.cpp:349] Iteration 97200 (5.42856 iter/s, 18.4211s/100 iter), loss = 1.419
I0629 01:25:01.501873  5893 solver.cpp:371]     Train net output #0: loss = 1.35257 (* 1 = 1.35257 loss)
I0629 01:25:01.501878  5893 sgd_solver.cpp:137] Iteration 97200, lr = 0.003925, m = 0.9
I0629 01:25:19.920342  5893 solver.cpp:349] Iteration 97300 (5.42954 iter/s, 18.4178s/100 iter), loss = 1.41529
I0629 01:25:19.920388  5893 solver.cpp:371]     Train net output #0: loss = 1.78943 (* 1 = 1.78943 loss)
I0629 01:25:19.920393  5893 sgd_solver.cpp:137] Iteration 97300, lr = 0.00391875, m = 0.9
I0629 01:25:38.403805  5893 solver.cpp:349] Iteration 97400 (5.41045 iter/s, 18.4827s/100 iter), loss = 1.40982
I0629 01:25:38.403829  5893 solver.cpp:371]     Train net output #0: loss = 1.15315 (* 1 = 1.15315 loss)
I0629 01:25:38.403832  5893 sgd_solver.cpp:137] Iteration 97400, lr = 0.0039125, m = 0.9
I0629 01:25:56.846536  5893 solver.cpp:349] Iteration 97500 (5.42237 iter/s, 18.4421s/100 iter), loss = 1.67663
I0629 01:25:56.846606  5893 solver.cpp:371]     Train net output #0: loss = 1.44279 (* 1 = 1.44279 loss)
I0629 01:25:56.846611  5893 sgd_solver.cpp:137] Iteration 97500, lr = 0.00390625, m = 0.9
I0629 01:26:15.322621  5893 solver.cpp:349] Iteration 97600 (5.4126 iter/s, 18.4754s/100 iter), loss = 1.68729
I0629 01:26:15.322645  5893 solver.cpp:371]     Train net output #0: loss = 1.78345 (* 1 = 1.78345 loss)
I0629 01:26:15.322649  5893 sgd_solver.cpp:137] Iteration 97600, lr = 0.0039, m = 0.9
I0629 01:26:33.806232  5893 solver.cpp:349] Iteration 97700 (5.41038 iter/s, 18.483s/100 iter), loss = 1.52399
I0629 01:26:33.806341  5893 solver.cpp:371]     Train net output #0: loss = 1.31212 (* 1 = 1.31212 loss)
I0629 01:26:33.806349  5893 sgd_solver.cpp:137] Iteration 97700, lr = 0.00389375, m = 0.9
I0629 01:26:52.328517  5893 solver.cpp:349] Iteration 97800 (5.39911 iter/s, 18.5216s/100 iter), loss = 1.76747
I0629 01:26:52.328541  5893 solver.cpp:371]     Train net output #0: loss = 1.61193 (* 1 = 1.61193 loss)
I0629 01:26:52.328544  5893 sgd_solver.cpp:137] Iteration 97800, lr = 0.0038875, m = 0.9
I0629 01:27:10.822958  5893 solver.cpp:349] Iteration 97900 (5.40721 iter/s, 18.4938s/100 iter), loss = 1.59419
I0629 01:27:10.823055  5893 solver.cpp:371]     Train net output #0: loss = 1.84942 (* 1 = 1.84942 loss)
I0629 01:27:10.823061  5893 sgd_solver.cpp:137] Iteration 97900, lr = 0.00388125, m = 0.9
I0629 01:27:29.104722  5893 solver.cpp:401] Sparsity after update:
I0629 01:27:29.109933  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:27:29.109942  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:27:29.109948  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:27:29.109951  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:27:29.109952  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:27:29.109954  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:27:29.109956  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:27:29.109958  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:27:29.109961  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:27:29.109961  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:27:29.109963  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:27:29.109966  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:27:29.109967  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:27:29.109974  5893 solver.cpp:545] Iteration 98000, Testing net (#0)
I0629 01:27:53.269281  5888 data_reader.cpp:262] Starting prefetch of epoch 98
I0629 01:27:53.334652  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56308
I0629 01:27:53.334677  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79272
I0629 01:27:53.334682  5893 solver.cpp:630]     Test net output #2: loss = 1.92423 (* 1 = 1.92423 loss)
I0629 01:27:53.334702  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.224s
I0629 01:27:53.522356  5893 solver.cpp:349] Iteration 98000 (2.34203 iter/s, 42.6979s/100 iter), loss = 1.84014
I0629 01:27:53.522378  5893 solver.cpp:371]     Train net output #0: loss = 1.81777 (* 1 = 1.81777 loss)
I0629 01:27:53.522382  5893 sgd_solver.cpp:137] Iteration 98000, lr = 0.003875, m = 0.9
I0629 01:28:11.956512  5893 solver.cpp:349] Iteration 98100 (5.4249 iter/s, 18.4335s/100 iter), loss = 1.84105
I0629 01:28:11.956535  5893 solver.cpp:371]     Train net output #0: loss = 1.56679 (* 1 = 1.56679 loss)
I0629 01:28:11.956539  5893 sgd_solver.cpp:137] Iteration 98100, lr = 0.00386875, m = 0.9
I0629 01:28:30.395165  5893 solver.cpp:349] Iteration 98200 (5.42357 iter/s, 18.438s/100 iter), loss = 1.52754
I0629 01:28:30.395277  5893 solver.cpp:371]     Train net output #0: loss = 1.49935 (* 1 = 1.49935 loss)
I0629 01:28:30.395283  5893 sgd_solver.cpp:137] Iteration 98200, lr = 0.0038625, m = 0.9
I0629 01:28:48.814153  5893 solver.cpp:349] Iteration 98300 (5.42939 iter/s, 18.4183s/100 iter), loss = 1.58671
I0629 01:28:48.814182  5893 solver.cpp:371]     Train net output #0: loss = 1.74998 (* 1 = 1.74998 loss)
I0629 01:28:48.814188  5893 sgd_solver.cpp:137] Iteration 98300, lr = 0.00385625, m = 0.9
I0629 01:29:07.240124  5893 solver.cpp:349] Iteration 98400 (5.42731 iter/s, 18.4253s/100 iter), loss = 1.62048
I0629 01:29:07.240208  5893 solver.cpp:371]     Train net output #0: loss = 1.59722 (* 1 = 1.59722 loss)
I0629 01:29:07.240213  5893 sgd_solver.cpp:137] Iteration 98400, lr = 0.00385, m = 0.9
I0629 01:29:25.680819  5893 solver.cpp:349] Iteration 98500 (5.42299 iter/s, 18.44s/100 iter), loss = 1.39588
I0629 01:29:25.680842  5893 solver.cpp:371]     Train net output #0: loss = 1.56681 (* 1 = 1.56681 loss)
I0629 01:29:25.680846  5893 sgd_solver.cpp:137] Iteration 98500, lr = 0.00384375, m = 0.9
I0629 01:29:44.114138  5893 solver.cpp:349] Iteration 98600 (5.42514 iter/s, 18.4327s/100 iter), loss = 1.84483
I0629 01:29:44.114233  5893 solver.cpp:371]     Train net output #0: loss = 1.71264 (* 1 = 1.71264 loss)
I0629 01:29:44.114239  5893 sgd_solver.cpp:137] Iteration 98600, lr = 0.0038375, m = 0.9
I0629 01:30:02.555151  5893 solver.cpp:349] Iteration 98700 (5.4229 iter/s, 18.4403s/100 iter), loss = 1.60285
I0629 01:30:02.555172  5893 solver.cpp:371]     Train net output #0: loss = 1.60902 (* 1 = 1.60902 loss)
I0629 01:30:02.555176  5893 sgd_solver.cpp:137] Iteration 98700, lr = 0.00383125, m = 0.9
I0629 01:30:21.071180  5893 solver.cpp:349] Iteration 98800 (5.40091 iter/s, 18.5154s/100 iter), loss = 1.74541
I0629 01:30:21.071260  5893 solver.cpp:371]     Train net output #0: loss = 1.43838 (* 1 = 1.43838 loss)
I0629 01:30:21.071265  5893 sgd_solver.cpp:137] Iteration 98800, lr = 0.003825, m = 0.9
I0629 01:30:39.545858  5893 solver.cpp:349] Iteration 98900 (5.41302 iter/s, 18.474s/100 iter), loss = 1.63781
I0629 01:30:39.545881  5893 solver.cpp:371]     Train net output #0: loss = 1.30932 (* 1 = 1.30932 loss)
I0629 01:30:39.545886  5893 sgd_solver.cpp:137] Iteration 98900, lr = 0.00381875, m = 0.9
I0629 01:30:57.829507  5893 solver.cpp:401] Sparsity after update:
I0629 01:30:57.834707  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:30:57.834720  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:30:57.834728  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:30:57.834731  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:30:57.834734  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:30:57.834738  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:30:57.834748  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:30:57.834753  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:30:57.834758  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:30:57.834763  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:30:57.834767  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:30:57.834772  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:30:57.834775  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:30:57.834787  5893 solver.cpp:545] Iteration 99000, Testing net (#0)
I0629 01:31:22.153654  5888 data_reader.cpp:262] Starting prefetch of epoch 99
I0629 01:31:22.215430  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.562241
I0629 01:31:22.215453  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7918
I0629 01:31:22.215458  5893 solver.cpp:630]     Test net output #2: loss = 1.92857 (* 1 = 1.92857 loss)
I0629 01:31:22.215473  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3799s
I0629 01:31:22.402758  5893 solver.cpp:349] Iteration 99000 (2.33342 iter/s, 42.8555s/100 iter), loss = 1.6476
I0629 01:31:22.402781  5893 solver.cpp:371]     Train net output #0: loss = 1.58158 (* 1 = 1.58158 loss)
I0629 01:31:22.402786  5893 sgd_solver.cpp:137] Iteration 99000, lr = 0.0038125, m = 0.9
I0629 01:31:40.833688  5893 solver.cpp:349] Iteration 99100 (5.42585 iter/s, 18.4303s/100 iter), loss = 1.43468
I0629 01:31:40.833782  5893 solver.cpp:371]     Train net output #0: loss = 1.64044 (* 1 = 1.64044 loss)
I0629 01:31:40.833788  5893 sgd_solver.cpp:137] Iteration 99100, lr = 0.00380625, m = 0.9
I0629 01:31:59.261183  5893 solver.cpp:349] Iteration 99200 (5.42688 iter/s, 18.4268s/100 iter), loss = 1.58453
I0629 01:31:59.261206  5893 solver.cpp:371]     Train net output #0: loss = 1.68595 (* 1 = 1.68595 loss)
I0629 01:31:59.261210  5893 sgd_solver.cpp:137] Iteration 99200, lr = 0.0038, m = 0.9
I0629 01:32:17.671027  5893 solver.cpp:349] Iteration 99300 (5.43206 iter/s, 18.4092s/100 iter), loss = 1.42513
I0629 01:32:17.671133  5893 solver.cpp:371]     Train net output #0: loss = 1.46062 (* 1 = 1.46062 loss)
I0629 01:32:17.671139  5893 sgd_solver.cpp:137] Iteration 99300, lr = 0.00379375, m = 0.9
I0629 01:32:36.099717  5893 solver.cpp:349] Iteration 99400 (5.42654 iter/s, 18.428s/100 iter), loss = 1.55475
I0629 01:32:36.099740  5893 solver.cpp:371]     Train net output #0: loss = 1.74089 (* 1 = 1.74089 loss)
I0629 01:32:36.099745  5893 sgd_solver.cpp:137] Iteration 99400, lr = 0.0037875, m = 0.9
I0629 01:32:54.517834  5893 solver.cpp:349] Iteration 99500 (5.42963 iter/s, 18.4175s/100 iter), loss = 1.77638
I0629 01:32:54.517874  5893 solver.cpp:371]     Train net output #0: loss = 1.61124 (* 1 = 1.61124 loss)
I0629 01:32:54.517879  5893 sgd_solver.cpp:137] Iteration 99500, lr = 0.00378125, m = 0.9
I0629 01:33:12.934506  5893 solver.cpp:349] Iteration 99600 (5.43006 iter/s, 18.416s/100 iter), loss = 1.66283
I0629 01:33:12.934528  5893 solver.cpp:371]     Train net output #0: loss = 1.71784 (* 1 = 1.71784 loss)
I0629 01:33:12.934532  5893 sgd_solver.cpp:137] Iteration 99600, lr = 0.003775, m = 0.9
I0629 01:33:31.358455  5893 solver.cpp:349] Iteration 99700 (5.42791 iter/s, 18.4233s/100 iter), loss = 1.97894
I0629 01:33:31.358563  5893 solver.cpp:371]     Train net output #0: loss = 2.4496 (* 1 = 2.4496 loss)
I0629 01:33:31.358569  5893 sgd_solver.cpp:137] Iteration 99700, lr = 0.00376875, m = 0.9
I0629 01:33:49.871495  5893 solver.cpp:349] Iteration 99800 (5.40181 iter/s, 18.5123s/100 iter), loss = 1.70774
I0629 01:33:49.871517  5893 solver.cpp:371]     Train net output #0: loss = 1.64821 (* 1 = 1.64821 loss)
I0629 01:33:49.871522  5893 sgd_solver.cpp:137] Iteration 99800, lr = 0.0037625, m = 0.9
I0629 01:34:08.398131  5893 solver.cpp:349] Iteration 99900 (5.39782 iter/s, 18.526s/100 iter), loss = 1.98334
I0629 01:34:08.398177  5893 solver.cpp:371]     Train net output #0: loss = 1.99201 (* 1 = 1.99201 loss)
I0629 01:34:08.398182  5893 sgd_solver.cpp:137] Iteration 99900, lr = 0.00375625, m = 0.9
I0629 01:34:26.686537  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_100000.caffemodel
I0629 01:34:26.696945  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_100000.solverstate
I0629 01:34:26.701314  5893 solver.cpp:401] Sparsity after update:
I0629 01:34:26.702169  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:34:26.702178  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:34:26.702185  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:34:26.702188  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:34:26.702190  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:34:26.702193  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:34:26.702194  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:34:26.702196  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:34:26.702198  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:34:26.702200  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:34:26.702203  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:34:26.702205  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:34:26.702208  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:34:26.702215  5893 solver.cpp:545] Iteration 100000, Testing net (#0)
I0629 01:34:51.005362  5888 data_reader.cpp:262] Starting prefetch of epoch 100
I0629 01:34:51.067319  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56296
I0629 01:34:51.067343  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79376
I0629 01:34:51.067348  5893 solver.cpp:630]     Test net output #2: loss = 1.91618 (* 1 = 1.91618 loss)
I0629 01:34:51.067374  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3643s
I0629 01:34:51.252449  5893 solver.cpp:349] Iteration 100000 (2.33357 iter/s, 42.8528s/100 iter), loss = 1.36201
I0629 01:34:51.252473  5893 solver.cpp:371]     Train net output #0: loss = 1.41672 (* 1 = 1.41672 loss)
I0629 01:34:51.252477  5893 sgd_solver.cpp:137] Iteration 100000, lr = 0.00375, m = 0.9
I0629 01:35:07.696774  5875 data_reader.cpp:262] Starting prefetch of epoch 20
I0629 01:35:09.685909  5893 solver.cpp:349] Iteration 100100 (5.42511 iter/s, 18.4328s/100 iter), loss = 1.67188
I0629 01:35:09.685932  5893 solver.cpp:371]     Train net output #0: loss = 1.65578 (* 1 = 1.65578 loss)
I0629 01:35:09.685936  5893 sgd_solver.cpp:137] Iteration 100100, lr = 0.00374375, m = 0.9
I0629 01:35:28.134202  5893 solver.cpp:349] Iteration 100200 (5.42075 iter/s, 18.4476s/100 iter), loss = 1.99632
I0629 01:35:28.134313  5893 solver.cpp:371]     Train net output #0: loss = 2.40413 (* 1 = 2.40413 loss)
I0629 01:35:28.134322  5893 sgd_solver.cpp:137] Iteration 100200, lr = 0.0037375, m = 0.9
I0629 01:35:46.574879  5893 solver.cpp:349] Iteration 100300 (5.42301 iter/s, 18.4399s/100 iter), loss = 1.8566
I0629 01:35:46.574903  5893 solver.cpp:371]     Train net output #0: loss = 1.67008 (* 1 = 1.67008 loss)
I0629 01:35:46.574906  5893 sgd_solver.cpp:137] Iteration 100300, lr = 0.00373125, m = 0.9
I0629 01:36:05.005641  5893 solver.cpp:349] Iteration 100400 (5.4259 iter/s, 18.4301s/100 iter), loss = 1.70858
I0629 01:36:05.005741  5893 solver.cpp:371]     Train net output #0: loss = 1.77553 (* 1 = 1.77553 loss)
I0629 01:36:05.005748  5893 sgd_solver.cpp:137] Iteration 100400, lr = 0.003725, m = 0.9
I0629 01:36:23.459332  5893 solver.cpp:349] Iteration 100500 (5.41919 iter/s, 18.453s/100 iter), loss = 1.54031
I0629 01:36:23.459357  5893 solver.cpp:371]     Train net output #0: loss = 1.50948 (* 1 = 1.50948 loss)
I0629 01:36:23.459360  5893 sgd_solver.cpp:137] Iteration 100500, lr = 0.00371875, m = 0.9
I0629 01:36:41.898731  5893 solver.cpp:349] Iteration 100600 (5.42336 iter/s, 18.4387s/100 iter), loss = 1.53835
I0629 01:36:41.898830  5893 solver.cpp:371]     Train net output #0: loss = 1.4742 (* 1 = 1.4742 loss)
I0629 01:36:41.898836  5893 sgd_solver.cpp:137] Iteration 100600, lr = 0.0037125, m = 0.9
I0629 01:37:00.345537  5893 solver.cpp:349] Iteration 100700 (5.42121 iter/s, 18.4461s/100 iter), loss = 1.4145
I0629 01:37:00.345569  5893 solver.cpp:371]     Train net output #0: loss = 1.49384 (* 1 = 1.49384 loss)
I0629 01:37:00.345573  5893 sgd_solver.cpp:137] Iteration 100700, lr = 0.00370625, m = 0.9
I0629 01:37:18.885957  5893 solver.cpp:349] Iteration 100800 (5.39382 iter/s, 18.5397s/100 iter), loss = 1.28063
I0629 01:37:18.886072  5893 solver.cpp:371]     Train net output #0: loss = 1.3381 (* 1 = 1.3381 loss)
I0629 01:37:18.886080  5893 sgd_solver.cpp:137] Iteration 100800, lr = 0.0037, m = 0.9
I0629 01:37:37.381664  5893 solver.cpp:349] Iteration 100900 (5.40688 iter/s, 18.4949s/100 iter), loss = 1.77632
I0629 01:37:37.381692  5893 solver.cpp:371]     Train net output #0: loss = 1.47053 (* 1 = 1.47053 loss)
I0629 01:37:37.381700  5893 sgd_solver.cpp:137] Iteration 100900, lr = 0.00369375, m = 0.9
I0629 01:37:55.664523  5893 solver.cpp:401] Sparsity after update:
I0629 01:37:55.669790  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:37:55.669797  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:37:55.669803  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:37:55.669806  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:37:55.669807  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:37:55.669809  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:37:55.669811  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:37:55.669813  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:37:55.669816  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:37:55.669817  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:37:55.669819  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:37:55.669821  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:37:55.669822  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:37:55.669831  5893 solver.cpp:545] Iteration 101000, Testing net (#0)
I0629 01:37:58.071882  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 01:38:20.304863  5888 data_reader.cpp:262] Starting prefetch of epoch 101
I0629 01:38:20.366549  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5622
I0629 01:38:20.366569  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79216
I0629 01:38:20.366575  5893 solver.cpp:630]     Test net output #2: loss = 1.92221 (* 1 = 1.92221 loss)
I0629 01:38:20.366588  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6959s
I0629 01:38:20.555794  5893 solver.cpp:349] Iteration 101000 (2.31628 iter/s, 43.1726s/100 iter), loss = 1.96643
I0629 01:38:20.555816  5893 solver.cpp:371]     Train net output #0: loss = 2.15091 (* 1 = 2.15091 loss)
I0629 01:38:20.555820  5893 sgd_solver.cpp:137] Iteration 101000, lr = 0.0036875, m = 0.9
I0629 01:38:39.041213  5893 solver.cpp:349] Iteration 101100 (5.40986 iter/s, 18.4848s/100 iter), loss = 1.20485
I0629 01:38:39.041314  5893 solver.cpp:371]     Train net output #0: loss = 1.05406 (* 1 = 1.05406 loss)
I0629 01:38:39.041321  5893 sgd_solver.cpp:137] Iteration 101100, lr = 0.00368125, m = 0.9
I0629 01:38:57.521056  5893 solver.cpp:349] Iteration 101200 (5.41152 iter/s, 18.4791s/100 iter), loss = 1.92764
I0629 01:38:57.521080  5893 solver.cpp:371]     Train net output #0: loss = 1.98635 (* 1 = 1.98635 loss)
I0629 01:38:57.521083  5893 sgd_solver.cpp:137] Iteration 101200, lr = 0.003675, m = 0.9
I0629 01:39:15.933032  5893 solver.cpp:349] Iteration 101300 (5.43144 iter/s, 18.4113s/100 iter), loss = 1.80562
I0629 01:39:15.933130  5893 solver.cpp:371]     Train net output #0: loss = 1.58088 (* 1 = 1.58088 loss)
I0629 01:39:15.933136  5893 sgd_solver.cpp:137] Iteration 101300, lr = 0.00366875, m = 0.9
I0629 01:39:34.357275  5893 solver.cpp:349] Iteration 101400 (5.42785 iter/s, 18.4235s/100 iter), loss = 1.6832
I0629 01:39:34.357297  5893 solver.cpp:371]     Train net output #0: loss = 1.51896 (* 1 = 1.51896 loss)
I0629 01:39:34.357301  5893 sgd_solver.cpp:137] Iteration 101400, lr = 0.0036625, m = 0.9
I0629 01:39:52.783293  5893 solver.cpp:349] Iteration 101500 (5.4273 iter/s, 18.4254s/100 iter), loss = 1.48187
I0629 01:39:52.783406  5893 solver.cpp:371]     Train net output #0: loss = 1.62132 (* 1 = 1.62132 loss)
I0629 01:39:52.783412  5893 sgd_solver.cpp:137] Iteration 101500, lr = 0.00365625, m = 0.9
I0629 01:40:11.194090  5893 solver.cpp:349] Iteration 101600 (5.43182 iter/s, 18.41s/100 iter), loss = 1.49055
I0629 01:40:11.194114  5893 solver.cpp:371]     Train net output #0: loss = 1.74571 (* 1 = 1.74571 loss)
I0629 01:40:11.194119  5893 sgd_solver.cpp:137] Iteration 101600, lr = 0.00365, m = 0.9
I0629 01:40:29.605551  5893 solver.cpp:349] Iteration 101700 (5.4316 iter/s, 18.4108s/100 iter), loss = 1.52093
I0629 01:40:29.605617  5893 solver.cpp:371]     Train net output #0: loss = 1.29082 (* 1 = 1.29082 loss)
I0629 01:40:29.605621  5893 sgd_solver.cpp:137] Iteration 101700, lr = 0.00364375, m = 0.9
I0629 01:40:48.178563  5893 solver.cpp:349] Iteration 101800 (5.38437 iter/s, 18.5723s/100 iter), loss = 1.66258
I0629 01:40:48.178583  5893 solver.cpp:371]     Train net output #0: loss = 1.53899 (* 1 = 1.53899 loss)
I0629 01:40:48.178587  5893 sgd_solver.cpp:137] Iteration 101800, lr = 0.0036375, m = 0.9
I0629 01:41:06.683897  5893 solver.cpp:349] Iteration 101900 (5.40404 iter/s, 18.5047s/100 iter), loss = 1.35925
I0629 01:41:06.683974  5893 solver.cpp:371]     Train net output #0: loss = 1.60131 (* 1 = 1.60131 loss)
I0629 01:41:06.683977  5893 sgd_solver.cpp:137] Iteration 101900, lr = 0.00363125, m = 0.9
I0629 01:41:25.020305  5893 solver.cpp:401] Sparsity after update:
I0629 01:41:25.025612  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:41:25.025629  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:41:25.025637  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:41:25.025641  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:41:25.025645  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:41:25.025650  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:41:25.025653  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:41:25.025657  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:41:25.025661  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:41:25.025665  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:41:25.025668  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:41:25.025672  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:41:25.025676  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:41:25.025689  5893 solver.cpp:545] Iteration 102000, Testing net (#0)
I0629 01:41:49.341183  5888 data_reader.cpp:262] Starting prefetch of epoch 102
I0629 01:41:49.403424  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56152
I0629 01:41:49.403446  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79344
I0629 01:41:49.403451  5893 solver.cpp:630]     Test net output #2: loss = 1.92028 (* 1 = 1.92028 loss)
I0629 01:41:49.403468  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3769s
I0629 01:41:49.591966  5893 solver.cpp:349] Iteration 102000 (2.33065 iter/s, 42.9065s/100 iter), loss = 1.38393
I0629 01:41:49.591994  5893 solver.cpp:371]     Train net output #0: loss = 1.48397 (* 1 = 1.48397 loss)
I0629 01:41:49.591998  5893 sgd_solver.cpp:137] Iteration 102000, lr = 0.003625, m = 0.9
I0629 01:42:08.016225  5893 solver.cpp:349] Iteration 102100 (5.42783 iter/s, 18.4236s/100 iter), loss = 1.38562
I0629 01:42:08.016248  5893 solver.cpp:371]     Train net output #0: loss = 1.40918 (* 1 = 1.40918 loss)
I0629 01:42:08.016252  5893 sgd_solver.cpp:137] Iteration 102100, lr = 0.00361875, m = 0.9
I0629 01:42:26.446449  5893 solver.cpp:349] Iteration 102200 (5.42607 iter/s, 18.4295s/100 iter), loss = 1.52897
I0629 01:42:26.446493  5893 solver.cpp:371]     Train net output #0: loss = 1.28995 (* 1 = 1.28995 loss)
I0629 01:42:26.446498  5893 sgd_solver.cpp:137] Iteration 102200, lr = 0.0036125, m = 0.9
I0629 01:42:44.891628  5893 solver.cpp:349] Iteration 102300 (5.42168 iter/s, 18.4445s/100 iter), loss = 1.64551
I0629 01:42:44.891650  5893 solver.cpp:371]     Train net output #0: loss = 1.84321 (* 1 = 1.84321 loss)
I0629 01:42:44.891654  5893 sgd_solver.cpp:137] Iteration 102300, lr = 0.00360625, m = 0.9
I0629 01:43:03.316623  5893 solver.cpp:349] Iteration 102400 (5.42761 iter/s, 18.4243s/100 iter), loss = 1.57793
I0629 01:43:03.316736  5893 solver.cpp:371]     Train net output #0: loss = 1.72403 (* 1 = 1.72403 loss)
I0629 01:43:03.316742  5893 sgd_solver.cpp:137] Iteration 102400, lr = 0.0036, m = 0.9
I0629 01:43:21.727293  5893 solver.cpp:349] Iteration 102500 (5.43186 iter/s, 18.4099s/100 iter), loss = 1.7915
I0629 01:43:21.727315  5893 solver.cpp:371]     Train net output #0: loss = 1.84155 (* 1 = 1.84155 loss)
I0629 01:43:21.727319  5893 sgd_solver.cpp:137] Iteration 102500, lr = 0.00359375, m = 0.9
I0629 01:43:40.146905  5893 solver.cpp:349] Iteration 102600 (5.4292 iter/s, 18.4189s/100 iter), loss = 1.78857
I0629 01:43:40.146999  5893 solver.cpp:371]     Train net output #0: loss = 1.51988 (* 1 = 1.51988 loss)
I0629 01:43:40.147006  5893 sgd_solver.cpp:137] Iteration 102600, lr = 0.0035875, m = 0.9
I0629 01:43:58.586393  5893 solver.cpp:349] Iteration 102700 (5.42337 iter/s, 18.4387s/100 iter), loss = 1.63984
I0629 01:43:58.586418  5893 solver.cpp:371]     Train net output #0: loss = 1.42329 (* 1 = 1.42329 loss)
I0629 01:43:58.586423  5893 sgd_solver.cpp:137] Iteration 102700, lr = 0.00358125, m = 0.9
I0629 01:44:17.045356  5893 solver.cpp:349] Iteration 102800 (5.41762 iter/s, 18.4583s/100 iter), loss = 1.71776
I0629 01:44:17.045459  5893 solver.cpp:371]     Train net output #0: loss = 1.73874 (* 1 = 1.73874 loss)
I0629 01:44:17.045464  5893 sgd_solver.cpp:137] Iteration 102800, lr = 0.003575, m = 0.9
I0629 01:44:35.588106  5893 solver.cpp:349] Iteration 102900 (5.39317 iter/s, 18.542s/100 iter), loss = 1.81504
I0629 01:44:35.588129  5893 solver.cpp:371]     Train net output #0: loss = 1.72268 (* 1 = 1.72268 loss)
I0629 01:44:35.588134  5893 sgd_solver.cpp:137] Iteration 102900, lr = 0.00356875, m = 0.9
I0629 01:44:53.904005  5893 solver.cpp:401] Sparsity after update:
I0629 01:44:53.909186  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:44:53.909195  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:44:53.909201  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:44:53.909204  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:44:53.909205  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:44:53.909207  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:44:53.909209  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:44:53.909211  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:44:53.909214  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:44:53.909215  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:44:53.909216  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:44:53.909219  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:44:53.909220  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:44:53.909227  5893 solver.cpp:545] Iteration 103000, Testing net (#0)
I0629 01:45:18.226534  5888 data_reader.cpp:262] Starting prefetch of epoch 103
I0629 01:45:18.296669  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56208
I0629 01:45:18.296689  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79364
I0629 01:45:18.296695  5893 solver.cpp:630]     Test net output #2: loss = 1.9211 (* 1 = 1.9211 loss)
I0629 01:45:18.296715  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3866s
I0629 01:45:18.481264  5893 solver.cpp:349] Iteration 103000 (2.33146 iter/s, 42.8916s/100 iter), loss = 1.76846
I0629 01:45:18.481286  5893 solver.cpp:371]     Train net output #0: loss = 1.65758 (* 1 = 1.65758 loss)
I0629 01:45:18.481290  5893 sgd_solver.cpp:137] Iteration 103000, lr = 0.0035625, m = 0.9
I0629 01:45:36.929054  5893 solver.cpp:349] Iteration 103100 (5.42091 iter/s, 18.4471s/100 iter), loss = 1.30981
I0629 01:45:36.929158  5893 solver.cpp:371]     Train net output #0: loss = 1.56484 (* 1 = 1.56484 loss)
I0629 01:45:36.929167  5893 sgd_solver.cpp:137] Iteration 103100, lr = 0.00355625, m = 0.9
I0629 01:45:55.403218  5893 solver.cpp:349] Iteration 103200 (5.41319 iter/s, 18.4734s/100 iter), loss = 1.52693
I0629 01:45:55.403241  5893 solver.cpp:371]     Train net output #0: loss = 1.62617 (* 1 = 1.62617 loss)
I0629 01:45:55.403245  5893 sgd_solver.cpp:137] Iteration 103200, lr = 0.00355, m = 0.9
I0629 01:46:13.816303  5893 solver.cpp:349] Iteration 103300 (5.43112 iter/s, 18.4124s/100 iter), loss = 1.44201
I0629 01:46:13.816396  5893 solver.cpp:371]     Train net output #0: loss = 1.6535 (* 1 = 1.6535 loss)
I0629 01:46:13.816402  5893 sgd_solver.cpp:137] Iteration 103300, lr = 0.00354375, m = 0.9
I0629 01:46:32.297994  5893 solver.cpp:349] Iteration 103400 (5.41098 iter/s, 18.4809s/100 iter), loss = 1.94546
I0629 01:46:32.298019  5893 solver.cpp:371]     Train net output #0: loss = 1.91787 (* 1 = 1.91787 loss)
I0629 01:46:32.298023  5893 sgd_solver.cpp:137] Iteration 103400, lr = 0.0035375, m = 0.9
I0629 01:46:50.760198  5893 solver.cpp:349] Iteration 103500 (5.41668 iter/s, 18.4615s/100 iter), loss = 1.49159
I0629 01:46:50.760282  5893 solver.cpp:371]     Train net output #0: loss = 1.55986 (* 1 = 1.55986 loss)
I0629 01:46:50.760293  5893 sgd_solver.cpp:137] Iteration 103500, lr = 0.00353125, m = 0.9
I0629 01:47:09.222857  5893 solver.cpp:349] Iteration 103600 (5.41656 iter/s, 18.4619s/100 iter), loss = 1.52617
I0629 01:47:09.222880  5893 solver.cpp:371]     Train net output #0: loss = 1.25059 (* 1 = 1.25059 loss)
I0629 01:47:09.222884  5893 sgd_solver.cpp:137] Iteration 103600, lr = 0.003525, m = 0.9
I0629 01:47:27.684553  5893 solver.cpp:349] Iteration 103700 (5.41682 iter/s, 18.461s/100 iter), loss = 1.69467
I0629 01:47:27.684654  5893 solver.cpp:371]     Train net output #0: loss = 1.48765 (* 1 = 1.48765 loss)
I0629 01:47:27.684661  5893 sgd_solver.cpp:137] Iteration 103700, lr = 0.00351875, m = 0.9
I0629 01:47:46.170830  5893 solver.cpp:349] Iteration 103800 (5.40965 iter/s, 18.4855s/100 iter), loss = 1.43515
I0629 01:47:46.170855  5893 solver.cpp:371]     Train net output #0: loss = 1.5663 (* 1 = 1.5663 loss)
I0629 01:47:46.170858  5893 sgd_solver.cpp:137] Iteration 103800, lr = 0.0035125, m = 0.9
I0629 01:48:04.653528  5893 solver.cpp:349] Iteration 103900 (5.41067 iter/s, 18.482s/100 iter), loss = 1.54389
I0629 01:48:04.653641  5893 solver.cpp:371]     Train net output #0: loss = 1.62657 (* 1 = 1.62657 loss)
I0629 01:48:04.653646  5893 sgd_solver.cpp:137] Iteration 103900, lr = 0.00350625, m = 0.9
I0629 01:48:22.976438  5893 solver.cpp:401] Sparsity after update:
I0629 01:48:22.981621  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:48:22.981629  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:48:22.981637  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:48:22.981639  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:48:22.981644  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:48:22.981648  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:48:22.981652  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:48:22.981657  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:48:22.981662  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:48:22.981664  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:48:22.981667  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:48:22.981672  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:48:22.981675  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:48:22.981686  5893 solver.cpp:545] Iteration 104000, Testing net (#0)
I0629 01:48:47.493191  5888 data_reader.cpp:262] Starting prefetch of epoch 104
I0629 01:48:47.563066  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5618
I0629 01:48:47.563086  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79448
I0629 01:48:47.563091  5893 solver.cpp:630]     Test net output #2: loss = 1.91265 (* 1 = 1.91265 loss)
I0629 01:48:47.563110  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5805s
I0629 01:48:47.748853  5893 solver.cpp:349] Iteration 104000 (2.32053 iter/s, 43.0937s/100 iter), loss = 1.58104
I0629 01:48:47.748874  5893 solver.cpp:371]     Train net output #0: loss = 1.68041 (* 1 = 1.68041 loss)
I0629 01:48:47.748879  5893 sgd_solver.cpp:137] Iteration 104000, lr = 0.0035, m = 0.9
I0629 01:49:06.183902  5893 solver.cpp:349] Iteration 104100 (5.42466 iter/s, 18.4343s/100 iter), loss = 1.80348
I0629 01:49:06.183924  5893 solver.cpp:371]     Train net output #0: loss = 1.83292 (* 1 = 1.83292 loss)
I0629 01:49:06.183928  5893 sgd_solver.cpp:137] Iteration 104100, lr = 0.00349375, m = 0.9
I0629 01:49:24.601704  5893 solver.cpp:349] Iteration 104200 (5.42974 iter/s, 18.4171s/100 iter), loss = 1.60929
I0629 01:49:24.601816  5893 solver.cpp:371]     Train net output #0: loss = 1.87101 (* 1 = 1.87101 loss)
I0629 01:49:24.601824  5893 sgd_solver.cpp:137] Iteration 104200, lr = 0.0034875, m = 0.9
I0629 01:49:43.031642  5893 solver.cpp:349] Iteration 104300 (5.42619 iter/s, 18.4291s/100 iter), loss = 1.4331
I0629 01:49:43.031662  5893 solver.cpp:371]     Train net output #0: loss = 1.49349 (* 1 = 1.49349 loss)
I0629 01:49:43.031666  5893 sgd_solver.cpp:137] Iteration 104300, lr = 0.00348125, m = 0.9
I0629 01:50:01.461465  5893 solver.cpp:349] Iteration 104400 (5.42619 iter/s, 18.4291s/100 iter), loss = 1.61853
I0629 01:50:01.462105  5893 solver.cpp:371]     Train net output #0: loss = 1.6258 (* 1 = 1.6258 loss)
I0629 01:50:01.462111  5893 sgd_solver.cpp:137] Iteration 104400, lr = 0.003475, m = 0.9
I0629 01:50:19.909200  5893 solver.cpp:349] Iteration 104500 (5.42111 iter/s, 18.4464s/100 iter), loss = 1.443
I0629 01:50:19.909222  5893 solver.cpp:371]     Train net output #0: loss = 1.2643 (* 1 = 1.2643 loss)
I0629 01:50:19.909226  5893 sgd_solver.cpp:137] Iteration 104500, lr = 0.00346875, m = 0.9
I0629 01:50:38.350395  5893 solver.cpp:349] Iteration 104600 (5.42285 iter/s, 18.4405s/100 iter), loss = 1.47449
I0629 01:50:38.350481  5893 solver.cpp:371]     Train net output #0: loss = 1.40058 (* 1 = 1.40058 loss)
I0629 01:50:38.350486  5893 sgd_solver.cpp:137] Iteration 104600, lr = 0.0034625, m = 0.9
I0629 01:50:56.795337  5893 solver.cpp:349] Iteration 104700 (5.42177 iter/s, 18.4442s/100 iter), loss = 1.66497
I0629 01:50:56.795361  5893 solver.cpp:371]     Train net output #0: loss = 1.92537 (* 1 = 1.92537 loss)
I0629 01:50:56.795366  5893 sgd_solver.cpp:137] Iteration 104700, lr = 0.00345625, m = 0.9
I0629 01:51:15.387367  5893 solver.cpp:349] Iteration 104800 (5.37886 iter/s, 18.5913s/100 iter), loss = 1.52306
I0629 01:51:15.387485  5893 solver.cpp:371]     Train net output #0: loss = 1.4315 (* 1 = 1.4315 loss)
I0629 01:51:15.387491  5893 sgd_solver.cpp:137] Iteration 104800, lr = 0.00345, m = 0.9
I0629 01:51:33.936017  5893 solver.cpp:349] Iteration 104900 (5.39144 iter/s, 18.5479s/100 iter), loss = 1.38174
I0629 01:51:33.936035  5893 solver.cpp:371]     Train net output #0: loss = 1.19901 (* 1 = 1.19901 loss)
I0629 01:51:33.936039  5893 sgd_solver.cpp:137] Iteration 104900, lr = 0.00344375, m = 0.9
I0629 01:51:52.241530  5893 solver.cpp:401] Sparsity after update:
I0629 01:51:52.246772  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:51:52.246784  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:51:52.246789  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:51:52.246791  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:51:52.246794  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:51:52.246796  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:51:52.246798  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:51:52.246800  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:51:52.246801  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:51:52.246803  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:51:52.246814  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:51:52.246817  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:51:52.246820  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:51:52.246836  5893 solver.cpp:545] Iteration 105000, Testing net (#0)
I0629 01:52:16.527935  5888 data_reader.cpp:262] Starting prefetch of epoch 105
I0629 01:52:16.590103  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.566
I0629 01:52:16.590126  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7964
I0629 01:52:16.590132  5893 solver.cpp:630]     Test net output #2: loss = 1.90725 (* 1 = 1.90725 loss)
I0629 01:52:16.590153  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3426s
I0629 01:52:16.774722  5893 solver.cpp:349] Iteration 105000 (2.33441 iter/s, 42.8373s/100 iter), loss = 1.63489
I0629 01:52:16.774746  5893 solver.cpp:371]     Train net output #0: loss = 1.71354 (* 1 = 1.71354 loss)
I0629 01:52:16.774750  5893 sgd_solver.cpp:137] Iteration 105000, lr = 0.0034375, m = 0.9
I0629 01:52:34.049672  5875 data_reader.cpp:262] Starting prefetch of epoch 21
I0629 01:52:35.191725  5893 solver.cpp:349] Iteration 105100 (5.42995 iter/s, 18.4164s/100 iter), loss = 1.63645
I0629 01:52:35.191748  5893 solver.cpp:371]     Train net output #0: loss = 1.57961 (* 1 = 1.57961 loss)
I0629 01:52:35.191752  5893 sgd_solver.cpp:137] Iteration 105100, lr = 0.00343125, m = 0.9
I0629 01:52:53.616250  5893 solver.cpp:349] Iteration 105200 (5.42773 iter/s, 18.4239s/100 iter), loss = 1.51278
I0629 01:52:53.616273  5893 solver.cpp:371]     Train net output #0: loss = 1.3448 (* 1 = 1.3448 loss)
I0629 01:52:53.616277  5893 sgd_solver.cpp:137] Iteration 105200, lr = 0.003425, m = 0.9
I0629 01:53:12.067900  5893 solver.cpp:349] Iteration 105300 (5.41975 iter/s, 18.451s/100 iter), loss = 1.43339
I0629 01:53:12.067968  5893 solver.cpp:371]     Train net output #0: loss = 1.50907 (* 1 = 1.50907 loss)
I0629 01:53:12.067973  5893 sgd_solver.cpp:137] Iteration 105300, lr = 0.00341875, m = 0.9
I0629 01:53:30.487017  5893 solver.cpp:349] Iteration 105400 (5.42934 iter/s, 18.4185s/100 iter), loss = 1.55383
I0629 01:53:30.487040  5893 solver.cpp:371]     Train net output #0: loss = 1.61364 (* 1 = 1.61364 loss)
I0629 01:53:30.487045  5893 sgd_solver.cpp:137] Iteration 105400, lr = 0.0034125, m = 0.9
I0629 01:53:48.903245  5893 solver.cpp:349] Iteration 105500 (5.43018 iter/s, 18.4156s/100 iter), loss = 1.74912
I0629 01:53:48.903316  5893 solver.cpp:371]     Train net output #0: loss = 1.83347 (* 1 = 1.83347 loss)
I0629 01:53:48.903321  5893 sgd_solver.cpp:137] Iteration 105500, lr = 0.00340625, m = 0.9
I0629 01:54:07.328537  5893 solver.cpp:349] Iteration 105600 (5.42752 iter/s, 18.4246s/100 iter), loss = 1.39457
I0629 01:54:07.328558  5893 solver.cpp:371]     Train net output #0: loss = 1.47104 (* 1 = 1.47104 loss)
I0629 01:54:07.328562  5893 sgd_solver.cpp:137] Iteration 105600, lr = 0.0034, m = 0.9
I0629 01:54:25.865573  5893 solver.cpp:349] Iteration 105700 (5.39479 iter/s, 18.5364s/100 iter), loss = 1.75079
I0629 01:54:25.865667  5893 solver.cpp:371]     Train net output #0: loss = 1.46967 (* 1 = 1.46967 loss)
I0629 01:54:25.865672  5893 sgd_solver.cpp:137] Iteration 105700, lr = 0.00339375, m = 0.9
I0629 01:54:44.397020  5893 solver.cpp:349] Iteration 105800 (5.39644 iter/s, 18.5307s/100 iter), loss = 1.44313
I0629 01:54:44.397042  5893 solver.cpp:371]     Train net output #0: loss = 1.33402 (* 1 = 1.33402 loss)
I0629 01:54:44.397047  5893 sgd_solver.cpp:137] Iteration 105800, lr = 0.0033875, m = 0.9
I0629 01:55:02.931223  5893 solver.cpp:349] Iteration 105900 (5.39561 iter/s, 18.5336s/100 iter), loss = 1.60104
I0629 01:55:02.931321  5893 solver.cpp:371]     Train net output #0: loss = 1.57608 (* 1 = 1.57608 loss)
I0629 01:55:02.931330  5893 sgd_solver.cpp:137] Iteration 105900, lr = 0.00338125, m = 0.9
I0629 01:55:21.232303  5893 solver.cpp:401] Sparsity after update:
I0629 01:55:21.237576  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:55:21.237587  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:55:21.237596  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:55:21.237598  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:55:21.237601  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:55:21.237602  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:55:21.237604  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:55:21.237607  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:55:21.237608  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:55:21.237610  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:55:21.237612  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:55:21.237613  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:55:21.237615  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:55:21.237623  5893 solver.cpp:545] Iteration 106000, Testing net (#0)
I0629 01:55:23.691525  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 01:55:45.490821  5888 data_reader.cpp:262] Starting prefetch of epoch 106
I0629 01:55:45.557957  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56216
I0629 01:55:45.557977  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.793081
I0629 01:55:45.557982  5893 solver.cpp:630]     Test net output #2: loss = 1.9176 (* 1 = 1.9176 loss)
I0629 01:55:45.557999  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3196s
I0629 01:55:45.746904  5893 solver.cpp:349] Iteration 106000 (2.33567 iter/s, 42.8142s/100 iter), loss = 1.79076
I0629 01:55:45.746928  5893 solver.cpp:371]     Train net output #0: loss = 1.48529 (* 1 = 1.48529 loss)
I0629 01:55:45.746932  5893 sgd_solver.cpp:137] Iteration 106000, lr = 0.003375, m = 0.9
I0629 01:56:04.189635  5893 solver.cpp:349] Iteration 106100 (5.42238 iter/s, 18.4421s/100 iter), loss = 1.66161
I0629 01:56:04.189659  5893 solver.cpp:371]     Train net output #0: loss = 1.89615 (* 1 = 1.89615 loss)
I0629 01:56:04.189663  5893 sgd_solver.cpp:137] Iteration 106100, lr = 0.00336875, m = 0.9
I0629 01:56:22.623914  5893 solver.cpp:349] Iteration 106200 (5.42486 iter/s, 18.4336s/100 iter), loss = 1.69398
I0629 01:56:22.624027  5893 solver.cpp:371]     Train net output #0: loss = 1.87861 (* 1 = 1.87861 loss)
I0629 01:56:22.624034  5893 sgd_solver.cpp:137] Iteration 106200, lr = 0.0033625, m = 0.9
I0629 01:56:41.059830  5893 solver.cpp:349] Iteration 106300 (5.42441 iter/s, 18.4352s/100 iter), loss = 1.74893
I0629 01:56:41.059850  5893 solver.cpp:371]     Train net output #0: loss = 1.18206 (* 1 = 1.18206 loss)
I0629 01:56:41.059854  5893 sgd_solver.cpp:137] Iteration 106300, lr = 0.00335625, m = 0.9
I0629 01:56:59.490862  5893 solver.cpp:349] Iteration 106400 (5.42582 iter/s, 18.4304s/100 iter), loss = 1.30815
I0629 01:56:59.490949  5893 solver.cpp:371]     Train net output #0: loss = 1.3846 (* 1 = 1.3846 loss)
I0629 01:56:59.490953  5893 sgd_solver.cpp:137] Iteration 106400, lr = 0.00335, m = 0.9
I0629 01:57:17.910352  5893 solver.cpp:349] Iteration 106500 (5.42924 iter/s, 18.4188s/100 iter), loss = 1.65363
I0629 01:57:17.910377  5893 solver.cpp:371]     Train net output #0: loss = 1.47983 (* 1 = 1.47983 loss)
I0629 01:57:17.910380  5893 sgd_solver.cpp:137] Iteration 106500, lr = 0.00334375, m = 0.9
I0629 01:57:36.347276  5893 solver.cpp:349] Iteration 106600 (5.42409 iter/s, 18.4363s/100 iter), loss = 1.82681
I0629 01:57:36.349182  5893 solver.cpp:371]     Train net output #0: loss = 1.73651 (* 1 = 1.73651 loss)
I0629 01:57:36.349200  5893 sgd_solver.cpp:137] Iteration 106600, lr = 0.0033375, m = 0.9
I0629 01:57:54.927268  5893 solver.cpp:349] Iteration 106700 (5.38287 iter/s, 18.5774s/100 iter), loss = 1.43799
I0629 01:57:54.927289  5893 solver.cpp:371]     Train net output #0: loss = 1.42573 (* 1 = 1.42573 loss)
I0629 01:57:54.927294  5893 sgd_solver.cpp:137] Iteration 106700, lr = 0.00333125, m = 0.9
I0629 01:58:13.460530  5893 solver.cpp:349] Iteration 106800 (5.39589 iter/s, 18.5326s/100 iter), loss = 1.53125
I0629 01:58:13.460636  5893 solver.cpp:371]     Train net output #0: loss = 1.61357 (* 1 = 1.61357 loss)
I0629 01:58:13.460642  5893 sgd_solver.cpp:137] Iteration 106800, lr = 0.003325, m = 0.9
I0629 01:58:32.032444  5893 solver.cpp:349] Iteration 106900 (5.38469 iter/s, 18.5712s/100 iter), loss = 1.85651
I0629 01:58:32.032465  5893 solver.cpp:371]     Train net output #0: loss = 1.71265 (* 1 = 1.71265 loss)
I0629 01:58:32.032470  5893 sgd_solver.cpp:137] Iteration 106900, lr = 0.00331875, m = 0.9
I0629 01:58:50.328819  5893 solver.cpp:401] Sparsity after update:
I0629 01:58:50.334055  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 01:58:50.334064  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 01:58:50.334071  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 01:58:50.334074  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 01:58:50.334079  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 01:58:50.334081  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 01:58:50.334084  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 01:58:50.334087  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 01:58:50.334090  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 01:58:50.334094  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 01:58:50.334096  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 01:58:50.334100  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 01:58:50.334103  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 01:58:50.334113  5893 solver.cpp:545] Iteration 107000, Testing net (#0)
I0629 01:59:14.621965  5888 data_reader.cpp:262] Starting prefetch of epoch 107
I0629 01:59:14.687268  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5658
I0629 01:59:14.687288  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79596
I0629 01:59:14.687292  5893 solver.cpp:630]     Test net output #2: loss = 1.91119 (* 1 = 1.91119 loss)
I0629 01:59:14.687306  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3524s
I0629 01:59:14.878082  5893 solver.cpp:349] Iteration 107000 (2.33404 iter/s, 42.8442s/100 iter), loss = 1.60212
I0629 01:59:14.878106  5893 solver.cpp:371]     Train net output #0: loss = 1.67057 (* 1 = 1.67057 loss)
I0629 01:59:14.878110  5893 sgd_solver.cpp:137] Iteration 107000, lr = 0.0033125, m = 0.9
I0629 01:59:33.327359  5893 solver.cpp:349] Iteration 107100 (5.42046 iter/s, 18.4486s/100 iter), loss = 1.7354
I0629 01:59:33.327456  5893 solver.cpp:371]     Train net output #0: loss = 1.8517 (* 1 = 1.8517 loss)
I0629 01:59:33.327461  5893 sgd_solver.cpp:137] Iteration 107100, lr = 0.00330625, m = 0.9
I0629 01:59:51.803334  5893 solver.cpp:349] Iteration 107200 (5.41265 iter/s, 18.4753s/100 iter), loss = 1.69184
I0629 01:59:51.803357  5893 solver.cpp:371]     Train net output #0: loss = 1.26924 (* 1 = 1.26924 loss)
I0629 01:59:51.803361  5893 sgd_solver.cpp:137] Iteration 107200, lr = 0.0033, m = 0.9
I0629 02:00:10.235858  5893 solver.cpp:349] Iteration 107300 (5.42538 iter/s, 18.4319s/100 iter), loss = 1.68374
I0629 02:00:10.235958  5893 solver.cpp:371]     Train net output #0: loss = 1.7285 (* 1 = 1.7285 loss)
I0629 02:00:10.235965  5893 sgd_solver.cpp:137] Iteration 107300, lr = 0.00329375, m = 0.9
I0629 02:00:28.667713  5893 solver.cpp:349] Iteration 107400 (5.4256 iter/s, 18.4311s/100 iter), loss = 1.41154
I0629 02:00:28.667737  5893 solver.cpp:371]     Train net output #0: loss = 1.39921 (* 1 = 1.39921 loss)
I0629 02:00:28.667742  5893 sgd_solver.cpp:137] Iteration 107400, lr = 0.0032875, m = 0.9
I0629 02:00:47.090165  5893 solver.cpp:349] Iteration 107500 (5.42835 iter/s, 18.4218s/100 iter), loss = 1.41292
I0629 02:00:47.090230  5893 solver.cpp:371]     Train net output #0: loss = 1.55061 (* 1 = 1.55061 loss)
I0629 02:00:47.090235  5893 sgd_solver.cpp:137] Iteration 107500, lr = 0.00328125, m = 0.9
I0629 02:01:05.579082  5893 solver.cpp:349] Iteration 107600 (5.40885 iter/s, 18.4882s/100 iter), loss = 1.59423
I0629 02:01:05.579107  5893 solver.cpp:371]     Train net output #0: loss = 1.47935 (* 1 = 1.47935 loss)
I0629 02:01:05.579110  5893 sgd_solver.cpp:137] Iteration 107600, lr = 0.003275, m = 0.9
I0629 02:01:24.078716  5893 solver.cpp:349] Iteration 107700 (5.4057 iter/s, 18.499s/100 iter), loss = 1.5512
I0629 02:01:24.078809  5893 solver.cpp:371]     Train net output #0: loss = 1.34301 (* 1 = 1.34301 loss)
I0629 02:01:24.078816  5893 sgd_solver.cpp:137] Iteration 107700, lr = 0.00326875, m = 0.9
I0629 02:01:42.559362  5893 solver.cpp:349] Iteration 107800 (5.41128 iter/s, 18.4799s/100 iter), loss = 1.65184
I0629 02:01:42.559386  5893 solver.cpp:371]     Train net output #0: loss = 1.61061 (* 1 = 1.61061 loss)
I0629 02:01:42.559389  5893 sgd_solver.cpp:137] Iteration 107800, lr = 0.0032625, m = 0.9
I0629 02:02:01.066303  5893 solver.cpp:349] Iteration 107900 (5.40357 iter/s, 18.5063s/100 iter), loss = 1.47228
I0629 02:02:01.066416  5893 solver.cpp:371]     Train net output #0: loss = 1.30747 (* 1 = 1.30747 loss)
I0629 02:02:01.066426  5893 sgd_solver.cpp:137] Iteration 107900, lr = 0.00325625, m = 0.9
I0629 02:02:19.360517  5893 solver.cpp:401] Sparsity after update:
I0629 02:02:19.365794  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:02:19.365810  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:02:19.365816  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:02:19.365819  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:02:19.365823  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:02:19.365826  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:02:19.365829  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:02:19.365833  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:02:19.365835  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:02:19.365839  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:02:19.365841  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:02:19.365845  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:02:19.365851  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:02:19.365864  5893 solver.cpp:545] Iteration 108000, Testing net (#0)
I0629 02:02:43.671322  5888 data_reader.cpp:262] Starting prefetch of epoch 108
I0629 02:02:43.733999  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.564081
I0629 02:02:43.734020  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79448
I0629 02:02:43.734027  5893 solver.cpp:630]     Test net output #2: loss = 1.90806 (* 1 = 1.90806 loss)
I0629 02:02:43.734050  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3674s
I0629 02:02:43.918789  5893 solver.cpp:349] Iteration 108000 (2.33367 iter/s, 42.851s/100 iter), loss = 1.67213
I0629 02:02:43.918812  5893 solver.cpp:371]     Train net output #0: loss = 1.55683 (* 1 = 1.55683 loss)
I0629 02:02:43.918817  5893 sgd_solver.cpp:137] Iteration 108000, lr = 0.00325, m = 0.9
I0629 02:03:02.350088  5893 solver.cpp:349] Iteration 108100 (5.42573 iter/s, 18.4307s/100 iter), loss = 1.75551
I0629 02:03:02.350111  5893 solver.cpp:371]     Train net output #0: loss = 1.53021 (* 1 = 1.53021 loss)
I0629 02:03:02.350116  5893 sgd_solver.cpp:137] Iteration 108100, lr = 0.00324375, m = 0.9
I0629 02:03:20.766135  5893 solver.cpp:349] Iteration 108200 (5.43023 iter/s, 18.4154s/100 iter), loss = 1.91478
I0629 02:03:20.766217  5893 solver.cpp:371]     Train net output #0: loss = 1.62695 (* 1 = 1.62695 loss)
I0629 02:03:20.766222  5893 sgd_solver.cpp:137] Iteration 108200, lr = 0.0032375, m = 0.9
I0629 02:03:39.204751  5893 solver.cpp:349] Iteration 108300 (5.4236 iter/s, 18.4379s/100 iter), loss = 1.4766
I0629 02:03:39.204777  5893 solver.cpp:371]     Train net output #0: loss = 1.41316 (* 1 = 1.41316 loss)
I0629 02:03:39.204782  5893 sgd_solver.cpp:137] Iteration 108300, lr = 0.00323125, m = 0.9
I0629 02:03:57.633839  5893 solver.cpp:349] Iteration 108400 (5.42639 iter/s, 18.4285s/100 iter), loss = 1.29353
I0629 02:03:57.633924  5893 solver.cpp:371]     Train net output #0: loss = 1.29453 (* 1 = 1.29453 loss)
I0629 02:03:57.633929  5893 sgd_solver.cpp:137] Iteration 108400, lr = 0.003225, m = 0.9
I0629 02:04:16.059458  5893 solver.cpp:349] Iteration 108500 (5.42743 iter/s, 18.4249s/100 iter), loss = 1.8704
I0629 02:04:16.059479  5893 solver.cpp:371]     Train net output #0: loss = 2.20115 (* 1 = 2.20115 loss)
I0629 02:04:16.059484  5893 sgd_solver.cpp:137] Iteration 108500, lr = 0.00321875, m = 0.9
I0629 02:04:34.495496  5893 solver.cpp:349] Iteration 108600 (5.42434 iter/s, 18.4354s/100 iter), loss = 1.83939
I0629 02:04:34.495609  5893 solver.cpp:371]     Train net output #0: loss = 1.68128 (* 1 = 1.68128 loss)
I0629 02:04:34.495615  5893 sgd_solver.cpp:137] Iteration 108600, lr = 0.0032125, m = 0.9
I0629 02:04:52.957556  5893 solver.cpp:349] Iteration 108700 (5.41672 iter/s, 18.4613s/100 iter), loss = 1.67321
I0629 02:04:52.957576  5893 solver.cpp:371]     Train net output #0: loss = 1.89007 (* 1 = 1.89007 loss)
I0629 02:04:52.957581  5893 sgd_solver.cpp:137] Iteration 108700, lr = 0.00320625, m = 0.9
I0629 02:05:11.486845  5893 solver.cpp:349] Iteration 108800 (5.39704 iter/s, 18.5287s/100 iter), loss = 1.8178
I0629 02:05:11.486932  5893 solver.cpp:371]     Train net output #0: loss = 1.53125 (* 1 = 1.53125 loss)
I0629 02:05:11.486937  5893 sgd_solver.cpp:137] Iteration 108800, lr = 0.0032, m = 0.9
I0629 02:05:29.984632  5893 solver.cpp:349] Iteration 108900 (5.40625 iter/s, 18.4971s/100 iter), loss = 1.36076
I0629 02:05:29.984652  5893 solver.cpp:371]     Train net output #0: loss = 1.55673 (* 1 = 1.55673 loss)
I0629 02:05:29.984657  5893 sgd_solver.cpp:137] Iteration 108900, lr = 0.00319375, m = 0.9
I0629 02:05:48.283596  5893 solver.cpp:401] Sparsity after update:
I0629 02:05:48.292150  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:05:48.292160  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:05:48.292168  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:05:48.292171  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:05:48.292176  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:05:48.292178  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:05:48.292182  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:05:48.292186  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:05:48.292188  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:05:48.292191  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:05:48.292194  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:05:48.292199  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:05:48.292203  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:05:48.292214  5893 solver.cpp:545] Iteration 109000, Testing net (#0)
I0629 02:06:12.865748  5888 data_reader.cpp:262] Starting prefetch of epoch 109
I0629 02:06:12.927516  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56624
I0629 02:06:12.927536  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79368
I0629 02:06:12.927541  5893 solver.cpp:630]     Test net output #2: loss = 1.90102 (* 1 = 1.90102 loss)
I0629 02:06:12.927557  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6346s
I0629 02:06:13.112124  5893 solver.cpp:349] Iteration 109000 (2.31878 iter/s, 43.1261s/100 iter), loss = 1.47964
I0629 02:06:13.112149  5893 solver.cpp:371]     Train net output #0: loss = 1.36931 (* 1 = 1.36931 loss)
I0629 02:06:13.112152  5893 sgd_solver.cpp:137] Iteration 109000, lr = 0.0031875, m = 0.9
I0629 02:06:31.606302  5893 solver.cpp:349] Iteration 109100 (5.40729 iter/s, 18.4935s/100 iter), loss = 1.64123
I0629 02:06:31.606401  5893 solver.cpp:371]     Train net output #0: loss = 1.75087 (* 1 = 1.75087 loss)
I0629 02:06:31.606408  5893 sgd_solver.cpp:137] Iteration 109100, lr = 0.00318125, m = 0.9
I0629 02:06:50.090394  5893 solver.cpp:349] Iteration 109200 (5.41027 iter/s, 18.4834s/100 iter), loss = 1.57312
I0629 02:06:50.090415  5893 solver.cpp:371]     Train net output #0: loss = 1.56493 (* 1 = 1.56493 loss)
I0629 02:06:50.090420  5893 sgd_solver.cpp:137] Iteration 109200, lr = 0.003175, m = 0.9
I0629 02:07:08.534139  5893 solver.cpp:349] Iteration 109300 (5.42208 iter/s, 18.4431s/100 iter), loss = 1.31732
I0629 02:07:08.534214  5893 solver.cpp:371]     Train net output #0: loss = 1.44274 (* 1 = 1.44274 loss)
I0629 02:07:08.534219  5893 sgd_solver.cpp:137] Iteration 109300, lr = 0.00316875, m = 0.9
I0629 02:07:26.975651  5893 solver.cpp:349] Iteration 109400 (5.42275 iter/s, 18.4408s/100 iter), loss = 1.40917
I0629 02:07:26.975673  5893 solver.cpp:371]     Train net output #0: loss = 1.37254 (* 1 = 1.37254 loss)
I0629 02:07:26.975678  5893 sgd_solver.cpp:137] Iteration 109400, lr = 0.0031625, m = 0.9
I0629 02:07:45.431146  5893 solver.cpp:349] Iteration 109500 (5.41863 iter/s, 18.4549s/100 iter), loss = 1.48
I0629 02:07:45.431229  5893 solver.cpp:371]     Train net output #0: loss = 1.31858 (* 1 = 1.31858 loss)
I0629 02:07:45.431234  5893 sgd_solver.cpp:137] Iteration 109500, lr = 0.00315625, m = 0.9
I0629 02:08:03.881816  5893 solver.cpp:349] Iteration 109600 (5.42006 iter/s, 18.45s/100 iter), loss = 1.5528
I0629 02:08:03.881840  5893 solver.cpp:371]     Train net output #0: loss = 1.40293 (* 1 = 1.40293 loss)
I0629 02:08:03.881844  5893 sgd_solver.cpp:137] Iteration 109600, lr = 0.00315, m = 0.9
I0629 02:08:22.358001  5893 solver.cpp:349] Iteration 109700 (5.41256 iter/s, 18.4755s/100 iter), loss = 1.35481
I0629 02:08:22.358108  5893 solver.cpp:371]     Train net output #0: loss = 1.26483 (* 1 = 1.26483 loss)
I0629 02:08:22.358116  5893 sgd_solver.cpp:137] Iteration 109700, lr = 0.00314375, m = 0.9
I0629 02:08:40.841249  5893 solver.cpp:349] Iteration 109800 (5.41052 iter/s, 18.4825s/100 iter), loss = 1.54066
I0629 02:08:40.841275  5893 solver.cpp:371]     Train net output #0: loss = 1.50649 (* 1 = 1.50649 loss)
I0629 02:08:40.841280  5893 sgd_solver.cpp:137] Iteration 109800, lr = 0.0031375, m = 0.9
I0629 02:08:59.376639  5893 solver.cpp:349] Iteration 109900 (5.39527 iter/s, 18.5347s/100 iter), loss = 1.425
I0629 02:08:59.376729  5893 solver.cpp:371]     Train net output #0: loss = 1.57972 (* 1 = 1.57972 loss)
I0629 02:08:59.376736  5893 sgd_solver.cpp:137] Iteration 109900, lr = 0.00313125, m = 0.9
I0629 02:09:17.689525  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_110000.caffemodel
I0629 02:09:17.728929  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_110000.solverstate
I0629 02:09:17.734566  5893 solver.cpp:401] Sparsity after update:
I0629 02:09:17.735580  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:09:17.735591  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:09:17.735599  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:09:17.735604  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:09:17.735606  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:09:17.735611  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:09:17.735615  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:09:17.735617  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:09:17.735621  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:09:17.735625  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:09:17.735628  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:09:17.735635  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:09:17.735641  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:09:17.735652  5893 solver.cpp:545] Iteration 110000, Testing net (#0)
I0629 02:09:42.069097  5888 data_reader.cpp:262] Starting prefetch of epoch 110
I0629 02:09:42.208998  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56568
I0629 02:09:42.209018  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79648
I0629 02:09:42.209023  5893 solver.cpp:630]     Test net output #2: loss = 1.90265 (* 1 = 1.90265 loss)
I0629 02:09:42.209039  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4726s
I0629 02:09:42.398568  5893 solver.cpp:349] Iteration 110000 (2.32448 iter/s, 43.0204s/100 iter), loss = 1.69684
I0629 02:09:42.398591  5893 solver.cpp:371]     Train net output #0: loss = 1.67998 (* 1 = 1.67998 loss)
I0629 02:09:42.398593  5893 sgd_solver.cpp:137] Iteration 110000, lr = 0.003125, m = 0.9
I0629 02:10:00.497036  5875 data_reader.cpp:262] Starting prefetch of epoch 22
I0629 02:10:00.806568  5893 solver.cpp:349] Iteration 110100 (5.43261 iter/s, 18.4074s/100 iter), loss = 1.47136
I0629 02:10:00.806591  5893 solver.cpp:371]     Train net output #0: loss = 1.61592 (* 1 = 1.61592 loss)
I0629 02:10:00.806596  5893 sgd_solver.cpp:137] Iteration 110100, lr = 0.00311875, m = 0.9
I0629 02:10:19.256346  5893 solver.cpp:349] Iteration 110200 (5.42031 iter/s, 18.4491s/100 iter), loss = 1.67682
I0629 02:10:19.256453  5893 solver.cpp:371]     Train net output #0: loss = 1.60298 (* 1 = 1.60298 loss)
I0629 02:10:19.256459  5893 sgd_solver.cpp:137] Iteration 110200, lr = 0.0031125, m = 0.9
I0629 02:10:37.701164  5893 solver.cpp:349] Iteration 110300 (5.42179 iter/s, 18.4441s/100 iter), loss = 1.54065
I0629 02:10:37.701184  5893 solver.cpp:371]     Train net output #0: loss = 1.4732 (* 1 = 1.4732 loss)
I0629 02:10:37.701189  5893 sgd_solver.cpp:137] Iteration 110300, lr = 0.00310625, m = 0.9
I0629 02:10:56.183162  5893 solver.cpp:349] Iteration 110400 (5.41086 iter/s, 18.4814s/100 iter), loss = 1.60975
I0629 02:10:56.183212  5893 solver.cpp:371]     Train net output #0: loss = 1.69077 (* 1 = 1.69077 loss)
I0629 02:10:56.183218  5893 sgd_solver.cpp:137] Iteration 110400, lr = 0.0031, m = 0.9
I0629 02:11:14.637382  5893 solver.cpp:349] Iteration 110500 (5.41901 iter/s, 18.4535s/100 iter), loss = 1.39596
I0629 02:11:14.637408  5893 solver.cpp:371]     Train net output #0: loss = 1.54385 (* 1 = 1.54385 loss)
I0629 02:11:14.637413  5893 sgd_solver.cpp:137] Iteration 110500, lr = 0.00309375, m = 0.9
I0629 02:11:33.098685  5893 solver.cpp:349] Iteration 110600 (5.41693 iter/s, 18.4606s/100 iter), loss = 1.47496
I0629 02:11:33.098781  5893 solver.cpp:371]     Train net output #0: loss = 1.50715 (* 1 = 1.50715 loss)
I0629 02:11:33.098788  5893 sgd_solver.cpp:137] Iteration 110600, lr = 0.0030875, m = 0.9
I0629 02:11:51.557376  5893 solver.cpp:349] Iteration 110700 (5.41772 iter/s, 18.458s/100 iter), loss = 1.61233
I0629 02:11:51.557399  5893 solver.cpp:371]     Train net output #0: loss = 1.82754 (* 1 = 1.82754 loss)
I0629 02:11:51.557404  5893 sgd_solver.cpp:137] Iteration 110700, lr = 0.00308125, m = 0.9
I0629 02:12:10.102213  5893 solver.cpp:349] Iteration 110800 (5.39253 iter/s, 18.5442s/100 iter), loss = 1.63911
I0629 02:12:10.105589  5893 solver.cpp:371]     Train net output #0: loss = 1.472 (* 1 = 1.472 loss)
I0629 02:12:10.105602  5893 sgd_solver.cpp:137] Iteration 110800, lr = 0.003075, m = 0.9
I0629 02:12:28.559154  5893 solver.cpp:349] Iteration 110900 (5.4192 iter/s, 18.4529s/100 iter), loss = 1.45308
I0629 02:12:28.559180  5893 solver.cpp:371]     Train net output #0: loss = 1.45859 (* 1 = 1.45859 loss)
I0629 02:12:28.559185  5893 sgd_solver.cpp:137] Iteration 110900, lr = 0.00306875, m = 0.9
I0629 02:12:46.840442  5893 solver.cpp:401] Sparsity after update:
I0629 02:12:46.845679  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:12:46.845690  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:12:46.845697  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:12:46.845700  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:12:46.845705  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:12:46.845707  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:12:46.845710  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:12:46.845713  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:12:46.845716  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:12:46.845719  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:12:46.845722  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:12:46.845726  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:12:46.845731  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:12:46.845741  5893 solver.cpp:545] Iteration 111000, Testing net (#0)
I0629 02:12:49.614567  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 02:13:11.335227  5888 data_reader.cpp:262] Starting prefetch of epoch 111
I0629 02:13:11.524564  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.566
I0629 02:13:11.524580  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79476
I0629 02:13:11.524585  5893 solver.cpp:630]     Test net output #2: loss = 1.9079 (* 1 = 1.9079 loss)
I0629 02:13:11.524603  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.678s
I0629 02:13:11.708765  5893 solver.cpp:349] Iteration 111000 (2.3176 iter/s, 43.1481s/100 iter), loss = 1.6079
I0629 02:13:11.708788  5893 solver.cpp:371]     Train net output #0: loss = 1.40701 (* 1 = 1.40701 loss)
I0629 02:13:11.708792  5893 sgd_solver.cpp:137] Iteration 111000, lr = 0.0030625, m = 0.9
I0629 02:13:30.137945  5893 solver.cpp:349] Iteration 111100 (5.42637 iter/s, 18.4285s/100 iter), loss = 1.78475
I0629 02:13:30.138042  5893 solver.cpp:371]     Train net output #0: loss = 1.72806 (* 1 = 1.72806 loss)
I0629 02:13:30.138049  5893 sgd_solver.cpp:137] Iteration 111100, lr = 0.00305625, m = 0.9
I0629 02:13:48.573526  5893 solver.cpp:349] Iteration 111200 (5.42451 iter/s, 18.4348s/100 iter), loss = 1.5928
I0629 02:13:48.573554  5893 solver.cpp:371]     Train net output #0: loss = 1.47689 (* 1 = 1.47689 loss)
I0629 02:13:48.573561  5893 sgd_solver.cpp:137] Iteration 111200, lr = 0.00305, m = 0.9
I0629 02:14:06.983507  5893 solver.cpp:349] Iteration 111300 (5.43204 iter/s, 18.4093s/100 iter), loss = 1.82472
I0629 02:14:06.983608  5893 solver.cpp:371]     Train net output #0: loss = 1.70948 (* 1 = 1.70948 loss)
I0629 02:14:06.983613  5893 sgd_solver.cpp:137] Iteration 111300, lr = 0.00304375, m = 0.9
I0629 02:14:25.411069  5893 solver.cpp:349] Iteration 111400 (5.42687 iter/s, 18.4268s/100 iter), loss = 1.7321
I0629 02:14:25.411090  5893 solver.cpp:371]     Train net output #0: loss = 1.4516 (* 1 = 1.4516 loss)
I0629 02:14:25.411094  5893 sgd_solver.cpp:137] Iteration 111400, lr = 0.0030375, m = 0.9
I0629 02:14:43.838013  5893 solver.cpp:349] Iteration 111500 (5.42703 iter/s, 18.4263s/100 iter), loss = 1.48022
I0629 02:14:43.838112  5893 solver.cpp:371]     Train net output #0: loss = 1.29647 (* 1 = 1.29647 loss)
I0629 02:14:43.838119  5893 sgd_solver.cpp:137] Iteration 111500, lr = 0.00303125, m = 0.9
I0629 02:15:02.272092  5893 solver.cpp:349] Iteration 111600 (5.42495 iter/s, 18.4333s/100 iter), loss = 1.88297
I0629 02:15:02.272116  5893 solver.cpp:371]     Train net output #0: loss = 1.81529 (* 1 = 1.81529 loss)
I0629 02:15:02.272119  5893 sgd_solver.cpp:137] Iteration 111600, lr = 0.003025, m = 0.9
I0629 02:15:20.765262  5893 solver.cpp:349] Iteration 111700 (5.4076 iter/s, 18.4925s/100 iter), loss = 1.69941
I0629 02:15:20.765363  5893 solver.cpp:371]     Train net output #0: loss = 1.77697 (* 1 = 1.77697 loss)
I0629 02:15:20.765369  5893 sgd_solver.cpp:137] Iteration 111700, lr = 0.00301875, m = 0.9
I0629 02:15:39.308622  5893 solver.cpp:349] Iteration 111800 (5.39298 iter/s, 18.5426s/100 iter), loss = 1.61634
I0629 02:15:39.308645  5893 solver.cpp:371]     Train net output #0: loss = 1.50134 (* 1 = 1.50134 loss)
I0629 02:15:39.308650  5893 sgd_solver.cpp:137] Iteration 111800, lr = 0.0030125, m = 0.9
I0629 02:15:57.796437  5893 solver.cpp:349] Iteration 111900 (5.40916 iter/s, 18.4872s/100 iter), loss = 1.97636
I0629 02:15:57.796538  5893 solver.cpp:371]     Train net output #0: loss = 2.39692 (* 1 = 2.39692 loss)
I0629 02:15:57.796545  5893 sgd_solver.cpp:137] Iteration 111900, lr = 0.00300625, m = 0.9
I0629 02:16:16.096226  5893 solver.cpp:401] Sparsity after update:
I0629 02:16:16.101487  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:16:16.101496  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:16:16.101505  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:16:16.101508  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:16:16.101511  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:16:16.101514  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:16:16.101517  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:16:16.101521  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:16:16.101524  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:16:16.101527  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:16:16.101531  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:16:16.101533  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:16:16.101536  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:16:16.101558  5893 solver.cpp:545] Iteration 112000, Testing net (#0)
I0629 02:16:40.324924  5888 data_reader.cpp:262] Starting prefetch of epoch 112
I0629 02:16:40.492285  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56524
I0629 02:16:40.492307  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.795
I0629 02:16:40.492312  5893 solver.cpp:630]     Test net output #2: loss = 1.9104 (* 1 = 1.9104 loss)
I0629 02:16:40.492329  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3899s
I0629 02:16:40.677567  5893 solver.cpp:349] Iteration 112000 (2.33211 iter/s, 42.8796s/100 iter), loss = 1.60601
I0629 02:16:40.677588  5893 solver.cpp:371]     Train net output #0: loss = 1.66164 (* 1 = 1.66164 loss)
I0629 02:16:40.677592  5893 sgd_solver.cpp:137] Iteration 112000, lr = 0.003, m = 0.9
I0629 02:16:59.109803  5893 solver.cpp:349] Iteration 112100 (5.42547 iter/s, 18.4316s/100 iter), loss = 1.42525
I0629 02:16:59.109827  5893 solver.cpp:371]     Train net output #0: loss = 1.47653 (* 1 = 1.47653 loss)
I0629 02:16:59.109830  5893 sgd_solver.cpp:137] Iteration 112100, lr = 0.00299375, m = 0.9
I0629 02:17:17.536504  5893 solver.cpp:349] Iteration 112200 (5.4271 iter/s, 18.426s/100 iter), loss = 1.44942
I0629 02:17:17.536589  5893 solver.cpp:371]     Train net output #0: loss = 1.53714 (* 1 = 1.53714 loss)
I0629 02:17:17.536594  5893 sgd_solver.cpp:137] Iteration 112200, lr = 0.0029875, m = 0.9
I0629 02:17:35.968269  5893 solver.cpp:349] Iteration 112300 (5.42563 iter/s, 18.431s/100 iter), loss = 1.48975
I0629 02:17:35.968291  5893 solver.cpp:371]     Train net output #0: loss = 1.71082 (* 1 = 1.71082 loss)
I0629 02:17:35.968294  5893 sgd_solver.cpp:137] Iteration 112300, lr = 0.00298125, m = 0.9
I0629 02:17:54.388068  5893 solver.cpp:349] Iteration 112400 (5.42914 iter/s, 18.4191s/100 iter), loss = 1.40237
I0629 02:17:54.388170  5893 solver.cpp:371]     Train net output #0: loss = 1.41245 (* 1 = 1.41245 loss)
I0629 02:17:54.388175  5893 sgd_solver.cpp:137] Iteration 112400, lr = 0.002975, m = 0.9
I0629 02:18:12.806506  5893 solver.cpp:349] Iteration 112500 (5.42956 iter/s, 18.4177s/100 iter), loss = 1.56369
I0629 02:18:12.806529  5893 solver.cpp:371]     Train net output #0: loss = 1.37712 (* 1 = 1.37712 loss)
I0629 02:18:12.806532  5893 sgd_solver.cpp:137] Iteration 112500, lr = 0.00296875, m = 0.9
I0629 02:18:31.286478  5893 solver.cpp:349] Iteration 112600 (5.41146 iter/s, 18.4793s/100 iter), loss = 1.75845
I0629 02:18:31.286561  5893 solver.cpp:371]     Train net output #0: loss = 1.75922 (* 1 = 1.75922 loss)
I0629 02:18:31.286566  5893 sgd_solver.cpp:137] Iteration 112600, lr = 0.0029625, m = 0.9
I0629 02:18:49.852798  5893 solver.cpp:349] Iteration 112700 (5.38629 iter/s, 18.5656s/100 iter), loss = 1.88399
I0629 02:18:49.852820  5893 solver.cpp:371]     Train net output #0: loss = 2.0359 (* 1 = 2.0359 loss)
I0629 02:18:49.852824  5893 sgd_solver.cpp:137] Iteration 112700, lr = 0.00295625, m = 0.9
I0629 02:19:08.370468  5893 solver.cpp:349] Iteration 112800 (5.40043 iter/s, 18.5171s/100 iter), loss = 1.40139
I0629 02:19:08.370568  5893 solver.cpp:371]     Train net output #0: loss = 1.21484 (* 1 = 1.21484 loss)
I0629 02:19:08.370575  5893 sgd_solver.cpp:137] Iteration 112800, lr = 0.00295, m = 0.9
I0629 02:19:26.888700  5893 solver.cpp:349] Iteration 112900 (5.40029 iter/s, 18.5175s/100 iter), loss = 1.62279
I0629 02:19:26.888723  5893 solver.cpp:371]     Train net output #0: loss = 1.5194 (* 1 = 1.5194 loss)
I0629 02:19:26.888727  5893 sgd_solver.cpp:137] Iteration 112900, lr = 0.00294375, m = 0.9
I0629 02:19:45.212108  5893 solver.cpp:401] Sparsity after update:
I0629 02:19:45.217254  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:19:45.217263  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:19:45.217269  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:19:45.217272  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:19:45.217274  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:19:45.217277  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:19:45.217278  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:19:45.217279  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:19:45.217281  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:19:45.217283  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:19:45.217285  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:19:45.217288  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:19:45.217289  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:19:45.217296  5893 solver.cpp:545] Iteration 113000, Testing net (#0)
I0629 02:20:09.407039  5888 data_reader.cpp:262] Starting prefetch of epoch 113
I0629 02:20:09.480532  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56532
I0629 02:20:09.480553  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7962
I0629 02:20:09.480558  5893 solver.cpp:630]     Test net output #2: loss = 1.90164 (* 1 = 1.90164 loss)
I0629 02:20:09.480574  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2625s
I0629 02:20:09.665834  5893 solver.cpp:349] Iteration 113000 (2.33777 iter/s, 42.7758s/100 iter), loss = 1.67263
I0629 02:20:09.665858  5893 solver.cpp:371]     Train net output #0: loss = 1.78088 (* 1 = 1.78088 loss)
I0629 02:20:09.665864  5893 sgd_solver.cpp:137] Iteration 113000, lr = 0.0029375, m = 0.9
I0629 02:20:28.074249  5893 solver.cpp:349] Iteration 113100 (5.43248 iter/s, 18.4078s/100 iter), loss = 1.57783
I0629 02:20:28.074326  5893 solver.cpp:371]     Train net output #0: loss = 1.69473 (* 1 = 1.69473 loss)
I0629 02:20:28.074332  5893 sgd_solver.cpp:137] Iteration 113100, lr = 0.00293125, m = 0.9
I0629 02:20:46.513595  5893 solver.cpp:349] Iteration 113200 (5.42339 iter/s, 18.4387s/100 iter), loss = 1.71953
I0629 02:20:46.513620  5893 solver.cpp:371]     Train net output #0: loss = 1.70474 (* 1 = 1.70474 loss)
I0629 02:20:46.513626  5893 sgd_solver.cpp:137] Iteration 113200, lr = 0.002925, m = 0.9
I0629 02:21:04.949787  5893 solver.cpp:349] Iteration 113300 (5.4243 iter/s, 18.4356s/100 iter), loss = 1.6483
I0629 02:21:04.949870  5893 solver.cpp:371]     Train net output #0: loss = 1.39896 (* 1 = 1.39896 loss)
I0629 02:21:04.949875  5893 sgd_solver.cpp:137] Iteration 113300, lr = 0.00291875, m = 0.9
I0629 02:21:23.377270  5893 solver.cpp:349] Iteration 113400 (5.42688 iter/s, 18.4268s/100 iter), loss = 1.6132
I0629 02:21:23.377293  5893 solver.cpp:371]     Train net output #0: loss = 1.86129 (* 1 = 1.86129 loss)
I0629 02:21:23.377297  5893 sgd_solver.cpp:137] Iteration 113400, lr = 0.0029125, m = 0.9
I0629 02:21:41.806115  5893 solver.cpp:349] Iteration 113500 (5.42646 iter/s, 18.4282s/100 iter), loss = 1.68091
I0629 02:21:41.806221  5893 solver.cpp:371]     Train net output #0: loss = 1.54312 (* 1 = 1.54312 loss)
I0629 02:21:41.806227  5893 sgd_solver.cpp:137] Iteration 113500, lr = 0.00290625, m = 0.9
I0629 02:22:00.267221  5893 solver.cpp:349] Iteration 113600 (5.417 iter/s, 18.4604s/100 iter), loss = 1.76302
I0629 02:22:00.267244  5893 solver.cpp:371]     Train net output #0: loss = 1.81691 (* 1 = 1.81691 loss)
I0629 02:22:00.267248  5893 sgd_solver.cpp:137] Iteration 113600, lr = 0.0029, m = 0.9
I0629 02:22:18.797615  5893 solver.cpp:349] Iteration 113700 (5.39672 iter/s, 18.5298s/100 iter), loss = 1.42828
I0629 02:22:18.797700  5893 solver.cpp:371]     Train net output #0: loss = 1.6618 (* 1 = 1.6618 loss)
I0629 02:22:18.797704  5893 sgd_solver.cpp:137] Iteration 113700, lr = 0.00289375, m = 0.9
I0629 02:22:37.296027  5893 solver.cpp:349] Iteration 113800 (5.40607 iter/s, 18.4977s/100 iter), loss = 1.31957
I0629 02:22:37.296051  5893 solver.cpp:371]     Train net output #0: loss = 0.956099 (* 1 = 0.956099 loss)
I0629 02:22:37.296054  5893 sgd_solver.cpp:137] Iteration 113800, lr = 0.0028875, m = 0.9
I0629 02:22:55.828548  5893 solver.cpp:349] Iteration 113900 (5.3961 iter/s, 18.5319s/100 iter), loss = 1.57747
I0629 02:22:55.828665  5893 solver.cpp:371]     Train net output #0: loss = 1.61612 (* 1 = 1.61612 loss)
I0629 02:22:55.828670  5893 sgd_solver.cpp:137] Iteration 113900, lr = 0.00288125, m = 0.9
I0629 02:23:14.121615  5893 solver.cpp:401] Sparsity after update:
I0629 02:23:14.126843  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:23:14.126852  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:23:14.126858  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:23:14.126860  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:23:14.126863  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:23:14.126864  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:23:14.126866  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:23:14.126868  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:23:14.126870  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:23:14.126871  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:23:14.126873  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:23:14.126875  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:23:14.126878  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:23:14.126884  5893 solver.cpp:545] Iteration 114000, Testing net (#0)
I0629 02:23:38.331333  5888 data_reader.cpp:262] Starting prefetch of epoch 114
I0629 02:23:38.397060  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5642
I0629 02:23:38.397080  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79572
I0629 02:23:38.397085  5893 solver.cpp:630]     Test net output #2: loss = 1.90417 (* 1 = 1.90417 loss)
I0629 02:23:38.397101  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2694s
I0629 02:23:38.582837  5893 solver.cpp:349] Iteration 114000 (2.33903 iter/s, 42.7528s/100 iter), loss = 1.57006
I0629 02:23:38.582860  5893 solver.cpp:371]     Train net output #0: loss = 1.4737 (* 1 = 1.4737 loss)
I0629 02:23:38.582864  5893 sgd_solver.cpp:137] Iteration 114000, lr = 0.002875, m = 0.9
I0629 02:23:57.015311  5893 solver.cpp:349] Iteration 114100 (5.42539 iter/s, 18.4318s/100 iter), loss = 1.60495
I0629 02:23:57.015334  5893 solver.cpp:371]     Train net output #0: loss = 1.80039 (* 1 = 1.80039 loss)
I0629 02:23:57.015341  5893 sgd_solver.cpp:137] Iteration 114100, lr = 0.00286875, m = 0.9
I0629 02:24:15.492553  5893 solver.cpp:349] Iteration 114200 (5.41225 iter/s, 18.4766s/100 iter), loss = 1.44944
I0629 02:24:15.493165  5893 solver.cpp:371]     Train net output #0: loss = 1.52473 (* 1 = 1.52473 loss)
I0629 02:24:15.493173  5893 sgd_solver.cpp:137] Iteration 114200, lr = 0.0028625, m = 0.9
I0629 02:24:33.935083  5893 solver.cpp:349] Iteration 114300 (5.42261 iter/s, 18.4413s/100 iter), loss = 1.43946
I0629 02:24:33.935107  5893 solver.cpp:371]     Train net output #0: loss = 1.40471 (* 1 = 1.40471 loss)
I0629 02:24:33.935113  5893 sgd_solver.cpp:137] Iteration 114300, lr = 0.00285625, m = 0.9
I0629 02:24:52.390596  5893 solver.cpp:349] Iteration 114400 (5.41862 iter/s, 18.4549s/100 iter), loss = 1.50294
I0629 02:24:52.390635  5893 solver.cpp:371]     Train net output #0: loss = 1.60461 (* 1 = 1.60461 loss)
I0629 02:24:52.390640  5893 sgd_solver.cpp:137] Iteration 114400, lr = 0.00285, m = 0.9
I0629 02:25:10.841615  5893 solver.cpp:349] Iteration 114500 (5.41995 iter/s, 18.4504s/100 iter), loss = 1.80004
I0629 02:25:10.841641  5893 solver.cpp:371]     Train net output #0: loss = 1.50925 (* 1 = 1.50925 loss)
I0629 02:25:10.841646  5893 sgd_solver.cpp:137] Iteration 114500, lr = 0.00284375, m = 0.9
I0629 02:25:29.293398  5893 solver.cpp:349] Iteration 114600 (5.41972 iter/s, 18.4511s/100 iter), loss = 1.88664
I0629 02:25:29.293470  5893 solver.cpp:371]     Train net output #0: loss = 1.85276 (* 1 = 1.85276 loss)
I0629 02:25:29.293476  5893 sgd_solver.cpp:137] Iteration 114600, lr = 0.0028375, m = 0.9
I0629 02:25:47.778383  5893 solver.cpp:349] Iteration 114700 (5.41 iter/s, 18.4843s/100 iter), loss = 1.42443
I0629 02:25:47.778408  5893 solver.cpp:371]     Train net output #0: loss = 1.50889 (* 1 = 1.50889 loss)
I0629 02:25:47.778411  5893 sgd_solver.cpp:137] Iteration 114700, lr = 0.00283125, m = 0.9
I0629 02:26:06.308554  5893 solver.cpp:349] Iteration 114800 (5.39679 iter/s, 18.5295s/100 iter), loss = 1.32168
I0629 02:26:06.308665  5893 solver.cpp:371]     Train net output #0: loss = 1.39227 (* 1 = 1.39227 loss)
I0629 02:26:06.308672  5893 sgd_solver.cpp:137] Iteration 114800, lr = 0.002825, m = 0.9
I0629 02:26:24.765753  5893 solver.cpp:349] Iteration 114900 (5.41816 iter/s, 18.4565s/100 iter), loss = 1.51905
I0629 02:26:24.765776  5893 solver.cpp:371]     Train net output #0: loss = 1.46982 (* 1 = 1.46982 loss)
I0629 02:26:24.765780  5893 sgd_solver.cpp:137] Iteration 114900, lr = 0.00281875, m = 0.9
I0629 02:26:43.043781  5893 solver.cpp:401] Sparsity after update:
I0629 02:26:43.049031  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:26:43.049039  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:26:43.049046  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:26:43.049047  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:26:43.049049  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:26:43.049052  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:26:43.049053  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:26:43.049055  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:26:43.049057  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:26:43.049059  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:26:43.049060  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:26:43.049062  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:26:43.049064  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:26:43.049072  5893 solver.cpp:545] Iteration 115000, Testing net (#0)
I0629 02:27:07.314445  5888 data_reader.cpp:262] Starting prefetch of epoch 115
I0629 02:27:07.376827  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56784
I0629 02:27:07.376852  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.797721
I0629 02:27:07.376857  5893 solver.cpp:630]     Test net output #2: loss = 1.89651 (* 1 = 1.89651 loss)
I0629 02:27:07.376876  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.327s
I0629 02:27:07.562404  5893 solver.cpp:349] Iteration 115000 (2.33671 iter/s, 42.7952s/100 iter), loss = 1.58563
I0629 02:27:07.562422  5893 solver.cpp:371]     Train net output #0: loss = 1.55977 (* 1 = 1.55977 loss)
I0629 02:27:07.562427  5893 sgd_solver.cpp:137] Iteration 115000, lr = 0.0028125, m = 0.9
I0629 02:27:25.999300  5893 solver.cpp:349] Iteration 115100 (5.42409 iter/s, 18.4363s/100 iter), loss = 1.47727
I0629 02:27:25.999399  5893 solver.cpp:371]     Train net output #0: loss = 1.49381 (* 1 = 1.49381 loss)
I0629 02:27:25.999406  5893 sgd_solver.cpp:137] Iteration 115100, lr = 0.00280625, m = 0.9
I0629 02:27:26.519918  5875 data_reader.cpp:262] Starting prefetch of epoch 23
I0629 02:27:44.443358  5893 solver.cpp:349] Iteration 115200 (5.42201 iter/s, 18.4433s/100 iter), loss = 1.33054
I0629 02:27:44.443382  5893 solver.cpp:371]     Train net output #0: loss = 1.3177 (* 1 = 1.3177 loss)
I0629 02:27:44.443387  5893 sgd_solver.cpp:137] Iteration 115200, lr = 0.0028, m = 0.9
I0629 02:28:02.882412  5893 solver.cpp:349] Iteration 115300 (5.42346 iter/s, 18.4384s/100 iter), loss = 1.46821
I0629 02:28:02.882495  5893 solver.cpp:371]     Train net output #0: loss = 1.1662 (* 1 = 1.1662 loss)
I0629 02:28:02.882500  5893 sgd_solver.cpp:137] Iteration 115300, lr = 0.00279375, m = 0.9
I0629 02:28:21.308715  5893 solver.cpp:349] Iteration 115400 (5.42723 iter/s, 18.4256s/100 iter), loss = 1.70831
I0629 02:28:21.308739  5893 solver.cpp:371]     Train net output #0: loss = 2.16994 (* 1 = 2.16994 loss)
I0629 02:28:21.308743  5893 sgd_solver.cpp:137] Iteration 115400, lr = 0.0027875, m = 0.9
I0629 02:28:39.763690  5893 solver.cpp:349] Iteration 115500 (5.41878 iter/s, 18.4543s/100 iter), loss = 1.76358
I0629 02:28:39.763808  5893 solver.cpp:371]     Train net output #0: loss = 2.21585 (* 1 = 2.21585 loss)
I0629 02:28:39.763815  5893 sgd_solver.cpp:137] Iteration 115500, lr = 0.00278125, m = 0.9
I0629 02:28:58.220041  5893 solver.cpp:349] Iteration 115600 (5.41841 iter/s, 18.4556s/100 iter), loss = 1.82501
I0629 02:28:58.220064  5893 solver.cpp:371]     Train net output #0: loss = 1.87248 (* 1 = 1.87248 loss)
I0629 02:28:58.220068  5893 sgd_solver.cpp:137] Iteration 115600, lr = 0.002775, m = 0.9
I0629 02:29:16.694361  5893 solver.cpp:349] Iteration 115700 (5.41311 iter/s, 18.4737s/100 iter), loss = 1.62805
I0629 02:29:16.694412  5893 solver.cpp:371]     Train net output #0: loss = 1.26918 (* 1 = 1.26918 loss)
I0629 02:29:16.694419  5893 sgd_solver.cpp:137] Iteration 115700, lr = 0.00276875, m = 0.9
I0629 02:29:35.204749  5893 solver.cpp:349] Iteration 115800 (5.40257 iter/s, 18.5097s/100 iter), loss = 1.59386
I0629 02:29:35.204772  5893 solver.cpp:371]     Train net output #0: loss = 2.02629 (* 1 = 2.02629 loss)
I0629 02:29:35.204777  5893 sgd_solver.cpp:137] Iteration 115800, lr = 0.0027625, m = 0.9
I0629 02:29:53.679504  5893 solver.cpp:349] Iteration 115900 (5.41298 iter/s, 18.4741s/100 iter), loss = 1.53436
I0629 02:29:53.679603  5893 solver.cpp:371]     Train net output #0: loss = 1.7181 (* 1 = 1.7181 loss)
I0629 02:29:53.679610  5893 sgd_solver.cpp:137] Iteration 115900, lr = 0.00275625, m = 0.9
I0629 02:30:12.007562  5893 solver.cpp:401] Sparsity after update:
I0629 02:30:12.012517  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:30:12.012526  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:30:12.012532  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:30:12.012534  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:30:12.012537  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:30:12.012540  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:30:12.012542  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:30:12.012544  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:30:12.012547  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:30:12.012548  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:30:12.012550  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:30:12.012552  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:30:12.012555  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:30:12.012562  5893 solver.cpp:545] Iteration 116000, Testing net (#0)
I0629 02:30:14.634968  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 02:30:36.326457  5888 data_reader.cpp:262] Starting prefetch of epoch 116
I0629 02:30:36.388645  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56804
I0629 02:30:36.388669  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79632
I0629 02:30:36.388674  5893 solver.cpp:630]     Test net output #2: loss = 1.89509 (* 1 = 1.89509 loss)
I0629 02:30:36.388691  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3753s
I0629 02:30:36.573709  5893 solver.cpp:349] Iteration 116000 (2.3314 iter/s, 42.8927s/100 iter), loss = 1.31725
I0629 02:30:36.573734  5893 solver.cpp:371]     Train net output #0: loss = 1.22326 (* 1 = 1.22326 loss)
I0629 02:30:36.573738  5893 sgd_solver.cpp:137] Iteration 116000, lr = 0.00275, m = 0.9
I0629 02:30:55.007112  5893 solver.cpp:349] Iteration 116100 (5.42513 iter/s, 18.4327s/100 iter), loss = 1.74048
I0629 02:30:55.007133  5893 solver.cpp:371]     Train net output #0: loss = 1.94991 (* 1 = 1.94991 loss)
I0629 02:30:55.007138  5893 sgd_solver.cpp:137] Iteration 116100, lr = 0.00274375, m = 0.9
I0629 02:31:13.465823  5893 solver.cpp:349] Iteration 116200 (5.41769 iter/s, 18.4581s/100 iter), loss = 1.9553
I0629 02:31:13.465920  5893 solver.cpp:371]     Train net output #0: loss = 2.00292 (* 1 = 2.00292 loss)
I0629 02:31:13.465927  5893 sgd_solver.cpp:137] Iteration 116200, lr = 0.0027375, m = 0.9
I0629 02:31:31.909502  5893 solver.cpp:349] Iteration 116300 (5.42213 iter/s, 18.4429s/100 iter), loss = 1.44207
I0629 02:31:31.909523  5893 solver.cpp:371]     Train net output #0: loss = 1.33718 (* 1 = 1.33718 loss)
I0629 02:31:31.909526  5893 sgd_solver.cpp:137] Iteration 116300, lr = 0.00273125, m = 0.9
I0629 02:31:50.357421  5893 solver.cpp:349] Iteration 116400 (5.42086 iter/s, 18.4473s/100 iter), loss = 1.46543
I0629 02:31:50.357514  5893 solver.cpp:371]     Train net output #0: loss = 1.35853 (* 1 = 1.35853 loss)
I0629 02:31:50.357519  5893 sgd_solver.cpp:137] Iteration 116400, lr = 0.002725, m = 0.9
I0629 02:32:08.788835  5893 solver.cpp:349] Iteration 116500 (5.42574 iter/s, 18.4307s/100 iter), loss = 1.47379
I0629 02:32:08.788858  5893 solver.cpp:371]     Train net output #0: loss = 1.22103 (* 1 = 1.22103 loss)
I0629 02:32:08.788863  5893 sgd_solver.cpp:137] Iteration 116500, lr = 0.00271875, m = 0.9
I0629 02:32:27.241752  5893 solver.cpp:349] Iteration 116600 (5.41939 iter/s, 18.4523s/100 iter), loss = 1.6648
I0629 02:32:27.241825  5893 solver.cpp:371]     Train net output #0: loss = 1.54599 (* 1 = 1.54599 loss)
I0629 02:32:27.241830  5893 sgd_solver.cpp:137] Iteration 116600, lr = 0.0027125, m = 0.9
I0629 02:32:45.721562  5893 solver.cpp:349] Iteration 116700 (5.41152 iter/s, 18.4791s/100 iter), loss = 1.58013
I0629 02:32:45.721586  5893 solver.cpp:371]     Train net output #0: loss = 1.57829 (* 1 = 1.57829 loss)
I0629 02:32:45.721592  5893 sgd_solver.cpp:137] Iteration 116700, lr = 0.00270625, m = 0.9
I0629 02:33:04.219244  5893 solver.cpp:349] Iteration 116800 (5.40628 iter/s, 18.497s/100 iter), loss = 1.45492
I0629 02:33:04.219343  5893 solver.cpp:371]     Train net output #0: loss = 1.28069 (* 1 = 1.28069 loss)
I0629 02:33:04.219350  5893 sgd_solver.cpp:137] Iteration 116800, lr = 0.0027, m = 0.9
I0629 02:33:22.691360  5893 solver.cpp:349] Iteration 116900 (5.41378 iter/s, 18.4714s/100 iter), loss = 1.61109
I0629 02:33:22.691383  5893 solver.cpp:371]     Train net output #0: loss = 1.3909 (* 1 = 1.3909 loss)
I0629 02:33:22.691387  5893 sgd_solver.cpp:137] Iteration 116900, lr = 0.00269375, m = 0.9
I0629 02:33:40.980669  5893 solver.cpp:401] Sparsity after update:
I0629 02:33:40.985893  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:33:40.985903  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:33:40.985908  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:33:40.985909  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:33:40.985913  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:33:40.985914  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:33:40.985915  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:33:40.985918  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:33:40.985919  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:33:40.985921  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:33:40.985924  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:33:40.985925  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:33:40.985927  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:33:40.985934  5893 solver.cpp:545] Iteration 117000, Testing net (#0)
I0629 02:34:05.239600  5888 data_reader.cpp:262] Starting prefetch of epoch 117
I0629 02:34:05.302167  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56872
I0629 02:34:05.302191  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79576
I0629 02:34:05.302196  5893 solver.cpp:630]     Test net output #2: loss = 1.90305 (* 1 = 1.90305 loss)
I0629 02:34:05.302215  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3154s
I0629 02:34:05.502159  5893 solver.cpp:349] Iteration 117000 (2.33594 iter/s, 42.8093s/100 iter), loss = 1.61733
I0629 02:34:05.502184  5893 solver.cpp:371]     Train net output #0: loss = 1.56762 (* 1 = 1.56762 loss)
I0629 02:34:05.502190  5893 sgd_solver.cpp:137] Iteration 117000, lr = 0.0026875, m = 0.9
I0629 02:34:23.954813  5893 solver.cpp:349] Iteration 117100 (5.41947 iter/s, 18.452s/100 iter), loss = 1.70018
I0629 02:34:23.954908  5893 solver.cpp:371]     Train net output #0: loss = 1.60015 (* 1 = 1.60015 loss)
I0629 02:34:23.954913  5893 sgd_solver.cpp:137] Iteration 117100, lr = 0.00268125, m = 0.9
I0629 02:34:42.376260  5893 solver.cpp:349] Iteration 117200 (5.42867 iter/s, 18.4207s/100 iter), loss = 1.49929
I0629 02:34:42.376284  5893 solver.cpp:371]     Train net output #0: loss = 1.82809 (* 1 = 1.82809 loss)
I0629 02:34:42.376288  5893 sgd_solver.cpp:137] Iteration 117200, lr = 0.002675, m = 0.9
I0629 02:35:00.795786  5893 solver.cpp:349] Iteration 117300 (5.42922 iter/s, 18.4189s/100 iter), loss = 1.66439
I0629 02:35:00.795892  5893 solver.cpp:371]     Train net output #0: loss = 1.60541 (* 1 = 1.60541 loss)
I0629 02:35:00.795897  5893 sgd_solver.cpp:137] Iteration 117300, lr = 0.00266875, m = 0.9
I0629 02:35:19.216908  5893 solver.cpp:349] Iteration 117400 (5.42877 iter/s, 18.4204s/100 iter), loss = 1.72552
I0629 02:35:19.216931  5893 solver.cpp:371]     Train net output #0: loss = 1.89427 (* 1 = 1.89427 loss)
I0629 02:35:19.216935  5893 sgd_solver.cpp:137] Iteration 117400, lr = 0.0026625, m = 0.9
I0629 02:35:37.656572  5893 solver.cpp:349] Iteration 117500 (5.42329 iter/s, 18.439s/100 iter), loss = 1.54241
I0629 02:35:37.656679  5893 solver.cpp:371]     Train net output #0: loss = 1.3965 (* 1 = 1.3965 loss)
I0629 02:35:37.656687  5893 sgd_solver.cpp:137] Iteration 117500, lr = 0.00265625, m = 0.9
I0629 02:35:56.086946  5893 solver.cpp:349] Iteration 117600 (5.42605 iter/s, 18.4296s/100 iter), loss = 1.71003
I0629 02:35:56.086967  5893 solver.cpp:371]     Train net output #0: loss = 1.62117 (* 1 = 1.62117 loss)
I0629 02:35:56.086971  5893 sgd_solver.cpp:137] Iteration 117600, lr = 0.00265, m = 0.9
I0629 02:36:14.621212  5893 solver.cpp:349] Iteration 117700 (5.39561 iter/s, 18.5336s/100 iter), loss = 1.79416
I0629 02:36:14.621304  5893 solver.cpp:371]     Train net output #0: loss = 1.96427 (* 1 = 1.96427 loss)
I0629 02:36:14.621310  5893 sgd_solver.cpp:137] Iteration 117700, lr = 0.00264375, m = 0.9
I0629 02:36:33.133424  5893 solver.cpp:349] Iteration 117800 (5.40206 iter/s, 18.5115s/100 iter), loss = 1.65159
I0629 02:36:33.133443  5893 solver.cpp:371]     Train net output #0: loss = 1.74179 (* 1 = 1.74179 loss)
I0629 02:36:33.133446  5893 sgd_solver.cpp:137] Iteration 117800, lr = 0.0026375, m = 0.9
I0629 02:36:51.633558  5893 solver.cpp:349] Iteration 117900 (5.40556 iter/s, 18.4995s/100 iter), loss = 1.48234
I0629 02:36:51.633664  5893 solver.cpp:371]     Train net output #0: loss = 1.75569 (* 1 = 1.75569 loss)
I0629 02:36:51.633671  5893 sgd_solver.cpp:137] Iteration 117900, lr = 0.00263125, m = 0.9
I0629 02:37:09.951766  5893 solver.cpp:401] Sparsity after update:
I0629 02:37:09.956383  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:37:09.956390  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:37:09.956396  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:37:09.956398  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:37:09.956400  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:37:09.956403  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:37:09.956404  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:37:09.956406  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:37:09.956408  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:37:09.956410  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:37:09.956413  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:37:09.956414  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:37:09.956416  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:37:09.956423  5893 solver.cpp:545] Iteration 118000, Testing net (#0)
I0629 02:37:34.185322  5888 data_reader.cpp:262] Starting prefetch of epoch 118
I0629 02:37:34.383857  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56656
I0629 02:37:34.383873  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79824
I0629 02:37:34.383878  5893 solver.cpp:630]     Test net output #2: loss = 1.89619 (* 1 = 1.89619 loss)
I0629 02:37:34.383895  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4267s
I0629 02:37:34.568950  5893 solver.cpp:349] Iteration 118000 (2.32917 iter/s, 42.9338s/100 iter), loss = 1.70469
I0629 02:37:34.568974  5893 solver.cpp:371]     Train net output #0: loss = 1.73904 (* 1 = 1.73904 loss)
I0629 02:37:34.568979  5893 sgd_solver.cpp:137] Iteration 118000, lr = 0.002625, m = 0.9
I0629 02:37:52.989164  5893 solver.cpp:349] Iteration 118100 (5.429 iter/s, 18.4196s/100 iter), loss = 1.60811
I0629 02:37:52.989186  5893 solver.cpp:371]     Train net output #0: loss = 1.98549 (* 1 = 1.98549 loss)
I0629 02:37:52.989189  5893 sgd_solver.cpp:137] Iteration 118100, lr = 0.00261875, m = 0.9
I0629 02:38:11.411134  5893 solver.cpp:349] Iteration 118200 (5.42848 iter/s, 18.4214s/100 iter), loss = 1.44814
I0629 02:38:11.411232  5893 solver.cpp:371]     Train net output #0: loss = 1.32581 (* 1 = 1.32581 loss)
I0629 02:38:11.411237  5893 sgd_solver.cpp:137] Iteration 118200, lr = 0.0026125, m = 0.9
I0629 02:38:29.846896  5893 solver.cpp:349] Iteration 118300 (5.42445 iter/s, 18.4351s/100 iter), loss = 1.63572
I0629 02:38:29.846920  5893 solver.cpp:371]     Train net output #0: loss = 1.76774 (* 1 = 1.76774 loss)
I0629 02:38:29.846923  5893 sgd_solver.cpp:137] Iteration 118300, lr = 0.00260625, m = 0.9
I0629 02:38:48.329027  5893 solver.cpp:349] Iteration 118400 (5.41081 iter/s, 18.4815s/100 iter), loss = 1.56723
I0629 02:38:48.329128  5893 solver.cpp:371]     Train net output #0: loss = 1.59246 (* 1 = 1.59246 loss)
I0629 02:38:48.329133  5893 sgd_solver.cpp:137] Iteration 118400, lr = 0.0026, m = 0.9
I0629 02:39:06.770056  5893 solver.cpp:349] Iteration 118500 (5.4229 iter/s, 18.4403s/100 iter), loss = 1.42565
I0629 02:39:06.770079  5893 solver.cpp:371]     Train net output #0: loss = 1.73444 (* 1 = 1.73444 loss)
I0629 02:39:06.770086  5893 sgd_solver.cpp:137] Iteration 118500, lr = 0.00259375, m = 0.9
I0629 02:39:25.237237  5893 solver.cpp:349] Iteration 118600 (5.4152 iter/s, 18.4666s/100 iter), loss = 1.39606
I0629 02:39:25.237320  5893 solver.cpp:371]     Train net output #0: loss = 1.60072 (* 1 = 1.60072 loss)
I0629 02:39:25.237325  5893 sgd_solver.cpp:137] Iteration 118600, lr = 0.0025875, m = 0.9
I0629 02:39:43.782048  5893 solver.cpp:349] Iteration 118700 (5.39254 iter/s, 18.5441s/100 iter), loss = 1.34673
I0629 02:39:43.782071  5893 solver.cpp:371]     Train net output #0: loss = 1.19641 (* 1 = 1.19641 loss)
I0629 02:39:43.782075  5893 sgd_solver.cpp:137] Iteration 118700, lr = 0.00258125, m = 0.9
I0629 02:40:02.282702  5893 solver.cpp:349] Iteration 118800 (5.4054 iter/s, 18.5s/100 iter), loss = 1.4975
I0629 02:40:02.282805  5893 solver.cpp:371]     Train net output #0: loss = 1.54717 (* 1 = 1.54717 loss)
I0629 02:40:02.282812  5893 sgd_solver.cpp:137] Iteration 118800, lr = 0.002575, m = 0.9
I0629 02:40:20.758316  5893 solver.cpp:349] Iteration 118900 (5.41275 iter/s, 18.4749s/100 iter), loss = 1.75165
I0629 02:40:20.758339  5893 solver.cpp:371]     Train net output #0: loss = 1.93582 (* 1 = 1.93582 loss)
I0629 02:40:20.758343  5893 sgd_solver.cpp:137] Iteration 118900, lr = 0.00256875, m = 0.9
I0629 02:40:39.077718  5893 solver.cpp:401] Sparsity after update:
I0629 02:40:39.082898  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:40:39.082907  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:40:39.082914  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:40:39.082916  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:40:39.082919  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:40:39.082923  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:40:39.082928  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:40:39.082932  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:40:39.082942  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:40:39.082944  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:40:39.082947  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:40:39.082949  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:40:39.082952  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:40:39.082959  5893 solver.cpp:545] Iteration 119000, Testing net (#0)
I0629 02:41:03.694437  5888 data_reader.cpp:262] Starting prefetch of epoch 119
I0629 02:41:03.771324  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56772
I0629 02:41:03.771347  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79612
I0629 02:41:03.771351  5893 solver.cpp:630]     Test net output #2: loss = 1.89365 (* 1 = 1.89365 loss)
I0629 02:41:03.771368  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6876s
I0629 02:41:03.958734  5893 solver.cpp:349] Iteration 119000 (2.31487 iter/s, 43.199s/100 iter), loss = 1.6495
I0629 02:41:03.958756  5893 solver.cpp:371]     Train net output #0: loss = 1.67956 (* 1 = 1.67956 loss)
I0629 02:41:03.958760  5893 sgd_solver.cpp:137] Iteration 119000, lr = 0.0025625, m = 0.9
I0629 02:41:22.411168  5893 solver.cpp:349] Iteration 119100 (5.41952 iter/s, 18.4518s/100 iter), loss = 1.61461
I0629 02:41:22.411222  5893 solver.cpp:371]     Train net output #0: loss = 1.46523 (* 1 = 1.46523 loss)
I0629 02:41:22.411228  5893 sgd_solver.cpp:137] Iteration 119100, lr = 0.00255625, m = 0.9
I0629 02:41:40.851075  5893 solver.cpp:349] Iteration 119200 (5.42322 iter/s, 18.4392s/100 iter), loss = 1.46776
I0629 02:41:40.851099  5893 solver.cpp:371]     Train net output #0: loss = 1.46377 (* 1 = 1.46377 loss)
I0629 02:41:40.851105  5893 sgd_solver.cpp:137] Iteration 119200, lr = 0.00255, m = 0.9
I0629 02:41:59.290868  5893 solver.cpp:349] Iteration 119300 (5.42324 iter/s, 18.4392s/100 iter), loss = 1.91375
I0629 02:41:59.290971  5893 solver.cpp:371]     Train net output #0: loss = 1.9047 (* 1 = 1.9047 loss)
I0629 02:41:59.290978  5893 sgd_solver.cpp:137] Iteration 119300, lr = 0.00254375, m = 0.9
I0629 02:42:17.744029  5893 solver.cpp:349] Iteration 119400 (5.41934 iter/s, 18.4524s/100 iter), loss = 1.83431
I0629 02:42:17.744053  5893 solver.cpp:371]     Train net output #0: loss = 1.54919 (* 1 = 1.54919 loss)
I0629 02:42:17.744057  5893 sgd_solver.cpp:137] Iteration 119400, lr = 0.0025375, m = 0.9
I0629 02:42:36.186599  5893 solver.cpp:349] Iteration 119500 (5.42243 iter/s, 18.4419s/100 iter), loss = 1.96479
I0629 02:42:36.186703  5893 solver.cpp:371]     Train net output #0: loss = 1.98885 (* 1 = 1.98885 loss)
I0629 02:42:36.186709  5893 sgd_solver.cpp:137] Iteration 119500, lr = 0.00253125, m = 0.9
I0629 02:42:54.616174  5893 solver.cpp:349] Iteration 119600 (5.42627 iter/s, 18.4289s/100 iter), loss = 1.50015
I0629 02:42:54.616197  5893 solver.cpp:371]     Train net output #0: loss = 1.83443 (* 1 = 1.83443 loss)
I0629 02:42:54.616201  5893 sgd_solver.cpp:137] Iteration 119600, lr = 0.002525, m = 0.9
I0629 02:43:13.101881  5893 solver.cpp:349] Iteration 119700 (5.40977 iter/s, 18.4851s/100 iter), loss = 1.65457
I0629 02:43:13.101982  5893 solver.cpp:371]     Train net output #0: loss = 1.35824 (* 1 = 1.35824 loss)
I0629 02:43:13.101989  5893 sgd_solver.cpp:137] Iteration 119700, lr = 0.00251875, m = 0.9
I0629 02:43:31.641083  5893 solver.cpp:349] Iteration 119800 (5.39419 iter/s, 18.5385s/100 iter), loss = 1.55685
I0629 02:43:31.641105  5893 solver.cpp:371]     Train net output #0: loss = 1.72893 (* 1 = 1.72893 loss)
I0629 02:43:31.641109  5893 sgd_solver.cpp:137] Iteration 119800, lr = 0.0025125, m = 0.9
I0629 02:43:50.116267  5893 solver.cpp:349] Iteration 119900 (5.41285 iter/s, 18.4745s/100 iter), loss = 1.37976
I0629 02:43:50.116338  5893 solver.cpp:371]     Train net output #0: loss = 1.46326 (* 1 = 1.46326 loss)
I0629 02:43:50.116341  5893 sgd_solver.cpp:137] Iteration 119900, lr = 0.00250625, m = 0.9
I0629 02:44:08.412461  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_120000.caffemodel
I0629 02:44:08.423342  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_120000.solverstate
I0629 02:44:08.427726  5893 solver.cpp:401] Sparsity after update:
I0629 02:44:08.428560  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:44:08.428567  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:44:08.428575  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:44:08.428576  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:44:08.428578  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:44:08.428580  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:44:08.428582  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:44:08.428584  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:44:08.428586  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:44:08.428587  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:44:08.428589  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:44:08.428591  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:44:08.428593  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:44:08.428601  5893 solver.cpp:545] Iteration 120000, Testing net (#0)
I0629 02:44:32.869141  5888 data_reader.cpp:262] Starting prefetch of epoch 120
I0629 02:44:32.931089  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56884
I0629 02:44:32.931110  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79784
I0629 02:44:32.931115  5893 solver.cpp:630]     Test net output #2: loss = 1.88949 (* 1 = 1.88949 loss)
I0629 02:44:32.931133  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5017s
I0629 02:44:33.115957  5893 solver.cpp:349] Iteration 120000 (2.32568 iter/s, 42.9982s/100 iter), loss = 1.54636
I0629 02:44:33.115979  5893 solver.cpp:371]     Train net output #0: loss = 1.61631 (* 1 = 1.61631 loss)
I0629 02:44:33.115983  5893 sgd_solver.cpp:137] Iteration 120000, lr = 0.0025, m = 0.9
I0629 02:44:51.604307  5893 solver.cpp:349] Iteration 120100 (5.409 iter/s, 18.4877s/100 iter), loss = 1.45413
I0629 02:44:51.604329  5893 solver.cpp:371]     Train net output #0: loss = 1.51825 (* 1 = 1.51825 loss)
I0629 02:44:51.604333  5893 sgd_solver.cpp:137] Iteration 120100, lr = 0.00249375, m = 0.9
I0629 02:44:52.960289  5875 data_reader.cpp:262] Starting prefetch of epoch 24
I0629 02:45:10.035537  5893 solver.cpp:349] Iteration 120200 (5.42576 iter/s, 18.4306s/100 iter), loss = 1.80793
I0629 02:45:10.035606  5893 solver.cpp:371]     Train net output #0: loss = 2.31217 (* 1 = 2.31217 loss)
I0629 02:45:10.035611  5893 sgd_solver.cpp:137] Iteration 120200, lr = 0.0024875, m = 0.9
I0629 02:45:28.501946  5893 solver.cpp:349] Iteration 120300 (5.41544 iter/s, 18.4657s/100 iter), loss = 1.54147
I0629 02:45:28.501971  5893 solver.cpp:371]     Train net output #0: loss = 1.55143 (* 1 = 1.55143 loss)
I0629 02:45:28.501974  5893 sgd_solver.cpp:137] Iteration 120300, lr = 0.00248125, m = 0.9
I0629 02:45:46.929133  5893 solver.cpp:349] Iteration 120400 (5.42696 iter/s, 18.4265s/100 iter), loss = 1.59552
I0629 02:45:46.929167  5893 solver.cpp:371]     Train net output #0: loss = 1.76528 (* 1 = 1.76528 loss)
I0629 02:45:46.929170  5893 sgd_solver.cpp:137] Iteration 120400, lr = 0.002475, m = 0.9
I0629 02:46:05.351052  5893 solver.cpp:349] Iteration 120500 (5.42851 iter/s, 18.4213s/100 iter), loss = 1.66084
I0629 02:46:05.351078  5893 solver.cpp:371]     Train net output #0: loss = 1.84051 (* 1 = 1.84051 loss)
I0629 02:46:05.351083  5893 sgd_solver.cpp:137] Iteration 120500, lr = 0.00246875, m = 0.9
I0629 02:46:23.913022  5893 solver.cpp:349] Iteration 120600 (5.38755 iter/s, 18.5613s/100 iter), loss = 1.69672
I0629 02:46:23.913125  5893 solver.cpp:371]     Train net output #0: loss = 1.49669 (* 1 = 1.49669 loss)
I0629 02:46:23.913133  5893 sgd_solver.cpp:137] Iteration 120600, lr = 0.0024625, m = 0.9
I0629 02:46:42.435336  5893 solver.cpp:349] Iteration 120700 (5.39911 iter/s, 18.5216s/100 iter), loss = 1.58466
I0629 02:46:42.435364  5893 solver.cpp:371]     Train net output #0: loss = 1.54298 (* 1 = 1.54298 loss)
I0629 02:46:42.435369  5893 sgd_solver.cpp:137] Iteration 120700, lr = 0.00245625, m = 0.9
I0629 02:47:00.913671  5893 solver.cpp:349] Iteration 120800 (5.41194 iter/s, 18.4777s/100 iter), loss = 1.6318
I0629 02:47:00.913789  5893 solver.cpp:371]     Train net output #0: loss = 1.71497 (* 1 = 1.71497 loss)
I0629 02:47:00.913797  5893 sgd_solver.cpp:137] Iteration 120800, lr = 0.00245, m = 0.9
I0629 02:47:19.382472  5893 solver.cpp:349] Iteration 120900 (5.41476 iter/s, 18.468s/100 iter), loss = 1.79754
I0629 02:47:19.382496  5893 solver.cpp:371]     Train net output #0: loss = 1.77005 (* 1 = 1.77005 loss)
I0629 02:47:19.382503  5893 sgd_solver.cpp:137] Iteration 120900, lr = 0.00244375, m = 0.9
I0629 02:47:37.692894  5893 solver.cpp:401] Sparsity after update:
I0629 02:47:37.698114  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:47:37.698124  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:47:37.698133  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:47:37.698137  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:47:37.698139  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:47:37.698143  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:47:37.698146  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:47:37.698149  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:47:37.698153  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:47:37.698155  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:47:37.698158  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:47:37.698161  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:47:37.698165  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:47:37.698175  5893 solver.cpp:545] Iteration 121000, Testing net (#0)
I0629 02:47:40.444792  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 02:48:01.988219  5888 data_reader.cpp:262] Starting prefetch of epoch 121
I0629 02:48:02.051407  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.569
I0629 02:48:02.051441  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79788
I0629 02:48:02.051448  5893 solver.cpp:630]     Test net output #2: loss = 1.8917 (* 1 = 1.8917 loss)
I0629 02:48:02.051472  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3525s
I0629 02:48:02.236039  5893 solver.cpp:349] Iteration 121000 (2.33361 iter/s, 42.8521s/100 iter), loss = 1.67539
I0629 02:48:02.236063  5893 solver.cpp:371]     Train net output #0: loss = 1.65982 (* 1 = 1.65982 loss)
I0629 02:48:02.236066  5893 sgd_solver.cpp:137] Iteration 121000, lr = 0.0024375, m = 0.9
I0629 02:48:20.648978  5893 solver.cpp:349] Iteration 121100 (5.43116 iter/s, 18.4123s/100 iter), loss = 1.5966
I0629 02:48:20.649046  5893 solver.cpp:371]     Train net output #0: loss = 1.68594 (* 1 = 1.68594 loss)
I0629 02:48:20.649051  5893 sgd_solver.cpp:137] Iteration 121100, lr = 0.00243125, m = 0.9
I0629 02:48:39.082479  5893 solver.cpp:349] Iteration 121200 (5.42511 iter/s, 18.4328s/100 iter), loss = 1.45963
I0629 02:48:39.082515  5893 solver.cpp:371]     Train net output #0: loss = 1.39715 (* 1 = 1.39715 loss)
I0629 02:48:39.082520  5893 sgd_solver.cpp:137] Iteration 121200, lr = 0.002425, m = 0.9
I0629 02:48:57.543409  5893 solver.cpp:349] Iteration 121300 (5.41704 iter/s, 18.4603s/100 iter), loss = 1.87368
I0629 02:48:57.543480  5893 solver.cpp:371]     Train net output #0: loss = 2.20355 (* 1 = 2.20355 loss)
I0629 02:48:57.543485  5893 sgd_solver.cpp:137] Iteration 121300, lr = 0.00241875, m = 0.9
I0629 02:49:15.984371  5893 solver.cpp:349] Iteration 121400 (5.42292 iter/s, 18.4403s/100 iter), loss = 1.30276
I0629 02:49:15.984395  5893 solver.cpp:371]     Train net output #0: loss = 0.922718 (* 1 = 0.922718 loss)
I0629 02:49:15.984398  5893 sgd_solver.cpp:137] Iteration 121400, lr = 0.0024125, m = 0.9
I0629 02:49:34.434154  5893 solver.cpp:349] Iteration 121500 (5.42031 iter/s, 18.4491s/100 iter), loss = 1.24916
I0629 02:49:34.434206  5893 solver.cpp:371]     Train net output #0: loss = 1.53342 (* 1 = 1.53342 loss)
I0629 02:49:34.434211  5893 sgd_solver.cpp:137] Iteration 121500, lr = 0.00240625, m = 0.9
I0629 02:49:52.885320  5893 solver.cpp:349] Iteration 121600 (5.41992 iter/s, 18.4505s/100 iter), loss = 1.4095
I0629 02:49:52.885344  5893 solver.cpp:371]     Train net output #0: loss = 1.49791 (* 1 = 1.49791 loss)
I0629 02:49:52.885350  5893 sgd_solver.cpp:137] Iteration 121600, lr = 0.0024, m = 0.9
I0629 02:50:11.384091  5893 solver.cpp:349] Iteration 121700 (5.40596 iter/s, 18.4981s/100 iter), loss = 1.67677
I0629 02:50:11.384192  5893 solver.cpp:371]     Train net output #0: loss = 2.00421 (* 1 = 2.00421 loss)
I0629 02:50:11.384199  5893 sgd_solver.cpp:137] Iteration 121700, lr = 0.00239375, m = 0.9
I0629 02:50:29.965054  5893 solver.cpp:349] Iteration 121800 (5.38207 iter/s, 18.5802s/100 iter), loss = 1.70793
I0629 02:50:29.965075  5893 solver.cpp:371]     Train net output #0: loss = 1.83657 (* 1 = 1.83657 loss)
I0629 02:50:29.965080  5893 sgd_solver.cpp:137] Iteration 121800, lr = 0.0023875, m = 0.9
I0629 02:50:48.474082  5893 solver.cpp:349] Iteration 121900 (5.40296 iter/s, 18.5084s/100 iter), loss = 1.75503
I0629 02:50:48.474185  5893 solver.cpp:371]     Train net output #0: loss = 1.51496 (* 1 = 1.51496 loss)
I0629 02:50:48.474192  5893 sgd_solver.cpp:137] Iteration 121900, lr = 0.00238125, m = 0.9
I0629 02:51:06.753417  5893 solver.cpp:401] Sparsity after update:
I0629 02:51:06.758688  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:51:06.758698  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:51:06.758707  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:51:06.758709  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:51:06.758713  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:51:06.758716  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:51:06.758719  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:51:06.758723  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:51:06.758725  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:51:06.758728  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:51:06.758731  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:51:06.758735  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:51:06.758739  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:51:06.758749  5893 solver.cpp:545] Iteration 122000, Testing net (#0)
I0629 02:51:31.070070  5888 data_reader.cpp:262] Starting prefetch of epoch 122
I0629 02:51:31.196979  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56816
I0629 02:51:31.197001  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79696
I0629 02:51:31.197006  5893 solver.cpp:630]     Test net output #2: loss = 1.89741 (* 1 = 1.89741 loss)
I0629 02:51:31.197022  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4374s
I0629 02:51:31.385025  5893 solver.cpp:349] Iteration 122000 (2.33049 iter/s, 42.9094s/100 iter), loss = 1.47507
I0629 02:51:31.385048  5893 solver.cpp:371]     Train net output #0: loss = 1.47696 (* 1 = 1.47696 loss)
I0629 02:51:31.385052  5893 sgd_solver.cpp:137] Iteration 122000, lr = 0.002375, m = 0.9
I0629 02:51:49.853596  5893 solver.cpp:349] Iteration 122100 (5.4148 iter/s, 18.4679s/100 iter), loss = 1.85695
I0629 02:51:49.853619  5893 solver.cpp:371]     Train net output #0: loss = 1.58998 (* 1 = 1.58998 loss)
I0629 02:51:49.853623  5893 sgd_solver.cpp:137] Iteration 122100, lr = 0.00236875, m = 0.9
I0629 02:52:08.315634  5893 solver.cpp:349] Iteration 122200 (5.41672 iter/s, 18.4614s/100 iter), loss = 1.49336
I0629 02:52:08.315721  5893 solver.cpp:371]     Train net output #0: loss = 1.54931 (* 1 = 1.54931 loss)
I0629 02:52:08.315726  5893 sgd_solver.cpp:137] Iteration 122200, lr = 0.0023625, m = 0.9
I0629 02:52:26.754616  5893 solver.cpp:349] Iteration 122300 (5.42351 iter/s, 18.4382s/100 iter), loss = 1.71233
I0629 02:52:26.754639  5893 solver.cpp:371]     Train net output #0: loss = 1.73802 (* 1 = 1.73802 loss)
I0629 02:52:26.754643  5893 sgd_solver.cpp:137] Iteration 122300, lr = 0.00235625, m = 0.9
I0629 02:52:45.185087  5893 solver.cpp:349] Iteration 122400 (5.426 iter/s, 18.4298s/100 iter), loss = 1.58088
I0629 02:52:45.185178  5893 solver.cpp:371]     Train net output #0: loss = 1.45597 (* 1 = 1.45597 loss)
I0629 02:52:45.185184  5893 sgd_solver.cpp:137] Iteration 122400, lr = 0.00235, m = 0.9
I0629 02:53:03.596701  5893 solver.cpp:349] Iteration 122500 (5.43157 iter/s, 18.4109s/100 iter), loss = 1.43941
I0629 02:53:03.596725  5893 solver.cpp:371]     Train net output #0: loss = 1.3958 (* 1 = 1.3958 loss)
I0629 02:53:03.596730  5893 sgd_solver.cpp:137] Iteration 122500, lr = 0.00234375, m = 0.9
I0629 02:53:22.051304  5893 solver.cpp:349] Iteration 122600 (5.4189 iter/s, 18.4539s/100 iter), loss = 1.65861
I0629 02:53:22.051407  5893 solver.cpp:371]     Train net output #0: loss = 1.44803 (* 1 = 1.44803 loss)
I0629 02:53:22.051414  5893 sgd_solver.cpp:137] Iteration 122600, lr = 0.0023375, m = 0.9
I0629 02:53:40.538866  5893 solver.cpp:349] Iteration 122700 (5.40927 iter/s, 18.4868s/100 iter), loss = 1.17948
I0629 02:53:40.538888  5893 solver.cpp:371]     Train net output #0: loss = 0.837618 (* 1 = 0.837618 loss)
I0629 02:53:40.538892  5893 sgd_solver.cpp:137] Iteration 122700, lr = 0.00233125, m = 0.9
I0629 02:53:59.088419  5893 solver.cpp:349] Iteration 122800 (5.39116 iter/s, 18.5489s/100 iter), loss = 1.64435
I0629 02:53:59.093600  5893 solver.cpp:371]     Train net output #0: loss = 1.73068 (* 1 = 1.73068 loss)
I0629 02:53:59.093611  5893 sgd_solver.cpp:137] Iteration 122800, lr = 0.002325, m = 0.9
I0629 02:54:17.580307  5893 solver.cpp:349] Iteration 122900 (5.40949 iter/s, 18.486s/100 iter), loss = 1.26755
I0629 02:54:17.580329  5893 solver.cpp:371]     Train net output #0: loss = 1.14844 (* 1 = 1.14844 loss)
I0629 02:54:17.580333  5893 sgd_solver.cpp:137] Iteration 122900, lr = 0.00231875, m = 0.9
I0629 02:54:35.873687  5893 solver.cpp:401] Sparsity after update:
I0629 02:54:35.878342  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:54:35.878350  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:54:35.878356  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:54:35.878360  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:54:35.878361  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:54:35.878363  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:54:35.878365  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:54:35.878366  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:54:35.878368  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:54:35.878371  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:54:35.878372  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:54:35.878374  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:54:35.878376  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:54:35.878383  5893 solver.cpp:545] Iteration 123000, Testing net (#0)
I0629 02:55:00.378664  5888 data_reader.cpp:262] Starting prefetch of epoch 123
I0629 02:55:00.446418  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.565799
I0629 02:55:00.446439  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7986
I0629 02:55:00.446442  5893 solver.cpp:630]     Test net output #2: loss = 1.88975 (* 1 = 1.88975 loss)
I0629 02:55:00.446458  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5672s
I0629 02:55:00.635753  5893 solver.cpp:349] Iteration 123000 (2.32267 iter/s, 43.0539s/100 iter), loss = 1.10671
I0629 02:55:00.635776  5893 solver.cpp:371]     Train net output #0: loss = 1.02258 (* 1 = 1.02258 loss)
I0629 02:55:00.635782  5893 sgd_solver.cpp:137] Iteration 123000, lr = 0.0023125, m = 0.9
I0629 02:55:19.049789  5893 solver.cpp:349] Iteration 123100 (5.43084 iter/s, 18.4134s/100 iter), loss = 1.54354
I0629 02:55:19.049873  5893 solver.cpp:371]     Train net output #0: loss = 1.7021 (* 1 = 1.7021 loss)
I0629 02:55:19.049878  5893 sgd_solver.cpp:137] Iteration 123100, lr = 0.00230625, m = 0.9
I0629 02:55:37.466058  5893 solver.cpp:349] Iteration 123200 (5.43018 iter/s, 18.4156s/100 iter), loss = 1.51988
I0629 02:55:37.466084  5893 solver.cpp:371]     Train net output #0: loss = 1.52653 (* 1 = 1.52653 loss)
I0629 02:55:37.466089  5893 sgd_solver.cpp:137] Iteration 123200, lr = 0.0023, m = 0.9
I0629 02:55:55.915575  5893 solver.cpp:349] Iteration 123300 (5.42038 iter/s, 18.4489s/100 iter), loss = 1.44097
I0629 02:55:55.915688  5893 solver.cpp:371]     Train net output #0: loss = 1.62644 (* 1 = 1.62644 loss)
I0629 02:55:55.915695  5893 sgd_solver.cpp:137] Iteration 123300, lr = 0.00229375, m = 0.9
I0629 02:56:14.342841  5893 solver.cpp:349] Iteration 123400 (5.42695 iter/s, 18.4266s/100 iter), loss = 1.41496
I0629 02:56:14.342862  5893 solver.cpp:371]     Train net output #0: loss = 1.27868 (* 1 = 1.27868 loss)
I0629 02:56:14.342867  5893 sgd_solver.cpp:137] Iteration 123400, lr = 0.0022875, m = 0.9
I0629 02:56:32.764478  5893 solver.cpp:349] Iteration 123500 (5.42858 iter/s, 18.421s/100 iter), loss = 1.50517
I0629 02:56:32.764549  5893 solver.cpp:371]     Train net output #0: loss = 1.54024 (* 1 = 1.54024 loss)
I0629 02:56:32.764554  5893 sgd_solver.cpp:137] Iteration 123500, lr = 0.00228125, m = 0.9
I0629 02:56:51.195235  5893 solver.cpp:349] Iteration 123600 (5.42591 iter/s, 18.4301s/100 iter), loss = 1.61814
I0629 02:56:51.195258  5893 solver.cpp:371]     Train net output #0: loss = 1.3779 (* 1 = 1.3779 loss)
I0629 02:56:51.195262  5893 sgd_solver.cpp:137] Iteration 123600, lr = 0.002275, m = 0.9
I0629 02:57:09.682139  5893 solver.cpp:349] Iteration 123700 (5.40942 iter/s, 18.4863s/100 iter), loss = 1.68472
I0629 02:57:09.682243  5893 solver.cpp:371]     Train net output #0: loss = 1.68132 (* 1 = 1.68132 loss)
I0629 02:57:09.682250  5893 sgd_solver.cpp:137] Iteration 123700, lr = 0.00226875, m = 0.9
I0629 02:57:28.244904  5893 solver.cpp:349] Iteration 123800 (5.38734 iter/s, 18.562s/100 iter), loss = 1.83307
I0629 02:57:28.244926  5893 solver.cpp:371]     Train net output #0: loss = 1.95518 (* 1 = 1.95518 loss)
I0629 02:57:28.244930  5893 sgd_solver.cpp:137] Iteration 123800, lr = 0.0022625, m = 0.9
I0629 02:57:46.757108  5893 solver.cpp:349] Iteration 123900 (5.40203 iter/s, 18.5116s/100 iter), loss = 1.95082
I0629 02:57:46.757160  5893 solver.cpp:371]     Train net output #0: loss = 2.011 (* 1 = 2.011 loss)
I0629 02:57:46.757167  5893 sgd_solver.cpp:137] Iteration 123900, lr = 0.00225625, m = 0.9
I0629 02:58:05.047083  5893 solver.cpp:401] Sparsity after update:
I0629 02:58:05.052309  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 02:58:05.052319  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 02:58:05.052325  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 02:58:05.052327  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 02:58:05.052330  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 02:58:05.052337  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 02:58:05.052340  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 02:58:05.052341  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 02:58:05.052343  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 02:58:05.052347  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 02:58:05.052350  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 02:58:05.052351  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 02:58:05.052353  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 02:58:05.052361  5893 solver.cpp:545] Iteration 124000, Testing net (#0)
I0629 02:58:29.348417  5888 data_reader.cpp:262] Starting prefetch of epoch 124
I0629 02:58:29.437930  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.567
I0629 02:58:29.437953  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79672
I0629 02:58:29.437960  5893 solver.cpp:630]     Test net output #2: loss = 1.89016 (* 1 = 1.89016 loss)
I0629 02:58:29.437979  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3848s
I0629 02:58:29.624218  5893 solver.cpp:349] Iteration 124000 (2.33287 iter/s, 42.8657s/100 iter), loss = 1.56619
I0629 02:58:29.624240  5893 solver.cpp:371]     Train net output #0: loss = 1.75855 (* 1 = 1.75855 loss)
I0629 02:58:29.624244  5893 sgd_solver.cpp:137] Iteration 124000, lr = 0.00225, m = 0.9
I0629 02:58:48.076650  5893 solver.cpp:349] Iteration 124100 (5.41952 iter/s, 18.4518s/100 iter), loss = 1.52898
I0629 02:58:48.076673  5893 solver.cpp:371]     Train net output #0: loss = 1.48609 (* 1 = 1.48609 loss)
I0629 02:58:48.076676  5893 sgd_solver.cpp:137] Iteration 124100, lr = 0.00224375, m = 0.9
I0629 02:59:06.526561  5893 solver.cpp:349] Iteration 124200 (5.42026 iter/s, 18.4493s/100 iter), loss = 1.54046
I0629 02:59:06.526672  5893 solver.cpp:371]     Train net output #0: loss = 1.54802 (* 1 = 1.54802 loss)
I0629 02:59:06.526679  5893 sgd_solver.cpp:137] Iteration 124200, lr = 0.0022375, m = 0.9
I0629 02:59:25.019695  5893 solver.cpp:349] Iteration 124300 (5.40762 iter/s, 18.4924s/100 iter), loss = 1.63097
I0629 02:59:25.019718  5893 solver.cpp:371]     Train net output #0: loss = 1.48799 (* 1 = 1.48799 loss)
I0629 02:59:25.019724  5893 sgd_solver.cpp:137] Iteration 124300, lr = 0.00223125, m = 0.9
I0629 02:59:43.468570  5893 solver.cpp:349] Iteration 124400 (5.42057 iter/s, 18.4482s/100 iter), loss = 1.52613
I0629 02:59:43.468648  5893 solver.cpp:371]     Train net output #0: loss = 1.53389 (* 1 = 1.53389 loss)
I0629 02:59:43.468653  5893 sgd_solver.cpp:137] Iteration 124400, lr = 0.002225, m = 0.9
I0629 03:00:01.898519  5893 solver.cpp:349] Iteration 124500 (5.42615 iter/s, 18.4293s/100 iter), loss = 1.49674
I0629 03:00:01.898540  5893 solver.cpp:371]     Train net output #0: loss = 1.50265 (* 1 = 1.50265 loss)
I0629 03:00:01.898545  5893 sgd_solver.cpp:137] Iteration 124500, lr = 0.00221875, m = 0.9
I0629 03:00:20.376436  5893 solver.cpp:349] Iteration 124600 (5.41205 iter/s, 18.4773s/100 iter), loss = 1.56455
I0629 03:00:20.376507  5893 solver.cpp:371]     Train net output #0: loss = 1.36774 (* 1 = 1.36774 loss)
I0629 03:00:20.376513  5893 sgd_solver.cpp:137] Iteration 124600, lr = 0.0022125, m = 0.9
I0629 03:00:38.859176  5893 solver.cpp:349] Iteration 124700 (5.41066 iter/s, 18.482s/100 iter), loss = 1.54693
I0629 03:00:38.859200  5893 solver.cpp:371]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0629 03:00:38.859205  5893 sgd_solver.cpp:137] Iteration 124700, lr = 0.00220625, m = 0.9
I0629 03:00:57.387473  5893 solver.cpp:349] Iteration 124800 (5.39734 iter/s, 18.5277s/100 iter), loss = 1.589
I0629 03:00:57.387557  5893 solver.cpp:371]     Train net output #0: loss = 1.91038 (* 1 = 1.91038 loss)
I0629 03:00:57.387560  5893 sgd_solver.cpp:137] Iteration 124800, lr = 0.0022, m = 0.9
I0629 03:01:15.880376  5893 solver.cpp:349] Iteration 124900 (5.40769 iter/s, 18.4922s/100 iter), loss = 1.3767
I0629 03:01:15.880400  5893 solver.cpp:371]     Train net output #0: loss = 1.24944 (* 1 = 1.24944 loss)
I0629 03:01:15.880405  5893 sgd_solver.cpp:137] Iteration 124900, lr = 0.00219375, m = 0.9
I0629 03:01:34.168196  5893 solver.cpp:401] Sparsity after update:
I0629 03:01:34.173439  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:01:34.173455  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:01:34.173462  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:01:34.173466  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:01:34.173470  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:01:34.173472  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:01:34.173475  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:01:34.173478  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:01:34.173482  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:01:34.173485  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:01:34.173488  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:01:34.173492  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:01:34.173496  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:01:34.173513  5893 solver.cpp:545] Iteration 125000, Testing net (#0)
I0629 03:01:58.597389  5888 data_reader.cpp:262] Starting prefetch of epoch 125
I0629 03:01:58.659369  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57016
I0629 03:01:58.659394  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79808
I0629 03:01:58.659399  5893 solver.cpp:630]     Test net output #2: loss = 1.88836 (* 1 = 1.88836 loss)
I0629 03:01:58.659413  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4851s
I0629 03:01:58.845175  5893 solver.cpp:349] Iteration 125000 (2.32756 iter/s, 42.9634s/100 iter), loss = 1.49009
I0629 03:01:58.845197  5893 solver.cpp:371]     Train net output #0: loss = 1.57854 (* 1 = 1.57854 loss)
I0629 03:01:58.845201  5893 sgd_solver.cpp:137] Iteration 125000, lr = 0.0021875, m = 0.9
I0629 03:02:17.292129  5893 solver.cpp:349] Iteration 125100 (5.42114 iter/s, 18.4463s/100 iter), loss = 1.68393
I0629 03:02:17.292240  5893 solver.cpp:371]     Train net output #0: loss = 1.80335 (* 1 = 1.80335 loss)
I0629 03:02:17.292248  5893 sgd_solver.cpp:137] Iteration 125100, lr = 0.00218125, m = 0.9
I0629 03:02:19.491979  5875 data_reader.cpp:262] Starting prefetch of epoch 25
I0629 03:02:35.713858  5893 solver.cpp:349] Iteration 125200 (5.42859 iter/s, 18.421s/100 iter), loss = 1.66976
I0629 03:02:35.713882  5893 solver.cpp:371]     Train net output #0: loss = 1.57611 (* 1 = 1.57611 loss)
I0629 03:02:35.713886  5893 sgd_solver.cpp:137] Iteration 125200, lr = 0.002175, m = 0.9
I0629 03:02:54.133007  5893 solver.cpp:349] Iteration 125300 (5.42932 iter/s, 18.4185s/100 iter), loss = 1.45499
I0629 03:02:54.133071  5893 solver.cpp:371]     Train net output #0: loss = 1.45713 (* 1 = 1.45713 loss)
I0629 03:02:54.133077  5893 sgd_solver.cpp:137] Iteration 125300, lr = 0.00216875, m = 0.9
I0629 03:03:12.584547  5893 solver.cpp:349] Iteration 125400 (5.41981 iter/s, 18.4508s/100 iter), loss = 1.44255
I0629 03:03:12.584569  5893 solver.cpp:371]     Train net output #0: loss = 1.48465 (* 1 = 1.48465 loss)
I0629 03:03:12.584573  5893 sgd_solver.cpp:137] Iteration 125400, lr = 0.0021625, m = 0.9
I0629 03:03:31.001727  5893 solver.cpp:349] Iteration 125500 (5.4299 iter/s, 18.4165s/100 iter), loss = 1.70281
I0629 03:03:31.001830  5893 solver.cpp:371]     Train net output #0: loss = 1.74403 (* 1 = 1.74403 loss)
I0629 03:03:31.001837  5893 sgd_solver.cpp:137] Iteration 125500, lr = 0.00215625, m = 0.9
I0629 03:03:49.459584  5893 solver.cpp:349] Iteration 125600 (5.41796 iter/s, 18.4571s/100 iter), loss = 1.52467
I0629 03:03:49.459604  5893 solver.cpp:371]     Train net output #0: loss = 1.48587 (* 1 = 1.48587 loss)
I0629 03:03:49.459609  5893 sgd_solver.cpp:137] Iteration 125600, lr = 0.00215, m = 0.9
I0629 03:04:07.889416  5893 solver.cpp:349] Iteration 125700 (5.42618 iter/s, 18.4292s/100 iter), loss = 1.5972
I0629 03:04:07.889530  5893 solver.cpp:371]     Train net output #0: loss = 1.51325 (* 1 = 1.51325 loss)
I0629 03:04:07.889538  5893 sgd_solver.cpp:137] Iteration 125700, lr = 0.00214375, m = 0.9
I0629 03:04:26.369904  5893 solver.cpp:349] Iteration 125800 (5.41133 iter/s, 18.4797s/100 iter), loss = 1.47289
I0629 03:04:26.369927  5893 solver.cpp:371]     Train net output #0: loss = 1.64256 (* 1 = 1.64256 loss)
I0629 03:04:26.369931  5893 sgd_solver.cpp:137] Iteration 125800, lr = 0.0021375, m = 0.9
I0629 03:04:44.888720  5893 solver.cpp:349] Iteration 125900 (5.4001 iter/s, 18.5182s/100 iter), loss = 1.34182
I0629 03:04:44.888828  5893 solver.cpp:371]     Train net output #0: loss = 1.31539 (* 1 = 1.31539 loss)
I0629 03:04:44.888836  5893 sgd_solver.cpp:137] Iteration 125900, lr = 0.00213125, m = 0.9
I0629 03:05:03.179145  5893 solver.cpp:401] Sparsity after update:
I0629 03:05:03.184371  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:05:03.184381  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:05:03.184386  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:05:03.184388  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:05:03.184391  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:05:03.184392  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:05:03.184396  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:05:03.184398  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:05:03.184401  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:05:03.184402  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:05:03.184404  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:05:03.184406  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:05:03.184408  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:05:03.184417  5893 solver.cpp:545] Iteration 126000, Testing net (#0)
I0629 03:05:06.018239  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 03:05:27.439975  5888 data_reader.cpp:262] Starting prefetch of epoch 126
I0629 03:05:27.514341  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56812
I0629 03:05:27.514363  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79672
I0629 03:05:27.514366  5893 solver.cpp:630]     Test net output #2: loss = 1.89227 (* 1 = 1.89227 loss)
I0629 03:05:27.514382  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3292s
I0629 03:05:27.698559  5893 solver.cpp:349] Iteration 126000 (2.336 iter/s, 42.8083s/100 iter), loss = 1.37401
I0629 03:05:27.698581  5893 solver.cpp:371]     Train net output #0: loss = 1.35825 (* 1 = 1.35825 loss)
I0629 03:05:27.698585  5893 sgd_solver.cpp:137] Iteration 126000, lr = 0.002125, m = 0.9
I0629 03:05:46.133569  5893 solver.cpp:349] Iteration 126100 (5.42465 iter/s, 18.4344s/100 iter), loss = 1.67136
I0629 03:05:46.133591  5893 solver.cpp:371]     Train net output #0: loss = 1.61985 (* 1 = 1.61985 loss)
I0629 03:05:46.133595  5893 sgd_solver.cpp:137] Iteration 126100, lr = 0.00211875, m = 0.9
I0629 03:06:04.567378  5893 solver.cpp:349] Iteration 126200 (5.42501 iter/s, 18.4332s/100 iter), loss = 1.64641
I0629 03:06:04.567477  5893 solver.cpp:371]     Train net output #0: loss = 1.44112 (* 1 = 1.44112 loss)
I0629 03:06:04.567483  5893 sgd_solver.cpp:137] Iteration 126200, lr = 0.0021125, m = 0.9
I0629 03:06:22.990777  5893 solver.cpp:349] Iteration 126300 (5.4281 iter/s, 18.4227s/100 iter), loss = 1.5192
I0629 03:06:22.990799  5893 solver.cpp:371]     Train net output #0: loss = 1.38217 (* 1 = 1.38217 loss)
I0629 03:06:22.990804  5893 sgd_solver.cpp:137] Iteration 126300, lr = 0.00210625, m = 0.9
I0629 03:06:41.479455  5893 solver.cpp:349] Iteration 126400 (5.40891 iter/s, 18.488s/100 iter), loss = 1.2044
I0629 03:06:41.479506  5893 solver.cpp:371]     Train net output #0: loss = 1.21932 (* 1 = 1.21932 loss)
I0629 03:06:41.479512  5893 sgd_solver.cpp:137] Iteration 126400, lr = 0.0021, m = 0.9
I0629 03:06:59.892971  5893 solver.cpp:349] Iteration 126500 (5.431 iter/s, 18.4128s/100 iter), loss = 1.51343
I0629 03:06:59.892995  5893 solver.cpp:371]     Train net output #0: loss = 1.5106 (* 1 = 1.5106 loss)
I0629 03:06:59.892999  5893 sgd_solver.cpp:137] Iteration 126500, lr = 0.00209375, m = 0.9
I0629 03:07:18.340831  5893 solver.cpp:349] Iteration 126600 (5.42088 iter/s, 18.4472s/100 iter), loss = 1.61788
I0629 03:07:18.340899  5893 solver.cpp:371]     Train net output #0: loss = 1.55039 (* 1 = 1.55039 loss)
I0629 03:07:18.340903  5893 sgd_solver.cpp:137] Iteration 126600, lr = 0.0020875, m = 0.9
I0629 03:07:36.905983  5893 solver.cpp:349] Iteration 126700 (5.38664 iter/s, 18.5644s/100 iter), loss = 1.81164
I0629 03:07:36.906008  5893 solver.cpp:371]     Train net output #0: loss = 1.99287 (* 1 = 1.99287 loss)
I0629 03:07:36.906011  5893 sgd_solver.cpp:137] Iteration 126700, lr = 0.00208125, m = 0.9
I0629 03:07:55.396589  5893 solver.cpp:349] Iteration 126800 (5.40835 iter/s, 18.4899s/100 iter), loss = 1.57043
I0629 03:07:55.396689  5893 solver.cpp:371]     Train net output #0: loss = 1.54746 (* 1 = 1.54746 loss)
I0629 03:07:55.396695  5893 sgd_solver.cpp:137] Iteration 126800, lr = 0.002075, m = 0.9
I0629 03:08:13.921694  5893 solver.cpp:349] Iteration 126900 (5.3983 iter/s, 18.5244s/100 iter), loss = 1.62002
I0629 03:08:13.921716  5893 solver.cpp:371]     Train net output #0: loss = 1.41385 (* 1 = 1.41385 loss)
I0629 03:08:13.921720  5893 sgd_solver.cpp:137] Iteration 126900, lr = 0.00206875, m = 0.9
I0629 03:08:32.271576  5893 solver.cpp:401] Sparsity after update:
I0629 03:08:32.276815  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:08:32.276825  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:08:32.276834  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:08:32.276836  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:08:32.276840  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:08:32.276844  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:08:32.276846  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:08:32.276849  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:08:32.276852  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:08:32.276855  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:08:32.276859  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:08:32.276862  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:08:32.276866  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:08:32.276876  5893 solver.cpp:545] Iteration 127000, Testing net (#0)
I0629 03:08:56.641852  5888 data_reader.cpp:262] Starting prefetch of epoch 127
I0629 03:08:56.703817  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57044
I0629 03:08:56.703841  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79816
I0629 03:08:56.703846  5893 solver.cpp:630]     Test net output #2: loss = 1.88867 (* 1 = 1.88867 loss)
I0629 03:08:56.703862  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4262s
I0629 03:08:56.897632  5893 solver.cpp:349] Iteration 127000 (2.32696 iter/s, 42.9744s/100 iter), loss = 1.54919
I0629 03:08:56.897655  5893 solver.cpp:371]     Train net output #0: loss = 1.41114 (* 1 = 1.41114 loss)
I0629 03:08:56.897658  5893 sgd_solver.cpp:137] Iteration 127000, lr = 0.0020625, m = 0.9
I0629 03:09:15.342509  5893 solver.cpp:349] Iteration 127100 (5.42176 iter/s, 18.4442s/100 iter), loss = 1.54078
I0629 03:09:15.342620  5893 solver.cpp:371]     Train net output #0: loss = 1.69601 (* 1 = 1.69601 loss)
I0629 03:09:15.342627  5893 sgd_solver.cpp:137] Iteration 127100, lr = 0.00205625, m = 0.9
I0629 03:09:33.805094  5893 solver.cpp:349] Iteration 127200 (5.41658 iter/s, 18.4618s/100 iter), loss = 1.72693
I0629 03:09:33.805116  5893 solver.cpp:371]     Train net output #0: loss = 1.49525 (* 1 = 1.49525 loss)
I0629 03:09:33.805120  5893 sgd_solver.cpp:137] Iteration 127200, lr = 0.00205, m = 0.9
I0629 03:09:52.211144  5893 solver.cpp:349] Iteration 127300 (5.43319 iter/s, 18.4054s/100 iter), loss = 1.49737
I0629 03:09:52.211252  5893 solver.cpp:371]     Train net output #0: loss = 1.43732 (* 1 = 1.43732 loss)
I0629 03:09:52.211258  5893 sgd_solver.cpp:137] Iteration 127300, lr = 0.00204375, m = 0.9
I0629 03:10:10.643728  5893 solver.cpp:349] Iteration 127400 (5.4254 iter/s, 18.4318s/100 iter), loss = 1.28544
I0629 03:10:10.643752  5893 solver.cpp:371]     Train net output #0: loss = 1.19078 (* 1 = 1.19078 loss)
I0629 03:10:10.643756  5893 sgd_solver.cpp:137] Iteration 127400, lr = 0.0020375, m = 0.9
I0629 03:10:29.070730  5893 solver.cpp:349] Iteration 127500 (5.42702 iter/s, 18.4263s/100 iter), loss = 1.70656
I0629 03:10:29.070773  5893 solver.cpp:371]     Train net output #0: loss = 1.53147 (* 1 = 1.53147 loss)
I0629 03:10:29.070778  5893 sgd_solver.cpp:137] Iteration 127500, lr = 0.00203125, m = 0.9
I0629 03:10:47.501957  5893 solver.cpp:349] Iteration 127600 (5.42578 iter/s, 18.4305s/100 iter), loss = 1.64642
I0629 03:10:47.501981  5893 solver.cpp:371]     Train net output #0: loss = 1.61342 (* 1 = 1.61342 loss)
I0629 03:10:47.501984  5893 sgd_solver.cpp:137] Iteration 127600, lr = 0.002025, m = 0.9
I0629 03:11:05.946319  5893 solver.cpp:349] Iteration 127700 (5.42191 iter/s, 18.4437s/100 iter), loss = 1.88622
I0629 03:11:05.946434  5893 solver.cpp:371]     Train net output #0: loss = 1.90059 (* 1 = 1.90059 loss)
I0629 03:11:05.946444  5893 sgd_solver.cpp:137] Iteration 127700, lr = 0.00201875, m = 0.9
I0629 03:11:24.513449  5893 solver.cpp:349] Iteration 127800 (5.38609 iter/s, 18.5663s/100 iter), loss = 1.6092
I0629 03:11:24.513473  5893 solver.cpp:371]     Train net output #0: loss = 1.58436 (* 1 = 1.58436 loss)
I0629 03:11:24.513476  5893 sgd_solver.cpp:137] Iteration 127800, lr = 0.0020125, m = 0.9
I0629 03:11:43.002590  5893 solver.cpp:349] Iteration 127900 (5.40878 iter/s, 18.4885s/100 iter), loss = 1.99423
I0629 03:11:43.002696  5893 solver.cpp:371]     Train net output #0: loss = 1.92126 (* 1 = 1.92126 loss)
I0629 03:11:43.002702  5893 sgd_solver.cpp:137] Iteration 127900, lr = 0.00200625, m = 0.9
I0629 03:12:01.296651  5893 solver.cpp:401] Sparsity after update:
I0629 03:12:01.301877  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:12:01.301887  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:12:01.301892  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:12:01.301894  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:12:01.301897  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:12:01.301898  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:12:01.301900  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:12:01.301903  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:12:01.301905  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:12:01.301908  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:12:01.301909  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:12:01.301913  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:12:01.301914  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:12:01.301923  5893 solver.cpp:545] Iteration 128000, Testing net (#0)
I0629 03:12:25.629501  5888 data_reader.cpp:262] Starting prefetch of epoch 128
I0629 03:12:25.694422  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56964
I0629 03:12:25.694445  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79896
I0629 03:12:25.694453  5893 solver.cpp:630]     Test net output #2: loss = 1.88142 (* 1 = 1.88142 loss)
I0629 03:12:25.694471  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3917s
I0629 03:12:25.883826  5893 solver.cpp:349] Iteration 128000 (2.33211 iter/s, 42.8796s/100 iter), loss = 1.82967
I0629 03:12:25.883848  5893 solver.cpp:371]     Train net output #0: loss = 1.69657 (* 1 = 1.69657 loss)
I0629 03:12:25.883853  5893 sgd_solver.cpp:137] Iteration 128000, lr = 0.002, m = 0.9
I0629 03:12:44.324781  5893 solver.cpp:349] Iteration 128100 (5.42291 iter/s, 18.4403s/100 iter), loss = 1.42072
I0629 03:12:44.324805  5893 solver.cpp:371]     Train net output #0: loss = 1.45049 (* 1 = 1.45049 loss)
I0629 03:12:44.324808  5893 sgd_solver.cpp:137] Iteration 128100, lr = 0.00199375, m = 0.9
I0629 03:13:02.780251  5893 solver.cpp:349] Iteration 128200 (5.41865 iter/s, 18.4548s/100 iter), loss = 1.28131
I0629 03:13:02.780336  5893 solver.cpp:371]     Train net output #0: loss = 1.13016 (* 1 = 1.13016 loss)
I0629 03:13:02.780340  5893 sgd_solver.cpp:137] Iteration 128200, lr = 0.0019875, m = 0.9
I0629 03:13:21.222400  5893 solver.cpp:349] Iteration 128300 (5.42257 iter/s, 18.4414s/100 iter), loss = 1.44631
I0629 03:13:21.222424  5893 solver.cpp:371]     Train net output #0: loss = 1.59696 (* 1 = 1.59696 loss)
I0629 03:13:21.222429  5893 sgd_solver.cpp:137] Iteration 128300, lr = 0.00198125, m = 0.9
I0629 03:13:39.636065  5893 solver.cpp:349] Iteration 128400 (5.43093 iter/s, 18.413s/100 iter), loss = 1.51335
I0629 03:13:39.636154  5893 solver.cpp:371]     Train net output #0: loss = 1.67894 (* 1 = 1.67894 loss)
I0629 03:13:39.636158  5893 sgd_solver.cpp:137] Iteration 128400, lr = 0.001975, m = 0.9
I0629 03:13:58.065021  5893 solver.cpp:349] Iteration 128500 (5.42645 iter/s, 18.4283s/100 iter), loss = 1.58541
I0629 03:13:58.065040  5893 solver.cpp:371]     Train net output #0: loss = 1.3895 (* 1 = 1.3895 loss)
I0629 03:13:58.065047  5893 sgd_solver.cpp:137] Iteration 128500, lr = 0.00196875, m = 0.9
I0629 03:14:16.546063  5893 solver.cpp:349] Iteration 128600 (5.41113 iter/s, 18.4804s/100 iter), loss = 1.43299
I0629 03:14:16.546183  5893 solver.cpp:371]     Train net output #0: loss = 1.2643 (* 1 = 1.2643 loss)
I0629 03:14:16.546190  5893 sgd_solver.cpp:137] Iteration 128600, lr = 0.0019625, m = 0.9
I0629 03:14:35.085124  5893 solver.cpp:349] Iteration 128700 (5.39423 iter/s, 18.5383s/100 iter), loss = 1.56822
I0629 03:14:35.085145  5893 solver.cpp:371]     Train net output #0: loss = 1.68898 (* 1 = 1.68898 loss)
I0629 03:14:35.085150  5893 sgd_solver.cpp:137] Iteration 128700, lr = 0.00195625, m = 0.9
I0629 03:14:53.592398  5893 solver.cpp:349] Iteration 128800 (5.40347 iter/s, 18.5066s/100 iter), loss = 1.67361
I0629 03:14:53.592497  5893 solver.cpp:371]     Train net output #0: loss = 2.02603 (* 1 = 2.02603 loss)
I0629 03:14:53.592504  5893 sgd_solver.cpp:137] Iteration 128800, lr = 0.00195, m = 0.9
I0629 03:15:12.092088  5893 solver.cpp:349] Iteration 128900 (5.40571 iter/s, 18.499s/100 iter), loss = 1.48723
I0629 03:15:12.092113  5893 solver.cpp:371]     Train net output #0: loss = 1.50999 (* 1 = 1.50999 loss)
I0629 03:15:12.092118  5893 sgd_solver.cpp:137] Iteration 128900, lr = 0.00194375, m = 0.9
I0629 03:15:30.385283  5893 solver.cpp:401] Sparsity after update:
I0629 03:15:30.390449  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:15:30.390456  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:15:30.390463  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:15:30.390465  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:15:30.390467  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:15:30.390470  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:15:30.390471  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:15:30.390473  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:15:30.390475  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:15:30.390476  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:15:30.390478  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:15:30.390480  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:15:30.390482  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:15:30.390489  5893 solver.cpp:545] Iteration 129000, Testing net (#0)
I0629 03:15:54.643512  5888 data_reader.cpp:262] Starting prefetch of epoch 129
I0629 03:15:54.725010  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56844
I0629 03:15:54.725030  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798
I0629 03:15:54.725037  5893 solver.cpp:630]     Test net output #2: loss = 1.88736 (* 1 = 1.88736 loss)
I0629 03:15:54.725055  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3338s
I0629 03:15:54.912907  5893 solver.cpp:349] Iteration 129000 (2.33539 iter/s, 42.8194s/100 iter), loss = 1.34242
I0629 03:15:54.912930  5893 solver.cpp:371]     Train net output #0: loss = 1.50686 (* 1 = 1.50686 loss)
I0629 03:15:54.912935  5893 sgd_solver.cpp:137] Iteration 129000, lr = 0.0019375, m = 0.9
I0629 03:16:13.340422  5893 solver.cpp:349] Iteration 129100 (5.42686 iter/s, 18.4269s/100 iter), loss = 1.66918
I0629 03:16:13.340523  5893 solver.cpp:371]     Train net output #0: loss = 1.79347 (* 1 = 1.79347 loss)
I0629 03:16:13.340530  5893 sgd_solver.cpp:137] Iteration 129100, lr = 0.00193125, m = 0.9
I0629 03:16:31.805740  5893 solver.cpp:349] Iteration 129200 (5.41577 iter/s, 18.4646s/100 iter), loss = 1.69105
I0629 03:16:31.805763  5893 solver.cpp:371]     Train net output #0: loss = 1.71632 (* 1 = 1.71632 loss)
I0629 03:16:31.805768  5893 sgd_solver.cpp:137] Iteration 129200, lr = 0.001925, m = 0.9
I0629 03:16:50.222757  5893 solver.cpp:349] Iteration 129300 (5.42995 iter/s, 18.4164s/100 iter), loss = 1.31978
I0629 03:16:50.222836  5893 solver.cpp:371]     Train net output #0: loss = 1.28207 (* 1 = 1.28207 loss)
I0629 03:16:50.222841  5893 sgd_solver.cpp:137] Iteration 129300, lr = 0.00191875, m = 0.9
I0629 03:17:08.661978  5893 solver.cpp:349] Iteration 129400 (5.42343 iter/s, 18.4385s/100 iter), loss = 1.8256
I0629 03:17:08.662001  5893 solver.cpp:371]     Train net output #0: loss = 1.49803 (* 1 = 1.49803 loss)
I0629 03:17:08.662005  5893 sgd_solver.cpp:137] Iteration 129400, lr = 0.0019125, m = 0.9
I0629 03:17:27.099581  5893 solver.cpp:349] Iteration 129500 (5.42389 iter/s, 18.437s/100 iter), loss = 1.67699
I0629 03:17:27.099675  5893 solver.cpp:371]     Train net output #0: loss = 1.59991 (* 1 = 1.59991 loss)
I0629 03:17:27.099681  5893 sgd_solver.cpp:137] Iteration 129500, lr = 0.00190625, m = 0.9
I0629 03:17:45.558275  5893 solver.cpp:349] Iteration 129600 (5.41771 iter/s, 18.458s/100 iter), loss = 1.90651
I0629 03:17:45.558296  5893 solver.cpp:371]     Train net output #0: loss = 1.95977 (* 1 = 1.95977 loss)
I0629 03:17:45.558301  5893 sgd_solver.cpp:137] Iteration 129600, lr = 0.0019, m = 0.9
I0629 03:18:04.116505  5893 solver.cpp:349] Iteration 129700 (5.38863 iter/s, 18.5576s/100 iter), loss = 1.69883
I0629 03:18:04.116591  5893 solver.cpp:371]     Train net output #0: loss = 1.58687 (* 1 = 1.58687 loss)
I0629 03:18:04.116596  5893 sgd_solver.cpp:137] Iteration 129700, lr = 0.00189375, m = 0.9
I0629 03:18:22.657186  5893 solver.cpp:349] Iteration 129800 (5.39375 iter/s, 18.54s/100 iter), loss = 1.49255
I0629 03:18:22.657210  5893 solver.cpp:371]     Train net output #0: loss = 1.6247 (* 1 = 1.6247 loss)
I0629 03:18:22.657214  5893 sgd_solver.cpp:137] Iteration 129800, lr = 0.0018875, m = 0.9
I0629 03:18:41.178673  5893 solver.cpp:349] Iteration 129900 (5.39932 iter/s, 18.5208s/100 iter), loss = 1.57894
I0629 03:18:41.178772  5893 solver.cpp:371]     Train net output #0: loss = 1.64743 (* 1 = 1.64743 loss)
I0629 03:18:41.178778  5893 sgd_solver.cpp:137] Iteration 129900, lr = 0.00188125, m = 0.9
I0629 03:18:59.479537  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_130000.caffemodel
I0629 03:18:59.491994  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_130000.solverstate
I0629 03:18:59.497681  5893 solver.cpp:401] Sparsity after update:
I0629 03:18:59.498692  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:18:59.498703  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:18:59.498711  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:18:59.498715  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:18:59.498719  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:18:59.498723  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:18:59.498728  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:18:59.498731  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:18:59.498734  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:18:59.498739  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:18:59.498742  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:18:59.498746  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:18:59.498750  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:18:59.498760  5893 solver.cpp:545] Iteration 130000, Testing net (#0)
I0629 03:19:23.631060  5888 data_reader.cpp:262] Starting prefetch of epoch 130
I0629 03:19:23.772398  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57052
I0629 03:19:23.772419  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79816
I0629 03:19:23.772423  5893 solver.cpp:630]     Test net output #2: loss = 1.88151 (* 1 = 1.88151 loss)
I0629 03:19:23.772440  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2729s
I0629 03:19:23.960130  5893 solver.cpp:349] Iteration 130000 (2.33754 iter/s, 42.7799s/100 iter), loss = 1.61391
I0629 03:19:23.960151  5893 solver.cpp:371]     Train net output #0: loss = 1.62179 (* 1 = 1.62179 loss)
I0629 03:19:23.960155  5893 sgd_solver.cpp:137] Iteration 130000, lr = 0.001875, m = 0.9
I0629 03:19:42.418030  5893 solver.cpp:349] Iteration 130100 (5.41792 iter/s, 18.4573s/100 iter), loss = 1.5512
I0629 03:19:42.418051  5893 solver.cpp:371]     Train net output #0: loss = 1.86343 (* 1 = 1.86343 loss)
I0629 03:19:42.418057  5893 sgd_solver.cpp:137] Iteration 130100, lr = 0.00186875, m = 0.9
I0629 03:19:45.477527  5875 data_reader.cpp:262] Starting prefetch of epoch 26
I0629 03:20:00.864074  5893 solver.cpp:349] Iteration 130200 (5.42141 iter/s, 18.4454s/100 iter), loss = 1.87812
I0629 03:20:00.864135  5893 solver.cpp:371]     Train net output #0: loss = 2.30768 (* 1 = 2.30768 loss)
I0629 03:20:00.864142  5893 sgd_solver.cpp:137] Iteration 130200, lr = 0.0018625, m = 0.9
I0629 03:20:19.319675  5893 solver.cpp:349] Iteration 130300 (5.41861 iter/s, 18.4549s/100 iter), loss = 1.61459
I0629 03:20:19.319699  5893 solver.cpp:371]     Train net output #0: loss = 1.62547 (* 1 = 1.62547 loss)
I0629 03:20:19.319702  5893 sgd_solver.cpp:137] Iteration 130300, lr = 0.00185625, m = 0.9
I0629 03:20:37.768725  5893 solver.cpp:349] Iteration 130400 (5.42052 iter/s, 18.4484s/100 iter), loss = 1.80095
I0629 03:20:37.768815  5893 solver.cpp:371]     Train net output #0: loss = 1.80031 (* 1 = 1.80031 loss)
I0629 03:20:37.768821  5893 sgd_solver.cpp:137] Iteration 130400, lr = 0.00185, m = 0.9
I0629 03:20:56.244976  5893 solver.cpp:349] Iteration 130500 (5.41257 iter/s, 18.4755s/100 iter), loss = 1.73634
I0629 03:20:56.244998  5893 solver.cpp:371]     Train net output #0: loss = 1.83009 (* 1 = 1.83009 loss)
I0629 03:20:56.245002  5893 sgd_solver.cpp:137] Iteration 130500, lr = 0.00184375, m = 0.9
I0629 03:21:14.684988  5893 solver.cpp:349] Iteration 130600 (5.42318 iter/s, 18.4394s/100 iter), loss = 1.62227
I0629 03:21:14.685089  5893 solver.cpp:371]     Train net output #0: loss = 1.7027 (* 1 = 1.7027 loss)
I0629 03:21:14.685099  5893 sgd_solver.cpp:137] Iteration 130600, lr = 0.0018375, m = 0.9
I0629 03:21:33.151613  5893 solver.cpp:349] Iteration 130700 (5.41539 iter/s, 18.4659s/100 iter), loss = 1.59339
I0629 03:21:33.151635  5893 solver.cpp:371]     Train net output #0: loss = 1.52457 (* 1 = 1.52457 loss)
I0629 03:21:33.151641  5893 sgd_solver.cpp:137] Iteration 130700, lr = 0.00183125, m = 0.9
I0629 03:21:51.692848  5893 solver.cpp:349] Iteration 130800 (5.39358 iter/s, 18.5406s/100 iter), loss = 1.48776
I0629 03:21:51.692917  5893 solver.cpp:371]     Train net output #0: loss = 1.46015 (* 1 = 1.46015 loss)
I0629 03:21:51.692922  5893 sgd_solver.cpp:137] Iteration 130800, lr = 0.001825, m = 0.9
I0629 03:22:10.183794  5893 solver.cpp:349] Iteration 130900 (5.40826 iter/s, 18.4902s/100 iter), loss = 1.62463
I0629 03:22:10.183817  5893 solver.cpp:371]     Train net output #0: loss = 1.59069 (* 1 = 1.59069 loss)
I0629 03:22:10.183821  5893 sgd_solver.cpp:137] Iteration 130900, lr = 0.00181875, m = 0.9
I0629 03:22:28.519278  5893 solver.cpp:401] Sparsity after update:
I0629 03:22:28.524503  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:22:28.524511  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:22:28.524518  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:22:28.524519  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:22:28.524521  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:22:28.524523  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:22:28.524526  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:22:28.524528  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:22:28.524530  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:22:28.524533  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:22:28.524535  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:22:28.524538  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:22:28.524539  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:22:28.524546  5893 solver.cpp:545] Iteration 131000, Testing net (#0)
I0629 03:22:31.434068  5894 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 03:22:52.787621  5888 data_reader.cpp:262] Starting prefetch of epoch 131
I0629 03:22:52.849534  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56896
I0629 03:22:52.849566  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79844
I0629 03:22:52.849571  5893 solver.cpp:630]     Test net output #2: loss = 1.88369 (* 1 = 1.88369 loss)
I0629 03:22:52.849587  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3242s
I0629 03:22:53.033603  5893 solver.cpp:349] Iteration 131000 (2.33381 iter/s, 42.8483s/100 iter), loss = 1.70983
I0629 03:22:53.033622  5893 solver.cpp:371]     Train net output #0: loss = 1.70797 (* 1 = 1.70797 loss)
I0629 03:22:53.033625  5893 sgd_solver.cpp:137] Iteration 131000, lr = 0.0018125, m = 0.9
I0629 03:23:11.478544  5893 solver.cpp:349] Iteration 131100 (5.42173 iter/s, 18.4443s/100 iter), loss = 1.42657
I0629 03:23:11.478652  5893 solver.cpp:371]     Train net output #0: loss = 1.3879 (* 1 = 1.3879 loss)
I0629 03:23:11.478659  5893 sgd_solver.cpp:137] Iteration 131100, lr = 0.00180625, m = 0.9
I0629 03:23:29.945775  5893 solver.cpp:349] Iteration 131200 (5.41522 iter/s, 18.4665s/100 iter), loss = 1.51032
I0629 03:23:29.945796  5893 solver.cpp:371]     Train net output #0: loss = 1.63303 (* 1 = 1.63303 loss)
I0629 03:23:29.945801  5893 sgd_solver.cpp:137] Iteration 131200, lr = 0.0018, m = 0.9
I0629 03:23:48.385932  5893 solver.cpp:349] Iteration 131300 (5.42314 iter/s, 18.4395s/100 iter), loss = 1.49296
I0629 03:23:48.385998  5893 solver.cpp:371]     Train net output #0: loss = 1.48382 (* 1 = 1.48382 loss)
I0629 03:23:48.386003  5893 sgd_solver.cpp:137] Iteration 131300, lr = 0.00179375, m = 0.9
I0629 03:24:06.806905  5893 solver.cpp:349] Iteration 131400 (5.4288 iter/s, 18.4203s/100 iter), loss = 1.40176
I0629 03:24:06.806929  5893 solver.cpp:371]     Train net output #0: loss = 1.47345 (* 1 = 1.47345 loss)
I0629 03:24:06.806933  5893 sgd_solver.cpp:137] Iteration 131400, lr = 0.0017875, m = 0.9
I0629 03:24:25.234493  5893 solver.cpp:349] Iteration 131500 (5.42684 iter/s, 18.4269s/100 iter), loss = 1.55323
I0629 03:24:25.234591  5893 solver.cpp:371]     Train net output #0: loss = 1.43887 (* 1 = 1.43887 loss)
I0629 03:24:25.234597  5893 sgd_solver.cpp:137] Iteration 131500, lr = 0.00178125, m = 0.9
I0629 03:24:43.656299  5893 solver.cpp:349] Iteration 131600 (5.42857 iter/s, 18.4211s/100 iter), loss = 1.42304
I0629 03:24:43.656321  5893 solver.cpp:371]     Train net output #0: loss = 1.66119 (* 1 = 1.66119 loss)
I0629 03:24:43.656324  5893 sgd_solver.cpp:137] Iteration 131600, lr = 0.001775, m = 0.9
I0629 03:25:02.186380  5893 solver.cpp:349] Iteration 131700 (5.39683 iter/s, 18.5294s/100 iter), loss = 1.65111
I0629 03:25:02.186467  5893 solver.cpp:371]     Train net output #0: loss = 1.46554 (* 1 = 1.46554 loss)
I0629 03:25:02.186471  5893 sgd_solver.cpp:137] Iteration 131700, lr = 0.00176875, m = 0.9
I0629 03:25:20.688884  5893 solver.cpp:349] Iteration 131800 (5.40489 iter/s, 18.5018s/100 iter), loss = 1.37041
I0629 03:25:20.688905  5893 solver.cpp:371]     Train net output #0: loss = 1.50839 (* 1 = 1.50839 loss)
I0629 03:25:20.688911  5893 sgd_solver.cpp:137] Iteration 131800, lr = 0.0017625, m = 0.9
I0629 03:25:39.189236  5893 solver.cpp:349] Iteration 131900 (5.4055 iter/s, 18.4997s/100 iter), loss = 1.5977
I0629 03:25:39.189337  5893 solver.cpp:371]     Train net output #0: loss = 1.47929 (* 1 = 1.47929 loss)
I0629 03:25:39.189345  5893 sgd_solver.cpp:137] Iteration 131900, lr = 0.00175625, m = 0.9
I0629 03:25:57.502838  5893 solver.cpp:401] Sparsity after update:
I0629 03:25:57.507797  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:25:57.507805  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:25:57.507813  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:25:57.507817  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:25:57.507820  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:25:57.507823  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:25:57.507827  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:25:57.507829  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:25:57.507833  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:25:57.507835  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:25:57.507838  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:25:57.507841  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:25:57.507844  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:25:57.507854  5893 solver.cpp:545] Iteration 132000, Testing net (#0)
I0629 03:26:21.735743  5888 data_reader.cpp:262] Starting prefetch of epoch 132
I0629 03:26:21.960582  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56984
I0629 03:26:21.960602  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7992
I0629 03:26:21.960606  5893 solver.cpp:630]     Test net output #2: loss = 1.88444 (* 1 = 1.88444 loss)
I0629 03:26:21.960623  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4519s
I0629 03:26:22.146693  5893 solver.cpp:349] Iteration 132000 (2.32797 iter/s, 42.9559s/100 iter), loss = 1.35993
I0629 03:26:22.146716  5893 solver.cpp:371]     Train net output #0: loss = 1.27675 (* 1 = 1.27675 loss)
I0629 03:26:22.146719  5893 sgd_solver.cpp:137] Iteration 132000, lr = 0.00175, m = 0.9
I0629 03:26:40.564625  5893 solver.cpp:349] Iteration 132100 (5.42969 iter/s, 18.4173s/100 iter), loss = 1.53195
I0629 03:26:40.564649  5893 solver.cpp:371]     Train net output #0: loss = 1.24849 (* 1 = 1.24849 loss)
I0629 03:26:40.564653  5893 sgd_solver.cpp:137] Iteration 132100, lr = 0.00174375, m = 0.9
I0629 03:26:58.975798  5893 solver.cpp:349] Iteration 132200 (5.43168 iter/s, 18.4105s/100 iter), loss = 1.44006
I0629 03:26:58.975891  5893 solver.cpp:371]     Train net output #0: loss = 1.40868 (* 1 = 1.40868 loss)
I0629 03:26:58.975898  5893 sgd_solver.cpp:137] Iteration 132200, lr = 0.0017375, m = 0.9
I0629 03:27:17.417942  5893 solver.cpp:349] Iteration 132300 (5.42258 iter/s, 18.4414s/100 iter), loss = 1.77717
I0629 03:27:17.417963  5893 solver.cpp:371]     Train net output #0: loss = 1.72171 (* 1 = 1.72171 loss)
I0629 03:27:17.417968  5893 sgd_solver.cpp:137] Iteration 132300, lr = 0.00173125, m = 0.9
I0629 03:27:35.841841  5893 solver.cpp:349] Iteration 132400 (5.42793 iter/s, 18.4232s/100 iter), loss = 1.43243
I0629 03:27:35.841945  5893 solver.cpp:371]     Train net output #0: loss = 1.19569 (* 1 = 1.19569 loss)
I0629 03:27:35.841953  5893 sgd_solver.cpp:137] Iteration 132400, lr = 0.001725, m = 0.9
I0629 03:27:54.297881  5893 solver.cpp:349] Iteration 132500 (5.4185 iter/s, 18.4553s/100 iter), loss = 1.28643
I0629 03:27:54.297904  5893 solver.cpp:371]     Train net output #0: loss = 1.37996 (* 1 = 1.37996 loss)
I0629 03:27:54.297909  5893 sgd_solver.cpp:137] Iteration 132500, lr = 0.00171875, m = 0.9
I0629 03:28:12.770463  5893 solver.cpp:349] Iteration 132600 (5.41363 iter/s, 18.4719s/100 iter), loss = 1.63537
I0629 03:28:12.770562  5893 solver.cpp:371]     Train net output #0: loss = 1.70547 (* 1 = 1.70547 loss)
I0629 03:28:12.770570  5893 sgd_solver.cpp:137] Iteration 132600, lr = 0.0017125, m = 0.9
I0629 03:28:31.342564  5893 solver.cpp:349] Iteration 132700 (5.38464 iter/s, 18.5713s/100 iter), loss = 1.57981
I0629 03:28:31.342586  5893 solver.cpp:371]     Train net output #0: loss = 1.66486 (* 1 = 1.66486 loss)
I0629 03:28:31.342591  5893 sgd_solver.cpp:137] Iteration 132700, lr = 0.00170625, m = 0.9
I0629 03:28:49.875701  5893 solver.cpp:349] Iteration 132800 (5.39594 iter/s, 18.5325s/100 iter), loss = 1.40747
I0629 03:28:49.875808  5893 solver.cpp:371]     Train net output #0: loss = 1.57839 (* 1 = 1.57839 loss)
I0629 03:28:49.875815  5893 sgd_solver.cpp:137] Iteration 132800, lr = 0.0017, m = 0.9
I0629 03:29:08.374135  5893 solver.cpp:349] Iteration 132900 (5.40609 iter/s, 18.4977s/100 iter), loss = 1.63423
I0629 03:29:08.374158  5893 solver.cpp:371]     Train net output #0: loss = 1.51762 (* 1 = 1.51762 loss)
I0629 03:29:08.374162  5893 sgd_solver.cpp:137] Iteration 132900, lr = 0.00169375, m = 0.9
I0629 03:29:26.675274  5893 solver.cpp:401] Sparsity after update:
I0629 03:29:26.680480  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:29:26.680487  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:29:26.680495  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:29:26.680500  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:29:26.680503  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:29:26.680508  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:29:26.680512  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:29:26.680516  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:29:26.680521  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:29:26.680523  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:29:26.680527  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:29:26.680531  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:29:26.680538  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:29:26.680549  5893 solver.cpp:545] Iteration 133000, Testing net (#0)
I0629 03:29:50.902812  5888 data_reader.cpp:262] Starting prefetch of epoch 133
I0629 03:29:50.964962  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57088
I0629 03:29:50.964984  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79928
I0629 03:29:50.964989  5893 solver.cpp:630]     Test net output #2: loss = 1.87952 (* 1 = 1.87952 loss)
I0629 03:29:50.965005  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2836s
I0629 03:29:51.150758  5893 solver.cpp:349] Iteration 133000 (2.33781 iter/s, 42.7751s/100 iter), loss = 1.59896
I0629 03:29:51.150779  5893 solver.cpp:371]     Train net output #0: loss = 1.78519 (* 1 = 1.78519 loss)
I0629 03:29:51.150784  5893 sgd_solver.cpp:137] Iteration 133000, lr = 0.0016875, m = 0.9
I0629 03:30:09.611764  5893 solver.cpp:349] Iteration 133100 (5.41702 iter/s, 18.4603s/100 iter), loss = 1.64275
I0629 03:30:09.611809  5893 solver.cpp:371]     Train net output #0: loss = 1.72528 (* 1 = 1.72528 loss)
I0629 03:30:09.611814  5893 sgd_solver.cpp:137] Iteration 133100, lr = 0.00168125, m = 0.9
I0629 03:30:28.088785  5893 solver.cpp:349] Iteration 133200 (5.41234 iter/s, 18.4763s/100 iter), loss = 1.35025
I0629 03:30:28.088809  5893 solver.cpp:371]     Train net output #0: loss = 1.37895 (* 1 = 1.37895 loss)
I0629 03:30:28.088814  5893 sgd_solver.cpp:137] Iteration 133200, lr = 0.001675, m = 0.9
I0629 03:30:46.540902  5893 solver.cpp:349] Iteration 133300 (5.41963 iter/s, 18.4514s/100 iter), loss = 1.2237
I0629 03:30:46.540990  5893 solver.cpp:371]     Train net output #0: loss = 1.16864 (* 1 = 1.16864 loss)
I0629 03:30:46.540997  5893 sgd_solver.cpp:137] Iteration 133300, lr = 0.00166875, m = 0.9
I0629 03:31:04.952818  5893 solver.cpp:349] Iteration 133400 (5.43149 iter/s, 18.4112s/100 iter), loss = 1.65575
I0629 03:31:04.952839  5893 solver.cpp:371]     Train net output #0: loss = 1.68905 (* 1 = 1.68905 loss)
I0629 03:31:04.952843  5893 sgd_solver.cpp:137] Iteration 133400, lr = 0.0016625, m = 0.9
I0629 03:31:23.381863  5893 solver.cpp:349] Iteration 133500 (5.42642 iter/s, 18.4284s/100 iter), loss = 1.85884
I0629 03:31:23.381949  5893 solver.cpp:371]     Train net output #0: loss = 1.69614 (* 1 = 1.69614 loss)
I0629 03:31:23.381954  5893 sgd_solver.cpp:137] Iteration 133500, lr = 0.00165625, m = 0.9
I0629 03:31:41.870108  5893 solver.cpp:349] Iteration 133600 (5.40906 iter/s, 18.4875s/100 iter), loss = 1.48779
I0629 03:31:41.870132  5893 solver.cpp:371]     Train net output #0: loss = 1.40166 (* 1 = 1.40166 loss)
I0629 03:31:41.870136  5893 sgd_solver.cpp:137] Iteration 133600, lr = 0.00165, m = 0.9
I0629 03:32:00.406568  5893 solver.cpp:349] Iteration 133700 (5.39498 iter/s, 18.5358s/100 iter), loss = 1.88204
I0629 03:32:00.406672  5893 solver.cpp:371]     Train net output #0: loss = 1.88929 (* 1 = 1.88929 loss)
I0629 03:32:00.406679  5893 sgd_solver.cpp:137] Iteration 133700, lr = 0.00164375, m = 0.9
I0629 03:32:18.948141  5893 solver.cpp:349] Iteration 133800 (5.39351 iter/s, 18.5408s/100 iter), loss = 1.65526
I0629 03:32:18.948163  5893 solver.cpp:371]     Train net output #0: loss = 1.42179 (* 1 = 1.42179 loss)
I0629 03:32:18.948166  5893 sgd_solver.cpp:137] Iteration 133800, lr = 0.0016375, m = 0.9
I0629 03:32:37.401255  5893 solver.cpp:349] Iteration 133900 (5.41934 iter/s, 18.4524s/100 iter), loss = 1.54881
I0629 03:32:37.401365  5893 solver.cpp:371]     Train net output #0: loss = 1.67436 (* 1 = 1.67436 loss)
I0629 03:32:37.401371  5893 sgd_solver.cpp:137] Iteration 133900, lr = 0.00163125, m = 0.9
I0629 03:32:55.712651  5893 solver.cpp:401] Sparsity after update:
I0629 03:32:55.717855  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:32:55.717862  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:32:55.717869  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:32:55.717871  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:32:55.717875  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:32:55.717876  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:32:55.717878  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:32:55.717881  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:32:55.717883  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:32:55.717885  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:32:55.717886  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:32:55.717888  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:32:55.717891  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:32:55.717900  5893 solver.cpp:545] Iteration 134000, Testing net (#0)
I0629 03:33:20.005290  5888 data_reader.cpp:262] Starting prefetch of epoch 134
I0629 03:33:20.150343  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57216
I0629 03:33:20.150364  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798999
I0629 03:33:20.150368  5893 solver.cpp:630]     Test net output #2: loss = 1.87551 (* 1 = 1.87551 loss)
I0629 03:33:20.150387  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4316s
I0629 03:33:20.336809  5893 solver.cpp:349] Iteration 134000 (2.32916 iter/s, 42.9339s/100 iter), loss = 1.72728
I0629 03:33:20.336836  5893 solver.cpp:371]     Train net output #0: loss = 1.86298 (* 1 = 1.86298 loss)
I0629 03:33:20.336841  5893 sgd_solver.cpp:137] Iteration 134000, lr = 0.001625, m = 0.9
I0629 03:33:38.769774  5893 solver.cpp:349] Iteration 134100 (5.42527 iter/s, 18.4323s/100 iter), loss = 1.74469
I0629 03:33:38.769804  5893 solver.cpp:371]     Train net output #0: loss = 1.87464 (* 1 = 1.87464 loss)
I0629 03:33:38.769807  5893 sgd_solver.cpp:137] Iteration 134100, lr = 0.00161875, m = 0.9
I0629 03:33:57.200242  5893 solver.cpp:349] Iteration 134200 (5.426 iter/s, 18.4298s/100 iter), loss = 1.47966
I0629 03:33:57.200330  5893 solver.cpp:371]     Train net output #0: loss = 1.65706 (* 1 = 1.65706 loss)
I0629 03:33:57.200335  5893 sgd_solver.cpp:137] Iteration 134200, lr = 0.0016125, m = 0.9
I0629 03:34:15.646164  5893 solver.cpp:349] Iteration 134300 (5.42148 iter/s, 18.4452s/100 iter), loss = 1.4255
I0629 03:34:15.646188  5893 solver.cpp:371]     Train net output #0: loss = 1.495 (* 1 = 1.495 loss)
I0629 03:34:15.646193  5893 sgd_solver.cpp:137] Iteration 134300, lr = 0.00160625, m = 0.9
I0629 03:34:34.086827  5893 solver.cpp:349] Iteration 134400 (5.423 iter/s, 18.44s/100 iter), loss = 1.78094
I0629 03:34:34.086907  5893 solver.cpp:371]     Train net output #0: loss = 1.92337 (* 1 = 1.92337 loss)
I0629 03:34:34.086912  5893 sgd_solver.cpp:137] Iteration 134400, lr = 0.0016, m = 0.9
I0629 03:34:52.513504  5893 solver.cpp:349] Iteration 134500 (5.42714 iter/s, 18.4259s/100 iter), loss = 1.5001
I0629 03:34:52.513525  5893 solver.cpp:371]     Train net output #0: loss = 1.82159 (* 1 = 1.82159 loss)
I0629 03:34:52.513530  5893 sgd_solver.cpp:137] Iteration 134500, lr = 0.00159375, m = 0.9
I0629 03:35:10.944466  5893 solver.cpp:349] Iteration 134600 (5.42586 iter/s, 18.4303s/100 iter), loss = 1.48798
I0629 03:35:10.944550  5893 solver.cpp:371]     Train net output #0: loss = 1.44654 (* 1 = 1.44654 loss)
I0629 03:35:10.944555  5893 sgd_solver.cpp:137] Iteration 134600, lr = 0.0015875, m = 0.9
I0629 03:35:29.459697  5893 solver.cpp:349] Iteration 134700 (5.40118 iter/s, 18.5145s/100 iter), loss = 1.63953
I0629 03:35:29.459720  5893 solver.cpp:371]     Train net output #0: loss = 1.78323 (* 1 = 1.78323 loss)
I0629 03:35:29.459725  5893 sgd_solver.cpp:137] Iteration 134700, lr = 0.00158125, m = 0.9
I0629 03:35:47.982336  5893 solver.cpp:349] Iteration 134800 (5.39901 iter/s, 18.5219s/100 iter), loss = 1.61802
I0629 03:35:47.982445  5893 solver.cpp:371]     Train net output #0: loss = 1.6764 (* 1 = 1.6764 loss)
I0629 03:35:47.982451  5893 sgd_solver.cpp:137] Iteration 134800, lr = 0.001575, m = 0.9
I0629 03:36:06.512996  5893 solver.cpp:349] Iteration 134900 (5.39669 iter/s, 18.5299s/100 iter), loss = 1.69236
I0629 03:36:06.513020  5893 solver.cpp:371]     Train net output #0: loss = 1.93941 (* 1 = 1.93941 loss)
I0629 03:36:06.513023  5893 sgd_solver.cpp:137] Iteration 134900, lr = 0.00156875, m = 0.9
I0629 03:36:24.830744  5893 solver.cpp:401] Sparsity after update:
I0629 03:36:24.835983  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:36:24.835992  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:36:24.835999  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:36:24.836000  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:36:24.836002  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:36:24.836004  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:36:24.836006  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:36:24.836009  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:36:24.836010  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:36:24.836011  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:36:24.836014  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:36:24.836015  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:36:24.836017  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:36:24.836024  5893 solver.cpp:545] Iteration 135000, Testing net (#0)
I0629 03:36:49.299787  5888 data_reader.cpp:262] Starting prefetch of epoch 135
I0629 03:36:49.361649  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57244
I0629 03:36:49.361675  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.800681
I0629 03:36:49.361680  5893 solver.cpp:630]     Test net output #2: loss = 1.87389 (* 1 = 1.87389 loss)
I0629 03:36:49.361696  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5248s
I0629 03:36:49.545827  5893 solver.cpp:349] Iteration 135000 (2.32389 iter/s, 43.0312s/100 iter), loss = 1.54316
I0629 03:36:49.545851  5893 solver.cpp:371]     Train net output #0: loss = 1.3684 (* 1 = 1.3684 loss)
I0629 03:36:49.545855  5893 sgd_solver.cpp:137] Iteration 135000, lr = 0.0015625, m = 0.9
I0629 03:37:08.018707  5893 solver.cpp:349] Iteration 135100 (5.41355 iter/s, 18.4722s/100 iter), loss = 1.50793
I0629 03:37:08.018811  5893 solver.cpp:371]     Train net output #0: loss = 1.56661 (* 1 = 1.56661 loss)
I0629 03:37:08.018817  5893 sgd_solver.cpp:137] Iteration 135100, lr = 0.00155625, m = 0.9
I0629 03:37:11.906541  5875 data_reader.cpp:262] Starting prefetch of epoch 27
I0629 03:37:26.454090  5893 solver.cpp:349] Iteration 135200 (5.42457 iter/s, 18.4346s/100 iter), loss = 1.73455
I0629 03:37:26.454113  5893 solver.cpp:371]     Train net output #0: loss = 1.96663 (* 1 = 1.96663 loss)
I0629 03:37:26.454118  5893 sgd_solver.cpp:137] Iteration 135200, lr = 0.00155, m = 0.9
I0629 03:37:44.860421  5893 solver.cpp:349] Iteration 135300 (5.4331 iter/s, 18.4057s/100 iter), loss = 1.67377
I0629 03:37:44.860525  5893 solver.cpp:371]     Train net output #0: loss = 1.79137 (* 1 = 1.79137 loss)
I0629 03:37:44.860532  5893 sgd_solver.cpp:137] Iteration 135300, lr = 0.00154375, m = 0.9
I0629 03:38:03.279060  5893 solver.cpp:349] Iteration 135400 (5.42949 iter/s, 18.4179s/100 iter), loss = 1.54401
I0629 03:38:03.279083  5893 solver.cpp:371]     Train net output #0: loss = 1.40656 (* 1 = 1.40656 loss)
I0629 03:38:03.279086  5893 sgd_solver.cpp:137] Iteration 135400, lr = 0.0015375, m = 0.9
I0629 03:38:21.697196  5893 solver.cpp:349] Iteration 135500 (5.42962 iter/s, 18.4175s/100 iter), loss = 1.459
I0629 03:38:21.697312  5893 solver.cpp:371]     Train net output #0: loss = 1.47485 (* 1 = 1.47485 loss)
I0629 03:38:21.697319  5893 sgd_solver.cpp:137] Iteration 135500, lr = 0.00153125, m = 0.9
I0629 03:38:40.141988  5893 solver.cpp:349] Iteration 135600 (5.4218 iter/s, 18.4441s/100 iter), loss = 1.63633
I0629 03:38:40.142010  5893 solver.cpp:371]     Train net output #0: loss = 1.62582 (* 1 = 1.62582 loss)
I0629 03:38:40.142014  5893 sgd_solver.cpp:137] Iteration 135600, lr = 0.001525, m = 0.9
I0629 03:38:58.722216  5893 solver.cpp:349] Iteration 135700 (5.38225 iter/s, 18.5796s/100 iter), loss = 1.8335
I0629 03:38:58.722319  5893 solver.cpp:371]     Train net output #0: loss = 1.97226 (* 1 = 1.97226 loss)
I0629 03:38:58.722326  5893 sgd_solver.cpp:137] Iteration 135700, lr = 0.00151875, m = 0.9
I0629 03:39:17.235795  5893 solver.cpp:349] Iteration 135800 (5.40165 iter/s, 18.5129s/100 iter), loss = 1.87186
I0629 03:39:17.235819  5893 solver.cpp:371]     Train net output #0: loss = 1.79731 (* 1 = 1.79731 loss)
I0629 03:39:17.235823  5893 sgd_solver.cpp:137] Iteration 135800, lr = 0.0015125, m = 0.9
I0629 03:39:35.739781  5893 solver.cpp:349] Iteration 135900 (5.40443 iter/s, 18.5034s/100 iter), loss = 1.36284
I0629 03:39:35.739879  5893 solver.cpp:371]     Train net output #0: loss = 1.40395 (* 1 = 1.40395 loss)
I0629 03:39:35.739886  5893 sgd_solver.cpp:137] Iteration 135900, lr = 0.00150625, m = 0.9
I0629 03:39:54.033131  5893 solver.cpp:401] Sparsity after update:
I0629 03:39:54.038379  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:39:54.038388  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:39:54.038394  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:39:54.038398  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:39:54.038399  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:39:54.038401  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:39:54.038403  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:39:54.038406  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:39:54.038408  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:39:54.038410  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:39:54.038413  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:39:54.038414  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:39:54.038417  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:39:54.038424  5893 solver.cpp:545] Iteration 136000, Testing net (#0)
I0629 03:39:57.058797  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 03:40:18.340517  5888 data_reader.cpp:262] Starting prefetch of epoch 136
I0629 03:40:18.402659  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.56924
I0629 03:40:18.402679  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79792
I0629 03:40:18.402684  5893 solver.cpp:630]     Test net output #2: loss = 1.88076 (* 1 = 1.88076 loss)
I0629 03:40:18.402701  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3635s
I0629 03:40:18.593281  5893 solver.cpp:349] Iteration 136000 (2.33361 iter/s, 42.852s/100 iter), loss = 1.54035
I0629 03:40:18.593305  5893 solver.cpp:371]     Train net output #0: loss = 1.53498 (* 1 = 1.53498 loss)
I0629 03:40:18.593309  5893 sgd_solver.cpp:137] Iteration 136000, lr = 0.0015, m = 0.9
I0629 03:40:37.036630  5893 solver.cpp:349] Iteration 136100 (5.4222 iter/s, 18.4427s/100 iter), loss = 1.87584
I0629 03:40:37.036650  5893 solver.cpp:371]     Train net output #0: loss = 1.55924 (* 1 = 1.55924 loss)
I0629 03:40:37.036654  5893 sgd_solver.cpp:137] Iteration 136100, lr = 0.00149375, m = 0.9
I0629 03:40:55.446291  5893 solver.cpp:349] Iteration 136200 (5.43212 iter/s, 18.409s/100 iter), loss = 1.47513
I0629 03:40:55.446377  5893 solver.cpp:371]     Train net output #0: loss = 1.45488 (* 1 = 1.45488 loss)
I0629 03:40:55.446382  5893 sgd_solver.cpp:137] Iteration 136200, lr = 0.0014875, m = 0.9
I0629 03:41:13.870874  5893 solver.cpp:349] Iteration 136300 (5.42774 iter/s, 18.4239s/100 iter), loss = 1.79475
I0629 03:41:13.870898  5893 solver.cpp:371]     Train net output #0: loss = 1.90198 (* 1 = 1.90198 loss)
I0629 03:41:13.870903  5893 sgd_solver.cpp:137] Iteration 136300, lr = 0.00148125, m = 0.9
I0629 03:41:32.306615  5893 solver.cpp:349] Iteration 136400 (5.42444 iter/s, 18.4351s/100 iter), loss = 1.53376
I0629 03:41:32.306723  5893 solver.cpp:371]     Train net output #0: loss = 1.44797 (* 1 = 1.44797 loss)
I0629 03:41:32.306730  5893 sgd_solver.cpp:137] Iteration 136400, lr = 0.001475, m = 0.9
I0629 03:41:50.752647  5893 solver.cpp:349] Iteration 136500 (5.42143 iter/s, 18.4453s/100 iter), loss = 2.0382
I0629 03:41:50.752670  5893 solver.cpp:371]     Train net output #0: loss = 2.0966 (* 1 = 2.0966 loss)
I0629 03:41:50.752674  5893 sgd_solver.cpp:137] Iteration 136500, lr = 0.00146875, m = 0.9
I0629 03:42:09.186619  5893 solver.cpp:349] Iteration 136600 (5.42496 iter/s, 18.4333s/100 iter), loss = 1.48687
I0629 03:42:09.186700  5893 solver.cpp:371]     Train net output #0: loss = 1.35887 (* 1 = 1.35887 loss)
I0629 03:42:09.186705  5893 sgd_solver.cpp:137] Iteration 136600, lr = 0.0014625, m = 0.9
I0629 03:42:27.706322  5893 solver.cpp:349] Iteration 136700 (5.39986 iter/s, 18.519s/100 iter), loss = 1.42298
I0629 03:42:27.706344  5893 solver.cpp:371]     Train net output #0: loss = 1.21209 (* 1 = 1.21209 loss)
I0629 03:42:27.706347  5893 sgd_solver.cpp:137] Iteration 136700, lr = 0.00145625, m = 0.9
I0629 03:42:46.214988  5893 solver.cpp:349] Iteration 136800 (5.40306 iter/s, 18.508s/100 iter), loss = 1.45492
I0629 03:42:46.215090  5893 solver.cpp:371]     Train net output #0: loss = 1.4632 (* 1 = 1.4632 loss)
I0629 03:42:46.215096  5893 sgd_solver.cpp:137] Iteration 136800, lr = 0.00145, m = 0.9
I0629 03:43:04.693789  5893 solver.cpp:349] Iteration 136900 (5.41182 iter/s, 18.4781s/100 iter), loss = 1.65643
I0629 03:43:04.693811  5893 solver.cpp:371]     Train net output #0: loss = 1.89044 (* 1 = 1.89044 loss)
I0629 03:43:04.693815  5893 sgd_solver.cpp:137] Iteration 136900, lr = 0.00144375, m = 0.9
I0629 03:43:23.009363  5893 solver.cpp:401] Sparsity after update:
I0629 03:43:23.014575  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:43:23.014583  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:43:23.014590  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:43:23.014591  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:43:23.014595  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:43:23.014596  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:43:23.014598  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:43:23.014600  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:43:23.014601  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:43:23.014603  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:43:23.014605  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:43:23.014607  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:43:23.014609  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:43:23.014616  5893 solver.cpp:545] Iteration 137000, Testing net (#0)
I0629 03:43:47.140290  5888 data_reader.cpp:262] Starting prefetch of epoch 137
I0629 03:43:47.232259  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5718
I0629 03:43:47.232280  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7982
I0629 03:43:47.232285  5893 solver.cpp:630]     Test net output #2: loss = 1.87857 (* 1 = 1.87857 loss)
I0629 03:43:47.232300  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2169s
I0629 03:43:47.420590  5893 solver.cpp:349] Iteration 137000 (2.34053 iter/s, 42.7254s/100 iter), loss = 1.69484
I0629 03:43:47.420614  5893 solver.cpp:371]     Train net output #0: loss = 1.78145 (* 1 = 1.78145 loss)
I0629 03:43:47.420617  5893 sgd_solver.cpp:137] Iteration 137000, lr = 0.0014375, m = 0.9
I0629 03:44:05.871964  5893 solver.cpp:349] Iteration 137100 (5.41984 iter/s, 18.4507s/100 iter), loss = 1.5473
I0629 03:44:05.872076  5893 solver.cpp:371]     Train net output #0: loss = 1.72715 (* 1 = 1.72715 loss)
I0629 03:44:05.872082  5893 sgd_solver.cpp:137] Iteration 137100, lr = 0.00143125, m = 0.9
I0629 03:44:24.331393  5893 solver.cpp:349] Iteration 137200 (5.4175 iter/s, 18.4587s/100 iter), loss = 1.77913
I0629 03:44:24.331418  5893 solver.cpp:371]     Train net output #0: loss = 2.09511 (* 1 = 2.09511 loss)
I0629 03:44:24.331421  5893 sgd_solver.cpp:137] Iteration 137200, lr = 0.001425, m = 0.9
I0629 03:44:42.759907  5893 solver.cpp:349] Iteration 137300 (5.42657 iter/s, 18.4279s/100 iter), loss = 1.46934
I0629 03:44:42.759954  5893 solver.cpp:371]     Train net output #0: loss = 1.30576 (* 1 = 1.30576 loss)
I0629 03:44:42.759959  5893 sgd_solver.cpp:137] Iteration 137300, lr = 0.00141875, m = 0.9
I0629 03:45:01.194910  5893 solver.cpp:349] Iteration 137400 (5.42466 iter/s, 18.4343s/100 iter), loss = 1.85213
I0629 03:45:01.194929  5893 solver.cpp:371]     Train net output #0: loss = 1.37963 (* 1 = 1.37963 loss)
I0629 03:45:01.194933  5893 sgd_solver.cpp:137] Iteration 137400, lr = 0.0014125, m = 0.9
I0629 03:45:19.622102  5893 solver.cpp:349] Iteration 137500 (5.42695 iter/s, 18.4265s/100 iter), loss = 1.51703
I0629 03:45:19.622172  5893 solver.cpp:371]     Train net output #0: loss = 1.82848 (* 1 = 1.82848 loss)
I0629 03:45:19.622176  5893 sgd_solver.cpp:137] Iteration 137500, lr = 0.00140625, m = 0.9
I0629 03:45:38.040033  5893 solver.cpp:349] Iteration 137600 (5.4297 iter/s, 18.4172s/100 iter), loss = 1.66389
I0629 03:45:38.040052  5893 solver.cpp:371]     Train net output #0: loss = 1.62132 (* 1 = 1.62132 loss)
I0629 03:45:38.040056  5893 sgd_solver.cpp:137] Iteration 137600, lr = 0.0014, m = 0.9
I0629 03:45:56.523562  5893 solver.cpp:349] Iteration 137700 (5.41041 iter/s, 18.4829s/100 iter), loss = 1.15147
I0629 03:45:56.523665  5893 solver.cpp:371]     Train net output #0: loss = 1.40762 (* 1 = 1.40762 loss)
I0629 03:45:56.523672  5893 sgd_solver.cpp:137] Iteration 137700, lr = 0.00139375, m = 0.9
I0629 03:46:15.068472  5893 solver.cpp:349] Iteration 137800 (5.39253 iter/s, 18.5442s/100 iter), loss = 1.30147
I0629 03:46:15.068492  5893 solver.cpp:371]     Train net output #0: loss = 1.10922 (* 1 = 1.10922 loss)
I0629 03:46:15.068496  5893 sgd_solver.cpp:137] Iteration 137800, lr = 0.0013875, m = 0.9
I0629 03:46:33.563585  5893 solver.cpp:349] Iteration 137900 (5.40703 iter/s, 18.4945s/100 iter), loss = 1.33121
I0629 03:46:33.563660  5893 solver.cpp:371]     Train net output #0: loss = 1.41586 (* 1 = 1.41586 loss)
I0629 03:46:33.563665  5893 sgd_solver.cpp:137] Iteration 137900, lr = 0.00138125, m = 0.9
I0629 03:46:51.871896  5893 solver.cpp:401] Sparsity after update:
I0629 03:46:51.876504  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:46:51.876513  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:46:51.876518  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:46:51.876521  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:46:51.876523  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:46:51.876525  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:46:51.876528  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:46:51.876538  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:46:51.876540  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:46:51.876543  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:46:51.876544  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:46:51.876546  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:46:51.876549  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:46:51.876556  5893 solver.cpp:545] Iteration 138000, Testing net (#0)
I0629 03:47:16.129775  5888 data_reader.cpp:262] Starting prefetch of epoch 138
I0629 03:47:16.225894  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57164
I0629 03:47:16.225915  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79984
I0629 03:47:16.225920  5893 solver.cpp:630]     Test net output #2: loss = 1.87497 (* 1 = 1.87497 loss)
I0629 03:47:16.225936  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3486s
I0629 03:47:16.411810  5893 solver.cpp:349] Iteration 138000 (2.3339 iter/s, 42.8467s/100 iter), loss = 1.55677
I0629 03:47:16.411834  5893 solver.cpp:371]     Train net output #0: loss = 1.65064 (* 1 = 1.65064 loss)
I0629 03:47:16.411837  5893 sgd_solver.cpp:137] Iteration 138000, lr = 0.001375, m = 0.9
I0629 03:47:34.865466  5893 solver.cpp:349] Iteration 138100 (5.41918 iter/s, 18.453s/100 iter), loss = 1.30613
I0629 03:47:34.865489  5893 solver.cpp:371]     Train net output #0: loss = 1.39112 (* 1 = 1.39112 loss)
I0629 03:47:34.865494  5893 sgd_solver.cpp:137] Iteration 138100, lr = 0.00136875, m = 0.9
I0629 03:47:53.316403  5893 solver.cpp:349] Iteration 138200 (5.41997 iter/s, 18.4503s/100 iter), loss = 1.73845
I0629 03:47:53.316507  5893 solver.cpp:371]     Train net output #0: loss = 1.88767 (* 1 = 1.88767 loss)
I0629 03:47:53.316514  5893 sgd_solver.cpp:137] Iteration 138200, lr = 0.0013625, m = 0.9
I0629 03:48:11.781144  5893 solver.cpp:349] Iteration 138300 (5.41595 iter/s, 18.464s/100 iter), loss = 1.27852
I0629 03:48:11.781167  5893 solver.cpp:371]     Train net output #0: loss = 1.51121 (* 1 = 1.51121 loss)
I0629 03:48:11.781172  5893 sgd_solver.cpp:137] Iteration 138300, lr = 0.00135625, m = 0.9
I0629 03:48:30.211359  5893 solver.cpp:349] Iteration 138400 (5.42606 iter/s, 18.4296s/100 iter), loss = 1.38249
I0629 03:48:30.211462  5893 solver.cpp:371]     Train net output #0: loss = 1.459 (* 1 = 1.459 loss)
I0629 03:48:30.211468  5893 sgd_solver.cpp:137] Iteration 138400, lr = 0.00135, m = 0.9
I0629 03:48:48.640625  5893 solver.cpp:349] Iteration 138500 (5.42636 iter/s, 18.4286s/100 iter), loss = 1.71937
I0629 03:48:48.640647  5893 solver.cpp:371]     Train net output #0: loss = 1.87064 (* 1 = 1.87064 loss)
I0629 03:48:48.640651  5893 sgd_solver.cpp:137] Iteration 138500, lr = 0.00134375, m = 0.9
I0629 03:49:07.100395  5893 solver.cpp:349] Iteration 138600 (5.41737 iter/s, 18.4591s/100 iter), loss = 1.63159
I0629 03:49:07.100502  5893 solver.cpp:371]     Train net output #0: loss = 1.71948 (* 1 = 1.71948 loss)
I0629 03:49:07.100508  5893 sgd_solver.cpp:137] Iteration 138600, lr = 0.0013375, m = 0.9
I0629 03:49:25.642874  5893 solver.cpp:349] Iteration 138700 (5.39323 iter/s, 18.5418s/100 iter), loss = 1.63523
I0629 03:49:25.642897  5893 solver.cpp:371]     Train net output #0: loss = 1.52293 (* 1 = 1.52293 loss)
I0629 03:49:25.642901  5893 sgd_solver.cpp:137] Iteration 138700, lr = 0.00133125, m = 0.9
I0629 03:49:44.210747  5893 solver.cpp:349] Iteration 138800 (5.38583 iter/s, 18.5672s/100 iter), loss = 1.28513
I0629 03:49:44.210850  5893 solver.cpp:371]     Train net output #0: loss = 1.31409 (* 1 = 1.31409 loss)
I0629 03:49:44.210855  5893 sgd_solver.cpp:137] Iteration 138800, lr = 0.001325, m = 0.9
I0629 03:50:02.677052  5893 solver.cpp:349] Iteration 138900 (5.41548 iter/s, 18.4656s/100 iter), loss = 1.45833
I0629 03:50:02.677073  5893 solver.cpp:371]     Train net output #0: loss = 1.5916 (* 1 = 1.5916 loss)
I0629 03:50:02.677078  5893 sgd_solver.cpp:137] Iteration 138900, lr = 0.00131875, m = 0.9
I0629 03:50:20.961863  5893 solver.cpp:401] Sparsity after update:
I0629 03:50:20.967128  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:50:20.967134  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:50:20.967142  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:50:20.967147  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:50:20.967152  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:50:20.967156  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:50:20.967160  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:50:20.967164  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:50:20.967169  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:50:20.967171  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:50:20.967175  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:50:20.967180  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:50:20.967182  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:50:20.967195  5893 solver.cpp:545] Iteration 139000, Testing net (#0)
I0629 03:50:45.305025  5888 data_reader.cpp:262] Starting prefetch of epoch 139
I0629 03:50:45.393268  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57196
I0629 03:50:45.393290  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.7992
I0629 03:50:45.393295  5893 solver.cpp:630]     Test net output #2: loss = 1.87423 (* 1 = 1.87423 loss)
I0629 03:50:45.393311  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4253s
I0629 03:50:45.577868  5893 solver.cpp:349] Iteration 139000 (2.33103 iter/s, 42.8994s/100 iter), loss = 1.60597
I0629 03:50:45.577891  5893 solver.cpp:371]     Train net output #0: loss = 1.56114 (* 1 = 1.56114 loss)
I0629 03:50:45.577895  5893 sgd_solver.cpp:137] Iteration 139000, lr = 0.0013125, m = 0.9
I0629 03:51:04.015171  5893 solver.cpp:349] Iteration 139100 (5.42397 iter/s, 18.4367s/100 iter), loss = 1.58429
I0629 03:51:04.015234  5893 solver.cpp:371]     Train net output #0: loss = 1.73873 (* 1 = 1.73873 loss)
I0629 03:51:04.015241  5893 sgd_solver.cpp:137] Iteration 139100, lr = 0.00130625, m = 0.9
I0629 03:51:22.423992  5893 solver.cpp:349] Iteration 139200 (5.43238 iter/s, 18.4081s/100 iter), loss = 1.71678
I0629 03:51:22.424018  5893 solver.cpp:371]     Train net output #0: loss = 1.74687 (* 1 = 1.74687 loss)
I0629 03:51:22.424023  5893 sgd_solver.cpp:137] Iteration 139200, lr = 0.0013, m = 0.9
I0629 03:51:40.849246  5893 solver.cpp:349] Iteration 139300 (5.42752 iter/s, 18.4246s/100 iter), loss = 1.57508
I0629 03:51:40.849352  5893 solver.cpp:371]     Train net output #0: loss = 1.46655 (* 1 = 1.46655 loss)
I0629 03:51:40.849361  5893 sgd_solver.cpp:137] Iteration 139300, lr = 0.00129375, m = 0.9
I0629 03:51:59.295613  5893 solver.cpp:349] Iteration 139400 (5.42134 iter/s, 18.4456s/100 iter), loss = 1.49767
I0629 03:51:59.295635  5893 solver.cpp:371]     Train net output #0: loss = 1.32853 (* 1 = 1.32853 loss)
I0629 03:51:59.295639  5893 sgd_solver.cpp:137] Iteration 139400, lr = 0.0012875, m = 0.9
I0629 03:52:17.755069  5893 solver.cpp:349] Iteration 139500 (5.41746 iter/s, 18.4588s/100 iter), loss = 1.69214
I0629 03:52:17.755111  5893 solver.cpp:371]     Train net output #0: loss = 1.63538 (* 1 = 1.63538 loss)
I0629 03:52:17.755116  5893 sgd_solver.cpp:137] Iteration 139500, lr = 0.00128125, m = 0.9
I0629 03:52:36.185611  5893 solver.cpp:349] Iteration 139600 (5.42597 iter/s, 18.4299s/100 iter), loss = 1.77048
I0629 03:52:36.185633  5893 solver.cpp:371]     Train net output #0: loss = 1.68528 (* 1 = 1.68528 loss)
I0629 03:52:36.185637  5893 sgd_solver.cpp:137] Iteration 139600, lr = 0.001275, m = 0.9
I0629 03:52:54.809748  5893 solver.cpp:349] Iteration 139700 (5.36956 iter/s, 18.6235s/100 iter), loss = 1.38853
I0629 03:52:54.809823  5893 solver.cpp:371]     Train net output #0: loss = 1.45745 (* 1 = 1.45745 loss)
I0629 03:52:54.809828  5893 sgd_solver.cpp:137] Iteration 139700, lr = 0.00126875, m = 0.9
I0629 03:53:13.354692  5893 solver.cpp:349] Iteration 139800 (5.39251 iter/s, 18.5442s/100 iter), loss = 1.50989
I0629 03:53:13.354714  5893 solver.cpp:371]     Train net output #0: loss = 1.34056 (* 1 = 1.34056 loss)
I0629 03:53:13.354718  5893 sgd_solver.cpp:137] Iteration 139800, lr = 0.0012625, m = 0.9
I0629 03:53:31.909442  5893 solver.cpp:349] Iteration 139900 (5.38964 iter/s, 18.5541s/100 iter), loss = 1.42165
I0629 03:53:31.909543  5893 solver.cpp:371]     Train net output #0: loss = 1.21333 (* 1 = 1.21333 loss)
I0629 03:53:31.909554  5893 sgd_solver.cpp:137] Iteration 139900, lr = 0.00125625, m = 0.9
I0629 03:53:50.218051  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_140000.caffemodel
I0629 03:53:50.267679  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_140000.solverstate
I0629 03:53:50.272110  5893 solver.cpp:401] Sparsity after update:
I0629 03:53:50.275228  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:53:50.275239  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:53:50.275249  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:53:50.275252  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:53:50.275255  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:53:50.275259  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:53:50.275262  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:53:50.275265  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:53:50.275285  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:53:50.275288  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:53:50.275291  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:53:50.275300  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:53:50.275303  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:53:50.275318  5893 solver.cpp:545] Iteration 140000, Testing net (#0)
I0629 03:54:14.441814  5888 data_reader.cpp:262] Starting prefetch of epoch 140
I0629 03:54:14.543661  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57276
I0629 03:54:14.543682  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.800361
I0629 03:54:14.543687  5893 solver.cpp:630]     Test net output #2: loss = 1.87203 (* 1 = 1.87203 loss)
I0629 03:54:14.543704  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2676s
I0629 03:54:14.730836  5893 solver.cpp:349] Iteration 140000 (2.33536 iter/s, 42.8199s/100 iter), loss = 1.48319
I0629 03:54:14.730859  5893 solver.cpp:371]     Train net output #0: loss = 1.27915 (* 1 = 1.27915 loss)
I0629 03:54:14.730862  5893 sgd_solver.cpp:137] Iteration 140000, lr = 0.00125, m = 0.9
I0629 03:54:33.172065  5893 solver.cpp:349] Iteration 140100 (5.42282 iter/s, 18.4406s/100 iter), loss = 1.60013
I0629 03:54:33.172088  5893 solver.cpp:371]     Train net output #0: loss = 1.62943 (* 1 = 1.62943 loss)
I0629 03:54:33.172092  5893 sgd_solver.cpp:137] Iteration 140100, lr = 0.00124375, m = 0.9
I0629 03:54:37.909497  5875 data_reader.cpp:262] Starting prefetch of epoch 28
I0629 03:54:51.629681  5893 solver.cpp:349] Iteration 140200 (5.418 iter/s, 18.457s/100 iter), loss = 1.36376
I0629 03:54:51.629797  5893 solver.cpp:371]     Train net output #0: loss = 1.38534 (* 1 = 1.38534 loss)
I0629 03:54:51.629804  5893 sgd_solver.cpp:137] Iteration 140200, lr = 0.0012375, m = 0.9
I0629 03:55:10.038844  5893 solver.cpp:349] Iteration 140300 (5.43229 iter/s, 18.4084s/100 iter), loss = 1.45984
I0629 03:55:10.038866  5893 solver.cpp:371]     Train net output #0: loss = 1.40745 (* 1 = 1.40745 loss)
I0629 03:55:10.038871  5893 sgd_solver.cpp:137] Iteration 140300, lr = 0.00123125, m = 0.9
I0629 03:55:28.479071  5893 solver.cpp:349] Iteration 140400 (5.42311 iter/s, 18.4396s/100 iter), loss = 1.52573
I0629 03:55:28.479174  5893 solver.cpp:371]     Train net output #0: loss = 1.76328 (* 1 = 1.76328 loss)
I0629 03:55:28.479182  5893 sgd_solver.cpp:137] Iteration 140400, lr = 0.001225, m = 0.9
I0629 03:55:46.890516  5893 solver.cpp:349] Iteration 140500 (5.43161 iter/s, 18.4107s/100 iter), loss = 1.82191
I0629 03:55:46.890540  5893 solver.cpp:371]     Train net output #0: loss = 1.72096 (* 1 = 1.72096 loss)
I0629 03:55:46.890544  5893 sgd_solver.cpp:137] Iteration 140500, lr = 0.00121875, m = 0.9
I0629 03:56:05.382483  5893 solver.cpp:349] Iteration 140600 (5.40794 iter/s, 18.4913s/100 iter), loss = 1.33763
I0629 03:56:05.382589  5893 solver.cpp:371]     Train net output #0: loss = 1.47324 (* 1 = 1.47324 loss)
I0629 03:56:05.382596  5893 sgd_solver.cpp:137] Iteration 140600, lr = 0.0012125, m = 0.9
I0629 03:56:23.880254  5893 solver.cpp:349] Iteration 140700 (5.40627 iter/s, 18.497s/100 iter), loss = 1.70508
I0629 03:56:23.880277  5893 solver.cpp:371]     Train net output #0: loss = 1.5535 (* 1 = 1.5535 loss)
I0629 03:56:23.880281  5893 sgd_solver.cpp:137] Iteration 140700, lr = 0.00120625, m = 0.9
I0629 03:56:42.365025  5893 solver.cpp:349] Iteration 140800 (5.41005 iter/s, 18.4841s/100 iter), loss = 1.47454
I0629 03:56:42.365139  5893 solver.cpp:371]     Train net output #0: loss = 1.52296 (* 1 = 1.52296 loss)
I0629 03:56:42.365145  5893 sgd_solver.cpp:137] Iteration 140800, lr = 0.0012, m = 0.9
I0629 03:57:00.814682  5893 solver.cpp:349] Iteration 140900 (5.42037 iter/s, 18.4489s/100 iter), loss = 1.62939
I0629 03:57:00.814705  5893 solver.cpp:371]     Train net output #0: loss = 1.42493 (* 1 = 1.42493 loss)
I0629 03:57:00.814709  5893 sgd_solver.cpp:137] Iteration 140900, lr = 0.00119375, m = 0.9
I0629 03:57:19.080101  5893 solver.cpp:401] Sparsity after update:
I0629 03:57:19.085311  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 03:57:19.085328  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 03:57:19.085336  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 03:57:19.085340  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 03:57:19.085343  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 03:57:19.085346  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 03:57:19.085350  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 03:57:19.085355  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 03:57:19.085358  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 03:57:19.085363  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 03:57:19.085367  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 03:57:19.085371  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 03:57:19.085376  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 03:57:19.085387  5893 solver.cpp:545] Iteration 141000, Testing net (#0)
I0629 03:57:22.175344  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 03:57:43.490244  5888 data_reader.cpp:262] Starting prefetch of epoch 141
I0629 03:57:43.552080  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57172
I0629 03:57:43.552105  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.798921
I0629 03:57:43.552110  5893 solver.cpp:630]     Test net output #2: loss = 1.87354 (* 1 = 1.87354 loss)
I0629 03:57:43.552125  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4659s
I0629 03:57:43.737015  5893 solver.cpp:349] Iteration 141000 (2.32987 iter/s, 42.9209s/100 iter), loss = 1.67989
I0629 03:57:43.737035  5893 solver.cpp:371]     Train net output #0: loss = 1.67727 (* 1 = 1.67727 loss)
I0629 03:57:43.737040  5893 sgd_solver.cpp:137] Iteration 141000, lr = 0.0011875, m = 0.9
I0629 03:58:02.169637  5893 solver.cpp:349] Iteration 141100 (5.42535 iter/s, 18.432s/100 iter), loss = 1.52545
I0629 03:58:02.169677  5893 solver.cpp:371]     Train net output #0: loss = 1.69329 (* 1 = 1.69329 loss)
I0629 03:58:02.169682  5893 sgd_solver.cpp:137] Iteration 141100, lr = 0.00118125, m = 0.9
I0629 03:58:20.582842  5893 solver.cpp:349] Iteration 141200 (5.43108 iter/s, 18.4125s/100 iter), loss = 1.61016
I0629 03:58:20.582864  5893 solver.cpp:371]     Train net output #0: loss = 1.50431 (* 1 = 1.50431 loss)
I0629 03:58:20.582868  5893 sgd_solver.cpp:137] Iteration 141200, lr = 0.001175, m = 0.9
I0629 03:58:39.055322  5893 solver.cpp:349] Iteration 141300 (5.41365 iter/s, 18.4718s/100 iter), loss = 1.69447
I0629 03:58:39.055418  5893 solver.cpp:371]     Train net output #0: loss = 1.78456 (* 1 = 1.78456 loss)
I0629 03:58:39.055423  5893 sgd_solver.cpp:137] Iteration 141300, lr = 0.00116875, m = 0.9
I0629 03:58:57.505169  5893 solver.cpp:349] Iteration 141400 (5.42031 iter/s, 18.4491s/100 iter), loss = 1.18612
I0629 03:58:57.505192  5893 solver.cpp:371]     Train net output #0: loss = 1.09416 (* 1 = 1.09416 loss)
I0629 03:58:57.505197  5893 sgd_solver.cpp:137] Iteration 141400, lr = 0.0011625, m = 0.9
I0629 03:59:15.982754  5893 solver.cpp:349] Iteration 141500 (5.41215 iter/s, 18.4769s/100 iter), loss = 1.6488
I0629 03:59:15.982848  5893 solver.cpp:371]     Train net output #0: loss = 1.60873 (* 1 = 1.60873 loss)
I0629 03:59:15.982854  5893 sgd_solver.cpp:137] Iteration 141500, lr = 0.00115625, m = 0.9
I0629 03:59:34.423372  5893 solver.cpp:349] Iteration 141600 (5.42302 iter/s, 18.4399s/100 iter), loss = 1.76777
I0629 03:59:34.423399  5893 solver.cpp:371]     Train net output #0: loss = 1.5718 (* 1 = 1.5718 loss)
I0629 03:59:34.423404  5893 sgd_solver.cpp:137] Iteration 141600, lr = 0.00115, m = 0.9
I0629 03:59:52.957262  5893 solver.cpp:349] Iteration 141700 (5.39571 iter/s, 18.5332s/100 iter), loss = 1.61663
I0629 03:59:52.957370  5893 solver.cpp:371]     Train net output #0: loss = 1.68829 (* 1 = 1.68829 loss)
I0629 03:59:52.957376  5893 sgd_solver.cpp:137] Iteration 141700, lr = 0.00114375, m = 0.9
I0629 04:00:11.464474  5893 solver.cpp:349] Iteration 141800 (5.40351 iter/s, 18.5065s/100 iter), loss = 1.68832
I0629 04:00:11.464494  5893 solver.cpp:371]     Train net output #0: loss = 1.80839 (* 1 = 1.80839 loss)
I0629 04:00:11.464498  5893 sgd_solver.cpp:137] Iteration 141800, lr = 0.0011375, m = 0.9
I0629 04:00:29.981228  5893 solver.cpp:349] Iteration 141900 (5.4007 iter/s, 18.5161s/100 iter), loss = 1.40748
I0629 04:00:29.981273  5893 solver.cpp:371]     Train net output #0: loss = 1.49324 (* 1 = 1.49324 loss)
I0629 04:00:29.981277  5893 sgd_solver.cpp:137] Iteration 141900, lr = 0.00113125, m = 0.9
I0629 04:00:48.305480  5893 solver.cpp:401] Sparsity after update:
I0629 04:00:48.310748  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:00:48.310757  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:00:48.310767  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:00:48.310772  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:00:48.310776  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:00:48.310781  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:00:48.310784  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:00:48.310789  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:00:48.310792  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:00:48.310796  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:00:48.310801  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:00:48.310803  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:00:48.310807  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:00:48.310819  5893 solver.cpp:545] Iteration 142000, Testing net (#0)
I0629 04:01:12.722991  5888 data_reader.cpp:262] Starting prefetch of epoch 142
I0629 04:01:12.845579  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57432
I0629 04:01:12.845598  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80208
I0629 04:01:12.845603  5893 solver.cpp:630]     Test net output #2: loss = 1.86991 (* 1 = 1.86991 loss)
I0629 04:01:12.845618  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.534s
I0629 04:01:13.030378  5893 solver.cpp:349] Iteration 142000 (2.32301 iter/s, 43.0477s/100 iter), loss = 1.31747
I0629 04:01:13.030395  5893 solver.cpp:371]     Train net output #0: loss = 1.27974 (* 1 = 1.27974 loss)
I0629 04:01:13.030400  5893 sgd_solver.cpp:137] Iteration 142000, lr = 0.001125, m = 0.9
I0629 04:01:31.463713  5893 solver.cpp:349] Iteration 142100 (5.42514 iter/s, 18.4327s/100 iter), loss = 1.37196
I0629 04:01:31.463737  5893 solver.cpp:371]     Train net output #0: loss = 1.16296 (* 1 = 1.16296 loss)
I0629 04:01:31.463742  5893 sgd_solver.cpp:137] Iteration 142100, lr = 0.00111875, m = 0.9
I0629 04:01:49.946907  5893 solver.cpp:349] Iteration 142200 (5.41051 iter/s, 18.4825s/100 iter), loss = 1.36767
I0629 04:01:49.946981  5893 solver.cpp:371]     Train net output #0: loss = 1.39496 (* 1 = 1.39496 loss)
I0629 04:01:49.946988  5893 sgd_solver.cpp:137] Iteration 142200, lr = 0.0011125, m = 0.9
I0629 04:02:08.398771  5893 solver.cpp:349] Iteration 142300 (5.41972 iter/s, 18.4512s/100 iter), loss = 1.67563
I0629 04:02:08.398793  5893 solver.cpp:371]     Train net output #0: loss = 1.76061 (* 1 = 1.76061 loss)
I0629 04:02:08.398797  5893 sgd_solver.cpp:137] Iteration 142300, lr = 0.00110625, m = 0.9
I0629 04:02:26.824049  5893 solver.cpp:349] Iteration 142400 (5.42752 iter/s, 18.4246s/100 iter), loss = 1.58632
I0629 04:02:26.824144  5893 solver.cpp:371]     Train net output #0: loss = 1.47103 (* 1 = 1.47103 loss)
I0629 04:02:26.824149  5893 sgd_solver.cpp:137] Iteration 142400, lr = 0.0011, m = 0.9
I0629 04:02:45.270757  5893 solver.cpp:349] Iteration 142500 (5.42124 iter/s, 18.446s/100 iter), loss = 1.36845
I0629 04:02:45.270779  5893 solver.cpp:371]     Train net output #0: loss = 1.42032 (* 1 = 1.42032 loss)
I0629 04:02:45.270783  5893 sgd_solver.cpp:137] Iteration 142500, lr = 0.00109375, m = 0.9
I0629 04:03:03.725380  5893 solver.cpp:349] Iteration 142600 (5.41889 iter/s, 18.454s/100 iter), loss = 1.51289
I0629 04:03:03.725466  5893 solver.cpp:371]     Train net output #0: loss = 1.72672 (* 1 = 1.72672 loss)
I0629 04:03:03.725471  5893 sgd_solver.cpp:137] Iteration 142600, lr = 0.0010875, m = 0.9
I0629 04:03:22.203485  5893 solver.cpp:349] Iteration 142700 (5.41202 iter/s, 18.4774s/100 iter), loss = 1.63481
I0629 04:03:22.203506  5893 solver.cpp:371]     Train net output #0: loss = 1.38812 (* 1 = 1.38812 loss)
I0629 04:03:22.203510  5893 sgd_solver.cpp:137] Iteration 142700, lr = 0.00108125, m = 0.9
I0629 04:03:40.700013  5893 solver.cpp:349] Iteration 142800 (5.40661 iter/s, 18.4959s/100 iter), loss = 1.41834
I0629 04:03:40.700122  5893 solver.cpp:371]     Train net output #0: loss = 1.50437 (* 1 = 1.50437 loss)
I0629 04:03:40.700129  5893 sgd_solver.cpp:137] Iteration 142800, lr = 0.001075, m = 0.9
I0629 04:03:59.196724  5893 solver.cpp:349] Iteration 142900 (5.40659 iter/s, 18.496s/100 iter), loss = 1.62663
I0629 04:03:59.196746  5893 solver.cpp:371]     Train net output #0: loss = 1.44646 (* 1 = 1.44646 loss)
I0629 04:03:59.196750  5893 sgd_solver.cpp:137] Iteration 142900, lr = 0.00106875, m = 0.9
I0629 04:04:17.531877  5893 solver.cpp:401] Sparsity after update:
I0629 04:04:17.537075  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:04:17.537083  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:04:17.537089  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:04:17.537091  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:04:17.537094  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:04:17.537096  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:04:17.537097  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:04:17.537099  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:04:17.537101  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:04:17.537103  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:04:17.537106  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:04:17.537107  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:04:17.537109  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:04:17.537117  5893 solver.cpp:545] Iteration 143000, Testing net (#0)
I0629 04:04:41.809382  5888 data_reader.cpp:262] Starting prefetch of epoch 143
I0629 04:04:41.903352  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57372
I0629 04:04:41.903374  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80116
I0629 04:04:41.903379  5893 solver.cpp:630]     Test net output #2: loss = 1.86961 (* 1 = 1.86961 loss)
I0629 04:04:41.903394  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3655s
I0629 04:04:42.088595  5893 solver.cpp:349] Iteration 143000 (2.33152 iter/s, 42.8904s/100 iter), loss = 1.59422
I0629 04:04:42.088618  5893 solver.cpp:371]     Train net output #0: loss = 1.65791 (* 1 = 1.65791 loss)
I0629 04:04:42.088621  5893 sgd_solver.cpp:137] Iteration 143000, lr = 0.0010625, m = 0.9
I0629 04:05:00.516120  5893 solver.cpp:349] Iteration 143100 (5.42686 iter/s, 18.4269s/100 iter), loss = 1.50178
I0629 04:05:00.516173  5893 solver.cpp:371]     Train net output #0: loss = 1.61057 (* 1 = 1.61057 loss)
I0629 04:05:00.516180  5893 sgd_solver.cpp:137] Iteration 143100, lr = 0.00105625, m = 0.9
I0629 04:05:18.951715  5893 solver.cpp:349] Iteration 143200 (5.42449 iter/s, 18.4349s/100 iter), loss = 1.46565
I0629 04:05:18.951736  5893 solver.cpp:371]     Train net output #0: loss = 1.58865 (* 1 = 1.58865 loss)
I0629 04:05:18.951740  5893 sgd_solver.cpp:137] Iteration 143200, lr = 0.00105, m = 0.9
I0629 04:05:37.379310  5893 solver.cpp:349] Iteration 143300 (5.42684 iter/s, 18.4269s/100 iter), loss = 1.75763
I0629 04:05:37.379415  5893 solver.cpp:371]     Train net output #0: loss = 2.0304 (* 1 = 2.0304 loss)
I0629 04:05:37.379422  5893 sgd_solver.cpp:137] Iteration 143300, lr = 0.00104375, m = 0.9
I0629 04:05:55.800950  5893 solver.cpp:349] Iteration 143400 (5.42862 iter/s, 18.4209s/100 iter), loss = 1.19934
I0629 04:05:55.800973  5893 solver.cpp:371]     Train net output #0: loss = 1.26112 (* 1 = 1.26112 loss)
I0629 04:05:55.800979  5893 sgd_solver.cpp:137] Iteration 143400, lr = 0.0010375, m = 0.9
I0629 04:06:14.230914  5893 solver.cpp:349] Iteration 143500 (5.42608 iter/s, 18.4295s/100 iter), loss = 1.65582
I0629 04:06:14.231019  5893 solver.cpp:371]     Train net output #0: loss = 1.87069 (* 1 = 1.87069 loss)
I0629 04:06:14.231025  5893 sgd_solver.cpp:137] Iteration 143500, lr = 0.00103125, m = 0.9
I0629 04:06:32.680338  5893 solver.cpp:349] Iteration 143600 (5.42036 iter/s, 18.449s/100 iter), loss = 1.47759
I0629 04:06:32.680361  5893 solver.cpp:371]     Train net output #0: loss = 1.6148 (* 1 = 1.6148 loss)
I0629 04:06:32.680366  5893 sgd_solver.cpp:137] Iteration 143600, lr = 0.001025, m = 0.9
I0629 04:06:51.162531  5893 solver.cpp:349] Iteration 143700 (5.41072 iter/s, 18.4818s/100 iter), loss = 1.46418
I0629 04:06:51.162623  5893 solver.cpp:371]     Train net output #0: loss = 1.481 (* 1 = 1.481 loss)
I0629 04:06:51.162629  5893 sgd_solver.cpp:137] Iteration 143700, lr = 0.00101875, m = 0.9
I0629 04:07:09.683650  5893 solver.cpp:349] Iteration 143800 (5.39938 iter/s, 18.5207s/100 iter), loss = 1.53964
I0629 04:07:09.683675  5893 solver.cpp:371]     Train net output #0: loss = 1.92093 (* 1 = 1.92093 loss)
I0629 04:07:09.683681  5893 sgd_solver.cpp:137] Iteration 143800, lr = 0.0010125, m = 0.9
I0629 04:07:28.205773  5893 solver.cpp:349] Iteration 143900 (5.39906 iter/s, 18.5217s/100 iter), loss = 1.59545
I0629 04:07:28.205876  5893 solver.cpp:371]     Train net output #0: loss = 1.6574 (* 1 = 1.6574 loss)
I0629 04:07:28.205883  5893 sgd_solver.cpp:137] Iteration 143900, lr = 0.00100625, m = 0.9
I0629 04:07:46.517267  5893 solver.cpp:401] Sparsity after update:
I0629 04:07:46.522531  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:07:46.522541  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:07:46.522548  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:07:46.522552  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:07:46.522555  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:07:46.522558  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:07:46.522562  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:07:46.522564  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:07:46.522567  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:07:46.522572  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:07:46.522574  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:07:46.522578  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:07:46.522583  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:07:46.522593  5893 solver.cpp:545] Iteration 144000, Testing net (#0)
I0629 04:08:10.980304  5888 data_reader.cpp:262] Starting prefetch of epoch 144
I0629 04:08:11.076504  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57504
I0629 04:08:11.076524  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.79972
I0629 04:08:11.076529  5893 solver.cpp:630]     Test net output #2: loss = 1.86811 (* 1 = 1.86811 loss)
I0629 04:08:11.076547  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5535s
I0629 04:08:11.260993  5893 solver.cpp:349] Iteration 144000 (2.32265 iter/s, 43.0543s/100 iter), loss = 1.40261
I0629 04:08:11.261015  5893 solver.cpp:371]     Train net output #0: loss = 1.70791 (* 1 = 1.70791 loss)
I0629 04:08:11.261019  5893 sgd_solver.cpp:137] Iteration 144000, lr = 0.001, m = 0.9
I0629 04:08:29.716652  5893 solver.cpp:349] Iteration 144100 (5.41851 iter/s, 18.4553s/100 iter), loss = 1.34607
I0629 04:08:29.716675  5893 solver.cpp:371]     Train net output #0: loss = 1.38183 (* 1 = 1.38183 loss)
I0629 04:08:29.716680  5893 sgd_solver.cpp:137] Iteration 144100, lr = 0.00099375, m = 0.9
I0629 04:08:48.170502  5893 solver.cpp:349] Iteration 144200 (5.41904 iter/s, 18.4535s/100 iter), loss = 1.47997
I0629 04:08:48.170624  5893 solver.cpp:371]     Train net output #0: loss = 1.46055 (* 1 = 1.46055 loss)
I0629 04:08:48.170630  5893 sgd_solver.cpp:137] Iteration 144200, lr = 0.0009875, m = 0.9
I0629 04:09:06.605290  5893 solver.cpp:349] Iteration 144300 (5.42467 iter/s, 18.4343s/100 iter), loss = 1.40872
I0629 04:09:06.605314  5893 solver.cpp:371]     Train net output #0: loss = 1.39335 (* 1 = 1.39335 loss)
I0629 04:09:06.605317  5893 sgd_solver.cpp:137] Iteration 144300, lr = 0.00098125, m = 0.9
I0629 04:09:25.068039  5893 solver.cpp:349] Iteration 144400 (5.41643 iter/s, 18.4624s/100 iter), loss = 1.39231
I0629 04:09:25.068106  5893 solver.cpp:371]     Train net output #0: loss = 1.56141 (* 1 = 1.56141 loss)
I0629 04:09:25.068111  5893 sgd_solver.cpp:137] Iteration 144400, lr = 0.000975, m = 0.9
I0629 04:09:43.485344  5893 solver.cpp:349] Iteration 144500 (5.42981 iter/s, 18.4169s/100 iter), loss = 1.58129
I0629 04:09:43.485368  5893 solver.cpp:371]     Train net output #0: loss = 1.35869 (* 1 = 1.35869 loss)
I0629 04:09:43.485374  5893 sgd_solver.cpp:137] Iteration 144500, lr = 0.00096875, m = 0.9
I0629 04:10:01.938973  5893 solver.cpp:349] Iteration 144600 (5.41911 iter/s, 18.4532s/100 iter), loss = 1.1416
I0629 04:10:01.939050  5893 solver.cpp:371]     Train net output #0: loss = 1.18587 (* 1 = 1.18587 loss)
I0629 04:10:01.939055  5893 sgd_solver.cpp:137] Iteration 144600, lr = 0.0009625, m = 0.9
I0629 04:10:20.457787  5893 solver.cpp:349] Iteration 144700 (5.40005 iter/s, 18.5183s/100 iter), loss = 1.48703
I0629 04:10:20.457813  5893 solver.cpp:371]     Train net output #0: loss = 1.53554 (* 1 = 1.53554 loss)
I0629 04:10:20.457819  5893 sgd_solver.cpp:137] Iteration 144700, lr = 0.00095625, m = 0.9
I0629 04:10:38.948967  5893 solver.cpp:349] Iteration 144800 (5.40811 iter/s, 18.4908s/100 iter), loss = 1.64292
I0629 04:10:38.949069  5893 solver.cpp:371]     Train net output #0: loss = 1.7526 (* 1 = 1.7526 loss)
I0629 04:10:38.949075  5893 sgd_solver.cpp:137] Iteration 144800, lr = 0.00095, m = 0.9
I0629 04:10:57.447051  5893 solver.cpp:349] Iteration 144900 (5.40611 iter/s, 18.4976s/100 iter), loss = 1.32255
I0629 04:10:57.447072  5893 solver.cpp:371]     Train net output #0: loss = 1.15356 (* 1 = 1.15356 loss)
I0629 04:10:57.447077  5893 sgd_solver.cpp:137] Iteration 144900, lr = 0.00094375, m = 0.9
I0629 04:11:15.789744  5893 solver.cpp:401] Sparsity after update:
I0629 04:11:15.795315  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:11:15.795325  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:11:15.795333  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:11:15.795337  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:11:15.795341  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:11:15.795343  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:11:15.795346  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:11:15.795351  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:11:15.795353  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:11:15.795356  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:11:15.795359  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:11:15.795362  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:11:15.795367  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:11:15.795382  5893 solver.cpp:545] Iteration 145000, Testing net (#0)
I0629 04:11:40.127974  5888 data_reader.cpp:262] Starting prefetch of epoch 145
I0629 04:11:40.439677  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57408
I0629 04:11:40.439697  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80084
I0629 04:11:40.439702  5893 solver.cpp:630]     Test net output #2: loss = 1.86712 (* 1 = 1.86712 loss)
I0629 04:11:40.439719  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6438s
I0629 04:11:40.625934  5893 solver.cpp:349] Iteration 145000 (2.316 iter/s, 43.178s/100 iter), loss = 1.54088
I0629 04:11:40.625957  5893 solver.cpp:371]     Train net output #0: loss = 1.88904 (* 1 = 1.88904 loss)
I0629 04:11:40.625962  5893 sgd_solver.cpp:137] Iteration 145000, lr = 0.0009375, m = 0.9
I0629 04:11:59.063136  5893 solver.cpp:349] Iteration 145100 (5.42394 iter/s, 18.4368s/100 iter), loss = 1.52352
I0629 04:11:59.063246  5893 solver.cpp:371]     Train net output #0: loss = 1.33422 (* 1 = 1.33422 loss)
I0629 04:11:59.063252  5893 sgd_solver.cpp:137] Iteration 145100, lr = 0.00093125, m = 0.9
I0629 04:12:04.635447  5875 data_reader.cpp:262] Starting prefetch of epoch 29
I0629 04:12:17.475781  5893 solver.cpp:349] Iteration 145200 (5.4312 iter/s, 18.4121s/100 iter), loss = 1.56645
I0629 04:12:17.475805  5893 solver.cpp:371]     Train net output #0: loss = 1.92415 (* 1 = 1.92415 loss)
I0629 04:12:17.475808  5893 sgd_solver.cpp:137] Iteration 145200, lr = 0.000925, m = 0.9
I0629 04:12:35.918547  5893 solver.cpp:349] Iteration 145300 (5.42231 iter/s, 18.4423s/100 iter), loss = 1.36197
I0629 04:12:35.918648  5893 solver.cpp:371]     Train net output #0: loss = 1.40339 (* 1 = 1.40339 loss)
I0629 04:12:35.918654  5893 sgd_solver.cpp:137] Iteration 145300, lr = 0.00091875, m = 0.9
I0629 04:12:54.352824  5893 solver.cpp:349] Iteration 145400 (5.42483 iter/s, 18.4338s/100 iter), loss = 1.70253
I0629 04:12:54.352847  5893 solver.cpp:371]     Train net output #0: loss = 1.98911 (* 1 = 1.98911 loss)
I0629 04:12:54.352851  5893 sgd_solver.cpp:137] Iteration 145400, lr = 0.0009125, m = 0.9
I0629 04:13:12.763900  5893 solver.cpp:349] Iteration 145500 (5.43164 iter/s, 18.4106s/100 iter), loss = 1.59457
I0629 04:13:12.764004  5893 solver.cpp:371]     Train net output #0: loss = 1.76644 (* 1 = 1.76644 loss)
I0629 04:13:12.764011  5893 sgd_solver.cpp:137] Iteration 145500, lr = 0.00090625, m = 0.9
I0629 04:13:31.201537  5893 solver.cpp:349] Iteration 145600 (5.42384 iter/s, 18.4371s/100 iter), loss = 1.46457
I0629 04:13:31.201565  5893 solver.cpp:371]     Train net output #0: loss = 1.2201 (* 1 = 1.2201 loss)
I0629 04:13:31.201570  5893 sgd_solver.cpp:137] Iteration 145600, lr = 0.0009, m = 0.9
I0629 04:13:49.662786  5893 solver.cpp:349] Iteration 145700 (5.41689 iter/s, 18.4608s/100 iter), loss = 1.86177
I0629 04:13:49.662830  5893 solver.cpp:371]     Train net output #0: loss = 2.03915 (* 1 = 2.03915 loss)
I0629 04:13:49.662834  5893 sgd_solver.cpp:137] Iteration 145700, lr = 0.00089375, m = 0.9
I0629 04:14:08.148150  5893 solver.cpp:349] Iteration 145800 (5.40982 iter/s, 18.4849s/100 iter), loss = 1.54862
I0629 04:14:08.148174  5893 solver.cpp:371]     Train net output #0: loss = 1.80813 (* 1 = 1.80813 loss)
I0629 04:14:08.148177  5893 sgd_solver.cpp:137] Iteration 145800, lr = 0.0008875, m = 0.9
I0629 04:14:26.652606  5893 solver.cpp:349] Iteration 145900 (5.40424 iter/s, 18.504s/100 iter), loss = 1.43824
I0629 04:14:26.652705  5893 solver.cpp:371]     Train net output #0: loss = 1.31136 (* 1 = 1.31136 loss)
I0629 04:14:26.652711  5893 sgd_solver.cpp:137] Iteration 145900, lr = 0.00088125, m = 0.9
I0629 04:14:44.979404  5893 solver.cpp:401] Sparsity after update:
I0629 04:14:44.984583  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:14:44.984591  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:14:44.984597  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:14:44.984599  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:14:44.984601  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:14:44.984603  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:14:44.984606  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:14:44.984607  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:14:44.984609  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:14:44.984611  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:14:44.984613  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:14:44.984616  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:14:44.984617  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:14:44.984624  5893 solver.cpp:545] Iteration 146000, Testing net (#0)
I0629 04:14:48.162736  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 04:15:09.361968  5888 data_reader.cpp:262] Starting prefetch of epoch 146
I0629 04:15:09.424191  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57304
I0629 04:15:09.424214  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8016
I0629 04:15:09.424219  5893 solver.cpp:630]     Test net output #2: loss = 1.86622 (* 1 = 1.86622 loss)
I0629 04:15:09.424235  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.439s
I0629 04:15:09.609494  5893 solver.cpp:349] Iteration 146000 (2.32798 iter/s, 42.9558s/100 iter), loss = 1.42724
I0629 04:15:09.609515  5893 solver.cpp:371]     Train net output #0: loss = 1.25534 (* 1 = 1.25534 loss)
I0629 04:15:09.609519  5893 sgd_solver.cpp:137] Iteration 146000, lr = 0.000875, m = 0.9
I0629 04:15:28.033259  5893 solver.cpp:349] Iteration 146100 (5.42791 iter/s, 18.4233s/100 iter), loss = 1.64341
I0629 04:15:28.033278  5893 solver.cpp:371]     Train net output #0: loss = 1.6206 (* 1 = 1.6206 loss)
I0629 04:15:28.033282  5893 sgd_solver.cpp:137] Iteration 146100, lr = 0.00086875, m = 0.9
I0629 04:15:46.461272  5893 solver.cpp:349] Iteration 146200 (5.42666 iter/s, 18.4275s/100 iter), loss = 1.36744
I0629 04:15:46.461346  5893 solver.cpp:371]     Train net output #0: loss = 1.29146 (* 1 = 1.29146 loss)
I0629 04:15:46.461354  5893 sgd_solver.cpp:137] Iteration 146200, lr = 0.0008625, m = 0.9
I0629 04:16:04.896327  5893 solver.cpp:349] Iteration 146300 (5.42461 iter/s, 18.4345s/100 iter), loss = 1.54783
I0629 04:16:04.896353  5893 solver.cpp:371]     Train net output #0: loss = 1.347 (* 1 = 1.347 loss)
I0629 04:16:04.896358  5893 sgd_solver.cpp:137] Iteration 146300, lr = 0.00085625, m = 0.9
I0629 04:16:23.311275  5893 solver.cpp:349] Iteration 146400 (5.43051 iter/s, 18.4145s/100 iter), loss = 1.34118
I0629 04:16:23.311375  5893 solver.cpp:371]     Train net output #0: loss = 1.55018 (* 1 = 1.55018 loss)
I0629 04:16:23.311381  5893 sgd_solver.cpp:137] Iteration 146400, lr = 0.00085, m = 0.9
I0629 04:16:41.734622  5893 solver.cpp:349] Iteration 146500 (5.42806 iter/s, 18.4228s/100 iter), loss = 1.42628
I0629 04:16:41.734647  5893 solver.cpp:371]     Train net output #0: loss = 1.49009 (* 1 = 1.49009 loss)
I0629 04:16:41.734650  5893 sgd_solver.cpp:137] Iteration 146500, lr = 0.00084375, m = 0.9
I0629 04:17:00.162300  5893 solver.cpp:349] Iteration 146600 (5.42676 iter/s, 18.4272s/100 iter), loss = 1.59306
I0629 04:17:00.162402  5893 solver.cpp:371]     Train net output #0: loss = 1.19062 (* 1 = 1.19062 loss)
I0629 04:17:00.162408  5893 sgd_solver.cpp:137] Iteration 146600, lr = 0.0008375, m = 0.9
I0629 04:17:18.764292  5893 solver.cpp:349] Iteration 146700 (5.37594 iter/s, 18.6014s/100 iter), loss = 1.49209
I0629 04:17:18.764314  5893 solver.cpp:371]     Train net output #0: loss = 1.45615 (* 1 = 1.45615 loss)
I0629 04:17:18.764318  5893 sgd_solver.cpp:137] Iteration 146700, lr = 0.00083125, m = 0.9
I0629 04:17:37.328699  5893 solver.cpp:349] Iteration 146800 (5.3868 iter/s, 18.5639s/100 iter), loss = 1.42502
I0629 04:17:37.328804  5893 solver.cpp:371]     Train net output #0: loss = 1.38603 (* 1 = 1.38603 loss)
I0629 04:17:37.328811  5893 sgd_solver.cpp:137] Iteration 146800, lr = 0.000825, m = 0.9
I0629 04:17:55.834403  5893 solver.cpp:349] Iteration 146900 (5.40391 iter/s, 18.5051s/100 iter), loss = 1.41296
I0629 04:17:55.834426  5893 solver.cpp:371]     Train net output #0: loss = 1.5537 (* 1 = 1.5537 loss)
I0629 04:17:55.834430  5893 sgd_solver.cpp:137] Iteration 146900, lr = 0.00081875, m = 0.9
I0629 04:18:14.132644  5893 solver.cpp:401] Sparsity after update:
I0629 04:18:14.137908  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:18:14.137917  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:18:14.137923  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:18:14.137925  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:18:14.137928  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:18:14.137929  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:18:14.137931  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:18:14.137933  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:18:14.137935  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:18:14.137938  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:18:14.137939  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:18:14.137940  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:18:14.137943  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:18:14.137949  5893 solver.cpp:545] Iteration 147000, Testing net (#0)
I0629 04:18:38.371183  5888 data_reader.cpp:262] Starting prefetch of epoch 147
I0629 04:18:38.434934  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57464
I0629 04:18:38.434958  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80196
I0629 04:18:38.434964  5893 solver.cpp:630]     Test net output #2: loss = 1.86372 (* 1 = 1.86372 loss)
I0629 04:18:38.434983  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.2964s
I0629 04:18:38.621750  5893 solver.cpp:349] Iteration 147000 (2.3372 iter/s, 42.7862s/100 iter), loss = 1.80098
I0629 04:18:38.621794  5893 solver.cpp:371]     Train net output #0: loss = 1.87674 (* 1 = 1.87674 loss)
I0629 04:18:38.621801  5893 sgd_solver.cpp:137] Iteration 147000, lr = 0.0008125, m = 0.9
I0629 04:18:57.071143  5893 solver.cpp:349] Iteration 147100 (5.42039 iter/s, 18.4489s/100 iter), loss = 1.41859
I0629 04:18:57.071245  5893 solver.cpp:371]     Train net output #0: loss = 1.44792 (* 1 = 1.44792 loss)
I0629 04:18:57.071252  5893 sgd_solver.cpp:137] Iteration 147100, lr = 0.00080625, m = 0.9
I0629 04:19:15.509721  5893 solver.cpp:349] Iteration 147200 (5.42359 iter/s, 18.438s/100 iter), loss = 1.62248
I0629 04:19:15.509744  5893 solver.cpp:371]     Train net output #0: loss = 1.54091 (* 1 = 1.54091 loss)
I0629 04:19:15.509748  5893 sgd_solver.cpp:137] Iteration 147200, lr = 0.0008, m = 0.9
I0629 04:19:33.933931  5893 solver.cpp:349] Iteration 147300 (5.42779 iter/s, 18.4237s/100 iter), loss = 1.6578
I0629 04:19:33.934028  5893 solver.cpp:371]     Train net output #0: loss = 1.6348 (* 1 = 1.6348 loss)
I0629 04:19:33.934034  5893 sgd_solver.cpp:137] Iteration 147300, lr = 0.00079375, m = 0.9
I0629 04:19:52.366031  5893 solver.cpp:349] Iteration 147400 (5.42549 iter/s, 18.4315s/100 iter), loss = 1.6478
I0629 04:19:52.366055  5893 solver.cpp:371]     Train net output #0: loss = 1.83708 (* 1 = 1.83708 loss)
I0629 04:19:52.366060  5893 sgd_solver.cpp:137] Iteration 147400, lr = 0.0007875, m = 0.9
I0629 04:20:10.822775  5893 solver.cpp:349] Iteration 147500 (5.41823 iter/s, 18.4562s/100 iter), loss = 1.71802
I0629 04:20:10.822881  5893 solver.cpp:371]     Train net output #0: loss = 1.79554 (* 1 = 1.79554 loss)
I0629 04:20:10.822887  5893 sgd_solver.cpp:137] Iteration 147500, lr = 0.00078125, m = 0.9
I0629 04:20:29.249245  5893 solver.cpp:349] Iteration 147600 (5.42716 iter/s, 18.4259s/100 iter), loss = 1.70455
I0629 04:20:29.249269  5893 solver.cpp:371]     Train net output #0: loss = 1.62229 (* 1 = 1.62229 loss)
I0629 04:20:29.249274  5893 sgd_solver.cpp:137] Iteration 147600, lr = 0.000775, m = 0.9
I0629 04:20:47.750788  5893 solver.cpp:349] Iteration 147700 (5.40498 iter/s, 18.5015s/100 iter), loss = 1.57823
I0629 04:20:47.750859  5893 solver.cpp:371]     Train net output #0: loss = 1.7153 (* 1 = 1.7153 loss)
I0629 04:20:47.750864  5893 sgd_solver.cpp:137] Iteration 147700, lr = 0.00076875, m = 0.9
I0629 04:21:06.263897  5893 solver.cpp:349] Iteration 147800 (5.40158 iter/s, 18.5131s/100 iter), loss = 1.60136
I0629 04:21:06.263921  5893 solver.cpp:371]     Train net output #0: loss = 1.63011 (* 1 = 1.63011 loss)
I0629 04:21:06.263924  5893 sgd_solver.cpp:137] Iteration 147800, lr = 0.0007625, m = 0.9
I0629 04:21:24.764679  5893 solver.cpp:349] Iteration 147900 (5.40517 iter/s, 18.5008s/100 iter), loss = 1.2657
I0629 04:21:24.764780  5893 solver.cpp:371]     Train net output #0: loss = 1.16678 (* 1 = 1.16678 loss)
I0629 04:21:24.764787  5893 sgd_solver.cpp:137] Iteration 147900, lr = 0.00075625, m = 0.9
I0629 04:21:43.070683  5893 solver.cpp:401] Sparsity after update:
I0629 04:21:43.075924  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:21:43.075935  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:21:43.075944  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:21:43.075948  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:21:43.075953  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:21:43.075956  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:21:43.075960  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:21:43.075964  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:21:43.075968  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:21:43.075973  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:21:43.075976  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:21:43.075979  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:21:43.075983  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:21:43.075994  5893 solver.cpp:545] Iteration 148000, Testing net (#0)
I0629 04:22:07.231055  5888 data_reader.cpp:262] Starting prefetch of epoch 148
I0629 04:22:07.377648  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57296
I0629 04:22:07.377666  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80148
I0629 04:22:07.377671  5893 solver.cpp:630]     Test net output #2: loss = 1.86462 (* 1 = 1.86462 loss)
I0629 04:22:07.377688  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3017s
I0629 04:22:07.566781  5893 solver.cpp:349] Iteration 148000 (2.33634 iter/s, 42.802s/100 iter), loss = 1.41829
I0629 04:22:07.566803  5893 solver.cpp:371]     Train net output #0: loss = 1.42496 (* 1 = 1.42496 loss)
I0629 04:22:07.566807  5893 sgd_solver.cpp:137] Iteration 148000, lr = 0.00075, m = 0.9
I0629 04:22:26.019976  5893 solver.cpp:349] Iteration 148100 (5.41914 iter/s, 18.4531s/100 iter), loss = 1.29641
I0629 04:22:26.019997  5893 solver.cpp:371]     Train net output #0: loss = 1.23694 (* 1 = 1.23694 loss)
I0629 04:22:26.020001  5893 sgd_solver.cpp:137] Iteration 148100, lr = 0.00074375, m = 0.9
I0629 04:22:44.452502  5893 solver.cpp:349] Iteration 148200 (5.42522 iter/s, 18.4324s/100 iter), loss = 1.45037
I0629 04:22:44.452605  5893 solver.cpp:371]     Train net output #0: loss = 1.57644 (* 1 = 1.57644 loss)
I0629 04:22:44.452611  5893 sgd_solver.cpp:137] Iteration 148200, lr = 0.0007375, m = 0.9
I0629 04:23:02.875984  5893 solver.cpp:349] Iteration 148300 (5.42791 iter/s, 18.4233s/100 iter), loss = 1.41342
I0629 04:23:02.876006  5893 solver.cpp:371]     Train net output #0: loss = 1.33326 (* 1 = 1.33326 loss)
I0629 04:23:02.876013  5893 sgd_solver.cpp:137] Iteration 148300, lr = 0.00073125, m = 0.9
I0629 04:23:21.320741  5893 solver.cpp:349] Iteration 148400 (5.42163 iter/s, 18.4446s/100 iter), loss = 1.60672
I0629 04:23:21.320844  5893 solver.cpp:371]     Train net output #0: loss = 1.40562 (* 1 = 1.40562 loss)
I0629 04:23:21.320852  5893 sgd_solver.cpp:137] Iteration 148400, lr = 0.000725, m = 0.9
I0629 04:23:39.745800  5893 solver.cpp:349] Iteration 148500 (5.42745 iter/s, 18.4248s/100 iter), loss = 1.59458
I0629 04:23:39.745826  5893 solver.cpp:371]     Train net output #0: loss = 1.82617 (* 1 = 1.82617 loss)
I0629 04:23:39.745831  5893 sgd_solver.cpp:137] Iteration 148500, lr = 0.00071875, m = 0.9
I0629 04:23:58.191143  5893 solver.cpp:349] Iteration 148600 (5.42146 iter/s, 18.4452s/100 iter), loss = 1.43626
I0629 04:23:58.191238  5893 solver.cpp:371]     Train net output #0: loss = 1.44454 (* 1 = 1.44454 loss)
I0629 04:23:58.191244  5893 sgd_solver.cpp:137] Iteration 148600, lr = 0.0007125, m = 0.9
I0629 04:24:16.693955  5893 solver.cpp:349] Iteration 148700 (5.40465 iter/s, 18.5026s/100 iter), loss = 1.60556
I0629 04:24:16.693979  5893 solver.cpp:371]     Train net output #0: loss = 1.76614 (* 1 = 1.76614 loss)
I0629 04:24:16.693981  5893 sgd_solver.cpp:137] Iteration 148700, lr = 0.00070625, m = 0.9
I0629 04:24:35.259366  5893 solver.cpp:349] Iteration 148800 (5.38641 iter/s, 18.5652s/100 iter), loss = 1.45718
I0629 04:24:35.259476  5893 solver.cpp:371]     Train net output #0: loss = 1.60691 (* 1 = 1.60691 loss)
I0629 04:24:35.259483  5893 sgd_solver.cpp:137] Iteration 148800, lr = 0.0007, m = 0.9
I0629 04:24:53.783845  5893 solver.cpp:349] Iteration 148900 (5.39834 iter/s, 18.5242s/100 iter), loss = 1.45845
I0629 04:24:53.783872  5893 solver.cpp:371]     Train net output #0: loss = 1.43035 (* 1 = 1.43035 loss)
I0629 04:24:53.783877  5893 sgd_solver.cpp:137] Iteration 148900, lr = 0.00069375, m = 0.9
I0629 04:25:12.101140  5893 solver.cpp:401] Sparsity after update:
I0629 04:25:12.106441  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:25:12.106612  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:25:12.106689  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:25:12.106755  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:25:12.106819  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:25:12.106885  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:25:12.106976  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:25:12.107991  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:25:12.108053  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:25:12.108072  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:25:12.108086  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:25:12.108101  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:25:12.108121  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:25:12.108597  5893 solver.cpp:545] Iteration 149000, Testing net (#0)
I0629 04:25:36.650169  5888 data_reader.cpp:262] Starting prefetch of epoch 149
I0629 04:25:36.772469  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57452
I0629 04:25:36.772490  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80128
I0629 04:25:36.772495  5893 solver.cpp:630]     Test net output #2: loss = 1.8623 (* 1 = 1.8623 loss)
I0629 04:25:36.772511  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.6637s
I0629 04:25:36.956686  5893 solver.cpp:349] Iteration 149000 (2.31629 iter/s, 43.1724s/100 iter), loss = 1.68849
I0629 04:25:36.956707  5893 solver.cpp:371]     Train net output #0: loss = 1.91453 (* 1 = 1.91453 loss)
I0629 04:25:36.956710  5893 sgd_solver.cpp:137] Iteration 149000, lr = 0.0006875, m = 0.9
I0629 04:25:55.394886  5893 solver.cpp:349] Iteration 149100 (5.42359 iter/s, 18.438s/100 iter), loss = 1.80939
I0629 04:25:55.394973  5893 solver.cpp:371]     Train net output #0: loss = 2.03246 (* 1 = 2.03246 loss)
I0629 04:25:55.394978  5893 sgd_solver.cpp:137] Iteration 149100, lr = 0.00068125, m = 0.9
I0629 04:26:13.858050  5893 solver.cpp:349] Iteration 149200 (5.41628 iter/s, 18.4629s/100 iter), loss = 1.70032
I0629 04:26:13.858073  5893 solver.cpp:371]     Train net output #0: loss = 1.72464 (* 1 = 1.72464 loss)
I0629 04:26:13.858079  5893 sgd_solver.cpp:137] Iteration 149200, lr = 0.000675, m = 0.9
I0629 04:26:32.306486  5893 solver.cpp:349] Iteration 149300 (5.42058 iter/s, 18.4482s/100 iter), loss = 1.37142
I0629 04:26:32.306591  5893 solver.cpp:371]     Train net output #0: loss = 1.37857 (* 1 = 1.37857 loss)
I0629 04:26:32.306596  5893 sgd_solver.cpp:137] Iteration 149300, lr = 0.00066875, m = 0.9
I0629 04:26:50.767112  5893 solver.cpp:349] Iteration 149400 (5.41703 iter/s, 18.4603s/100 iter), loss = 1.71998
I0629 04:26:50.767134  5893 solver.cpp:371]     Train net output #0: loss = 1.65364 (* 1 = 1.65364 loss)
I0629 04:26:50.767138  5893 sgd_solver.cpp:137] Iteration 149400, lr = 0.0006625, m = 0.9
I0629 04:27:09.211863  5893 solver.cpp:349] Iteration 149500 (5.42167 iter/s, 18.4445s/100 iter), loss = 1.52775
I0629 04:27:09.211972  5893 solver.cpp:371]     Train net output #0: loss = 1.50903 (* 1 = 1.50903 loss)
I0629 04:27:09.211979  5893 sgd_solver.cpp:137] Iteration 149500, lr = 0.00065625, m = 0.9
I0629 04:27:27.653434  5893 solver.cpp:349] Iteration 149600 (5.42264 iter/s, 18.4412s/100 iter), loss = 1.57155
I0629 04:27:27.653456  5893 solver.cpp:371]     Train net output #0: loss = 1.25774 (* 1 = 1.25774 loss)
I0629 04:27:27.653460  5893 sgd_solver.cpp:137] Iteration 149600, lr = 0.00065, m = 0.9
I0629 04:27:46.127873  5893 solver.cpp:349] Iteration 149700 (5.41297 iter/s, 18.4742s/100 iter), loss = 1.46657
I0629 04:27:46.127974  5893 solver.cpp:371]     Train net output #0: loss = 1.50181 (* 1 = 1.50181 loss)
I0629 04:27:46.127982  5893 sgd_solver.cpp:137] Iteration 149700, lr = 0.00064375, m = 0.9
I0629 04:28:04.634258  5893 solver.cpp:349] Iteration 149800 (5.40365 iter/s, 18.506s/100 iter), loss = 1.65119
I0629 04:28:04.634279  5893 solver.cpp:371]     Train net output #0: loss = 1.47733 (* 1 = 1.47733 loss)
I0629 04:28:04.634284  5893 sgd_solver.cpp:137] Iteration 149800, lr = 0.0006375, m = 0.9
I0629 04:28:23.138911  5893 solver.cpp:349] Iteration 149900 (5.40413 iter/s, 18.5044s/100 iter), loss = 1.38548
I0629 04:28:23.138978  5893 solver.cpp:371]     Train net output #0: loss = 1.1829 (* 1 = 1.1829 loss)
I0629 04:28:23.138983  5893 sgd_solver.cpp:137] Iteration 149900, lr = 0.00063125, m = 0.9
I0629 04:28:41.444514  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_150000.caffemodel
I0629 04:28:41.456558  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_150000.solverstate
I0629 04:28:41.462260  5893 solver.cpp:401] Sparsity after update:
I0629 04:28:41.463245  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:28:41.463254  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:28:41.463263  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:28:41.463266  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:28:41.463269  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:28:41.463273  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:28:41.463275  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:28:41.463279  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:28:41.463281  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:28:41.463285  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:28:41.463289  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:28:41.463294  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:28:41.463297  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:28:41.463309  5893 solver.cpp:545] Iteration 150000, Testing net (#0)
I0629 04:29:05.809931  5888 data_reader.cpp:262] Starting prefetch of epoch 150
I0629 04:29:05.900230  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57336
I0629 04:29:05.900254  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8004
I0629 04:29:05.900259  5893 solver.cpp:630]     Test net output #2: loss = 1.86224 (* 1 = 1.86224 loss)
I0629 04:29:05.900277  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4366s
I0629 04:29:06.084847  5893 solver.cpp:349] Iteration 150000 (2.32855 iter/s, 42.9452s/100 iter), loss = 1.62862
I0629 04:29:06.084870  5893 solver.cpp:371]     Train net output #0: loss = 1.61899 (* 1 = 1.61899 loss)
I0629 04:29:06.084875  5893 sgd_solver.cpp:137] Iteration 150000, lr = 0.000625, m = 0.9
I0629 04:29:24.505501  5893 solver.cpp:349] Iteration 150100 (5.42879 iter/s, 18.4203s/100 iter), loss = 1.60082
I0629 04:29:24.505522  5893 solver.cpp:371]     Train net output #0: loss = 1.64313 (* 1 = 1.64313 loss)
I0629 04:29:24.505527  5893 sgd_solver.cpp:137] Iteration 150100, lr = 0.00061875, m = 0.9
I0629 04:29:30.932575  5875 data_reader.cpp:262] Starting prefetch of epoch 30
I0629 04:29:42.951246  5893 solver.cpp:349] Iteration 150200 (5.4214 iter/s, 18.4454s/100 iter), loss = 1.68126
I0629 04:29:42.951304  5893 solver.cpp:371]     Train net output #0: loss = 1.50418 (* 1 = 1.50418 loss)
I0629 04:29:42.951309  5893 sgd_solver.cpp:137] Iteration 150200, lr = 0.0006125, m = 0.9
I0629 04:30:01.394806  5893 solver.cpp:349] Iteration 150300 (5.42206 iter/s, 18.4432s/100 iter), loss = 2.00362
I0629 04:30:01.394829  5893 solver.cpp:371]     Train net output #0: loss = 1.8408 (* 1 = 1.8408 loss)
I0629 04:30:01.394834  5893 sgd_solver.cpp:137] Iteration 150300, lr = 0.00060625, m = 0.9
I0629 04:30:19.836314  5893 solver.cpp:349] Iteration 150400 (5.42265 iter/s, 18.4412s/100 iter), loss = 1.75447
I0629 04:30:19.836400  5893 solver.cpp:371]     Train net output #0: loss = 1.65879 (* 1 = 1.65879 loss)
I0629 04:30:19.836405  5893 sgd_solver.cpp:137] Iteration 150400, lr = 0.0006, m = 0.9
I0629 04:30:38.251600  5893 solver.cpp:349] Iteration 150500 (5.4304 iter/s, 18.4149s/100 iter), loss = 1.48026
I0629 04:30:38.251624  5893 solver.cpp:371]     Train net output #0: loss = 1.32338 (* 1 = 1.32338 loss)
I0629 04:30:38.251628  5893 sgd_solver.cpp:137] Iteration 150500, lr = 0.00059375, m = 0.9
I0629 04:30:56.699059  5893 solver.cpp:349] Iteration 150600 (5.42091 iter/s, 18.4471s/100 iter), loss = 1.74742
I0629 04:30:56.699162  5893 solver.cpp:371]     Train net output #0: loss = 1.6949 (* 1 = 1.6949 loss)
I0629 04:30:56.699167  5893 sgd_solver.cpp:137] Iteration 150600, lr = 0.0005875, m = 0.9
I0629 04:31:15.172129  5893 solver.cpp:349] Iteration 150700 (5.41342 iter/s, 18.4726s/100 iter), loss = 1.65731
I0629 04:31:15.172152  5893 solver.cpp:371]     Train net output #0: loss = 1.6331 (* 1 = 1.6331 loss)
I0629 04:31:15.172158  5893 sgd_solver.cpp:137] Iteration 150700, lr = 0.00058125, m = 0.9
I0629 04:31:33.630863  5893 solver.cpp:349] Iteration 150800 (5.4176 iter/s, 18.4583s/100 iter), loss = 1.77027
I0629 04:31:33.630946  5893 solver.cpp:371]     Train net output #0: loss = 1.57653 (* 1 = 1.57653 loss)
I0629 04:31:33.630951  5893 sgd_solver.cpp:137] Iteration 150800, lr = 0.000575, m = 0.9
I0629 04:31:52.129851  5893 solver.cpp:349] Iteration 150900 (5.40583 iter/s, 18.4985s/100 iter), loss = 1.26839
I0629 04:31:52.129874  5893 solver.cpp:371]     Train net output #0: loss = 1.3687 (* 1 = 1.3687 loss)
I0629 04:31:52.129878  5893 sgd_solver.cpp:137] Iteration 150900, lr = 0.00056875, m = 0.9
I0629 04:32:10.479220  5893 solver.cpp:401] Sparsity after update:
I0629 04:32:10.484488  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:32:10.484494  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:32:10.484500  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:32:10.484503  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:32:10.484505  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:32:10.484508  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:32:10.484508  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:32:10.484510  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:32:10.484513  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:32:10.484514  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:32:10.484516  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:32:10.484519  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:32:10.484520  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:32:10.484527  5893 solver.cpp:545] Iteration 151000, Testing net (#0)
I0629 04:32:13.683820  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 04:32:34.724472  5888 data_reader.cpp:262] Starting prefetch of epoch 151
I0629 04:32:34.926342  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57388
I0629 04:32:34.926362  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.801961
I0629 04:32:34.926367  5893 solver.cpp:630]     Test net output #2: loss = 1.86247 (* 1 = 1.86247 loss)
I0629 04:32:34.926385  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4414s
I0629 04:32:35.110922  5893 solver.cpp:349] Iteration 151000 (2.32665 iter/s, 42.9802s/100 iter), loss = 1.49028
I0629 04:32:35.110946  5893 solver.cpp:371]     Train net output #0: loss = 1.49058 (* 1 = 1.49058 loss)
I0629 04:32:35.110950  5893 sgd_solver.cpp:137] Iteration 151000, lr = 0.0005625, m = 0.9
I0629 04:32:53.621071  5893 solver.cpp:349] Iteration 151100 (5.40256 iter/s, 18.5097s/100 iter), loss = 1.69516
I0629 04:32:53.621187  5893 solver.cpp:371]     Train net output #0: loss = 1.71835 (* 1 = 1.71835 loss)
I0629 04:32:53.621193  5893 sgd_solver.cpp:137] Iteration 151100, lr = 0.00055625, m = 0.9
I0629 04:33:12.042520  5893 solver.cpp:349] Iteration 151200 (5.42861 iter/s, 18.4209s/100 iter), loss = 1.754
I0629 04:33:12.042539  5893 solver.cpp:371]     Train net output #0: loss = 1.88822 (* 1 = 1.88822 loss)
I0629 04:33:12.042543  5893 sgd_solver.cpp:137] Iteration 151200, lr = 0.00055, m = 0.9
I0629 04:33:30.453682  5893 solver.cpp:349] Iteration 151300 (5.43161 iter/s, 18.4107s/100 iter), loss = 1.58901
I0629 04:33:30.453783  5893 solver.cpp:371]     Train net output #0: loss = 1.59042 (* 1 = 1.59042 loss)
I0629 04:33:30.453788  5893 sgd_solver.cpp:137] Iteration 151300, lr = 0.00054375, m = 0.9
I0629 04:33:48.881491  5893 solver.cpp:349] Iteration 151400 (5.42673 iter/s, 18.4273s/100 iter), loss = 1.76461
I0629 04:33:48.881515  5893 solver.cpp:371]     Train net output #0: loss = 1.92743 (* 1 = 1.92743 loss)
I0629 04:33:48.881520  5893 sgd_solver.cpp:137] Iteration 151400, lr = 0.0005375, m = 0.9
I0629 04:34:07.319911  5893 solver.cpp:349] Iteration 151500 (5.42359 iter/s, 18.438s/100 iter), loss = 1.87448
I0629 04:34:07.320009  5893 solver.cpp:371]     Train net output #0: loss = 1.86095 (* 1 = 1.86095 loss)
I0629 04:34:07.320015  5893 sgd_solver.cpp:137] Iteration 151500, lr = 0.00053125, m = 0.9
I0629 04:34:25.748476  5893 solver.cpp:349] Iteration 151600 (5.42652 iter/s, 18.428s/100 iter), loss = 1.85873
I0629 04:34:25.748500  5893 solver.cpp:371]     Train net output #0: loss = 1.48861 (* 1 = 1.48861 loss)
I0629 04:34:25.748505  5893 sgd_solver.cpp:137] Iteration 151600, lr = 0.000525, m = 0.9
I0629 04:34:44.209429  5893 solver.cpp:349] Iteration 151700 (5.41698 iter/s, 18.4605s/100 iter), loss = 1.59989
I0629 04:34:44.209552  5893 solver.cpp:371]     Train net output #0: loss = 1.37766 (* 1 = 1.37766 loss)
I0629 04:34:44.209558  5893 sgd_solver.cpp:137] Iteration 151700, lr = 0.00051875, m = 0.9
I0629 04:35:02.761911  5893 solver.cpp:349] Iteration 151800 (5.39028 iter/s, 18.5519s/100 iter), loss = 1.53393
I0629 04:35:02.761934  5893 solver.cpp:371]     Train net output #0: loss = 1.55954 (* 1 = 1.55954 loss)
I0629 04:35:02.761937  5893 sgd_solver.cpp:137] Iteration 151800, lr = 0.0005125, m = 0.9
I0629 04:35:21.243855  5893 solver.cpp:349] Iteration 151900 (5.41082 iter/s, 18.4815s/100 iter), loss = 1.35503
I0629 04:35:21.243978  5893 solver.cpp:371]     Train net output #0: loss = 1.27618 (* 1 = 1.27618 loss)
I0629 04:35:21.243985  5893 sgd_solver.cpp:137] Iteration 151900, lr = 0.00050625, m = 0.9
I0629 04:35:39.567893  5893 solver.cpp:401] Sparsity after update:
I0629 04:35:39.573146  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:35:39.573159  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:35:39.573165  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:35:39.573168  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:35:39.573173  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:35:39.573175  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:35:39.573179  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:35:39.573181  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:35:39.573184  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:35:39.573187  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:35:39.573190  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:35:39.573194  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:35:39.573196  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:35:39.573206  5893 solver.cpp:545] Iteration 152000, Testing net (#0)
I0629 04:36:03.893378  5888 data_reader.cpp:262] Starting prefetch of epoch 152
I0629 04:36:03.955772  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57536
I0629 04:36:03.955795  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8022
I0629 04:36:03.955801  5893 solver.cpp:630]     Test net output #2: loss = 1.86129 (* 1 = 1.86129 loss)
I0629 04:36:03.955821  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.382s
I0629 04:36:04.141558  5893 solver.cpp:349] Iteration 152000 (2.33119 iter/s, 42.8965s/100 iter), loss = 1.54472
I0629 04:36:04.141582  5893 solver.cpp:371]     Train net output #0: loss = 1.70859 (* 1 = 1.70859 loss)
I0629 04:36:04.141588  5893 sgd_solver.cpp:137] Iteration 152000, lr = 0.0005, m = 0.9
I0629 04:36:22.566990  5893 solver.cpp:349] Iteration 152100 (5.42743 iter/s, 18.4249s/100 iter), loss = 1.4924
I0629 04:36:22.567015  5893 solver.cpp:371]     Train net output #0: loss = 1.34232 (* 1 = 1.34232 loss)
I0629 04:36:22.567020  5893 sgd_solver.cpp:137] Iteration 152100, lr = 0.00049375, m = 0.9
I0629 04:36:40.995559  5893 solver.cpp:349] Iteration 152200 (5.42651 iter/s, 18.4281s/100 iter), loss = 1.42154
I0629 04:36:40.995661  5893 solver.cpp:371]     Train net output #0: loss = 1.46039 (* 1 = 1.46039 loss)
I0629 04:36:40.995667  5893 sgd_solver.cpp:137] Iteration 152200, lr = 0.0004875, m = 0.9
I0629 04:36:59.406179  5893 solver.cpp:349] Iteration 152300 (5.43182 iter/s, 18.41s/100 iter), loss = 1.62652
I0629 04:36:59.406203  5893 solver.cpp:371]     Train net output #0: loss = 1.85947 (* 1 = 1.85947 loss)
I0629 04:36:59.406208  5893 sgd_solver.cpp:137] Iteration 152300, lr = 0.00048125, m = 0.9
I0629 04:37:17.856891  5893 solver.cpp:349] Iteration 152400 (5.42 iter/s, 18.4502s/100 iter), loss = 1.67666
I0629 04:37:17.856994  5893 solver.cpp:371]     Train net output #0: loss = 1.54203 (* 1 = 1.54203 loss)
I0629 04:37:17.857000  5893 sgd_solver.cpp:137] Iteration 152400, lr = 0.000475, m = 0.9
I0629 04:37:36.313894  5893 solver.cpp:349] Iteration 152500 (5.41818 iter/s, 18.4564s/100 iter), loss = 1.54194
I0629 04:37:36.313917  5893 solver.cpp:371]     Train net output #0: loss = 1.4215 (* 1 = 1.4215 loss)
I0629 04:37:36.313921  5893 sgd_solver.cpp:137] Iteration 152500, lr = 0.00046875, m = 0.9
I0629 04:37:54.779711  5893 solver.cpp:349] Iteration 152600 (5.41557 iter/s, 18.4653s/100 iter), loss = 1.90466
I0629 04:37:54.779779  5893 solver.cpp:371]     Train net output #0: loss = 1.87763 (* 1 = 1.87763 loss)
I0629 04:37:54.779784  5893 sgd_solver.cpp:137] Iteration 152600, lr = 0.0004625, m = 0.9
I0629 04:38:13.210759  5893 solver.cpp:349] Iteration 152700 (5.4258 iter/s, 18.4305s/100 iter), loss = 1.65977
I0629 04:38:13.210783  5893 solver.cpp:371]     Train net output #0: loss = 1.66959 (* 1 = 1.66959 loss)
I0629 04:38:13.210786  5893 sgd_solver.cpp:137] Iteration 152700, lr = 0.00045625, m = 0.9
I0629 04:38:31.776322  5893 solver.cpp:349] Iteration 152800 (5.38647 iter/s, 18.565s/100 iter), loss = 1.41433
I0629 04:38:31.776423  5893 solver.cpp:371]     Train net output #0: loss = 1.37123 (* 1 = 1.37123 loss)
I0629 04:38:31.776430  5893 sgd_solver.cpp:137] Iteration 152800, lr = 0.00045, m = 0.9
I0629 04:38:50.309257  5893 solver.cpp:349] Iteration 152900 (5.39598 iter/s, 18.5323s/100 iter), loss = 1.76065
I0629 04:38:50.309281  5893 solver.cpp:371]     Train net output #0: loss = 1.40745 (* 1 = 1.40745 loss)
I0629 04:38:50.309285  5893 sgd_solver.cpp:137] Iteration 152900, lr = 0.00044375, m = 0.9
I0629 04:39:08.597158  5893 solver.cpp:401] Sparsity after update:
I0629 04:39:08.604555  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:39:08.604563  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:39:08.604570  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:39:08.604573  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:39:08.604574  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:39:08.604576  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:39:08.604578  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:39:08.604580  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:39:08.604583  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:39:08.604584  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:39:08.604585  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:39:08.604588  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:39:08.604589  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:39:08.604596  5893 solver.cpp:545] Iteration 153000, Testing net (#0)
I0629 04:39:32.905359  5888 data_reader.cpp:262] Starting prefetch of epoch 153
I0629 04:39:33.003280  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.5754
I0629 04:39:33.003301  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80208
I0629 04:39:33.003306  5893 solver.cpp:630]     Test net output #2: loss = 1.85982 (* 1 = 1.85982 loss)
I0629 04:39:33.003324  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.398s
I0629 04:39:33.188359  5893 solver.cpp:349] Iteration 153000 (2.3322 iter/s, 42.8779s/100 iter), loss = 1.56034
I0629 04:39:33.188379  5893 solver.cpp:371]     Train net output #0: loss = 1.60219 (* 1 = 1.60219 loss)
I0629 04:39:33.188382  5893 sgd_solver.cpp:137] Iteration 153000, lr = 0.0004375, m = 0.9
I0629 04:39:51.658459  5893 solver.cpp:349] Iteration 153100 (5.41432 iter/s, 18.4695s/100 iter), loss = 1.26623
I0629 04:39:51.658577  5893 solver.cpp:371]     Train net output #0: loss = 1.33837 (* 1 = 1.33837 loss)
I0629 04:39:51.658583  5893 sgd_solver.cpp:137] Iteration 153100, lr = 0.00043125, m = 0.9
I0629 04:40:10.081516  5893 solver.cpp:349] Iteration 153200 (5.42818 iter/s, 18.4224s/100 iter), loss = 1.51326
I0629 04:40:10.081537  5893 solver.cpp:371]     Train net output #0: loss = 1.69112 (* 1 = 1.69112 loss)
I0629 04:40:10.081542  5893 sgd_solver.cpp:137] Iteration 153200, lr = 0.000425, m = 0.9
I0629 04:40:28.574893  5893 solver.cpp:349] Iteration 153300 (5.40751 iter/s, 18.4928s/100 iter), loss = 1.64599
I0629 04:40:28.574990  5893 solver.cpp:371]     Train net output #0: loss = 1.47073 (* 1 = 1.47073 loss)
I0629 04:40:28.574996  5893 sgd_solver.cpp:137] Iteration 153300, lr = 0.00041875, m = 0.9
I0629 04:40:47.056159  5893 solver.cpp:349] Iteration 153400 (5.41078 iter/s, 18.4816s/100 iter), loss = 1.34867
I0629 04:40:47.056180  5893 solver.cpp:371]     Train net output #0: loss = 1.355 (* 1 = 1.355 loss)
I0629 04:40:47.056183  5893 sgd_solver.cpp:137] Iteration 153400, lr = 0.0004125, m = 0.9
I0629 04:41:05.520210  5893 solver.cpp:349] Iteration 153500 (5.41581 iter/s, 18.4645s/100 iter), loss = 1.76069
I0629 04:41:05.520314  5893 solver.cpp:371]     Train net output #0: loss = 1.60792 (* 1 = 1.60792 loss)
I0629 04:41:05.520321  5893 sgd_solver.cpp:137] Iteration 153500, lr = 0.00040625, m = 0.9
I0629 04:41:23.964046  5893 solver.cpp:349] Iteration 153600 (5.42178 iter/s, 18.4441s/100 iter), loss = 1.58911
I0629 04:41:23.964068  5893 solver.cpp:371]     Train net output #0: loss = 1.35709 (* 1 = 1.35709 loss)
I0629 04:41:23.964074  5893 sgd_solver.cpp:137] Iteration 153600, lr = 0.0004, m = 0.9
I0629 04:41:42.532784  5893 solver.cpp:349] Iteration 153700 (5.3853 iter/s, 18.5691s/100 iter), loss = 1.53067
I0629 04:41:42.532893  5893 solver.cpp:371]     Train net output #0: loss = 1.71763 (* 1 = 1.71763 loss)
I0629 04:41:42.532901  5893 sgd_solver.cpp:137] Iteration 153700, lr = 0.00039375, m = 0.9
I0629 04:42:01.046825  5893 solver.cpp:349] Iteration 153800 (5.40125 iter/s, 18.5142s/100 iter), loss = 1.77508
I0629 04:42:01.046845  5893 solver.cpp:371]     Train net output #0: loss = 1.3418 (* 1 = 1.3418 loss)
I0629 04:42:01.046851  5893 sgd_solver.cpp:137] Iteration 153800, lr = 0.0003875, m = 0.9
I0629 04:42:19.535790  5893 solver.cpp:349] Iteration 153900 (5.40856 iter/s, 18.4892s/100 iter), loss = 1.50108
I0629 04:42:19.535883  5893 solver.cpp:371]     Train net output #0: loss = 1.55841 (* 1 = 1.55841 loss)
I0629 04:42:19.535888  5893 sgd_solver.cpp:137] Iteration 153900, lr = 0.00038125, m = 0.9
I0629 04:42:37.849521  5893 solver.cpp:401] Sparsity after update:
I0629 04:42:37.854774  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:42:37.854784  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:42:37.854792  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:42:37.854795  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:42:37.854799  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:42:37.854804  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:42:37.854806  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:42:37.854809  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:42:37.854813  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:42:37.854817  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:42:37.854820  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:42:37.854823  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:42:37.854826  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:42:37.854851  5893 solver.cpp:545] Iteration 154000, Testing net (#0)
I0629 04:43:02.453637  5888 data_reader.cpp:262] Starting prefetch of epoch 154
I0629 04:43:02.595221  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57428
I0629 04:43:02.595247  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.802
I0629 04:43:02.595252  5893 solver.cpp:630]     Test net output #2: loss = 1.85977 (* 1 = 1.85977 loss)
I0629 04:43:02.595269  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.741s
I0629 04:43:02.780038  5893 solver.cpp:349] Iteration 154000 (2.31241 iter/s, 43.245s/100 iter), loss = 1.43017
I0629 04:43:02.780061  5893 solver.cpp:371]     Train net output #0: loss = 1.39553 (* 1 = 1.39553 loss)
I0629 04:43:02.780066  5893 sgd_solver.cpp:137] Iteration 154000, lr = 0.000375, m = 0.9
I0629 04:43:21.224190  5893 solver.cpp:349] Iteration 154100 (5.42165 iter/s, 18.4446s/100 iter), loss = 1.18122
I0629 04:43:21.224212  5893 solver.cpp:371]     Train net output #0: loss = 1.0491 (* 1 = 1.0491 loss)
I0629 04:43:21.224216  5893 sgd_solver.cpp:137] Iteration 154100, lr = 0.00036875, m = 0.9
I0629 04:43:39.645761  5893 solver.cpp:349] Iteration 154200 (5.42832 iter/s, 18.4219s/100 iter), loss = 1.58421
I0629 04:43:39.645860  5893 solver.cpp:371]     Train net output #0: loss = 1.62668 (* 1 = 1.62668 loss)
I0629 04:43:39.645866  5893 sgd_solver.cpp:137] Iteration 154200, lr = 0.0003625, m = 0.9
I0629 04:43:58.072580  5893 solver.cpp:349] Iteration 154300 (5.42681 iter/s, 18.427s/100 iter), loss = 1.82947
I0629 04:43:58.072603  5893 solver.cpp:371]     Train net output #0: loss = 1.96926 (* 1 = 1.96926 loss)
I0629 04:43:58.072608  5893 sgd_solver.cpp:137] Iteration 154300, lr = 0.00035625, m = 0.9
I0629 04:44:16.484308  5893 solver.cpp:349] Iteration 154400 (5.43124 iter/s, 18.412s/100 iter), loss = 1.42836
I0629 04:44:16.484385  5893 solver.cpp:371]     Train net output #0: loss = 1.4539 (* 1 = 1.4539 loss)
I0629 04:44:16.484391  5893 sgd_solver.cpp:137] Iteration 154400, lr = 0.00035, m = 0.9
I0629 04:44:34.905445  5893 solver.cpp:349] Iteration 154500 (5.42849 iter/s, 18.4213s/100 iter), loss = 1.79088
I0629 04:44:34.905470  5893 solver.cpp:371]     Train net output #0: loss = 1.64238 (* 1 = 1.64238 loss)
I0629 04:44:34.905477  5893 sgd_solver.cpp:137] Iteration 154500, lr = 0.00034375, m = 0.9
I0629 04:44:53.330040  5893 solver.cpp:349] Iteration 154600 (5.42747 iter/s, 18.4248s/100 iter), loss = 1.4553
I0629 04:44:53.331187  5893 solver.cpp:371]     Train net output #0: loss = 1.50778 (* 1 = 1.50778 loss)
I0629 04:44:53.331193  5893 sgd_solver.cpp:137] Iteration 154600, lr = 0.0003375, m = 0.9
I0629 04:45:11.801381  5893 solver.cpp:349] Iteration 154700 (5.41407 iter/s, 18.4704s/100 iter), loss = 1.39163
I0629 04:45:11.801405  5893 solver.cpp:371]     Train net output #0: loss = 1.57264 (* 1 = 1.57264 loss)
I0629 04:45:11.801409  5893 sgd_solver.cpp:137] Iteration 154700, lr = 0.00033125, m = 0.9
I0629 04:45:30.312820  5893 solver.cpp:349] Iteration 154800 (5.40202 iter/s, 18.5116s/100 iter), loss = 1.56932
I0629 04:45:30.312933  5893 solver.cpp:371]     Train net output #0: loss = 1.3565 (* 1 = 1.3565 loss)
I0629 04:45:30.312940  5893 sgd_solver.cpp:137] Iteration 154800, lr = 0.000325, m = 0.9
I0629 04:45:48.820417  5893 solver.cpp:349] Iteration 154900 (5.40318 iter/s, 18.5076s/100 iter), loss = 1.54944
I0629 04:45:48.820441  5893 solver.cpp:371]     Train net output #0: loss = 1.70162 (* 1 = 1.70162 loss)
I0629 04:45:48.820444  5893 sgd_solver.cpp:137] Iteration 154900, lr = 0.00031875, m = 0.9
I0629 04:46:07.109973  5893 solver.cpp:401] Sparsity after update:
I0629 04:46:07.114954  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:46:07.114962  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:46:07.114969  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:46:07.114970  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:46:07.114972  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:46:07.114974  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:46:07.114976  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:46:07.114979  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:46:07.114980  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:46:07.114982  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:46:07.114984  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:46:07.114985  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:46:07.114989  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:46:07.114995  5893 solver.cpp:545] Iteration 155000, Testing net (#0)
I0629 04:46:31.583382  5888 data_reader.cpp:262] Starting prefetch of epoch 155
I0629 04:46:31.648968  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57408
I0629 04:46:31.648988  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80208
I0629 04:46:31.648993  5893 solver.cpp:630]     Test net output #2: loss = 1.85855 (* 1 = 1.85855 loss)
I0629 04:46:31.649019  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.5338s
I0629 04:46:31.834439  5893 solver.cpp:349] Iteration 155000 (2.32484 iter/s, 43.0137s/100 iter), loss = 1.73365
I0629 04:46:31.834462  5893 solver.cpp:371]     Train net output #0: loss = 1.83583 (* 1 = 1.83583 loss)
I0629 04:46:31.834466  5893 sgd_solver.cpp:137] Iteration 155000, lr = 0.0003125, m = 0.9
I0629 04:46:50.262701  5893 solver.cpp:349] Iteration 155100 (5.42651 iter/s, 18.4281s/100 iter), loss = 1.58872
I0629 04:46:50.262816  5893 solver.cpp:371]     Train net output #0: loss = 1.36434 (* 1 = 1.36434 loss)
I0629 04:46:50.262822  5893 sgd_solver.cpp:137] Iteration 155100, lr = 0.00030625, m = 0.9
I0629 04:46:57.503677  5875 data_reader.cpp:262] Starting prefetch of epoch 31
I0629 04:47:08.670914  5893 solver.cpp:349] Iteration 155200 (5.43245 iter/s, 18.4079s/100 iter), loss = 1.46633
I0629 04:47:08.670936  5893 solver.cpp:371]     Train net output #0: loss = 1.35658 (* 1 = 1.35658 loss)
I0629 04:47:08.670940  5893 sgd_solver.cpp:137] Iteration 155200, lr = 0.0003, m = 0.9
I0629 04:47:27.115273  5893 solver.cpp:349] Iteration 155300 (5.42178 iter/s, 18.4441s/100 iter), loss = 1.8281
I0629 04:47:27.115375  5893 solver.cpp:371]     Train net output #0: loss = 1.95624 (* 1 = 1.95624 loss)
I0629 04:47:27.115381  5893 sgd_solver.cpp:137] Iteration 155300, lr = 0.00029375, m = 0.9
I0629 04:47:45.587615  5893 solver.cpp:349] Iteration 155400 (5.41359 iter/s, 18.472s/100 iter), loss = 1.51767
I0629 04:47:45.587638  5893 solver.cpp:371]     Train net output #0: loss = 1.47293 (* 1 = 1.47293 loss)
I0629 04:47:45.587643  5893 sgd_solver.cpp:137] Iteration 155400, lr = 0.0002875, m = 0.9
I0629 04:48:04.042878  5893 solver.cpp:349] Iteration 155500 (5.41858 iter/s, 18.455s/100 iter), loss = 1.6152
I0629 04:48:04.042986  5893 solver.cpp:371]     Train net output #0: loss = 1.50465 (* 1 = 1.50465 loss)
I0629 04:48:04.042994  5893 sgd_solver.cpp:137] Iteration 155500, lr = 0.00028125, m = 0.9
I0629 04:48:22.503952  5893 solver.cpp:349] Iteration 155600 (5.41691 iter/s, 18.4607s/100 iter), loss = 1.68576
I0629 04:48:22.503975  5893 solver.cpp:371]     Train net output #0: loss = 1.719 (* 1 = 1.719 loss)
I0629 04:48:22.503979  5893 sgd_solver.cpp:137] Iteration 155600, lr = 0.000275, m = 0.9
I0629 04:48:41.035430  5893 solver.cpp:349] Iteration 155700 (5.39631 iter/s, 18.5312s/100 iter), loss = 1.88625
I0629 04:48:41.035538  5893 solver.cpp:371]     Train net output #0: loss = 2.1211 (* 1 = 2.1211 loss)
I0629 04:48:41.035544  5893 sgd_solver.cpp:137] Iteration 155700, lr = 0.00026875, m = 0.9
I0629 04:48:59.553470  5893 solver.cpp:349] Iteration 155800 (5.40025 iter/s, 18.5177s/100 iter), loss = 1.55951
I0629 04:48:59.553493  5893 solver.cpp:371]     Train net output #0: loss = 1.73351 (* 1 = 1.73351 loss)
I0629 04:48:59.553498  5893 sgd_solver.cpp:137] Iteration 155800, lr = 0.0002625, m = 0.9
I0629 04:49:18.068306  5893 solver.cpp:349] Iteration 155900 (5.40116 iter/s, 18.5145s/100 iter), loss = 1.35596
I0629 04:49:18.068409  5893 solver.cpp:371]     Train net output #0: loss = 1.42541 (* 1 = 1.42541 loss)
I0629 04:49:18.068415  5893 sgd_solver.cpp:137] Iteration 155900, lr = 0.00025625, m = 0.9
I0629 04:49:36.370574  5893 solver.cpp:401] Sparsity after update:
I0629 04:49:36.375808  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:49:36.375818  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:49:36.375828  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:49:36.375830  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:49:36.375833  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:49:36.375838  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:49:36.375840  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:49:36.375844  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:49:36.375846  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:49:36.375849  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:49:36.375852  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:49:36.375855  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:49:36.375859  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:49:36.375869  5893 solver.cpp:545] Iteration 156000, Testing net (#0)
I0629 04:49:39.738289  5893 blocking_queue.cpp:40] Data layer prefetch queue empty
I0629 04:50:00.720940  5888 data_reader.cpp:262] Starting prefetch of epoch 156
I0629 04:50:00.783293  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57496
I0629 04:50:00.783315  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.802441
I0629 04:50:00.783323  5893 solver.cpp:630]     Test net output #2: loss = 1.85865 (* 1 = 1.85865 loss)
I0629 04:50:00.783340  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4071s
I0629 04:50:00.968241  5893 solver.cpp:349] Iteration 156000 (2.33105 iter/s, 42.8991s/100 iter), loss = 1.58392
I0629 04:50:00.968263  5893 solver.cpp:371]     Train net output #0: loss = 1.77427 (* 1 = 1.77427 loss)
I0629 04:50:00.968268  5893 sgd_solver.cpp:137] Iteration 156000, lr = 0.00025, m = 0.9
I0629 04:50:19.400925  5893 solver.cpp:349] Iteration 156100 (5.42525 iter/s, 18.4323s/100 iter), loss = 1.50752
I0629 04:50:19.400949  5893 solver.cpp:371]     Train net output #0: loss = 1.51746 (* 1 = 1.51746 loss)
I0629 04:50:19.400954  5893 sgd_solver.cpp:137] Iteration 156100, lr = 0.00024375, m = 0.9
I0629 04:50:37.819016  5893 solver.cpp:349] Iteration 156200 (5.42955 iter/s, 18.4177s/100 iter), loss = 1.69773
I0629 04:50:37.819128  5893 solver.cpp:371]     Train net output #0: loss = 1.53658 (* 1 = 1.53658 loss)
I0629 04:50:37.819133  5893 sgd_solver.cpp:137] Iteration 156200, lr = 0.0002375, m = 0.9
I0629 04:50:56.230890  5893 solver.cpp:349] Iteration 156300 (5.43141 iter/s, 18.4114s/100 iter), loss = 1.50038
I0629 04:50:56.230913  5893 solver.cpp:371]     Train net output #0: loss = 1.2234 (* 1 = 1.2234 loss)
I0629 04:50:56.230917  5893 sgd_solver.cpp:137] Iteration 156300, lr = 0.00023125, m = 0.9
I0629 04:51:14.647696  5893 solver.cpp:349] Iteration 156400 (5.42993 iter/s, 18.4164s/100 iter), loss = 1.23884
I0629 04:51:14.647770  5893 solver.cpp:371]     Train net output #0: loss = 1.03553 (* 1 = 1.03553 loss)
I0629 04:51:14.647778  5893 sgd_solver.cpp:137] Iteration 156400, lr = 0.000225, m = 0.9
I0629 04:51:33.058548  5893 solver.cpp:349] Iteration 156500 (5.43171 iter/s, 18.4104s/100 iter), loss = 1.55935
I0629 04:51:33.058569  5893 solver.cpp:371]     Train net output #0: loss = 1.52112 (* 1 = 1.52112 loss)
I0629 04:51:33.058573  5893 sgd_solver.cpp:137] Iteration 156500, lr = 0.00021875, m = 0.9
I0629 04:51:51.523097  5893 solver.cpp:349] Iteration 156600 (5.4159 iter/s, 18.4642s/100 iter), loss = 1.42276
I0629 04:51:51.523200  5893 solver.cpp:371]     Train net output #0: loss = 1.4387 (* 1 = 1.4387 loss)
I0629 04:51:51.523206  5893 sgd_solver.cpp:137] Iteration 156600, lr = 0.0002125, m = 0.9
I0629 04:52:10.110224  5893 solver.cpp:349] Iteration 156700 (5.38021 iter/s, 18.5866s/100 iter), loss = 1.63149
I0629 04:52:10.110244  5893 solver.cpp:371]     Train net output #0: loss = 1.60343 (* 1 = 1.60343 loss)
I0629 04:52:10.110249  5893 sgd_solver.cpp:137] Iteration 156700, lr = 0.00020625, m = 0.9
I0629 04:52:28.632830  5893 solver.cpp:349] Iteration 156800 (5.39893 iter/s, 18.5222s/100 iter), loss = 1.38229
I0629 04:52:28.632930  5893 solver.cpp:371]     Train net output #0: loss = 1.35237 (* 1 = 1.35237 loss)
I0629 04:52:28.632936  5893 sgd_solver.cpp:137] Iteration 156800, lr = 0.0002, m = 0.9
I0629 04:52:47.133435  5893 solver.cpp:349] Iteration 156900 (5.40538 iter/s, 18.5001s/100 iter), loss = 1.65683
I0629 04:52:47.133455  5893 solver.cpp:371]     Train net output #0: loss = 1.76447 (* 1 = 1.76447 loss)
I0629 04:52:47.133460  5893 sgd_solver.cpp:137] Iteration 156900, lr = 0.00019375, m = 0.9
I0629 04:53:05.412833  5893 solver.cpp:401] Sparsity after update:
I0629 04:53:05.418021  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:53:05.418035  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:53:05.418040  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:53:05.418041  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:53:05.418043  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:53:05.418045  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:53:05.418047  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:53:05.418050  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:53:05.418051  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:53:05.418053  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:53:05.418058  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:53:05.418061  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:53:05.418062  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:53:05.418072  5893 solver.cpp:545] Iteration 157000, Testing net (#0)
I0629 04:53:29.705588  5888 data_reader.cpp:262] Starting prefetch of epoch 157
I0629 04:53:29.774668  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57588
I0629 04:53:29.774689  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.8028
I0629 04:53:29.774694  5893 solver.cpp:630]     Test net output #2: loss = 1.8572 (* 1 = 1.8572 loss)
I0629 04:53:29.774709  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3561s
I0629 04:53:29.964581  5893 solver.cpp:349] Iteration 157000 (2.3348 iter/s, 42.8302s/100 iter), loss = 1.44738
I0629 04:53:29.964603  5893 solver.cpp:371]     Train net output #0: loss = 1.30901 (* 1 = 1.30901 loss)
I0629 04:53:29.964607  5893 sgd_solver.cpp:137] Iteration 157000, lr = 0.0001875, m = 0.9
I0629 04:53:48.380754  5893 solver.cpp:349] Iteration 157100 (5.43014 iter/s, 18.4157s/100 iter), loss = 1.40468
I0629 04:53:48.380873  5893 solver.cpp:371]     Train net output #0: loss = 1.34811 (* 1 = 1.34811 loss)
I0629 04:53:48.380880  5893 sgd_solver.cpp:137] Iteration 157100, lr = 0.00018125, m = 0.9
I0629 04:54:06.812295  5893 solver.cpp:349] Iteration 157200 (5.42565 iter/s, 18.431s/100 iter), loss = 1.84957
I0629 04:54:06.812319  5893 solver.cpp:371]     Train net output #0: loss = 1.99128 (* 1 = 1.99128 loss)
I0629 04:54:06.812325  5893 sgd_solver.cpp:137] Iteration 157200, lr = 0.000175, m = 0.9
I0629 04:54:25.250313  5893 solver.cpp:349] Iteration 157300 (5.42371 iter/s, 18.4376s/100 iter), loss = 1.56099
I0629 04:54:25.250432  5893 solver.cpp:371]     Train net output #0: loss = 1.52581 (* 1 = 1.52581 loss)
I0629 04:54:25.250439  5893 sgd_solver.cpp:137] Iteration 157300, lr = 0.00016875, m = 0.9
I0629 04:54:43.717947  5893 solver.cpp:349] Iteration 157400 (5.415 iter/s, 18.4672s/100 iter), loss = 1.26218
I0629 04:54:43.717970  5893 solver.cpp:371]     Train net output #0: loss = 1.30905 (* 1 = 1.30905 loss)
I0629 04:54:43.717974  5893 sgd_solver.cpp:137] Iteration 157400, lr = 0.0001625, m = 0.9
I0629 04:55:02.148730  5893 solver.cpp:349] Iteration 157500 (5.42575 iter/s, 18.4306s/100 iter), loss = 1.71167
I0629 04:55:02.148792  5893 solver.cpp:371]     Train net output #0: loss = 2.05593 (* 1 = 2.05593 loss)
I0629 04:55:02.148797  5893 sgd_solver.cpp:137] Iteration 157500, lr = 0.00015625, m = 0.9
I0629 04:55:20.561218  5893 solver.cpp:349] Iteration 157600 (5.43115 iter/s, 18.4123s/100 iter), loss = 1.80388
I0629 04:55:20.561239  5893 solver.cpp:371]     Train net output #0: loss = 1.88876 (* 1 = 1.88876 loss)
I0629 04:55:20.561244  5893 sgd_solver.cpp:137] Iteration 157600, lr = 0.00015, m = 0.9
I0629 04:55:39.003975  5893 solver.cpp:349] Iteration 157700 (5.42223 iter/s, 18.4426s/100 iter), loss = 1.76453
I0629 04:55:39.004051  5893 solver.cpp:371]     Train net output #0: loss = 1.70444 (* 1 = 1.70444 loss)
I0629 04:55:39.004055  5893 sgd_solver.cpp:137] Iteration 157700, lr = 0.00014375, m = 0.9
I0629 04:55:57.493505  5893 solver.cpp:349] Iteration 157800 (5.40854 iter/s, 18.4893s/100 iter), loss = 1.92837
I0629 04:55:57.493528  5893 solver.cpp:371]     Train net output #0: loss = 1.85438 (* 1 = 1.85438 loss)
I0629 04:55:57.493532  5893 sgd_solver.cpp:137] Iteration 157800, lr = 0.0001375, m = 0.9
I0629 04:56:16.029750  5893 solver.cpp:349] Iteration 157900 (5.39489 iter/s, 18.536s/100 iter), loss = 1.43103
I0629 04:56:16.029848  5893 solver.cpp:371]     Train net output #0: loss = 1.31125 (* 1 = 1.31125 loss)
I0629 04:56:16.029857  5893 sgd_solver.cpp:137] Iteration 157900, lr = 0.00013125, m = 0.9
I0629 04:56:34.315888  5893 solver.cpp:401] Sparsity after update:
I0629 04:56:34.321111  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 04:56:34.321118  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 04:56:34.321125  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 04:56:34.321127  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 04:56:34.321130  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 04:56:34.321131  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 04:56:34.321133  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 04:56:34.321135  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 04:56:34.321137  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 04:56:34.321140  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 04:56:34.321141  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 04:56:34.321142  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 04:56:34.321144  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 04:56:34.321152  5893 solver.cpp:545] Iteration 158000, Testing net (#0)
I0629 04:56:58.603221  5888 data_reader.cpp:262] Starting prefetch of epoch 158
I0629 04:56:58.665249  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57556
I0629 04:56:58.665271  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80168
I0629 04:56:58.665276  5893 solver.cpp:630]     Test net output #2: loss = 1.85801 (* 1 = 1.85801 loss)
I0629 04:56:58.665293  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.3437s
I0629 04:56:58.850332  5893 solver.cpp:349] Iteration 158000 (2.33536 iter/s, 42.8199s/100 iter), loss = 1.46735
I0629 04:56:58.850354  5893 solver.cpp:371]     Train net output #0: loss = 1.0568 (* 1 = 1.0568 loss)
I0629 04:56:58.850358  5893 sgd_solver.cpp:137] Iteration 158000, lr = 0.000125, m = 0.9
I0629 04:57:17.278434  5893 solver.cpp:349] Iteration 158100 (5.42665 iter/s, 18.4276s/100 iter), loss = 1.43732
I0629 04:57:17.278457  5893 solver.cpp:371]     Train net output #0: loss = 1.66724 (* 1 = 1.66724 loss)
I0629 04:57:17.278461  5893 sgd_solver.cpp:137] Iteration 158100, lr = 0.00011875, m = 0.9
I0629 04:57:35.694865  5893 solver.cpp:349] Iteration 158200 (5.43008 iter/s, 18.4159s/100 iter), loss = 1.32577
I0629 04:57:35.694970  5893 solver.cpp:371]     Train net output #0: loss = 1.41316 (* 1 = 1.41316 loss)
I0629 04:57:35.694977  5893 sgd_solver.cpp:137] Iteration 158200, lr = 0.0001125, m = 0.9
I0629 04:57:54.142602  5893 solver.cpp:349] Iteration 158300 (5.4209 iter/s, 18.4471s/100 iter), loss = 1.53903
I0629 04:57:54.142626  5893 solver.cpp:371]     Train net output #0: loss = 1.65522 (* 1 = 1.65522 loss)
I0629 04:57:54.142629  5893 sgd_solver.cpp:137] Iteration 158300, lr = 0.00010625, m = 0.9
I0629 04:58:12.577785  5893 solver.cpp:349] Iteration 158400 (5.42456 iter/s, 18.4347s/100 iter), loss = 1.42645
I0629 04:58:12.577857  5893 solver.cpp:371]     Train net output #0: loss = 1.16605 (* 1 = 1.16605 loss)
I0629 04:58:12.577862  5893 sgd_solver.cpp:137] Iteration 158400, lr = 9.99999e-05, m = 0.9
I0629 04:58:31.040904  5893 solver.cpp:349] Iteration 158500 (5.41637 iter/s, 18.4626s/100 iter), loss = 1.68696
I0629 04:58:31.040922  5893 solver.cpp:371]     Train net output #0: loss = 1.59691 (* 1 = 1.59691 loss)
I0629 04:58:31.040927  5893 sgd_solver.cpp:137] Iteration 158500, lr = 9.37498e-05, m = 0.9
I0629 04:58:49.483211  5893 solver.cpp:349] Iteration 158600 (5.42247 iter/s, 18.4418s/100 iter), loss = 1.57751
I0629 04:58:49.483283  5893 solver.cpp:371]     Train net output #0: loss = 1.50168 (* 1 = 1.50168 loss)
I0629 04:58:49.483288  5893 sgd_solver.cpp:137] Iteration 158600, lr = 8.75002e-05, m = 0.9
I0629 04:59:07.980346  5893 solver.cpp:349] Iteration 158700 (5.40641 iter/s, 18.4966s/100 iter), loss = 1.65464
I0629 04:59:07.980370  5893 solver.cpp:371]     Train net output #0: loss = 1.91847 (* 1 = 1.91847 loss)
I0629 04:59:07.980373  5893 sgd_solver.cpp:137] Iteration 158700, lr = 8.12501e-05, m = 0.9
I0629 04:59:26.492827  5893 solver.cpp:349] Iteration 158800 (5.40191 iter/s, 18.512s/100 iter), loss = 1.60111
I0629 04:59:26.492931  5893 solver.cpp:371]     Train net output #0: loss = 1.56416 (* 1 = 1.56416 loss)
I0629 04:59:26.492938  5893 sgd_solver.cpp:137] Iteration 158800, lr = 7.49999e-05, m = 0.9
I0629 04:59:45.005998  5893 solver.cpp:349] Iteration 158900 (5.40174 iter/s, 18.5126s/100 iter), loss = 1.5392
I0629 04:59:45.006021  5893 solver.cpp:371]     Train net output #0: loss = 1.49743 (* 1 = 1.49743 loss)
I0629 04:59:45.006026  5893 sgd_solver.cpp:137] Iteration 158900, lr = 6.87498e-05, m = 0.9
I0629 05:00:03.308804  5893 solver.cpp:401] Sparsity after update:
I0629 05:00:03.314054  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 05:00:03.314064  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 05:00:03.314069  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 05:00:03.314072  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 05:00:03.314074  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 05:00:03.314076  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 05:00:03.314079  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 05:00:03.314079  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 05:00:03.314081  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 05:00:03.314083  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 05:00:03.314085  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 05:00:03.314087  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 05:00:03.314090  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 05:00:03.314096  5893 solver.cpp:545] Iteration 159000, Testing net (#0)
I0629 05:00:27.612983  5888 data_reader.cpp:262] Starting prefetch of epoch 159
I0629 05:00:27.741592  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57604
I0629 05:00:27.741611  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80144
I0629 05:00:27.741616  5893 solver.cpp:630]     Test net output #2: loss = 1.85728 (* 1 = 1.85728 loss)
I0629 05:00:27.741632  5893 solver.cpp:305] [MultiGPU] Tests completed in 24.4269s
I0629 05:00:27.926002  5893 solver.cpp:349] Iteration 159000 (2.32998 iter/s, 42.9188s/100 iter), loss = 1.9855
I0629 05:00:27.926023  5893 solver.cpp:371]     Train net output #0: loss = 1.91578 (* 1 = 1.91578 loss)
I0629 05:00:27.926028  5893 sgd_solver.cpp:137] Iteration 159000, lr = 6.25002e-05, m = 0.9
I0629 05:00:46.339157  5893 solver.cpp:349] Iteration 159100 (5.43106 iter/s, 18.4126s/100 iter), loss = 1.25355
I0629 05:00:46.339275  5893 solver.cpp:371]     Train net output #0: loss = 1.40664 (* 1 = 1.40664 loss)
I0629 05:00:46.339282  5893 sgd_solver.cpp:137] Iteration 159100, lr = 5.62501e-05, m = 0.9
I0629 05:01:04.754334  5893 solver.cpp:349] Iteration 159200 (5.43049 iter/s, 18.4145s/100 iter), loss = 1.48822
I0629 05:01:04.754357  5893 solver.cpp:371]     Train net output #0: loss = 1.37917 (* 1 = 1.37917 loss)
I0629 05:01:04.754361  5893 sgd_solver.cpp:137] Iteration 159200, lr = 5e-05, m = 0.9
I0629 05:01:23.173070  5893 solver.cpp:349] Iteration 159300 (5.42941 iter/s, 18.4182s/100 iter), loss = 1.68579
I0629 05:01:23.173141  5893 solver.cpp:371]     Train net output #0: loss = 1.49083 (* 1 = 1.49083 loss)
I0629 05:01:23.173146  5893 sgd_solver.cpp:137] Iteration 159300, lr = 4.37498e-05, m = 0.9
I0629 05:01:41.592695  5893 solver.cpp:349] Iteration 159400 (5.42916 iter/s, 18.419s/100 iter), loss = 1.48299
I0629 05:01:41.592718  5893 solver.cpp:371]     Train net output #0: loss = 1.33005 (* 1 = 1.33005 loss)
I0629 05:01:41.592723  5893 sgd_solver.cpp:137] Iteration 159400, lr = 3.75003e-05, m = 0.9
I0629 05:02:00.044790  5893 solver.cpp:349] Iteration 159500 (5.4196 iter/s, 18.4516s/100 iter), loss = 1.45834
I0629 05:02:00.044891  5893 solver.cpp:371]     Train net output #0: loss = 1.37082 (* 1 = 1.37082 loss)
I0629 05:02:00.044898  5893 sgd_solver.cpp:137] Iteration 159500, lr = 3.12501e-05, m = 0.9
I0629 05:02:18.474617  5893 solver.cpp:349] Iteration 159600 (5.42617 iter/s, 18.4292s/100 iter), loss = 1.58096
I0629 05:02:18.474639  5893 solver.cpp:371]     Train net output #0: loss = 1.62614 (* 1 = 1.62614 loss)
I0629 05:02:18.474644  5893 sgd_solver.cpp:137] Iteration 159600, lr = 2.5e-05, m = 0.9
I0629 05:02:37.021456  5893 solver.cpp:349] Iteration 159700 (5.39191 iter/s, 18.5463s/100 iter), loss = 1.88802
I0629 05:02:37.021728  5893 solver.cpp:371]     Train net output #0: loss = 1.64129 (* 1 = 1.64129 loss)
I0629 05:02:37.021736  5893 sgd_solver.cpp:137] Iteration 159700, lr = 1.87498e-05, m = 0.9
I0629 05:02:55.531394  5893 solver.cpp:349] Iteration 159800 (5.40274 iter/s, 18.5091s/100 iter), loss = 1.45646
I0629 05:02:55.531417  5893 solver.cpp:371]     Train net output #0: loss = 1.38983 (* 1 = 1.38983 loss)
I0629 05:02:55.531421  5893 sgd_solver.cpp:137] Iteration 159800, lr = 1.25003e-05, m = 0.9
I0629 05:03:13.994283  5893 solver.cpp:349] Iteration 159900 (5.41643 iter/s, 18.4623s/100 iter), loss = 1.63588
I0629 05:03:13.994382  5893 solver.cpp:371]     Train net output #0: loss = 1.95773 (* 1 = 1.95773 loss)
I0629 05:03:13.994390  5893 sgd_solver.cpp:137] Iteration 159900, lr = 6.25014e-06, m = 0.9
I0629 05:03:32.326974  5893 solver.cpp:349] Iteration 159999 (5.40037 iter/s, 18.3321s/100 iter), loss = 1.17524
I0629 05:03:32.326997  5893 solver.cpp:371]     Train net output #0: loss = 1.07651 (* 1 = 1.07651 loss)
I0629 05:03:32.327004  5893 solver.cpp:675] Snapshotting to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_160000.caffemodel
I0629 05:03:32.337569  5893 sgd_solver.cpp:288] Snapshotting solver state to binary proto file training/imagenet_jacintonet11v2_2017-06-28_19-45-45/sparse/imagenet_jacintonet11v2_iter_160000.solverstate
I0629 05:03:32.342806  5893 solver.cpp:401] Sparsity after update:
I0629 05:03:32.343658  5893 net.cpp:2161] Num Params(11), Sparsity (zero_weights/count): 
I0629 05:03:32.343667  5893 net.cpp:2170] conv1a_param_0(0.405) 
I0629 05:03:32.343673  5893 net.cpp:2170] conv1b_param_0(0.737) 
I0629 05:03:32.343675  5893 net.cpp:2170] fc1000_param_0(0) 
I0629 05:03:32.343677  5893 net.cpp:2170] res2a_branch2a_param_0(0.81) 
I0629 05:03:32.343679  5893 net.cpp:2170] res2a_branch2b_param_0(0.81) 
I0629 05:03:32.343682  5893 net.cpp:2170] res3a_branch2a_param_0(0.81) 
I0629 05:03:32.343683  5893 net.cpp:2170] res3a_branch2b_param_0(0.81) 
I0629 05:03:32.343685  5893 net.cpp:2170] res4a_branch2a_param_0(0.81) 
I0629 05:03:32.343688  5893 net.cpp:2170] res4a_branch2b_param_0(0.81) 
I0629 05:03:32.343688  5893 net.cpp:2170] res5a_branch2a_param_0(0.81) 
I0629 05:03:32.343690  5893 net.cpp:2170] res5a_branch2b_param_0(0.81) 
I0629 05:03:32.343693  5893 net.cpp:2172] Total Sparsity (zero_weights/count) =  (1.90622e+06/2.86678e+06) 0.665
I0629 05:03:32.447551  5893 solver.cpp:522] Iteration 160000, loss = 1.99174
I0629 05:03:32.447623  5893 solver.cpp:545] Iteration 160000, Testing net (#0)
I0629 05:03:56.771296  5888 data_reader.cpp:262] Starting prefetch of epoch 160
I0629 05:03:56.851083  5893 solver.cpp:630]     Test net output #0: accuracy/top1 = 0.57612
I0629 05:03:56.851104  5893 solver.cpp:630]     Test net output #1: accuracy/top5 = 0.80172
I0629 05:03:56.851109  5893 solver.cpp:630]     Test net output #2: loss = 1.85697 (* 1 = 1.85697 loss)
I0629 05:03:56.884251  5852 parallel.cpp:71] Root Solver performance on device 0: 4.786 * 64 = 306.3 img/sec
I0629 05:03:56.884265  5852 parallel.cpp:76]      Solver performance on device 1: 4.786 * 64 = 306.3 img/sec
I0629 05:03:56.884268  5852 parallel.cpp:79] Overall multi-GPU performance: 612.588 img/sec
I0629 05:03:57.440055  5852 caffe.cpp:247] Optimization Done in 9h 17m 42s
